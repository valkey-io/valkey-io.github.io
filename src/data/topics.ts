// This file is auto-generated. Do not edit manually.
import { CommandCategory, TopicCategory } from './types';

export const topics: CommandCategory[] = [
  {
    "id": "ARM",
    "topicName": "ARM support",
    "description": "Exploring Valkey on the ARM CPU Architecture\n",
    "htmlContent": "<p>Valkey supports the ARM processor, for example<br>the Raspberry Pi, as a main platform.<br>While Valkey does run on Android, in the future we look forward to extend our testing efforts to Android<br>to also make it an officially supported platform.</p>\n<p>We believe that Valkey is ideal for IoT and embedded devices for several<br>reasons:</p>\n<ul>\n<li>Valkey has a very small memory footprint and CPU requirements. It can run in small devices like the Raspberry Pi Zero without impacting the overall performance, using a small amount of memory while delivering good performance for many use cases.</li>\n<li>The data structures of Valkey are often an ideal way to model IoT/embedded use cases. Some examples include accumulating time series data, receiving or queuing commands to execute or respond to send back to the remote servers, and so forth.</li>\n<li>Modeling data inside Valkey can be very useful in order to make in-device decisions for appliances that must respond very quickly or when the remote servers are offline.</li>\n<li>Valkey can be used as a communication system between the processes running in the device.</li>\n<li>The append-only file storage of Valkey is well suited for SSD cards.</li>\n<li>The stream data structure was specifically designed for time series applications and has a very low memory overhead.</li>\n</ul>\n<h2>Valkey /proc/cpu/alignment requirements</h2>\n<p>Linux on ARM allows to trap unaligned accesses and fix them inside the kernel<br>in order to continue the execution of the offending program instead of<br>generating a <code>SIGBUS</code>. Valkey avoids any kind<br>of unaligned access, so there is no need to have a specific value for this<br>kernel configuration. Even when kernel alignment fixing set as disabled Valkey should<br>run as expected.</p>\n<h2>Building Valkey in the Pi</h2>\n<ul>\n<li>Download Valkey.</li>\n<li>Use <code>make</code> as usual to create the executable.</li>\n</ul>\n<p>There is nothing special in the process. The only difference is that by<br>default, Valkey uses the <code>libc</code> allocator instead of defaulting to <code>jemalloc</code><br>as it does in other Linux based environments. This is because we believe<br>that for the small use cases inside embedded devices, memory fragmentation<br>is unlikely to be a problem. Moreover <code>jemalloc</code> on ARM may not be as tested<br>as the <code>libc</code> allocator.</p>\n<h2>Performance</h2>\n<p>Performance testing of Valkey was performed on the Raspberry Pi 3 and Pi 1 model B. The difference between the two Pis in terms of delivered performance is quite big. The benchmarks were performed via the<br>loopback interface, since most use cases will probably use Valkey from within<br>the device and not via the network. The following numbers were obtained using<br>Redis OSS 4.0.</p>\n<p>Raspberry Pi 3:</p>\n<ul>\n<li>Test 1 : 5 millions writes with 1 million keys (even distribution among keys).  No persistence, no pipelining. 28,000 ops/sec.</li>\n<li>Test 2: Like test 1 but with pipelining using groups of 8 operations: 80,000 ops/sec.</li>\n<li>Test 3: Like test 1 but with AOF enabled, fsync 1 sec: 23,000 ops/sec</li>\n<li>Test 4: Like test 3, but with an AOF rewrite in progress: 21,000 ops/sec</li>\n</ul>\n<p>Raspberry Pi 1 model B:</p>\n<ul>\n<li>Test 1 : 5 millions writes with 1 million keys (even distribution among keys).  No persistence, no pipelining.  2,200 ops/sec.</li>\n<li>Test 2: Like test 1 but with pipelining using groups of 8 operations: 8,500 ops/sec.</li>\n<li>Test 3: Like test 1 but with AOF enabled, fsync 1 sec: 1,820 ops/sec</li>\n<li>Test 4: Like test 3, but with an AOF rewrite in progress: 1,000 ops/sec</li>\n</ul>\n<p>The benchmarks above are referring to simple <code>SET</code>/<code>GET</code> operations. The performance is similar for all the Valkey fast operations (not running in linear time). However sorted sets may show slightly slower numbers.</p>\n"
  },
  {
    "id": "RDMA",
    "topicName": "RDMA experimental support",
    "description": "Valkey Over RDMA experimental support",
    "htmlContent": "<p>Valkey supports the Remote Direct Memory Access (RDMA) connection type via a<br>Valkey module that can be dynamically loaded on demand.</p>\n<h2>Getting Started</h2>\n<p><a href=\"https://en.wikipedia.org/wiki/Remote_direct_memory_access\">RDMA</a><br>enables direct data exchange between networked computers&#39; main memory,<br>bypassing processors and operating systems.</p>\n<p>As a result, RDMA offers better performance compared to TCP/IP. Test results indicate that<br>Valkey Over RDMA achieves approximately 2 times higher QPS and lower latency.</p>\n<p>Please note that Valkey Over RDMA is currently supported only on Linux.<br>Also, before using Valkey Over RDMA, you must understand how to configure<br>RDMA on your server and client machines.</p>\n<h2>Running manually</h2>\n<p>To run a Valkey server with RDMA mode:</p>\n<pre><code>./src/valkey-server --protected-mode no \\\n     --loadmodule src/valkey-rdma.so bind=192.168.122.100 port=6379\n</code></pre>\n<p>Bind address/port of RDMA can be modified at runtime using the following command:</p>\n<pre><code>192.168.122.100:6379&gt; CONFIG SET rdma-port 6380\n</code></pre>\n<p>Valkey can run both RDMA and TCP/IP concurrently on the same port:</p>\n<pre><code>./src/valkey-server --protected-mode no \\\n     --loadmodule src/valkey-rdma.so bind=192.168.122.100 port=6379 \\\n     --port 6379\n</code></pre>\n<p>Or append <code>loadmodule src/valkey-rdma.so bind=192.168.122.100 port=6379</code> in valkey.conf, then:</p>\n<pre><code>./src/valkey-server valkey.conf\n</code></pre>\n<h3>Prerequisites</h3>\n<p>Note that the network interface (192.168.122.100 of this example) should support<br>RDMA. To test a server supports RDMA or not:</p>\n<pre><code>rdma dev show (a new version iproute2 package)\n</code></pre>\n<p>Or:</p>\n<pre><code>ibv_devices (ibverbs-utils package of Debian/Ubuntu)\n</code></pre>\n<h2>Performance tuning</h2>\n<p>The RDMA completion queue will use the completion vector to signal completion events<br>via hardware interrupts. A large number of hardware interrupts can affect CPU performance.<br>It is possible to tune the performance using <code>rdma-comp-vector</code>.</p>\n<p>See <a href=\"https://man7.org/linux/man-pages/man3/ibv_create_cq.3.html\">RDMA CQ completion vector</a></p>\n<h3>Example 1</h3>\n<ul>\n<li>Pin hardware interrupt vectors [0, 3] to CPU [0, 3].</li>\n<li>Set CPU affinity for valkey to CPU [4, X].</li>\n<li>Any valkey server uses a random RDMA completion vector [-1].</li>\n</ul>\n<p>All valkey servers will not affect each other and will be isolated from kernel interrupts.</p>\n<pre><code>  SYS    SYS    SYS    SYS  VALKEY VALKEY     VALKEY\n   |      |      |      |      |      |          |\n CPU0   CPU1   CPU2   CPU3   CPU4   CPU5   ... CPUX\n   |      |      |      |\n INTR0  INTR1  INTR2  INTR3\n</code></pre>\n<h3>Example 2</h3>\n<ul>\n<li>Pin hardware interrupt vectors [0, X] to CPU [0, X].</li>\n<li>Set CPU affinity for valkey [M] to CPU [M].</li>\n<li>Valkey server [M] uses RDMA completion vector [M].</li>\n</ul>\n<p>A single CPU [M] handles hardware interrupts, the RDMA completion vector [M],<br>and the valkey server [M] within its context only.<br>This avoids overhead and function calls across multiple CPUs, fully isolating<br>each valkey server from one another.</p>\n<pre><code>VALKEY VALKEY VALKEY VALKEY VALKEY VALKEY     VALKEY\n   |      |      |      |      |      |          |\n CPU0   CPU1   CPU2   CPU3   CPU4   CPU5  ...  CPUX\n   |      |      |      |      |      |          |\n INTR0  INTR1  INTR2  INTR3  INTR4  INTR5      INTRX\n</code></pre>\n<p>Use 0 and positive numbers to specify the RDMA completion vector, or specify -1 to allow<br>the server to use a random vector for a new connection. The default vector is -1.</p>\n<h2>Protocol</h2>\n<p>The protocol defines the Queue Pairs (QP) type reliable connection (RC),<br>like TCP, communication commands, and payload exchange mechanism.<br>This dependency is based solely on the RDMA (aka Infiniband) specification<br>and is independent of both software (including the OS and user libraries)<br>and hardware (including vendors and low-level transports).</p>\n<p>Valkey Over RDMA has control-plane (control messages) and data-plane (payload transfer).</p>\n<h3>Control message</h3>\n<p>Control messages use fixed 32-byte big-endian message structures:</p>\n<pre><code class=\"language-C\">typedef struct ValkeyRdmaFeature {\n    /* defined as following Opcodes */\n    uint16_t opcode;\n    /* select features */\n    uint16_t select;\n    uint8_t reserved[20];\n    /* feature bits */\n    uint64_t features;\n} ValkeyRdmaFeature;\n\ntypedef struct ValkeyRdmaKeepalive {\n    /* defined as following Opcodes */\n    uint16_t opcode;\n    uint8_t reserved[30];\n} ValkeyRdmaKeepalive;\n\ntypedef struct ValkeyRdmaMemory {\n    /* defined as following Opcodes */\n    uint16_t opcode;\n    uint8_t reserved[14];\n    /* address of a transfer buffer which is used to receive remote streaming data,\n     * aka &#39;RX buffer address&#39;. The remote side should use this as &#39;TX buffer address&#39; */\n    uint64_t addr;\n    /* length of the &#39;RX buffer&#39; */\n    uint32_t length;\n    /* the RDMA remote key of &#39;RX buffer&#39; */\n    uint32_t key;\n} ValkeyRdmaMemory;\n\ntypedef union ValkeyRdmaCmd {\n    ValkeyRdmaFeature feature;\n    ValkeyRdmaKeepalive keepalive;\n    ValkeyRdmaMemory memory;\n} ValkeyRdmaCmd;\n</code></pre>\n<h3>Opcodes</h3>\n<table>\n<thead>\n<tr>\n<th align=\"center\">Command</th>\n<th align=\"center\">Value</th>\n<th align=\"center\">Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\"><code>GetServerFeature</code></td>\n<td align=\"center\">0</td>\n<td align=\"center\">required, get the features offered by Valkey server</td>\n</tr>\n<tr>\n<td align=\"center\"><code>SetClientFeature</code></td>\n<td align=\"center\">1</td>\n<td align=\"center\">required, negotiate features and set it to Valkey server</td>\n</tr>\n<tr>\n<td align=\"center\"><code>Keepalive</code></td>\n<td align=\"center\">2</td>\n<td align=\"center\">required, detect unexpected orphan connection</td>\n</tr>\n<tr>\n<td align=\"center\"><code>RegisterXferMemory</code></td>\n<td align=\"center\">3</td>\n<td align=\"center\">required, tell the &#39;RX transfer buffer&#39; information to the remote side, and the remote side uses this as &#39;TX transfer buffer&#39;</td>\n</tr>\n</tbody></table>\n<p>Once any new feature and command are introduced into <code>Valkey Over RDMA</code>, the client should<br>detect the new feature <code>VALKEY_RDMA_FEATURE_FOO</code> through the <code>GetServerFeature</code> command,<br>and then use the <code>SetClientFeature</code> command to enable the feature <code>VALKEY_RDMA_FEATURE_FOO</code>.<br>Once <code>VALKEY_RDMA_FEATURE_FOO</code> is negotiated successfully, the optional<br><code>ValkeyRdmaFoo</code> command will be supported within the connection.</p>\n<h3>RDMA Operations</h3>\n<ul>\n<li>Send a control message by RDMA &#39;<strong><code>ibv_post_send</code></strong>&#39; with opcode &#39;<strong><code>IBV_WR_SEND</code></strong>&#39; with structure<br>&#39;ValkeyRdmaCmd&#39;.</li>\n<li>Receive a control message by RDMA &#39;<strong><code>ibv_post_recv</code></strong>&#39;, and the received buffer<br>size should be size of &#39;ValkeyRdmaCmd&#39;.</li>\n<li>Transfer stream data by RDMA &#39;<strong><code>ibv_post_send</code></strong>&#39; with opcode &#39;<strong><code>IBV_WR_RDMA_WRITE</code></strong>&#39; (optional) and<br>&#39;<strong><code>IBV_WR_RDMA_WRITE_WITH_IMM</code></strong>&#39; (required), to write data segments into a connection by<br>RDMA [WRITE][WRITE][WRITE]...[WRITE WITH IMM], the length of total buffer is described by<br>immediate data (unsigned int 32). For example:<br>a, [WRITE 128 bytes][WRITE 256 bytes][WRITE 128 bytes WITH IMM 512] writes 512 bytes to the<br>remote side, the remote side is notified only once.<br>b, [WRITE 128 bytes WITH IMM 128][WRITE 256 bytes WITH IMM 256][WRITE 128 bytes WITH IMM 128]<br>writes 512 bytes to the remote side, the remote side is notified three times.<br>Both example a and b write the same 512 bytes,<br>example a has better performance, however b is easier to implement.</li>\n</ul>\n<h3>Maximum WQEs of RDMA</h3>\n<p>No specific limit, 1024 recommended for WQEs.<br>Flow control for WQE MAY be defined/implemented in the future.</p>\n<h3>The workflow of this protocol</h3>\n<pre><code>                                                                    valkey-server\n                                                                    listen RDMA port\n   valkey-client\n                -------------------RDMA connect--------------------&gt;\n                                                                    accept connection\n                &lt;--------------- Establish RDMA --------------------\n\n                --------Get server feature [@IBV_WR_SEND] ---------&gt;\n\n                --------Set client feature [@IBV_WR_SEND] ---------&gt;\n                                                                    setup RX buffer\n                &lt;---- Register transfer memory [@IBV_WR_SEND] ------\n[@ibv_post_recv]\nsetup TX buffer\n                ----- Register transfer memory [@IBV_WR_SEND] -----&gt;\n                                                                    [@ibv_post_recv]\n                                                                    setup TX buffer\n                -- Valkey commands [@IBV_WR_RDMA_WRITE_WITH_IMM] --&gt;\n                &lt;- Valkey response [@IBV_WR_RDMA_WRITE_WITH_IMM] ---\n                                  .......\n                -- Valkey commands [@IBV_WR_RDMA_WRITE_WITH_IMM] --&gt;\n                &lt;- Valkey response [@IBV_WR_RDMA_WRITE_WITH_IMM] ---\n                                  .......\n\n\nRX is full\n                ----- Register transfer memory [@IBV_WR_SEND] -----&gt;\n                                                                    [@ibv_post_recv]\n                                                                    setup TX buffer\n                &lt;- Valkey response [@IBV_WR_RDMA_WRITE_WITH_IMM] ---\n                                  .......\n\n                                                                    RX is full\n                &lt;---- Register transfer memory [@IBV_WR_SEND] ------\n[@ibv_post_recv]\nsetup TX buffer\n                -- Valkey commands [@IBV_WR_RDMA_WRITE_WITH_IMM] --&gt;\n                &lt;- Valkey response [@IBV_WR_RDMA_WRITE_WITH_IMM] ---\n                                  .......\n\n                -------------------RDMA disconnect-----------------&gt;\n                &lt;------------------RDMA disconnect------------------\n</code></pre>\n<p>The Valkey Over RDMA protocol is designed to efficiently transfer stream data and<br>bears similarities to several mechanisms introduced in academic papers with some differences:</p>\n<ul>\n<li><a href=\"https://dl.acm.org/doi/10.1145/3341302.3342071\">Socksdirect: datacenter sockets can be fast and compatible</a></li>\n<li><a href=\"https://dl.acm.org/doi/abs/10.1145/3132747.3132762\">LITE Kernel RDMA Support for Datacenter Applications</a></li>\n<li><a href=\"https://www.usenix.org/system/files/conference/nsdi14/nsdi14-paper-dragojevic.pdf\">FaRM: Fast Remote Memory</a></li>\n</ul>\n<h2>How does Valkey use RDMA</h2>\n<p>Valkey supports a connection abstraction framework that hides listen/connect/accept/shutdown/read/write,<br>and so on. This allows the connection types to register into Valkey core during startup time.<br>What&#39;s more, a connection type is either Valkey built-in (Ex, TCP/IP and Unix domain socket) or<br>Valkey module (Ex, TLS).<br>Enabling RDMA support needs to link additional libraries, rather than valkey-server&#39;s additional dependence<br>on the shared libraries, build Valkey Over RDMA into Valkey module,<br>Then a user starts valkey-server with RDMA module, valkey-server loads the additional shared libraries on demand.</p>\n<h2>Limitations</h2>\n<ul>\n<li>Valkey Over RDMA is experimental, it may be changed or be removed in any minor or major version.</li>\n<li>TLS is not supported by Valkey Over RDMA. But it is workable in theory by a certain amount of work.</li>\n<li>Valkey Over RDMA is supported on Linux only.</li>\n<li>Not compatible with replication currently, TCP/TLS is needed for replication.</li>\n<li>Depending on different hardware, too many active queue pairs may lead performance drop.</li>\n</ul>\n"
  },
  {
    "id": "acl",
    "topicName": "ACL",
    "description": "Valkey Access Control List",
    "htmlContent": "<p>The Valkey ACL, short for Access Control List, is a feature that allows certain connections to be limited in terms of the commands that can be executed and the keys that can be accessed.<br>The way it works is that, after connecting, a client is required to provide a username and a valid password to authenticate.<br>If authentication succeeded, the connection is associated with a given user and the limits the user has.<br>Valkey can be configured so that new connections are already authenticated with a &quot;default&quot; user (this is the default configuration).<br>Configuring the default user has, as a side effect, the ability to provide only a specific subset of functionalities to connections that are not explicitly authenticated.</p>\n<p>The standard way to authenticate is the two-argument form of the <code>AUTH</code> command:</p>\n<pre><code>AUTH &lt;username&gt; &lt;password&gt;\n</code></pre>\n<p>If the password is valid matches, the connection will be authenticated to the user with the name <code>&lt;username&gt;</code>.</p>\n<p>When the single argument form of the command is used, where only the password is specified, it is assumed that the implicit username is &quot;default&quot;.</p>\n<pre><code>AUTH &lt;password&gt;\n</code></pre>\n<p>This form authenticates against the &quot;default&quot; user&#39;s password, either set by ACLs or by setting <code>requirepass</code>.</p>\n<h2>When ACLs are useful</h2>\n<p>Before using ACLs, you may want to ask yourself what&#39;s the goal you want to<br>accomplish by implementing this layer of protection. Normally there are<br>two main goals that are well served by ACLs:</p>\n<ol>\n<li>You want to improve security by restricting the access to commands and keys, so that untrusted clients have no access and trusted clients have just the minimum access level to the database in order to perform the work needed. For instance, certain clients may just be able to execute read only commands.</li>\n<li>You want to improve operational safety, so that processes or humans accessing Valkey are not allowed to damage the data or the configuration due to software errors or manual mistakes. For instance, there is no reason for a worker that fetches delayed jobs from Valkey to be able to call the <code>FLUSHALL</code> command.</li>\n</ol>\n<p>Another typical usage of ACLs is related to managed Valkey instances. Valkey is<br>often provided as a managed service both by internal company teams that handle<br>the Valkey infrastructure for the other internal customers they have, or is<br>provided in a software-as-a-service setup by cloud providers. In both<br>setups, we want to be sure that configuration commands are excluded for the<br>customers.</p>\n<h2>Configure ACLs with the ACL command</h2>\n<p>ACLs are defined using a DSL (domain specific language) that describes what<br>a given user is allowed to do. Such rules are always implemented from the<br>first to the last, left-to-right, because sometimes the order of the rules is<br>important to understand what the user is really able to do.</p>\n<p>By default there is a single user defined, called <em>default</em>. We<br>can use the <code>ACL LIST</code> command in order to check the currently active ACLs<br>and verify what the configuration of a freshly started, defaults-configured<br>Valkey instance is:</p>\n<pre><code>&gt; ACL LIST\n1) &quot;user default on nopass ~* &amp;* +@all&quot;\n</code></pre>\n<p>The command above reports the list of users in the same format that is<br>used in the Valkey configuration files, by translating the current ACLs set<br>for the users back into their description.</p>\n<p>The first two words in each line are &quot;user&quot; followed by the username. The<br>next words are ACL rules that describe different things. We&#39;ll show how the rules work in detail, but for now it is enough to say that the default<br>user is configured to be active (on), to require no password (nopass), to<br>access every possible key (<code>~*</code>) and Pub/Sub channel (<code>&amp;*</code>), and be able to<br>call every possible command (<code>+@all</code>).</p>\n<p>Also, in the special case of the default user, having the <em>nopass</em> rule means<br>that new connections are automatically authenticated with the default user<br>without any explicit <code>AUTH</code> call needed.</p>\n<h2>ACL rules</h2>\n<p>The following is the list of valid ACL rules. Certain rules are just<br>single words that are used in order to activate or remove a flag, or to<br>perform a given change to the user ACL. Other rules are char prefixes that<br>are concatenated with command or category names, key patterns, and<br>so forth.</p>\n<p>Enable and disallow users:</p>\n<ul>\n<li><code>on</code>: Enable the user: it is possible to authenticate as this user.</li>\n<li><code>off</code>: Disallow the user: it&#39;s no longer possible to authenticate with this user; however, previously authenticated connections will still work. Note that if the default user is flagged as <em>off</em>, new connections will start as not authenticated and will require the user to send <code>AUTH</code> or <code>HELLO</code> with the AUTH option in order to authenticate in some way, regardless of the default user configuration.</li>\n</ul>\n<p>Allow and disallow commands:</p>\n<ul>\n<li><code>+&lt;command&gt;</code>: Add the command to the list of commands the user can call. Can be used with <code>|</code> for allowing subcommands (e.g &quot;+config|get&quot;).</li>\n<li><code>-&lt;command&gt;</code>: Remove the command to the list of commands the user can call. Starting Valkey 7.0, it can be used with <code>|</code> for blocking subcommands (e.g &quot;-config|set&quot;).</li>\n<li><code>+@&lt;category&gt;</code>: Add all the commands in such category to be called by the user, with valid categories being like @admin, @set, @sortedset, ... and so forth, see the full list by calling the <code>ACL CAT</code> command. The special category @all means all the commands, both the ones currently present in the server, and the ones that will be loaded in the future via modules.</li>\n<li><code>-@&lt;category&gt;</code>: Like <code>+@&lt;category&gt;</code> but removes the commands from the list of commands the client can call.</li>\n<li><code>+&lt;command&gt;|first-arg</code>: Allow a specific first argument of an otherwise disabled command. It is only supported on commands with no sub-commands, and is not allowed as negative form like -SELECT|1, only additive starting with &quot;+&quot;. This feature is deprecated and may be removed in the future.</li>\n<li><code>allcommands</code>: Alias for +@all. Note that it implies the ability to execute all the future commands loaded via the modules system.</li>\n<li><code>nocommands</code>: Alias for -@all.</li>\n</ul>\n<p>Allow and disallow certain keys and key permissions:</p>\n<ul>\n<li><code>~&lt;pattern&gt;</code>: Add a pattern of keys that can be mentioned as part of commands. For instance <code>~*</code> allows all the keys. The pattern is a glob-style pattern like the one of <code>KEYS</code>. It is possible to specify multiple patterns.</li>\n<li><code>%R~&lt;pattern&gt;</code>: Add the specified read key pattern. This behaves similar to the regular key pattern but only grants permission to read from keys that match the given pattern. See <a href=\"#key-permissions\">key permissions</a> for more information.</li>\n<li><code>%W~&lt;pattern&gt;</code>: Add the specified write key pattern. This behaves similar to the regular key pattern but only grants permission to write to keys that match the given pattern. See <a href=\"#key-permissions\">key permissions</a> for more information.</li>\n<li><code>%RW~&lt;pattern&gt;</code>: Alias for <code>~&lt;pattern&gt;</code>. </li>\n<li><code>allkeys</code>: Alias for <code>~*</code>.</li>\n<li><code>resetkeys</code>: Flush the list of allowed keys patterns. For instance the ACL <code>~foo:* ~bar:* resetkeys ~objects:*</code>, will only allow the client to access keys that match the pattern <code>objects:*</code>.</li>\n</ul>\n<p>Allow and disallow Pub/Sub channels:</p>\n<ul>\n<li><code>&amp;&lt;pattern&gt;</code>: Add a glob style pattern of Pub/Sub channels that can be accessed by the user. It is possible to specify multiple channel patterns. Note that pattern matching is done only for channels mentioned by <code>PUBLISH</code> and <code>SUBSCRIBE</code>, whereas <code>PSUBSCRIBE</code> requires a literal match between its channel patterns and those allowed for user.</li>\n<li><code>allchannels</code>: Alias for <code>&amp;*</code> that allows the user to access all Pub/Sub channels.</li>\n<li><code>resetchannels</code>: Flush the list of allowed channel patterns and disconnect the user&#39;s Pub/Sub clients if these are no longer able to access their respective channels and/or channel patterns.</li>\n</ul>\n<p>Configure valid passwords for the user:</p>\n<ul>\n<li><code>&gt;&lt;password&gt;</code>: Add this password to the list of valid passwords for the user. For example <code>&gt;mypass</code> will add &quot;mypass&quot; to the list of valid passwords.  This directive clears the <em>nopass</em> flag (see later). Every user can have any number of passwords.</li>\n<li><code>&lt;&lt;password&gt;</code>: Remove this password from the list of valid passwords. Emits an error in case the password you are trying to remove is actually not set.</li>\n<li><code>#&lt;hash&gt;</code>: Add this SHA-256 hash value to the list of valid passwords for the user. This hash value will be compared to the hash of a password entered for an ACL user. This allows users to store hashes in the <code>acl.conf</code> file rather than storing cleartext passwords. Only SHA-256 hash values are accepted as the password hash must be 64 characters and only contain lowercase hexadecimal characters.</li>\n<li><code>!&lt;hash&gt;</code>: Remove this hash value from the list of valid passwords. This is useful when you do not know the password specified by the hash value but would like to remove the password from the user.</li>\n<li><code>nopass</code>: All the set passwords of the user are removed, and the user is flagged as requiring no password: it means that every password will work against this user. If this directive is used for the default user, every new connection will be immediately authenticated with the default user without any explicit AUTH command required. Note that the <em>resetpass</em> directive will clear this condition.</li>\n<li><code>resetpass</code>: Flushes the list of allowed passwords and removes the <em>nopass</em> status. After <em>resetpass</em>, the user has no associated passwords and there is no way to authenticate without adding some password (or setting it as <em>nopass</em> later).</li>\n</ul>\n<p><em>Note: if a user is not flagged with nopass and has no list of valid passwords, that user is effectively impossible to use because there will be no way to log in as that user.</em></p>\n<p>Configure selectors for the user:</p>\n<ul>\n<li><code>(&lt;rule list&gt;)</code>: Create a new selector to match rules against. Selectors are evaluated after the user permissions, and are evaluated according to the order they are defined. If a command matches either the user permissions or any selector, it is allowed. See <a href=\"#selectors\">selectors</a> for more information.</li>\n<li><code>clearselectors</code>: Delete all of the selectors attached to the user.</li>\n</ul>\n<p>Reset the user:</p>\n<ul>\n<li><code>reset</code> Performs the following actions: resetpass, resetkeys, resetchannels, allchannels (if acl-pubsub-default is set), off, clearselectors, -@all. The user returns to the same state it had immediately after its creation.</li>\n</ul>\n<h2>Create and edit user ACLs with the ACL SETUSER command</h2>\n<p>Users can be created and modified in two main ways:</p>\n<ol>\n<li>Using the ACL command and its <code>ACL SETUSER</code> subcommand.</li>\n<li>Modifying the server configuration, where users can be defined, and restarting the server. With an <em>external ACL file</em>, just call <code>ACL LOAD</code>.</li>\n</ol>\n<p>In this section we&#39;ll learn how to define users using the <code>ACL</code> command.<br>With such knowledge, it will be trivial to do the same things via the<br>configuration files. Defining users in the configuration deserves its own<br>section and will be discussed later separately.</p>\n<p>To start, try the simplest <code>ACL SETUSER</code> command call:</p>\n<pre><code>&gt; ACL SETUSER alice\nOK\n</code></pre>\n<p>The <code>ACL SETUSER</code> command takes the username and a list of ACL rules to apply<br>to the user. However the above example did not specify any rule at all.<br>This will just create the user if it did not exist, using the defaults for new<br>users. If the user already exists, the command above will do nothing at all.</p>\n<p>Check the default user status:</p>\n<pre><code>&gt; ACL LIST\n1) &quot;user alice off resetchannels -@all&quot;\n2) &quot;user default on nopass ~* &amp;* +@all&quot;\n</code></pre>\n<p>The new user &quot;alice&quot; is:</p>\n<ul>\n<li>In the off status, so <code>AUTH</code> will not work for the user &quot;alice&quot;.</li>\n<li>The user also has no passwords set.</li>\n<li>Cannot access any command. Note that the user is created by default without the ability to access any command, so the <code>-@all</code> in the output above could be omitted; however, <code>ACL LIST</code> attempts to be explicit rather than implicit.</li>\n<li>There are no key patterns that the user can access.</li>\n<li>There are no Pub/Sub channels that the user can access.</li>\n</ul>\n<p>Such user is completely useless. Let&#39;s try to define the user so that<br>it is active, has a password, and can access with only the <code>GET</code> command<br>to key names starting with the string &quot;cached:&quot;.</p>\n<pre><code>&gt; ACL SETUSER alice on &gt;p1pp0 ~cached:* +get\nOK\n</code></pre>\n<p>Now the user can do something, but will refuse to do other things:</p>\n<pre><code>&gt; AUTH alice p1pp0\nOK\n&gt; GET foo\n(error) NOPERM this user has no permissions to access one of the keys used as arguments\n&gt; GET cached:1234\n(nil)\n&gt; SET cached:1234 zap\n(error) NOPERM this user has no permissions to run the &#39;set&#39; command\n</code></pre>\n<p>Things are working as expected. In order to inspect the configuration of the<br>user alice (remember that user names are case sensitive), it is possible to<br>use an alternative to <code>ACL LIST</code> which is designed to be more suitable for<br>computers to read, while <code>ACL GETUSER</code> is more human readable.</p>\n<pre><code>&gt; ACL GETUSER alice\n1) &quot;flags&quot;\n2) 1) &quot;on&quot;\n3) &quot;passwords&quot;\n4) 1) &quot;2d9c75...&quot;\n5) &quot;commands&quot;\n6) &quot;-@all +get&quot;\n7) &quot;keys&quot;\n8) &quot;~cached:*&quot;\n9) &quot;channels&quot;\n10) &quot;&quot;\n11) &quot;selectors&quot;\n12) (empty array)\n</code></pre>\n<p>The <code>ACL GETUSER</code> returns a field-value array that describes the user in more parsable terms. The output includes the set of flags, a list of key patterns, passwords, and so forth. The output is probably more readable if we use RESP3, so that it is returned as a map reply:</p>\n<pre><code>&gt; ACL GETUSER alice\n1# &quot;flags&quot; =&gt; 1~ &quot;on&quot;\n2# &quot;passwords&quot; =&gt; 1) &quot;2d9c75273d72b32df726fb545c8a4edc719f0a95a6fd993950b10c474ad9c927&quot;\n3# &quot;commands&quot; =&gt; &quot;-@all +get&quot;\n4# &quot;keys&quot; =&gt; &quot;~cached:*&quot;\n5# &quot;channels&quot; =&gt; &quot;&quot;\n6# &quot;selectors&quot; =&gt; (empty array)\n</code></pre>\n<p><em>Note: from now on, we&#39;ll continue using the Valkey default protocol, version 2</em></p>\n<p>Using another <code>ACL SETUSER</code> command (from a different user, because alice cannot run the <code>ACL</code> command), we can add multiple patterns to the user:</p>\n<pre><code>&gt; ACL SETUSER alice ~objects:* ~items:* ~public:*\nOK\n&gt; ACL LIST\n1) &quot;user alice on #2d9c75... ~cached:* ~objects:* ~items:* ~public:* resetchannels -@all +get&quot;\n2) &quot;user default on nopass ~* &amp;* +@all&quot;\n</code></pre>\n<p>The user representation in memory is now as we expect it to be.</p>\n<h2>Multiple calls to ACL SETUSER</h2>\n<p>It is very important to understand what happens when <code>ACL SETUSER</code> is called<br>multiple times. What is critical to know is that every <code>ACL SETUSER</code> call will<br>NOT reset the user, but will just apply the ACL rules to the existing user.<br>The user is reset only if it was not known before. In that case, a brand new<br>user is created with zeroed-ACLs. The user cannot do anything, is<br>disallowed, has no passwords, and so forth. This is the best default for safety.</p>\n<p>However later calls will just modify the user incrementally. For instance,<br>the following sequence:</p>\n<pre><code>&gt; ACL SETUSER myuser +set\nOK\n&gt; ACL SETUSER myuser +get\nOK\n</code></pre>\n<p>Will result in myuser being able to call both <code>GET</code> and <code>SET</code>:</p>\n<pre><code>&gt; ACL LIST\n1) &quot;user default on nopass ~* &amp;* +@all&quot;\n2) &quot;user myuser off resetchannels -@all +get +set&quot;\n</code></pre>\n<h2>Command categories</h2>\n<p>Setting user ACLs by specifying all the commands one after the other is<br>really annoying, so instead we do things like this:</p>\n<pre><code>&gt; ACL SETUSER antirez on +@all -@dangerous &gt;42a979... ~*\n</code></pre>\n<p>By saying +@all and -@dangerous, we included all the commands and later removed<br>all the commands that are tagged as dangerous inside the Valkey command table.<br>Note that command categories <strong>never include modules commands</strong> with<br>the exception of +@all. If you say +@all, all the commands can be executed by<br>the user, even future commands loaded via the modules system. However if you<br>use the ACL rule +@read or any other, the modules commands are always<br>excluded. This is very important because you should just trust the Valkey<br>internal command table. Modules may expose dangerous things and in<br>the case of an ACL that is just additive, that is, in the form of <code>+@all -...</code><br>You should be absolutely sure that you&#39;ll never include what you did not mean<br>to.</p>\n<p>The following is a list of command categories and their meanings:</p>\n<ul>\n<li><strong>admin</strong> - Administrative commands. Normal applications will never need to use<br>these. Includes <code>REPLICAOF</code>, <code>CONFIG</code>, <code>DEBUG</code>, <code>SAVE</code>, <code>MONITOR</code>, <code>ACL</code>, <code>SHUTDOWN</code>, etc.</li>\n<li><strong>bitmap</strong> - Data type: bitmaps related.</li>\n<li><strong>blocking</strong> - Potentially blocking the connection until released by another<br>command.</li>\n<li><strong>connection</strong> - Commands affecting the connection or other connections.<br>This includes <code>AUTH</code>, <code>SELECT</code>, <code>COMMAND</code>, <code>CLIENT</code>, <code>ECHO</code>, <code>PING</code>, etc.</li>\n<li><strong>dangerous</strong> - Potentially dangerous commands (each should be considered with care for<br>various reasons). This includes <code>FLUSHALL</code>, <code>MIGRATE</code>, <code>RESTORE</code>, <code>SORT</code>, <code>KEYS</code>,<br><code>CLIENT</code>, <code>DEBUG</code>, <code>INFO</code>, <code>CONFIG</code>, <code>SAVE</code>, <code>REPLICAOF</code>, etc.</li>\n<li><strong>geo</strong> - Data type: geospatial indexes related.</li>\n<li><strong>hash</strong> - Data type: hashes related.</li>\n<li><strong>hyperloglog</strong> - Data type: hyperloglog related.</li>\n<li><strong>fast</strong> - Fast O(1) commands. May loop on the number of arguments, but not the<br>number of elements in the key.</li>\n<li><strong>keyspace</strong> - Writing or reading from keys, databases, or their metadata<br>in a type agnostic way. Includes <code>DEL</code>, <code>RESTORE</code>, <code>DUMP</code>, <code>RENAME</code>, <code>EXISTS</code>, <code>DBSIZE</code>,<br><code>KEYS</code>, <code>EXPIRE</code>, <code>TTL</code>, <code>FLUSHALL</code>, etc. Commands that may modify the keyspace,<br>key, or metadata will also have the <code>write</code> category. Commands that only read<br>the keyspace, key, or metadata will have the <code>read</code> category.</li>\n<li><strong>list</strong> - Data type: lists related.</li>\n<li><strong>pubsub</strong> - PubSub-related commands.</li>\n<li><strong>read</strong> - Reading from keys (values or metadata). Note that commands that don&#39;t<br>interact with keys, will not have either <code>read</code> or <code>write</code>.</li>\n<li><strong>scripting</strong> - Scripting related.</li>\n<li><strong>set</strong> - Data type: sets related.</li>\n<li><strong>sortedset</strong> - Data type: sorted sets related.</li>\n<li><strong>slow</strong> - All commands that are not <code>fast</code>.</li>\n<li><strong>stream</strong> - Data type: streams related.</li>\n<li><strong>string</strong> - Data type: strings related.</li>\n<li><strong>transaction</strong> - <code>WATCH</code> / <code>MULTI</code> / <code>EXEC</code> related commands.</li>\n<li><strong>write</strong> - Writing to keys (values or metadata).</li>\n</ul>\n<p>Valkey can also show you a list of all categories and the exact commands each category includes using the Valkey <code>ACL CAT</code> command. It can be used in two forms:</p>\n<pre><code>ACL CAT -- Will just list all the categories available\nACL CAT &lt;category-name&gt; -- Will list all the commands inside the category\n</code></pre>\n<p>Examples:</p>\n<pre><code> &gt; ACL CAT\n 1) &quot;keyspace&quot;\n 2) &quot;read&quot;\n 3) &quot;write&quot;\n 4) &quot;set&quot;\n 5) &quot;sortedset&quot;\n 6) &quot;list&quot;\n 7) &quot;hash&quot;\n 8) &quot;string&quot;\n 9) &quot;bitmap&quot;\n10) &quot;hyperloglog&quot;\n11) &quot;geo&quot;\n12) &quot;stream&quot;\n13) &quot;pubsub&quot;\n14) &quot;admin&quot;\n15) &quot;fast&quot;\n16) &quot;slow&quot;\n17) &quot;blocking&quot;\n18) &quot;dangerous&quot;\n19) &quot;connection&quot;\n20) &quot;transaction&quot;\n21) &quot;scripting&quot;\n</code></pre>\n<p>As you can see, so far there are 21 distinct categories. Now let&#39;s check what<br>command is part of the <em>geo</em> category:</p>\n<pre><code> &gt; ACL CAT geo\n 1) &quot;geohash&quot;\n 2) &quot;georadius_ro&quot;\n 3) &quot;georadiusbymember&quot;\n 4) &quot;geopos&quot;\n 5) &quot;geoadd&quot;\n 6) &quot;georadiusbymember_ro&quot;\n 7) &quot;geodist&quot;\n 8) &quot;georadius&quot;\n 9) &quot;geosearch&quot;\n10) &quot;geosearchstore&quot;\n</code></pre>\n<p>Note that commands may be part of multiple categories. For example, an<br>ACL rule like <code>+@geo -@read</code> will result in certain geo commands to be<br>excluded because they are read-only commands.</p>\n<h2>Allow/block subcommands</h2>\n<p>Subcommands can be allowed/blocked just like other<br>commands (by using the separator <code>|</code> between the command and subcommand, for<br>example: <code>+config|get</code> or <code>-config|set</code>)</p>\n<p>That is true for all commands except DEBUG. In order to allow/block specific DEBUG subcommands, see the next section.</p>\n<h2>Allow the first-arg of a blocked command</h2>\n<p><strong>Note: This feature is deprecated and may be removed in the future.</strong></p>\n<p>Sometimes the ability to exclude or include a command or a subcommand as a whole is not enough.<br>Many deployments may not be happy providing the ability to execute a <code>SELECT</code> for any DB, but may<br>still want to be able to run <code>SELECT 0</code>.</p>\n<p>In such case we could alter the ACL of a user in the following way:</p>\n<pre><code>ACL SETUSER myuser -select +select|0\n</code></pre>\n<p>First, remove the <code>SELECT</code> command and then add the allowed<br>first-arg. Note that <strong>it is not possible to do the reverse</strong> since first-args<br>can be only added, not excluded. It is safer to specify all the first-args<br>that are valid for some user since it is possible that<br>new first-args may be added in the future.</p>\n<p>Another example:</p>\n<pre><code>ACL SETUSER myuser -debug +debug|digest\n</code></pre>\n<p>Note that first-arg matching may add some performance penalty; however, it is hard to measure even with synthetic benchmarks. The<br>additional CPU cost is only paid when such commands are called, and not when<br>other commands are called.</p>\n<p>It is possible to use this mechanism in order to allow subcommands in Valkey<br>versions prior to 7.0 (see above section).</p>\n<h2>+@all VS -@all</h2>\n<p>In the previous section, it was observed how it is possible to define command<br>ACLs based on adding/removing single commands.</p>\n<h2>Selectors</h2>\n<p>Valkey supports adding multiple sets of rules that are evaluated independently of each other.<br>These secondary sets of permissions are called selectors and added by wrapping a set of rules within parentheses.<br>In order to execute a command, either the root permissions (rules defined outside of parenthesis) or any of the selectors (rules defined inside parenthesis) must match the given command.<br>Internally, the root permissions are checked first followed by selectors in the order they were added.</p>\n<p>For example, consider a user with the ACL rules <code>+GET ~key1 (+SET ~key2)</code>.<br>This user is able to execute <code>GET key1</code> and <code>SET key2 hello</code>, but not <code>GET key2</code> or <code>SET key1 world</code>.</p>\n<p>Unlike the user&#39;s root permissions, selectors cannot be modified after they are added.<br>Instead, selectors can be removed with the <code>clearselectors</code> keyword, which removes all of the added selectors.<br>Note that <code>clearselectors</code> does not remove the root permissions.</p>\n<h2>Key permissions</h2>\n<p>key patterns can also be used to define how a command is able to touch a key.<br>This is achieved through rules that define key permissions.<br>The key permission rules take the form of <code>%(&lt;permission&gt;)~&lt;pattern&gt;</code>.<br>Permissions are defined as individual characters that map to the following key permissions:</p>\n<ul>\n<li>W (Write): The data stored within the key may be updated or deleted. </li>\n<li>R (Read): User supplied data from the key is processed, copied or returned. Note that this does not include metadata such as size information (example <code>STRLEN</code>), type information (example <code>TYPE</code>) or information about whether a value exists within a collection (example <code>SISMEMBER</code>).</li>\n</ul>\n<p>Permissions can be composed together by specifying multiple characters.<br>Specifying the permission as &#39;RW&#39; is considered full access and is analogous to just passing in <code>~&lt;pattern&gt;</code>.</p>\n<p>For a concrete example, consider a user with ACL rules <code>+@all ~app1:* (+@read ~app2:*)</code>.<br>This user has full access on <code>app1:*</code> and readonly access on <code>app2:*</code>.<br>However, some commands support reading data from one key, doing some transformation, and storing it into another key.<br>One such command is the <code>COPY</code> command, which copies the data from the source key into the destination key.<br>The example set of ACL rules is unable to handle a request copying data from <code>app2:user</code> into <code>app1:user</code>, since neither the root permission nor the selector fully matches the command.<br>However, using key selectors you can define a set of ACL rules that can handle this request <code>+@all ~app1:* %R~app2:*</code>.<br>The first pattern is able to match <code>app1:user</code> and the second pattern is able to match <code>app2:user</code>.</p>\n<p>Which type of permission is required for a command is documented through <a href=\"key-specs#logical-operation-flags\">key specifications</a>.<br>The type of permission is based off the keys logical operation flags.<br>The insert, update, and delete flags map to the write key permission.<br>The access flag maps to the read key permission.<br>If the key has no logical operation flags, such as <code>EXISTS</code>, the user still needs either key read or key write permissions to execute the command. </p>\n<p>Note: Side channels to accessing user data are ignored when it comes to evaluating whether read permissions are required to execute a command.<br>This means that some write commands that return metadata about the modified key only require write permission on the key to execute.<br>For example, consider the following two commands:</p>\n<ul>\n<li><code>LPUSH key1 data</code>: modifies &quot;key1&quot; but only returns metadata about it, the size of the list after the push, so the command only requires write permission on &quot;key1&quot; to execute.</li>\n<li><code>LPOP key2</code>: modifies &quot;key2&quot; but also returns data from it, the left most item in the list, so the command requires both read and write permission on &quot;key2&quot; to execute.</li>\n</ul>\n<p>If an application needs to make sure no data is accessed from a key, including side channels, it&#39;s recommended to not provide any access to the key.</p>\n<h2>How passwords are stored internally</h2>\n<p>Valkey internally stores passwords hashed with SHA256. If you set a password<br>and check the output of <code>ACL LIST</code> or <code>ACL GETUSER</code>, you&#39;ll see a long hex<br>string that looks pseudo random. Here is an example, because in the previous<br>examples, for the sake of brevity, the long hex string was trimmed:</p>\n<pre><code>&gt; ACL GETUSER default\n1) &quot;flags&quot;\n2) 1) &quot;on&quot;\n3) &quot;passwords&quot;\n4) 1) &quot;2d9c75273d72b32df726fb545c8a4edc719f0a95a6fd993950b10c474ad9c927&quot;\n5) &quot;commands&quot;\n6) &quot;+@all&quot;\n7) &quot;keys&quot;\n8) &quot;~*&quot;\n9) &quot;channels&quot;\n10) &quot;&amp;*&quot;\n11) &quot;selectors&quot;\n12) (empty array)\n</code></pre>\n<p>Using SHA256 provides the ability to avoid storing the password in clear text<br>while still allowing for a very fast <code>AUTH</code> command, which is a very important<br>feature of Valkey and is coherent with what clients expect from Valkey.</p>\n<p>However ACL <em>passwords</em> are not really passwords. They are shared secrets<br>between the server and the client, because the password is<br>not an authentication token used by a human being. For instance:</p>\n<ul>\n<li>There are no length limits, the password will just be memorized in some client software. There is no human that needs to recall a password in this context.</li>\n<li>The ACL password does not protect any other thing. For example, it will never be the password for some email account.</li>\n<li>Often when you are able to access the hashed password itself, by having full access to the Valkey commands of a given server, or corrupting the system itself, you already have access to what the password is protecting: the Valkey instance stability and the data it contains.</li>\n</ul>\n<p>For this reason, slowing down the password authentication, in order to use an<br>algorithm that uses time and space to make password cracking hard,<br>is a very poor choice. What we suggest instead is to generate strong<br>passwords, so that nobody will be able to crack it using a<br>dictionary or a brute force attack even if they have the hash. To do so, there is a special ACL<br>command <code>ACL GENPASS</code> that generates passwords using the system cryptographic pseudorandom<br>generator:</p>\n<pre><code>&gt; ACL GENPASS\n&quot;dd721260bfe1b3d9601e7fbab36de6d04e2e67b0ef1c53de59d45950db0dd3cc&quot;\n</code></pre>\n<p>The command outputs a 32-byte (256-bit) pseudorandom string converted to a<br>64-byte alphanumerical string. This is long enough to avoid attacks and short<br>enough to be easy to manage, cut &amp; paste, store, and so forth. This is what<br>you should use in order to generate Valkey passwords.</p>\n<h2>Use an external ACL file</h2>\n<p>There are two ways to store users inside the Valkey configuration:</p>\n<ol>\n<li>Users can be specified directly inside the <code>valkey.conf</code> file.</li>\n<li>It is possible to specify an external ACL file.</li>\n</ol>\n<p>The two methods are <em>mutually incompatible</em>, so Valkey will ask you to use one<br>or the other. Specifying users inside <code>valkey.conf</code> is<br>good for simple use cases. When there are multiple users to define, in a<br>complex environment, we recommend you use the ACL file instead.</p>\n<p>The format used inside <code>valkey.conf</code> and in the external ACL file is exactly<br>the same, so it is trivial to switch from one to the other, and is<br>the following:</p>\n<pre><code>user &lt;username&gt; ... acl rules ...\n</code></pre>\n<p>For instance:</p>\n<pre><code>user worker +@list +@connection ~jobs:* on &gt;ffa9203c493aa99\n</code></pre>\n<p>When you want to use an external ACL file, you are required to specify<br>the configuration directive called <code>aclfile</code>, like this:</p>\n<pre><code>aclfile /etc/valkey/users.acl\n</code></pre>\n<p>When you are just specifying a few users directly inside the <code>valkey.conf</code><br>file, you can use <code>CONFIG REWRITE</code> in order to store the new user configuration<br>inside the file by rewriting it.</p>\n<p>The external ACL file however is more powerful. You can do the following:</p>\n<ul>\n<li>Use <code>ACL LOAD</code> if you modified the ACL file manually and you want Valkey to reload the new configuration. Note that this command is able to load the file <em>only if all the users are correctly specified</em>. Otherwise, an error is reported to the user, and the old configuration will remain valid.</li>\n<li>Use <code>ACL SAVE</code> to save the current ACL configuration to the ACL file.</li>\n</ul>\n<p>Note that <code>CONFIG REWRITE</code> does not also trigger <code>ACL SAVE</code>. When you use<br>an ACL file, the configuration and the ACLs are handled separately.</p>\n<h2>ACL rules for Sentinel and Replicas</h2>\n<p>In case you don&#39;t want to provide Valkey replicas and Valkey Sentinel instances<br>full access to your Valkey instances, the following is the set of commands<br>that must be allowed in order for everything to work correctly.</p>\n<p>For Sentinel, allow the user to access the following commands both in the primary and replica instances:</p>\n<ul>\n<li>AUTH, CLIENT, SUBSCRIBE, SCRIPT, PUBLISH, PING, INFO, MULTI, SLAVEOF, CONFIG, CLIENT, EXEC.</li>\n</ul>\n<p>Sentinel does not need to access any key in the database but does use Pub/Sub, so the ACL rule would be the following (note: <code>AUTH</code> is not needed since it is always allowed):</p>\n<pre><code>ACL SETUSER sentinel-user on &gt;somepassword allchannels +multi +slaveof +ping +exec +subscribe +config|rewrite +role +publish +info +client|setname +client|kill +script|kill\n</code></pre>\n<p>Valkey replicas require the following commands to be allowed on the primary instance:</p>\n<ul>\n<li>PSYNC, REPLCONF, PING</li>\n</ul>\n<p>No keys need to be accessed, so this translates to the following rules:</p>\n<pre><code>ACL setuser replica-user on &gt;somepassword +psync +replconf +ping\n</code></pre>\n<p>Note that you don&#39;t need to configure the replicas to allow the primary to be able to execute any set of commands. The primary is always authenticated as the root user from the point of view of replicas.</p>\n"
  },
  {
    "id": "admin",
    "topicName": "Administration",
    "description": "Advice for configuring and managing Valkey in production",
    "htmlContent": "<h2>Valkey setup tips</h2>\n<h3>Linux</h3>\n<ul>\n<li><p>Deploy Valkey using the Linux operating system.<br>Valkey is also regularly tested on macOS and FreeBSD, and from time to time on other OpenBSD, NetBSD, DragonFlyBSD and Solaris-derived systems.<br>However, Linux is where most of the stress testing is performed, and where most production deployments are run.</p>\n</li>\n<li><p>Set the Linux kernel overcommit memory setting to 1. Add <code>vm.overcommit_memory = 1</code> to <code>/etc/sysctl.conf</code>. Then, reboot or run the command <code>sysctl vm.overcommit_memory=1</code> to activate the setting. See <a href=\"faq#background-saving-fails-with-a-fork-error-on-linux\">FAQ: Background saving fails with a fork() error on Linux?</a> for details. </p>\n</li>\n<li><p>To ensure the Linux kernel feature Transparent Huge Pages does not impact Valkey memory usage and latency, run the command: <code>echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</code> to disable it. See <a href=\"latency#latency-induced-by-transparent-huge-pages\">Latency Diagnosis - Latency induced by transparent huge pages</a> for additional context.</p>\n</li>\n</ul>\n<h3>Memory</h3>\n<ul>\n<li><p>Ensured that swap is enabled and that your swap file size is equal to amount of memory on your system. If Linux does not have swap set up, and your Valkey instance accidentally consumes too much memory, Valkey can crash when it is out of memory, or the Linux kernel OOM killer can kill the Valkey process. When swapping is enabled, you can detect latency spikes and act on them.</p>\n</li>\n<li><p>Set an explicit <code>maxmemory</code> option limit in your instance to make sure that it will report errors instead of failing when the system memory limit is near to be reached. Note that <code>maxmemory</code> should be set by calculating the overhead for Valkey, other than data, and the fragmentation overhead. So if you think you have 10 GB of free memory, set it to 8 or 9.</p>\n</li>\n<li><p>If you are using Valkey in a write-heavy application, while saving an RDB file on disk or rewriting the AOF log, Valkey can use up to 2 times the memory normally used. The additional memory used is proportional to the number of memory pages modified by writes during the saving process, so it is often proportional to the number of keys (or aggregate types items) touched during this time. Make sure to size your memory accordingly.</p>\n</li>\n<li><p>See the <code>LATENCY DOCTOR</code> and <code>MEMORY DOCTOR</code> commands to assist in troubleshooting.</p>\n</li>\n</ul>\n<h3>Imaging</h3>\n<ul>\n<li>When running under daemontools, use <code>daemonize no</code>.</li>\n</ul>\n<h3>Replication</h3>\n<ul>\n<li><p>Set up a non-trivial replication backlog in proportion to the amount of memory Valkey is using. The backlog allows replicas to sync with the primary instance much more easily.</p>\n</li>\n<li><p>If you use replication, Valkey performs RDB saves even if persistence is disabled. (This does not apply to diskless replication.) If you don&#39;t have disk usage on the primary, enable diskless replication.</p>\n</li>\n<li><p>If you are using replication, ensure that either your primary has persistence enabled, or that it does not automatically restart on crashes. Replicas will try to maintain an exact copy of the primary, so if a primary restarts with an empty data set, replicas will be wiped as well.</p>\n</li>\n</ul>\n<h3>Security</h3>\n<ul>\n<li>By default, Valkey does not require any authentication and listens to all the network interfaces. This is a big security issue if you leave Valkey exposed on the internet or other places where attackers can reach it. Please check our <a href=\"security\">security page</a> and the <a href=\"quickstart\">quick start</a> for information about how to secure Valkey.</li>\n</ul>\n<h2>Running Valkey on EC2</h2>\n<ul>\n<li>Use HVM based instances, not PV based instances.</li>\n<li>The use of Valkey persistence with EC2 EBS volumes needs to be handled with care because sometimes EBS volumes have high latency characteristics.</li>\n<li>You may want to try diskless replication if you have issues when replicas are synchronizing with the primary.</li>\n</ul>\n<h2>Upgrading or restarting a Valkey instance without downtime</h2>\n<p>Valkey is designed to be a long-running process in your server. You can modify many configuration options without a restart using the <code>CONFIG SET</code> command. You can also switch from AOF to RDB snapshots persistence, or the other way around, without restarting Valkey. Check the output of the <code>CONFIG GET *</code> command for more information.</p>\n<p>From time to time, a restart is required, for example, to upgrade the Valkey process to a newer version, or when you need to modify a configuration parameter that is currently not supported by the <code>CONFIG</code> command.</p>\n<p>Follow these steps to avoid downtime.</p>\n<ul>\n<li><p>Set up your new Valkey instance as a replica for your current Valkey instance. In order to do so, you need a different server, or a server that has enough RAM to keep two instances of Valkey running at the same time.</p>\n</li>\n<li><p>If you use a single server, ensure that the replica is started on a different port than the primary instance, otherwise the replica cannot start.</p>\n</li>\n<li><p>Wait for the replication initial synchronization to complete. Check the replica&#39;s log file.</p>\n</li>\n<li><p>Using <code>INFO</code>, ensure the primary and replica have the same number of keys. Use <code>valkey-cli</code> to check that the replica is working as expected and is replying to your commands.</p>\n</li>\n<li><p>Allow writes to the replica using <code>CONFIG SET replica-read-only no</code>.</p>\n</li>\n<li><p>Configure all your clients to use the new instance (the replica). Note that you may want to use the <code>CLIENT PAUSE</code> command to ensure that no client can write to the old primary during the switch.</p>\n</li>\n<li><p>Once you confirm that the primary is no longer receiving any queries (you can check this using the <code>MONITOR</code> command), elect the replica to primary using the <code>REPLICAOF NO ONE</code> command, and then shut down your primary.</p>\n</li>\n</ul>\n<p>If you are using <a href=\"sentinel\">Valkey Sentinel</a> or <a href=\"cluster-tutorial\">Valkey Cluster</a>, the simplest way to upgrade to newer versions is to upgrade one replica after the other. Then you can perform a manual failover to promote one of the upgraded replicas to primary, and finally promote the last replica.</p>\n"
  },
  {
    "id": "benchmark",
    "topicName": "Benchmarking tool",
    "description": "Using the valkey-benchmark utility on a Valkey server\n",
    "htmlContent": "<h2>Usage</h2>\n<p><strong><code>valkey-benchmark</code></strong> [ <em>OPTIONS</em> ] [ <em>COMMAND</em> <em>ARGS</em>... ]</p>\n<h2>Description</h2>\n<p>Valkey includes the <code>valkey-benchmark</code> utility that simulates running commands done<br>by N clients while at the same time sending M total queries. The utility provides<br>a default set of tests, or you can supply a custom set of tests.</p>\n<h2>Options</h2>\n<p><strong><code>-h</code></strong> <em>hostname</em><br>: Server hostname (default 127.0.0.1)</p>\n<p><strong><code>-p</code></strong> <em>port</em><br>: Server port (default 6379)</p>\n<p><strong><code>-s</code></strong> <em>socket</em><br>: Server socket (overrides host and port)</p>\n<p><strong><code>-a</code></strong> <em>password</em><br>: Password for Valkey Auth</p>\n<p><strong><code>--user</code></strong> <em>username</em><br>: Used to send ACL style &#39;AUTH username pass&#39;. Needs -a.</p>\n<p><strong><code>-u</code></strong> <em>uri</em><br>: Server URI on format <code>valkey://user:password@host:port/dbnum</code>.<br>  User, password and dbnum are optional. For authentication<br>  without a username, use username &#39;default&#39;. For TLS, use<br>  the scheme &#39;valkeys&#39;.</p>\n<p><strong><code>-c</code></strong> <em>clients</em><br>: Number of parallel connections (default 50).<br>  Note: If <code>--cluster</code> is used then number of clients has to be<br>  the same or higher than the number of nodes.</p>\n<p><strong><code>-n</code></strong> <em>requests</em><br>: Total number of requests (default 100000)</p>\n<p><strong><code>-d</code></strong> <em>size</em><br>: Data size of SET/GET value in bytes (default 3)</p>\n<p><strong><code>--dbnum</code></strong> <em>db</em><br>: SELECT the specified db number (default 0)</p>\n<p><strong><code>-3</code></strong><br>: Start session in RESP3 protocol mode.</p>\n<p><strong><code>--threads</code></strong> <em>num</em><br>: Enable multi-thread mode.</p>\n<p><strong><code>--cluster</code></strong><br>: Enable cluster mode.<br>  If the command is supplied on the command line in cluster<br>  mode, the key must contain &quot;{tag}&quot;. Otherwise, the<br>  command will not be sent to the right cluster node.</p>\n<p><strong><code>--rfr</code></strong> <em>mode</em><br>: Enable read from replicas in cluster mode.<br>  This command must be used with the <code>--cluster</code> option.<br>  There are three modes for reading from replicas:</p>\n<p>  <strong>no</strong> - sends read requests to primaries only (default).</p>\n<p>  <strong>yes</strong> - sends read requests to replicas only.</p>\n<p>  <strong>all</strong> - sends read requests to all nodes.</p>\n<p>   Since write commands will be rejected by replicas,<br>   it is recommended to enable read from replicas only for read command tests.</p>\n<p><strong><code>--enable-tracking</code></strong><br>: Send CLIENT TRACKING ON before starting benchmark.</p>\n<p><strong><code>-k</code></strong> <em>boolean</em><br>: 1=keep alive 0=reconnect (default 1)</p>\n<p><strong><code>-r</code></strong> <em>keyspacelen</em><br>: Use random keys for SET/GET/INCR, random values for SADD,<br>  random members and scores for ZADD.<br>  Using this option the benchmark will expand the string<br>  <code>__rand_int__</code> inside an argument with a 12 digits number in<br>  the specified range from 0 to keyspacelen - 1. The<br>  substitution changes every time a command is executed.<br>  Default tests use this to hit random keys in the specified<br>  range.<br>  Note: If <code>-r</code> is omitted, all commands in a benchmark will<br>  use the same key.</p>\n<p><strong><code>-P</code></strong> <em>numreq</em><br>: Pipeline <em>numreq</em> requests. Default 1 (no pipeline).</p>\n<p><strong><code>-q</code></strong><br>: Quiet. Just show query/sec values</p>\n<p><strong><code>--precision</code></strong><br>: Number of decimal places to display in latency output (default 0)</p>\n<p><strong><code>--csv</code></strong><br>: Output in CSV format</p>\n<p><strong><code>-l</code></strong><br>: Loop. Run the tests forever</p>\n<p><strong><code>-t</code></strong> <em>tests</em><br>: Only run the comma separated list of tests. The test<br>  names are the same as the ones produced as output.<br>  The <code>-t</code> option is ignored if a specific command is supplied<br>  on the command line.</p>\n<p><strong><code>-I</code></strong><br>: Idle mode. Just open N idle connections and wait.</p>\n<p><strong><code>-x</code></strong><br>: Read last argument from STDIN.</p>\n<p><strong><code>--seed</code></strong> <em>num</em><br>: Set the seed for random number generator. Default seed is based on time.</p>\n<p><strong><code>--tls</code></strong><br>: Establish a secure TLS connection.</p>\n<p><strong><code>--sni</code></strong> <em>host</em><br>: Server name indication for TLS.</p>\n<p><strong><code>--cacert</code></strong> <em>file</em><br>: CA Certificate file to verify with.</p>\n<p><strong><code>--cacertdir</code></strong> <em>dir</em><br>: Directory where trusted CA certificates are stored.<br>  If neither cacert nor cacertdir are specified, the default<br>  system-wide trusted root certs configuration will apply.</p>\n<p><strong><code>--insecure</code></strong><br>: Allow insecure TLS connection by skipping cert validation.</p>\n<p><strong><code>--cert</code></strong> <em>file</em><br>: Client certificate to authenticate with.</p>\n<p><strong><code>--key</code></strong> <em>file</em><br>: Private key file to authenticate with.</p>\n<p><strong><code>--tls-ciphers</code></strong> <em>list</em><br>: Sets the list of preferred ciphers (TLSv1.2 and below)<br>  in order of preference from highest to lowest separated by colon (&quot;:&quot;).<br>  See the <strong>ciphers</strong>(1ssl) manpage for more information about the syntax of this string.</p>\n<p><strong><code>--tls-ciphersuites</code></strong> <em>list</em><br>: Sets the list of preferred ciphersuites (TLSv1.3)<br>  in order of preference from highest to lowest separated by colon (&quot;:&quot;).<br>  See the <strong>ciphers</strong>(1ssl) manpage for more information about the syntax of this string,<br>  and specifically for TLSv1.3 ciphersuites.</p>\n<p><strong><code>--help</code></strong><br>: Output help and exit.</p>\n<p><strong><code>--version</code></strong><br>: Output version and exit.</p>\n<h2>Examples</h2>\n<p>Run the benchmark with the default configuration against 127.0.0.1:6379. You<br>need to have a running Valkey instance before launching the benchmark:</p>\n<pre><code>$ valkey-benchmark\n</code></pre>\n<p>Run a benchmark with 20 parallel clients, pipelining 10 commands at a time,<br>using 2 threads and less verbose output:</p>\n<pre><code>$ valkey-benchmark -c 20 -P 10 --threads 2 -q\n</code></pre>\n<p>Use 20 parallel clients, for a total of 100k requests, against 192.168.1.1:</p>\n<pre><code>$ valkey-benchmark -h 192.168.1.1 -p 6379 -n 100000 -c 20\n</code></pre>\n<p>Fill 127.0.0.1:6379 with about 1 million keys only using the SET test:</p>\n<pre><code>$ valkey-benchmark -t set -n 1000000 -r 100000000\n</code></pre>\n<p>Benchmark 127.0.0.1:6379 for a few commands producing CSV output:</p>\n<pre><code>$ valkey-benchmark -t ping,set,get -n 100000 --csv\n</code></pre>\n<p>Benchmark a specific command line:</p>\n<pre><code>$ valkey-benchmark -r 10000 -n 10000 eval &#39;return redis.call(&quot;ping&quot;)&#39; 0\n</code></pre>\n<p>Fill a list with 10000 random elements:</p>\n<pre><code>$ valkey-benchmark -r 10000 -n 10000 lpush mylist __rand_int__\n</code></pre>\n<p>On user specified command lines <code>__rand_int__</code> is replaced with a random integer<br>with a range of values selected by the <code>-r</code> option.</p>\n<h3>Running only a subset of the tests</h3>\n<p>You don&#39;t need to run all the default tests every time you execute <code>valkey-benchmark</code>.<br>For example, to select only a subset of tests, use the <code>-t</code> option<br>as in the following example:</p>\n<pre><code>$ valkey-benchmark -t set,lpush -n 100000 -q\nSET: 74239.05 requests per second\nLPUSH: 79239.30 requests per second\n</code></pre>\n<p>This example runs the tests for the <code>SET</code> and <code>LPUSH</code> commands and uses quiet mode (see the <code>-q</code> switch).</p>\n<p>You can even benchmark a specific command:</p>\n<pre><code>$ valkey-benchmark -n 100000 -q script load &quot;server.call(&#39;set&#39;,&#39;foo&#39;,&#39;bar&#39;)&quot;\nscript load server.call(&#39;set&#39;,&#39;foo&#39;,&#39;bar&#39;): 69881.20 requests per second\n</code></pre>\n<h3>Selecting the size of the key space</h3>\n<p>By default, the benchmark runs against a single key. In Valkey the difference<br>between such a synthetic benchmark and a real one is not huge since it is an<br>in-memory system, however it is possible to stress cache misses and in general<br>to simulate a more real-world work load by using a large key space.</p>\n<p>This is obtained by using the <code>-r</code> switch. For instance if I want to run<br>one million SET operations, using a random key for every operation out of<br>100k possible keys, I&#39;ll use the following command line:</p>\n<pre><code>$ valkey-cli flushall\nOK\n\n$ valkey-benchmark -t set -r 100000 -n 1000000\n====== SET ======\n  1000000 requests completed in 13.86 seconds\n  50 parallel clients\n  3 bytes payload\n  keep alive: 1\n\n99.76% `&lt;=` 1 milliseconds\n99.98% `&lt;=` 2 milliseconds\n100.00% `&lt;=` 3 milliseconds\n100.00% `&lt;=` 3 milliseconds\n72144.87 requests per second\n\n$ valkey-cli dbsize\n(integer) 99993\n</code></pre>\n<h3>Using pipelining</h3>\n<p>By default every client (the benchmark simulates 50 clients if not otherwise<br>specified with <code>-c</code>) sends the next command only when the reply of the previous<br>command is received, this means that the server will likely need a read call<br>in order to read each command from every client. Also RTT is paid as well.</p>\n<p>Valkey supports <a href=\"pipelining\">pipelining</a>, so it is possible to send<br>multiple commands at once, a feature often exploited by real world applications.<br>Valkey pipelining is able to dramatically improve the number of operations per<br>second a server is able do deliver.</p>\n<p>Consider this example of running the benchmark using a<br>pipelining of 16 commands:</p>\n<pre><code>$ valkey-benchmark -n 1000000 -t set,get -P 16 -q\nSET: 403063.28 requests per second\nGET: 508388.41 requests per second\n</code></pre>\n<p>Using pipelining results in a significant increase in performance.</p>\n<h3>Pitfalls and misconceptions</h3>\n<p>The first point is obvious: the golden rule of a useful benchmark is to<br>only compare apples and apples. You can compare different versions of Valkey on the same workload or the same version of Valkey, but with<br>different options. If you plan to compare Valkey to something else, then it is<br>important to evaluate the functional and technical differences, and take them<br>in account.</p>\n<ul>\n<li>Valkey is a server: all commands involve network or IPC round trips. It is meaningless to compare it to embedded data stores, because the cost of most operations is primarily in network/protocol management.</li>\n<li>Valkey commands return an acknowledgment for all usual commands. Some other data stores do not. Comparing Valkey to stores involving one-way queries is only mildly useful.</li>\n<li>Naively iterating on synchronous Valkey commands does not benchmark Valkey itself, but rather measure your network (or IPC) latency and the client library intrinsic latency. To really test Valkey, you need multiple connections (like valkey-benchmark) and/or to use pipelining to aggregate several commands and/or multiple threads or processes.</li>\n<li>Valkey is an in-memory data store with some optional persistence options. If you plan to compare it to transactional servers (MySQL, PostgreSQL, etc ...), then you should consider activating AOF and decide on a suitable fsync policy.</li>\n<li>Valkey primarily operates as a single-threaded server from the POV of commands execution. While the server can employ threads for I/O operations and command parsing, the core command execution remains sequential. For CPU-intensive workloads requiring multiple cores, users should consider running multiple Valkey instances in parallel. It is not really fair to compare one single Valkey instance to a multi-threaded data store.</li>\n</ul>\n<p>The <code>valkey-benchmark</code> program is a quick and useful way to get some figures and<br>evaluate the performance of a Valkey instance on a given hardware. However,<br>by default, it does not represent the maximum throughput a Valkey instance can<br>sustain. Actually, by using pipelining and a fast client (hiredis), it is fairly<br>easy to write a program generating more throughput than valkey-benchmark. The<br>default behavior of valkey-benchmark is to achieve throughput by exploiting<br>concurrency only (i.e. it creates several connections to the server).<br>It does not use pipelining or any parallelism at all (one pending query per<br>connection at most, and no multi-threading), if not explicitly enabled via<br>the <code>-P</code> parameter. So in some way using <code>valkey-benchmark</code> and, triggering, for<br>example, a <code>BGSAVE</code> operation in the background at the same time, will provide<br>the user with numbers more near to the <em>worst case</em> than to the best case.</p>\n<p>To run a benchmark using pipelining mode (and achieve higher throughput),<br>you need to explicitly use the -P option. Please note that it is still a<br>realistic behavior since a lot of Valkey based applications actively use<br>pipelining to improve performance. However you should use a pipeline size that<br>is more or less the average pipeline length you&#39;ll be able to use in your<br>application in order to get realistic numbers.</p>\n<p>The benchmark should apply the same operations, and work in the same way<br>with the multiple data stores you want to compare. It is absolutely pointless to<br>compare the result of valkey-benchmark to the result of another benchmark<br>program and extrapolate.</p>\n<p>For instance, Valkey and memcached in single-threaded mode can be compared on<br>GET/SET operations. Both are in-memory data stores, working mostly in the same<br>way at the protocol level. Provided their respective benchmark application is<br>aggregating queries in the same way (pipelining) and use a similar number of<br>connections, the comparison is actually meaningful.</p>\n<p>When you&#39;re benchmarking a high-performance, in-memory database like Valkey,<br>it may be difficult to saturate<br>the server. Sometimes, the performance bottleneck is on the client side,<br>and not the server-side. In that case, the client (i.e., the benchmarking program itself)<br>must be fixed, or perhaps scaled out, to reach the maximum throughput.</p>\n<h3>Factors impacting Valkey performance</h3>\n<p>There are multiple factors having direct consequences on Valkey performance.<br>We mention them here, since they can alter the result of any benchmarks.<br>Please note however, that a typical Valkey instance running on a low end,<br>untuned box usually provides good enough performance for most applications.</p>\n<ul>\n<li><p>Network bandwidth and latency usually have a direct impact on the performance.<br>It is a good practice to use the ping program to quickly check the latency<br>between the client and server hosts is normal before launching the benchmark.<br>Regarding the bandwidth, it is generally useful to estimate<br>the throughput in Gbit/s and compare it to the theoretical bandwidth<br>of the network. For instance a benchmark setting 4 KB strings<br>in Valkey at 100000 q/s, would actually consume 3.2 Gbit/s of bandwidth<br>and probably fit within a 10 Gbit/s link, but not a 1 Gbit/s one. In many real<br>world scenarios, Valkey throughput is limited by the network well before being<br>limited by the CPU. To consolidate several high-throughput Valkey instances<br>on a single server, it worth considering putting a 10 Gbit/s NIC<br>or multiple 1 Gbit/s NICs with TCP/IP bonding.</p>\n</li>\n<li><p>CPU is another important factor.</p>\n</li>\n<li><p>Speed of RAM and memory bandwidth seem less critical for global performance<br>especially for small objects. For large objects (&gt;10 KB), it may become<br>noticeable though. Usually, it is not really cost-effective to buy expensive<br>fast memory modules to optimize Valkey.</p>\n</li>\n<li><p>Valkey runs slower on a VM compared to running without virtualization using<br>the same hardware. If you have the chance to run Valkey on a physical machine<br>this is preferred. However this does not mean that Valkey is slow in<br>virtualized environments, the delivered performances are still very good<br>and most of the serious performance issues you may incur in virtualized<br>environments are due to over-provisioning, non-local disks with high latency,<br>or old hypervisor software that have slow <code>fork</code> syscall implementation.</p>\n</li>\n<li><p>When the server and client benchmark programs run on the same box, both<br>the TCP/IP loopback and unix domain sockets can be used. Depending on the<br>platform, unix domain sockets can achieve around 50% more throughput than<br>the TCP/IP loopback (on Linux for instance). The default behavior of<br>valkey-benchmark is to use the TCP/IP loopback.</p>\n</li>\n<li><p>The performance benefit of unix domain sockets compared to TCP/IP loopback<br>tends to decrease when pipelining is heavily used (i.e. long pipelines).</p>\n</li>\n<li><p>When an ethernet network is used to access Valkey, aggregating commands using<br>pipelining is especially efficient when the size of the data is kept under<br>the ethernet packet size (about 1500 bytes). Actually, processing 10 bytes,<br>100 bytes, or 1000 bytes queries almost result in the same throughput.<br>See the graph below.</p>\n<p>  <img src=\"Data_size.png\" alt=\"Data size impact\"></p>\n</li>\n<li><p>On multi CPU sockets servers, Valkey performance becomes dependent on the<br>NUMA configuration and process location. The most visible effect is that<br>valkey-benchmark results seem non-deterministic because client and server<br>processes are distributed randomly on the cores. To get deterministic results,<br>it is required to use process placement tools (on Linux: taskset or numactl).<br>The most efficient combination is always to put the client and server on two<br>different cores of the same CPU to benefit from the L3 cache.<br>Here are some results of 4 KB SET benchmark for 3 server CPUs (AMD Istanbul,<br>Intel Nehalem EX, and Intel Westmere) with different relative placements.<br>Please note this benchmark is not meant to compare CPU models between themselves<br>(CPUs exact model and frequency are therefore not disclosed).</p>\n<p>  <img src=\"NUMA_chart.gif\" alt=\"NUMA chart\"></p>\n</li>\n<li><p>With high-end configurations, the number of client connections is also an<br>important factor. Being based on epoll/kqueue, the Valkey event loop is quite<br>scalable. Valkey has already been benchmarked at more than 60000 connections,<br>and was still able to sustain 50000 q/s in these conditions. As a rule of thumb,<br>an instance with 30000 connections can only process half the throughput<br>achievable with 100 connections. Here is an example showing the throughput of<br>a Valkey instance per number of connections:</p>\n<p>  <img src=\"Connections_chart.png\" alt=\"connections chart\"></p>\n</li>\n<li><p>With high-end configurations, it is possible to achieve higher throughput by<br>tuning the NIC(s) configuration and associated interruptions. Best throughput<br>is achieved by setting an affinity between Rx/Tx NIC queues and CPU cores,<br>and activating RPS (Receive Packet Steering) support. More information in this<br><a href=\"https://groups.google.com/forum/#!msg/redis-db/gUhc19gnYgc/BruTPCOroiMJ\">thread</a>.<br>Jumbo frames may also provide a performance boost when large objects are used.</p>\n</li>\n<li><p>Depending on the platform, Valkey can be compiled against different memory<br>allocators (libc malloc, jemalloc, tcmalloc), which may have different behaviors<br>in term of raw speed, internal and external fragmentation.<br>If you did not compile Valkey yourself, you can use the INFO command to check<br>the <code>mem_allocator</code> field. Please note most benchmarks do not run long enough to<br>generate significant external fragmentation (contrary to production Valkey<br>instances).</p>\n</li>\n</ul>\n<h3>Other things to consider</h3>\n<p>One important goal of any benchmark is to get reproducible results, so they<br>can be compared to the results of other tests.</p>\n<ul>\n<li>A good practice is to try to run tests on isolated hardware as much as possible.<br>If it is not possible, then the system must be monitored to check the benchmark<br>is not impacted by some external activity.</li>\n<li>Some configurations (desktops and laptops for sure, some servers as well)<br>have a variable CPU core frequency mechanism. The policy controlling this<br>mechanism can be set at the OS level. Some CPU models are more aggressive than<br>others at adapting the frequency of the CPU cores to the workload. To get<br>reproducible results, it is better to set the highest possible fixed frequency<br>for all the CPU cores involved in the benchmark.</li>\n<li>An important point is to size the system accordingly to the benchmark.<br>The system must have enough RAM and must not swap. On Linux, do not forget<br>to set the <code>overcommit_memory</code> parameter correctly. Please note 32 and 64 bit<br>Valkey instances do not have the same memory footprint.</li>\n<li>If you plan to use RDB or AOF for your benchmark, please check there is no other<br>I/O activity in the system. Avoid putting RDB or AOF files on NAS or NFS shares,<br>or on any other devices impacting your network bandwidth and/or latency<br>(for instance, EBS on Amazon EC2).</li>\n<li>Set Valkey logging level (loglevel parameter) to warning or notice. Avoid putting<br>the generated log file on a remote filesystem.</li>\n<li>Avoid using monitoring tools which can alter the result of the benchmark. For<br>instance using INFO at regular interval to gather statistics is probably fine,<br>but MONITOR will impact the measured performance significantly.</li>\n<li>When running <code>valkey-benchmark</code> on the same machine as the <code>valkey-server</code><br>being tested, you may need to run the benchmark with at least two threads<br>(<code>--threads 2</code>) to prevent the benchmarking tool itself from being the<br>bottleneck, i.e. prevent that <code>valkey-benchmark</code> is running on 100% CPU while<br><code>valkey-server</code> is using less than 100% CPU.</li>\n</ul>\n<h3>Other Valkey benchmarking tools</h3>\n<p>There are several third-party tools that can be used for benchmarking Valkey. Refer to each tool&#39;s<br>documentation for more information about its goals and capabilities.</p>\n<ul>\n<li><a href=\"https://github.com/redislabs/memtier_benchmark\">memtier_benchmark</a> from <a href=\"https://twitter.com/RedisInc\">Redis Ltd.</a> is a NoSQL Valkey, Redis and Memcache traffic generation and benchmarking tool.</li>\n<li><a href=\"https://github.com/twitter/rpc-perf\">rpc-perf</a> from <a href=\"https://twitter.com/twitter\">Twitter</a> is a tool for benchmarking RPC services that supports Valkey and Memcache.</li>\n<li><a href=\"https://github.com/brianfrankcooper/YCSB\">YCSB</a> from <a href=\"https://twitter.com/Yahoo\">Yahoo @Yahoo</a> is a benchmarking framework with clients to many databases, including Valkey.</li>\n</ul>\n<h2>See also</h2>\n<p><a href=\"cli\">valkey-cli</a>, <a href=\"server\">valkey-server</a></p>\n"
  },
  {
    "id": "bitfields",
    "topicName": "Bitfields",
    "description": "Introduction to Bitfields\n",
    "htmlContent": "<p>Bitfields let you set, increment, and get integer values of arbitrary bit length.<br>For example, you can operate on anything from unsigned 1-bit integers to signed 63-bit integers.</p>\n<p>These values are stored using binary-encoded Strings.<br>Bitfields support atomic read, write and increment operations, making them a good choice for managing counters and similar numerical values.</p>\n<h2>Basic commands</h2>\n<ul>\n<li><code>BITFIELD</code> atomically sets, increments and reads one or more values.</li>\n<li><code>BITFIELD_RO</code> is a read-only variant of <code>BITFIELD</code>.</li>\n</ul>\n<h2>Example</h2>\n<p>Suppose you want to maintain two metrics for various bicycles: the current price and the number of owners over time. You can represent these counters with a 32-bit wide bitfield per for each bike.</p>\n<ul>\n<li>Bike 1 initially costs 1,000 (counter in offset 0) and has never had an owner. After being sold, it&#39;s now considered used and the price instantly drops to reflect its new condition, and it now has an owner (offset 1). After quite some time, the bike becomes a classic. The original owner sells it for a profit, so the price goes up and the number of owners does as well.Finally, you can look at the bike&#39;s current price and number of owners.</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; BITFIELD bike:1:stats SET u32 #0 1000\n1) (integer) 0\n127.0.0.1:6379&gt; BITFIELD bike:1:stats INCRBY u32 #0 -50 INCRBY u32 #1 1\n1) (integer) 950\n2) (integer) 1\n127.0.0.1:6379&gt; BITFIELD bike:1:stats INCRBY u32 #0 500 INCRBY u32 #1 1\n1) (integer) 1450\n2) (integer) 2\n127.0.0.1:6379&gt; BITFIELD bike:1:stats GET u32 #0 GET u32 #1\n1) (integer) 1450\n2) (integer) 2\n</code></pre>\n<h2>Performance</h2>\n<p><code>BITFIELD</code> is O(n), where <em>n</em> is the number of counters accessed.</p>\n"
  },
  {
    "id": "bitmaps",
    "topicName": "Bitmaps",
    "description": "Introduction to Bitmaps\n",
    "htmlContent": "<p>Bitmaps are not an actual data type, but a set of bit-oriented operations<br>defined on the String type which is treated like a bit vector.<br>Since strings are binary safe blobs and their maximum length is 512 MB,<br>they are suitable to set up to 2^32 different bits.</p>\n<p>You can perform bitwise operations on one or more strings.<br>Some examples of bitmap use cases include:</p>\n<ul>\n<li>Efficient set representations for cases where the members of a set correspond to the integers 0-N.</li>\n<li>Object permissions, where each bit represents a particular permission, similar to the way that file systems store permissions.</li>\n</ul>\n<h2>Basic commands</h2>\n<ul>\n<li><code>SETBIT</code> sets a bit at the provided offset to 0 or 1.</li>\n<li><code>GETBIT</code> returns the value of a bit at a given offset.</li>\n</ul>\n<p>See the <a href=\"../commands/#bitmap\">complete list of bitmap commands</a>.</p>\n<h2>Example</h2>\n<p>Suppose you have 1000 cyclists racing through the country-side, with sensors on their bikes labeled 0-999.<br>You want to quickly determine whether a given sensor has pinged a tracking server within the hour to check in on a rider. </p>\n<p>You can represent this scenario using a bitmap whose key references the current hour.</p>\n<ul>\n<li>Rider 123 pings the server on January 1, 2024 within the 00:00 hour. You can then confirm that rider 123 pinged the server. You can also check to see if rider 456 has pinged the server for that same hour.</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; SETBIT pings:2024-01-01-00:00 123 1\n(integer) 0\n127.0.0.1:6379&gt; GETBIT pings:2024-01-01-00:00 123\n(integer) 1\n127.0.0.1:6379&gt; GETBIT pings:2024-01-01-00:00 456\n(integer) 0\n</code></pre>\n<h2>Bit Operations</h2>\n<p>Bit operations are divided into two groups: constant-time single bit<br>operations, like setting a bit to 1 or 0, or getting its value, and<br>operations on groups of bits, for example counting the number of set<br>bits in a given range of bits (e.g., population counting).</p>\n<p>One of the biggest advantages of bitmaps is that they often provide<br>extreme space savings when storing information. For example in a system<br>where different users are represented by incremental user IDs, it is possible<br>to remember a single bit information (for example, knowing whether<br>a user wants to receive a newsletter) of 4 billion users using just 512 MB of memory.</p>\n<p>The <code>SETBIT</code> command takes as its first argument the bit number, and as its second<br>argument the value to set the bit to, which is 1 or 0. The command<br>automatically enlarges the string if the addressed bit is outside the<br>current string length.</p>\n<p><code>GETBIT</code> just returns the value of the bit at the specified index.<br>Out of range bits (addressing a bit that is outside the length of the string<br>stored into the target key) are always considered to be zero.</p>\n<p>There are three commands operating on group of bits:</p>\n<ol>\n<li><code>BITOP</code> performs bit-wise operations between different strings. The provided operations are AND, OR, XOR and NOT.</li>\n<li><code>BITCOUNT</code> performs population counting, reporting the number of bits set to 1.</li>\n<li><code>BITPOS</code> finds the first bit having the specified value of 0 or 1.</li>\n</ol>\n<p>Both <code>BITPOS</code> and <code>BITCOUNT</code> are able to operate with byte ranges of the<br>string, instead of running for the whole length of the string. We can trivially see the number of bits that have been set in a bitmap.</p>\n<pre><code>127.0.0.1:6379&gt; BITCOUNT pings:2024-01-01-00:00\n(integer) 1\n</code></pre>\n<p>For example imagine you want to know the longest streak of daily visits of<br>your web site users. You start counting days starting from zero, that is the<br>day you made your web site public, and set a bit with <code>SETBIT</code> every time<br>the user visits the web site. As a bit index you simply take the current unix<br>time, subtract the initial offset, and divide by the number of seconds in a day<br>(normally, 3600*24).</p>\n<p>This way for each user you have a small string containing the visit<br>information for each day. With <code>BITCOUNT</code> it is possible to easily get<br>the number of days a given user visited the web site, while with<br>a few <code>BITPOS</code> calls, or simply fetching and analyzing the bitmap client-side,<br>it is possible to easily compute the longest streak.</p>\n<p>Bitmaps are trivial to split into multiple keys, for example for<br>the sake of sharding the data set and because in general it is better to<br>avoid working with huge keys. To split a bitmap across different keys<br>instead of setting all the bits into a key, a trivial strategy is just<br>to store M bits per key and obtain the key name with <code>bit-number/M</code> and<br>the Nth bit to address inside the key with <code>bit-number MOD M</code>.</p>\n<h2>Performance</h2>\n<p><code>SETBIT</code> and <code>GETBIT</code> are O(1).<br><code>BITOP</code> is O(n), where <em>n</em> is the length of the longest string in the comparison.</p>\n"
  },
  {
    "id": "cli",
    "topicName": "CLI",
    "description": "Valkey command line interface\n",
    "htmlContent": "<h2>Usage</h2>\n<p><strong><code>valkey-cli</code></strong> [<em>OPTIONS</em>] [<em>cmd</em> [<em>arg</em>...]]</p>\n<h2>Description</h2>\n<p>The Valkey command line interface is used for administration, troubleshooting and experimenting with Valkey.</p>\n<p>In interactive mode, <code>valkey-cli</code> has basic line editing capabilities to provide a familiar typing experience.</p>\n<p>To launch the program in special modes, you can use several options, including:</p>\n<ul>\n<li>Simulate a replica and print the replication stream it receives from the primary.</li>\n<li>Check the latency of a Valkey server and display statistics. </li>\n<li>Request ASCII-art spectrogram of latency samples and frequencies.</li>\n</ul>\n<p>This topic covers the different aspects of <code>valkey-cli</code>, starting from the simplest and ending with the more advanced features.</p>\n<h2>Options</h2>\n<p><strong><code>-h</code></strong> <em>hostname</em><br>: Server hostname (default: 127.0.0.1).</p>\n<p><strong><code>-p</code></strong> <em>port</em><br>: Server port (default: 6379).</p>\n<p><strong><code>-t</code></strong> <em>timeout</em><br>: Server connection timeout in seconds (decimals allowed).<br>  Default timeout is 0, meaning no limit, depending on the OS.</p>\n<p><strong><code>-s</code></strong> <em>socket</em><br>: Server socket (overrides hostname and port).</p>\n<p><strong><code>-a</code></strong> <em>password</em><br>: Password to use when connecting to the server.<br>  You can also use the <code>REDISCLI_AUTH</code> environment<br>  variable to pass this password more safely.<br>  (If both are used, this argument takes precedence.)</p>\n<p><strong><code>--user</code></strong> <em>username</em><br>: Used to send ACL style &#39;AUTH username pass&#39;. Needs <code>-a</code>.</p>\n<p><strong><code>--pass</code></strong> <em>password</em><br>: Alias of -a for consistency with the new --user option.</p>\n<p><strong><code>--askpass</code></strong><br>: Force user to input password with mask from STDIN.<br>  If this argument is used, <code>-a</code> and the <code>REDISCLI_AUTH</code><br>  environment variable will be ignored.</p>\n<p><strong><code>-u</code></strong> <em>uri</em><br>: Server URI on format <code>valkey://user:password@host:port/dbnum</code>.<br>  User, password and dbnum are optional. For authentication<br>  without a username, use username &#39;default&#39;. For TLS, use<br>  the scheme &#39;valkeys&#39;.</p>\n<p><strong><code>-r</code></strong> <em>repeat</em><br>: Execute specified command N times.</p>\n<p><strong><code>-i</code></strong> <em>interval</em><br>: When <code>-r</code> is used, waits <em>interval</em> seconds per command.<br>  It is possible to specify sub-second times like <code>-i 0.1</code>.<br>  This interval is also used in <code>--scan</code> and <code>--stat</code> per cycle.<br>  and in <code>--bigkeys</code>, <code>--memkeys</code>, and <code>--hotkeys</code> per 100 cycles.</p>\n<p><strong><code>-n</code></strong> <em>db</em><br>: Database number.</p>\n<p><strong><code>-2</code></strong><br>: Start session in RESP2 protocol mode.</p>\n<p><strong><code>-3</code></strong><br>: Start session in RESP3 protocol mode.</p>\n<p><strong><code>-x</code></strong><br>: Read last argument from STDIN (see example below).</p>\n<p><strong><code>-X</code></strong><br>: Read <tag> argument from STDIN (see example below).</p>\n<p><strong><code>-d</code></strong> <em>delimiter</em><br>: Delimiter between response bulks for raw formatting (default: <code>\\n</code>).</p>\n<p><strong><code>-D</code></strong> <em>delimiter</em><br>: Delimiter between responses for raw formatting (default: <code>\\n</code>).</p>\n<p><strong><code>-c</code></strong><br>: Enable cluster mode (follow -ASK and -MOVED redirections).</p>\n<p><strong><code>-e</code></strong><br>: Return exit error code when command execution fails.</p>\n<p><strong><code>-4</code></strong><br>: Prefer IPv4 over IPv6 on DNS lookup.</p>\n<p><strong><code>-6</code></strong><br>: Prefer IPv6 over IPv4 on DNS lookup.&#39;</p>\n<p><strong><code>--tls</code></strong><br>: Establish a secure TLS connection.</p>\n<p><strong><code>--sni</code></strong> <em>host</em><br>: Server name indication for TLS.</p>\n<p><strong><code>--cacert</code></strong> <em>file</em><br>: CA Certificate file to verify with.</p>\n<p><strong><code>--cacertdir</code></strong> <em>dir</em><br>: Directory where trusted CA certificates are stored.<br>  If neither cacert nor cacertdir are specified, the default<br>  system-wide trusted root certs configuration will apply.</p>\n<p><strong><code>--insecure</code></strong><br>: Allow insecure TLS connection by skipping cert validation.</p>\n<p><strong><code>--cert</code></strong> <em>file</em><br>: Client certificate to authenticate with.</p>\n<p><strong><code>--key</code></strong> <em>file</em><br>: Private key file to authenticate with.</p>\n<p><strong><code>--tls-ciphers</code></strong> <em>list</em><br>: Sets the list of preferred ciphers (TLSv1.2 and below)<br>  in order of preference from highest to lowest separated by colon (&quot;:&quot;).<br>  See the <strong>ciphers</strong>(1ssl) manpage for more information about the syntax of this string.</p>\n<p><strong><code>--tls-ciphersuites</code></strong> <em>list</em><br>: Sets the list of preferred ciphersuites (TLSv1.3)<br>  in order of preference from highest to lowest separated by colon (&quot;:&quot;).<br>  See the <strong>ciphers</strong>(1ssl) manpage for more information about the syntax of this string,<br>  and specifically for TLSv1.3 ciphersuites.</p>\n<p><strong><code>--raw</code></strong><br>: Use raw formatting for replies (default when STDOUT is<br>  not a tty).</p>\n<p><strong><code>--no-raw</code></strong><br>: Force formatted output even when STDOUT is not a tty.</p>\n<p><strong><code>--quoted-input</code></strong><br>: Force input to be handled as quoted strings.</p>\n<p><strong><code>--csv</code></strong><br>: Output in CSV format.</p>\n<p><strong><code>--json</code></strong><br>: Output in JSON format (default RESP3, use -2 if you want to use with RESP2).</p>\n<p><strong><code>--quoted-json</code></strong><br>: Same as --json, but produce ASCII-safe quoted strings, not Unicode.</p>\n<p><strong><code>--show-pushes</code></strong> <strong><code>yes</code></strong>|<strong><code>no</code></strong><br>: Whether to print RESP3 PUSH messages.  Enabled by default when<br>  STDOUT is a tty but can be overridden with --show-pushes no.</p>\n<p><strong><code>--stat</code></strong><br>: Print rolling stats about server: mem, clients, ...</p>\n<p><strong><code>--latency</code></strong><br>: Enter a special mode continuously sampling latency.<br>  If you use this mode in an interactive session it runs<br>  forever displaying real-time stats. Otherwise if <code>--raw</code> or<br>  <code>--csv</code> is specified, or if you redirect the output to a non<br>  TTY, it samples the latency for 1 second (you can use<br>  <code>-i</code> to change the interval), then produces a single output<br>  and exits.</p>\n<p><strong><code>--latency-history</code></strong><br>: Like <code>--latency</code> but tracking latency changes over time.<br>  Default time interval is 15 sec. Change it using <code>-i</code>.</p>\n<p><strong><code>--latency-dist</code></strong><br>: Shows latency as a spectrum, requires xterm 256 colors.<br>  Default time interval is 1 sec. Change it using <code>-i</code>.</p>\n<p><strong><code>--lru-test</code></strong> <em>keys</em><br>: Simulate a cache workload with an 80-20 distribution.</p>\n<p><strong><code>--replica</code></strong><br>: Simulate a replica showing commands received from the primary.</p>\n<p><strong><code>--rdb</code></strong> <em>filename</em><br>: Transfer an RDB dump from remote server to local file.<br>  Use filename of &quot;-&quot; to write to stdout.</p>\n<p><strong><code>--functions-rdb</code></strong> <em>filename</em><br>: Like <code>--rdb</code> but only get the functions (not the keys)<br>  when getting the RDB dump file.</p>\n<p><strong><code>--pipe</code></strong><br>: Transfer raw RESP protocol from stdin to server.</p>\n<p><strong><code>--pipe-timeout</code></strong> <em>n</em><br>: In <code>--pipe</code> mode, abort with error if after sending all data.<br>  no reply is received within <em>n</em> seconds.<br>  Default timeout: 30. Use 0 to wait forever.</p>\n<p><strong><code>--bigkeys</code></strong><br>: Sample keys looking for keys with many elements (complexity).</p>\n<p><strong><code>--memkeys</code></strong><br>: Sample keys looking for keys consuming a lot of memory.</p>\n<p><strong><code>--memkeys-samples</code></strong> <em>n</em><br>: Sample keys looking for keys consuming a lot of memory.<br>  And define number of key elements to sample</p>\n<p><strong><code>--hotkeys</code></strong><br>: Sample keys looking for hot keys.<br>  only works when maxmemory-policy is <code>*lfu</code>.</p>\n<p><strong><code>--scan</code></strong><br>: List all keys using the SCAN command.</p>\n<p><strong><code>--pattern</code></strong> <em>pat</em><br>: Keys pattern when using the <code>--scan</code>, <code>--bigkeys</code> or <code>--hotkeys</code><br>  options (default: <code>*</code>).</p>\n<p><strong><code>--count</code></strong> <em>count</em><br>: Count option when using the <code>--scan</code>, <code>--bigkeys</code> or <code>--hotkeys</code> (default: 10).</p>\n<p><strong><code>--quoted-pattern</code></strong> <em>pat</em><br>: Same as <code>--pattern</code>, but the specified string can be<br>  quoted, in order to pass an otherwise non binary-safe string.</p>\n<p><strong><code>--intrinsic-latency</code></strong> <em>sec</em><br>: Run a test to measure intrinsic system latency.<br>  The test will run for the specified amount of seconds.</p>\n<p><strong><code>--eval</code></strong> <em>file</em><br>: Send an EVAL command using the Lua script at <em>file</em>.</p>\n<p><strong><code>--ldb</code></strong><br>: Used with <code>--eval</code> enable the Server Lua debugger.</p>\n<p><strong><code>--ldb-sync-mode</code></strong><br>: Like <code>--ldb</code> but uses the synchronous Lua debugger, in<br>  this mode the server is blocked and script changes are<br>  not rolled back from the server memory.</p>\n<p><strong><code>--cluster</code></strong> <em>command</em> [<em>args</em>...] [<em>opts</em>...]<br>: Cluster Manager command and arguments (see below).</p>\n<p><strong><code>--verbose</code></strong><br>: Verbose mode.</p>\n<p><strong><code>--no-auth-warning</code></strong><br>: Don&#39;t show warning message when using password on command<br>  line interface.</p>\n<p><strong><code>--help</code></strong><br>: Output help and exit.</p>\n<p><strong><code>--version</code></strong><br>: Output version and exit.</p>\n<h2>Cluster Manager commands</h2>\n<p>For management of <a href=\"cluster-tutorial\">Valkey Cluster</a>, the following syntax is used:</p>\n<p><strong><code>valkey-cli</code></strong> <strong><code>--cluster</code></strong> <em>command</em> [<em>args</em>...] [<em>opts</em>...]</p>\n<pre><code>  Command        Args\n  --------------------------------------------------------------------------------\n  create         host1:port1 ... hostN:portN\n                 --cluster-replicas &lt;arg&gt;\n  check          &lt;host:port&gt; or &lt;host&gt; &lt;port&gt; - separated by either colon or space\n                 --cluster-search-multiple-owners\n  info           &lt;host:port&gt; or &lt;host&gt; &lt;port&gt; - separated by either colon or space\n  fix            &lt;host:port&gt; or &lt;host&gt; &lt;port&gt; - separated by either colon or space\n                 --cluster-search-multiple-owners\n                 --cluster-fix-with-unreachable-masters\n  reshard        &lt;host:port&gt; or &lt;host&gt; &lt;port&gt; - separated by either colon or space\n                 --cluster-from &lt;arg&gt;\n                 --cluster-to &lt;arg&gt;\n                 --cluster-slots &lt;arg&gt;\n                 --cluster-yes\n                 --cluster-timeout &lt;arg&gt;\n                 --cluster-pipeline &lt;arg&gt;\n                 --cluster-replace\n  rebalance      &lt;host:port&gt; or &lt;host&gt; &lt;port&gt; - separated by either colon or space\n                 --cluster-weight &lt;node1=w1...nodeN=wN&gt;\n                 --cluster-use-empty-masters\n                 --cluster-timeout &lt;arg&gt;\n                 --cluster-simulate\n                 --cluster-pipeline &lt;arg&gt;\n                 --cluster-threshold &lt;arg&gt;\n                 --cluster-replace\n  add-node       new_host:new_port existing_host:existing_port\n                 --cluster-replica\n                 --cluster-master-id &lt;arg&gt;\n  del-node       host:port node_id\n  call           host:port command arg arg .. arg\n                 --cluster-only-masters\n                 --cluster-only-replicas\n  set-timeout    host:port milliseconds\n  import         host:port\n                 --cluster-from &lt;arg&gt;\n                 --cluster-from-user &lt;arg&gt;\n                 --cluster-from-pass &lt;arg&gt;\n                 --cluster-from-askpass\n                 --cluster-copy\n                 --cluster-replace\n  backup         host:port backup_directory\n  help\n</code></pre>\n<h2>Command line usage</h2>\n<p>To run a Valkey command and return a standard output at the terminal, include the command to execute as separate arguments of <code>valkey-cli</code>:</p>\n<pre><code>$ valkey-cli INCR mycounter\n(integer) 7\n</code></pre>\n<p>The reply of the command is &quot;7&quot;. Since Valkey replies are typed (strings, arrays, integers, nil, errors, etc.), you see the type of the reply between parentheses. This additional information may not be ideal when the output of <code>valkey-cli</code> must be used as input of another command or redirected into a file.</p>\n<p><code>valkey-cli</code> only shows additional information for human readability when it detects the standard output is a tty, or terminal. For all other outputs it will auto-enable the <em>raw output mode</em>, as in the following example:</p>\n<pre><code>$ valkey-cli INCR mycounter &gt; /tmp/output.txt\n$ cat /tmp/output.txt\n8\n</code></pre>\n<p>Note that <code>(integer)</code> is omitted from the output because <code>valkey-cli</code> detects<br>the output is no longer written to the terminal. You can force raw output<br>even on the terminal with the <code>--raw</code> option:</p>\n<pre><code>$ valkey-cli --raw INCR mycounter\n9\n</code></pre>\n<p>You can force human readable output when writing to a file or in<br>pipe to other commands by using <code>--no-raw</code>.</p>\n<h2>String quoting and escaping</h2>\n<p>When <code>valkey-cli</code> parses a command, whitespace characters automatically delimit the arguments.<br>In interactive mode, a newline sends the command for parsing and execution.<br>To input string values that contain whitespaces or non-printable characters, you can use quoted and escaped strings.</p>\n<p>Quoted string values are enclosed in double (<code>&quot;</code>) or single (<code>&#39;</code>) quotation marks.<br>Escape sequences are used to put nonprintable characters in character and string literals.</p>\n<p>An escape sequence contains a backslash (<code>\\</code>) symbol followed by one of the escape sequence characters.</p>\n<p>Doubly-quoted strings support the following escape sequences:</p>\n<ul>\n<li><code>\\&quot;</code> - double-quote</li>\n<li><code>\\n</code> - newline</li>\n<li><code>\\r</code> - carriage return</li>\n<li><code>\\t</code> - horizontal tab</li>\n<li><code>\\b</code> - backspace</li>\n<li><code>\\a</code> - alert</li>\n<li><code>\\\\</code> - backslash</li>\n<li><code>\\xhh</code> - any ASCII character represented by a hexadecimal number (<em>hh</em>)</li>\n</ul>\n<p>Single quotes assume the string is literal, and allow only the following escape sequences:</p>\n<ul>\n<li><code>\\&#39;</code> - single quote</li>\n<li><code>\\\\</code> - backslash</li>\n</ul>\n<p>For example, to return <code>Hello World</code> on two lines:</p>\n<pre><code>127.0.0.1:6379&gt; SET mykey &quot;Hello\\nWorld&quot;\nOK\n127.0.0.1:6379&gt; GET mykey\nHello\nWorld\n</code></pre>\n<p>When you input strings that contain single or double quotes, as you might in passwords, for example, escape the string, like so: </p>\n<pre><code>127.0.0.1:6379&gt; AUTH some_admin_user &quot;&gt;^8T&gt;6Na{u|jp&gt;+v\\&quot;55\\@_;OU(OR]7mbAYGqsfyu48(j&#39;%hQH7;v*f1H${*gD(Se&#39;&quot;\n</code></pre>\n<h2>Host, port, password, and database</h2>\n<p>By default, <code>valkey-cli</code> connects to the server at the address 127.0.0.1 with port 6379.<br>You can change the port using several command line options. To specify a different host name or an IP address, use the <code>-h</code> option. In order to set a different port, use <code>-p</code>.</p>\n<pre><code>$ valkey-cli -h valkey15.example.com -p 6390 PING\nPONG\n</code></pre>\n<p>If your instance is password protected, the <code>-a &lt;password&gt;</code> option will<br>perform authentication saving the need of explicitly using the <code>AUTH</code> command:</p>\n<pre><code>$ valkey-cli -a myUnguessablePazzzzzword123 PING\nPONG\n</code></pre>\n<p><strong>NOTE:</strong> For security reasons, provide the password to <code>valkey-cli</code> automatically via the<br><code>REDISCLI_AUTH</code> environment variable.</p>\n<p>Finally, it&#39;s possible to send a command that operates on a database number<br>other than the default number zero by using the <code>-n &lt;dbnum&gt;</code> option:</p>\n<pre><code>$ valkey-cli FLUSHALL\nOK\n$ valkey-cli -n 1 INCR a\n(integer) 1\n$ valkey-cli -n 1 INCR a\n(integer) 2\n$ valkey-cli -n 2 INCR a\n(integer) 1\n</code></pre>\n<p>Some or all of this information can also be provided by using the <code>-u &lt;uri&gt;</code><br>option and the URI pattern <code>valkey://user:password@host:port/dbnum</code>:</p>\n<pre><code>$ valkey-cli -u valkey://LJenkins:p%40ssw0rd@valkey-16379.example.com:16379/0 PING\nPONG\n</code></pre>\n<p><strong>NOTE:</strong><br>User, password and dbnum are optional.<br>For authentication without a username, use username <code>default</code>.<br>For TLS, use the scheme <code>valkeys</code>.</p>\n<h2>SSL/TLS</h2>\n<p>By default, <code>valkey-cli</code> uses a plain TCP connection to connect to Valkey.<br>You may enable SSL/TLS using the <code>--tls</code> option, along with <code>--cacert</code> or<br><code>--cacertdir</code> to configure a trusted root certificate bundle or directory.</p>\n<p>If the target server requires authentication using a client side certificate,<br>you can specify a certificate and a corresponding private key using <code>--cert</code> and<br><code>--key</code>.</p>\n<h2>Getting input from other programs</h2>\n<p>There are two ways you can use <code>valkey-cli</code> in order to receive input from other<br>commands via the standard input. One is to use the target payload as the last argument<br>from <em>stdin</em>. For example, in order to set the Valkey key <code>net_services</code><br>to the content of the file <code>/etc/services</code> from a local file system, use the <code>-x</code><br>option:</p>\n<pre><code>$ valkey-cli -x SET net_services &lt; /etc/services\nOK\n$ valkey-cli GETRANGE net_services 0 50\n&quot;#\\n# Network services, Internet style\\n#\\n# Note that &quot;\n</code></pre>\n<p>In the first line of the above session, <code>valkey-cli</code> was executed with the <code>-x</code> option and a file was redirected to the CLI&#39;s<br>standard input as the value to satisfy the <code>SET net_services</code> command phrase. This is useful for scripting.</p>\n<p>A different approach is to feed <code>valkey-cli</code> a sequence of commands written in a<br>text file:</p>\n<pre><code>$ cat /tmp/commands.txt\nSET item:3374 100\nINCR item:3374\nAPPEND item:3374 xxx\nGET item:3374\n$ cat /tmp/commands.txt | valkey-cli\nOK\n(integer) 101\n(integer) 6\n&quot;101xxx&quot;\n</code></pre>\n<p>All the commands in <code>commands.txt</code> are executed consecutively by<br><code>valkey-cli</code> as if they were typed by the user in interactive mode. Strings can be<br>quoted inside the file if needed, so that it&#39;s possible to have single<br>arguments with spaces, newlines, or other special characters:</p>\n<pre><code>$ cat /tmp/commands.txt\nSET arg_example &quot;This is a single argument&quot;\nSTRLEN arg_example\n$ cat /tmp/commands.txt | valkey-cli\nOK\n(integer) 25\n</code></pre>\n<h2>Continuously run the same command</h2>\n<p>It is possible to execute a single command a specified number of times<br>with a user-selected pause between executions. This is useful in<br>different contexts - for example when we want to continuously monitor some<br>key content or <code>INFO</code> field output, or when we want to simulate some<br>recurring write event, such as pushing a new item into a list every 5 seconds.</p>\n<p>This feature is controlled by two options: <code>-r &lt;count&gt;</code> and <code>-i &lt;delay&gt;</code>.<br>The <code>-r</code> option states how many times to run a command and <code>-i</code> sets<br>the delay between the different command calls in seconds (with the ability<br>to specify values such as 0.1 to represent 100 milliseconds).</p>\n<p>By default the interval (or delay) is set to 0, so commands are just executed<br>ASAP:</p>\n<pre><code>$ valkey-cli -r 5 INCR counter_value\n(integer) 1\n(integer) 2\n(integer) 3\n(integer) 4\n(integer) 5\n</code></pre>\n<p>To run the same command indefinitely, use <code>-1</code> as the count value.<br>To monitor over time the RSS memory size it&#39;s possible to use the following command:</p>\n<pre><code>$ valkey-cli -r -1 -i 1 INFO | grep rss_human\nused_memory_rss_human:2.71M\nused_memory_rss_human:2.73M\nused_memory_rss_human:2.73M\nused_memory_rss_human:2.73M\n... a new line will be printed each second ...\n</code></pre>\n<h2>Mass insertion of data using <code>valkey-cli</code></h2>\n<p>Mass insertion using <code>valkey-cli</code> is covered in a separate page as it is a<br>worthwhile topic itself. Please refer to our <a href=\"mass-insertion\">mass insertion guide</a>.</p>\n<h2>CSV output</h2>\n<p>A CSV (Comma Separated Values) output feature exists within <code>valkey-cli</code> to export data from Valkey to an external program.  </p>\n<pre><code>$ valkey-cli LPUSH mylist a b c d\n(integer) 4\n$ valkey-cli --csv LRANGE mylist 0 -1\n&quot;d&quot;,&quot;c&quot;,&quot;b&quot;,&quot;a&quot;\n</code></pre>\n<p>Note that the <code>--csv</code> flag will only work on a single command, not the entirety of a DB as an export.</p>\n<h2>Running Lua scripts</h2>\n<p>The <code>valkey-cli</code> has extensive support for using the debugging facility<br>of Lua scripting, available with Valkey 3.2 onwards. For this feature, refer to the <a href=\"ldb\">Valkey Lua debugger documentation</a>.</p>\n<p>Even without using the debugger, <code>valkey-cli</code> can be used to<br>run scripts from a file as an argument:</p>\n<pre><code>$ cat /tmp/script.lua\nreturn server.call(&#39;SET&#39;,KEYS[1],ARGV[1])\n$ valkey-cli --eval /tmp/script.lua location:hastings:temp , 23\nOK\n</code></pre>\n<p>The Valkey <code>EVAL</code> command takes the list of keys the script uses, and the<br>other non key arguments, as different arrays. When calling <code>EVAL</code> you<br>provide the number of keys as a number. </p>\n<p>When calling <code>valkey-cli</code> with the <code>--eval</code> option above, there is no need to specify the number of keys<br>explicitly. Instead it uses the convention of separating keys and arguments<br>with a comma. This is why in the above call you see <code>location:hastings:temp , 23</code> as arguments.</p>\n<p>So <code>location:hastings:temp</code> will populate the <code>KEYS</code> array, and <code>23</code> the <code>ARGV</code> array.</p>\n<p>The <code>--eval</code> option is useful when writing simple scripts. For more<br>complex work, the Lua debugger is recommended. It is possible to mix the two approaches, since the debugger can also execute scripts from an external file.</p>\n<h1>Interactive mode</h1>\n<p>We have explored how to use the Valkey CLI as a command line program.<br>This is useful for scripts and certain types of testing, however most<br>people will spend the majority of time in <code>valkey-cli</code> using its interactive<br>mode.</p>\n<p>In interactive mode the user types Valkey commands at the prompt. The command<br>is sent to the server, processed, and the reply is parsed back and rendered<br>into a simpler form to read.</p>\n<p>Nothing special is needed for running the <code>valkey-cli</code> in interactive mode -<br>just execute it without any arguments</p>\n<pre><code>$ valkey-cli\n127.0.0.1:6379&gt; PING\nPONG\n</code></pre>\n<p>The string <code>127.0.0.1:6379&gt;</code> is the prompt. It displays the connected Valkey server instance&#39;s hostname and port.</p>\n<p>The prompt updates as the connected server changes or when operating on a database different from the database number zero:</p>\n<pre><code>127.0.0.1:6379&gt; SELECT 2\nOK\n127.0.0.1:6379[2]&gt; DBSIZE\n(integer) 1\n127.0.0.1:6379[2]&gt; SELECT 0\nOK\n127.0.0.1:6379&gt; DBSIZE\n(integer) 503\n</code></pre>\n<h2>Handling connections and reconnections</h2>\n<p>Using the <code>CONNECT</code> command in interactive mode makes it possible to connect<br>to a different instance, by specifying the <em>hostname</em> and <em>port</em> we want<br>to connect to:</p>\n<pre><code>127.0.0.1:6379&gt; CONNECT metal 6379\nmetal:6379&gt; PING\nPONG\n</code></pre>\n<p>As you can see the prompt changes accordingly when connecting to a different server instance.<br>If a connection is attempted to an instance that is unreachable, the <code>valkey-cli</code> goes into disconnected<br>mode and attempts to reconnect with each new command:</p>\n<pre><code>127.0.0.1:6379&gt; CONNECT 127.0.0.1 9999\nCould not connect to Valkey at 127.0.0.1:9999: Connection refused\nnot connected&gt; PING\nCould not connect to Valkey at 127.0.0.1:9999: Connection refused\nnot connected&gt; PING\nCould not connect to Valkey at 127.0.0.1:9999: Connection refused\n</code></pre>\n<p>Generally after a disconnection is detected, <code>valkey-cli</code> always attempts to<br>reconnect transparently; if the attempt fails, it shows the error and<br>enters the disconnected state. The following is an example of disconnection<br>and reconnection:</p>\n<pre><code>127.0.0.1:6379&gt; INFO SERVER\nCould not connect to Valkey at 127.0.0.1:6379: Connection refused\nnot connected&gt; PING\nPONG\n127.0.0.1:6379&gt; \n(now we are connected again)\n</code></pre>\n<p>When a reconnection is performed, <code>valkey-cli</code> automatically re-selects the<br>last database number selected. However, all other states about the<br>connection is lost, such as within a MULTI/EXEC transaction:</p>\n<pre><code>$ valkey-cli\n127.0.0.1:6379&gt; MULTI\nOK\n127.0.0.1:6379&gt; PING\nQUEUED\n\n( here the server is manually restarted )\n\n127.0.0.1:6379&gt; EXEC\n(error) ERR EXEC without MULTI\n</code></pre>\n<p>This is usually not an issue when using the <code>valkey-cli</code> in interactive mode for<br>testing, but this limitation should be known.</p>\n<h2>Editing, history, completion and hints</h2>\n<p>Because <code>valkey-cli</code> uses the &quot;linenoise&quot; line editing library shipped with<br>Valkey, it has line editing capabilities without depending on <code>libreadline</code> or<br>other optional libraries.</p>\n<p>Command execution history can be accessed in order to avoid retyping commands by pressing the arrow keys (up and down).<br>The history is preserved between restarts of the CLI, in a file named<br><code>.valkeycli_history</code> inside the user home directory, as specified<br>by the <code>HOME</code> environment variable. It is possible to use a different<br>history filename by setting the <code>REDISCLI_HISTFILE</code> environment variable,<br>and disable it by setting it to <code>/dev/null</code>.</p>\n<p>The <code>valkey-cli</code> is also able to perform command-name completion by pressing the TAB<br>key, as in the following example:</p>\n<pre><code>127.0.0.1:6379&gt; Z&lt;TAB&gt;\n127.0.0.1:6379&gt; ZADD&lt;TAB&gt;\n127.0.0.1:6379&gt; ZCARD&lt;TAB&gt;\n</code></pre>\n<p>Once Valkey command name has been entered at the prompt, the <code>valkey-cli</code> will display<br>syntax hints. Like command history, this behavior can be turned on and off via the <code>valkey-cli</code> preferences.</p>\n<h2>Preferences</h2>\n<p>There are two ways to customize <code>valkey-cli</code> behavior. The file <code>.valkeyclirc</code><br>in the home directory is loaded by the CLI on startup. You can override the<br>file&#39;s default location by setting the <code>REDISCLI_RCFILE</code> environment variable to<br>an alternative path. Preferences can also be set during a CLI session, in which<br>case they will last only the duration of the session.</p>\n<p>To set preferences, use the special <code>:set</code> command. The following preferences<br>can be set, either by typing the command in the CLI or adding it to the<br><code>.valkeyclirc</code> file:</p>\n<ul>\n<li><code>:set hints</code> - enables syntax hints</li>\n<li><code>:set nohints</code> - disables syntax hints</li>\n</ul>\n<h2>Running the same command N times</h2>\n<p>It is possible to run the same command multiple times in interactive mode by prefixing the command<br>name by a number:</p>\n<pre><code>127.0.0.1:6379&gt; 5 INCR mycounter\n(integer) 1\n(integer) 2\n(integer) 3\n(integer) 4\n(integer) 5\n</code></pre>\n<h2>Showing help about Valkey commands</h2>\n<p><code>valkey-cli</code> provides online help for most Valkey <a href=\"../commands/\">commands</a>, using the <code>HELP</code> command. The command can be used<br>in two forms:</p>\n<ul>\n<li><code>HELP @&lt;category&gt;</code> shows all the commands about a given category. The<br>categories are: <ul>\n<li><code>@generic</code></li>\n<li><code>@string</code></li>\n<li><code>@list</code></li>\n<li><code>@set</code></li>\n<li><code>@sorted_set</code></li>\n<li><code>@hash</code></li>\n<li><code>@pubsub</code></li>\n<li><code>@transactions</code></li>\n<li><code>@connection</code></li>\n<li><code>@server</code></li>\n<li><code>@scripting</code></li>\n<li><code>@hyperloglog</code></li>\n<li><code>@cluster</code></li>\n<li><code>@geo</code></li>\n<li><code>@stream</code></li>\n</ul>\n</li>\n<li><code>HELP &lt;commandname&gt;</code> shows specific help for the command given as argument.</li>\n</ul>\n<p>For example in order to show help for the <code>PFADD</code> command, use:</p>\n<pre><code>127.0.0.1:6379&gt; HELP PFADD\n\nPFADD key element [element ...]\nsummary: Adds the specified elements to the specified HyperLogLog.\nsince: 2.8.9\n</code></pre>\n<p>Note that <code>HELP</code> supports TAB completion as well.</p>\n<h2>Clearing the terminal screen</h2>\n<p>Using the <code>CLEAR</code> command in interactive mode clears the terminal&#39;s screen.</p>\n<h1>Special modes of operation</h1>\n<p>So far we saw two main modes of <code>valkey-cli</code>.</p>\n<ul>\n<li>Command line execution of Valkey commands.</li>\n<li>Interactive &quot;REPL&quot; usage.</li>\n</ul>\n<p>The CLI performs other auxiliary tasks related to Valkey that<br>are explained in the next sections:</p>\n<ul>\n<li>Monitoring tool to show continuous stats about a Valkey server.</li>\n<li>Scanning a Valkey database for very large keys.</li>\n<li>Key space scanner with pattern matching.</li>\n<li>Acting as a <a href=\"pubsub\">Pub/Sub</a> client to subscribe to channels.</li>\n<li>Monitoring the commands executed into a Valkey instance.</li>\n<li>Checking the <a href=\"latency\">latency</a> of a Valkey server in different ways.</li>\n<li>Checking the scheduler latency of the local computer.</li>\n<li>Transferring RDB backups from a remote Valkey server locally.</li>\n<li>Acting as a Valkey replica for showing what a replica receives.</li>\n<li>Simulating <a href=\"lru-cache\">LRU</a> workloads for showing stats about keys hits.</li>\n<li>A client for the Lua debugger.</li>\n</ul>\n<h2>Continuous stats mode</h2>\n<p>Continuous stats mode is probably one of the lesser known yet very useful features of <code>valkey-cli</code> to monitor Valkey instances in real time. To enable this mode, the <code>--stat</code> option is used.<br>The output is very clear about the behavior of the CLI in this mode:</p>\n<pre><code>$ valkey-cli --stat\n------- data ------ --------------------- load -------------------- - child -\nkeys       mem      clients blocked requests            connections\n506        1015.00K 1       0       24 (+0)             7\n506        1015.00K 1       0       25 (+1)             7\n506        3.40M    51      0       60461 (+60436)      57\n506        3.40M    51      0       146425 (+85964)     107\n507        3.40M    51      0       233844 (+87419)     157\n507        3.40M    51      0       321715 (+87871)     207\n508        3.40M    51      0       408642 (+86927)     257\n508        3.40M    51      0       497038 (+88396)     257\n</code></pre>\n<p>In this mode a new line is printed every second with useful information and differences of request values between old data points. Memory usage, client connection counts, and various other statistics about the connected Valkey database can be easily understood with this auxiliary <code>valkey-cli</code> tool.</p>\n<p>The <code>-i &lt;interval&gt;</code> option in this case works as a modifier in order to<br>change the frequency at which new lines are emitted. The default is one<br>second.</p>\n<h2>Scanning for big keys</h2>\n<p>In this special mode, <code>valkey-cli</code> works as a key space analyzer. It scans the<br>dataset for big keys, but also provides information about the data types<br>that the data set consists of. This mode is enabled with the <code>--bigkeys</code> option,<br>and produces verbose output:</p>\n<pre><code>$ valkey-cli --bigkeys\n\n# Scanning the entire keyspace to find biggest keys as well as\n# average sizes per key type.  You can use -i 0.01 to sleep 0.01 sec\n# per SCAN command (not usually needed).\n\n[00.00%] Biggest string found so far &#39;key-419&#39; with 3 bytes\n[05.14%] Biggest list   found so far &#39;mylist&#39; with 100004 items\n[35.77%] Biggest string found so far &#39;counter:__rand_int__&#39; with 6 bytes\n[73.91%] Biggest hash   found so far &#39;myobject&#39; with 3 fields\n\n-------- summary -------\n\nSampled 506 keys in the keyspace!\nTotal key length in bytes is 3452 (avg len 6.82)\n\nBiggest string found &#39;counter:__rand_int__&#39; has 6 bytes\nBiggest   list found &#39;mylist&#39; has 100004 items\nBiggest   hash found &#39;myobject&#39; has 3 fields\n\n504 strings with 1403 bytes (99.60% of keys, avg size 2.78)\n1 lists with 100004 items (00.20% of keys, avg size 100004.00)\n0 sets with 0 members (00.00% of keys, avg size 0.00)\n1 hashs with 3 fields (00.20% of keys, avg size 3.00)\n0 zsets with 0 members (00.00% of keys, avg size 0.00)\n</code></pre>\n<p>In the first part of the output, each new key larger than the previous larger<br>key (of the same type) encountered is reported. The summary section<br>provides general stats about the data inside the Valkey instance.</p>\n<p>The program uses the <code>SCAN</code> command, so it can be executed against a busy<br>server without impacting the operations, however the <code>-i</code> option can be<br>used in order to throttle the scanning process of the specified fraction<br>of second for each <code>SCAN</code> command. </p>\n<p>For example, <code>-i 0.01</code> will slow down the program execution considerably, but will also reduce the load on the server<br>to a negligible amount.</p>\n<p>Note that the summary also reports in a cleaner form the biggest keys found<br>for each time. The initial output is just to provide some interesting info<br>ASAP if running against a very large data set.</p>\n<h2>Getting a list of keys</h2>\n<p>It is also possible to scan the key space, again in a way that does not<br>block the Valkey server (which does happen when you use a command<br>like <code>KEYS *</code>), and print all the key names, or filter them for specific<br>patterns. This mode, like the <code>--bigkeys</code> option, uses the <code>SCAN</code> command,<br>so keys may be reported multiple times if the dataset is changing, but no<br>key would ever be missing, if that key was present since the start of the<br>iteration. Because of the command that it uses this option is called <code>--scan</code>.</p>\n<pre><code>$ valkey-cli --scan | head -10\nkey-419\nkey-71\nkey-236\nkey-50\nkey-38\nkey-458\nkey-453\nkey-499\nkey-446\nkey-371\n</code></pre>\n<p>Note that <code>head -10</code> is used in order to print only the first ten lines of the<br>output.</p>\n<p>Scanning is able to use the underlying pattern matching capability of<br>the <code>SCAN</code> command with the <code>--pattern</code> option.</p>\n<pre><code>$ valkey-cli --scan --pattern &#39;*-11*&#39;\nkey-114\nkey-117\nkey-118\nkey-113\nkey-115\nkey-112\nkey-119\nkey-11\nkey-111\nkey-110\nkey-116\n</code></pre>\n<p>Piping the output through the <code>wc</code> command can be used to count specific<br>kind of objects, by key name:</p>\n<pre><code>$ valkey-cli --scan --pattern &#39;user:*&#39; | wc -l\n3829433\n</code></pre>\n<p>You can use <code>-i 0.01</code> to add a delay between calls to the <code>SCAN</code> command.<br>This will make the command slower but will significantly reduce load on the server.</p>\n<h2>Pub/sub mode</h2>\n<p>The CLI is able to publish messages in Valkey Pub/Sub channels using<br>the <code>PUBLISH</code> command. Subscribing to channels in order to receive<br>messages is different - the terminal is blocked and waits for<br>messages, so this is implemented as a special mode in <code>valkey-cli</code>. Unlike<br>other special modes this mode is not enabled by using a special option,<br>but simply by using the <code>SUBSCRIBE</code> or <code>PSUBSCRIBE</code> command, which are available in<br>interactive or command mode:</p>\n<pre><code>$ valkey-cli PSUBSCRIBE &#39;*&#39;\nReading messages... (press Ctrl-C to quit)\n1) &quot;PSUBSCRIBE&quot;\n2) &quot;*&quot;\n3) (integer) 1\n</code></pre>\n<p>The <em>reading messages</em> message shows that we entered Pub/Sub mode.<br>When another client publishes some message in some channel, such as with the command <code>valkey-cli PUBLISH mychannel mymessage</code>, the CLI in Pub/Sub mode will show something such as:</p>\n<pre><code>1) &quot;pmessage&quot;\n2) &quot;*&quot;\n3) &quot;mychannel&quot;\n4) &quot;mymessage&quot;\n</code></pre>\n<p>This is very useful for debugging Pub/Sub issues.<br>To exit the Pub/Sub mode just process <code>CTRL-C</code>.</p>\n<h2>Monitoring commands executed in Valkey</h2>\n<p>Similarly to the Pub/Sub mode, the monitoring mode is entered automatically<br>once you use the <code>MONITOR</code> command. All commands received by the active Valkey instance will be printed to the standard output:</p>\n<pre><code>$ valkey-cli MONITOR\nOK\n1460100081.165665 [0 127.0.0.1:51706] &quot;set&quot; &quot;shipment:8000736522714:status&quot; &quot;sorting&quot;\n1460100083.053365 [0 127.0.0.1:51707] &quot;get&quot; &quot;shipment:8000736522714:status&quot;\n</code></pre>\n<p>Note that it is possible to pipe the output, so you can monitor<br>for specific patterns using tools such as <code>grep</code>.</p>\n<h2>Monitoring the latency of Valkey instances</h2>\n<p>Valkey is often used in contexts where latency is very critical. Latency<br>involves multiple moving parts within the application, from the client library<br>to the network stack, to the Valkey instance itself.</p>\n<p>The <code>valkey-cli</code> has multiple facilities for studying the latency of a Valkey<br>instance and understanding the latency&#39;s maximum, average and distribution.</p>\n<p>The basic latency-checking tool is the <code>--latency</code> option. Using this<br>option the CLI runs a loop where the <code>PING</code> command is sent to the Valkey<br>instance and the time to receive a reply is measured. This happens 100<br>times per second, and stats are updated in a real time in the console:</p>\n<pre><code>$ valkey-cli --latency\nmin: 0, max: 1, avg: 0.19 (427 samples)\n</code></pre>\n<p>The stats are provided in milliseconds. Usually, the average latency of<br>a very fast instance tends to be overestimated a bit because of the<br>latency due to the kernel scheduler of the system running <code>valkey-cli</code><br>itself, so the average latency of 0.19 above may easily be 0.01 or less.<br>However this is usually not a big problem, since most developers are interested in<br>events of a few milliseconds or more.</p>\n<p>Sometimes it is useful to study how the maximum and average latencies<br>evolve during time. The <code>--latency-history</code> option is used for that<br>purpose: it works exactly like <code>--latency</code>, but every 15 seconds (by<br>default) a new sampling session is started from scratch:</p>\n<pre><code>$ valkey-cli --latency-history\nmin: 0, max: 1, avg: 0.14 (1314 samples) -- 15.01 seconds range\nmin: 0, max: 1, avg: 0.18 (1299 samples) -- 15.00 seconds range\nmin: 0, max: 1, avg: 0.20 (113 samples)^C\n</code></pre>\n<p>Sampling sessions&#39; length can be changed with the <code>-i &lt;interval&gt;</code> option.</p>\n<p>The most advanced latency study tool, but also the most complex to<br>interpret for non-experienced users, is the ability to use color terminals<br>to show a spectrum of latencies. You&#39;ll see a colored output that indicates the<br>different percentages of samples, and different ASCII characters that indicate<br>different latency figures. This mode is enabled using the <code>--latency-dist</code><br>option:</p>\n<pre><code>$ valkey-cli --latency-dist\n(output not displayed, requires a color terminal, try it!)\n</code></pre>\n<p>There is another pretty unusual latency tool implemented inside <code>valkey-cli</code>.<br>It does not check the latency of a Valkey instance, but the latency of the<br>computer running <code>valkey-cli</code>. This latency is intrinsic to the kernel scheduler,<br>the hypervisor in case of virtualized instances, and so forth.</p>\n<p>Valkey calls it <em>intrinsic latency</em> because it&#39;s mostly opaque to the programmer.<br>If the Valkey instance has high latency regardless of all the obvious things<br>that may be the source cause, it&#39;s worth to check what&#39;s the best your system<br>can do by running <code>valkey-cli</code> in this special mode directly in the system you<br>are running Valkey servers on.</p>\n<p>By measuring the intrinsic latency, you know that this is the baseline,<br>and Valkey cannot outdo your system. In order to run the CLI<br>in this mode, use the <code>--intrinsic-latency &lt;test-time&gt;</code>. Note that the test time is in seconds and dictates how long the test should run.</p>\n<pre><code>$ ./valkey-cli --intrinsic-latency 5\nMax latency so far: 1 microseconds.\nMax latency so far: 7 microseconds.\nMax latency so far: 9 microseconds.\nMax latency so far: 11 microseconds.\nMax latency so far: 13 microseconds.\nMax latency so far: 15 microseconds.\nMax latency so far: 34 microseconds.\nMax latency so far: 82 microseconds.\nMax latency so far: 586 microseconds.\nMax latency so far: 739 microseconds.\n\n65433042 total runs (avg latency: 0.0764 microseconds / 764.14 nanoseconds per run).\nWorst run took 9671x longer than the average latency.\n</code></pre>\n<p>IMPORTANT: this command must be executed on the computer that runs the Valkey server instance, not on a different host. It does not connect to a Valkey instance and performs the test locally.</p>\n<p>In the above case, the system cannot do better than 739 microseconds of worst<br>case latency, so one can expect certain queries to occasionally run less than 1 millisecond.</p>\n<h2>Remote backups of RDB files</h2>\n<p>During a Valkey replication&#39;s first synchronization, the primary and the replica<br>exchange the whole data set in the form of an RDB file. This feature is exploited<br>by <code>valkey-cli</code> in order to provide a remote backup facility that allows a<br>transfer of an RDB file from any Valkey instance to the local computer running<br><code>valkey-cli</code>. To use this mode, call the CLI with the <code>--rdb &lt;dest-filename&gt;</code><br>option:</p>\n<pre><code>$ valkey-cli --rdb /tmp/dump.rdb\nSYNC sent to master, writing 13256 bytes to &#39;/tmp/dump.rdb&#39;\nTransfer finished with success.\n</code></pre>\n<p>This is a simple but effective way to ensure disaster recovery<br>RDB backups exist of your Valkey instance. When using this options in<br>scripts or <code>cron</code> jobs, make sure to check the return value of the command.<br>If it is non zero, an error occurred as in the following example:</p>\n<pre><code>$ valkey-cli --rdb /tmp/dump.rdb\nSYNC with master failed: -ERR Can&#39;t SYNC while not connected with my master\n$ echo $?\n1\n</code></pre>\n<h2>Replica mode</h2>\n<p>The replica mode of the CLI is an advanced feature useful for<br>Valkey developers and for debugging operations.<br>It allows for the inspection of the content a primary sends to its replicas in the replication<br>stream in order to propagate the writes to its replicas. The option<br>name is simply <code>--replica</code>. The following is a working example:</p>\n<pre><code>$ valkey-cli --replica\nSYNC with master, discarding 13256 bytes of bulk transfer...\nSYNC done. Logging commands from master.\n&quot;PING&quot;\n&quot;SELECT&quot;,&quot;0&quot;\n&quot;SET&quot;,&quot;last_name&quot;,&quot;Enigk&quot;\n&quot;PING&quot;\n&quot;INCR&quot;,&quot;mycounter&quot;\n</code></pre>\n<p>The command begins by discarding the RDB file of the first synchronization<br>and then logs each command received in CSV format.</p>\n<p>If you think some of the commands are not replicated correctly in your replicas<br>this is a good way to check what&#39;s happening, and also useful information<br>in order to improve the bug report.</p>\n<h2>Performing an LRU simulation</h2>\n<p>Valkey is often used as a cache with <a href=\"lru-cache\">LRU eviction</a>.<br>Depending on the number of keys and the amount of memory allocated for the<br>cache (specified via the <code>maxmemory</code> directive), the amount of cache hits<br>and misses will change. Sometimes, simulating the rate of hits is very<br>useful to correctly provision your cache.</p>\n<p>The <code>valkey-cli</code> has a special mode where it performs a simulation of GET and SET<br>operations, using an 80-20% power law distribution in the requests pattern.<br>This means that 20% of keys will be requested 80% of times, which is a<br>common distribution in caching scenarios.</p>\n<p>Theoretically, given the distribution of the requests and the Valkey memory<br>overhead, it should be possible to compute the hit rate analytically<br>with a mathematical formula. However, Valkey can be configured with<br>different LRU settings (number of samples) and LRU&#39;s implementation, which<br>is approximated in Valkey, changes a lot between different versions. Similarly<br>the amount of memory per key may change between versions. That is why this<br>tool was built: its main motivation was for testing the quality of Valkey&#39; LRU<br>implementation, but now is also useful for testing how a given version<br>behaves with the settings originally intended for deployment.</p>\n<p>To use this mode, specify the amount of keys in the test and configure a sensible <code>maxmemory</code> setting as a first attempt.</p>\n<p>IMPORTANT NOTE: Configuring the <code>maxmemory</code> setting in the Valkey configuration<br>is crucial: if there is no cap to the maximum memory usage, the hit will<br>eventually be 100% since all the keys can be stored in memory. If too many keys are specified with maximum memory, eventually all of the computer RAM will be used. It is also needed to configure an appropriate<br><em>maxmemory policy</em>; most of the time <code>allkeys-lru</code> is selected.</p>\n<p>In the following example there is a configured a memory limit of 100MB and an LRU<br>simulation using 10 million keys.</p>\n<p>WARNING: the test uses pipelining and will stress the server, don&#39;t use it<br>with production instances.</p>\n<pre><code>$ ./valkey-cli --lru-test 10000000\n156000 Gets/sec | Hits: 4552 (2.92%) | Misses: 151448 (97.08%)\n153750 Gets/sec | Hits: 12906 (8.39%) | Misses: 140844 (91.61%)\n159250 Gets/sec | Hits: 21811 (13.70%) | Misses: 137439 (86.30%)\n151000 Gets/sec | Hits: 27615 (18.29%) | Misses: 123385 (81.71%)\n145000 Gets/sec | Hits: 32791 (22.61%) | Misses: 112209 (77.39%)\n157750 Gets/sec | Hits: 42178 (26.74%) | Misses: 115572 (73.26%)\n154500 Gets/sec | Hits: 47418 (30.69%) | Misses: 107082 (69.31%)\n151250 Gets/sec | Hits: 51636 (34.14%) | Misses: 99614 (65.86%)\n</code></pre>\n<p>The program shows stats every second. In the first seconds the cache starts to be populated. The misses rate later stabilizes into the actual figure that can be expected:</p>\n<pre><code>120750 Gets/sec | Hits: 48774 (40.39%) | Misses: 71976 (59.61%)\n122500 Gets/sec | Hits: 49052 (40.04%) | Misses: 73448 (59.96%)\n127000 Gets/sec | Hits: 50870 (40.06%) | Misses: 76130 (59.94%)\n124250 Gets/sec | Hits: 50147 (40.36%) | Misses: 74103 (59.64%)\n</code></pre>\n<p>A miss rate of 59% may not be acceptable for certain use cases therefor<br>100MB of memory is not enough. Observe an example using a half gigabyte of memory. After several<br>minutes the output stabilizes to the following figures:</p>\n<pre><code>140000 Gets/sec | Hits: 135376 (96.70%) | Misses: 4624 (3.30%)\n141250 Gets/sec | Hits: 136523 (96.65%) | Misses: 4727 (3.35%)\n140250 Gets/sec | Hits: 135457 (96.58%) | Misses: 4793 (3.42%)\n140500 Gets/sec | Hits: 135947 (96.76%) | Misses: 4553 (3.24%)\n</code></pre>\n<p>With 500MB there is sufficient space for the key quantity (10 million) and distribution (80-20 style).</p>\n"
  },
  {
    "id": "client-side-caching",
    "topicName": "Client-side caching",
    "description": "Server-assisted, client-side caching in Valkey\n",
    "htmlContent": "<p>Client-side caching is a technique used to create high performance services.<br>It exploits the memory available on application servers, servers that are<br>usually distinct computers compared to the Valkey nodes, to store some subset<br>of the Valkey information directly in the application side.</p>\n<p>Normally when data is required, the application servers ask the Valkey about<br>such information, like in the following diagram:</p>\n<pre><code>+-------------+                                +----------+\n|             | ------- GET user:1234 -------&gt; |          |\n| Application |                                |  Valkey  |\n|             | &lt;---- username = Alice ------- |          |\n+-------------+                                +----------+\n</code></pre>\n<p>When client-side caching is used, the application will store the reply of<br>popular queries directly inside the application memory, so that it can<br>reuse such replies later, without contacting the Valkey again:</p>\n<pre><code>+-------------+                                +----------+\n|             |                                |          |\n| Application |       ( No chat needed )       |  Valkey  |\n|             |                                |          |\n+-------------+                                +----------+\n| Local cache |\n|             |\n| user:1234 = |\n| username    |\n| Alice       |\n+-------------+\n</code></pre>\n<p>While the application memory used for the local cache may not be very big,<br>the time needed in order to access the local computer memory is orders of<br>magnitude smaller compared to accessing a networked service like a Valkey.<br>Since often the same small percentage of data are accessed frequently,<br>this pattern can greatly reduce the latency for the application to get data<br>and, at the same time, the load in the Valkey side.</p>\n<p>Moreover there are many datasets where items change very infrequently.<br>For instance, most user posts in a social network are either immutable or<br>rarely edited by the user. Adding to this the fact that usually a small<br>percentage of the posts are very popular, either because a small set of users<br>have a lot of followers and/or because recent posts have a lot more<br>visibility, it is clear why such a pattern can be very useful.</p>\n<p>Usually the two key advantages of client-side caching are:</p>\n<ol>\n<li>Data is available with a very small latency.</li>\n<li>The Valkey system receives less queries, allowing it to serve the same dataset with a smaller number of nodes.</li>\n</ol>\n<h2>There are two hard problems in computer science...</h2>\n<p>A problem with the above pattern is how to invalidate the information that<br>the application is holding, in order to avoid presenting stale data to the<br>user. For example after the application above locally cached the information<br>for user:1234, Alice may update her username to Flora. Yet the application<br>may continue to serve the old username for user:1234.</p>\n<p>Sometimes, depending on the exact application we are modeling, this isn&#39;t a<br>big deal, so the client will just use a fixed maximum &quot;time to live&quot; for the<br>cached information. Once a given amount of time has elapsed, the information<br>will no longer be considered valid. More complex patterns, when using Valkey,<br>leverage the Pub/Sub system in order to send invalidation messages to<br>listening clients. This can be made to work but is tricky and costly from<br>the point of view of the bandwidth used, because often such patterns involve<br>sending the invalidation messages to every client in the application, even<br>if certain clients may not have any copy of the invalidated data. Moreover<br>every application query altering the data requires to use the <code>PUBLISH</code><br>command, costing the Valkey more CPU time to process this command.</p>\n<p>Regardless of what schema is used, there is a simple fact: many very large<br>applications implement some form of client-side caching, because it is the<br>next logical step to having a fast store or a fast cache server. For this<br>reason Valkey implements direct support for client-side caching, in order<br>to make this pattern much simpler to implement, more accessible, reliable,<br>and efficient.</p>\n<h2>The Valkey implementation of client-side caching</h2>\n<p>The Valkey client-side caching support is called <em>Tracking</em>, and has two modes:</p>\n<ul>\n<li>In the default mode, the server remembers what keys a given client accessed, and sends invalidation messages when the same keys are modified. This costs memory in the server side, but sends invalidation messages only for the set of keys that the client might have in memory.</li>\n<li>In the <em>broadcasting</em> mode, the server does not attempt to remember what keys a given client accessed, so this mode costs no memory at all in the server side. Instead clients subscribe to key prefixes such as <code>object:</code> or <code>user:</code>, and receive a notification message every time a key matching a subscribed prefix is touched.</li>\n</ul>\n<p>To recap, for now let&#39;s forget for a moment about the broadcasting mode, to<br>focus on the first mode. We&#39;ll describe broadcasting in more detail later.</p>\n<ol>\n<li>Clients can enable tracking if they want. Connections start without tracking enabled.</li>\n<li>When tracking is enabled, the server remembers what keys each client requested during the connection lifetime (by sending read commands about such keys).</li>\n<li>When a key is modified by some client, or is evicted because it has an associated expire time, or evicted because of a <em>maxmemory</em> policy, all the clients with tracking enabled that may have the key cached, are notified with an <em>invalidation message</em>.</li>\n<li>When clients receive invalidation messages, they are required to remove the corresponding keys, in order to avoid serving stale data.</li>\n</ol>\n<p>This is an example of the protocol:</p>\n<ul>\n<li>Client 1 <code>-&gt;</code> Server: CLIENT TRACKING ON</li>\n<li>Client 1 <code>-&gt;</code> Server: GET foo</li>\n<li>(The server remembers that Client 1 may have the key &quot;foo&quot; cached)</li>\n<li>(Client 1 may remember the value of &quot;foo&quot; inside its local memory)</li>\n<li>Client 2 <code>-&gt;</code> Server: SET foo SomeOtherValue</li>\n<li>Server <code>-&gt;</code> Client 1: INVALIDATE &quot;foo&quot;</li>\n</ul>\n<p>This looks great superficially, but if you imagine 10k connected clients all<br>asking for millions of keys over long living connection, the server ends up<br>storing too much information. For this reason Valkey uses two key ideas in<br>order to limit the amount of memory used server-side and the CPU cost of<br>handling the data structures implementing the feature:</p>\n<ul>\n<li>The server remembers the list of clients that may have cached a given key in a single global table. This table is called the <strong>Invalidation Table</strong>. The invalidation table can contain a maximum number of entries. If a new key is inserted, the server may evict an older entry by pretending that such key was modified (even if it was not), and sending an invalidation message to the clients. Doing so, it can reclaim the memory used for this key, even if this will force the clients having a local copy of the key to evict it.</li>\n<li>Inside the invalidation table we don&#39;t really need to store pointers to clients&#39; structures, that would force a garbage collection procedure when the client disconnects: instead what we do is just store client IDs (each Valkey client has a unique numerical ID). If a client disconnects, the information will be incrementally garbage collected as caching slots are invalidated.</li>\n<li>There is a single keys namespace, not divided by Valkey numbers. So if a client is caching the key <code>foo</code> in Valkey 2, and some other client changes the value of the key <code>foo</code> in Valkey 3, an invalidation message will still be sent. This way we can ignore Valkey numbers reducing both the memory usage and the implementation complexity.</li>\n</ul>\n<h2>Two connections mode</h2>\n<p>Using the new version of the Valkey protocol, RESP3, it is possible to run the data queries and receive the invalidation messages in the same connection. However many client implementations may prefer to implement client-side caching using two separated connections: one for data, and one for invalidation messages. For this reason when a client enables tracking, it can specify to redirect the invalidation messages to another connection by specifying the &quot;client ID&quot; of a different connection. Many data connections can redirect invalidation messages to the same connection, this is useful for clients implementing connection pooling. The two connections model is the only one that is also supported for RESP2 (which lacks the ability to multiplex different kind of information in the same connection).</p>\n<p>Here&#39;s an example of a complete session using the Valkey protocol in the old RESP2 mode involving the following steps: enabling tracking redirecting to another connection, asking for a key, and getting an invalidation message once the key gets modified.</p>\n<p>To start, the client opens a first connection that will be used for invalidations, requests the connection ID, and subscribes via Pub/Sub to the special channel that is used to get invalidation messages when in RESP2 modes (remember that RESP2 is the usual Valkey protocol, and not the more advanced protocol that you can use, optionally, using the <code>HELLO</code> command):</p>\n<pre><code>(Connection 1 -- used for invalidations)\nCLIENT ID\n:4\nSUBSCRIBE __redis__:invalidate\n*3\n$9\nsubscribe\n$20\n__redis__:invalidate\n:1\n</code></pre>\n<p>Now we can enable tracking from the data connection:</p>\n<pre><code>(Connection 2 -- data connection)\nCLIENT TRACKING on REDIRECT 4\n+OK\n\nGET foo\n$3\nbar\n</code></pre>\n<p>The client may decide to cache <code>&quot;foo&quot; =&gt; &quot;bar&quot;</code> in the local memory.</p>\n<p>A different client will now modify the value of the &quot;foo&quot; key:</p>\n<pre><code>(Some other unrelated connection)\nSET foo bar\n+OK\n</code></pre>\n<p>As a result, the invalidations connection will receive a message that invalidates the specified key.</p>\n<pre><code>(Connection 1 -- used for invalidations)\n*3\n$7\nmessage\n$20\n__redis__:invalidate\n*1\n$3\nfoo\n</code></pre>\n<p>The client will check if there are cached keys in this caching slot, and will evict the information that is no longer valid.</p>\n<p>Note that the third element of the Pub/Sub message is not a single key but<br>is a Valkey array with just a single element. Since we send an array, if there<br>are groups of keys to invalidate, we can do that in a single message.<br>In case of a flush (<code>FLUSHALL</code> or <code>FLUSHDB</code>), a <code>null</code> message will be sent.</p>\n<p>A very important thing to understand about client-side caching used with<br>RESP2 and a Pub/Sub connection in order to read the invalidation messages,<br>is that using Pub/Sub is entirely a trick <strong>in order to reuse old client<br>implementations</strong>, but actually the message is not really sent to a channel<br>and received by all the clients subscribed to it. Only the connection we<br>specified in the <code>REDIRECT</code> argument of the <code>CLIENT</code> command will actually<br>receive the Pub/Sub message, making the feature a lot more scalable.</p>\n<p>When RESP3 is used instead, invalidation messages are sent (either in the<br>same connection, or in the secondary connection when redirection is used)<br>as <code>push</code> messages (read the RESP3 specification for more information).</p>\n<h2>What tracking tracks</h2>\n<p>As you can see clients do not need, by default, to tell the server what keys<br>they are caching. Every key that is mentioned in the context of a read-only<br>command is tracked by the server, because it <em>could be cached</em>.</p>\n<p>This has the obvious advantage of not requiring the client to tell the server<br>what it is caching. Moreover in many clients implementations, this is what<br>you want, because a good solution could be to just cache everything that is not<br>already cached, using a first-in first-out approach: we may want to cache a<br>fixed number of objects, every new data we retrieve, we could cache it,<br>discarding the oldest cached object. More advanced implementations may instead<br>drop the least used object or alike.</p>\n<p>Note that anyway if there is write traffic on the server, caching slots<br>will get invalidated during the course of the time. In general when the<br>server assumes that what we get we also cache, we are making a tradeoff:</p>\n<ol>\n<li>It is more efficient when the client tends to cache many things with a policy that welcomes new objects.</li>\n<li>The server will be forced to retain more data about the client keys.</li>\n<li>The client will receive useless invalidation messages about objects it did not cache.</li>\n</ol>\n<p>So there is an alternative described in the next section.</p>\n<h2>Opt-in caching</h2>\n<p>Clients implementations may want to cache only selected keys, and communicate<br>explicitly to the server what they&#39;ll cache and what they will not. This will<br>require more bandwidth when caching new objects, but at the same time reduces<br>the amount of data that the server has to remember and the amount of<br>invalidation messages received by the client.</p>\n<p>In order to do this, tracking must be enabled using the OPTIN option:</p>\n<pre><code>CLIENT TRACKING on REDIRECT 1234 OPTIN\n</code></pre>\n<p>In this mode, by default, keys mentioned in read queries <em>are not supposed to be cached</em>, instead when a client wants to cache something, it must send a special command immediately before the actual command to retrieve the data:</p>\n<pre><code>CLIENT CACHING YES\n+OK\nGET foo\n&quot;bar&quot;\n</code></pre>\n<p>The <code>CACHING</code> command affects the command executed immediately after it,<br>however in case the next command is <code>MULTI</code>, all the commands in the<br>transaction will be tracked. Similarly in case of Lua scripts, all the<br>commands executed by the script will be tracked.</p>\n<h2>Broadcasting mode</h2>\n<p>So far we described the first client-side caching model that Valkey implements.<br>There is another one, called broadcasting, that sees the problem from the<br>point of view of a different tradeoff, does not consume any memory on the<br>server side, but instead sends more invalidation messages to clients.<br>In this mode we have the following main behaviors:</p>\n<ul>\n<li>Clients enable client-side caching using the <code>BCAST</code> option, specifying one or more prefixes using the <code>PREFIX</code> option. For instance: <code>CLIENT TRACKING on REDIRECT 10 BCAST PREFIX object: PREFIX user:</code>. If no prefix is specified at all, the prefix is assumed to be the empty string, so the client will receive invalidation messages for every key that gets modified. Instead if one or more prefixes are used, only keys matching one of the specified prefixes will be sent in the invalidation messages.</li>\n<li>The server does not store anything in the invalidation table. Instead it uses a different <strong>Prefixes Table</strong>, where each prefix is associated to a list of clients.</li>\n<li>No two prefixes can track overlapping parts of the keyspace. For instance, having the prefix &quot;foo&quot; and &quot;foob&quot; would not be allowed, since they would both trigger an invalidation for the key &quot;foobar&quot;. However, just using the prefix &quot;foo&quot; is sufficient.</li>\n<li>Every time a key matching any of the prefixes is modified, all the clients subscribed to that prefix, will receive the invalidation message.</li>\n<li>The server will consume CPU proportional to the number of registered prefixes. If you have just a few, it is hard to see any difference. With a big number of prefixes the CPU cost can become quite large.</li>\n<li>In this mode the server can perform the optimization of creating a single reply for all the clients subscribed to a given prefix, and send the same reply to all. This helps to lower the CPU usage.</li>\n</ul>\n<h2>The NOLOOP option</h2>\n<p>By default client-side tracking will send invalidation messages to the<br>client that modified the key. Sometimes clients want this, since they<br>implement very basic logic that does not involve automatically caching<br>writes locally. However, more advanced clients may want to cache even the<br>writes they are doing in the local in-memory table. In such case receiving<br>an invalidation message immediately after the write is a problem, since it<br>will force the client to evict the value it just cached.</p>\n<p>In this case it is possible to use the <code>NOLOOP</code> option: it works both<br>in normal and broadcasting mode. Using this option, clients are able to<br>tell the server they don&#39;t want to receive invalidation messages for keys<br>that they modified.</p>\n<h2>Avoiding race conditions</h2>\n<p>When implementing client-side caching redirecting the invalidation messages<br>to a different connection, you should be aware that there is a possible<br>race condition. See the following example interaction, where we&#39;ll call<br>the data connection &quot;D&quot; and the invalidation connection &quot;I&quot;:</p>\n<pre><code>[D] client -&gt; server: GET foo\n[I] server -&gt; client: Invalidate foo (somebody else touched it)\n[D] server -&gt; client: &quot;bar&quot; (the reply of &quot;GET foo&quot;)\n</code></pre>\n<p>As you can see, because the reply to the GET was slower to reach the<br>client, we received the invalidation message before the actual data that<br>is already no longer valid. So we&#39;ll keep serving a stale version of the<br>foo key. To avoid this problem, it is a good idea to populate the cache<br>when we send the command with a placeholder:</p>\n<pre><code>Client cache: set the local copy of &quot;foo&quot; to &quot;caching-in-progress&quot;\n[D] client-&gt; server: GET foo.\n[I] server -&gt; client: Invalidate foo (somebody else touched it)\nClient cache: delete &quot;foo&quot; from the local cache.\n[D] server -&gt; client: &quot;bar&quot; (the reply of &quot;GET foo&quot;)\nClient cache: don&#39;t set &quot;bar&quot; since the entry for &quot;foo&quot; is missing.\n</code></pre>\n<p>Such a race condition is not possible when using a single connection for both<br>data and invalidation messages, since the order of the messages is always known<br>in that case.</p>\n<h2>What to do when losing connection with the server</h2>\n<p>Similarly, if we lost the connection with the socket we use in order to<br>get the invalidation messages, we may end with stale data. In order to avoid<br>this problem, we need to do the following things:</p>\n<ol>\n<li>Make sure that if the connection is lost, the local cache is flushed.</li>\n<li>Both when using RESP2 with Pub/Sub, or RESP3, ping the invalidation channel periodically (you can send PING commands even when the connection is in Pub/Sub mode!). If the connection looks broken and we are not able to receive ping backs, after a maximum amount of time, close the connection and flush the cache.</li>\n</ol>\n<h2>What to cache</h2>\n<p>Clients may want to run internal statistics about the number of times<br>a given cached key was actually served in a request, to understand in the<br>future what is good to cache. In general:</p>\n<ul>\n<li>We don&#39;t want to cache many keys that change continuously.</li>\n<li>We don&#39;t want to cache many keys that are requested very rarely.</li>\n<li>We want to cache keys that are requested often and change at a reasonable rate. For an example of key not changing at a reasonable rate, think of a global counter that is continuously <code>INCR</code>emented.</li>\n</ul>\n<p>However simpler clients may just evict data using some random sampling just<br>remembering the last time a given cached value was served, trying to evict<br>keys that were not served recently.</p>\n<h2>Other hints for implementing client libraries</h2>\n<ul>\n<li>Handling TTLs: make sure you also request the key TTL and set the TTL in the local cache if you want to support caching keys with a TTL.</li>\n<li>Putting a max TTL on every key is a good idea, even if it has no TTL. This protects against bugs or connection issues that would make the client have old data in the local copy.</li>\n<li>Limiting the amount of memory used by clients is absolutely needed. There must be a way to evict old keys when new ones are added.</li>\n</ul>\n<h2>Limiting the amount of memory used by Valkey</h2>\n<p>Be sure to configure a suitable value for the maximum number of keys remembered by Valkey or alternatively use the BCAST mode that consumes no memory at all on the Valkey side. Note that the memory consumed by Valkey when BCAST is not used, is proportional both to the number of keys tracked and the number of clients requesting such keys.</p>\n"
  },
  {
    "id": "clients",
    "topicName": "Client handling",
    "description": "How the Valkey server manages client connections\n",
    "htmlContent": "<p>This document provides information about how Valkey handles clients at the network layer level: connections, timeouts, buffers, and other similar topics are covered here.</p>\n<h2>Accepting Client Connections</h2>\n<p>Valkey accepts clients connections on the configured TCP port and on the Unix socket if enabled. When a new client connection is accepted the following operations are performed:</p>\n<ul>\n<li>The client socket is put in the non-blocking state since Valkey uses multiplexing and non-blocking I/O.</li>\n<li>The <code>TCP_NODELAY</code> option is set in order to ensure that there are no delays to the connection.</li>\n<li>A <em>readable</em> file event is created so that Valkey is able to collect the client queries as soon as new data is available to read on the socket.</li>\n</ul>\n<p>After the client is initialized, Valkey checks if it is already at the limit<br>configured for the number of simultaneous clients (configured using the <code>maxclients</code> configuration directive, see the next section of this document for further information).</p>\n<p>When Valkey can&#39;t accept a new client connection because the maximum number of clients<br>has been reached, it tries to send an error to the client in order to<br>make it aware of this condition, closing the connection immediately.<br>The error message will reach the client even if the connection is<br>closed immediately by Valkey because the new socket output buffer is usually<br>big enough to contain the error, so the kernel will handle transmission<br>of the error.</p>\n<h2>What Order are Client Requests Served In?</h2>\n<p>The order is determined by a combination of the client socket file descriptor<br>number and order in which the kernel reports events, so the order should be<br>considered as unspecified.</p>\n<p>However, Valkey does the following two things when serving clients:</p>\n<ul>\n<li>It only performs a single <code>read()</code> system call every time there is something new to read from the client socket. This ensures that if we have multiple clients connected, and a few send queries at a high rate, other clients are not penalized and will not experience latency issues.</li>\n<li>However once new data is read from a client, all the queries contained in the current buffers are processed sequentially. This improves locality and does not need iterating a second time to see if there are clients that need some processing time.</li>\n</ul>\n<h2>Maximum Concurrent Connected Clients</h2>\n<p>The limit for the maximum number of clients that can be handled simultaneously<br>is configurable using the <code>maxclients</code> directive in <code>valkey.conf</code>. The default<br>is 10,000 clients.</p>\n<p>However, Valkey checks with the kernel what the maximum number of file<br>descriptors that we are able to open is (the <em>soft limit</em> is checked). If the<br>limit is less than the maximum number of clients we want to handle, plus<br>32 (that is the number of file descriptors Valkey reserves for internal uses),<br>then the maximum number of clients is updated to match the number<br>of clients it is <em>really able to handle</em> under the current operating system<br>limit.</p>\n<p>When <code>maxclients</code> is set to a number greater than Valkey can support, a message is logged at startup:</p>\n<pre><code>$ ./valkey-server --maxclients 100000\n[41422] 23 Jan 11:28:33.179 # Unable to set the max number of files limit to 100032 (Invalid argument), setting the max clients configuration to 10112.\n</code></pre>\n<p>When Valkey is configured in order to handle a specific number of clients it<br>is a good idea to make sure that the operating system limit for the maximum<br>number of file descriptors per process is also set accordingly.</p>\n<p>Under Linux these limits can be set both in the current session and as a<br>system-wide setting with the following commands:</p>\n<ul>\n<li><code>ulimit -Sn 100000 # This will only work if hard limit is big enough.</code></li>\n<li><code>sysctl -w fs.file-max=100000</code></li>\n</ul>\n<h2>Output Buffer Limits</h2>\n<p>Valkey needs to handle a variable-length output buffer for every client, since<br>a command can produce a large amount of data that needs to be transferred to the<br>client.</p>\n<p>However it is possible that a client sends more commands producing more output<br>to serve at a faster rate than that which Valkey can send the existing output to the<br>client. This is especially true with Pub/Sub clients in case a client is not<br>able to process new messages fast enough.</p>\n<p>Both conditions will cause the client output buffer to grow and consume<br>more and more memory. For this reason by default Sets limits to the<br>output buffer size for different kind of clients. When the limit is reached<br>the client connection is closed and the event logged in the Valkey log file.</p>\n<p>There are two kind of limits Valkey uses:</p>\n<ul>\n<li>The <strong>hard limit</strong> is a fixed limit that when reached will make Valkey close the client connection as soon as possible.</li>\n<li>The <strong>soft limit</strong> instead is a limit that depends on the time, for instance a soft limit of 32 megabytes per 10 seconds means that if the client has an output buffer bigger than 32 megabytes for, continuously, 10 seconds, the connection gets closed.</li>\n</ul>\n<p>Different kind of clients have different default limits:</p>\n<ul>\n<li><strong>Normal clients</strong> have a default limit of 0, that means, no limit at all, because most normal clients use blocking implementations sending a single command and waiting for the reply to be completely read before sending the next command, so it is always not desirable to close the connection in case of a normal client.</li>\n<li><strong>Pub/Sub clients</strong> have a default hard limit of 32 megabytes and a soft limit of 8 megabytes per 60 seconds.</li>\n<li><strong>Replicas</strong> have a default hard limit of 256 megabytes and a soft limit of 64 megabyte per 60 seconds.</li>\n</ul>\n<p>It is possible to change the limit at runtime using the <code>CONFIG SET</code> command or in a permanent way using the Valkey configuration file <code>valkey.conf</code>. See the example <code>valkey.conf</code> in the Valkey distribution for more information about how to set the limit.</p>\n<h2>Query Buffer Hard Limit</h2>\n<p>Every client is also subject to a query buffer limit. This is a non-configurable hard limit that will close the connection when the client query buffer (that is the buffer we use to accumulate commands from the client) reaches 1 GB, and is actually only an extreme limit to avoid a server crash in case of client or server software bugs.</p>\n<h2>Client Eviction</h2>\n<p>Valkey is built to handle a very large number of client connections.<br>Client connections tend to consume memory, and when there are many of them, the aggregate memory consumption can be extremely high, leading to data eviction or out-of-memory errors.<br>These cases can be mitigated to an extent using <a href=\"#output-buffer-limits\">output buffer limits</a>, but Valkey allows us a more robust configuration to limit the aggregate memory used by all clients&#39; connections.</p>\n<p>This mechanism is called <strong>client eviction</strong>, and it&#39;s essentially a safety mechanism that will disconnect clients once the aggregate memory usage of all clients is above a threshold.<br>The mechanism first attempts to disconnect clients that use the most memory.<br>It disconnects the minimal number of clients needed to return below the <code>maxmemory-clients</code> threshold.</p>\n<p><code>maxmemory-clients</code> defines the maximum aggregate memory usage of all clients connected to Valkey.<br>The aggregation takes into account all the memory used by the client connections: the <a href=\"#query-buffer-hard-limit\">query buffer</a>, the output buffer, and other intermediate buffers.</p>\n<p>Note that replica and primary connections aren&#39;t affected by the client eviction mechanism. Therefore, such connections are never evicted.</p>\n<p><code>maxmemory-clients</code> can be set permanently in the configuration file (<code>valkey.conf</code>) or via the <code>CONFIG SET</code> command.<br>This setting can either be 0 (meaning no limit), a size in bytes (possibly with <code>mb</code>/<code>gb</code> suffix),<br>or a percentage of <code>maxmemory</code> by using the <code>%</code> suffix (e.g. setting it to <code>10%</code> would mean 10% of the <code>maxmemory</code> configuration).</p>\n<p>The default setting is 0, meaning client eviction is turned off by default.<br>However, for any large production deployment, it is highly recommended to configure some non-zero <code>maxmemory-clients</code> value.<br>A value <code>5%</code>, for example, can be a good place to start.</p>\n<p>It is possible to flag a specific client connection to be excluded from the client eviction mechanism.<br>This is useful for control path connections.<br>If, for example, you have an application that monitors the server via the <code>INFO</code> command and alerts you in case of a problem, you might want to make sure this connection isn&#39;t evicted.<br>You can do so using the following command (from the relevant client&#39;s connection):</p>\n<p><code>CLIENT NO-EVICT</code> <code>on</code></p>\n<p>And you can revert that with:</p>\n<p><code>CLIENT NO-EVICT</code> <code>off</code></p>\n<p>For more information and an example refer to the <code>maxmemory-clients</code> section in the default <code>valkey.conf</code> file.</p>\n<p>Client eviction is available from Redis OSS 7.0.</p>\n<h2>Client Timeouts</h2>\n<p>By default recent versions of Valkey don&#39;t close the connection with the client<br>if the client is idle for many seconds: the connection will remain open forever.</p>\n<p>However if you don&#39;t like this behavior, you can configure a timeout, so that<br>if the client is idle for more than the specified number of seconds, the client connection will be closed.</p>\n<p>You can configure this limit via <code>valkey.conf</code> or simply using <code>CONFIG SET timeout &lt;value&gt;</code>.</p>\n<p>Note that the timeout only applies to normal clients and it <strong>does not apply to Pub/Sub clients</strong>, since a Pub/Sub connection is a <em>push style</em> connection so a client that is idle is the norm.</p>\n<p>Even if by default connections are not subject to timeout, there are two conditions when it makes sense to set a timeout:</p>\n<ul>\n<li>Mission critical applications where a bug in the client software may saturate the Valkey server with idle connections, causing service disruption.</li>\n<li>As a debugging mechanism in order to be able to connect with the server if a bug in the client software saturates the server with idle connections, making it impossible to interact with the server.</li>\n</ul>\n<p>Timeouts are not to be considered very precise: Valkey avoids setting timer events or running O(N) algorithms in order to check idle clients, so the check is performed incrementally from time to time. This means that it is possible that while the timeout is set to 10 seconds, the client connection will be closed, for instance, after 12 seconds if many clients are connected at the same time.</p>\n<h2>The CLIENT Command</h2>\n<p>The Valkey <code>CLIENT</code> command allows you to inspect the state of every connected client, to kill a specific client, and to name connections. It is a very powerful debugging tool if you use Valkey at scale.</p>\n<p><code>CLIENT LIST</code> is used in order to obtain a list of connected clients and their state:</p>\n<pre><code>127.0.0.1:6379&gt; client list\naddr=127.0.0.1:52555 fd=5 name= age=855 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=32768 obl=0 oll=0 omem=0 events=r cmd=client\naddr=127.0.0.1:52787 fd=6 name= age=6 idle=5 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=ping\n</code></pre>\n<p>In the above example two clients are connected to the Valkey server. Let&#39;s look at what some of the data returned represents:</p>\n<ul>\n<li><strong>addr</strong>: The client address, that is, the client IP and the remote port number it used to connect with the Valkey server.</li>\n<li><strong>fd</strong>: The client socket file descriptor number.</li>\n<li><strong>name</strong>: The client name as set by <code>CLIENT SETNAME</code>.</li>\n<li><strong>age</strong>: The number of seconds the connection existed for.</li>\n<li><strong>idle</strong>: The number of seconds the connection is idle.</li>\n<li><strong>flags</strong>: The kind of client (N means normal client, check the <a href=\"../commands/client-list\">full list of flags</a>).</li>\n<li><strong>omem</strong>: The amount of memory used by the client for the output buffer.</li>\n<li><strong>cmd</strong>: The last executed command.</li>\n</ul>\n<p>See the <a href=\"../commands/client-list\"><code>CLIENT LIST</code></a> documentation for the full listing of fields and their purpose.</p>\n<p>Once you have the list of clients, you can close a client&#39;s connection using the <code>CLIENT KILL</code> command, specifying the client address as its argument.</p>\n<p>The commands <code>CLIENT SETNAME</code> and <code>CLIENT GETNAME</code> can be used to set and get the connection name. Starting with Redis OSS 4.0, the client name is shown in the<br><code>SLOWLOG</code> output, to help identify clients that create latency issues.</p>\n<h2>TCP keepalive</h2>\n<p>Valkey has TCP keepalive (<code>SO_KEEPALIVE</code> socket option) enabled by default and set to about 300 seconds. This option is useful in order to detect dead peers (clients that cannot be reached even if they look connected). Moreover, if there is network equipment between clients and servers that need to see some traffic in order to take the connection open, the option will prevent unexpected connection closed events.</p>\n"
  },
  {
    "id": "cluster-spec",
    "topicName": "Cluster specification",
    "description": "Detailed specification for Valkey cluster\n",
    "htmlContent": "<p>Welcome to the <strong>Valkey Cluster Specification</strong>. Here you&#39;ll find information<br>about the algorithms and design rationales of Valkey Cluster. This document is a work<br>in progress as it is continuously synchronized with the actual implementation<br>of Valkey.</p>\n<h2>Main properties and rationales of the design</h2>\n<h3>Valkey Cluster goals</h3>\n<p>Valkey Cluster is a distributed implementation of Valkey with the following goals in order of importance in the design:</p>\n<ul>\n<li>High performance and linear scalability up to 1000 nodes. There are no proxies, asynchronous replication is used, and no merge operations are performed on values.</li>\n<li>Acceptable degree of write safety: the system tries (in a best-effort way) to retain all the writes originating from clients connected with the majority of the primary nodes. Usually there are small windows where acknowledged writes can be lost. Windows to lose acknowledged writes are larger when clients are in a minority partition.</li>\n<li>Availability: Valkey Cluster is able to survive partitions where the majority of the primary nodes are reachable and there is at least one reachable replica for every primary node that is no longer reachable. Moreover using <em>replicas migration</em>, primaries no longer replicated by any replica will receive one from a primary which is covered by multiple replicas.</li>\n</ul>\n<h3>Implemented subset</h3>\n<p>Valkey Cluster implements all the single key commands available in the<br>non-distributed version of Valkey. Commands performing complex multi-key<br>operations like set unions and intersections are implemented for cases where<br>all of the keys involved in the operation hash to the same slot.</p>\n<p>Valkey Cluster implements a concept called <strong>hash tags</strong> that can be used<br>to force certain keys to be stored in the same hash slot. However, during<br>manual resharding, multi-key operations may become unavailable for some time<br>while single-key operations are always available.</p>\n<p>Valkey Cluster does not support multiple databases like the standalone version<br>of Valkey. We only support database <code>0</code>; the <code>SELECT</code> command is not allowed.</p>\n<h2>Client and Server roles in the Valkey cluster protocol</h2>\n<p>In Valkey Cluster, nodes are responsible for holding the data,<br>and taking the state of the cluster, including mapping keys to the right nodes.<br>Cluster nodes are also able to auto-discover other nodes, detect non-working<br>nodes, and promote replica nodes to primary when needed in order<br>to continue to operate when a failure occurs.</p>\n<p>To perform their tasks all the cluster nodes are connected using a<br>TCP bus and a binary protocol, called the <strong>Valkey Cluster Bus</strong>.<br>Every node is connected to every other node in the cluster using the cluster<br>bus. Nodes use a gossip protocol to propagate information about the cluster<br>in order to discover new nodes, to send ping packets to make sure all the<br>other nodes are working properly, and to send cluster messages needed to<br>signal specific conditions. The cluster bus is also used in order to<br>propagate Pub/Sub messages across the cluster and to orchestrate manual<br>failovers when requested by users (manual failovers are failovers which<br>are not initiated by the Valkey Cluster failure detector, but by the<br>system administrator directly).</p>\n<p>Since cluster nodes are not able to proxy requests, clients may be redirected<br>to other nodes using redirection errors <code>-MOVED</code> and <code>-ASK</code>.<br>The client is in theory free to send requests to all the nodes in the cluster,<br>getting redirected if needed, so the client is not required to hold the<br>state of the cluster. However clients that are able to cache the map between<br>keys and nodes can improve the performance in a sensible way.</p>\n<h3>Write safety</h3>\n<p>Valkey Cluster uses asynchronous replication between nodes, and <strong>last failover wins</strong> implicit merge function. This means that the last elected primary dataset eventually replaces all the other replicas. There is always a window of time when it is possible to lose writes during partitions. However these windows are very different in the case of a client that is connected to the majority of primaries, and a client that is connected to the minority of primaries.</p>\n<p>Valkey Cluster tries harder to retain writes that are performed by clients connected to the majority of primaries, compared to writes performed in the minority side.<br>The following are examples of scenarios that lead to loss of acknowledged<br>writes received in the majority partitions during failures:</p>\n<ol>\n<li><p>A write may reach a primary, but while the primary may be able to reply to the client, the write may not be propagated to replicas via the asynchronous replication used between primary and replica nodes. If the primary dies without the write reaching the replicas, the write is lost forever if the primary is unreachable for a long enough period that one of its replicas is promoted. This is usually hard to observe in the case of a total, sudden failure of a primary node since primaries try to reply to clients (with the acknowledge of the write) and replicas (propagating the write) at about the same time. However it is a real world failure mode.</p>\n</li>\n<li><p>Another theoretically possible failure mode where writes are lost is the following:</p>\n</li>\n</ol>\n<ul>\n<li>A primary is unreachable because of a partition.</li>\n<li>It gets failed over by one of its replicas.</li>\n<li>After some time it may be reachable again.</li>\n<li>A client with an out-of-date routing table may write to the old primary before it is converted into a replica (of the new primary) by the cluster.</li>\n</ul>\n<p>The second failure mode is unlikely to happen because primary nodes are unable to communicate with the majority of the other primaries for enough time to be failed over will no longer accept writes, and when the partition is fixed writes are still refused for a small amount of time to allow other nodes to inform about configuration changes. This failure mode also requires that the client&#39;s routing table has not yet been updated.</p>\n<p>Writes targeting the minority side of a partition have a larger window in which to get lost. For example, Valkey Cluster loses a non-trivial number of writes on partitions where there is a minority of primaries and at least one or more clients, since all the writes sent to the primaries may potentially get lost if the primaries are failed over in the majority side.</p>\n<p>Specifically, for a primary to be failed over it must be unreachable by the majority of primaries for at least <code>NODE_TIMEOUT</code>, so if the partition is fixed before that time, no writes are lost. When the partition lasts for more than <code>NODE_TIMEOUT</code>, all the writes performed in the minority side up to that point may be lost. However the minority side of a Valkey Cluster will start refusing writes as soon as <code>NODE_TIMEOUT</code> time has elapsed without contact with the majority, so there is a maximum window after which the minority becomes no longer available. Hence, no writes are accepted or lost after that time.</p>\n<h3>Availability</h3>\n<p>Valkey Cluster is not available in the minority side of the partition. In the majority side of the partition assuming that there are at least the majority of primaries and a replica for every unreachable primary, the cluster becomes available again after <code>NODE_TIMEOUT</code> time plus a few more seconds required for a replica to get elected and failover its primary (failovers are usually executed in a matter of 1 or 2 seconds).</p>\n<p>This means that Valkey Cluster is designed to survive failures of a few nodes in the cluster, but it is not a suitable solution for applications that require availability in the event of large net splits.</p>\n<p>In the example of a cluster composed of N primary nodes where every node has a single replica, the majority side of the cluster will remain available as long as a single node is partitioned away, and will remain available with a probability of <code>1-(1/(N*2-1))</code> when two nodes are partitioned away (after the first node fails we are left with <code>N*2-1</code> nodes in total, and the probability of the only primary without a replica to fail is <code>1/(N*2-1))</code>.</p>\n<p>For example, in a cluster with 5 nodes and a single replica per node, there is a <code>1/(5*2-1) = 11.11%</code> probability that after two nodes are partitioned away from the majority, the cluster will no longer be available.</p>\n<p>Thanks to a Valkey Cluster feature called <strong>replicas migration</strong> the Cluster<br>availability is improved in many real world scenarios by the fact that<br>replicas migrate to orphaned primaries (primaries no longer having replicas).<br>So at every successful failure event, the cluster may reconfigure the replicas<br>layout in order to better resist the next failure.</p>\n<h3>Performance</h3>\n<p>In Valkey Cluster nodes don&#39;t proxy commands to the right node in charge for a given key, but instead they redirect clients to the right nodes serving a given portion of the key space.</p>\n<p>Eventually clients obtain an up-to-date representation of the cluster and which node serves which subset of keys, so during normal operations clients directly contact the right nodes in order to send a given command.</p>\n<p>Because of the use of asynchronous replication, nodes do not wait for other nodes&#39; acknowledgment of writes (if not explicitly requested using the <code>WAIT</code> command).</p>\n<p>Also, because multi-key commands are only limited to <em>near</em> keys, data is never moved between nodes except when resharding.</p>\n<p>Normal operations are handled exactly as in the case of a single Valkey instance. This means that in a Valkey Cluster with N primary nodes you can expect the same performance as a single Valkey instance multiplied by N as the design scales linearly. At the same time the query is usually performed in a single round trip, since clients usually retain persistent connections with the nodes, so latency figures are also the same as the single standalone Valkey node case.</p>\n<p>Very high performance and scalability while preserving weak but<br>reasonable forms of data safety and availability is the main goal of<br>Valkey Cluster.</p>\n<h3>Why merge operations are avoided</h3>\n<p>The Valkey Cluster design avoids conflicting versions of the same key-value pair in multiple nodes as in the case of the Valkey data model this is not always desirable. Values in Valkey are often very large; it is common to see lists or sorted sets with millions of elements. Also data types are semantically complex. Transferring and merging these kind of values can be a major bottleneck and/or may require the non-trivial involvement of application-side logic, additional memory to store meta-data, and so forth.</p>\n<p>There are no strict technological limits here. CRDTs or synchronously replicated<br>state machines can model complex data types similar to Valkey. However, the<br>actual run time behavior of such systems would not be similar to Valkey Cluster.<br>Valkey Cluster was designed in order to cover the exact use cases of the<br>non-clustered Valkey deployment.</p>\n<h2>Overview of Valkey Cluster main components</h2>\n<h3>Key distribution model</h3>\n<p>The cluster&#39;s key space is split into 16384 slots, effectively setting an upper limit<br>for the cluster size of 16384 primary nodes (however, the suggested max size of<br>nodes is on the order of ~ 1000 nodes).</p>\n<p>Each primary node in a cluster handles a subset of the 16384 hash slots.<br>The cluster is <strong>stable</strong> when there is no cluster reconfiguration in<br>progress (i.e. where hash slots are being moved from one node to another).<br>When the cluster is stable, a single hash slot will be served by a single node<br>(however the serving node can have one or more replicas that will replace it in the case of net splits or failures,<br>and that can be used in order to scale read operations where reading stale data is acceptable).</p>\n<p>The base algorithm used to map keys to hash slots is the following<br>(read the next paragraph for the hash tag exception to this rule):</p>\n<pre><code>HASH_SLOT = CRC16(key) mod 16384\n</code></pre>\n<p>The CRC16 is specified as follows:</p>\n<ul>\n<li>Name: XMODEM (also known as ZMODEM or CRC-16/ACORN)</li>\n<li>Width: 16 bit</li>\n<li>Poly: 1021 (That is actually x^16 + x^12 + x^5 + 1)</li>\n<li>Initialization: 0000</li>\n<li>Reflect Input byte: False</li>\n<li>Reflect Output CRC: False</li>\n<li>Xor constant to output CRC: 0000</li>\n<li>Output for &quot;123456789&quot;: 31C3</li>\n</ul>\n<p>14 out of 16 CRC16 output bits are used (this is why there is<br>a modulo 16384 operation in the formula above).</p>\n<p>In our tests CRC16 behaved remarkably well in distributing different kinds of<br>keys evenly across the 16384 slots.</p>\n<p><strong>Note</strong>: A reference implementation of the CRC16 algorithm used is available in the Appendix A of this document.</p>\n<h3>Hash tags</h3>\n<p>There is an exception for the computation of the hash slot that is used in order<br>to implement <strong>hash tags</strong>. Hash tags are a way to ensure that multiple keys<br>are allocated in the same hash slot. This is used in order to implement<br>multi-key operations in Valkey Cluster.</p>\n<p>To implement hash tags, the hash slot for a key is computed in a<br>slightly different way in certain conditions.<br>If the key contains a &quot;{...}&quot; pattern only the substring between<br><code>{</code> and <code>}</code> is hashed in order to obtain the hash slot. However since it is<br>possible that there are multiple occurrences of <code>{</code> or <code>}</code> the algorithm is<br>well specified by the following rules:</p>\n<ul>\n<li>IF the key contains a <code>{</code> character.</li>\n<li>AND IF there is a <code>}</code> character to the right of <code>{</code>.</li>\n<li>AND IF there are one or more characters between the first occurrence of <code>{</code> and the first occurrence of <code>}</code>.</li>\n</ul>\n<p>Then instead of hashing the key, only what is between the first occurrence of <code>{</code> and the following first occurrence of <code>}</code> is hashed.</p>\n<p>Examples:</p>\n<ul>\n<li>The two keys <code>{user1000}.following</code> and <code>{user1000}.followers</code> will hash to the same hash slot since only the substring <code>user1000</code> will be hashed in order to compute the hash slot.</li>\n<li>For the key <code>foo{}{bar}</code> the whole key will be hashed as usually since the first occurrence of <code>{</code> is followed by <code>}</code> on the right without characters in the middle.</li>\n<li>For the key <code>foo{{bar}}zap</code> the substring <code>{bar</code> will be hashed, because it is the substring between the first occurrence of <code>{</code> and the first occurrence of <code>}</code> on its right.</li>\n<li>For the key <code>foo{bar}{zap}</code> the substring <code>bar</code> will be hashed, since the algorithm stops at the first valid or invalid (without bytes inside) match of <code>{</code> and <code>}</code>.</li>\n<li>What follows from the algorithm is that if the key starts with <code>{}</code>, it is guaranteed to be hashed as a whole. This is useful when using binary data as key names.</li>\n</ul>\n<h4>Glob-style patterns</h4>\n<p>Commands accepting a glob-style pattern, including <code>KEYS</code>, <code>SCAN</code> and <code>SORT</code>, are optimized for patterns that imply a single slot.<br>This means that if all keys that can match a pattern must belong to a specific slot, only this slot is searched for keys matching the pattern.<br>The pattern slot optimization is introduced in Valkey 8.0.</p>\n<p>The optimization kicks in when the pattern meets the following conditions:</p>\n<ul>\n<li>the pattern contains a hashtag,</li>\n<li>there are no wildcards or escape characters before the hashtag, and</li>\n<li>the hashtag within curly braces doesn&#39;t contain any wildcards or escape characters.</li>\n</ul>\n<p>For example, <code>SCAN 0 MATCH {abc}*</code> can successfully recognize the hashtag and scans only the slot corresponding to <code>abc</code>.<br>However, the patterns <code>*{abc}</code>, <code>{a*c}</code>, or <code>{a\\*bc}</code> cannot recognize the hashtag, so all slots need to be scanned.</p>\n<h4>Hash slot example code</h4>\n<p>Adding the hash tags exception, the following is an implementation of the <code>HASH_SLOT</code> function in Ruby and C language.</p>\n<p>Ruby example code:</p>\n<pre><code>def HASH_SLOT(key)\n    s = key.index &quot;{&quot;\n    if s\n        e = key.index &quot;}&quot;,s+1\n        if e &amp;&amp; e != s+1\n            key = key[s+1..e-1]\n        end\n    end\n    crc16(key) % 16384\nend\n</code></pre>\n<p>C example code:</p>\n<pre><code>unsigned int HASH_SLOT(char *key, int keylen) {\n    int s, e; /* start-end indexes of { and } */\n\n    /* Search the first occurrence of &#39;{&#39;. */\n    for (s = 0; s &lt; keylen; s++)\n        if (key[s] == &#39;{&#39;) break;\n\n    /* No &#39;{&#39; ? Hash the whole key. This is the base case. */\n    if (s == keylen) return crc16(key,keylen) &amp; 16383;\n\n    /* &#39;{&#39; found? Check if we have the corresponding &#39;}&#39;. */\n    for (e = s+1; e &lt; keylen; e++)\n        if (key[e] == &#39;}&#39;) break;\n\n    /* No &#39;}&#39; or nothing between {} ? Hash the whole key. */\n    if (e == keylen || e == s+1) return crc16(key,keylen) &amp; 16383;\n\n    /* If we are here there is both a { and a } on its right. Hash\n     * what is in the middle between { and }. */\n    return crc16(key+s+1,e-s-1) &amp; 16383;\n}\n</code></pre>\n<h3>Cluster node attributes</h3>\n<p>Every node has a unique name in the cluster. The node name is the<br>hex representation of a 160 bit random number, obtained the first time a<br>node is started (usually using /dev/urandom).<br>The node will save its ID in the node configuration file, and will use the<br>same ID forever, or at least as long as the node configuration file is not<br>deleted by the system administrator, or a <em>hard reset</em> is requested<br>via the <code>CLUSTER RESET</code> command.</p>\n<p>The node ID is used to identify every node across the whole cluster.<br>It is possible for a given node to change its IP address without any need<br>to also change the node ID. The cluster is also able to detect the change<br>in IP/port and reconfigure using the gossip protocol running over the cluster<br>bus.</p>\n<p>The node ID is not the only information associated with each node, but is<br>the only one that is always globally consistent. Every node has also the<br>following set of information associated. Some information is about the<br>cluster configuration detail of this specific node, and is eventually<br>consistent across the cluster. Some other information, like the last time<br>a node was pinged, is instead local to each node.</p>\n<p>Every node maintains the following information about other nodes that it is<br>aware of in the cluster: The node ID, IP and port of the node, a set of<br>flags, what is the primary of the node if it is flagged as <code>replica</code>, last time<br>the node was pinged and the last time the pong was received, the current<br><em>configuration epoch</em> of the node (explained later in this specification),<br>the link state and finally the set of hash slots served.</p>\n<p>A detailed <a href=\"../commands/cluster-nodes\">explanation of all the node fields</a> is described in the <code>CLUSTER NODES</code> documentation.</p>\n<p>The <code>CLUSTER NODES</code> command can be sent to any node in the cluster and provides the state of the cluster and the information for each node according to the local view the queried node has of the cluster.</p>\n<p>The following is sample output of the <code>CLUSTER NODES</code> command sent to a primary<br>node in a small cluster of three nodes.</p>\n<pre><code>$ valkey-cli cluster nodes\nd1861060fe6a534d42d8a19aeb36600e18785e04 127.0.0.1:6379 myself - 0 1318428930 1 connected 0-1364\n3886e65cc906bfd9b1f7e7bde468726a052d1dae 127.0.0.1:6380 master - 1318428930 1318428931 2 connected 1365-2729\nd289c575dcbc4bdd2931585fd4339089e461a27d 127.0.0.1:6381 master - 1318428931 1318428931 3 connected 2730-4095\n</code></pre>\n<p>In the above listing the different fields are in order: node id, address:port, flags, last ping sent, last pong received, configuration epoch, link state, slots. Details about the above fields will be covered as soon as we talk of specific parts of Valkey Cluster.</p>\n<h3>The cluster bus</h3>\n<p>Every Valkey Cluster node has an additional TCP port for receiving<br>incoming connections from other Valkey Cluster nodes. This port will be derived by adding 10000 to the data port or it can be specified with the cluster-port config. </p>\n<p>Example 1:</p>\n<p>If a Valkey node is listening for client connections on port 6379,<br>and you do not add cluster-port parameter in valkey.conf,<br>the Cluster bus port 16379 will be opened.</p>\n<p>Example 2:</p>\n<p>If a Valkey node is listening for client connections on port 6379,<br>and you set cluster-port 20000 in valkey.conf,<br>the Cluster bus port 20000 will be opened.</p>\n<p>Node-to-node communication happens exclusively using the Cluster bus and<br>the Cluster bus protocol: a binary protocol composed of frames<br>of different types and sizes. The Cluster bus binary protocol is not<br>publicly documented since it is not intended for external software devices<br>to talk with Valkey Cluster nodes using this protocol. However you can<br>obtain more details about the Cluster bus protocol by reading the<br><code>cluster.h</code> and <code>cluster.c</code> files in the Valkey Cluster source code.</p>\n<h3>Cluster topology</h3>\n<p>Valkey Cluster is a full mesh where every node is connected with every other node using a TCP connection.</p>\n<p>In a cluster of N nodes, every node has N-1 outgoing TCP connections, and N-1 incoming connections.</p>\n<p>These TCP connections are kept alive all the time and are not created on demand.<br>When a node expects a pong reply in response to a ping in the cluster bus, before waiting long enough to mark the node as unreachable, it will try to<br>refresh the connection with the node by reconnecting from scratch.</p>\n<p>While Valkey Cluster nodes form a full mesh, <strong>nodes use a gossip protocol and<br>a configuration update mechanism in order to avoid exchanging too many<br>messages between nodes during normal conditions</strong>, so the number of messages<br>exchanged is not exponential.</p>\n<h3>Node handshake</h3>\n<p>Nodes always accept connections on the cluster bus port, and even reply to<br>pings when received, even if the pinging node is not trusted.<br>However, all other packets will be discarded by the receiving node if the<br>sending node is not considered part of the cluster.</p>\n<p>A node will accept another node as part of the cluster only in two ways:</p>\n<ul>\n<li><p>If a node presents itself with a <code>MEET</code> message (<code>CLUSTER MEET</code> command). A meet message is exactly<br>like a <code>PING</code> message, but forces the receiver to accept the node as part of<br>the cluster. Nodes will send <code>MEET</code> messages to other nodes <strong>only if</strong> the system administrator requests this via <code>CLUSTER MEET ip port</code>.</p>\n</li>\n<li><p>A node will also register another node as part of the cluster if a node that is already trusted will gossip about this other node. So if A knows B, and B knows C, eventually B will send gossip messages to A about C. When this happens, A will register C as part of the network, and will try to connect with C.</p>\n</li>\n</ul>\n<p>This means that as long as we join nodes in any connected graph, they&#39;ll eventually form a fully connected graph automatically. This means that the cluster is able to auto-discover other nodes, but only if there is a trusted relationship that was forced by the system administrator.</p>\n<p>This mechanism makes the cluster more robust but prevents different Valkey clusters from accidentally mixing after change of IP addresses or other network related events.</p>\n<h2>Redirection and resharding</h2>\n<h3>MOVED Redirection</h3>\n<p>A Valkey client is free to send queries to every node in the cluster, including<br>replica nodes. The node will analyze the query, and if it is acceptable<br>(that is, only a single key is mentioned in the query, or the multiple keys<br>mentioned are all to the same hash slot) it will lookup what<br>node is responsible for the hash slot where the key or keys belong.</p>\n<p>If the hash slot is served by the node, the query is simply processed, otherwise<br>the node will check its internal hash slot to node map, and will reply<br>to the client with a MOVED error, like in the following example:</p>\n<pre><code>GET x\n-MOVED 3999 127.0.0.1:6381\n</code></pre>\n<p>The error includes the hash slot of the key (3999) and the endpoint:port of the instance that can serve the query.<br>The client needs to reissue the query to the specified node&#39;s endpoint address and port.<br>The endpoint can be either an IP address, a hostname, or it can be empty (e.g. <code>-MOVED 3999 :6380</code>).<br>An empty endpoint indicates that the server node has an unknown endpoint, and the client should send the next request to the same endpoint as the current request but with the provided port. </p>\n<p>Note that even if the client waits a long time before reissuing the query,<br>and in the meantime the cluster configuration changed, the destination node<br>will reply again with a MOVED error if the hash slot 3999 is now served by<br>another node. The same happens if the contacted node had no updated information.</p>\n<p>So while from the point of view of the cluster nodes are identified by<br>IDs we try to simplify our interface with the client just exposing a map<br>between hash slots and Valkey nodes identified by endpoint:port pairs.</p>\n<p>The client is not required to, but should try to memorize that hash slot<br>3999 is served by 127.0.0.1:6381. This way once a new command needs to<br>be issued it can compute the hash slot of the target key and have a<br>greater chance of choosing the right node.</p>\n<p>An alternative is to just refresh the whole client-side cluster layout<br>using the <code>CLUSTER SHARDS</code>, or the deprecated <code>CLUSTER SLOTS</code>, command<br>when a MOVED redirection is received. When a redirection is encountered, it<br>is likely multiple slots were reconfigured rather than just one, so updating<br>the client configuration as soon as possible is often the best strategy.</p>\n<p>Note that when the Cluster is stable (no ongoing changes in the configuration),<br>eventually all the clients will obtain a map of hash slots -&gt; nodes, making<br>the cluster efficient, with clients directly addressing the right nodes<br>without redirections, proxies or other single point of failure entities.</p>\n<p>A client <strong>must be also able to handle -ASK redirections</strong> that are described<br>later in this document, otherwise it is not a complete Valkey Cluster client.</p>\n<h3>Live resharding</h3>\n<p>Valkey Cluster supports the ability to add and remove nodes while the cluster<br>is running. Adding or removing a node is abstracted into the same<br>operation: moving a hash slot from one node to another. This means<br>that the same basic mechanism can be used in order to rebalance the cluster, add<br>or remove nodes, and so forth.</p>\n<ul>\n<li>To add a new node to the cluster an empty node is added to the cluster and some set of hash slots are moved from existing nodes to the new node.</li>\n<li>To remove a node from the cluster the hash slots assigned to that node are moved to other existing nodes.</li>\n<li>To rebalance the cluster a given set of hash slots are moved between nodes.</li>\n</ul>\n<p>The core of the implementation is the ability to move hash slots around.<br>From a practical point of view a hash slot is just a set of keys, so<br>what Valkey Cluster really does during <em>resharding</em> is to move keys from<br>an instance to another instance. Moving a hash slot means moving all the keys<br>that happen to hash into this hash slot.</p>\n<p>To understand how this works we need to show the <code>CLUSTER</code> subcommands<br>that are used to manipulate the slots translation table in a Valkey Cluster node.</p>\n<p>The following subcommands are available (among others not useful in this case):</p>\n<ul>\n<li><code>CLUSTER ADDSLOTS</code> slot1 [slot2] ... [slotN]</li>\n<li><code>CLUSTER DELSLOTS</code> slot1 [slot2] ... [slotN]</li>\n<li><code>CLUSTER ADDSLOTSRANGE</code> start-slot1 end-slot1 [start-slot2 end-slot2] ... [start-slotN end-slotN]</li>\n<li><code>CLUSTER DELSLOTSRANGE</code> start-slot1 end-slot1 [start-slot2 end-slot2] ... [start-slotN end-slotN]</li>\n<li><code>CLUSTER SETSLOT</code> slot NODE node</li>\n<li><code>CLUSTER SETSLOT</code> slot MIGRATING node</li>\n<li><code>CLUSTER SETSLOT</code> slot IMPORTING node</li>\n</ul>\n<p>The first four commands, <code>ADDSLOTS</code>, <code>DELSLOTS</code>, <code>ADDSLOTSRANGE</code> and <code>DELSLOTSRANGE</code>, are simply used to assign<br>(or remove) slots to a Valkey node. Assigning a slot means to tell a given<br>primary node that it will be in charge of storing and serving content for<br>the specified hash slot.</p>\n<p>After the hash slots are assigned they will propagate across the cluster<br>using the gossip protocol, as specified later in the<br><em>configuration propagation</em> section.</p>\n<p>The <code>ADDSLOTS</code> and <code>ADDSLOTSRANGE</code> commands are usually used when a new cluster is created<br>from scratch to assign each primary node a subset of all the 16384 hash<br>slots available.</p>\n<p>The <code>DELSLOTS</code>  and <code>DELSLOTSRANGE</code> are mainly used for manual modification of a cluster configuration<br>or for debugging tasks: in practice it is rarely used.</p>\n<p>The <code>SETSLOT</code> subcommand is used to assign a slot to a specific node ID if<br>the <code>SETSLOT &lt;slot&gt; NODE</code> form is used. Otherwise the slot can be set in the<br>two special states <code>MIGRATING</code> and <code>IMPORTING</code>. Those two special states<br>are used in order to migrate a hash slot from one node to another.</p>\n<ul>\n<li>When a slot is set as MIGRATING, the node will accept all queries that<br>are about this hash slot, but only if the key in question<br>exists, otherwise the query is forwarded using a <code>-ASK</code> redirection to the<br>node that is target of the migration.</li>\n<li>When a slot is set as IMPORTING, the node will accept all queries that<br>are about this hash slot, but only if the request is<br>preceded by an <code>ASKING</code> command. If the <code>ASKING</code> command was not given<br>by the client, the query is redirected to the real hash slot owner via<br>a <code>-MOVED</code> redirection error, as would happen normally.</li>\n</ul>\n<p>Let&#39;s make this clearer with an example of hash slot migration.<br>Assume that we have two Valkey primary nodes, called A and B.<br>We want to move hash slot 8 from A to B, so we issue commands like this:</p>\n<ul>\n<li>We send B: CLUSTER SETSLOT 8 IMPORTING A</li>\n<li>We send A: CLUSTER SETSLOT 8 MIGRATING B</li>\n</ul>\n<p>All the other nodes will continue to point clients to node &quot;A&quot; every time<br>they are queried with a key that belongs to hash slot 8, so what happens<br>is that:</p>\n<ul>\n<li>All queries about existing keys are processed by &quot;A&quot;.</li>\n<li>All queries about non-existing keys in A are processed by &quot;B&quot;, because &quot;A&quot; will redirect clients to &quot;B&quot;.</li>\n</ul>\n<p>This way we no longer create new keys in &quot;A&quot;.<br>In the meantime, <code>valkey-cli</code> used during reshardings<br>and Valkey Cluster configuration will migrate existing keys in<br>hash slot 8 from A to B.<br>This is performed using the following command:</p>\n<pre><code>CLUSTER GETKEYSINSLOT slot count\n</code></pre>\n<p>The above command will return <code>count</code> keys in the specified hash slot.<br>For keys returned, <code>valkey-cli</code> sends node &quot;A&quot; a <code>MIGRATE</code> command, that<br>will migrate the specified keys from A to B in an atomic way (both instances<br>are locked for the time (usually very small time) needed to migrate keys so<br>there are no race conditions). This is how <code>MIGRATE</code> works:</p>\n<pre><code>MIGRATE target_host target_port &quot;&quot; target_database id timeout KEYS key1 key2 ...\n</code></pre>\n<p><code>MIGRATE</code> will connect to the target instance, send a serialized version of<br>the key, and once an OK code is received, the old key from its own dataset<br>will be deleted. From the point of view of an external client a key exists<br>either in A or B at any given time.</p>\n<p>In Valkey Cluster there is no need to specify a database other than 0, but<br><code>MIGRATE</code> is a general command that can be used for other tasks not<br>involving Valkey Cluster.<br><code>MIGRATE</code> is optimized to be as fast as possible even when moving complex<br>keys such as long lists, but in Valkey Cluster reconfiguring the<br>cluster where big keys are present is not considered a wise procedure if<br>there are latency constraints in the application using the database.</p>\n<p>When the migration process is finally finished, the <code>SETSLOT &lt;slot&gt; NODE &lt;node-id&gt;</code> command is sent to the two nodes involved in the migration in order to<br>set the slots to their normal state again. The same command is usually<br>sent to all other nodes to avoid waiting for the natural<br>propagation of the new configuration across the cluster.</p>\n<h4>Replication of <code>CLUSTER SETSLOT</code></h4>\n<p>Starting from Valkey 8.0, the <code>CLUSTER SETSLOT</code> command is replicated if the replicas are running Valkey version 8.0+.<br>The primary node waits up to 2 seconds, by default, for all healthy replicas to acknowledge the replication.<br>If not all health replicas acknowledge the replication within this time frame, the primary aborts the command,<br>and the client receives a <code>NOREPLICAS Not enough good replicas to write</code> error.<br>Operators can retry the command or customize the timeout using the <code>TIMEOUT</code> parameter to further increase the<br>reliability of live resharding:</p>\n<pre><code>CLUSTER SETSLOT slot [MIGRATING|IMPORTING|NODE] node-id [TIMEOUT timeout]\n</code></pre>\n<p>The <code>timeout</code> is specified in seconds, where a value of 0 indicates an indefinite wait time.</p>\n<p>Replicating the slot information and ensuring acknowledgement from health replicas significantly reduces<br>the likelihood of losing replication states if the primary fails after executing the command.<br>For example, consider a scenario where the target primary node <code>B</code> is finalizing a slot migration.<br>Before the <code>SETSLOT</code> command is replicated to its replica node <code>B’</code>, <code>B</code> might send a cluster <code>PONG</code><br>message to the source primary node <code>A</code>, promoting <code>A</code> to relinquish its ownership of the slot in question.<br>If <code>B</code> crashes right after this point, the replica node <code>B’</code>, which could be elected as the new primary,<br>would not be aware of the slot ownership transfer without the successful replication of <code>SETSLOT</code>.<br>This would leave the slot without an owner, leading to potential data loss and cluster topology inconsistency.</p>\n<h4>Election in empty shards</h4>\n<p>Starting from Valkey 8.0, Valkey clusters introduce the ability to elect a primary in empty shards.<br>This behavior ensures that even when a shard is in the process of receiving its first slot,<br>a primary can be elected. This prevents scenarios where there would be no primary available in the<br>empty shard to handle redirected requests from the official slot owner,<br>thereby maintaining availability during the live resharding.</p>\n<h3>ASK redirection</h3>\n<p>In the previous section, we briefly talked about ASK redirection. Why can&#39;t<br>we simply use MOVED redirection? Because while MOVED means that<br>we think the hash slot is permanently served by a different node and the<br>next queries should be tried against the specified node. ASK means to<br>send only the next query to the specified node.</p>\n<p>This is needed because the next query about hash slot 8 can be about a<br>key that is still in A, so we always want the client to try A and<br>then B if needed. Since this happens only for one hash slot out of 16384<br>available, the performance hit on the cluster is acceptable.</p>\n<p>We need to force that client behavior, so to make sure<br>that clients will only try node B after A was tried, node B will only<br>accept queries of a slot that is set as IMPORTING if the client sends the<br>ASKING command before sending the query.</p>\n<p>Basically the ASKING command sets a one-time flag on the client that forces<br>a node to serve a query about an IMPORTING slot.</p>\n<p>The full semantics of ASK redirection from the point of view of the client is as follows:</p>\n<ul>\n<li>If ASK redirection is received, send only the query that was redirected to the specified node but continue sending subsequent queries to the old node.</li>\n<li>Start the redirected query with the ASKING command.</li>\n<li>Don&#39;t yet update local client tables to map hash slot 8 to B.</li>\n</ul>\n<p>Once hash slot 8 migration is completed, A will send a MOVED message and<br>the client may permanently map hash slot 8 to the new endpoint and port pair.<br>Note that if a buggy client performs the map earlier this is not<br>a problem since it will not send the ASKING command before issuing the query,<br>so B will redirect the client to A using a MOVED redirection error.</p>\n<p>Slots migration is explained in similar terms but with different wording<br>(for the sake of redundancy in the documentation) in the <code>CLUSTER SETSLOT</code><br>command documentation.</p>\n<p>Starting from Valkey 8.0, when the primary in either the source or target shard fails during live resharding,<br>the primary in the other shard will automatically attempt to update its migrating/importing state to correctly pair<br>with the newly elected primary. If this update is successful, the ASK redirection will continue functioning without<br>requiring administrator intervention. In the event that slot migration fails, administrators can manually resume<br>the interrupted slot migration by running the command <code>valkey-cli --cluster fix &lt;ip:port&gt;</code>.</p>\n<p>Additionally, since Valkey 8.0, replicas are now able to return <code>ASK</code> redirects during slot migrations.<br>This capability was previously unavailable, as replicas were not aware of ongoing slot migrations in earlier versions.<br>See the <a href=\"../commands/readonly\">READONLY</a> command.</p>\n<h3>Client connections and redirection handling</h3>\n<p>To be efficient, Valkey Cluster clients maintain a map of the current slot<br>configuration. However, this configuration is not <em>required</em> to be up to date.<br>When contacting the wrong node results in a redirection, the client<br>can update its internal slot map accordingly.</p>\n<p>Clients usually need to fetch a complete list of slots and mapped node<br>addresses in two different situations:</p>\n<ul>\n<li>At startup, to populate the initial slots configuration</li>\n<li>When the client receives a <code>MOVED</code> redirection</li>\n</ul>\n<p>Note that a client may handle the <code>MOVED</code> redirection by updating just the<br>moved slot in its table; however this is usually not efficient because often<br>the configuration of multiple slots will be modified at once. For example, if a<br>replica is promoted to primary, all of the slots served by the old primary will<br>be remapped). It is much simpler to react to a <code>MOVED</code> redirection by<br>fetching the full map of slots to nodes from scratch.</p>\n<p>Client can issue a <code>CLUSTER SLOTS</code> command to retrieve an array of slot<br>ranges and the associated primary and replica nodes serving the specified ranges.</p>\n<p>The following is an example of output of <code>CLUSTER SLOTS</code>:</p>\n<pre><code>127.0.0.1:7000&gt; cluster slots\n1) 1) (integer) 5461\n   2) (integer) 10922\n   3) 1) &quot;127.0.0.1&quot;\n      2) (integer) 7001\n   4) 1) &quot;127.0.0.1&quot;\n      2) (integer) 7004\n2) 1) (integer) 0\n   2) (integer) 5460\n   3) 1) &quot;127.0.0.1&quot;\n      2) (integer) 7000\n   4) 1) &quot;127.0.0.1&quot;\n      2) (integer) 7003\n3) 1) (integer) 10923\n   2) (integer) 16383\n   3) 1) &quot;127.0.0.1&quot;\n      2) (integer) 7002\n   4) 1) &quot;127.0.0.1&quot;\n      2) (integer) 7005\n</code></pre>\n<p>The first two sub-elements of every element of the returned array are the<br>start and end slots of the range. The additional elements represent address-port<br>pairs. The first address-port pair is the primary serving the slot, and the<br>additional address-port pairs are the replicas serving the same slot. Replicas<br>will be listed only when not in an error condition (i.e., when their FAIL flag is not set).</p>\n<p>The first element in the output above says that slots from 5461 to 10922<br>(start and end included) are served by 127.0.0.1:7001, and it is possible<br>to scale read-only load contacting the replica at 127.0.0.1:7004.</p>\n<p><code>CLUSTER SLOTS</code> is not guaranteed to return ranges that cover the full<br>16384 slots if the cluster is misconfigured, so clients should initialize the<br>slots configuration map filling the target nodes with NULL objects, and<br>report an error if the user tries to execute commands about keys<br>that belong to unassigned slots.</p>\n<p>Before returning an error to the caller when a slot is found to<br>be unassigned, the client should try to fetch the slots configuration<br>again to check if the cluster is now configured properly.</p>\n<h3>Multi-keys operations</h3>\n<p>Using hash tags, clients are free to use multi-key operations.<br>For example the following operation is valid:</p>\n<pre><code>MSET {user:1000}.name Angela {user:1000}.surname White\n</code></pre>\n<p>Multi-key operations may become unavailable when a resharding of the<br>hash slot the keys belong to is in progress.</p>\n<p>More specifically, even during a resharding the multi-key operations targeting<br>keys that all exist and all still hash to the same slot (either the source or<br>destination node) are still available.</p>\n<p>Operations on keys that don&#39;t exist or are - during the resharding - split<br>between the source and destination nodes, will generate a <code>-TRYAGAIN</code> error.<br>The client can try the operation after some time, or report back the error.</p>\n<p>As soon as migration of the specified hash slot has terminated, all<br>multi-key operations are available again for that hash slot.</p>\n<h3>Scaling reads using replica nodes</h3>\n<p>Normally replica nodes will redirect clients to the authoritative primary for<br>the hash slot involved in a given command, however clients can use replicas<br>in order to scale reads using the <code>READONLY</code> command.</p>\n<p><code>READONLY</code> tells a Valkey Cluster replica node that the client is ok reading<br>possibly stale data and is not interested in running write queries.</p>\n<p>When the connection is in readonly mode, the cluster will send a redirection<br>to the client only if the operation involves keys not served<br>by the replica&#39;s primary node. This may happen because:</p>\n<ol>\n<li>The client sent a command about hash slots never served by the primary of this replica.</li>\n<li>The cluster was reconfigured (for example resharded) and the replica is no longer able to serve commands for a given hash slot.</li>\n</ol>\n<p>When this happens the client should update its hash slot map as explained in<br>the previous sections.</p>\n<p>The readonly state of the connection can be cleared using the <code>READWRITE</code> command.</p>\n<h2>Fault Tolerance</h2>\n<h3>Heartbeat and gossip messages</h3>\n<p>Valkey Cluster nodes continuously exchange ping and pong packets. Those two kinds of packets have the same structure, and both carry important configuration information. The only actual difference is the message type field. We&#39;ll refer to the sum of ping and pong packets as <em>heartbeat packets</em>.</p>\n<p>Usually nodes send ping packets that will trigger the receivers to reply with pong packets. However this is not necessarily true. It is possible for nodes to just send pong packets to send information to other nodes about their configuration, without triggering a reply. This is useful, for example, in order to broadcast a new configuration as soon as possible.</p>\n<p>Usually a node will ping a few random nodes every second so that the total number of ping packets sent (and pong packets received) by each node is a constant amount regardless of the number of nodes in the cluster.</p>\n<p>However every node makes sure to ping every other node that hasn&#39;t sent a ping or received a pong for longer than half the <code>NODE_TIMEOUT</code> time. Before <code>NODE_TIMEOUT</code> has elapsed, nodes also try to reconnect the TCP link with another node to make sure nodes are not believed to be unreachable only because there is a problem in the current TCP connection.</p>\n<p>The number of messages globally exchanged can be sizable if <code>NODE_TIMEOUT</code> is set to a small figure and the number of nodes (N) is very large, since every node will try to ping every other node for which they don&#39;t have fresh information every half the <code>NODE_TIMEOUT</code> time.</p>\n<p>For example in a 100 node cluster with a node timeout set to 60 seconds, every node will try to send 99 pings every 30 seconds, with a total amount of pings of 3.3 per second. Multiplied by 100 nodes, this is 330 pings per second in the total cluster.</p>\n<p>There are ways to lower the number of messages, however there have been no<br>reported issues with the bandwidth currently used by Valkey Cluster failure<br>detection, so for now the obvious and direct design is used. Note that even<br>in the above example, the 330 packets per second exchanged are evenly<br>divided among 100 different nodes, so the traffic each node receives<br>is acceptable.</p>\n<h3>Heartbeat packet content</h3>\n<p>Ping and pong packets contain a header that is common to all types of packets (for instance packets to request a failover vote), and a special gossip section that is specific to Ping and Pong packets.</p>\n<p>The common header has the following information:</p>\n<ul>\n<li>Node ID, a 160 bit pseudorandom string that is assigned the first time a node is created and remains the same for all the life of a Valkey Cluster node.</li>\n<li>The <code>currentEpoch</code> and <code>configEpoch</code> fields of the sending node that are used to mount the distributed algorithms used by Valkey Cluster (this is explained in detail in the next sections). If the node is a replica the <code>configEpoch</code> is the last known <code>configEpoch</code> of its primary.</li>\n<li>The node flags, indicating if the node is a replica, a primary, and other single-bit node information.</li>\n<li>A bitmap of the hash slots served by the sending node, or if the node is a replica, a bitmap of the slots served by its primary.</li>\n<li>The sender TCP base port that is the port used by Valkey to accept client commands.</li>\n<li>The cluster port that is the port used by Valkey for node-to-node communication.</li>\n<li>The state of the cluster from the point of view of the sender (down or ok).</li>\n<li>The primary node ID of the sending node, if it is a replica.</li>\n</ul>\n<p>Ping and pong packets also contain a gossip section. This section offers to the receiver a view of what the sender node thinks about other nodes in the cluster. The gossip section only contains information about a few random nodes among the set of nodes known to the sender. The number of nodes mentioned in a gossip section is proportional to the cluster size.</p>\n<p>For every node added in the gossip section the following fields are reported:</p>\n<ul>\n<li>Node ID.</li>\n<li>IP and port of the node.</li>\n<li>Node flags.</li>\n</ul>\n<p>Gossip sections allow receiving nodes to get information about the state of other nodes from the point of view of the sender. This is useful both for failure detection and to discover other nodes in the cluster.</p>\n<h3>Failure detection</h3>\n<p>Valkey Cluster failure detection is used to recognize when a primary or replica node is no longer reachable by the majority of nodes and then respond by promoting a replica to the role of primary. When replica promotion is not possible the cluster is put in an error state to stop receiving queries from clients.</p>\n<p>As already mentioned, every node takes a list of flags associated with other known nodes. There are two flags that are used for failure detection that are called <code>PFAIL</code> and <code>FAIL</code>. <code>PFAIL</code> means <em>Possible failure</em>, and is a non-acknowledged failure type. <code>FAIL</code> means that a node is failing and that this condition was confirmed by a majority of primaries within a fixed amount of time.</p>\n<p><strong>PFAIL flag:</strong></p>\n<p>A node flags another node with the <code>PFAIL</code> flag when the node is not reachable for more than <code>NODE_TIMEOUT</code> time. Both primary and replica nodes can flag another node as <code>PFAIL</code>, regardless of its type.</p>\n<p>The concept of non-reachability for a Valkey Cluster node is that we have an <strong>active ping</strong> (a ping that we sent for which we have yet to get a reply) pending for longer than <code>NODE_TIMEOUT</code>. For this mechanism to work the <code>NODE_TIMEOUT</code> must be large compared to the network round trip time. In order to add reliability during normal operations, nodes will try to reconnect with other nodes in the cluster as soon as half of the <code>NODE_TIMEOUT</code> has elapsed without a reply to a ping. This mechanism ensures that connections are kept alive so broken connections usually won&#39;t result in false failure reports between nodes.</p>\n<p><strong>FAIL flag:</strong></p>\n<p>The <code>PFAIL</code> flag alone is just local information every node has about other nodes, but it is not sufficient to trigger a replica promotion. For a node to be considered down the <code>PFAIL</code> condition needs to be escalated to a <code>FAIL</code> condition.</p>\n<p>As outlined in the node heartbeats section of this document, every node sends gossip messages to every other node including the state of a few random known nodes. Every node eventually receives a set of node flags for every other node. This way every node has a mechanism to signal other nodes about failure conditions they have detected.</p>\n<p>A <code>PFAIL</code> condition is escalated to a <code>FAIL</code> condition when the following set of conditions are met:</p>\n<ul>\n<li>Some node, that we&#39;ll call A, has another node B flagged as <code>PFAIL</code>.</li>\n<li>Node A collected, via gossip sections, information about the state of B from the point of view of the majority of primaries in the cluster.</li>\n<li>The majority of primaries signaled the <code>PFAIL</code> or <code>FAIL</code> condition within <code>NODE_TIMEOUT * FAIL_REPORT_VALIDITY_MULT</code> time. (The validity factor is set to 2 in the current implementation, so this is just two times the <code>NODE_TIMEOUT</code> time).</li>\n</ul>\n<p>If all the above conditions are true, Node A will:</p>\n<ul>\n<li>Mark the node as <code>FAIL</code>.</li>\n<li>Send a <code>FAIL</code> message (as opposed to a <code>FAIL</code> condition within a heartbeat message) to all the reachable nodes.</li>\n</ul>\n<p>The <code>FAIL</code> message will force every receiving node to mark the node in <code>FAIL</code> state, whether or not it already flagged the node in <code>PFAIL</code> state.</p>\n<p>Note that <em>the FAIL flag is mostly one way</em>. That is, a node can go from <code>PFAIL</code> to <code>FAIL</code>, but a <code>FAIL</code> flag can only be cleared in the following situations:</p>\n<ul>\n<li>The node is already reachable and is a replica. In this case the <code>FAIL</code> flag can be cleared as replicas are not failed over.</li>\n<li>The node is already reachable and is a primary not serving any slot. In this case the <code>FAIL</code> flag can be cleared as primaries without slots do not really participate in the cluster and are waiting to be configured in order to join the cluster.</li>\n<li>The node is already reachable and is a primary, but a long time (N times the <code>NODE_TIMEOUT</code>) has elapsed without any detectable replica promotion. It&#39;s better for it to rejoin the cluster and continue in this case.</li>\n</ul>\n<p>It is useful to note that while the <code>PFAIL</code> -&gt; <code>FAIL</code> transition uses a form of agreement, the agreement used is weak:</p>\n<ol>\n<li>Nodes collect views of other nodes over some time period, so even if the majority of primary nodes need to &quot;agree&quot;, actually this is just state that we collected from different nodes at different times and we are not sure, nor we require, that at a given moment the majority of primaries agreed. However we discard failure reports which are old, so the failure was signaled by the majority of primaries within a window of time.</li>\n<li>While every node detecting the <code>FAIL</code> condition will force that condition on other nodes in the cluster using the <code>FAIL</code> message, there is no way to ensure the message will reach all the nodes. For instance a node may detect the <code>FAIL</code> condition and because of a partition will not be able to reach any other node.</li>\n</ol>\n<p>However the Valkey Cluster failure detection has a liveness requirement: eventually all the nodes should agree about the state of a given node. There are two cases that can originate from split brain conditions. Either some minority of nodes believe the node is in <code>FAIL</code> state, or a minority of nodes believe the node is not in <code>FAIL</code> state. In both the cases eventually the cluster will have a single view of the state of a given node:</p>\n<p><strong>Case 1</strong>: If a majority of primaries have flagged a node as <code>FAIL</code>, because of failure detection and the <em>chain effect</em> it generates, every other node will eventually flag the primary as <code>FAIL</code>, since in the specified window of time enough failures will be reported.</p>\n<p><strong>Case 2</strong>: When only a minority of primaries have flagged a node as <code>FAIL</code>, the replica promotion will not happen (as it uses a more formal algorithm that makes sure everybody knows about the promotion eventually) and every node will clear the <code>FAIL</code> state as per the <code>FAIL</code> state clearing rules above (i.e. no promotion after N times the <code>NODE_TIMEOUT</code> has elapsed).</p>\n<p><strong>The <code>FAIL</code> flag is only used as a trigger to run the safe part of the algorithm</strong> for the replica promotion. In theory a replica may act independently and start a replica promotion when its primary is not reachable, and wait for the primaries to refuse to provide the acknowledgment if the primary is actually reachable by the majority. However the added complexity of the <code>PFAIL -&gt; FAIL</code> state, the weak agreement, and the <code>FAIL</code> message forcing the propagation of the state in the shortest amount of time in the reachable part of the cluster, have practical advantages. Because of these mechanisms, usually all the nodes will stop accepting writes at about the same time if the cluster is in an error state. This is a desirable feature from the point of view of applications using Valkey Cluster. Also erroneous election attempts initiated by replicas that can&#39;t reach its primary due to local problems (the primary is otherwise reachable by the majority of other primary nodes) are avoided.</p>\n<h2>Configuration handling, propagation, and failovers</h2>\n<h3>Cluster current epoch</h3>\n<p>Valkey Cluster uses a concept similar to the Raft algorithm &quot;term&quot;. In Valkey Cluster the term is called epoch instead, and it is used in order to give incremental versioning to events. When multiple nodes provide conflicting information, it becomes possible for another node to understand which state is the most up to date.</p>\n<p>The <code>currentEpoch</code> is a 64 bit unsigned number.</p>\n<p>At node creation every Valkey Cluster node, both replicas and primary nodes, set the <code>currentEpoch</code> to 0.</p>\n<p>Every time a packet is received from another node, if the epoch of the sender (part of the cluster bus messages header) is greater than the local node epoch, the <code>currentEpoch</code> is updated to the sender epoch.</p>\n<p>Because of these semantics, eventually all the nodes will agree to the greatest <code>currentEpoch</code> in the cluster.</p>\n<p>This information is used when the state of the cluster is changed and a node seeks agreement in order to perform some action.</p>\n<p>Currently this happens only during replica promotion, as described in the next section. Basically the epoch is a logical clock for the cluster and dictates that given information wins over one with a smaller epoch.</p>\n<h3>Configuration epoch</h3>\n<p>Every primary always advertises its <code>configEpoch</code> in ping and pong packets along with a bitmap advertising the set of slots it serves.</p>\n<p>The <code>configEpoch</code> is set to zero in primaries when a new node is created.</p>\n<p>A new <code>configEpoch</code> is created during replica election. Replicas trying to replace<br>failing primaries increment their epoch and try to get authorization from<br>a majority of primaries. When a replica is authorized, a new unique <code>configEpoch</code><br>is created and the replica turns into a primary using the new <code>configEpoch</code>.</p>\n<p>As explained in the next sections the <code>configEpoch</code> helps to resolve conflicts when different nodes claim divergent configurations (a condition that may happen because of network partitions and node failures).</p>\n<p>Replica nodes also advertise the <code>configEpoch</code> field in ping and pong packets, but in the case of replicas the field represents the <code>configEpoch</code> of its primary as of the last time they exchanged packets. This allows other instances to detect when a replica has an old configuration that needs to be updated (primary nodes will not grant votes to replicas with an old configuration).</p>\n<p>Every time the <code>configEpoch</code> changes for some known node, it is permanently stored in the nodes.conf file by all the nodes that receive this information. The same also happens for the <code>currentEpoch</code> value. These two variables are guaranteed to be saved and <code>fsync-ed</code> to disk when updated before a node continues its operations.</p>\n<p>The <code>configEpoch</code> values generated using a simple algorithm during failovers<br>are guaranteed to be new, incremental, and unique.</p>\n<h3>Replica election and promotion</h3>\n<p>Replica election and promotion is handled by replica nodes, with the help of the primary nodes that vote for the replica to promote.<br>A replica election happens when a primary is in <code>FAIL</code> state from the point of view of at least one of its replicas that has the prerequisites in order to become a primary.</p>\n<p>In order for a replica to promote itself to primary, it needs to start an election and win it. All the replicas for a given primary can start an election if the primary is in <code>FAIL</code> state, however only one replica will win the election and promote itself to primary.</p>\n<p>A replica starts an election when the following conditions are met:</p>\n<ul>\n<li>The replica&#39;s primary is in <code>FAIL</code> state.</li>\n<li>The primary was serving a non-zero number of slots.</li>\n<li>The replica replication link was disconnected from the primary for no longer than a given amount of time, in order to ensure the promoted replica&#39;s data is reasonably fresh. This time is user configurable.</li>\n</ul>\n<p>In order to be elected, the first step for a replica is to increment its <code>currentEpoch</code> counter, and request votes from primary instances.</p>\n<p>Votes are requested by the replica by broadcasting a <code>FAILOVER_AUTH_REQUEST</code> packet to every primary node of the cluster. Then it waits for a maximum time of two times the <code>NODE_TIMEOUT</code> for replies to arrive (but always for at least 2 seconds).</p>\n<p>Once a primary has voted for a given replica, replying positively with a <code>FAILOVER_AUTH_ACK</code>, it can no longer vote for another replica of the same primary for a period of <code>NODE_TIMEOUT * 2</code>. In this period it will not be able to reply to other authorization requests for the same primary. This is not needed to guarantee safety, but useful for preventing multiple replicas from getting elected (even if with a different <code>configEpoch</code>) at around the same time, which is usually not wanted.</p>\n<p>A replica discards any <code>AUTH_ACK</code> replies with an epoch that is less than the <code>currentEpoch</code> at the time the vote request was sent. This ensures it doesn&#39;t count votes intended for a previous election.</p>\n<p>Once the replica receives ACKs from the majority of primaries, it wins the election.<br>Otherwise if the majority is not reached within the period of two times <code>NODE_TIMEOUT</code> (but always at least 2 seconds), the election is aborted and a new one will be tried again after <code>NODE_TIMEOUT * 4</code> (and always at least 4 seconds).</p>\n<h3>Replica rank</h3>\n<p>As soon as a primary is in <code>FAIL</code> state, a replica waits a short period of time before trying to get elected. That delay is computed as follows:</p>\n<pre><code>DELAY = 500 milliseconds + random delay between 0 and 500 milliseconds +\n        REPLICA_RANK * 1000 milliseconds.\n</code></pre>\n<p>The fixed delay ensures that we wait for the <code>FAIL</code> state to propagate across the cluster, otherwise the replica may try to get elected while the primaries are still unaware of the <code>FAIL</code> state, refusing to grant their vote.</p>\n<p>The random delay is used to desynchronize replicas so they&#39;re unlikely to start an election at the same time.</p>\n<p>The <code>REPLICA_RANK</code> is the rank of this replica regarding the amount of replication data it has processed from the primary.<br>Replicas exchange messages when the primary is failing in order to establish a (best effort) rank:<br>the replica with the most updated replication offset is at rank 0, the second most updated at rank 1, and so forth.<br>In this way the most updated replicas try to get elected before others.</p>\n<p>Rank order is not strictly enforced; if a replica of higher rank fails to be<br>elected, the others will try shortly.</p>\n<p>Once a replica wins the election, it obtains a new unique and incremental <code>configEpoch</code> which is higher than that of any other existing primary. It starts advertising itself as primary in ping and pong packets, providing the set of served slots with a <code>configEpoch</code> that will win over the past ones.</p>\n<p>In order to speedup the reconfiguration of other nodes, a pong packet is broadcast to all the nodes of the cluster. Currently unreachable nodes will eventually be reconfigured when they receive a ping or pong packet from another node or will receive an <code>UPDATE</code> packet from another node if the information it publishes via heartbeat packets are detected to be out of date.</p>\n<p>The other nodes will detect that there is a new primary serving the same slots served by the old primary but with a greater <code>configEpoch</code>, and will upgrade their configuration. Replicas of the old primary (or the failed over primary if it rejoins the cluster) will not just upgrade the configuration but will also reconfigure to replicate from the new primary. How nodes rejoining the cluster are configured is explained in the next sections.</p>\n<h3>Masters reply to replica vote request</h3>\n<p>In the previous section, we discussed how replicas try to get elected. This section explains what happens from the point of view of a primary that is requested to vote for a given replica.</p>\n<p>Masters receive requests for votes in form of <code>FAILOVER_AUTH_REQUEST</code> requests from replicas.</p>\n<p>For a vote to be granted the following conditions need to be met:</p>\n<ol>\n<li>A primary only votes a single time for a given epoch, and refuses to vote for older epochs: every primary has a lastVoteEpoch field and will refuse to vote again as long as the <code>currentEpoch</code> in the auth request packet is not greater than the lastVoteEpoch. When a primary replies positively to a vote request, the lastVoteEpoch is updated accordingly, and safely stored on disk.</li>\n<li>A primary votes for a replica only if the replica&#39;s primary is flagged as <code>FAIL</code>.</li>\n<li>Auth requests with a <code>currentEpoch</code> that is less than the primary <code>currentEpoch</code> are ignored. Because of this the primary reply will always have the same <code>currentEpoch</code> as the auth request. If the same replica asks again to be voted, incrementing the <code>currentEpoch</code>, it is guaranteed that an old delayed reply from the primary can not be accepted for the new vote.</li>\n</ol>\n<p>Example of the issue caused by not using rule number 3:</p>\n<p>Primary <code>currentEpoch</code> is 5, lastVoteEpoch is 1 (this may happen after a few failed elections)</p>\n<ul>\n<li>Replica <code>currentEpoch</code> is 3.</li>\n<li>Replica tries to be elected with epoch 4 (3+1), primary replies with an ok with <code>currentEpoch</code> 5, however the reply is delayed.</li>\n<li>Replica will try to be elected again, at a later time, with epoch 5 (4+1), the delayed reply reaches the replica with <code>currentEpoch</code> 5, and is accepted as valid.</li>\n</ul>\n<ol start=\"4\">\n<li>Primaries don&#39;t vote for a replica of the same primary before <code>NODE_TIMEOUT * 2</code> has elapsed if a replica of that primary was already voted for. This is not strictly required as it is not possible for two replicas to win the election in the same epoch. However, in practical terms it ensures that when a replica is elected it has plenty of time to inform the other replicas and avoid the possibility that another replica will win a new election, performing an unnecessary second failover.</li>\n<li>Primaries make no effort to select the best replica in any way. If the replica&#39;s primary is in <code>FAIL</code> state and the primary did not vote in the current term, a positive vote is granted. The best replica is the most likely to start an election and win it before the other replicas, since it will usually be able to start the voting process earlier because of its <em>higher rank</em> as explained in the previous section.</li>\n<li>When a primary refuses to vote for a given replica there is no negative response, the request is simply ignored.</li>\n<li>Primaries don&#39;t vote for replicas sending a <code>configEpoch</code> that is less than any <code>configEpoch</code> in the primary table for the slots claimed by the replica. Remember that the replica sends the <code>configEpoch</code> of its primary, and the bitmap of the slots served by its primary. This means that the replica requesting the vote must have a configuration for the slots it wants to failover that is newer or equal the one of the primary granting the vote.</li>\n</ol>\n<h3>Practical example of configuration epoch usefulness during partitions</h3>\n<p>This section illustrates how the epoch concept is used to make the replica promotion process more resistant to partitions.</p>\n<ul>\n<li>A primary is no longer reachable indefinitely. The primary has three replicas A, B, C.</li>\n<li>Replica A wins the election and is promoted to primary.</li>\n<li>A network partition makes A not available for the majority of the cluster.</li>\n<li>Replica B wins the election and is promoted as primary.</li>\n<li>A partition makes B not available for the majority of the cluster.</li>\n<li>The previous partition is fixed, and A is available again.</li>\n</ul>\n<p>At this point B is down and A is available again with a role of primary (actually <code>UPDATE</code> messages would reconfigure it promptly, but here we assume all <code>UPDATE</code> messages were lost). At the same time, replica C will try to get elected in order to fail over B. This is what happens:</p>\n<ol>\n<li>C will try to get elected and will succeed, since for the majority of primaries its primary is actually down. It will obtain a new incremental <code>configEpoch</code>.</li>\n<li>A will not be able to claim to be the primary for its hash slots, because the other nodes already have the same hash slots associated with a higher configuration epoch (the one of B) compared to the one published by A.</li>\n<li>So, all the nodes will upgrade their table to assign the hash slots to C, and the cluster will continue its operations.</li>\n</ol>\n<p>As you&#39;ll see in the next sections, a stale node rejoining a cluster<br>will usually get notified as soon as possible about the configuration change<br>because as soon as it pings any other node, the receiver will detect it<br>has stale information and will send an <code>UPDATE</code> message.</p>\n<h3>Hash slots configuration propagation</h3>\n<p>An important part of Valkey Cluster is the mechanism used to propagate the information about which cluster node is serving a given set of hash slots. This is vital to both the startup of a fresh cluster and the ability to upgrade the configuration after a replica was promoted to serve the slots of its failing primary.</p>\n<p>The same mechanism allows nodes partitioned away for an indefinite amount of<br>time to rejoin the cluster in a sensible way.</p>\n<p>There are two ways hash slot configurations are propagated:</p>\n<ol>\n<li>Heartbeat messages. The sender of a ping or pong packet always adds information about the set of hash slots it (or its primary, if it is a replica) serves.</li>\n<li><code>UPDATE</code> messages. Since in every heartbeat packet there is information about the sender <code>configEpoch</code> and set of hash slots served, if a receiver of a heartbeat packet finds the sender information is stale, it will send a packet with new information, forcing the stale node to update its info.</li>\n</ol>\n<p>The receiver of a heartbeat or <code>UPDATE</code> message uses certain simple rules in<br>order to update its table mapping hash slots to nodes. When a new Valkey Cluster node is created, its local hash slot table is simply initialized to <code>NULL</code> entries so that each hash slot is not bound or linked to any node. This looks similar to the following:</p>\n<pre><code>0 -&gt; NULL\n1 -&gt; NULL\n2 -&gt; NULL\n...\n16383 -&gt; NULL\n</code></pre>\n<p>The first rule followed by a node in order to update its hash slot table is the following:</p>\n<p><strong>Rule 1</strong>: If a hash slot is unassigned (set to <code>NULL</code>), and a known node claims it, I&#39;ll modify my hash slot table and associate the claimed hash slots to it.</p>\n<p>So if we receive a heartbeat from node A claiming to serve hash slots 1 and 2 with a configuration epoch value of 3, the table will be modified to:</p>\n<pre><code>0 -&gt; NULL\n1 -&gt; A [3]\n2 -&gt; A [3]\n...\n16383 -&gt; NULL\n</code></pre>\n<p>When a new cluster is created, a system administrator needs to manually assign (using the <code>CLUSTER ADDSLOTS</code> command, via the valkey-cli command line tool, or by any other means) the slots served by each primary node only to the node itself, and the information will rapidly propagate across the cluster.</p>\n<p>However this rule is not enough. We know that hash slot mapping can change<br>during two events:</p>\n<ol>\n<li>A replica replaces its primary during a failover.</li>\n<li>A slot is resharded from a node to a different one.</li>\n</ol>\n<p>For now let&#39;s focus on failovers. When a replica fails over its primary, it obtains<br>a configuration epoch which is guaranteed to be greater than the one of its<br>primary (and more generally greater than any other configuration epoch<br>generated previously). For example node B, which is a replica of A, may failover<br>A with configuration epoch of 4. It will start to send heartbeat packets<br>(the first time mass-broadcasting cluster-wide) and because of the following<br>second rule, receivers will update their hash slot tables:</p>\n<p><strong>Rule 2</strong>: If a hash slot is already assigned, and a known node is advertising it using a <code>configEpoch</code> that is greater than the <code>configEpoch</code> of the primary currently associated with the slot, it&#39;ll rebind the hash slot to the new node.</p>\n<p>So after receiving messages from B that claim to serve hash slots 1 and 2 with configuration epoch of 4, the receivers will update their table in the following way:</p>\n<pre><code>0 -&gt; NULL\n1 -&gt; B [4]\n2 -&gt; B [4]\n...\n16383 -&gt; NULL\n</code></pre>\n<p>Liveness property: because of the second rule, eventually all nodes in the cluster will agree that the owner of a slot is the one with the greatest <code>configEpoch</code> among the nodes advertising it.</p>\n<p>This mechanism in Valkey Cluster is called <strong>last failover wins</strong>.</p>\n<p>The same happens during resharding. When a node importing a hash slot completes<br>the import operation, its configuration epoch is incremented to make sure the<br>change will be propagated throughout the cluster.</p>\n<h3>UPDATE messages, a closer look</h3>\n<p>With the previous section in mind, it is easier to see how update messages<br>work. Node A may rejoin the cluster after some time. It will send heartbeat<br>packets where it claims it serves hash slots 1 and 2 with configuration epoch<br>of 3. All the receivers with updated information will instead see that<br>the same hash slots are associated with node B having a higher configuration<br>epoch. Because of this they&#39;ll send an <code>UPDATE</code> message to A with the new<br>configuration for the slots. A will update its configuration because of the<br><strong>rule 2</strong> above.</p>\n<h3>How nodes rejoin the cluster</h3>\n<p>The same basic mechanism is used when a node rejoins a cluster.<br>Continuing with the example above, node A will be notified<br>that hash slots 1 and 2 are now served by B. Assuming that these two were<br>the only hash slots served by A, the count of hash slots served by A will<br>drop to 0! So A will <strong>reconfigure to be a replica of the new primary</strong>.</p>\n<p>The actual rule followed is a bit more complex than this. In general it may<br>happen that A rejoins after a lot of time, in the meantime it may happen that<br>hash slots originally served by A are served by multiple nodes, for example<br>hash slot 1 may be served by B, and hash slot 2 by C.</p>\n<p>So the actual <em>Valkey Cluster node role switch rule</em> is: <strong>A primary node will change its configuration to replicate (be a replica of) the node that stole its last hash slot</strong>.</p>\n<p>During reconfiguration, eventually the number of served hash slots will drop to zero, and the node will reconfigure accordingly. Note that in the base case this just means that the old primary will be a replica of the replica that replaced it after a failover. However in the general form the rule covers all possible cases.</p>\n<p>Replicas do exactly the same: they reconfigure to replicate the node that<br>stole the last hash slot of its former primary.</p>\n<h3>Replica migration</h3>\n<p>Valkey Cluster implements a concept called <em>replica migration</em> in order to<br>improve the availability of the system. The idea is that in a cluster with<br>a primary-replica setup, if the map between replicas and primaries is fixed<br>availability is limited over time if multiple independent failures of single<br>nodes happen.</p>\n<p>For example in a cluster where every primary has a single replica, the cluster<br>can continue operations as long as either the primary or the replica fail, but not<br>if both fail the same time. However there is a class of failures that are<br>the independent failures of single nodes caused by hardware or software issues<br>that can accumulate over time. For example:</p>\n<ul>\n<li>Master A has a single replica A1.</li>\n<li>Master A fails. A1 is promoted as new primary.</li>\n<li>Three hours later A1 fails in an independent manner (unrelated to the failure of A). No other replica is available for promotion since node A is still down. The cluster cannot continue normal operations.</li>\n</ul>\n<p>If the map between primaries and replicas is fixed, the only way to make the cluster<br>more resistant to the above scenario is to add replicas to every primary, however<br>this is costly as it requires more instances of Valkey to be executed, more<br>memory, and so forth.</p>\n<p>An alternative is to create an asymmetry in the cluster, and let the cluster<br>layout automatically change over time. For example the cluster may have three<br>primaries A, B, C. A and B have a single replica each, A1 and B1. However, the primary<br>C is different and has two replicas: C1 and C2.</p>\n<p>Replica migration is the process of automatic reconfiguration of a replica<br>in order to <em>migrate</em> to a primary that has no longer coverage (no working<br>replicas). With replica migration the scenario mentioned above turns into the<br>following:</p>\n<ul>\n<li>Master A fails. A1 is promoted.</li>\n<li>C2 migrates as replica of A1, that is otherwise not backed by any replica.</li>\n<li>Three hours later A1 fails as well.</li>\n<li>C2 is promoted as a new primary to replace A1.</li>\n<li>The cluster can continue the operations.</li>\n</ul>\n<h3>Replica migration algorithm</h3>\n<p>The migration algorithm does not use any form of agreement since the replica<br>layout in a Valkey Cluster is not part of the cluster configuration that needs<br>to be consistent and/or versioned with config epochs. Instead it uses an<br>algorithm to avoid mass-migration of replicas when a primary is not backed.<br>The algorithm guarantees that eventually (once the cluster configuration is<br>stable) every primary will be backed by at least one replica.</p>\n<p>This is how the algorithm works. To start we need to define what is a<br><em>good replica</em> in this context: a good replica is a replica not in <code>FAIL</code> state<br>from the point of view of a given node.</p>\n<p>The execution of the algorithm is triggered in every replica that detects that<br>there is at least a single primary without good replicas. However among all the<br>replicas detecting this condition, only a subset should act. This subset is<br>actually often a single replica unless different replicas have in a given moment<br>a slightly different view of the failure state of other nodes.</p>\n<p>The <em>acting replica</em> is the replica among the primaries with the maximum number<br>of attached replicas, that is not in FAIL state and has the smallest node ID.</p>\n<p>So for example if there are 10 primaries with 1 replica each, and 2 primaries with<br>5 replicas each, the replica that will try to migrate is - among the 2 primaries<br>having 5 replicas - the one with the lowest node ID. Given that no agreement<br>is used, it is possible that when the cluster configuration is not stable,<br>a race condition occurs where multiple replicas believe themselves to be<br>the non-failing replica with the lower node ID (it is unlikely for this to happen<br>in practice). If this happens, the result is multiple replicas migrating to the<br>same primary, which is harmless. If the race happens in a way that will leave<br>the ceding primary without replicas, as soon as the cluster is stable again<br>the algorithm will be re-executed again and will migrate a replica back to<br>the original primary.</p>\n<p>Eventually every primary will be backed by at least one replica. However,<br>the normal behavior is that a single replica migrates from a primary with<br>multiple replicas to an orphaned primary.</p>\n<p>The algorithm is controlled by a user-configurable parameter called<br><code>cluster-migration-barrier</code>: the number of good replicas a primary<br>must be left with before a replica can migrate away. For example, if this<br>parameter is set to 2, a replica can try to migrate only if its primary remains<br>with two working replicas.</p>\n<h3>configEpoch conflicts resolution algorithm</h3>\n<p>When new <code>configEpoch</code> values are created via replica promotion during<br>failovers, they are guaranteed to be unique.</p>\n<p>However there are two distinct events where new configEpoch values are<br>created in an unsafe way, just incrementing the local <code>currentEpoch</code> of<br>the local node and hoping there are no conflicts at the same time.<br>Both the events are system-administrator triggered:</p>\n<ol>\n<li><code>CLUSTER FAILOVER</code> command with <code>TAKEOVER</code> option is able to manually promote a replica node into a primary <em>without the majority of primaries being available</em>. This is useful, for example, in multi data center setups.</li>\n<li>Migration of slots for cluster rebalancing also generates new configuration epochs inside the local node without agreement for performance reasons.</li>\n</ol>\n<p>Specifically, during manual resharding, when a hash slot is migrated from<br>a node A to a node B, the resharding program will force B to upgrade<br>its configuration to an epoch which is the greatest found in the cluster,<br>plus 1 (unless the node is already the one with the greatest configuration<br>epoch), without requiring agreement from other nodes.<br>Usually a real world resharding involves moving several hundred hash slots<br>(especially in small clusters). Requiring an agreement to generate new<br>configuration epochs during resharding, for each hash slot moved, is<br>inefficient. Moreover it requires a fsync in each of the cluster nodes<br>every time in order to store the new configuration. Because of the way it is<br>performed instead, we only need a new config epoch when the first hash slot is moved,<br>making it much more efficient in production environments.</p>\n<p>However because of the two cases above, it is possible (though unlikely) to end<br>with multiple nodes having the same configuration epoch. A resharding operation<br>performed by the system administrator, and a failover happening at the same<br>time (plus a lot of bad luck) could cause <code>currentEpoch</code> collisions if<br>they are not propagated fast enough.</p>\n<p>Moreover, software bugs and filesystem corruptions can also contribute<br>to multiple nodes having the same configuration epoch.</p>\n<p>When primaries serving different hash slots have the same <code>configEpoch</code>, there<br>are no issues. It is more important that replicas failing over a primary have<br>unique configuration epochs.</p>\n<p>That said, manual interventions or resharding may change the cluster<br>configuration in different ways. The Valkey Cluster main liveness property<br>requires that slot configurations always converge, so under every circumstance<br>we really want all the primary nodes to have a different <code>configEpoch</code>.</p>\n<p>In order to enforce this, <strong>a conflict resolution algorithm</strong> is used in the<br>event that two nodes end up with the same <code>configEpoch</code>.</p>\n<ul>\n<li>IF a primary node detects another primary node is advertising itself with<br>the same <code>configEpoch</code>.</li>\n<li>AND IF the node has a lexicographically smaller Node ID compared to the other node claiming the same <code>configEpoch</code>.</li>\n<li>THEN it increments its <code>currentEpoch</code> by 1, and uses it as the new <code>configEpoch</code>.</li>\n</ul>\n<p>If there are any set of nodes with the same <code>configEpoch</code>, all the nodes but the one with the greatest Node ID will move forward, guaranteeing that, eventually, every node will pick a unique configEpoch regardless of what happened.</p>\n<p>This mechanism also guarantees that after a fresh cluster is created, all<br>nodes start with a different <code>configEpoch</code> (even if this is not actually<br>used) since <code>valkey-cli</code> makes sure to use <code>CLUSTER SET-CONFIG-EPOCH</code> at startup.<br>However if for some reason a node is left misconfigured, it will update<br>its configuration to a different configuration epoch automatically.</p>\n<h3>Node resets</h3>\n<p>Nodes can be software reset (without restarting them) in order to be reused<br>in a different role or in a different cluster. This is useful in normal<br>operations, in testing, and in cloud environments where a given node can<br>be reprovisioned to join a different set of nodes to enlarge or create a new<br>cluster.</p>\n<p>In Valkey Cluster nodes are reset using the <code>CLUSTER RESET</code> command. The<br>command is provided in two variants:</p>\n<ul>\n<li><code>CLUSTER RESET SOFT</code></li>\n<li><code>CLUSTER RESET HARD</code></li>\n</ul>\n<p>The command must be sent directly to the node to reset. If no reset type is<br>provided, a soft reset is performed.</p>\n<p>The following is a list of operations performed by a reset:</p>\n<ol>\n<li>Soft and hard reset: If the node is a replica, it is turned into a primary, and its dataset is discarded. If the node is a primary and contains keys the reset operation is aborted.</li>\n<li>Soft and hard reset: All the slots are released, and the manual failover state is reset.</li>\n<li>Soft and hard reset: All the other nodes in the nodes table are removed, so the node no longer knows any other node.</li>\n<li>Hard reset only: <code>currentEpoch</code>, <code>configEpoch</code>, and <code>lastVoteEpoch</code> are set to 0.</li>\n<li>Hard reset only: the Node ID is changed to a new random ID.</li>\n</ol>\n<p>Master nodes with non-empty data sets can&#39;t be reset (since normally you want to reshard data to the other nodes). However, under special conditions when this is appropriate (e.g. when a cluster is totally destroyed with the intent of creating a new one), <code>FLUSHALL</code> must be executed before proceeding with the reset.</p>\n<h3>Removing nodes from a cluster</h3>\n<p>It is possible to practically remove a node from an existing cluster by<br>resharding all its data to other nodes (if it is a primary node) and<br>shutting it down. However, the other nodes will still remember its node<br>ID and address, and will attempt to connect with it.</p>\n<p>For this reason, when a node is removed we want to also remove its entry<br>from all the other nodes tables. This is accomplished by using the<br><code>CLUSTER FORGET &lt;node-id&gt;</code> command.</p>\n<p>The command does two things:</p>\n<ol>\n<li>It removes the node with the specified node ID from the nodes table.</li>\n<li>It sets a 60 second ban which prevents a node with the same node ID from being re-added.</li>\n</ol>\n<p>The second operation is needed because Valkey Cluster uses gossip in order to auto-discover nodes, so removing the node X from node A, could result in node B gossiping about node X to A again. Because of the 60 second ban, the Valkey Cluster administration tools have 60 seconds in order to remove the node from all the nodes, preventing the re-addition of the node due to auto discovery.</p>\n<p>Further information is available in the <code>CLUSTER FORGET</code> documentation.</p>\n<h2>Publish/Subscribe</h2>\n<p>In a Valkey Cluster, clients can subscribe to every node, and can also<br>publish to every other node. The cluster will make sure that published<br>messages are forwarded as needed.</p>\n<p>The clients can send SUBSCRIBE to any node and can also send PUBLISH to any node.<br>It will simply broadcast each published message to all other nodes.</p>\n<p>Redis OSS 7.0 and later features sharded pub/sub, in which shard channels are assigned to slots by the same algorithm used to assign keys to slots.<br>A shard message must be sent to a node that owns the slot the shard channel is hashed to.<br>The cluster makes sure the published shard messages are forwarded to all nodes in the shard, so clients can subscribe to a shard channel by connecting to either the primary responsible for the slot, or to any of its replicas.</p>\n<h2>Appendix</h2>\n<h3>Appendix A: CRC16 reference implementation in ANSI C</h3>\n<pre><code>/*\n * Copyright 2001-2010 Georges Menie (www.menie.org)\n * Copyright 2010 Salvatore Sanfilippo (adapted to Redis coding style)\n * All rights reserved.\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n *     * Redistributions of source code must retain the above copyright\n *       notice, this list of conditions and the following disclaimer.\n *     * Redistributions in binary form must reproduce the above copyright\n *       notice, this list of conditions and the following disclaimer in the\n *       documentation and/or other materials provided with the distribution.\n *     * Neither the name of the University of California, Berkeley nor the\n *       names of its contributors may be used to endorse or promote products\n *       derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS&#39;&#39; AND ANY\n * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n * DISCLAIMED. IN NO EVENT SHALL THE REGENTS AND CONTRIBUTORS BE LIABLE FOR ANY\n * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\n * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n/* CRC16 implementation according to CCITT standards.\n *\n * Note by @antirez: this is actually the XMODEM CRC 16 algorithm, using the\n * following parameters:\n *\n * Name                       : &quot;XMODEM&quot;, also known as &quot;ZMODEM&quot;, &quot;CRC-16/ACORN&quot;\n * Width                      : 16 bit\n * Poly                       : 1021 (That is actually x^16 + x^12 + x^5 + 1)\n * Initialization             : 0000\n * Reflect Input byte         : False\n * Reflect Output CRC         : False\n * Xor constant to output CRC : 0000\n * Output for &quot;123456789&quot;     : 31C3\n */\n\nstatic const uint16_t crc16tab[256]= {\n    0x0000,0x1021,0x2042,0x3063,0x4084,0x50a5,0x60c6,0x70e7,\n    0x8108,0x9129,0xa14a,0xb16b,0xc18c,0xd1ad,0xe1ce,0xf1ef,\n    0x1231,0x0210,0x3273,0x2252,0x52b5,0x4294,0x72f7,0x62d6,\n    0x9339,0x8318,0xb37b,0xa35a,0xd3bd,0xc39c,0xf3ff,0xe3de,\n    0x2462,0x3443,0x0420,0x1401,0x64e6,0x74c7,0x44a4,0x5485,\n    0xa56a,0xb54b,0x8528,0x9509,0xe5ee,0xf5cf,0xc5ac,0xd58d,\n    0x3653,0x2672,0x1611,0x0630,0x76d7,0x66f6,0x5695,0x46b4,\n    0xb75b,0xa77a,0x9719,0x8738,0xf7df,0xe7fe,0xd79d,0xc7bc,\n    0x48c4,0x58e5,0x6886,0x78a7,0x0840,0x1861,0x2802,0x3823,\n    0xc9cc,0xd9ed,0xe98e,0xf9af,0x8948,0x9969,0xa90a,0xb92b,\n    0x5af5,0x4ad4,0x7ab7,0x6a96,0x1a71,0x0a50,0x3a33,0x2a12,\n    0xdbfd,0xcbdc,0xfbbf,0xeb9e,0x9b79,0x8b58,0xbb3b,0xab1a,\n    0x6ca6,0x7c87,0x4ce4,0x5cc5,0x2c22,0x3c03,0x0c60,0x1c41,\n    0xedae,0xfd8f,0xcdec,0xddcd,0xad2a,0xbd0b,0x8d68,0x9d49,\n    0x7e97,0x6eb6,0x5ed5,0x4ef4,0x3e13,0x2e32,0x1e51,0x0e70,\n    0xff9f,0xefbe,0xdfdd,0xcffc,0xbf1b,0xaf3a,0x9f59,0x8f78,\n    0x9188,0x81a9,0xb1ca,0xa1eb,0xd10c,0xc12d,0xf14e,0xe16f,\n    0x1080,0x00a1,0x30c2,0x20e3,0x5004,0x4025,0x7046,0x6067,\n    0x83b9,0x9398,0xa3fb,0xb3da,0xc33d,0xd31c,0xe37f,0xf35e,\n    0x02b1,0x1290,0x22f3,0x32d2,0x4235,0x5214,0x6277,0x7256,\n    0xb5ea,0xa5cb,0x95a8,0x8589,0xf56e,0xe54f,0xd52c,0xc50d,\n    0x34e2,0x24c3,0x14a0,0x0481,0x7466,0x6447,0x5424,0x4405,\n    0xa7db,0xb7fa,0x8799,0x97b8,0xe75f,0xf77e,0xc71d,0xd73c,\n    0x26d3,0x36f2,0x0691,0x16b0,0x6657,0x7676,0x4615,0x5634,\n    0xd94c,0xc96d,0xf90e,0xe92f,0x99c8,0x89e9,0xb98a,0xa9ab,\n    0x5844,0x4865,0x7806,0x6827,0x18c0,0x08e1,0x3882,0x28a3,\n    0xcb7d,0xdb5c,0xeb3f,0xfb1e,0x8bf9,0x9bd8,0xabbb,0xbb9a,\n    0x4a75,0x5a54,0x6a37,0x7a16,0x0af1,0x1ad0,0x2ab3,0x3a92,\n    0xfd2e,0xed0f,0xdd6c,0xcd4d,0xbdaa,0xad8b,0x9de8,0x8dc9,\n    0x7c26,0x6c07,0x5c64,0x4c45,0x3ca2,0x2c83,0x1ce0,0x0cc1,\n    0xef1f,0xff3e,0xcf5d,0xdf7c,0xaf9b,0xbfba,0x8fd9,0x9ff8,\n    0x6e17,0x7e36,0x4e55,0x5e74,0x2e93,0x3eb2,0x0ed1,0x1ef0\n};\n\nuint16_t crc16(const char *buf, int len) {\n    int counter;\n    uint16_t crc = 0;\n    for (counter = 0; counter &lt; len; counter++)\n            crc = (crc&lt;&lt;8) ^ crc16tab[((crc&gt;&gt;8) ^ *buf++)&amp;0x00FF];\n    return crc;\n}\n</code></pre>\n"
  },
  {
    "id": "cluster-tutorial",
    "topicName": "Cluster tutorial",
    "description": "Horizontal scaling with Valkey Cluster",
    "htmlContent": "<p>Valkey scales horizontally with a deployment topology called Valkey Cluster.<br>This topic will teach you how to set up, test, and operate Valkey Cluster in production.<br>You will learn about the availability and consistency characteristics of Valkey Cluster from the end user&#39;s point of view.</p>\n<p>If you plan to run a production Valkey Cluster deployment or want to understand better how Valkey Cluster works internally, consult the <a href=\"cluster-spec\">Valkey Cluster specification</a>.</p>\n<h2>Valkey Cluster 101</h2>\n<p>Valkey Cluster provides a way to run a Valkey installation where data is automatically sharded across multiple Valkey nodes.<br>Valkey Cluster also provides some degree of availability during partitions&mdash;in practical terms, the ability to continue operations when some nodes fail or are unable to communicate.<br>However, the cluster will become unavailable in the event of larger failures (for example, when the majority of primaries are unavailable).</p>\n<p>So, with Valkey Cluster, you get the ability to:</p>\n<ul>\n<li>Automatically split your dataset among multiple nodes.</li>\n<li>Continue operations when a subset of the nodes are experiencing failures or are unable to communicate with the rest of the cluster.</li>\n</ul>\n<h4>Valkey Cluster TCP ports</h4>\n<p>Every Valkey Cluster node requires two open TCP connections: a Valkey TCP port used to serve clients, e.g., 6379, and second port known as the <em>cluster bus port</em>.<br>By default, the cluster bus port is set by adding 10000 to the data port (e.g., 16379); however, you can override this in the <code>cluster-port</code> configuration.</p>\n<p>Cluster bus is a node-to-node communication channel that uses a binary protocol, which is more suited to exchanging information between nodes due to<br>little bandwidth and processing time.<br>Nodes use the cluster bus for failure detection, configuration updates, failover authorization, and so forth.<br>Clients should never try to communicate with the cluster bus port, but rather use the Valkey command port.<br>However, make sure you open both ports in your firewall, otherwise Valkey cluster nodes won&#39;t be able to communicate.</p>\n<p>For a Valkey Cluster to work properly you need, for each node:</p>\n<ol>\n<li>The client communication port (usually 6379) used to communicate with clients and be open to all the clients that need to reach the cluster, plus all the other cluster nodes that use the client port for key migrations.</li>\n<li>The cluster bus port must be reachable from all the other cluster nodes.</li>\n</ol>\n<p>If you don&#39;t open both TCP ports, your cluster will not work as expected.</p>\n<h4>Valkey Cluster and Docker</h4>\n<p>Currently, Valkey Cluster does not support NATted environments and in general<br>environments where IP addresses or TCP ports are remapped.</p>\n<p>Docker uses a technique called <em>port mapping</em>: programs running inside Docker containers may be exposed with a different port compared to the one the program believes to be using.<br>This is useful for running multiple containers using the same ports, at the same time, in the same server.</p>\n<p>To make Docker compatible with Valkey Cluster, you need to use Docker&#39;s <em>host networking mode</em>.<br>Please see the <code>--net=host</code> option in the <a href=\"https://docs.docker.com/engine/userguide/networking/dockernetworks/\">Docker documentation</a> for more information.</p>\n<h4>Valkey Cluster data sharding</h4>\n<p>Valkey Cluster does not use consistent hashing, but a different form of sharding<br>where every key is conceptually part of what we call a <strong>hash slot</strong>.</p>\n<p>There are 16384 hash slots in Valkey Cluster, and to compute the hash<br>slot for a given key, we simply take the CRC16 of the key modulo<br>16384.</p>\n<p>Every node in a Valkey Cluster is responsible for a subset of the hash slots,<br>so, for example, you may have a cluster with 3 nodes, where:</p>\n<ul>\n<li>Node A contains hash slots from 0 to 5500.</li>\n<li>Node B contains hash slots from 5501 to 11000.</li>\n<li>Node C contains hash slots from 11001 to 16383.</li>\n</ul>\n<p>This makes it easy to add and remove cluster nodes. For example, if<br>I want to add a new node D, I need to move some hash slots from nodes A, B, C<br>to D. Similarly, if I want to remove node A from the cluster, I can just<br>move the hash slots served by A to B and C. Once node A is empty,<br>I can remove it from the cluster completely.</p>\n<p>Moving hash slots from a node to another does not require stopping<br>any operations; therefore, adding and removing nodes, or changing the percentage of hash slots held by a node, requires no downtime.</p>\n<p>Valkey Cluster supports multiple key operations as long as all of the keys involved in a single command execution (or whole transaction, or Lua script<br>execution) belong to the same hash slot. The user can force multiple keys<br>to be part of the same hash slot by using a feature called <em>hash tags</em>.</p>\n<p>Hash tags are documented in the Valkey Cluster specification, but the gist is<br>that if there is a substring between {} brackets in a key, only what is<br>inside the string is hashed. For example, the keys <code>user:{123}:profile</code> and <code>user:{123}:account</code> are guaranteed to be in the same hash slot because they share the same hash tag. As a result, you can operate on these two keys in the same multi-key operation.</p>\n<h4>Valkey Cluster primary-replica model</h4>\n<p>To remain available when a subset of primary nodes are failing or are<br>not able to communicate with the majority of nodes, Valkey Cluster uses a<br>primary-replica model where every hash slot has from 1 (the primary itself) to N<br>replicas (N-1 additional replica nodes).</p>\n<p>In our example cluster with nodes A, B, C, if node B fails the cluster is not<br>able to continue, since we no longer have a way to serve hash slots in the<br>range 5501-11000.</p>\n<p>However, when the cluster is created (or at a later time), we add a replica<br>node to every primary, so that the final cluster is composed of A, B, C<br>that are primary nodes, and A1, B1, C1 that are replica nodes.<br>This way, the system can continue if node B fails.</p>\n<p>Node B1 replicates B, and B fails, the cluster will promote node B1 as the new<br>primary and will continue to operate correctly.</p>\n<p>However, note that if nodes B and B1 fail at the same time, Valkey Cluster will not be able to continue to operate.</p>\n<h4>Valkey Cluster consistency guarantees</h4>\n<p>Valkey Cluster does not guarantee <strong>strong consistency</strong>. In practical<br>terms this means that under certain conditions it is possible that Valkey<br>Cluster will lose writes that were acknowledged by the system to the client.</p>\n<p>The first reason why Valkey Cluster can lose writes is because it uses<br>asynchronous replication. This means that during writes the following<br>happens:</p>\n<ul>\n<li>Your client writes to the primary B.</li>\n<li>The primary B replies OK to your client.</li>\n<li>The primary B propagates the write to its replicas B1, B2 and B3.</li>\n</ul>\n<p>As you can see, B does not wait for an acknowledgement from B1, B2, B3 before<br>replying to the client, since this would be a prohibitive latency penalty<br>for Valkey, so if your client writes something, B acknowledges the write,<br>but crashes before being able to send the write to its replicas, one of the<br>replicas (that did not receive the write) can be promoted to primary, losing<br>the write forever.</p>\n<p>This is very similar to what happens with most databases that are<br>configured to flush data to disk every second, so it is a scenario you<br>are already able to reason about because of past experiences with traditional<br>database systems not involving distributed systems. Similarly you can<br>improve consistency by forcing the database to flush data to disk before<br>replying to the client, but this usually results in prohibitively low<br>performance. That would be the equivalent of synchronous replication in<br>the case of Valkey Cluster.</p>\n<p>Basically, there is a trade-off to be made between performance and consistency.</p>\n<p>Valkey Cluster has support for synchronous writes when absolutely needed,<br>implemented via the <code>WAIT</code> command. This makes losing writes a lot less<br>likely. However, note that Valkey Cluster does not implement strong consistency<br>even when synchronous replication is used: it is always possible, under more<br>complex failure scenarios, that a replica that was not able to receive the write<br>will be elected as primary.</p>\n<p>There is another notable scenario where Valkey Cluster will lose writes, that<br>happens during a network partition where a client is isolated with a minority<br>of instances including at least a primary.</p>\n<p>Take as an example our 6 nodes cluster composed of A, B, C, A1, B1, C1,<br>with 3 primaries and 3 replicas. There is also a client, that we will call Z1.</p>\n<p>After a partition occurs, it is possible that in one side of the<br>partition we have A, C, A1, B1, C1, and in the other side we have B and Z1.</p>\n<p>Z1 is still able to write to B, which will accept its writes. If the<br>partition heals in a very short time, the cluster will continue normally.<br>However, if the partition lasts enough time for B1 to be promoted to primary<br>on the majority side of the partition, the writes that Z1 has sent to B<br>in the meantime will be lost.</p>\n<p><strong>Note:</strong><br>There is a <strong>maximum window</strong> to the amount of writes Z1 will be able<br>to send to B: if enough time has elapsed for the majority side of the<br>partition to elect a replica as primary, every primary node in the minority<br>side will have stopped accepting writes.</p>\n<p>This amount of time is a very important configuration directive of Valkey<br>Cluster, and is called the <strong>node timeout</strong>.</p>\n<p>After node timeout has elapsed, a primary node is considered to be failing,<br>and can be replaced by one of its replicas.<br>Similarly, after node timeout has elapsed without a primary node to be able<br>to sense the majority of the other primary nodes, it enters an error state<br>and stops accepting writes.</p>\n<h2>Valkey Cluster configuration parameters</h2>\n<p>We are about to create an example cluster deployment.<br>Before we continue, let&#39;s introduce the configuration parameters that Valkey Cluster introduces<br>in the <code>valkey.conf</code> file.</p>\n<ul>\n<li><strong>cluster-enabled <code>&lt;yes/no&gt;</code></strong>: If yes, enables Valkey Cluster support in a specific Valkey instance. Otherwise the instance starts as a standalone instance as usual.</li>\n<li><strong>cluster-config-file <code>&lt;filename&gt;</code></strong>: Note that despite the name of this option, this is not a user editable configuration file, but the file where a Valkey Cluster node automatically persists the cluster configuration (the state, basically) every time there is a change, in order to be able to re-read it at startup. The file lists things like the other nodes in the cluster, their state, persistent variables, and so forth. Often this file is rewritten and flushed on disk as a result of some message reception.</li>\n<li><strong>cluster-node-timeout <code>&lt;milliseconds&gt;</code></strong>: The maximum amount of time a Valkey Cluster node can be unavailable, without it being considered as failing. If a primary node is not reachable for more than the specified amount of time, it will be failed over by its replicas. This parameter controls other important things in Valkey Cluster. Notably, every node that can&#39;t reach the majority of primary nodes for the specified amount of time, will stop accepting queries.</li>\n<li><strong>cluster-replica-validity-factor <code>&lt;factor&gt;</code></strong>: If set to zero, a replica will always consider itself valid, and will therefore always try to failover a primary, regardless of the amount of time the link between the primary and the replica remained disconnected. If the value is positive, a maximum disconnection time is calculated as the <em>node timeout</em> value multiplied by the factor provided with this option, and if the node is a replica, it will not try to start a failover if the primary link was disconnected for more than the specified amount of time. For example, if the node timeout is set to 5 seconds and the validity factor is set to 10, a replica disconnected from the primary for more than 50 seconds will not try to failover its primary. Note that any value different than zero may result in Valkey Cluster being unavailable after a primary failure if there is no replica that is able to failover it. In that case the cluster will return to being available only when the original primary rejoins the cluster.</li>\n<li><strong>cluster-migration-barrier <code>&lt;count&gt;</code></strong>: Minimum number of replicas a primary will remain connected with, for another replica to migrate to a primary which is no longer covered by any replica. See the appropriate section about replica migration in this tutorial for more information.</li>\n<li><strong>cluster-require-full-coverage <code>&lt;yes/no&gt;</code></strong>: If this is set to yes, as it is by default, the cluster stops accepting writes if some percentage of the key space is not covered by any node. If the option is set to no, the cluster will still serve queries even if only requests about a subset of keys can be processed.</li>\n<li><strong>cluster-allow-reads-when-down <code>&lt;yes/no&gt;</code></strong>: If this is set to no, as it is by default, a node in a Valkey Cluster will stop serving all traffic when the cluster is marked as failed, either when a node can&#39;t reach a quorum of primaries or when full coverage is not met. This prevents reading potentially inconsistent data from a node that is unaware of changes in the cluster. This option can be set to yes to allow reads from a node during the fail state, which is useful for applications that want to prioritize read availability but still want to prevent inconsistent writes. It can also be used for when using Valkey Cluster with only one or two shards, as it allows the nodes to continue serving writes when a primary fails but automatic failover is impossible.</li>\n</ul>\n<h2>Create and use a Valkey Cluster</h2>\n<p>To create and use a Valkey Cluster, follow these steps:</p>\n<ul>\n<li><a href=\"#create-a-valkey-cluster\">Create a Valkey Cluster</a></li>\n<li><a href=\"#interact-with-the-cluster\">Interact with the cluster</a></li>\n<li><a href=\"#write-an-example-app-with-redis-rb-cluster\">Write an example app with redis-rb-cluster</a></li>\n<li><a href=\"#reshard-the-cluster\">Reshard the cluster</a></li>\n<li><a href=\"#a-more-interesting-example-application\">A more interesting example application</a></li>\n<li><a href=\"#test-the-failover\">Test the failover</a></li>\n<li><a href=\"#manual-failover\">Manual failover</a></li>\n<li><a href=\"#add-a-new-node\">Add a new node</a></li>\n<li><a href=\"#remove-a-node\">Remove a node</a></li>\n<li><a href=\"#replica-migration\">Replica migration</a></li>\n<li><a href=\"#upgrade-nodes-in-a-valkey-cluster\">Upgrade nodes in a Valkey Cluster</a></li>\n<li><a href=\"#migrate-to-valkey-cluster\">Migrate to Valkey Cluster</a></li>\n</ul>\n<p>But, first, familiarize yourself with the requirements for creating a cluster.</p>\n<h4>Requirements to create a Valkey Cluster</h4>\n<p>To create a cluster, the first thing you need is to have a few empty Valkey instances running in <em>cluster mode</em>. </p>\n<p>At minimum, set the following directives in the <code>valkey.conf</code> file:</p>\n<pre><code>port 7000\ncluster-enabled yes\ncluster-config-file nodes.conf\ncluster-node-timeout 5000\nappendonly yes\n</code></pre>\n<p>To enable cluster mode, set the <code>cluster-enabled</code> directive to <code>yes</code>.<br>Every instance also contains the path of a file where the<br>configuration for this node is stored, which by default is <code>nodes.conf</code>.<br>This file is never touched by humans; it is simply generated at startup<br>by the Valkey Cluster instances, and updated every time it is needed.</p>\n<p>Note that the <strong>minimal cluster</strong> that works as expected must contain<br>at least three primary nodes. For deployment, we strongly recommend<br>a six-node cluster, with three primaries and three replicas.</p>\n<p>You can test this locally by creating the following directories named<br>after the port number of the instance you&#39;ll run inside any given directory.</p>\n<p>For example:</p>\n<pre><code>mkdir cluster-test\ncd cluster-test\nmkdir 7000 7001 7002 7003 7004 7005\n</code></pre>\n<p>Create a <code>valkey.conf</code> file inside each of the directories, from 7000 to 7005.<br>As a template for your configuration file just use the small example above,<br>but make sure to replace the port number <code>7000</code> with the right port number<br>according to the directory name.</p>\n<p>You can start each instance as follows, each running in a separate terminal tab:</p>\n<pre><code>cd 7000\nvalkey-server ./valkey.conf\n</code></pre>\n<p>You&#39;ll see from the logs that every node assigns itself a new ID:</p>\n<pre><code>[82462] 26 Nov 11:56:55.329 * No cluster configuration found, I&#39;m 97a3a64667477371c4479320d683e4c8db5858b1\n</code></pre>\n<p>This ID will be used forever by this specific instance in order for the instance<br>to have a unique name in the context of the cluster. Every node<br>remembers every other node using this IDs, and not by IP or port.<br>IP addresses and ports may change, but the unique node identifier will never<br>change for all the life of the node. We call this identifier simply <strong>Node ID</strong>.</p>\n<h4>Create a Valkey Cluster</h4>\n<p>Now that we have a number of instances running, you need to create your cluster by writing some meaningful configuration to the nodes.</p>\n<p>You can configure and execute individual instances manually or use the create-cluster script.<br>Let&#39;s go over how you do it manually.</p>\n<p>To create the cluster, run:</p>\n<pre><code>valkey-cli --cluster create 127.0.0.1:7000 127.0.0.1:7001 \\\n127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 \\\n--cluster-replicas 1\n</code></pre>\n<p>The command used here is <strong>create</strong>, since we want to create a new cluster.<br>The option <code>--cluster-replicas 1</code> means that we want a replica for every primary created.</p>\n<p>The other arguments are the list of addresses of the instances I want to use<br>to create the new cluster.</p>\n<p><code>valkey-cli</code> will propose a configuration. Accept the proposed configuration by typing <strong>yes</strong>.<br>The cluster will be configured and <em>joined</em>, which means that instances will be<br>bootstrapped into talking with each other. Finally, if everything has gone well, you&#39;ll see a message like this:</p>\n<pre><code>[OK] All 16384 slots covered\n</code></pre>\n<p>This means that there is at least one primary instance serving each of the<br>16384 available slots.</p>\n<p>If you don&#39;t want to create a Valkey Cluster by configuring and executing<br>individual instances manually as explained above, there is a much simpler<br>system (but you&#39;ll not learn the same amount of operational details).</p>\n<p>Find the <code>utils/create-cluster</code> directory in the Valkey distribution.<br>There is a script called <code>create-cluster</code> inside (same name as the directory<br>it is contained into), it&#39;s a simple bash script. In order to start<br>a 6 nodes cluster with 3 primaries and 3 replicas just type the following<br>commands:</p>\n<ol>\n<li><code>create-cluster start</code></li>\n<li><code>create-cluster create</code></li>\n</ol>\n<p>Reply to <code>yes</code> in step 2 when the <code>valkey-cli</code> utility wants you to accept<br>the cluster layout.</p>\n<p>You can now interact with the cluster, the first node will start at port 30001<br>by default. When you are done, stop the cluster with:</p>\n<ol start=\"3\">\n<li><code>create-cluster stop</code></li>\n</ol>\n<p>Please read the <code>README</code> inside this directory for more information on how<br>to run the script.</p>\n<h4>Interact with the cluster</h4>\n<p>To connect to Valkey Cluster, you&#39;ll need a cluster-aware Valkey client.<br>See the documentation for your <a href=\"../clients/\">client of choice</a> to determine its cluster support.</p>\n<p>You can also test your Valkey Cluster using the <code>valkey-cli</code> command line utility:</p>\n<pre><code>$ valkey-cli -c -p 7000\n127.0.0.1:7000&gt; set foo bar\n-&gt; Redirected to slot [12182] located at 127.0.0.1:7002\nOK\n127.0.0.1:7002&gt; set hello world\n-&gt; Redirected to slot [866] located at 127.0.0.1:7000\nOK\n127.0.0.1:7000&gt; get foo\n-&gt; Redirected to slot [12182] located at 127.0.0.1:7002\n&quot;bar&quot;\n127.0.0.1:7002&gt; get hello\n-&gt; Redirected to slot [866] located at 127.0.0.1:7000\n&quot;world&quot;\n</code></pre>\n<p><strong>Note:</strong><br>If you created the cluster using the script, your nodes may listen<br>on different ports, starting from 30001 by default.</p>\n<p>The <code>valkey-cli</code> cluster support is very basic, so it always uses the fact that<br>Valkey Cluster nodes are able to redirect a client to the right node.<br>A serious client is able to do better than that, and cache the map between<br>hash slots and nodes addresses, to directly use the right connection to the<br>right node. The map is refreshed only when something changed in the cluster<br>configuration, for example after a failover or after the system administrator<br>changed the cluster layout by adding or removing nodes.</p>\n<h4>Write an example app with redis-rb-cluster</h4>\n<p>Before going forward showing how to operate the Valkey Cluster, doing things<br>like a failover, or a resharding, we need to create some example application<br>or at least to be able to understand the semantics of a simple Valkey Cluster<br>client interaction.</p>\n<p>In this way we can run an example and at the same time try to make nodes<br>failing, or start a resharding, to see how Valkey Cluster behaves under real<br>world conditions. It is not very helpful to see what happens while nobody<br>is writing to the cluster.</p>\n<p>This section explains some basic usage of<br><a href=\"https://github.com/antirez/redis-rb-cluster\">redis-rb-cluster</a> showing two<br>examples.<br>The first is the following, and is the<br><a href=\"https://github.com/antirez/redis-rb-cluster/blob/master/example.rb\"><code>example.rb</code></a><br>file inside the redis-rb-cluster distribution:</p>\n<pre><code class=\"language-ruby\">require &#39;./cluster&#39;\n\nif ARGV.length != 2\n    startup_nodes = [\n        {:host =&gt; &quot;127.0.0.1&quot;, :port =&gt; 7000},\n        {:host =&gt; &quot;127.0.0.1&quot;, :port =&gt; 7001}\n    ]\nelse\n    startup_nodes = [\n        {:host =&gt; ARGV[0], :port =&gt; ARGV[1].to_i}\n    ]\nend\n\nrc = RedisCluster.new(startup_nodes,32,:timeout =&gt; 0.1)\n\nlast = false\n\nwhile not last\n    begin\n        last = rc.get(&quot;__last__&quot;)\n        last = 0 if !last\n    rescue =&gt; e\n        puts &quot;error #{e.to_s}&quot;\n        sleep 1\n    end\nend\n\n((last.to_i+1)..1000000000).each{|x|\n    begin\n        rc.set(&quot;foo#{x}&quot;,x)\n        puts rc.get(&quot;foo#{x}&quot;)\n        rc.set(&quot;__last__&quot;,x)\n    rescue =&gt; e\n        puts &quot;error #{e.to_s}&quot;\n    end\n    sleep 0.1\n}\n</code></pre>\n<p>The application does a very simple thing, it sets keys in the form <code>foo&lt;number&gt;</code> to <code>number</code>, one after the other. So if you run the program the result is the<br>following stream of commands:</p>\n<ul>\n<li>SET foo0 0</li>\n<li>SET foo1 1</li>\n<li>SET foo2 2</li>\n<li>And so forth...</li>\n</ul>\n<p>The program looks more complex than it should usually as it is designed to<br>show errors on the screen instead of exiting with an exception, so every<br>operation performed with the cluster is wrapped by <code>begin</code> <code>rescue</code> blocks.</p>\n<p>The <strong>line 14</strong> is the first interesting line in the program. It creates the<br>Valkey Cluster object, using as argument a list of <em>startup nodes</em>, the maximum<br>number of connections this object is allowed to take against different nodes,<br>and finally the timeout after a given operation is considered to be failed.</p>\n<p>The startup nodes don&#39;t need to be all the nodes of the cluster. The important<br>thing is that at least one node is reachable. Also note that redis-rb-cluster<br>updates this list of startup nodes as soon as it is able to connect with the<br>first node. You should expect such a behavior with any other serious client.</p>\n<p>Now that we have the Valkey Cluster object instance stored in the <strong>rc</strong> variable,<br>we are ready to use the object like if it was a normal Valkey object instance.</p>\n<p>This is exactly what happens in <strong>line 18 to 26</strong>: when we restart the example<br>we don&#39;t want to start again with <code>foo0</code>, so we store the counter inside<br>Valkey itself. The code above is designed to read this counter, or if the<br>counter does not exist, to assign it the value of zero.</p>\n<p>However note how it is a while loop, as we want to try again and again even<br>if the cluster is down and is returning errors. Normal applications don&#39;t need<br>to be so careful.</p>\n<p><strong>Lines between 28 and 37</strong> start the main loop where the keys are set or<br>an error is displayed.</p>\n<p>Note the <code>sleep</code> call at the end of the loop. In your tests you can remove<br>the sleep if you want to write to the cluster as fast as possible (relatively<br>to the fact that this is a busy loop without real parallelism of course, so<br>you&#39;ll get the usually 10k ops/second in the best of the conditions).</p>\n<p>Normally writes are slowed down in order for the example application to be<br>easier to follow by humans.</p>\n<p>Starting the application produces the following output:</p>\n<pre><code>ruby ./example.rb\n1\n2\n3\n4\n5\n6\n7\n8\n9\n^C (I stopped the program here)\n</code></pre>\n<p>This is not a very interesting program and we&#39;ll use a better one in a moment<br>but we can already see what happens during a resharding when the program<br>is running.</p>\n<h4>Reshard the cluster</h4>\n<p>Now we are ready to try a cluster resharding. To do this, please<br>keep the example.rb program running, so that you can see if there is some<br>impact on the program running. Also, you may want to comment the <code>sleep</code><br>call to have some more serious write load during resharding.</p>\n<p>Resharding basically means to move hash slots from a set of nodes to another<br>set of nodes.<br>Like cluster creation, it is accomplished using the valkey-cli utility.</p>\n<p>To start a resharding, just type:</p>\n<pre><code>valkey-cli --cluster reshard 127.0.0.1:7000\n</code></pre>\n<p>You only need to specify a single node, valkey-cli will find the other nodes<br>automatically.</p>\n<p>Currently valkey-cli is only able to reshard with the administrator support,<br>you can&#39;t just say move 5% of slots from this node to the other one (but<br>this is pretty trivial to implement). So it starts with questions. The first<br>is how much of a resharding do you want to do:</p>\n<pre><code>How many slots do you want to move (from 1 to 16384)?\n</code></pre>\n<p>We can try to reshard 1000 hash slots, that should already contain a non<br>trivial amount of keys if the example is still running without the sleep<br>call.</p>\n<p>Then valkey-cli needs to know what is the target of the resharding, that is,<br>the node that will receive the hash slots.<br>I&#39;ll use the first primary node, that is, 127.0.0.1:7000, but I need<br>to specify the Node ID of the instance. This was already printed in a<br>list by valkey-cli, but I can always find the ID of a node with the following<br>command if I need:</p>\n<pre><code>$ valkey-cli -p 7000 cluster nodes | grep myself\n97a3a64667477371c4479320d683e4c8db5858b1 :0 myself,master - 0 0 0 connected 0-5460\n</code></pre>\n<p>Ok so my target node is 97a3a64667477371c4479320d683e4c8db5858b1.</p>\n<p>Now you&#39;ll get asked from what nodes you want to take those keys.<br>I&#39;ll just type <code>all</code> in order to take a bit of hash slots from all the<br>other primary nodes.</p>\n<p>After the final confirmation you&#39;ll see a message for every slot that<br>valkey-cli is going to move from a node to another, and a dot will be printed<br>for every actual key moved from one side to the other.</p>\n<p>While the resharding is in progress you should be able to see your<br>example program running unaffected. You can stop and restart it multiple times<br>during the resharding if you want.</p>\n<p>At the end of the resharding, you can test the health of the cluster with<br>the following command:</p>\n<pre><code>valkey-cli --cluster check 127.0.0.1:7000\n</code></pre>\n<p>All the slots will be covered as usual, but this time the primary at<br>127.0.0.1:7000 will have more hash slots, something around 6461.</p>\n<p>Resharding can be performed automatically without the need to manually<br>enter the parameters in an interactive way. This is possible using a command<br>line like the following:</p>\n<pre><code>valkey-cli --cluster reshard &lt;host&gt;:&lt;port&gt; --cluster-from &lt;node-id&gt; --cluster-to &lt;node-id&gt; --cluster-slots &lt;number of slots&gt; --cluster-yes\n</code></pre>\n<p>This allows to build some automatism if you are likely to reshard often,<br>however currently there is no way for <code>valkey-cli</code> to automatically<br>rebalance the cluster checking the distribution of keys across the cluster<br>nodes and intelligently moving slots as needed. This feature will be added<br>in the future.</p>\n<p>The <code>--cluster-yes</code> option instructs the cluster manager to automatically answer<br>&quot;yes&quot; to the command&#39;s prompts, allowing it to run in a non-interactive mode.<br>Note that this option can also be activated by setting the<br><code>REDISCLI_CLUSTER_YES</code> environment variable.</p>\n<h4>A more interesting example application</h4>\n<p>The example application we wrote early is not very good.<br>It writes to the cluster in a simple way without even checking if what was<br>written is the right thing.</p>\n<p>From our point of view the cluster receiving the writes could just always<br>write the key <code>foo</code> to <code>42</code> to every operation, and we would not notice at<br>all.</p>\n<p>So in the <code>redis-rb-cluster</code> repository, there is a more interesting application<br>that is called <code>consistency-test.rb</code>. It uses a set of counters, by default 1000, and sends <code>INCR</code> commands in order to increment the counters.</p>\n<p>However instead of just writing, the application does two additional things:</p>\n<ul>\n<li>When a counter is updated using <code>INCR</code>, the application remembers the write.</li>\n<li>It also reads a random counter before every write, and check if the value is what we expected it to be, comparing it with the value it has in memory.</li>\n</ul>\n<p>What this means is that this application is a simple <strong>consistency checker</strong>,<br>and is able to tell you if the cluster lost some write, or if it accepted<br>a write that we did not receive acknowledgment for. In the first case we&#39;ll<br>see a counter having a value that is smaller than the one we remember, while<br>in the second case the value will be greater.</p>\n<p>Running the consistency-test application produces a line of output every<br>second:</p>\n<pre><code>$ ruby consistency-test.rb\n925 R (0 err) | 925 W (0 err) |\n5030 R (0 err) | 5030 W (0 err) |\n9261 R (0 err) | 9261 W (0 err) |\n13517 R (0 err) | 13517 W (0 err) |\n17780 R (0 err) | 17780 W (0 err) |\n22025 R (0 err) | 22025 W (0 err) |\n25818 R (0 err) | 25818 W (0 err) |\n</code></pre>\n<p>The line shows the number of <strong>R</strong>eads and <strong>W</strong>rites performed, and the<br>number of errors (query not accepted because of errors since the system was<br>not available).</p>\n<p>If some inconsistency is found, new lines are added to the output.<br>This is what happens, for example, if I reset a counter manually while<br>the program is running:</p>\n<pre><code>$ valkey-cli -h 127.0.0.1 -p 7000 set key_217 0\nOK\n\n(in the other tab I see...)\n\n94774 R (0 err) | 94774 W (0 err) |\n98821 R (0 err) | 98821 W (0 err) |\n102886 R (0 err) | 102886 W (0 err) | 114 lost |\n107046 R (0 err) | 107046 W (0 err) | 114 lost |\n</code></pre>\n<p>When I set the counter to 0 the real value was 114, so the program reports<br>114 lost writes (<code>INCR</code> commands that are not remembered by the cluster).</p>\n<p>This program is much more interesting as a test case, so we&#39;ll use it<br>to test the Valkey Cluster failover.</p>\n<h4>Test the failover</h4>\n<p>To trigger the failover, the simplest thing we can do (that is also<br>the semantically simplest failure that can occur in a distributed system)<br>is to crash a single process, in our case a single primary.</p>\n<p><strong>Note:</strong><br>During this test, you should take a tab open with the consistency test<br>application running.</p>\n<p>We can identify a primary and crash it with the following command:</p>\n<pre><code>$ valkey-cli -p 7000 cluster nodes | grep master\n3e3a6cb0d9a9a87168e266b0a0b24026c0aae3f0 127.0.0.1:7001 master - 0 1385482984082 0 connected 5960-10921\n2938205e12de373867bf38f1ca29d31d0ddb3e46 127.0.0.1:7002 master - 0 1385482983582 0 connected 11423-16383\n97a3a64667477371c4479320d683e4c8db5858b1 :0 myself,master - 0 0 0 connected 0-5959 10922-11422\n</code></pre>\n<p>Ok, so 7000, 7001, and 7002 are primaries. Let&#39;s crash node 7002 with the<br><strong>DEBUG SEGFAULT</strong> command:</p>\n<pre><code>$ valkey-cli -p 7002 debug segfault\nError: Server closed the connection\n</code></pre>\n<p>Now we can look at the output of the consistency test to see what it reported.</p>\n<pre><code>18849 R (0 err) | 18849 W (0 err) |\n23151 R (0 err) | 23151 W (0 err) |\n27302 R (0 err) | 27302 W (0 err) |\n\n... many error warnings here ...\n\n29659 R (578 err) | 29660 W (577 err) |\n33749 R (578 err) | 33750 W (577 err) |\n37918 R (578 err) | 37919 W (577 err) |\n42077 R (578 err) | 42078 W (577 err) |\n</code></pre>\n<p>As you can see during the failover the system was not able to accept 578 reads and 577 writes, however no inconsistency was created in the database. This may<br>sound unexpected as in the first part of this tutorial we stated that Valkey<br>Cluster can lose writes during the failover because it uses asynchronous<br>replication. What we did not say is that this is not very likely to happen<br>because Valkey sends the reply to the client, and the commands to replicate<br>to the replicas, about at the same time, so there is a very small window to<br>lose data. However the fact that it is hard to trigger does not mean that it<br>is impossible, so this does not change the consistency guarantees provided<br>by Valkey cluster.</p>\n<p>We can now check what is the cluster setup after the failover (note that<br>in the meantime I restarted the crashed instance so that it rejoins the<br>cluster as a replica):</p>\n<pre><code>$ valkey-cli -p 7000 cluster nodes\n3fc783611028b1707fd65345e763befb36454d73 127.0.0.1:7004 slave 3e3a6cb0d9a9a87168e266b0a0b24026c0aae3f0 0 1385503418521 0 connected\na211e242fc6b22a9427fed61285e85892fa04e08 127.0.0.1:7003 slave 97a3a64667477371c4479320d683e4c8db5858b1 0 1385503419023 0 connected\n97a3a64667477371c4479320d683e4c8db5858b1 :0 myself,master - 0 0 0 connected 0-5959 10922-11422\n3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e 127.0.0.1:7005 master - 0 1385503419023 3 connected 11423-16383\n3e3a6cb0d9a9a87168e266b0a0b24026c0aae3f0 127.0.0.1:7001 master - 0 1385503417005 0 connected 5960-10921\n2938205e12de373867bf38f1ca29d31d0ddb3e46 127.0.0.1:7002 slave 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e 0 1385503418016 3 connected\n</code></pre>\n<p>Now the primaries are running on ports 7000, 7001 and 7005. What was previously<br>a primary, that is the Valkey instance running on port 7002, is now a replica of<br>7005.</p>\n<p>The output of the <code>CLUSTER NODES</code> command may look intimidating, but it is actually pretty simple, and is composed of the following tokens:</p>\n<ul>\n<li>Node ID</li>\n<li>ip:port</li>\n<li>flags: master, replica, myself, fail, ...</li>\n<li>if it is a replica, the Node ID of the master</li>\n<li>Time of the last pending PING still waiting for a reply.</li>\n<li>Time of the last PONG received.</li>\n<li>Configuration epoch for this node (see the Cluster specification).</li>\n<li>Status of the link to this node.</li>\n<li>Slots served...</li>\n</ul>\n<h4>Manual failover</h4>\n<p>Sometimes it is useful to force a failover without actually causing any problem<br>on a primary. For example, to upgrade the Valkey process of one of the<br>primary nodes it is a good idea to failover it to turn it into a replica<br>with minimal impact on availability.</p>\n<p>Manual failovers are supported by Valkey Cluster using the <code>CLUSTER FAILOVER</code><br>command, that must be executed in one of the replicas of the primary you want<br>to failover.</p>\n<p>Manual failovers are special and are safer compared to failovers resulting from<br>actual primary failures. They occur in a way that avoids data loss in the<br>process, by switching clients from the original primary to the new primary only<br>when the system is sure that the new primary processed all the replication stream<br>from the old one.</p>\n<p>This is what you see in the replica log when you perform a manual failover:</p>\n<pre><code># Manual failover user request accepted.\n# Received replication offset for paused primary manual failover: 347540\n# All primary replication stream processed, manual failover can start.\n# Start of election delayed for 0 milliseconds (rank #0, offset 347540).\n# Starting a failover election for epoch 7545.\n# Failover election won: I&#39;m the new primary.\n</code></pre>\n<p>Clients sending write commands to the primary are blocked during the failover.<br>When the primary sends its replication offset to the replica, the replica<br>waits to reach the offset on its side. When the replication offset is reached,<br>the failover starts, and the old primary is informed about the configuration<br>switch. When the switch is complete, the clients are unblocked on the old<br>primary and they are redirected to the new primary.</p>\n<p><strong>Note:</strong><br>To promote a replica to primary, it must first be known as a replica by a majority of the primaries in the cluster.<br>  Otherwise, it cannot win the failover election.<br>  If the replica has just been added to the cluster (see <a href=\"#add-a-new-node-as-a-replica\">Add a new node as a replica</a>), you may need to wait a while before sending the <code>CLUSTER FAILOVER</code> command, to make sure the primaries in cluster are aware of the new replica.</p>\n<h4>Add a new node</h4>\n<p>Adding a new node is basically the process of adding an empty node and then<br>moving some data into it, in case it is a new primary, or telling it to<br>setup as a replica of a known node, in case it is a replica.</p>\n<p>We&#39;ll show both, starting with the addition of a new primary instance.</p>\n<p>In both cases the first step to perform is <strong>adding an empty node</strong>.</p>\n<p>This is as simple as to start a new node in port 7006 (we already used<br>from 7000 to 7005 for our existing 6 nodes) with the same configuration<br>used for the other nodes, except for the port number, so what you should<br>do in order to conform with the setup we used for the previous nodes:</p>\n<ul>\n<li>Create a new tab in your terminal application.</li>\n<li>Enter the <code>cluster-test</code> directory.</li>\n<li>Create a directory named <code>7006</code>.</li>\n<li>Create a valkey.conf file inside, similar to the one used for the other nodes but using 7006 as port number.</li>\n<li>Finally start the server with <code>../valkey-server ./valkey.conf</code></li>\n</ul>\n<p>At this point the server should be running.</p>\n<p>Now we can use <strong>valkey-cli</strong> as usual in order to add the node to<br>the existing cluster.</p>\n<pre><code>valkey-cli --cluster add-node 127.0.0.1:7006 127.0.0.1:7000\n</code></pre>\n<p>As you can see I used the <strong>add-node</strong> command specifying the address of the<br>new node as first argument, and the address of a random existing node in the<br>cluster as second argument.</p>\n<p>In practical terms valkey-cli here did very little to help us, it just<br>sent a <code>CLUSTER MEET</code> message to the node, something that is also possible<br>to accomplish manually. However valkey-cli also checks the state of the<br>cluster before to operate, so it is a good idea to perform cluster operations<br>always via valkey-cli even when you know how the internals work.</p>\n<p>Now we can connect to the new node to see if it really joined the cluster:</p>\n<pre><code>valkey 127.0.0.1:7006&gt; cluster nodes\n3e3a6cb0d9a9a87168e266b0a0b24026c0aae3f0 127.0.0.1:7001 master - 0 1385543178575 0 connected 5960-10921\n3fc783611028b1707fd65345e763befb36454d73 127.0.0.1:7004 slave 3e3a6cb0d9a9a87168e266b0a0b24026c0aae3f0 0 1385543179583 0 connected\nf093c80dde814da99c5cf72a7dd01590792b783b :0 myself,master - 0 0 0 connected\n2938205e12de373867bf38f1ca29d31d0ddb3e46 127.0.0.1:7002 slave 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e 0 1385543178072 3 connected\na211e242fc6b22a9427fed61285e85892fa04e08 127.0.0.1:7003 slave 97a3a64667477371c4479320d683e4c8db5858b1 0 1385543178575 0 connected\n97a3a64667477371c4479320d683e4c8db5858b1 127.0.0.1:7000 master - 0 1385543179080 0 connected 0-5959 10922-11422\n3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e 127.0.0.1:7005 master - 0 1385543177568 3 connected 11423-16383\n</code></pre>\n<p>Note that since this node is already connected to the cluster it is already<br>able to redirect client queries correctly and is generally speaking part of<br>the cluster. However it has two peculiarities compared to the other primaries:</p>\n<ul>\n<li>It holds no data as it has no assigned hash slots.</li>\n<li>Because it is a primary without assigned slots, it does not participate in the election process when a replica wants to become a primary.</li>\n</ul>\n<p>Now it is possible to assign hash slots to this node using the resharding<br>feature of <code>valkey-cli</code>.<br>It is basically useless to show this as we already<br>did in a previous section, there is no difference, it is just a resharding<br>having as a target the empty node.</p>\n<h5>Add a new node as a replica</h5>\n<p>Adding a new replica can be performed in two ways. The obvious one is to<br>use valkey-cli again, but with the --cluster-replica option, like this:</p>\n<pre><code>valkey-cli --cluster add-node 127.0.0.1:7006 127.0.0.1:7000 --cluster-replica\n</code></pre>\n<p>Note that the command line here is exactly like the one we used to add<br>a new primary, so we are not specifying to which primary we want to add<br>the replica. In this case, what happens is that valkey-cli will add the new<br>node as replica of a random primary among the primaries with fewer replicas.</p>\n<p>However you can specify exactly what primary you want to target with your<br>new replica with the following command line:</p>\n<pre><code>valkey-cli --cluster add-node 127.0.0.1:7006 127.0.0.1:7000 --cluster-replica --cluster-master-id 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e\n</code></pre>\n<p>This way we assign the new replica to a specific primary.</p>\n<p>A more manual way to add a replica to a specific primary is to add the new<br>node as an empty primary, and then turn it into a replica using the<br><code>CLUSTER REPLICATE</code> command. This also works if the node was added as a replica<br>but you want to move it as a replica of a different primary.</p>\n<p>For example in order to add a replica for the node 127.0.0.1:7005 that is<br>currently serving hash slots in the range 11423-16383, that has a Node ID<br>3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e, all I need to do is to connect<br>with the new node (already added as empty primary) and send the command:</p>\n<pre><code>valkey 127.0.0.1:7006&gt; cluster replicate 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e\n</code></pre>\n<p>That&#39;s it. Now we have a new replica for this set of hash slots, and all<br>the other nodes in the cluster already know (after a few seconds needed to<br>update their config). We can verify with the following command:</p>\n<pre><code>$ valkey-cli -p 7000 cluster nodes | grep slave | grep 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e\nf093c80dde814da99c5cf72a7dd01590792b783b 127.0.0.1:7006 replica 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e 0 1385543617702 3 connected\n2938205e12de373867bf38f1ca29d31d0ddb3e46 127.0.0.1:7002 replica 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e 0 1385543617198 3 connected\n</code></pre>\n<p>The node 3c3a0c... now has two replicas, running on ports 7002 (the existing one) and 7006 (the new one).</p>\n<h4>Remove a node</h4>\n<p>To remove a replica node just use the <code>del-node</code> command of valkey-cli:</p>\n<pre><code>valkey-cli --cluster del-node 127.0.0.1:7000 `&lt;node-id&gt;`\n</code></pre>\n<p>The first argument is just a random node in the cluster, the second argument<br>is the ID of the node you want to remove.</p>\n<p>You can remove a primary node in the same way as well, <strong>however in order to<br>remove a primary node it must be empty</strong>. If the primary is not empty you need<br>to reshard data away from it to all the other primary nodes before.</p>\n<p>An alternative to remove a primary node is to perform a manual failover of it<br>over one of its replicas and remove the node after it turned into a replica of the<br>new primary. Obviously this does not help when you want to reduce the actual<br>number of primaries in your cluster, in that case, a resharding is needed.</p>\n<p>There is a special scenario where you want to remove a failed node.<br>You should not use the <code>del-node</code> command because it tries to connect to all nodes and you will encounter a &quot;connection refused&quot; error.<br>Instead, you can use the <code>call</code> command:</p>\n<pre><code>valkey-cli --cluster call 127.0.0.1:7000 cluster forget `&lt;node-id&gt;`\n</code></pre>\n<p>This command will execute <code>CLUSTER FORGET</code> command on every node. </p>\n<h4>Replica migration</h4>\n<p>In Valkey Cluster, you can reconfigure a replica to replicate with a<br>different primary at any time just using this command:</p>\n<pre><code>CLUSTER REPLICATE &lt;master-node-id&gt;\n</code></pre>\n<p>However there is a special scenario where you want replicas to move from one<br>primary to another one automatically, without the help of the system administrator.<br>The automatic reconfiguration of replicas is called <em>replicas migration</em> and is<br>able to improve the reliability of a Valkey Cluster.</p>\n<p><strong>Note:</strong><br>You can read the details of replicas migration in the <a href=\"cluster-spec\">Valkey Cluster Specification</a>, here we&#39;ll only provide some information about the<br>general idea and what you should do in order to benefit from it.</p>\n<p>The reason why you may want to let your cluster replicas to move from one primary<br>to another under certain condition, is that usually the Valkey Cluster is as<br>resistant to failures as the number of replicas attached to a given primary.</p>\n<p>For example a cluster where every primary has a single replica can&#39;t continue<br>operations if the primary and its replica fail at the same time, simply because<br>there is no other instance to have a copy of the hash slots the primary was<br>serving. However while net-splits are likely to isolate a number of nodes<br>at the same time, many other kind of failures, like hardware or software failures<br>local to a single node, are a very notable class of failures that are unlikely<br>to happen at the same time, so it is possible that in your cluster where<br>every primary has a replica, the replica is killed at 4am, and the primary is killed<br>at 6am. This still will result in a cluster that can no longer operate.</p>\n<p>To improve reliability of the system we have the option to add additional<br>replicas to every primary, but this is expensive. Replica migration allows to<br>add more replicas to just a few primaries. So you have 10 primaries with 1 replica<br>each, for a total of 20 instances. However you add, for example, 3 instances<br>more as replicas of some of your primaries, so certain primaries will have more<br>than a single replica.</p>\n<p>With replicas migration what happens is that if a primary is left without<br>replicas, a replica from a primary that has multiple replicas will migrate to<br>the <em>orphaned</em> primary. So after your replica goes down at 4am as in the example<br>we made above, another replica will take its place, and when the primary<br>will fail as well at 5am, there is still a replica that can be elected so that<br>the cluster can continue to operate.</p>\n<p>So what you should know about replicas migration in short?</p>\n<ul>\n<li>The cluster will try to migrate a replica from the primary that has the greatest number of replicas in a given moment.</li>\n<li>To benefit from replica migration you have just to add a few more replicas to a single primary in your cluster, it does not matter what primary.</li>\n<li>There is a configuration parameter that controls the replica migration feature that is called <code>cluster-migration-barrier</code>: you can read more about it in the example <code>valkey.conf</code> file provided with Valkey Cluster.</li>\n</ul>\n<h4>Upgrade nodes in a Valkey Cluster</h4>\n<p>Upgrading replica nodes is easy since you just need to stop the node and restart<br>it with an updated version of Valkey. If there are clients scaling reads using<br>replica nodes, they should be able to reconnect to a different replica if a given<br>one is not available.</p>\n<p>Upgrading primaries is a bit more complex. The suggested procedure is to trigger<br>a manual failover to turn the old primary into a replica and then upgrading it.</p>\n<p>A complete rolling upgrade of all nodes in a cluster can be performed by<br>repeating the following procedure for each shard (a primary and its replicas):</p>\n<ol>\n<li><p>Add one or more upgraded nodes as new replicas to the primary. This step is<br>optional but it ensures that the number of replicas is not compromised during<br>the rolling upgrade. To add a new node, use <a href=\"../commands/cluster-meet\"><code>CLUSTER MEET</code></a> and <a href=\"../commands/cluster-replicate\"><code>CLUSTER REPLICATE</code></a> or use <code>valkey-cli</code> as<br>described under <a href=\"#add-a-new-node-as-a-replica\">Add a new node as a replica</a>.</p>\n<p>An alternative is to upgrade one replica at a time and have fewer replicas<br>online during the upgrade.</p>\n</li>\n<li><p>Upgrade the old replicas you want to keep by restarting them with the updated<br>version of Valkey. If you&#39;re replacing all the old nodes with new nodes, you<br>can skip this step.</p>\n</li>\n<li><p>Select one of the upgraded replicas to be the new primary. Wait until this<br>replica has caught up the replication offset with the primary. You can use<br><a href=\"../commands/info\"><code>INFO REPLICATION</code></a> and check for the line<br><code>master_link_status:up</code> to be present. This indicates that the initial sync<br>with the primary is complete.</p>\n<p>After the initial full sync, the replica might still lag behind in<br>replication. Send <code>INFO REPLICATION</code> to the primary and the replica and<br>compare the field <code>master_repl_offset</code> returned by both nodes. If the offsets<br>match, it means that all writes have been replicated. However, if the primary<br>receives a constant stream of writes, it&#39;s possible that the offsets will<br>never be equal. In this step, you can accept a small difference. It&#39;s usually<br>enough to wait for some seconds to minimize the difference.</p>\n</li>\n<li><p>Check that the new replica is known by all nodes in the cluster, or at least<br>by the primaries in the cluster. You can send <a href=\"../commands/cluster-nodes\"><code>CLUSTER NODES</code></a> to each of the nodes in the cluster and<br>check that they all are aware of the new node. Wait for some time and repeat<br>the check if necessary.</p>\n</li>\n<li><p>Trigger a manual failover by sending <a href=\"../commands/cluster-failover\"><code>CLUSTER FAILOVER</code></a> to the replica node selected to<br>become the new primary. See the <a href=\"#manual-failover\">Manual failover</a> section<br>in this document for more information.</p>\n</li>\n<li><p>Wait for the failover to complete. To check, you can use<br><a href=\"../commands/role\"><code>ROLE</code></a>, <a href=\"../commands/info\"><code>INFO REPLICATION</code></a><br>(which indicates <code>role:master</code> after successful failover) or <a href=\"../commands/cluster-nodes\"><code>CLUSTER NODES</code></a> to verify that the state of the cluster<br>has changed shortly after the command was sent.</p>\n</li>\n<li><p>Take the old primary (now a replica) out of service, or upgrade it and add it<br>again as a replica. Remove additional replicas kept for redundancy during the<br>upgrade, if any.</p>\n</li>\n</ol>\n<p>Repeat this sequence for each shard (each primary and its replicas) until all<br>nodes in the cluster have been upgraded.</p>\n<h4>Migrate to Valkey Cluster</h4>\n<p>Users willing to migrate to Valkey Cluster may have just a single primary, or<br>may already using a preexisting sharding setup, where keys<br>are split among N nodes, using some in-house algorithm or a sharding algorithm<br>implemented by their client library or Valkey proxy.</p>\n<p>In both cases it is possible to migrate to Valkey Cluster easily, however<br>what is the most important detail is if multiple-keys operations are used<br>by the application, and how. There are three different cases:</p>\n<ol>\n<li>Multiple keys operations, or transactions, or Lua scripts involving multiple keys, are not used. Keys are accessed independently (even if accessed via transactions or Lua scripts grouping multiple commands, about the same key, together).</li>\n<li>Multiple keys operations, or transactions, or Lua scripts involving multiple keys are used but only with keys having the same <strong>hash tag</strong>, which means that the keys used together all have a <code>{...}</code> sub-string that happens to be identical. For example the following multiple keys operation is defined in the context of the same hash tag: <code>SUNION {user:1000}.foo {user:1000}.bar</code>.</li>\n<li>Multiple keys operations, or transactions, or Lua scripts involving multiple keys are used with key names not having an explicit, or the same, hash tag.</li>\n</ol>\n<p>The third case is not handled by Valkey Cluster: the application requires to<br>be modified in order to not use multi keys operations or only use them in<br>the context of the same hash tag.</p>\n<p>Case 1 and 2 are covered, so we&#39;ll focus on those two cases, that are handled<br>in the same way, so no distinction will be made in the documentation.</p>\n<p>Assuming you have your preexisting data set split into N primaries, where<br>N=1 if you have no preexisting sharding, the following steps are needed<br>in order to migrate your data set to Valkey Cluster:</p>\n<ol>\n<li>Stop your clients. No automatic live-migration to Valkey Cluster is currently possible. You may be able to do it orchestrating a live migration in the context of your application / environment.</li>\n<li>Generate an append only file for all of your N primaries using the <code>BGREWRITEAOF</code> command, and waiting for the AOF file to be completely generated.</li>\n<li>Save your AOF files from aof-1 to aof-N somewhere. At this point you can stop your old instances if you wish (this is useful since in non-virtualized deployments you often need to reuse the same computers).</li>\n<li>Create a Valkey Cluster composed of N primaries and zero replicas. You&#39;ll add replicas later. Make sure all your nodes are using the append only file for persistence.</li>\n<li>Stop all the cluster nodes, substitute their append only file with your pre-existing append only files, aof-1 for the first node, aof-2 for the second node, up to aof-N.</li>\n<li>Restart your Valkey Cluster nodes with the new AOF files. They&#39;ll complain that there are keys that should not be there according to their configuration.</li>\n<li>Use <code>valkey-cli --cluster fix</code> command in order to fix the cluster so that keys will be migrated according to the hash slots each node is authoritative or not.</li>\n<li>Use <code>valkey-cli --cluster check</code> at the end to make sure your cluster is ok.</li>\n<li>Restart your clients modified to use a Valkey Cluster aware client library.</li>\n</ol>\n<p>There is an alternative way to import data from external instances to a Valkey<br>Cluster, which is to use the <code>valkey-cli --cluster import</code> command.</p>\n<p>The command moves all the keys of a running instance (deleting the keys from<br>the source instance) to the specified pre-existing Valkey Cluster. </p>\n<p><strong>Note:</strong><br>If not for backward compatibility, the Valkey project no longer uses the words &quot;master&quot; and &quot;slave&quot;. Unfortunately in this command these words are part of the protocol, so we&#39;ll be able to remove such occurrences only when this API will be naturally deprecated.</p>\n<h2>Learn more</h2>\n<ul>\n<li><a href=\"cluster-spec\">Valkey Cluster specification</a></li>\n<li><a href=\"https://docs.docker.com/engine/userguide/networking/dockernetworks/\">Docker documentation</a></li>\n</ul>\n"
  },
  {
    "id": "command-arguments",
    "topicName": "Command arguments",
    "description": "How Valkey commands expose their documentation programmatically",
    "htmlContent": "<p>The <code>COMMAND DOCS</code> command returns documentation-focused information about available Valkey commands.<br>The map reply that the command returns includes the <em>arguments</em> key.<br>This key stores an array that describes the command&#39;s arguments.</p>\n<p>Every element in the <em>arguments</em> array is a map with the following fields:</p>\n<ul>\n<li><strong>name:</strong> the argument&#39;s name, always present.<br>The name of an argument is given for identification purposes alone.<br>It isn&#39;t displayed during the command&#39;s syntax rendering.<br>The same name can appear more than once in the entire argument tree, but it is unique compared to other sibling arguments&#39; names.<br>This allows obtaining a unique identifier for each argument (the concatenation of all names in the path from the root to any argument).</li>\n<li><strong>display_text:</strong> the argument&#39;s display string, present in arguments that have a displayable representation (all arguments that aren&#39;t oneof/block).<br>This is the string used in the command&#39;s syntax rendering.</li>\n<li><strong>type:</strong> the argument&#39;s type, always present.<br>An argument must have one of the following types:<ul>\n<li><strong>string:</strong> a string argument.</li>\n<li><strong>integer:</strong> an integer argument.</li>\n<li><strong>double:</strong> a double-precision argument.</li>\n<li><strong>key:</strong> a string that represents the name of a key.</li>\n<li><strong>pattern:</strong> a string that represents a glob-like pattern.</li>\n<li><strong>unix-time:</strong> an integer that represents a Unix timestamp.</li>\n<li><strong>pure-token:</strong> an argument is a token, meaning a reserved keyword, which may or may not be provided.<br>Not to be confused with free-text user input.</li>\n<li><strong>oneof</strong>: the argument is a container for nested arguments.<br>This type enables choice among several nested arguments (see the <code>XADD</code> example below).</li>\n<li><strong>block:</strong> the argument is a container for nested arguments.<br>This type enables grouping arguments and applying a property (such as <em>optional</em>) to all (see the <code>XADD</code> example below).</li>\n</ul>\n</li>\n<li><strong>key_spec_index:</strong> this value is available for every argument of the <em>key</em> type.<br>It is a 0-based index of the specification in the command&#39;s <a href=\"key-specs\">key specifications</a> that corresponds to the argument.</li>\n<li><strong>token</strong>: a constant literal that precedes the argument (user input) itself.</li>\n<li><strong>summary:</strong> a short description of the argument.</li>\n<li><strong>since:</strong> the debut Redis OSS version of the argument (or for module commands, the module version).</li>\n<li><strong>deprecated_since:</strong> the Redis OSS version that deprecated the command (or for module commands, the module version).</li>\n<li><strong>flags:</strong> an array of argument flags.<br>Possible flags are:<ul>\n<li><strong>optional</strong>: denotes that the argument is optional (for example, the <em>GET</em> clause of the  <code>SET</code> command).</li>\n<li><strong>multiple</strong>: denotes that the argument may be repeated (such as the <em>key</em> argument of <code>DEL</code>).</li>\n<li><strong>multiple-token:</strong> denotes the possible repetition of the argument with its preceding token (see <code>SORT</code>&#39;s <code>GET pattern</code> clause).</li>\n</ul>\n</li>\n<li><strong>value:</strong> the argument&#39;s value.<br>For arguments types other than <em>oneof</em> and <em>block</em>, this is a string that describes the value in the command&#39;s syntax.<br>For the <em>oneof</em> and <em>block</em> types, this is an array of nested arguments, each being a map as described in this section.</li>\n</ul>\n<h2>Example</h2>\n<p>The trimming clause of <code>XADD</code>, i.e., <code>[MAXLEN|MINID [=|~] threshold [LIMIT count]]</code>, is represented at the top-level as <em>block</em>-typed argument.</p>\n<p>It consists of four nested arguments:</p>\n<ol>\n<li><strong>trimming strategy:</strong> this nested argument has an <em>oneof</em> type with two nested arguments.<br>  Each of the nested arguments, <em>MAXLEN</em> and <em>MINID</em>, is typed as <em>pure-token</em>.</li>\n<li><strong>trimming operator:</strong> this nested argument is an optional <em>oneof</em> type with two nested arguments.<br>  Each of the nested arguments, <em>=</em> and <em>~</em>, is a <em>pure-token</em>.</li>\n<li><strong>threshold:</strong> this nested argument is a <em>string</em>.</li>\n<li><strong>count:</strong> this nested argument is an optional <em>integer</em> with a <em>token</em> (<em>LIMIT</em>).</li>\n</ol>\n<p>Here&#39;s <code>XADD</code>&#39;s arguments array:</p>\n<pre><code>1) 1) &quot;name&quot;\n   2) &quot;key&quot;\n   3) &quot;type&quot;\n   4) &quot;key&quot;\n   5) &quot;value&quot;\n   6) &quot;key&quot;\n2)  1) &quot;name&quot;\n    2) &quot;nomkstream&quot;\n    3) &quot;type&quot;\n    4) &quot;pure-token&quot;\n    5) &quot;token&quot;\n    6) &quot;NOMKSTREAM&quot;\n    7) &quot;since&quot;\n    8) &quot;6.2&quot;\n    9) &quot;flags&quot;\n   10) 1) optional\n3) 1) &quot;name&quot;\n   2) &quot;trim&quot;\n   3) &quot;type&quot;\n   4) &quot;block&quot;\n   5) &quot;flags&quot;\n   6) 1) optional\n   7) &quot;value&quot;\n   8) 1) 1) &quot;name&quot;\n         2) &quot;strategy&quot;\n         3) &quot;type&quot;\n         4) &quot;oneof&quot;\n         5) &quot;value&quot;\n         6) 1) 1) &quot;name&quot;\n               2) &quot;maxlen&quot;\n               3) &quot;type&quot;\n               4) &quot;pure-token&quot;\n               5) &quot;token&quot;\n               6) &quot;MAXLEN&quot;\n            2) 1) &quot;name&quot;\n               2) &quot;minid&quot;\n               3) &quot;type&quot;\n               4) &quot;pure-token&quot;\n               5) &quot;token&quot;\n               6) &quot;MINID&quot;\n               7) &quot;since&quot;\n               8) &quot;6.2&quot;\n      2) 1) &quot;name&quot;\n         2) &quot;operator&quot;\n         3) &quot;type&quot;\n         4) &quot;oneof&quot;\n         5) &quot;flags&quot;\n         6) 1) optional\n         7) &quot;value&quot;\n         8) 1) 1) &quot;name&quot;\n               2) &quot;equal&quot;\n               3) &quot;type&quot;\n               4) &quot;pure-token&quot;\n               5) &quot;token&quot;\n               6) &quot;=&quot;\n            2) 1) &quot;name&quot;\n               2) &quot;approximately&quot;\n               3) &quot;type&quot;\n               4) &quot;pure-token&quot;\n               5) &quot;token&quot;\n               6) &quot;~&quot;\n      3) 1) &quot;name&quot;\n         2) &quot;threshold&quot;\n         3) &quot;type&quot;\n         4) &quot;string&quot;\n         5) &quot;value&quot;\n         6) &quot;threshold&quot;\n      4)  1) &quot;name&quot;\n          2) &quot;count&quot;\n          3) &quot;type&quot;\n          4) &quot;integer&quot;\n          5) &quot;token&quot;\n          6) &quot;LIMIT&quot;\n          7) &quot;since&quot;\n          8) &quot;6.2&quot;\n          9) &quot;flags&quot;\n         10) 1) optional\n         11) &quot;value&quot;\n         12) &quot;count&quot;\n4) 1) &quot;name&quot;\n   2) &quot;id_or_auto&quot;\n   3) &quot;type&quot;\n   4) &quot;oneof&quot;\n   5) &quot;value&quot;\n   6) 1) 1) &quot;name&quot;\n         2) &quot;auto_id&quot;\n         3) &quot;type&quot;\n         4) &quot;pure-token&quot;\n         5) &quot;token&quot;\n         6) &quot;*&quot;\n      2) 1) &quot;name&quot;\n         2) &quot;id&quot;\n         3) &quot;type&quot;\n         4) &quot;string&quot;\n         5) &quot;value&quot;\n         6) &quot;id&quot;\n5) 1) &quot;name&quot;\n   2) &quot;field_value&quot;\n   3) &quot;type&quot;\n   4) &quot;block&quot;\n   5) &quot;flags&quot;\n   6) 1) multiple\n   7) &quot;value&quot;\n   8) 1) 1) &quot;name&quot;\n         2) &quot;field&quot;\n         3) &quot;type&quot;\n         4) &quot;string&quot;\n         5) &quot;value&quot;\n         6) &quot;field&quot;\n      2) 1) &quot;name&quot;\n         2) &quot;value&quot;\n         3) &quot;type&quot;\n         4) &quot;string&quot;\n         5) &quot;value&quot;\n         6) &quot;value&quot;\n</code></pre>\n"
  },
  {
    "id": "command-tips",
    "topicName": "Command tips",
    "description": "Get additional information about a command",
    "htmlContent": "<p>This page documents a small part of the reply of the <a href=\"../command\"><code>COMMAND</code></a>.<br>In the reply of the COMMAND command, each command is represented by an array.<br>The 8th element in this array is the command tips.<br>It&#39;s an array of strings.</p>\n<p>These provide Valkey clients with additional information about the command.<br>The information can instruct Valkey Cluster clients as to how the command should be executed and its output processed in a clustered deployment.</p>\n<p>Unlike the command&#39;s flags (see the 3rd element of <a href=\"../command\"><code>COMMAND</code></a>&#39;s reply), which are strictly internal to the server&#39;s operation, tips don&#39;t serve any purpose other than being reported to clients.</p>\n<h2><code>nondeterministic_output</code></h2>\n<p>This tip indicates that the command&#39;s output isn&#39;t deterministic.<br>That means that calls to the command may yield different results with the same arguments and data.<br>That difference could be the result of the command&#39;s random nature (e.g., <code>RANDOMKEY</code> and <code>SPOP</code>); the call&#39;s timing (e.g., <code>TTL</code>); or generic differences that relate to the server&#39;s state (e.g., <code>INFO</code> and <code>CLIENT LIST</code>).</p>\n<p><strong>Note:</strong><br>Prior to Redis OSS 7.0, this tip was the <code>random</code> command flag.</p>\n<h2><code>nondeterministic_output_order</code></h2>\n<p>The existence of this tip indicates that the command&#39;s output is deterministic, but its ordering is random (e.g., <code>HGETALL</code> and <code>SMEMBERS</code>).</p>\n<p><strong>Note:</strong><br>Prior to Redis OSS 7.0, this tip was the <code>sort_for_script</code> flag.</p>\n<h2><code>request_policy:</code><em>value</em></h2>\n<p>This tip can help clients determine the shards to send the command in clustering mode.<br>The default behavior a client should implement for commands without the <code>request_policy</code> tip is as follows:</p>\n<ol>\n<li>The command doesn&#39;t accept key name arguments: the client can execute the command on an arbitrary shard.</li>\n<li>For commands that accept one or more key name arguments: the client should route the command to a single shard, as determined by the hash slot of the input keys.</li>\n</ol>\n<p>In cases where the client should adopt a behavior different than the default, the <code>request_policy</code> tip can be one of:</p>\n<ul>\n<li><strong>all_nodes:</strong> the client should execute the command on all nodes - primaries and replicas alike.<br>An example is the <code>CONFIG SET</code> command.<br>This tip is in-use by commands that don&#39;t accept key name arguments.<br>The command operates atomically per shard.</li>\n</ul>\n<ul>\n<li><strong>all_shards:</strong> the client should execute the command on all primary shards (e.g., the <code>DBSIZE</code> command).<br>This tip is in-use by commands that don&#39;t accept key name arguments.<br>The command operates atomically per shard.</li>\n</ul>\n<ul>\n<li><strong>multi_shard:</strong> the client should execute the command on several shards.<br>The client should split the inputs according to the hash slots of its input key name arguments.<br>For example, the command <code>DEL {foo} {foo}1 bar</code> should be split to <code>DEL {foo} {foo}1</code> and <code>DEL bar</code>.<br>If the keys are hashed to more than a single slot, the command must be split even if all the slots are managed by the same shard.<br>Examples for such commands include <code>MSET</code>, <code>MGET</code> and <code>DEL</code>.<br>However, note that <code>SUNIONSTORE</code> isn&#39;t considered as <em>multi_shard</em> because all of its keys must belong to the same hash slot.</li>\n<li><strong>special:</strong> indicates a non-trivial form of the client&#39;s request policy, such as the <code>SCAN</code> command.</li>\n</ul>\n<h2><code>response_policy:</code><em>value</em></h2>\n<p>This tip can help clients determine the aggregate they need to compute from the replies of multiple shards in a cluster.<br>The default behavior for commands without a <code>request_policy</code> tip only applies to replies with of nested types (i.e., an array, a set, or a map).<br>The client&#39;s implementation for the default behavior should be as follows:</p>\n<ol>\n<li>The command doesn&#39;t accept key name arguments: the client can aggregate all replies within a single nested data structure.<br>For example, the array replies we get from calling <code>KEYS</code> against all shards.<br>These should be packed in a single in no particular order.</li>\n<li>For commands that accept one or more key name arguments: the client needs to retain the same order of replies as the input key names.<br>For example, <code>MGET</code>&#39;s aggregated reply.</li>\n</ol>\n<p>The <code>response_policy</code> tip is set for commands that reply with scalar data types, or when it&#39;s expected that clients implement a non-default aggregate.<br>This tip can be one of:</p>\n<ul>\n<li><strong>one_succeeded:</strong> the clients should return success if at least one shard didn&#39;t reply with an error.<br>The client should reply with the first non-error reply it obtains.<br>If all shards return an error, the client can reply with any one of these.<br>For example, consider a <code>SCRIPT KILL</code> command that&#39;s sent to all shards.<br>Although the script should be loaded in all of the cluster&#39;s shards, the <code>SCRIPT KILL</code> will typically run only on one at a given time.</li>\n<li><strong>all_succeeded:</strong> the client should return successfully only if there are no error replies.<br>Even a single error reply should disqualify the aggregate and be returned.<br>Otherwise, the client should return one of the non-error replies.<br>As an example, consider the <code>CONFIG SET</code>, <code>SCRIPT FLUSH</code> and <code>SCRIPT LOAD</code> commands.</li>\n<li><strong>agg_logical_and:</strong> the client should return the result of a logical <em>AND</em> operation on all replies (only applies to integer replies, usually from commands that return either <em>0</em> or <em>1</em>).<br>Consider the <code>SCRIPT EXISTS</code> command as an example.<br>It returns an array of <em>0</em>&#39;s and <em>1</em>&#39;s that denote the existence of its given SHA1 sums in the script cache.<br>The aggregated response should be <em>1</em> only when all shards had reported that a given script SHA1 sum is in their respective cache.</li>\n<li><strong>agg_logical_or:</strong> the client should return the result of a logical <em>AND</em> operation on all replies (only applies to integer replies, usually from commands that return either <em>0</em> or <em>1</em>).</li>\n<li><strong>agg_min:</strong> the client should return the minimal value from the replies (only applies to numerical replies).<br>The aggregate reply from a cluster-wide <code>WAIT</code> command, for example, should be the minimal value (number of synchronized replicas) from all shards.</li>\n<li><strong>agg_max:</strong> the client should return the maximal value from the replies (only applies to numerical replies).</li>\n<li><strong>agg_sum:</strong> the client should return the sum of replies (only applies to numerical replies).<br>Example: <code>DBSIZE</code>.</li>\n<li><strong>special:</strong> this type of tip indicates a non-trivial form of reply policy.<br><code>INFO</code> is an excellent example of that.</li>\n</ul>\n<h2>Example</h2>\n<pre><code>127.0.0.1:6379&gt; command info ping\n1)  1) &quot;ping&quot;\n    2) (integer) -1\n    3) 1) fast\n    4) (integer) 0\n    5) (integer) 0\n    6) (integer) 0\n    7) 1) @fast\n       2) @connection\n    8) 1) &quot;request_policy:all_shards&quot;\n       2) &quot;response_policy:all_succeeded&quot;\n    9) (empty array)\n   10) (empty array)\n</code></pre>\n"
  },
  {
    "id": "data-types",
    "topicName": "Data types",
    "description": "Overview of data types supported by Valkey",
    "htmlContent": "<p>Valkey is a data structure server.<br>At its core, Valkey provides a collection of native data types that help you solve a wide variety of problems, from <a href=\"client-side-caching\">caching</a> to <a href=\"lists\">queuing</a> to <a href=\"streams-intro\">event processing</a>.<br>Below is a short description of each data type, with links to broader overviews and command references.</p>\n<p>If you&#39;d like to try a comprehensive tutorial for each data structure, see their overview pages below.</p>\n<h2>Strings</h2>\n<p><a href=\"strings\">Strings</a> are the most basic Valkey data type, representing a sequence of bytes.<br>For more information, see:</p>\n<ul>\n<li><a href=\"strings\">Overview of Strings</a></li>\n<li><a href=\"../commands/#string\">String command reference</a></li>\n</ul>\n<h2>Lists</h2>\n<p><a href=\"lists\">Lists</a> are lists of strings sorted by insertion order.<br>For more information, see:</p>\n<ul>\n<li><a href=\"lists\">Overview of Lists</a></li>\n<li><a href=\"../commands/#list\">List command reference</a></li>\n</ul>\n<h2>Sets</h2>\n<p><a href=\"sets\">Sets</a> are unordered collections of unique strings that act like the sets from your favorite programming language (for example, <a href=\"https://docs.oracle.com/javase/7/docs/api/java/util/HashSet.html\">Java HashSets</a>, <a href=\"https://docs.python.org/3.10/library/stdtypes.html#set-types-set-frozenset\">Python sets</a>, and so on).<br>With a Set, you can add, remove, and test for existence in O(1) time (in other words, regardless of the number of set elements).<br>For more information, see:</p>\n<ul>\n<li><a href=\"sets\">Overview of Sets</a></li>\n<li><a href=\"../commands/#set\">Set command reference</a></li>\n</ul>\n<h2>Hashes</h2>\n<p><a href=\"hashes\">Hashes</a> are record types modeled as collections of field-value pairs.<br>As such, Hashes resemble <a href=\"https://docs.python.org/3/tutorial/datastructures.html#dictionaries\">Python dictionaries</a>, <a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/HashMap.html\">Java HashMaps</a>, and <a href=\"https://ruby-doc.org/core-3.1.2/Hash.html\">Ruby hashes</a>.<br>For more information, see:</p>\n<ul>\n<li><a href=\"hashes\">Overview of Hashes</a></li>\n<li><a href=\"../commands/#hash\">Hashes command reference</a></li>\n</ul>\n<h2>Sorted sets</h2>\n<p><a href=\"sorted-sets\">Sorted Sets</a> are collections of unique strings that maintain order by each string&#39;s associated score.<br>For more information, see:</p>\n<ul>\n<li><a href=\"sorted-sets\">Overview of Sorted Sets</a></li>\n<li><a href=\"../commands/#sorted-set\">Sorted Set command reference</a></li>\n</ul>\n<h2>Streams</h2>\n<p>A <a href=\"streams-intro\">Stream</a> is a data structure that acts like an append-only log.<br>Streams help record events in the order they occur and then syndicate them for processing.<br>For more information, see:</p>\n<ul>\n<li><a href=\"streams-intro\">Overview of Streams</a></li>\n<li><a href=\"../commands/#stream\">Streams command reference</a></li>\n</ul>\n<h2>Geospatial indexes</h2>\n<p><a href=\"geospatial\">Geospatial indexes</a> are useful for finding locations within a given geographic radius or bounding box.<br>For more information, see:</p>\n<ul>\n<li><a href=\"geospatial\">Overview of Geospatial indexes</a></li>\n<li><a href=\"../commands/#geo\">Geospatial indexes command reference</a></li>\n</ul>\n<h2>Bitmaps</h2>\n<p><a href=\"bitmaps\">Bitmaps</a> let you perform bitwise operations on strings.<br>For more information, see:</p>\n<ul>\n<li><a href=\"bitmaps\">Overview of Bitmaps</a></li>\n<li><a href=\"../commands/#bitmap\">Bitmap command reference</a></li>\n</ul>\n<h2>Bitfields</h2>\n<p><a href=\"bitfields\">Bitfields</a> efficiently encode multiple counters in a string value.<br>Bitfields provide atomic get, set, and increment operations and support different overflow policies.<br>For more information, see:</p>\n<ul>\n<li><a href=\"bitfields\">Overview of Bitfields</a></li>\n<li>The <code>BITFIELD</code> command.</li>\n</ul>\n<h2>HyperLogLog</h2>\n<p>The <a href=\"hyperloglogs\">HyperLogLog</a> data structures provide probabilistic estimates of the cardinality (i.e., number of elements) of large sets. For more information, see:</p>\n<ul>\n<li><a href=\"hyperloglogs\">Overview of HyperLogLog</a></li>\n<li><a href=\"../commands/#hyperloglog\">HyperLogLog command reference</a></li>\n</ul>\n<h2>Extensions</h2>\n<p>To extend the features provided by the included data types, use one of these options:</p>\n<ol>\n<li>Write your own custom <a href=\"programmability\">server-side functions in Lua</a>.</li>\n<li>Write your own Valkey module using the <a href=\"modules-intro\">modules API</a> or check out the <a href=\"../modules/\">modules</a>.</li>\n</ol>\n"
  },
  {
    "id": "debugging",
    "topicName": "Debugging",
    "description": "A guide to debugging Valkey server processes\n",
    "htmlContent": "<p>Valkey is developed with an emphasis on stability. We do our best with<br>every release to make sure you&#39;ll experience a stable product with no<br>crashes. However, if you ever need to debug the Valkey process itself, read on.</p>\n<p>When Valkey crashes, it produces a detailed report of what happened. However,<br>sometimes looking at the crash report is not enough, nor is it possible for<br>the Valkey core team to reproduce the issue independently. In this scenario, we<br>need help from the user who can reproduce the issue.</p>\n<p>This guide shows how to use GDB to provide the information the<br>Valkey developers will need to track the bug more easily.</p>\n<h2>What is GDB?</h2>\n<p>GDB is the Gnu Debugger: a program that is able to inspect the internal state<br>of another program. Usually tracking and fixing a bug is an exercise in<br>gathering more information about the state of the program at the moment the<br>bug happens, so GDB is an extremely useful tool.</p>\n<p>GDB can be used in two ways:</p>\n<ul>\n<li>It can attach to a running program and inspect the state of it at runtime.</li>\n<li>It can inspect the state of a program that already terminated using what is called a <em>core file</em>, that is, the image of the memory at the time the program was running.</li>\n</ul>\n<p>From the point of view of investigating Valkey bugs we need to use both of these<br>GDB modes. The user able to reproduce the bug attaches GDB to their running Valkey<br>instance, and when the crash happens, they create the <code>core</code> file that in turn<br>the developer will use to inspect the Valkey internals at the time of the crash.</p>\n<p>This way the developer can perform all the inspections in his or her computer<br>without the help of the user, and the user is free to restart Valkey in their<br>production environment.</p>\n<h2>Compiling Valkey without optimizations</h2>\n<p>By default, Valkey is compiled with the <code>-O3</code> optimization flag, which enables<br>a high level of compiler optimizations that aim to maximize runtime performance.<br>Valkey is also compiled with the <code>-fno-omit-frame-pointer</code> flag by default, ensuring that<br>the frame pointer is preserved across function calls. This combination allows for<br>precise stack walking and call stack tracing, which is essential for debugging.</p>\n<p>It is better to attach GDB to Valkey compiled without optimizations using the<br><code>make noopt</code> command (instead of just using the plain <code>make</code> command). However,<br>if you have an already running Valkey in production there is no need to recompile<br>and restart it if this is going to create problems on your side. GDB still works<br>against executables compiled with optimizations.</p>\n<p>You should not be overly concerned at the loss of performance from compiling Valkey<br>without optimizations. It is unlikely that this will cause problems in your<br>environment as Valkey is not very CPU-bound.</p>\n<h2>Attaching GDB to a running process</h2>\n<p>If you have an already running Valkey server, you can attach GDB to it, so that<br>if Valkey crashes it will be possible to both inspect the internals and generate<br>a <code>core dump</code> file.</p>\n<p>After you attach GDB to the Valkey process it will continue running as usual without<br>any loss of performance, so this is not a dangerous procedure.</p>\n<p>In order to attach GDB the first thing you need is the <em>process ID</em> of the running<br>Valkey instance (the <em>pid</em> of the process). You can easily obtain it using<br><code>valkey-cli</code>:</p>\n<pre><code>$ valkey-cli info | grep process_id\nprocess_id:58414\n</code></pre>\n<p>In the above example the process ID is <strong>58414</strong>.</p>\n<p>Login into your Valkey server.</p>\n<p>(Optional but recommended) Start <strong>screen</strong> or <strong>tmux</strong> or any other program that will make sure that your GDB session will not be closed if your ssh connection times out. You can learn more about screen in <a href=\"https://www.linuxjournal.com/article/6340\">this article</a>.</p>\n<p>Attach GDB to the running Valkey server by typing:</p>\n<pre><code>$ gdb &lt;path-to-valkey-executable&gt; &lt;pid&gt;\n</code></pre>\n<p>For example:</p>\n<pre><code>$ gdb /usr/local/bin/valkey-server 58414\n</code></pre>\n<p>GDB will start and will attach to the running server printing something like the following:</p>\n<pre><code>Reading symbols for shared libraries + done\n0x00007fff8d4797e6 in epoll_wait ()\n(gdb)\n</code></pre>\n<p>At this point GDB is attached but <strong>your Valkey instance is blocked by GDB</strong>. In<br>order to let the Valkey instance continue the execution just type <strong>continue</strong> at<br>the GDB prompt, and press enter.</p>\n<pre><code>(gdb) continue\nContinuing.\n</code></pre>\n<p>Done! Now your Valkey instance has GDB attached. Now you can wait for the next crash. :)</p>\n<p>Now it&#39;s time to detach your screen/tmux session, if you are running GDB using it, by<br>pressing <strong>Ctrl-a a</strong> key combination.</p>\n<h2>After the crash</h2>\n<p>Valkey has a command to simulate a segmentation fault (in other words a bad crash) using<br>the <code>DEBUG SEGFAULT</code> command (don&#39;t use it against a real production instance of course!<br>So I&#39;ll use this command to crash my instance to show what happens in the GDB side:</p>\n<pre><code>(gdb) continue\nContinuing.\n\nProgram received signal EXC_BAD_ACCESS, Could not access memory.\nReason: KERN_INVALID_ADDRESS at address: 0xffffffffffffffff\ndebugCommand (c=0x7ffc32005000) at debug.c:220\n220         *((char*)-1) = &#39;x&#39;;\n</code></pre>\n<p>As you can see GDB detected that Valkey crashed, and was even able to show me<br>the file name and line number causing the crash. This is already much better<br>than the Valkey crash report back trace (containing just function names and<br>binary offsets).</p>\n<h2>Obtaining the stack trace</h2>\n<p>The first thing to do is to obtain a full stack trace with GDB. This is as<br>simple as using the <strong>bt</strong> command:</p>\n<pre><code>(gdb) bt\n#0  debugCommand (c=0x7ffc32005000) at debug.c:220\n#1  0x000000010d246d63 in call (c=0x7ffc32005000) at valkey.c:1163\n#2  0x000000010d247290 in processCommand (c=0x7ffc32005000) at valkey.c:1305\n#3  0x000000010d251660 in processInputBuffer (c=0x7ffc32005000) at networking.c:959\n#4  0x000000010d251872 in readQueryFromClient (el=0x0, fd=5, privdata=0x7fff76f1c0b0, mask=220924512) at networking.c:1021\n#5  0x000000010d243523 in aeProcessEvents (eventLoop=0x7fff6ce408d0, flags=220829559) at ae.c:352\n#6  0x000000010d24373b in aeMain (eventLoop=0x10d429ef0) at ae.c:397\n#7  0x000000010d2494ff in main (argc=1, argv=0x10d2b2900) at valkey.c:2046\n</code></pre>\n<p>This shows the backtrace, but we also want to dump the processor registers using the <strong>info registers</strong> command:</p>\n<pre><code>(gdb) info registers\nrax            0x0  0\nrbx            0x7ffc32005000   140721147367424\nrcx            0x10d2b0a60  4515891808\nrdx            0x7fff76f1c0b0   140735188943024\nrsi            0x10d299777  4515796855\nrdi            0x0  0\nrbp            0x7fff6ce40730   0x7fff6ce40730\nrsp            0x7fff6ce40650   0x7fff6ce40650\nr8             0x4f26b3f7   1327936503\nr9             0x7fff6ce40718   140735020271384\nr10            0x81 129\nr11            0x10d430398  4517462936\nr12            0x4b7c04f8babc0  1327936503000000\nr13            0x10d3350a0  4516434080\nr14            0x10d42d9f0  4517452272\nr15            0x10d430398  4517462936\nrip            0x10d26cfd4  0x10d26cfd4 &lt;debugCommand+68&gt;\neflags         0x10246  66118\ncs             0x2b 43\nss             0x0  0\nds             0x0  0\nes             0x0  0\nfs             0x0  0\ngs             0x0  0\n</code></pre>\n<p>Please <strong>make sure to include</strong> both of these outputs in your bug report.</p>\n<h2>Obtaining the core file</h2>\n<p>The next step is to generate the core dump, that is the image of the memory of the running Valkey process. This is done using the <code>gcore</code> command:</p>\n<pre><code>(gdb) gcore\nSaved corefile core.58414\n</code></pre>\n<p>Now you have the core dump to send to the Valkey developer, but <strong>it is important<br>to understand</strong> that this happens to contain all the data that was inside the<br>Valkey instance at the time of the crash; Valkey developers will make sure not to<br>share the content with anyone else, and will delete the file as soon as it is no<br>longer used for debugging purposes, but you are warned that by sending the core<br>file you are sending your data.</p>\n<h2>What to send to developers</h2>\n<p>Finally you can send everything to the Valkey core team:</p>\n<ul>\n<li>The Valkey executable you are using.</li>\n<li>The stack trace produced by the <strong>bt</strong> command, and the registers dump.</li>\n<li>The core file you generated with gdb.</li>\n<li>Information about the operating system and GCC version, and Valkey version you are using.</li>\n</ul>\n<h2>Thank you</h2>\n<p>Your help is extremely important! Many issues can only be tracked this way. So<br>thanks!</p>\n"
  },
  {
    "id": "distlock",
    "topicName": "Distributed Locks",
    "description": "A distributed lock pattern with Valkey\n",
    "htmlContent": "<p>Distributed locks are a very useful primitive in many environments where<br>different processes must operate with shared resources in a mutually<br>exclusive way.</p>\n<p>There are a number of libraries and blog posts describing how to implement<br>a DLM (Distributed Lock Manager) with Valkey, but every library uses a different<br>approach, and many use a simple approach with lower guarantees compared to<br>what can be achieved with slightly more complex designs.</p>\n<p>This page describes a more canonical algorithm to implement<br>distributed locks with Valkey. We propose an algorithm, called <strong>Redlock</strong>,<br>which implements a DLM which we believe to be safer than the vanilla single<br>instance approach. We hope that the community will analyze it, provide<br>feedback, and use it as a starting point for the implementations or more<br>complex or alternative designs.</p>\n<h2>Implementations</h2>\n<p>Before describing the algorithm, here are a few links to implementations<br>already available that can be used for reference.</p>\n<ul>\n<li><a href=\"https://github.com/antirez/redlock-rb\">Redlock-rb</a> (Ruby implementation). There is also a <a href=\"https://github.com/leandromoreira/redlock-rb\">fork of Redlock-rb</a> that adds a gem for easy distribution.</li>\n<li><a href=\"https://github.com/SPSCommerce/redlock-py\">Redlock-py</a> (Python implementation).</li>\n<li><a href=\"https://github.com/brainix/pottery#redlock\">Pottery</a> (Python implementation).</li>\n<li><a href=\"https://github.com/joanvila/aioredlock\">Aioredlock</a> (Asyncio Python implementation).</li>\n<li><a href=\"https://github.com/malkusch/lock#redismutex\">RedisMutex</a> (PHP implementation with both <a href=\"https://github.com/phpredis/phpredis\">Redis extension</a> and <a href=\"https://github.com/predis/predis\">Predis library</a> clients support).</li>\n<li><a href=\"https://github.com/ronnylt/redlock-php\">Redlock-php</a> (PHP implementation).</li>\n<li><a href=\"https://github.com/cheprasov/php-redis-lock\">cheprasov/php-redis-lock</a> (PHP library for locks).</li>\n<li><a href=\"https://github.com/rtckit/reactphp-redlock\">rtckit/react-redlock</a> (Async PHP implementation).</li>\n<li><a href=\"https://github.com/go-redsync/redsync\">Redsync</a> (Go implementation).</li>\n<li><a href=\"https://github.com/mrniko/redisson\">Redisson</a> (Java implementation).</li>\n<li><a href=\"https://github.com/sbertrang/redis-distlock\">Redis::DistLock</a> (Perl implementation).</li>\n<li><a href=\"https://github.com/jacket-code/redlock-cpp\">Redlock-cpp</a> (C++ implementation).</li>\n<li><a href=\"https://github.com/sewenew/redis-plus-plus/#redlock\">Redis-plus-plus</a> (C++ implementation).</li>\n<li><a href=\"https://github.com/kidfashion/redlock-cs\">Redlock-cs</a> (C#/.NET implementation).</li>\n<li><a href=\"https://github.com/samcook/RedLock.net\">RedLock.net</a> (C#/.NET implementation). Includes async and lock extension support.</li>\n<li><a href=\"https://github.com/psibernetic/scarletlock\">ScarletLock</a> (C# .NET implementation with configurable datastore).</li>\n<li><a href=\"https://github.com/LiZhenNet/Redlock4Net\">Redlock4Net</a> (C# .NET implementation).</li>\n<li><a href=\"https://github.com/mike-marcacci/node-redlock\">node-redlock</a> (NodeJS implementation). Includes support for lock extension.</li>\n<li><a href=\"https://github.com/oslabs-beta/Deno-Redlock\">Deno DLM</a> (Deno implementation)</li>\n<li><a href=\"https://github.com/hexcowboy/rslock\">Rslock</a> (Rust implementation). Includes async and lock extension support.</li>\n</ul>\n<h2>Safety and Liveness Guarantees</h2>\n<p>We are going to model our design with just three properties that, from our point of view, are the minimum guarantees needed to use distributed locks in an effective way.</p>\n<ol>\n<li>Safety property: Mutual exclusion. At any given moment, only one client can hold a lock.</li>\n<li>Liveness property A: Deadlock free. Eventually it is always possible to acquire a lock, even if the client that locked a resource crashes or gets partitioned.</li>\n<li>Liveness property B: Fault tolerance. As long as the majority of Valkey nodes are up, clients are able to acquire and release locks.</li>\n</ol>\n<h2>Why Failover-based Implementations Are Not Enough</h2>\n<p>To understand what we want to improve, let’s analyze the current state of affairs with most Valkey-based distributed lock libraries.</p>\n<p>The simplest way to use Valkey to lock a resource is to create a key in an instance. The key is usually created with a limited time to live, using the Valkey expires feature, so that eventually it will get released (property 2 in our list). When the client needs to release the resource, it deletes the key.</p>\n<p>Superficially this works well, but there is a problem: this is a single point of failure in our architecture. What happens if the Valkey primary goes down?</p>\n<p>Well, let’s add a replica! And use it if the primary is unavailable. This is unfortunately not viable. By doing so we can’t implement our safety property of mutual exclusion, because Valkey replication is asynchronous.</p>\n<p>There is a race condition with this model:</p>\n<ol>\n<li>Client A acquires the lock in the primary.</li>\n<li>The primary crashes before the write to the key is transmitted to the replica.</li>\n<li>The replica gets promoted to primary.</li>\n<li>Client B acquires the lock to the same resource A already holds a lock for. <strong>SAFETY VIOLATION!</strong></li>\n</ol>\n<p>Sometimes it is perfectly fine that, under special circumstances, for example during a failure, multiple clients can hold the lock at the same time.<br>If this is the case, you can use your replication based solution. Otherwise we suggest to implement the solution described in this document.</p>\n<h2>Correct Implementation with a Single Instance</h2>\n<p>Before trying to overcome the limitation of the single instance setup described above, let’s check how to do it correctly in this simple case, since this is actually a viable solution in applications where a race condition from time to time is acceptable, and because locking into a single instance is the foundation we’ll use for the distributed algorithm described here.</p>\n<p>To acquire the lock, the way to go is the following:</p>\n<pre><code>    SET resource_name my_random_value NX PX 30000\n</code></pre>\n<p>The command will set the key only if it does not already exist (<code>NX</code> option), with an expire of 30000 milliseconds (<code>PX</code> option).<br>The key is set to a value “my_random_value”. This value must be unique across all clients and all lock requests.</p>\n<p>Basically the random value is used in order to release the lock in a safe way, with a script that tells Valkey: remove the key only if it exists and the value stored at the key is exactly the one I expect to be. This is accomplished by the following Lua script:</p>\n<pre><code>if server.call(&quot;get&quot;,KEYS[1]) == ARGV[1] then\n    return server.call(&quot;del&quot;,KEYS[1])\nelse\n    return 0\nend\n</code></pre>\n<p>This is important in order to avoid removing a lock that was created by another client. For example a client may acquire the lock, get blocked performing some operation for longer than the lock validity time (the time at which the key will expire), and later remove the lock, that was already acquired by some other client.<br>Using just <code>DEL</code> is not safe as a client may remove another client&#39;s lock. With the above script instead every lock is “signed” with a random string, so the lock will be removed only if it is still the one that was set by the client trying to remove it.</p>\n<p>What should this random string be? We assume it’s 20 bytes from <code>/dev/urandom</code>, but you can find cheaper ways to make it unique enough for your tasks.<br>For example a safe pick is to seed RC4 with <code>/dev/urandom</code>, and generate a pseudo random stream from that.<br>A simpler solution is to use a UNIX timestamp with microsecond precision, concatenating the timestamp with a client ID. It is not as safe, but probably sufficient for most environments.</p>\n<p>The &quot;lock validity time&quot; is the time we use as the key&#39;s time to live. It is both the auto release time, and the time the client has in order to perform the operation required before another client may be able to acquire the lock again, without technically violating the mutual exclusion guarantee, which is only limited to a given window of time from the moment the lock is acquired.</p>\n<p>So now we have a good way to acquire and release the lock. With this system, reasoning about a non-distributed system composed of a single, always available, instance, is safe. Let’s extend the concept to a distributed system where we don’t have such guarantees.</p>\n<h2>The Redlock Algorithm</h2>\n<p>In the distributed version of the algorithm we assume we have N Valkey primaries. Those nodes are totally independent, so we don’t use replication or any other implicit coordination system. We already described how to acquire and release the lock safely in a single instance. We take for granted that the algorithm will use this method to acquire and release the lock in a single instance. In our examples we set N=5, which is a reasonable value, so we need to run 5 Valkey primaries on different computers or virtual machines in order to ensure that they’ll fail in a mostly independent way.</p>\n<p>In order to acquire the lock, the client performs the following operations:</p>\n<ol>\n<li>It gets the current time in milliseconds.</li>\n<li>It tries to acquire the lock in all the N instances sequentially, using the same key name and random value in all the instances. During step 2, when setting the lock in each instance, the client uses a timeout which is small compared to the total lock auto-release time in order to acquire it. For example if the auto-release time is 10 seconds, the timeout could be in the ~ 5-50 milliseconds range. This prevents the client from remaining blocked for a long time trying to talk with a Valkey node which is down: if an instance is not available, we should try to talk with the next instance ASAP.</li>\n<li>The client computes how much time elapsed in order to acquire the lock, by subtracting from the current time the timestamp obtained in step 1. If and only if the client was able to acquire the lock in the majority of the instances (at least 3), and the total time elapsed to acquire the lock is less than lock validity time, the lock is considered to be acquired.</li>\n<li>If the lock was acquired, its validity time is considered to be the initial validity time minus the time elapsed, as computed in step 3.</li>\n<li>If the client failed to acquire the lock for some reason (either it was not able to lock N/2+1 instances or the validity time is negative), it will try to unlock all the instances (even the instances it believed it was not able to lock).</li>\n</ol>\n<h3>Is the Algorithm Asynchronous?</h3>\n<p>The algorithm relies on the assumption that while there is no synchronized clock across the processes, the local time in every process updates at approximately at the same rate, with a small margin of error compared to the auto-release time of the lock. This assumption closely resembles a real-world computer: every computer has a local clock and we can usually rely on different computers to have a clock drift which is small.</p>\n<p>At this point we need to better specify our mutual exclusion rule: it is guaranteed only as long as the client holding the lock terminates its work within the lock validity time (as obtained in step 3), minus some time (just a few milliseconds in order to compensate for clock drift between processes).</p>\n<p>This paper contains more information about similar systems requiring a bound <em>clock drift</em>: <a href=\"https://dl.acm.org/citation.cfm?id=74870\">Leases: an efficient fault-tolerant mechanism for distributed file cache consistency</a>.</p>\n<h3>Retry on Failure</h3>\n<p>When a client is unable to acquire the lock, it should try again after a random delay in order to try to desynchronize multiple clients trying to acquire the lock for the same resource at the same time (this may result in a split brain condition where nobody wins). Also the faster a client tries to acquire the lock in the majority of Valkey instances, the smaller the window for a split brain condition (and the need for a retry), so ideally the client should try to send the <code>SET</code> commands to the N instances at the same time using multiplexing.</p>\n<p>It is worth stressing how important it is for clients that fail to acquire the majority of locks, to release the (partially) acquired locks ASAP, so that there is no need to wait for key expiry in order for the lock to be acquired again (however if a network partition happens and the client is no longer able to communicate with the Valkey instances, there is an availability penalty to pay as it waits for key expiration).</p>\n<h3>Releasing the Lock</h3>\n<p>Releasing the lock is simple, and can be performed whether or not the client believes it was able to successfully lock a given instance.</p>\n<h3>Safety Arguments</h3>\n<p>Is the algorithm safe? Let&#39;s examine what happens in different scenarios.</p>\n<p>To start let’s assume that a client is able to acquire the lock in the majority of instances. All the instances will contain a key with the same time to live. However, the key was set at different times, so the keys will also expire at different times. But if the first key was set at worst at time T1 (the time we sample before contacting the first server) and the last key was set at worst at time T2 (the time we obtained the reply from the last server), we are sure that the first key to expire in the set will exist for at least <code>MIN_VALIDITY=TTL-(T2-T1)-CLOCK_DRIFT</code>. All the other keys will expire later, so we are sure that the keys will be simultaneously set for at least this time.</p>\n<p>During the time that the majority of keys are set, another client will not be able to acquire the lock, since N/2+1 SET NX operations can’t succeed if N/2+1 keys already exist. So if a lock was acquired, it is not possible to re-acquire it at the same time (violating the mutual exclusion property).</p>\n<p>However we want to also make sure that multiple clients trying to acquire the lock at the same time can’t simultaneously succeed.</p>\n<p>If a client locked the majority of instances using a time near, or greater, than the lock maximum validity time (the TTL we use for SET basically), it will consider the lock invalid and will unlock the instances, so we only need to consider the case where a client was able to lock the majority of instances in a time which is less than the validity time. In this case for the argument already expressed above, for <code>MIN_VALIDITY</code> no client should be able to re-acquire the lock. So multiple clients will be able to lock N/2+1 instances at the same time (with &quot;time&quot; being the end of Step 2) only when the time to lock the majority was greater than the TTL time, making the lock invalid.</p>\n<h3>Liveness Arguments</h3>\n<p>The system liveness is based on three main features:</p>\n<ol>\n<li>The auto release of the lock (since keys expire): eventually keys are available again to be locked.</li>\n<li>The fact that clients, usually, will cooperate removing the locks when the lock was not acquired, or when the lock was acquired and the work terminated, making it likely that we don’t have to wait for keys to expire to re-acquire the lock.</li>\n<li>The fact that when a client needs to retry a lock, it waits a time which is comparably greater than the time needed to acquire the majority of locks, in order to probabilistically make split brain conditions during resource contention unlikely.</li>\n</ol>\n<p>However, we pay an availability penalty equal to <code>TTL</code> time on network partitions, so if there are continuous partitions, we can pay this penalty indefinitely.<br>This happens every time a client acquires a lock and gets partitioned away before being able to remove the lock.</p>\n<p>Basically if there are infinite continuous network partitions, the system may become not available for an infinite amount of time.</p>\n<h3>Performance, Crash Recovery and fsync</h3>\n<p>Many users using Valkey as a lock server need high performance in terms of both latency to acquire and release a lock, and number of acquire / release operations that it is possible to perform per second. In order to meet this requirement, the strategy to talk with the N Valkey servers to reduce latency is definitely multiplexing (putting the socket in non-blocking mode, send all the commands, and read all the commands later, assuming that the RTT between the client and each instance is similar).</p>\n<p>However there is another consideration around persistence if we want to target a crash-recovery system model.</p>\n<p>Basically to see the problem here, let’s assume we configure Valkey without persistence at all. A client acquires the lock in 3 of 5 instances. One of the instances where the client was able to acquire the lock is restarted, at this point there are again 3 instances that we can lock for the same resource, and another client can lock it again, violating the safety property of exclusivity of lock.</p>\n<p>If we enable AOF persistence, things will improve quite a bit. For example we can upgrade a server by sending it a <code>SHUTDOWN</code> command and restarting it. Because Valkey expires are semantically implemented so that time still elapses when the server is off, all our requirements are fine.<br>However everything is fine as long as it is a clean shutdown. What about a power outage? If Valkey is configured, as by default, to fsync on disk every second, it is possible that after a restart our key is missing. In theory, if we want to guarantee the lock safety in the face of any kind of instance restart, we need to enable <code>fsync=always</code> in the persistence settings. This will affect performance due to the additional sync overhead.</p>\n<p>However things are better than they look like at a first glance. Basically,<br>the algorithm safety is retained as long as when an instance restarts after a<br>crash, it no longer participates to any <strong>currently active</strong> lock.  This means that the<br>set of currently active locks when the instance restarts were all obtained<br>by locking instances other than the one which is rejoining the system.</p>\n<p>To guarantee this we just need to make an instance, after a crash, unavailable<br>for at least a bit more than the max <code>TTL</code> we use.  This is the time needed<br>for all the keys about the locks that existed when the instance crashed to<br>become invalid and be automatically released.</p>\n<p>Using <em>delayed restarts</em> it is basically possible to achieve safety even<br>without any kind of Valkey persistence available, however note that this may<br>translate into an availability penalty. For example if a majority of instances<br>crash, the system will become globally unavailable for <code>TTL</code> (here globally means<br>that no resource at all will be lockable during this time).</p>\n<h3>Making the algorithm more reliable: Extending the lock</h3>\n<p>If the work performed by clients consists of small steps, it is possible to<br>use smaller lock validity times by default, and extend the algorithm implementing<br>a lock extension mechanism. Basically the client, if in the middle of the<br>computation while the lock validity is approaching a low value, may extend the<br>lock by sending a Lua script to all the instances that extends the TTL of the key<br>if the key exists and its value is still the random value the client assigned<br>when the lock was acquired.</p>\n<p>The client should only consider the lock re-acquired if it was able to extend<br>the lock into the majority of instances, and within the validity time<br>(basically the algorithm to use is very similar to the one used when acquiring<br>the lock).</p>\n<p>However this does not technically change the algorithm, so the maximum number<br>of lock reacquisition attempts should be limited, otherwise one of the liveness<br>properties is violated.</p>\n<h3>Disclaimer about consistency</h3>\n<p>Please consider thoroughly reviewing the <a href=\"#analysis-of-redlock\">Analysis of Redlock</a> section at the end of this page.<br>Martin Kleppman&#39;s article and antirez&#39;s answer to it are very relevant.<br>If you are concerned about consistency and correctness, you should pay attention to the following topics:</p>\n<ol>\n<li>You should implement fencing tokens.<br>  This is especially important for processes that can take significant time and applies to any distributed locking system.<br>  Extending locks&#39; lifetime is also an option, but don´t assume that a lock is retained as long as the process that had acquired it is alive.</li>\n<li>Valkey is not using monotonic clock for TTL expiration mechanism.<br>  That means that a wall-clock shift may result in a lock being acquired by more than one process.<br>  Even though the problem can be mitigated by preventing admins from manually setting the server&#39;s time and setting up NTP properly, there&#39;s still a chance of this issue occurring in real life and compromising consistency.</li>\n</ol>\n<h2>Want to help?</h2>\n<p>If you are into distributed systems, it would be great to have your opinion / analysis. Also reference implementations in other languages could be great.</p>\n<p>Thanks in advance!</p>\n<h2>Analysis of Redlock</h2>\n<hr>\n<ol>\n<li>Martin Kleppmann <a href=\"https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html\">analyzed Redlock here</a>. A counterpoint to this analysis can be <a href=\"https://web.archive.org/web/20241209045142/http://antirez.com/news/101\">found here</a>.</li>\n</ol>\n"
  },
  {
    "id": "encryption",
    "topicName": "TLS",
    "description": "Valkey TLS support",
    "htmlContent": "<p>SSL/TLS is supported by Valkey as an optional feature<br>that needs to be enabled at compile time.</p>\n<h2>Getting Started</h2>\n<h3>Building</h3>\n<p>To build with TLS support you&#39;ll need OpenSSL development libraries (e.g.<br><code>libssl-dev</code> on Debian/Ubuntu).</p>\n<p>Build Valkey with the following command:</p>\n<pre><code class=\"language-sh\">make BUILD_TLS=yes\n</code></pre>\n<h3>Tests</h3>\n<p>To run Valkey test suite with TLS, you&#39;ll need TLS support for TCL (i.e.<br><code>tcl-tls</code> package on Debian/Ubuntu).</p>\n<ol>\n<li><p>Run <code>./utils/gen-test-certs.sh</code> to generate a root CA and a server<br>certificate.</p>\n</li>\n<li><p>Run <code>./runtest --tls</code> or <code>./runtest-cluster --tls</code> to run Valkey and Valkey<br>Cluster tests in TLS mode.</p>\n</li>\n</ol>\n<h3>Running manually</h3>\n<p>To manually run a Valkey server with TLS mode (assuming <code>gen-test-certs.sh</code> was<br>invoked so sample certificates/keys are available):</p>\n<pre><code>./src/valkey-server --tls-port 6379 --port 0 \\\n    --tls-cert-file ./tests/tls/valkey.crt \\\n    --tls-key-file ./tests/tls/valkey.key \\\n    --tls-ca-cert-file ./tests/tls/ca.crt\n</code></pre>\n<p>To connect to this Valkey server with <code>valkey-cli</code>:</p>\n<pre><code>./src/valkey-cli --tls \\\n    --cert ./tests/tls/valkey.crt \\\n    --key ./tests/tls/valkey.key \\\n    --cacert ./tests/tls/ca.crt\n</code></pre>\n<h3>Certificate configuration</h3>\n<p>In order to support TLS, Valkey must be configured with a X.509 certificate and a<br>private key. In addition, it is necessary to specify a CA certificate bundle<br>file or path to be used as a trusted root when validating certificates. To<br>support DH based ciphers, a DH params file can also be configured. For example:</p>\n<pre><code>tls-cert-file /path/to/valkey.crt\ntls-key-file /path/to/valkey.key\ntls-ca-cert-file /path/to/ca.crt\ntls-dh-params-file /path/to/valkey.dh\n</code></pre>\n<h3>TLS listening port</h3>\n<p>The <code>tls-port</code> configuration directive enables accepting SSL/TLS connections on<br>the specified port. This is <strong>in addition</strong> to listening on <code>port</code> for TCP<br>connections, so it is possible to access Valkey on different ports using TLS and<br>non-TLS connections simultaneously.</p>\n<p>You may specify <code>port 0</code> to disable the non-TLS port completely. To enable only<br>TLS on the default Valkey port, use:</p>\n<pre><code>port 0\ntls-port 6379\n</code></pre>\n<h3>Client certificate authentication</h3>\n<p>By default, Valkey uses mutual TLS and requires clients to authenticate with a<br>valid certificate (authenticated against trusted root CAs specified by<br><code>ca-cert-file</code> or <code>ca-cert-dir</code>).</p>\n<p>You may use <code>tls-auth-clients no</code> to disable client authentication.</p>\n<h3>Replication</h3>\n<p>A Valkey primary server handles connecting clients and replica servers in the same<br>way, so the above <code>tls-port</code> and <code>tls-auth-clients</code> directives apply to<br>replication links as well.</p>\n<p>On the replica server side, it is necessary to specify <code>tls-replication yes</code> to<br>use TLS for outgoing connections to the primary.</p>\n<h3>Cluster</h3>\n<p>When Valkey Cluster is used, use <code>tls-cluster yes</code> in order to enable TLS for the<br>cluster bus and cross-node connections.</p>\n<h3>Sentinel</h3>\n<p>Sentinel inherits its networking configuration from the common Valkey<br>configuration, so all of the above applies to Sentinel as well.</p>\n<p>When connecting to primary servers, Sentinel will use the <code>tls-replication</code><br>directive to determine if a TLS or non-TLS connection is required.</p>\n<p>In addition, the very same <code>tls-replication</code> directive will determine whether Sentinel&#39;s<br>port, that accepts connections from other Sentinels, will support TLS as well. That is,<br>Sentinel will be configured with <code>tls-port</code> if and only if <code>tls-replication</code> is enabled. </p>\n<h3>Additional configuration</h3>\n<p>Additional TLS configuration is available to control the choice of TLS protocol<br>versions, ciphers and cipher suites, etc. Please consult the self documented<br><code>valkey.conf</code> for more information.</p>\n<h3>Performance considerations</h3>\n<p>TLS adds a layer to the communication stack with overheads due to writing/reading to/from an SSL connection, encryption/decryption and integrity checks. Consequently, using TLS results in a decrease of the achievable throughput per Valkey instance.</p>\n"
  },
  {
    "id": "eval-intro",
    "topicName": "Scripting with Lua",
    "description": "Executing Lua in Valkey\n",
    "htmlContent": "<p>Valkey lets users upload and execute Lua scripts on the server.<br>Scripts can employ programmatic control structures and use most of the <a href=\"../commands/\">commands</a> while executing to access the database.<br>Because scripts execute in the server, reading and writing data from scripts is very efficient.</p>\n<p>Valkey guarantees the script&#39;s atomic execution.<br>While executing the script, all server activities are blocked during its entire runtime.<br>These semantics mean that all of the script&#39;s effects either have yet to happen or had already happened.</p>\n<p>Scripting offers several properties that can be valuable in many cases.<br>These include:</p>\n<ul>\n<li>Providing locality by executing logic where data lives. Data locality reduces overall latency and saves networking resources.</li>\n<li>Blocking semantics that ensure the script&#39;s atomic execution.</li>\n<li>Enabling the composition of simple capabilities that are either missing from Valkey or are too niche to be a part of it.</li>\n</ul>\n<p>Lua lets you run part of your application logic inside Valkey.<br>Such scripts can perform conditional updates across multiple keys, possibly combining several different data types atomically.</p>\n<p>Scripts are executed in Valkey by an embedded execution engine.<br>Presently, Valkey supports a single scripting engine, the <a href=\"https://www.lua.org/\">Lua 5.1</a> interpreter.<br>Please refer to the <a href=\"lua-api\">Valkey Lua API Reference</a> page for complete documentation.</p>\n<p>Although the server executes them, Eval scripts are regarded as a part of the client-side application, which is why they&#39;re not named, versioned, or persisted.<br>So all scripts may need to be reloaded by the application at any time if missing (after a server restart, fail-over to a replica, etc.).<br>As of version 7.0, <a href=\"functions-intro\">Valkey Functions</a> offer an alternative approach to programmability which allow the server itself to be extended with additional programmed logic.</p>\n<h2>Getting started</h2>\n<p>We&#39;ll start scripting with Valkey by using the <code>EVAL</code> command.</p>\n<p>Here&#39;s our first example:</p>\n<pre><code>&gt; EVAL &quot;return &#39;Hello, scripting!&#39;&quot; 0\n&quot;Hello, scripting!&quot;\n</code></pre>\n<p>In this example, <code>EVAL</code> takes two arguments.<br>The first argument is a string that consists of the script&#39;s Lua source code.<br>The script doesn&#39;t need to include any definitions of Lua function.<br>It is just a Lua program that will run in the Valkey engine&#39;s context.</p>\n<p>The second argument is the number of arguments that follow the script&#39;s body, starting from the third argument, representing Valkey key names.<br>In this example, we used the value <em>0</em> because we didn&#39;t provide the script with any arguments, whether the names of keys or not.</p>\n<h2>Script parameterization</h2>\n<p>It is possible, although highly ill-advised, to have the application dynamically generate script source code per its needs.<br>For example, the application could send these two entirely different, but at the same time perfectly identical scripts:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &quot;return &#39;Hello&#39;&quot; 0\n&quot;Hello&quot;\n127.0.0.1:6379&gt; EVAL &quot;return &#39;Scripting!&#39;&quot; 0\n&quot;Scripting!&quot;\n</code></pre>\n<p>Although this mode of operation isn&#39;t blocked by Valkey, it is an anti-pattern due to script cache considerations (more on the topic below).<br>Instead of having your application generate subtle variations of the same scripts, you can parametrize them and pass any arguments needed for to execute them.</p>\n<p>The following example demonstrates how to achieve the same effects as above, but via parameterization:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &quot;return ARGV[1]&quot; 0 Hello\n&quot;Hello&quot;\n127.0.0.1:6379&gt; EVAL &quot;return ARGV[1]&quot; 0 Parameterization!\n&quot;Parameterization!&quot;\n</code></pre>\n<p>At this point, it is essential to understand the distinction Valkey makes between input arguments that are names of keys and those that aren&#39;t.</p>\n<p>While key names in Valkey are just strings, unlike any other string values, these represent keys in the database.<br>The name of a key is a fundamental concept in Valkey and is the basis for operating the Valkey Cluster.</p>\n<p><strong>Important:</strong><br>to ensure the correct execution of scripts, both in standalone and clustered deployments, all names of keys that a script accesses must be explicitly provided as input key arguments.<br>The script <strong>should only</strong> access keys whose names are given as input arguments.<br>Scripts <strong>should never</strong> access keys with programmatically-generated names or based on the contents of data structures stored in the database.</p>\n<p>Any input to the function that isn&#39;t the name of a key is a regular input argument.</p>\n<p>In the example above, both <em>Hello</em> and <em>Parameterization!</em> regular input arguments for the script.<br>Because the script doesn&#39;t touch any keys, we use the numerical argument <em>0</em> to specify there are no key name arguments.<br>The execution context makes arguments available to the script through <a href=\"lua-api#the-keys-global-variable\"><em>KEYS</em></a> and <a href=\"lua-api#the-argv-global-variable\"><em>ARGV</em></a> global runtime variables.<br>The <em>KEYS</em> table is pre-populated with all key name arguments provided to the script before its execution, whereas the <em>ARGV</em> table serves a similar purpose but for regular arguments.</p>\n<p>The following attempts to demonstrate the distribution of input arguments between the scripts <em>KEYS</em> and <em>ARGV</em> runtime global variables:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &quot;return { KEYS[1], KEYS[2], ARGV[1], ARGV[2], ARGV[3] }&quot; 2 key1 key2 arg1 arg2 arg3\n1) &quot;key1&quot;\n2) &quot;key2&quot;\n3) &quot;arg1&quot;\n4) &quot;arg2&quot;\n5) &quot;arg3&quot;\n</code></pre>\n<p><strong>Note:</strong><br>as can been seen above, Lua&#39;s table arrays are returned as <a href=\"protocol#arrays\">RESP2 array replies</a>, so it is likely that your client&#39;s library will convert it to the native array data type in your programming language.<br>Please refer to the rules that govern <a href=\"lua-api#data-type-conversion\">data type conversion</a> for more pertinent information.</p>\n<h2>Interacting with Valkey from a script</h2>\n<p>It is possible to call Valkey commands from a Lua script either via <a href=\"lua-api#server.call\"><code>server.call()</code></a> or <a href=\"lua-api#server.pcall\"><code>server.pcall()</code></a>.</p>\n<p>The two are nearly identical.<br>Both execute a Valkey command along with its provided arguments, if these represent a well-formed command.<br>However, the difference between the two functions lies in the manner in which runtime errors (such as syntax errors, for example) are handled.<br>Errors raised from calling <code>server.call()</code> function are returned directly to the client that had executed it.<br>Conversely, errors encountered when calling the <code>server.pcall()</code> function are returned to the script&#39;s execution context instead for possible handling.</p>\n<p>For example, consider the following:</p>\n<pre><code>&gt; EVAL &quot;return server.call(&#39;SET&#39;, KEYS[1], ARGV[1])&quot; 1 foo bar\nOK\n</code></pre>\n<p>The above script accepts one key name and one value as its input arguments.<br>When executed, the script calls the <code>SET</code> command to set the input key, <em>foo</em>, with the string value &quot;bar&quot;.</p>\n<h2>Script cache</h2>\n<p>Until this point, we&#39;ve used the <code>EVAL</code> command to run our script.</p>\n<p>Whenever we call <code>EVAL</code>, we also include the script&#39;s source code with the request.<br>Repeatedly calling <code>EVAL</code> to execute the same set of parameterized scripts, wastes both network bandwidth and also has some overheads in Valkey.<br>Naturally, saving on network and compute resources is key, so, instead, Valkey provides a caching mechanism for scripts.</p>\n<p>Every script you execute with <code>EVAL</code> is stored in a dedicated cache that the server keeps.<br>The cache&#39;s contents are organized by the scripts&#39; SHA1 digest sums, so the SHA1 digest sum of a script uniquely identifies it in the cache.<br>You can verify this behavior by running <code>EVAL</code> and calling <code>INFO</code> afterward.<br>You&#39;ll notice that the <em>used_memory_scripts_eval</em> and <em>number_of_cached_scripts</em> metrics grow with every new script that&#39;s executed.</p>\n<p>As mentioned above, dynamically-generated scripts are an anti-pattern.<br>Generating scripts during the application&#39;s runtime may, and probably will, exhaust the host&#39;s memory resources for caching them.<br>Instead, scripts should be as generic as possible and provide customized execution via their arguments.</p>\n<p>A script is loaded to the server&#39;s cache by calling the <code>SCRIPT LOAD</code> command and providing its source code.<br>The server doesn&#39;t execute the script, but instead just compiles and loads it to the server&#39;s cache.<br>Once loaded, you can execute the cached script with the SHA1 digest returned from the server.</p>\n<p>Here&#39;s an example of loading and then executing a cached script:</p>\n<pre><code>127.0.0.1:6379&gt; SCRIPT LOAD &quot;return &#39;Immabe a cached script&#39;&quot;\n&quot;c664a3bf70bd1d45c4284ffebb65a6f2299bfc9f&quot;\n127.0.0.1:6379&gt; EVALSHA c664a3bf70bd1d45c4284ffebb65a6f2299bfc9f 0\n&quot;Immabe a cached script&quot;\n</code></pre>\n<h3>Cache volatility</h3>\n<p>The Valkey script cache is <strong>always volatile</strong>.<br>It isn&#39;t considered as a part of the database and is <strong>not persisted</strong>.<br>The cache may be cleared when the server restarts, during fail-over when a replica assumes the primary role, or explicitly by <code>SCRIPT FLUSH</code>.<br>That means that cached scripts are ephemeral, and the cache&#39;s contents can be lost at any time.</p>\n<p>Applications that use scripts should always call <code>EVALSHA</code> to execute them.<br>The server returns an error if the script&#39;s SHA1 digest is not in the cache.<br>For example:</p>\n<pre><code>127.0.0.1:6379&gt; EVALSHA ffffffffffffffffffffffffffffffffffffffff 0\n(error) NOSCRIPT No matching script\n</code></pre>\n<p>In this case, the application should first load it with <code>SCRIPT LOAD</code> and then call <code>EVALSHA</code> once more to run the cached script by its SHA1 sum.<br>Most of <a href=\"../clients/\">Valkey&#39; clients</a> already provide utility APIs for doing that automatically.<br>Please consult your client&#39;s documentation regarding the specific details.</p>\n<h3><code>EVALSHA</code> in the context of pipelining</h3>\n<p>Special care should be given executing <code>EVALSHA</code> in the context of a <a href=\"pipelining\">pipelined request</a>.<br>The commands in a pipelined request run in the order they are sent, but other clients&#39; commands may be interleaved for execution between these.<br>Because of that, the <code>NOSCRIPT</code> error can return from a pipelined request but can&#39;t be handled.</p>\n<p>Therefore, a client library&#39;s implementation should revert to using plain <code>EVAL</code> of parameterized in the context of a pipeline.</p>\n<h3>Script cache semantics</h3>\n<p>During normal operation, an application&#39;s scripts are meant to stay indefinitely in the cache (that is, until the server is restarted or the cache being flushed).<br>The underlying reasoning is that the script cache contents of a well-written application are unlikely to grow continuously.<br>Even large applications that use hundreds of cached scripts shouldn&#39;t be an issue in terms of cache memory usage.</p>\n<p>The only way to flush the script cache is by explicitly calling the <code>SCRIPT FLUSH</code> command.<br>Running the command will <em>completely flush</em> the scripts cache, removing all the scripts executed so far.<br>Typically, this is only needed when the instance is going to be instantiated for another customer or application in a cloud environment.</p>\n<p>Also, as already mentioned, restarting a Valkey instance flushes the non-persistent script cache.<br>However, from the point of view of the Valkey client, there are only two ways to make sure that a Valkey instance was not restarted between two different commands:</p>\n<ul>\n<li>The connection we have with the server is persistent and was never closed so far.</li>\n<li>The client explicitly checks the <code>run_id</code> field in the <code>INFO</code> command to ensure the server was not restarted and is still the same process.</li>\n</ul>\n<p>Practically speaking, it is much simpler for the client to assume that in the context of a given connection, cached scripts are guaranteed to be there unless the administrator explicitly invoked the <code>SCRIPT FLUSH</code> command.<br>The fact that the user can count on Valkey to retain cached scripts is semantically helpful in the context of pipelining.</p>\n<h2>The <code>SCRIPT</code> command</h2>\n<p>The Valkey <code>SCRIPT</code> provides several ways for controlling the scripting subsystem.<br>These are:</p>\n<ul>\n<li><p><code>SCRIPT FLUSH</code>: this command is the only way to force Valkey to flush the scripts cache.<br>It is most useful in environments where the same Valkey instance is reassigned to different uses.<br>It is also helpful for testing client libraries&#39; implementations of the scripting feature.</p>\n</li>\n<li><p><code>SCRIPT EXISTS</code>: given one or more SHA1 digests as arguments, this command returns an array of <em>1</em>&#39;s and <em>0</em>&#39;s.<br><em>1</em> means the specific SHA1 is recognized as a script already present in the scripting cache. <em>0</em>&#39;s meaning is that a script with this SHA1 wasn&#39;t loaded before (or at least never since the latest call to <code>SCRIPT FLUSH</code>).</p>\n</li>\n<li><p><code>SCRIPT LOAD script</code>: this command registers the specified script in the Valkey script cache.<br>It is a useful command in all the contexts where we want to ensure that <code>EVALSHA</code> doesn&#39;t not fail (for instance, in a pipeline or when called from a <a href=\"transactions\"><code>MULTI</code>/<code>EXEC</code> transaction</a>), without the need to execute the script.</p>\n</li>\n<li><p><code>SCRIPT SHOW</code>: this command shows the original source code for a script that is stored in the script cache.<br>It is useful to help users easily obtain scripts using signature.</p>\n</li>\n<li><p><code>SCRIPT KILL</code>: this command is the only way to interrupt a long-running script (a.k.a slow script), short of shutting down the server.<br>A script is deemed as slow once its execution&#39;s duration exceeds the configured <a href=\"programmability#maximum-execution-time\">maximum execution time</a> threshold.<br>The <code>SCRIPT KILL</code> command can be used only with scripts that did not modify the dataset during their execution (since stopping a read-only script does not violate the scripting engine&#39;s guaranteed atomicity).</p>\n</li>\n<li><p><code>SCRIPT DEBUG</code>: controls use of the built-in <a href=\"ldb\">Valkey Lua scripts debugger</a>.</p>\n</li>\n</ul>\n<h2>Script replication</h2>\n<p>In a primary-replica setup (see <a href=\"replication\">replication</a>), write commands performed by a script on the primary are also sent to replicas to maintain consistency.<br>When the script execution finishes, the sequence of commands that the script generated are wrapped into a <a href=\"transactions\"><code>MULTI</code>/<code>EXEC</code> transaction</a> and are sent to the replicas and written to the AOF file, if an AOF file is used. (See <a href=\"persistence\">Persistence</a>.)<br>This is called <em>effects replication</em>.</p>\n<p>In the past, it was also possible to use <em>verbatim replication</em> which means that a script was replicated as a whole, but this was removed in 7.0.</p>\n<p>The <a href=\"lua-api#server.replicate_commands\"><code>server.replicate_commands()</code></a> function is deprecated and has no effect, but it exists to avoid breaking existing scripts.</p>\n<h2>Debugging Eval scripts</h2>\n<p>Valkey has a built-in Lua debugger.<br>The Valkey Lua debugger is a remote debugger consisting of a server, which is Valkey itself, and a client, which is by default <a href=\"cli\"><code>valkey-cli</code></a>.</p>\n<p>The Lua debugger is described in the <a href=\"ldb\">Lua scripts debugging</a> section of the Valkey documentation.</p>\n<h2>Execution under low memory conditions</h2>\n<p>When memory usage in Valkey exceeds the <code>maxmemory</code> limit, the first write command encountered in the script that uses additional memory will cause the script to abort (unless <a href=\"lua-api#server.pcall\"><code>server.pcall</code></a> was used).</p>\n<p>However, an exception to the above is when the script&#39;s first write command does not use additional memory, as is the case with  (for example, <code>DEL</code> and <code>LREM</code>).<br>In this case, Valkey will allow all commands in the script to run to ensure atomicity.<br>If subsequent writes in the script consume additional memory, Valkey&#39; memory usage can exceed the threshold set by the <code>maxmemory</code> configuration directive.</p>\n<p>Another scenario in which a script can cause memory usage to cross the <code>maxmemory</code> threshold is when the execution begins when Valkey is slightly below <code>maxmemory</code>, so the script&#39;s first write command is allowed.<br>As the script executes, subsequent write commands consume more memory leading to the server using more RAM than the configured <code>maxmemory</code> directive.</p>\n<p>In those scenarios, you should consider setting the <code>maxmemory-policy</code> configuration directive to any values other than <code>noeviction</code>.<br>In addition, Lua scripts should be as fast as possible so that eviction can kick in between executions.</p>\n<p>Note that you can change this behaviour by using <a href=\"#eval-flags\">flags</a></p>\n<h2>Eval flags</h2>\n<p>Normally, when you run an Eval script, the server does not know how it accesses the database.<br>By default, Valkey assumes that all scripts read and write data.<br>However, starting with Redis OSS 7.0, there&#39;s a way to declare flags when creating a script in order to tell Valkey how it should behave.</p>\n<p>The way to do that is by using a Shebang statement on the first line of the script like so:</p>\n<pre><code>#!lua flags=no-writes,allow-stale\nlocal x = server.call(&#39;get&#39;,&#39;x&#39;)\nreturn x\n</code></pre>\n<p>Note that as soon as Valkey sees the <code>#!</code> comment, it&#39;ll treat the script as if it declares flags, even if no flags are defined,<br>it still has a different set of defaults compared to a script without a <code>#!</code> line.</p>\n<p>Another difference is that scripts without <code>#!</code> can run commands that access keys belonging to different cluster hash slots, but ones with <code>#!</code> inherit the default flags, so they cannot.</p>\n<p>Please refer to <a href=\"lua-api#script_flags\">Script flags</a> to learn about the various scripts and the defaults.</p>\n"
  },
  {
    "id": "faq",
    "topicName": "FAQ",
    "description": "Commonly asked questions when getting started with Valkey\n",
    "htmlContent": "<h2>How is Valkey different from other key-value stores?</h2>\n<ul>\n<li>Valkey has a different evolution path in the key-value DBs where values can contain more complex data types, with atomic operations defined on those data types. Valkey data types are closely related to fundamental data structures and are exposed to the programmer as such, without additional abstraction layers.</li>\n<li>Valkey is an in-memory but persistent on disk database, so it represents a different trade off where very high write and read speed is achieved with the limitation of data sets that can&#39;t be larger than memory. Another advantage of<br>in-memory databases is that the memory representation of complex data structures<br>is much simpler to manipulate compared to the same data structures on disk, so<br>Valkey can do a lot with little internal complexity. At the same time the<br>two on-disk storage formats (RDB and AOF) don&#39;t need to be suitable for random<br>access, so they are compact and always generated in an append-only fashion<br>(Even the AOF log rotation is an append-only operation, since the new version<br>is generated from the copy of data in memory). However this design also involves<br>different challenges compared to traditional on-disk stores. Being the main data<br>representation on memory, Valkey operations must be carefully handled to make sure<br>there is always an updated version of the data set on disk.</li>\n</ul>\n<h2>What&#39;s the Valkey memory footprint?</h2>\n<p>To give you a few examples:</p>\n<ul>\n<li>An empty instance uses ~ 3MB of memory.</li>\n<li>1 Million small Keys -&gt; String Value pairs use ~ 85MB of memory.</li>\n<li>1 Million Keys -&gt; Hash value, representing an object with 5 fields, use ~ 160 MB of memory.</li>\n</ul>\n<p>Testing your use case is trivial. Use the <code>valkey-benchmark</code> utility to generate random data sets then check the space used with the <code>INFO memory</code> command.</p>\n<h2>Why does Valkey keep its entire dataset in memory?</h2>\n<p>In the past, developers experimented with Virtual Memory and other systems in order to allow larger than RAM datasets, but after all we are very happy if we can do one thing well: data served from memory, disk used for storage. So for now there are no plans to create an on disk backend for Valkey. Most of what<br>Valkey is, after all, a direct result of its current design.</p>\n<p>If your real problem is not the total RAM needed, but the fact that you need<br>to split your data set into multiple Valkey instances, please read the<br><a href=\"cluster-tutorial\">partitioning page</a> in this documentation for more info.</p>\n<h2>Can you use Valkey with a disk-based database?</h2>\n<p>Yes, a common design pattern involves taking very write-heavy small data<br>in Valkey (and data you need the Valkey data structures to model your problem<br>in an efficient way), and big <em>blobs</em> of data into an SQL or eventually<br>consistent on-disk database. Similarly sometimes Valkey is used in order to<br>take in memory another copy of a subset of the same data stored in the on-disk<br>database. This may look similar to caching, but actually is a more advanced model<br>since normally the Valkey dataset is updated together with the on-disk DB dataset,<br>and not refreshed on cache misses.</p>\n<h2>How can I reduce Valkey&#39; overall memory usage?</h2>\n<p>A good practice is to consider memory consumption when mapping your logical data model to the physical data model within Valkey. These considerations include using specific data types, key patterns, and normalization.</p>\n<p>Beyond data modeling, there is more info in the <a href=\"memory-optimization\">Memory Optimization page</a>.</p>\n<h2>What happens if Valkey runs out of memory?</h2>\n<p>Valkey has built-in protections allowing the users to set a max limit on memory<br>usage, using the <code>maxmemory</code> option in the configuration file to put a limit<br>to the memory Valkey can use. If this limit is reached, Valkey will start to reply<br>with an error to write commands (but will continue to accept read-only<br>commands).</p>\n<p>You can also configure Valkey to evict keys when the max memory limit<br>is reached. See the <a href=\"lru-cache\">eviction policy docs</a> for more information on this.</p>\n<h2>Background saving fails with a fork() error on Linux?</h2>\n<p>Short answer: <code>echo 1 &gt; /proc/sys/vm/overcommit_memory</code> :)</p>\n<p>And now the long one:</p>\n<p>The Valkey background saving schema relies on the copy-on-write semantic of the <code>fork</code> system call in<br>modern operating systems: Valkey forks (creates a child process) that is an<br>exact copy of the parent. The child process dumps the DB on disk and finally<br>exits. In theory the child should use as much memory as the parent being a<br>copy, but actually thanks to the copy-on-write semantic implemented by most<br>modern operating systems the parent and child process will <em>share</em> the common<br>memory pages. A page will be duplicated only when it changes in the child or in<br>the parent. Since in theory all the pages may change while the child process is<br>saving, Linux can&#39;t tell in advance how much memory the child will take, so if<br>the <code>overcommit_memory</code> setting is set to zero the fork will fail unless there is<br>as much free RAM as required to really duplicate all the parent memory pages.<br>If you have a Valkey dataset of 3 GB and just 2 GB of free<br>memory it will fail.</p>\n<p>Setting <code>overcommit_memory</code> to 1 tells Linux to relax and perform the fork in a<br>more optimistic allocation fashion, and this is indeed what you want for Valkey.</p>\n<p>You can refer to the <a href=\"https://man7.org/linux/man-pages/man5/proc.5.html\">proc(5)</a> man page for explanations of the<br>available values.</p>\n<h2>Are Valkey on-disk snapshots atomic?</h2>\n<p>Yes, the Valkey background saving process is always forked when the server is<br>outside of the execution of a command, so every command reported to be atomic<br>in RAM is also atomic from the point of view of the disk snapshot.</p>\n<h2>How can Valkey use multiple CPUs or cores?</h2>\n<p>Enable I/O threading to offload client communication to threads.<br>In Valkey 8, the I/O threading implementation has been rewritten and greatly improved.<br>Reading commands from clients and writing replies back uses considerable CPU time.<br>By offloading this work to separate threads, the main thread can focus on executing commands.</p>\n<p>You can also start multiple instances of Valkey in the same box and combine them into a <a href=\"cluster-tutorial\">cluster</a>.</p>\n<h2>What is the maximum number of keys a single Valkey instance can hold? What is the maximum number of elements in a Hash, List, Set, and Sorted Set?</h2>\n<p>Valkey can handle up to 2<sup>32</sup> keys, and was tested in practice to<br>handle at least 250 million keys per instance.</p>\n<p>Every hash, list, set, and sorted set, can hold 2<sup>32</sup> elements.</p>\n<p>In other words your limit is likely the available memory in your system.</p>\n<h2>Why does my replica have a different number of keys than its primary instance?</h2>\n<p>If you use keys with limited time to live (Valkey expires) this is normal behavior. This is what happens:</p>\n<ul>\n<li>The primary generates an RDB file on the first synchronization with the replica.</li>\n<li>The RDB file will not include keys already expired in the primary but which are still in memory.</li>\n<li>These keys are still in the memory of the Valkey primary, even if logically expired. They&#39;ll be considered non-existent, and their memory will be reclaimed later, either incrementally or explicitly on access. While these keys are not logically part of the dataset, they are accounted for in the <code>INFO</code> output and in the <code>DBSIZE</code> command.</li>\n<li>When the replica reads the RDB file generated by the primary, this set of keys will not be loaded.</li>\n</ul>\n<p>Because of this, it&#39;s common for users with many expired keys to see fewer keys in the replicas. However, logically, the primary and replica will have the same content.</p>\n<h2>Why did Linux Foundation start the Valkey project?</h2>\n<p>Read about <a href=\"history\">the history of Valkey</a>.</p>\n"
  },
  {
    "id": "functions-intro",
    "topicName": "Functions",
    "description": "Scripting with functions stored on the server\n",
    "htmlContent": "<p>Valkey Functions is an API for managing code to be executed on the server.<br>This feature is as a complement to <a href=\"eval-intro\">EVAL scripts</a>.</p>\n<h2>What&#39;s wrong with EVAL?</h2>\n<p>There&#39;s nothing wrong with <code>EVAL</code>, but there are some differences between EVAL scripts and Functions.<br>With the <a href=\"../commands/eval\"><code>EVAL</code></a> command, scripts are sent to the server for immediate execution.<br>The core use cases for <code>EVAL</code> scripts is executing part of your application logic inside Valkey, efficiently and atomically.<br>Such script can perform conditional updates across multiple keys, possibly combining several different data types.</p>\n<p>Using <code>EVAL</code> requires that the application sends the entire script for execution every time.<br>Because this results in network and script compilation overheads, Valkey provides an optimization in the form of the <a href=\"../commands/evalsha\"><code>EVALSHA</code></a> command.<br>By first calling <a href=\"../commands/script-load\"><code>SCRIPT LOAD</code></a> to obtain the script&#39;s SHA1, the application can invoke it repeatedly afterward with its digest alone.</p>\n<p>Valkey only caches the loaded scripts.<br>That means that the script cache can become lost at any time, such as after calling <code>SCRIPT FLUSH</code>, after restarting the server, or when failing over to a replica.<br>The application is responsible for reloading scripts during runtime if any are missing.<br>The underlying assumption is that scripts are a part of the application and not maintained by the Valkey server.</p>\n<p>This approach suits many light-weight scripting use cases, but introduces several difficulties once an application becomes complex and relies more heavily on scripting, namely:</p>\n<ol>\n<li>All client application instances must maintain a copy of all scripts. That means having some mechanism that applies script updates to all of the application&#39;s instances.</li>\n<li>Calling cached scripts within the context of a <a href=\"transactions\">transaction</a> increases the probability of the transaction failing because of a missing script. Being more likely to fail makes using cached scripts as building blocks of workflows less attractive.</li>\n<li>SHA1 digests are not readable for humans, making debugging the system hard (e.g. in a <a href=\"../commands/monitor\"><code>MONITOR</code></a> session).</li>\n<li>When used naively, <code>EVAL</code> promotes an anti-pattern in which the client application renders verbatim scripts instead of responsibly using the <a href=\"lua-api#runtime-globals\"><code>KEYS</code> and <code>ARGV</code> Lua APIs</a>.</li>\n<li>Because they are ephemeral, a script can&#39;t call another script. This makes sharing and reusing code between scripts nearly impossible, short of client-side preprocessing.</li>\n</ol>\n<p>To address these needs while avoiding breaking changes to already-established and well-liked ephemeral scripts, functions were introduced in version 7.0.</p>\n<h2>What are Valkey Functions?</h2>\n<p>Functions provide the same core functionality as scripts but are first-class artifacts of the database.<br>Valkey manages functions as an integral part of the database and ensures their availability via data persistence and replication.<br>Because functions are part of the database and therefore declared before use, applications aren&#39;t required to load them during runtime nor risk aborted transactions.<br>An application that uses functions depends only on their APIs rather than on the embedded script logic in the database.</p>\n<p>Whereas ephemeral scripts are considered a part of the application&#39;s domain, functions extend the database server itself with user-provided logic.<br>They can be loaded at startup and be used repeatedly by various applications and clients.<br>Functions are also persisted to the AOF file and replicated from primary to replicas, so they are as durable as the data itself.<br>When Valkey is used as an ephemeral cache, additional mechanisms (described below) are required to make functions more durable.</p>\n<p>Functions also simplify development by enabling code sharing.<br>Every function has a user-defined name and belongs to a library, and a library can consist of multiple functions.<br>The library&#39;s contents are immutable, and selective updates of its functions aren&#39;t allowed.<br>Instead, libraries are updated as a whole with all of their functions together in one operation.<br>This allows calling functions from other functions within the same library, or sharing code between functions by using a common code in library-internal methods, that can also take language native arguments.</p>\n<p>Like all other operations in Valkey, the execution of a function is atomic.<br>A function&#39;s execution blocks all server activities during its entire time, similarly to the semantics of <a href=\"transactions\">transactions</a>.<br>These semantics mean that all of the script&#39;s effects either have yet to happen or had already happened.<br>The blocking semantics of an executed function apply to all connected clients at all times.<br>Because running a function blocks the Valkey server, functions are meant to finish executing quickly, so you should avoid using long-running functions.</p>\n<p>Functions are written in <a href=\"lua-api\">Lua 5.1</a>.<br>Valkey functions can use all of Lua&#39;s available capabilities to ephemeral scripts,<br>with the only exception being the <a href=\"ldb\">Valkey Lua scripts debugger</a>.</p>\n<h2>Loading libraries and functions</h2>\n<p>Let&#39;s explore Valkey Functions via some tangible examples and Lua snippets.</p>\n<p>At this point, if you&#39;re unfamiliar with Lua in general and specifically in Valkey, you may benefit from reviewing some of the examples in <a href=\"eval-intro\">Introduction to Eval Scripts</a> and <a href=\"lua-api\">Lua API</a> pages for a better grasp of the language.</p>\n<p>Every Valkey function belongs to a library.<br>Loading a library to the database is done with the <a href=\"../commands/function-load\"><code>FUNCTION LOAD</code></a> command.<br>The library source code must start with a Shebang line that provides metadata about the library, like the language (always &quot;lua&quot;) and the library name.<br>The Shebang format is:</p>\n<pre><code>#!lua name=&lt;library name&gt;\n</code></pre>\n<p>Let&#39;s try loading an empty library:</p>\n<pre><code>127.0.0.1:6379&gt; FUNCTION LOAD &quot;#!lua name=mylib\\n&quot;\n(error) ERR No functions registered\n</code></pre>\n<p>The error is expected, as there are no functions in the loaded library. Every library needs to include at least one registered function to load successfully.<br>A registered function is named and acts as an entry point to the library.<br>When the target execution engine handles the <code>FUNCTION LOAD</code> command, it registers the library&#39;s functions.</p>\n<p>The Lua engine compiles and evaluates the library source code when loaded, and expects functions to be registered by calling the <code>server.register_function()</code> API.</p>\n<p>The following snippet demonstrates a simple library registering a single function named <em>knockknock</em>, returning a string reply:</p>\n<pre><code class=\"language-lua\">#!lua name=mylib\nserver.register_function(\n  &#39;knockknock&#39;,\n  function() return &#39;Who\\&#39;s there?&#39; end\n)\n</code></pre>\n<p>In the example above, we provide two arguments about the function to Lua&#39;s <code>server.register_function()</code> API: its registered name and a callback.</p>\n<p>We can load our library and use <code>FCALL</code> to call the registered function:</p>\n<pre><code>127.0.0.1:6379&gt; FUNCTION LOAD &quot;#!lua name=mylib\\nserver.register_function(&#39;knockknock&#39;, function() return &#39;Who\\\\&#39;s there?&#39; end)&quot;\nmylib\n127.0.0.1:6379&gt; FCALL knockknock 0\n&quot;Who&#39;s there?&quot;\n</code></pre>\n<p>Notice that the <code>FUNCTION LOAD</code> command returns the name of the loaded library, this name can later be used <code>FUNCTION LIST</code> and <code>FUNCTION DELETE</code>.</p>\n<p>We&#39;ve provided <a href=\"../commands/fcall\"><code>FCALL</code></a> with two arguments: the function&#39;s registered name and the numeric value <code>0</code>. This numeric value indicates the number of key names that follow it (the same way <code>EVAL</code> and <code>EVALSHA</code> works).</p>\n<p>We&#39;ll explain immediately how key names and additional arguments are available to the function. As this simple example doesn&#39;t involve keys, we simply use 0 for now.</p>\n<h2>Input keys and regular arguments</h2>\n<p>Before we move to the following example, it is vital to understand the distinction Valkey makes between arguments that are names of keys and those that aren&#39;t.</p>\n<p>While key names in Valkey are just strings, unlike any other string values, these represent keys in the database.<br>The name of a key is a fundamental concept in Valkey and is the basis for operating the Valkey Cluster.</p>\n<p><strong>Important:</strong><br>To ensure the correct execution of Valkey Functions, both in standalone and clustered deployments, all names of keys that a function accesses must be explicitly provided as input key arguments.</p>\n<p>Any input to the function that isn&#39;t the name of a key is a regular input argument.</p>\n<p>Now, let&#39;s pretend that our application stores some of its data in Hashes.<br>We want an <a href=\"../commands/hset\"><code>HSET</code></a>-like way to set and update fields in said Hashes and store the last modification time in a new field named <code>_last_modified_</code>.<br>We can implement a function to do all that.</p>\n<p>Our function will call <a href=\"../commands/time\"><code>TIME</code></a> to get the server&#39;s clock reading and update the target Hash with the new fields&#39; values and the modification&#39;s timestamp.<br>The function we&#39;ll implement accepts the following input arguments: the Hash&#39;s key name and the field-value pairs to update.</p>\n<p>The Lua API for Valkey Functions makes these inputs accessible as the first and second arguments to the function&#39;s callback.<br>The callback&#39;s first argument is a Lua table populated with all key names inputs to the function.<br>Similarly, the callback&#39;s second argument consists of all regular arguments.</p>\n<p>The following is a possible implementation for our function and its library registration:</p>\n<pre><code class=\"language-lua\">#!lua name=mylib\n\nlocal function my_hset(keys, args)\n  local hash = keys[1]\n  local time = server.call(&#39;TIME&#39;)[1]\n  return server.call(&#39;HSET&#39;, hash, &#39;_last_modified_&#39;, time, unpack(args))\nend\n\nserver.register_function(&#39;my_hset&#39;, my_hset)\n</code></pre>\n<p>If we create a new file named <em>mylib.lua</em> that consists of the library&#39;s definition, we can load it like so (without stripping the source code of helpful whitespaces):</p>\n<pre><code class=\"language-bash\">$ cat mylib.lua | valkey-cli -x FUNCTION LOAD REPLACE\n</code></pre>\n<p>We&#39;ve added the <code>REPLACE</code> modifier to the call to <code>FUNCTION LOAD</code> to tell Valkey that we want to overwrite the existing library definition.<br>Otherwise, we would have gotten an error from Valkey complaining that the library already exists.</p>\n<p>Now that the library&#39;s updated code is loaded to Valkey, we can proceed and call our function:</p>\n<pre><code>127.0.0.1:6379&gt; FCALL my_hset 1 myhash myfield &quot;some value&quot; another_field &quot;another value&quot;\n(integer) 3\n127.0.0.1:6379&gt; HGETALL myhash\n1) &quot;_last_modified_&quot;\n2) &quot;1640772721&quot;\n3) &quot;myfield&quot;\n4) &quot;some value&quot;\n5) &quot;another_field&quot;\n6) &quot;another value&quot;\n</code></pre>\n<p>In this case, we had invoked <code>FCALL</code> with <em>1</em> as the number of key name arguments.<br>That means that the function&#39;s first input argument is a name of a key (and is therefore included in the callback&#39;s <code>keys</code> table).<br>After that first argument, all following input arguments are considered regular arguments and constitute the <code>args</code> table passed to the callback as its second argument.</p>\n<h2>Expanding the library</h2>\n<p>We can add more functions to our library to benefit our application.<br>The additional metadata field we&#39;ve added to the Hash shouldn&#39;t be included in responses when accessing the Hash&#39;s data.<br>On the other hand, we do want to provide the means to obtain the modification timestamp for a given Hash key.</p>\n<p>We&#39;ll add two new functions to our library to accomplish these objectives:</p>\n<ol>\n<li>The <code>my_hgetall</code> Valkey Function will return all fields and their respective values from a given Hash key name, excluding the metadata (i.e., the <code>_last_modified_</code> field).</li>\n<li>The <code>my_hlastmodified</code> Valkey Function will return the modification timestamp for a given Hash key name.</li>\n</ol>\n<p>The library&#39;s source code could look something like the following:</p>\n<pre><code class=\"language-lua\">#!lua name=mylib\n\nlocal function my_hset(keys, args)\n  local hash = keys[1]\n  local time = server.call(&#39;TIME&#39;)[1]\n  return server.call(&#39;HSET&#39;, hash, &#39;_last_modified_&#39;, time, unpack(args))\nend\n\nlocal function my_hgetall(keys, args)\n  server.setresp(3)\n  local hash = keys[1]\n  local res = server.call(&#39;HGETALL&#39;, hash)\n  res[&#39;map&#39;][&#39;_last_modified_&#39;] = nil\n  return res\nend\n\nlocal function my_hlastmodified(keys, args)\n  local hash = keys[1]\n  return server.call(&#39;HGET&#39;, hash, &#39;_last_modified_&#39;)\nend\n\nserver.register_function(&#39;my_hset&#39;, my_hset)\nserver.register_function(&#39;my_hgetall&#39;, my_hgetall)\nserver.register_function(&#39;my_hlastmodified&#39;, my_hlastmodified)\n</code></pre>\n<p>While all of the above should be straightforward, note that the <code>my_hgetall</code> also calls <a href=\"lua-api#server.setresp\"><code>server.setresp(3)</code></a>.<br>That means that the function expects <a href=\"protocol\">RESP3</a> replies after calling <code>server.call()</code>, which, unlike the default RESP2 protocol, returns the replies as maps (associative arrays).<br>Doing so allows the function to delete (or set to <code>nil</code> as is the case with Lua tables) specific fields from the reply, and in our case, the <code>_last_modified_</code> field.</p>\n<p>Assuming you&#39;ve saved the library&#39;s implementation in the <em>mylib.lua</em> file, you can replace it with:</p>\n<pre><code class=\"language-bash\">$ cat mylib.lua | valkey-cli -x FUNCTION LOAD REPLACE\n</code></pre>\n<p>Once loaded, you can call the library&#39;s functions with <code>FCALL</code>:</p>\n<pre><code>127.0.0.1:6379&gt; FCALL my_hgetall 1 myhash\n1) &quot;myfield&quot;\n2) &quot;some value&quot;\n3) &quot;another_field&quot;\n4) &quot;another value&quot;\n127.0.0.1:6379&gt; FCALL my_hlastmodified 1 myhash\n&quot;1640772721&quot;\n</code></pre>\n<p>You can also get the library&#39;s details with the <code>FUNCTION LIST</code> command:</p>\n<pre><code>127.0.0.1:6379&gt; FUNCTION LIST\n1) 1) &quot;library_name&quot;\n   2) &quot;mylib&quot;\n   3) &quot;engine&quot;\n   4) &quot;LUA&quot;\n   5) &quot;functions&quot;\n   6) 1) 1) &quot;name&quot;\n         2) &quot;my_hset&quot;\n         3) &quot;description&quot;\n         4) (nil)\n         5) &quot;flags&quot;\n         6) (empty array)\n      2) 1) &quot;name&quot;\n         2) &quot;my_hgetall&quot;\n         3) &quot;description&quot;\n         4) (nil)\n         5) &quot;flags&quot;\n         6) (empty array)\n      3) 1) &quot;name&quot;\n         2) &quot;my_hlastmodified&quot;\n         3) &quot;description&quot;\n         4) (nil)\n         5) &quot;flags&quot;\n         6) (empty array)\n</code></pre>\n<p>You can see that it is easy to update our library with new capabilities.</p>\n<h2>Reusing code in the library</h2>\n<p>On top of bundling functions together into database-managed software artifacts, libraries also facilitate code sharing.<br>We can add to our library an error handling helper function called from other functions.<br>The helper function <code>check_keys()</code> verifies that the input <em>keys</em> table has a single key.<br>Upon success it returns <code>nil</code>, otherwise it returns an <a href=\"lua-api#server.error_reply\">error reply</a>.</p>\n<p>The updated library&#39;s source code would be:</p>\n<pre><code class=\"language-lua\">#!lua name=mylib\n\nlocal function check_keys(keys)\n  local error = nil\n  local nkeys = table.getn(keys)\n  if nkeys == 0 then\n    error = &#39;Hash key name not provided&#39;\n  elseif nkeys &gt; 1 then\n    error = &#39;Only one key name is allowed&#39;\n  end\n\n  if error ~= nil then\n    server.log(server.LOG_WARNING, error);\n    return server.error_reply(error)\n  end\n  return nil\nend\n\nlocal function my_hset(keys, args)\n  local error = check_keys(keys)\n  if error ~= nil then\n    return error\n  end\n\n  local hash = keys[1]\n  local time = server.call(&#39;TIME&#39;)[1]\n  return server.call(&#39;HSET&#39;, hash, &#39;_last_modified_&#39;, time, unpack(args))\nend\n\nlocal function my_hgetall(keys, args)\n  local error = check_keys(keys)\n  if error ~= nil then\n    return error\n  end\n\n  server.setresp(3)\n  local hash = keys[1]\n  local res = server.call(&#39;HGETALL&#39;, hash)\n  res[&#39;map&#39;][&#39;_last_modified_&#39;] = nil\n  return res\nend\n\nlocal function my_hlastmodified(keys, args)\n  local error = check_keys(keys)\n  if error ~= nil then\n    return error\n  end\n\n  local hash = keys[1]\n  return server.call(&#39;HGET&#39;, keys[1], &#39;_last_modified_&#39;)\nend\n\nserver.register_function(&#39;my_hset&#39;, my_hset)\nserver.register_function(&#39;my_hgetall&#39;, my_hgetall)\nserver.register_function(&#39;my_hlastmodified&#39;, my_hlastmodified)\n</code></pre>\n<p>After you&#39;ve replaced the library in Valkey with the above, you can immediately try out the new error handling mechanism:</p>\n<pre><code>127.0.0.1:6379&gt; FCALL my_hset 0 myhash nope nope\n(error) Hash key name not provided\n127.0.0.1:6379&gt; FCALL my_hgetall 2 myhash anotherone\n(error) Only one key name is allowed\n</code></pre>\n<p>And your Valkey log file should have lines in it that are similar to:</p>\n<pre><code>...\n20075:M 1 Jan 2022 16:53:57.688 # Hash key name not provided\n20075:M 1 Jan 2022 16:54:01.309 # Only one key name is allowed\n</code></pre>\n<h2>Functions in cluster</h2>\n<p>As noted above, Valkey automatically handles propagation of loaded functions to replicas.<br>In a <a href=\"cluster-tutorial\">cluster</a>, it is necessary to load functions to all primaries.</p>\n<p>As one of the goals of functions is to live separately from the client application, this should not be part of the Valkey client library responsibilities. Instead, <code>valkey-cli --cluster-only-primaries --cluster call host:port FUNCTION LOAD ...</code> can be used to execute the load command on all primary nodes.</p>\n<p>Also, note that <code>valkey-cli --cluster add-node</code> automatically takes care to propagate the loaded functions from one of the existing nodes to the new node.</p>\n<h2>Functions and ephemeral Valkey instances</h2>\n<p>In some cases there may be a need to start a fresh Valkey server with a set of functions pre-loaded. Common reasons for that could be:</p>\n<ul>\n<li>Starting Valkey in a new environment</li>\n<li>Re-starting an ephemeral (cache-only) Valkey, that uses functions</li>\n</ul>\n<p>In such cases, we need to make sure that the pre-loaded functions are available before Valkey accepts inbound user connections and commands.</p>\n<p>To do that, it is possible to use <code>valkey-cli --functions-rdb</code> to extract the functions from an existing server. This generates an RDB file that can be loaded by Valkey at startup.</p>\n<h2>Function flags</h2>\n<p>Valkey needs to have some information about how a function is going to behave when executed, in order to properly enforce resource usage policies and maintain data consistency.</p>\n<p>For example, Valkey needs to know that a certain function is read-only before permitting it to execute using <code>FCALL_RO</code> on a read-only replica.</p>\n<p>By default, Valkey assumes that all functions may perform arbitrary read or write operations. Function Flags make it possible to declare more specific function behavior at the time of registration. Let&#39;s see how this works.</p>\n<p>In our previous example, we defined two functions that only read data. We can try executing them using <code>FCALL_RO</code> against a read-only replica.</p>\n<pre><code>127.0.0.1:6379&gt; FCALL_RO my_hgetall 1 myhash\n(error) ERR Can not execute a function with write flag using fcall_ro.\n</code></pre>\n<p>Valkey returns this error because a function can, in theory, perform both read and write operations on the database.<br>As a safeguard and by default, Valkey assumes that the function does both, so it blocks its execution.<br>The server will reply with this error in the following cases:</p>\n<ol>\n<li>Executing a function with <code>FCALL</code> against a read-only replica.</li>\n<li>Using <code>FCALL_RO</code> to execute a function.</li>\n<li>A disk error was detected (Valkey is unable to persist so it rejects writes).</li>\n</ol>\n<p>In these cases, you can add the <code>no-writes</code> flag to the function&#39;s registration, disable the safeguard and allow them to run.<br>To register a function with flags use the <a href=\"lua-api#server.register_function_named_args\">named arguments</a> variant of <code>server.register_function</code>.</p>\n<p>The updated registration code snippet from the library looks like this:</p>\n<pre><code class=\"language-lua\">server.register_function(&#39;my_hset&#39;, my_hset)\nserver.register_function{\n  function_name=&#39;my_hgetall&#39;,\n  callback=my_hgetall,\n  flags={ &#39;no-writes&#39; }\n}\nserver.register_function{\n  function_name=&#39;my_hlastmodified&#39;,\n  callback=my_hlastmodified,\n  flags={ &#39;no-writes&#39; }\n}\n</code></pre>\n<p>Once we&#39;ve replaced the library, Valkey allows running both <code>my_hgetall</code> and <code>my_hlastmodified</code> with <code>FCALL_RO</code> against a read-only replica:</p>\n<pre><code>127.0.0.1:6379&gt; FCALL_RO my_hgetall 1 myhash\n1) &quot;myfield&quot;\n2) &quot;some value&quot;\n3) &quot;another_field&quot;\n4) &quot;another value&quot;\n127.0.0.1:6379&gt; FCALL_RO my_hlastmodified 1 myhash\n&quot;1640772721&quot;\n</code></pre>\n<p>For the complete documentation flags, please refer to <a href=\"lua-api#script_flags\">Script flags</a>.</p>\n"
  },
  {
    "id": "geospatial",
    "topicName": "Geospatial",
    "description": "Introduction to the Valkey Geospatial data type\n",
    "htmlContent": "<p>Geospatial indexes let you store coordinates and search for them.<br>This data structure is useful for finding nearby points within a given radius or bounding box.</p>\n<h2>Basic commands</h2>\n<ul>\n<li><code>GEOADD</code> adds a location to a given geospatial index (note that longitude comes before latitude with this command).</li>\n<li><code>GEOSEARCH</code> returns locations with a given radius or a bounding box.</li>\n</ul>\n<p>See the <a href=\"../commands/#geo\">complete list of geospatial index commands</a>.</p>\n<h2>Examples</h2>\n<p>Suppose you&#39;re building a mobile app that lets you find all of the bike rental stations closest to your current location.</p>\n<p>Add several locations to a geospatial index:</p>\n<pre><code>127.0.0.1:6379&gt; GEOADD bikes:rentable -122.27652 37.805186 station:1\n(integer) 1\n127.0.0.1:6379&gt; GEOADD bikes:rentable -122.2674626 37.8062344 station:2\n(integer) 1\n127.0.0.1:6379&gt; GEOADD bikes:rentable -122.2469854 37.8104049 station:3\n(integer) 1\n</code></pre>\n<p>Find all locations within a 5 kilometer radius of a given location, and return the distance to each location:</p>\n<pre><code>127.0.0.1:6379&gt; GEOSEARCH bikes:rentable FROMLONLAT -122.2612767 37.7936847 BYRADIUS 5 km WITHDIST\n1) 1) &quot;station:1&quot;\n   2) &quot;1.8523&quot;\n2) 1) &quot;station:2&quot;\n   2) &quot;1.4979&quot;\n3) 1) &quot;station:3&quot;\n   2) &quot;2.2441&quot;\n</code></pre>\n"
  },
  {
    "id": "hashes",
    "topicName": "Hashes",
    "description": "Introduction to Hashes\n",
    "htmlContent": "<p>Hashes are record types structured as collections of field-value pairs.<br>You can use hashes to represent basic objects and to store groupings of counters, among other things.</p>\n<pre><code>127.0.0.1:6379&gt; HSET bike:1 model Deimos brand Ergonom type &#39;Enduro bikes&#39; price 4972\n(integer) 4\n127.0.0.1:6379&gt; HGET bike:1 model\n&quot;Deimos&quot;\n127.0.0.1:6379&gt; HGET bike:1 price\n&quot;4972&quot;\n127.0.0.1:6379&gt; HGETALL bike:1\n1) &quot;model&quot;\n2) &quot;Deimos&quot;\n3) &quot;brand&quot;\n4) &quot;Ergonom&quot;\n5) &quot;type&quot;\n6) &quot;Enduro bikes&quot;\n7) &quot;price&quot;\n8) &quot;4972&quot;\n</code></pre>\n<p>While hashes are handy to represent <em>objects</em>, actually the number of fields you can<br>put inside a hash has no practical limits (other than available memory), so you can use<br>hashes in many different ways inside your application.</p>\n<p>The command <code>HSET</code> sets multiple fields of the hash, while <code>HGET</code> retrieves<br>a single field. <code>HMGET</code> is similar to <code>HGET</code> but returns an array of values:</p>\n<pre><code>127.0.0.1:6379&gt; HMGET bike:1 model price no-such-field\n1) &quot;Deimos&quot;\n2) &quot;4972&quot;\n3) (nil)\n</code></pre>\n<p>There are commands that are able to perform operations on individual fields<br>as well, like <code>HINCRBY</code>:</p>\n<pre><code>127.0.0.1:6379&gt; HINCRBY bike:1 price 100\n(integer) 5072\n127.0.0.1:6379&gt; HINCRBY bike:1 price -100\n(integer) 4972\n</code></pre>\n<p>It is worth noting that small hashes (i.e., a few elements with small values) are<br>encoded in special way in memory that make them very memory efficient.</p>\n<h2>Basic commands</h2>\n<ul>\n<li><code>HSET</code> sets the value of one or more fields on a hash.</li>\n<li><code>HGET</code> returns the value at a given field.</li>\n<li><code>HMGET</code> returns the values at one or more given fields.</li>\n<li><code>HINCRBY</code> increments the value at a given field by the integer provided.</li>\n</ul>\n<p>See the <a href=\"../commands/#hash\">complete list of hash commands</a>.</p>\n<h2>Examples</h2>\n<ul>\n<li>Store counters for the number of times bike:1 has been ridden, has crashed, or has changed owners:</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; HINCRBY bike:1:stats rides 1\n(integer) 1\n127.0.0.1:6379&gt; HINCRBY bike:1:stats rides 1\n(integer) 2\n127.0.0.1:6379&gt; HINCRBY bike:1:stats rides 1\n(integer) 3\n127.0.0.1:6379&gt; HINCRBY bike:1:stats crashes 1\n(integer) 1\n127.0.0.1:6379&gt; HINCRBY bike:1:stats owners 1\n(integer) 1\n127.0.0.1:6379&gt; HGET bike:1:stats rides\n&quot;3&quot;\n127.0.0.1:6379&gt; HMGET bike:1:stats owners crashes\n1) &quot;1&quot;\n2) &quot;1&quot;\n</code></pre>\n<h2>Performance</h2>\n<p>Most Hash commands are O(1).</p>\n<p>A few commands - such as <code>HKEYS</code>, <code>HVALS</code>, and <code>HGETALL</code> - are O(n), where <em>n</em> is the number of field-value pairs.</p>\n<h2>Limits</h2>\n<p>Every hash can store up to 4,294,967,295 (2^32 - 1) field-value pairs.<br>In practice, your hashes are limited only by the overall memory on the VMs hosting your Valkey deployment.</p>\n"
  },
  {
    "id": "history",
    "topicName": "History",
    "description": "How the Valkey project started",
    "htmlContent": "<p>Valkey is a fork of the open-source Redis (REmote DIctionary Server) database<br>created in 2009 by the Italian hacker Salvatore “antirez” Sanfilippo. He<br>announced it on <a href=\"https://news.ycombinator.com/item?id=494649\">Hacker News</a> on Feb 25, 2009. <a href=\"https://github.blog/2009-11-03-introducing-resque/\">GitHub</a> and<br><a href=\"https://instagram-engineering.com/storing-hundreds-of-millions-of-simple-key-value-pairs-in-redis-1091ae80f74c\">Instagram</a> were among the early adopters.</p>\n<h2>Early works of Salvatore Sanfilippo</h2>\n<p>At the time, Salvatore “antirez” was already known for inventing the <a href=\"https://en.wikipedia.org/wiki/Idle_scan\">Idle<br>scan</a> port scanning technique, the <a href=\"https://en.wikipedia.org/wiki/Hping\">Hping</a> TCP/IP packet<br>generator and analyzer, the <a href=\"https://jim.tcl-lang.org/index.html/doc/www/www/about/\">Jim</a> TCL interpreter and the <a href=\"https://github.com/antirez/lloogg/blob/master/README\">LLOOGG</a><br>real-time log analyzer. To improve it, he created an in-memory database called<br>called <a href=\"https://gist.github.com/antirez/6ca04dd191bdb82aad9fb241013e88a8\">LLOOGG Memory DB</a>, which was a proof-of-concept of what later<br>became Redis and Valkey.</p>\n<h2>Early contributions and sponsorships</h2>\n<p>During 2009, Engine Yard contributed blocking POP (BLPOP) and part of the<br>Virtual Memory implementation (later deleted), Hitmeister contributed part of<br>the Cluster implementation and Citrusbyte contributed part of Virtual Memory<br>implementation. In 2010, Slicehost (acquired by Rackspace) provided Virtual<br>Machines for testing in a virtualized environment and Linode provided virtual<br>machines for testing in a virtualized environment. Also thanks to the following<br>people or organizations that donated to the Project: Emil Vladev, <a href=\"https://bradjasper.com/\">Brad<br>Jasper</a> and <a href=\"http://mrkris.com/\">Mrkris</a>. The<br><a href=\"https://en.wikipedia.org/wiki/Shuttleworth_Foundation\">Shuttleworth Foundation</a><br>donated 5000 USD to the project in form of a flash grant.</p>\n<p>Pieter Noordhuis and Matt Stancliff provided a significant amount of code and<br>ideas to the core and client libraries.</p>\n<h2>The time with VMware</h2>\n<p>In March, 2010, Sanfilippo was hired by <a href=\"https://vmware.com\">VMware</a> to work on<br>Redis and Redis Tools. In his blog post <a href=\"https://web.archive.org/web/20241017012850/http://oldblog.antirez.com/post/vmware-the-new-redis-home.html\">VMware: the new Redis<br>home</a>, he writes:</p>\n<blockquote>\n<p>Not only Redis will remain a totally open source project, but Redis Tools will<br>be open sourced also (and this was an idea I got from VMware itself!).</p>\n<p>This is why I&#39;m truly excited about joining VMware: together we&#39;ll build a<br>better, free Redis, bringing Redis development to another level.</p>\n</blockquote>\n<p>VMware, and later Pivotal (a VMware spin-off), provided a 24 GB RAM workstation<br>for Salvatore to run the Redis CI test and other long running tests. Later,<br>Salvatore equipped the server with an SSD drive in order to test in the same<br>hardware with rotating and flash drives. VMware sponsored the project until May<br>2013, with the work of Salvatore Sanfilippo and Pieter Noordhuis. From May 2013<br>to June 2015, Salvatore&#39;s work was sponsored by Pivotal.</p>\n<h2>The Redis Labs era</h2>\n<p>In 2011, a company called Garantia Data was founded and started providing<br>database services based on Redis. In 2013, Garantia Data was changing its name<br>to RedisDB, but <a href=\"https://www.forbes.com/sites/benkepes/2013/11/04/was-garantia-is-now-redisdb-either-way-nosql-is-hot/\">decided to withdraw the change</a> after complaints by<br>Sanfilippo:</p>\n<blockquote>\n<p>If this is true, it is not a good thing as the current informal rule was: use<br>&quot;Redis&quot; in company names that are selling Redis services, but in a way that<br>makes it distinguishable from Redis as a project. There are many examples like<br>OpenRedis, RedisToGo, and so forth. However &quot;RedisDB&quot; is different as it is<br>more like &quot;We are Redis&quot;, (I even own the &quot;redis-db.com&quot; domain name since<br>2009! you can WHOIS it to check). So in my opinion calling the company<br>&quot;RedisDB&quot; is wrong, especially since I and Garantia Data from time to time<br>have friendly conversations as we are both part of the &quot;Redis ecosystem&quot;, but<br>I did not received any prior question about this issue.</p>\n</blockquote>\n<p>The following year, 2014, Garantia Data <a href=\"https://techcrunch.com/2014/01/29/database-provider-garantia-data-makes-another-name-change-this-time-to-redis-labs/\">changed its name to Redis Labs</a>.</p>\n<p>In 2015, Salvatore left Pivotal for Redis Labs. He writes in his blog post<br><a href=\"https://web.archive.org/web/20241123010805/http://antirez.com/news/91\">Thanks Pivotal, Hello Redis Labs</a>:</p>\n<blockquote>\n<p>Redis Labs was willing to continue what VMware and Pivotal started. I&#39;ll be<br>able to work as I do currently, spending all my time in the open source side<br>of the project, while Redis Labs continues to provide Redis users with an<br>hassles-free Redis experience of managed instances and products.</p>\n</blockquote>\n<p>In 2018, Redis Labs changed the license of some of its modules from AGPL to a<br>source-available license. The license prevents competing cloud providers from<br>offering these modules to customers and does therefore not fulfill the criteria<br>for an open source license.</p>\n<p>This was interpreted by some as if Redis is no longer open source. Sanfilippo<br>clarified on his blog <a href=\"https://web.archive.org/web/20241111062719/http://antirez.com/news/120\">Redis will remain BSD licensed</a>.</p>\n<p>Yiftach Shoolman, CTO and co-founder of Redis Labs, also clarified in in the<br>company&#39;s blog that <a href=\"https://redis.io/blog/redis-license-bsd-will-remain-bsd/\">Redis&#39; License is BSD and will remain<br>BSD</a>. He repeated this promise in <a href=\"https://news.ycombinator.com/item?id=17819392\">a comment on Hacker<br>News</a>, writing “let me assure you that Redis remains and always<br>will remain, open source, BSD license”.</p>\n<p>In 2020, Salvatore Sanfilippo announced in his blog post <a href=\"https://web.archive.org/web/20241123005834/http://antirez.com/news/133\">The end of the Redis<br>adventure</a> that he was stepping back as the Redis<br>maintainer, handing over the maintenance to Yossi Gottlieb and Oran Agra at<br>Redis Labs. The two created a “core team” to maintain the project and invited<br>Itamar Haber from Redis Labs, Zhao Zhao from Alibaba and Madelyn Olson from<br>Amazon. The members were selected “based on demonstrated, long-term personal<br>involvement and contributions”. This was described in the projects<br><a href=\"https://web.archive.org/web/20200709170526/https://redis.io/topics/governance\">Governance</a> page which was the inspiration for the current<br><a href=\"https://github.com/valkey-io/valkey/blob/unstable/GOVERNANCE\">Valkey governance</a>.</p>\n<p>In 2021, the Redis Labs changed its name to Redis Ltd. or just Redis. In this<br>article, we&#39;re using the name Redis Ltd. when referring to the company to avoid<br>confusion. By this time, Redis Ltd. had acquired the trademark rights to the<br>name Redis and the logo from Sanfilippo.</p>\n<h2>The end of open source Redis</h2>\n<p>In 2024, Redis Ltd. changed the license of Redis from the open source BSD<br>license to dual source-available licenses. This was announced in a blog post<br><a href=\"https://redis.io/blog/redis-adopts-dual-source-available-licensing/\">Redis Adopts Dual Source-Available Licensing</a> and the<br>license change was <a href=\"https://github.com/redis/redis/pull/13157\">committed to the repository</a> the same day.</p>\n<p>Neither of the licenses, Redis Source Available License (RSALv2) nor the Server<br>Side Public License (SSPLv1), are open source licenses, as neither meet the<br>criteria of an open source license.</p>\n<p>RSALv2 forbids the use of the software in database products, to prevent their<br>competitors from providing database products and services. Such a restriction is<br>not in line with <a href=\"https://opensource.org/osd\">The Open Source Definition</a>, criterion #6 “The license<br>must not restrict anyone from making use of the program in a specific field of<br>endeavor” by the Open Source Initiative, nor “the freedom to run the program as<br>you wish, for any purpose (freedom 0)” in the Free Software Foundation&#39;s<br>definition of Free Software. The SSPL has similar restrictions, explained in the<br><a href=\"https://en.wikipedia.org/wiki/Server_Side_Public_License\">SSPL article on Wikipedia</a>.</p>\n<h2>The birth of Valkey</h2>\n<p>Many contributors, including companies providing hosted Redis-derived or<br>Redis-compatible database services, just like Redis Ltd. does, have been using<br>and contributing to Redis just as long as Redis Ltd. has existed. It was<br>therefore and easy decision for many of them to continue the open source<br>development as usual under the BSD license.</p>\n<p>As Redis Ltd. owns the trademark rights to the name Redis, the open source<br>project needed to continue under a different name. A group of six active<br>contributors (one from each of Alibaba, Amazon, Ericsson, Google, Huawei and<br>Tencent) with the support from several other companies launched Valkey as a<br>Linux Foundation project. It was announced in a <a href=\"https://www.linuxfoundation.org/press/linux-foundation-launches-open-source-valkey-community\">press release</a> only<br>eight days after Redis&#39; license change. Three weeks later, a <a href=\"https://www.linuxfoundation.org/press/valkey-community-announces-release-candidate-amid-growing-support-for-open-source-data-store\">second press<br>release</a> announced seven more companies joining and the first<br>release, Valkey 7.2.5.</p>\n"
  },
  {
    "id": "hyperloglogs",
    "topicName": "HyperLogLog",
    "description": "HyperLogLog is a probabilistic data structure that estimates the cardinality of a set.\n",
    "htmlContent": "<p>HyperLogLog is a probabilistic data structure that estimates the cardinality of a set. As a probabilistic data structure, HyperLogLog trades perfect accuracy for efficient space utilization.</p>\n<p>The HyperLogLog implementation uses up to 12 KB and provides a standard error of 0.81%.</p>\n<p>Counting unique items usually requires an amount of memory<br>proportional to the number of items you want to count, because you need<br>to remember the elements you have already seen in the past in order to avoid<br>counting them multiple times. However, a set of algorithms exist that trade<br>memory for precision: they return an estimated measure with a standard error,<br>which, in the case of the Valkey implementation for HyperLogLog, is less than 1%.<br>The magic of this algorithm is that you no longer need to use an amount of memory<br>proportional to the number of items counted, and instead can use a<br>constant amount of memory; 12k bytes in the worst case, or a lot less if your<br>HyperLogLog (We&#39;ll just call them HLL from now) has seen very few elements.</p>\n<p>HLLs in Valkey, while technically a different data structure, are encoded<br>as a String, so you can call <code>GET</code> to serialize a HLL, and <code>SET</code><br>to deserialize it back to the server.</p>\n<p>Conceptually the HLL API is like using Sets to do the same task. You would<br><code>SADD</code> every observed element into a set, and would use <code>SCARD</code> to check the<br>number of elements inside the set, which are unique since <code>SADD</code> will not<br>re-add an existing element.</p>\n<p>While you don&#39;t really <em>add items</em> into an HLL, because the data structure<br>only contains a state that does not include actual elements, the API is the<br>same:</p>\n<ul>\n<li>Every time you see a new element, you add it to the count with <code>PFADD</code>.</li>\n<li>When you want to retrieve the current approximation of unique elements added using the <code>PFADD</code> command, you can use the <code>PFCOUNT</code> command. If you need to merge two different HLLs, the <code>PFMERGE</code> command is available. Since HLLs provide approximate counts of unique elements, the result of the merge will give you an approximation of the number of unique elements across both source HLLs.</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; PFADD bikes Hyperion Deimos Phoebe Quaoar\n(integer) 1\n127.0.0.1:6379&gt; PFCOUNT bikes\n(integer) 4\n127.0.0.1:6379&gt; PFADD commuter_bikes Salacia Mimas Quaoar\n(integer) 1\n127.0.0.1:6379&gt; PFMERGE all_bikes bikes commuter_bikes\nOK\n127.0.0.1:6379&gt; PFCOUNT all_bikes\n(integer) 6\n</code></pre>\n<p>Some examples of use cases for this data structure is counting unique queries<br>performed by users in a search form every day, number of unique visitors to a web page and other similar cases.</p>\n<p>Valkey is also able to perform the union of HLLs, please check the<br><a href=\"../commands/#hyperloglog\">full documentation</a> for more information.</p>\n<h2>Use cases</h2>\n<p><strong>Anonymous unique visits of a web page (SaaS, analytics tools)</strong> </p>\n<p>This application answers these questions: </p>\n<ul>\n<li>How many unique visits has this page had on this day? </li>\n<li>How many unique users have played this song? </li>\n<li>How many unique users have viewed this video?</li>\n</ul>\n<p><strong>Note:</strong><br>Storing the IP address or any other kind of personal identifier is against the law in some countries, which makes it impossible to get unique visitor statistics on your website.</p>\n<p>One HyperLogLog is created per page (video/song) per period, and every IP/identifier is added to it on every visit.</p>\n<h2>Basic commands</h2>\n<ul>\n<li><code>PFADD</code> adds an item to a HyperLogLog.</li>\n<li><code>PFCOUNT</code> returns an estimate of the number of items in the set.</li>\n<li><code>PFMERGE</code> combines two or more HyperLogLogs into one.</li>\n</ul>\n<p>See the <a href=\"../commands/#hyperloglog\">complete list of HyperLogLog commands</a>.</p>\n<h2>Performance</h2>\n<p>Writing (<code>PFADD</code>) to and reading from (<code>PFCOUNT</code>) the HyperLogLog is done in constant time and space.<br>Merging HLLs is O(n), where <em>n</em> is the number of sketches.</p>\n<h2>Limits</h2>\n<p>The HyperLogLog can estimate the cardinality of sets with up to 18,446,744,073,709,551,616 (2^64) members.</p>\n<h2>Learn more</h2>\n<ul>\n<li>This blog post on <a href=\"https://web.archive.org/web/20241019222035/http://antirez.com/news/75\">the HyperLogLog data structure</a> has a lot of details about the data structure and its implementation in Valkey.</li>\n</ul>\n"
  },
  {
    "id": "index",
    "topicName": "Valkey Documentation",
    "description": "",
    "htmlContent": "<p>The Valkey documentation is managed in markdown files in the<br><a href=\"https://github.com/valkey-io/valkey-doc\">valkey-doc repository</a>.<br>It&#39;s released under the<br><a href=\"https://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International license</a>.</p>\n<p>What is Valkey? See <a href=\"introduction\">Introduction</a>.</p>\n<h2>Programming with Valkey</h2>\n<ul>\n<li><a href=\"../commands/\">The full list of commands</a>, with documentation for each of them.</li>\n<li><a href=\"data-types\">Data types</a>: Keys are strings, but values can be of many different data types.</li>\n<li><a href=\"pipelining\">Pipelining</a>: How to send multiple commands at once, saving on round trip time.</li>\n<li><a href=\"pubsub\">Pub/Sub</a>: Using Valkey as a message broker using the Publish/Subscribe messaging system.</li>\n<li><a href=\"memory-optimization\">Memory optimization</a>: Understand how Valkey uses RAM.</li>\n<li><a href=\"../commands/expire\">Expires</a>: How to set a Time To Live (TTL) on key so that it will be automatically removed from the server when it expires.</li>\n<li><a href=\"lru-cache\">Valkey as an LRU cache</a>: How to configure Valkey as a cache with a fixed amount of memory and automatic eviction of keys.</li>\n<li><a href=\"transactions\">Transactions</a>: Valkey&#39;s approach to atomic transactions.</li>\n<li><a href=\"client-side-caching\">Client side caching</a>: How a client can be notified by the server when a key has changed.</li>\n<li><a href=\"notifications\">Keyspace notifications</a>: Get notifications of keyspace events via Pub/Sub.</li>\n<li><a href=\"protocol\">Protocol specification</a>: The client-server protocol, for client authors.</li>\n</ul>\n<h2>Server-side scripting in Valkey</h2>\n<ul>\n<li><a href=\"programmability\">Programmability overview</a>: An overview of programmability in Valkey.</li>\n<li><a href=\"lua-api\">Valkey Lua API</a>: The embedded <a href=\"https://lua.org\">Lua 5.1</a> interpreter runtime environment and APIs.</li>\n<li><a href=\"eval-intro\">Introduction to Eval Scripts</a>: An introduction about using cached scripts.</li>\n<li><a href=\"functions-intro\">Introduction to Valkey Functions</a>: An introduction about using functions.</li>\n<li><a href=\"ldb\">Debugging Lua scripts</a>: An overview of the native Valkey Lua debugger for cached scripts.</li>\n</ul>\n<h2>Administration</h2>\n<ul>\n<li><a href=\"installation\">Installation</a>: How to install and configure Valkey. This targets people without prior experience with Valkey.</li>\n<li><a href=\"cli\">valkey-cli</a>: The Valkey command line interface, used for administration, troubleshooting and experimenting with Valkey.</li>\n<li><a href=\"server\">valkey-server</a>: How to run the Valkey server.</li>\n<li><a href=\"valkey.conf\">Configuration</a>: How to configure Valkey.</li>\n<li><a href=\"replication\">Replication</a>: What you need to know to set up primary-replica replication.</li>\n<li><a href=\"migration\">Migration</a>: How to migrate from Redis to Valkey.</li>\n<li><a href=\"persistence\">Persistence</a>: Options for configuring durability using disk backups.</li>\n<li><a href=\"admin\">Administration</a>: Various administration topics.</li>\n<li><a href=\"security\">Security</a>: An overview of Valkey&#39;s security.</li>\n<li><a href=\"RDMA\">RDMA</a>: An overview of RDMA support.</li>\n<li><a href=\"acl\">Access Control Lists</a>: ACLs make it possible to allow users to run only selected commands and access only specific key patterns.</li>\n<li><a href=\"encryption\">Encryption</a>: How to use TLS for communication.</li>\n<li><a href=\"signals\">Signals Handling</a>: How Valkey handles signals.</li>\n<li><a href=\"clients\">Connections Handling</a>: How Valkey handles clients connections.</li>\n<li><a href=\"sentinel\">Sentinel</a>: Valkey Sentinel is one of the official high availability deployment modes.</li>\n<li><a href=\"releases\">Releases</a>: Valkey&#39;s development cycle and version numbering.</li>\n</ul>\n<h2>Valkey Cluster</h2>\n<ul>\n<li><a href=\"cluster-tutorial\">Cluster tutorial</a>: A gentle introduction to Valkey Cluster, a deployment mode for horizontal scaling and high availability.</li>\n<li><a href=\"cluster-spec\">Cluster specification</a>: The more formal description of the behavior and algorithms used in Valkey Cluster.</li>\n</ul>\n<h2>Valkey modules API</h2>\n<ul>\n<li><a href=\"modules-intro\">Introduction to Valkey modules</a>: Extend Valkey using dynamically linked modules.</li>\n<li><a href=\"modules-native-types\">Implementing native data types</a>: Modules scan implement new data types (data structures and more) that look like built-in data types. This documentation covers the API to do so.</li>\n<li><a href=\"modules-blocking-ops\">Blocking operations</a>: Write commands that can block the client (without blocking Valkey) and can execute tasks in other threads.</li>\n<li><a href=\"modules-api-ref\">Modules API reference</a>: Documentation of all module API functions. Low level details about API usage.</li>\n</ul>\n<h2>Performance</h2>\n<ul>\n<li><a href=\"latency-monitor\">Latency monitoring</a>: Integrated latency monitoring and reporting help tuning for low latency.</li>\n<li><a href=\"benchmark\">valkey-benchmark</a>: The benchmarking tool shipped with Valkey.</li>\n<li><a href=\"performance-on-cpu\">On-CPU profiling and tracing</a>: How to find on-CPU resource bottlenecks.</li>\n</ul>\n<h2>Tutorials &amp; FAQ</h2>\n<ul>\n<li><a href=\"quickstart\">Quick start</a>: Get started with Valkey.</li>\n<li><a href=\"mass-insertion\">Mass insertion of data</a>: How to add a big amount of data to a Valkey instance in a short time.</li>\n<li><a href=\"distlock\">Distributed locks</a>: Implementing a distributed lock manager.</li>\n<li><a href=\"indexing\">Secondary indexes</a>: How to simulate secondary indexes, composed indexes and traverse graphs using various data structures.</li>\n<li><a href=\"ARM\">ARM and Raspberry Pi</a>: ARM and the Raspberry Pi are supported platforms. This page contains general information and benchmarks.</li>\n<li><a href=\"twitter-clone\">Writing a simple Twitter clone with PHP and Valkey</a></li>\n<li><a href=\"problems\">Troubleshooting</a>: Problems? Bugs? High latency? Other issues? Use our problems troubleshooting page as a starting point to find more information.</li>\n<li><a href=\"faq\">FAQ</a>: Frequently asked questions.</li>\n</ul>\n<h2>Command runtime introspection</h2>\n<ul>\n<li><a href=\"key-specs\">Command key specifications</a>: How to extract the names of keys accessed by every command.</li>\n<li><a href=\"command-tips\">Command tips</a>: Command tips communicate non-trivial execution modes and post-processing information about commands.</li>\n<li><a href=\"command-arguments\">Command arguments</a>: An overview of command arguments as returned by the <code>COMMAND DOCS</code> command.</li>\n</ul>\n"
  },
  {
    "id": "indexing",
    "topicName": "Secondary indexing",
    "description": "Building secondary indexes in Valkey\n",
    "htmlContent": "<p>Valkey is not exactly a key-value store, since values can be complex data structures. However it has an external key-value shell: at API level data is addressed by the key name. It is fair to say that, natively, Valkey only offers <em>primary key access</em>. However since Valkey is a data structures server, its capabilities can be used for indexing, in order to create secondary indexes of different kinds, including composite (multi-column) indexes.</p>\n<p>This document explains how it is possible to create indexes in Valkey using the following data structures:</p>\n<ul>\n<li>Sorted sets to create secondary indexes by ID or other numerical fields.</li>\n<li>Sorted sets with lexicographical ranges for creating more advanced secondary indexes, composite indexes and graph traversal indexes.</li>\n<li>Sets for creating random indexes.</li>\n<li>Lists for creating simple iterable indexes and last N items indexes.</li>\n</ul>\n<p>Implementing and maintaining indexes with Valkey is an advanced topic, so most<br>users that need to perform complex queries on data should understand if they<br>are better served by a relational store. However often, especially in caching<br>scenarios, there is the explicit need to store indexed data into Valkey in order to speedup common queries which require some form of indexing in order to be executed.</p>\n<h1>Simple numerical indexes with sorted sets</h1>\n<p>The simplest secondary index you can create with Valkey is by using the<br>sorted set data type, which is a data structure representing a set of<br>elements ordered by a floating point number which is the <em>score</em> of<br>each element. Elements are ordered from the smallest to the highest score.</p>\n<p>Since the score is a double precision float, indexes you can build with<br>vanilla sorted sets are limited to things where the indexing field is a number<br>within a given range.</p>\n<p>The two commands to build these kind of indexes are <code>ZADD</code> and<br><code>ZRANGE</code> with the <code>BYSCORE</code> argument to respectively add items and retrieve items within a<br>specified range.</p>\n<p>For instance, it is possible to index a set of person names by their<br>age by adding element to a sorted set. The element will be the name of the<br>person and the score will be the age.</p>\n<pre><code>ZADD myindex 25 Manuel\nZADD myindex 18 Anna\nZADD myindex 35 Jon\nZADD myindex 67 Helen\n</code></pre>\n<p>In order to retrieve all persons with an age between 20 and 40, the following<br>command can be used:</p>\n<pre><code>ZRANGE myindex 20 40 BYSCORE\n1) &quot;Manuel&quot;\n2) &quot;Jon&quot;\n</code></pre>\n<p>By using the <strong>WITHSCORES</strong> option of <code>ZRANGE</code> it is also possible<br>to obtain the scores associated with the returned elements.</p>\n<p>The <code>ZCOUNT</code> command can be used in order to retrieve the number of elements<br>within a given range, without actually fetching the elements, which is also<br>useful, especially given the fact the operation is executed in logarithmic<br>time regardless of the size of the range.</p>\n<p>Ranges can be inclusive or exclusive, please refer to the <code>ZRANGE</code><br>command documentation for more information.</p>\n<p><strong>Note</strong>: Using the <code>ZRANGE</code> with the <code>BYSCORE</code> and <code>REV</code> arguments, it is possible to query a range in<br>reversed order, which is often useful when data is indexed in a given<br>direction (ascending or descending) but we want to retrieve information<br>the other way around.</p>\n<h2>Using objects IDs as associated values</h2>\n<p>In the above example we associated names to ages. However in general we<br>may want to index some field of an object which is stored elsewhere.<br>Instead of using the sorted set value directly to store the data associated<br>with the indexed field, it is possible to store just the ID of the object.</p>\n<p>For example I may have Hashes representing users. Each user is<br>represented by a single key, directly accessible by ID:</p>\n<pre><code>HSET user:1 id 1 username antirez ctime 1444809424 age 38\nHSET user:2 id 2 username maria ctime 1444808132 age 42\nHSET user:3 id 3 username jballard ctime 1443246218 age 33\n</code></pre>\n<p>If I want to create an index in order to query users by their age, I<br>could do:</p>\n<pre><code>ZADD user.age.index 38 1\nZADD user.age.index 42 2\nZADD user.age.index 33 3\n</code></pre>\n<p>This time the value associated with the score in the sorted set is the<br>ID of the object. So once I query the index with <code>ZRANGE</code> with the <code>BYSCORE</code> argument, I&#39;ll<br>also have to retrieve the information I need with <code>HGETALL</code> or similar<br>commands. The obvious advantage is that objects can change without touching<br>the index, as long as we don&#39;t change the indexed field.</p>\n<p>In the next examples we&#39;ll almost always use IDs as values associated with<br>the index, since this is usually the more sounding design, with a few<br>exceptions.</p>\n<h2>Updating simple sorted set indexes</h2>\n<p>Often we index things which change over time. In the above<br>example, the age of the user changes every year. In such a case it would<br>make sense to use the birth date as index instead of the age itself,<br>but there are other cases where we simply want some field to change from<br>time to time, and the index to reflect this change.</p>\n<p>The <code>ZADD</code> command makes updating simple indexes a very trivial operation<br>since re-adding back an element with a different score and the same value<br>will simply update the score and move the element at the right position,<br>so if the user <code>antirez</code> turned 39 years old, in order to update the<br>data in the hash representing the user, and in the index as well, we need<br>to execute the following two commands:</p>\n<pre><code>HSET user:1 age 39\nZADD user.age.index 39 1\n</code></pre>\n<p>The operation may be wrapped in a <code>MULTI</code>/<code>EXEC</code> transaction in order to<br>make sure both fields are updated or none.</p>\n<h2>Turning multi dimensional data into linear data</h2>\n<p>Indexes created with sorted sets are able to index only a single numerical<br>value. Because of this you may think it is impossible to index something<br>which has multiple dimensions using this kind of indexes, but actually this<br>is not always true. If you can efficiently represent something<br>multi-dimensional in a linear way, they it is often possible to use a simple<br>sorted set for indexing.</p>\n<p>For example the <a href=\"../commands/geoadd\">Valkey geo indexing API</a> uses a sorted<br>set to index places by latitude and longitude using a technique called<br><a href=\"https://en.wikipedia.org/wiki/Geohash\">Geo hash</a>. The sorted set score<br>represents alternating bits of longitude and latitude, so that we map the<br>linear score of a sorted set to many small <em>squares</em> in the earth surface.<br>By doing an 8+1 style center plus neighborhoods search it is possible to<br>retrieve elements by radius.</p>\n<h2>Limits of the score</h2>\n<p>Sorted set elements scores are double precision floats. It means that<br>they can represent different decimal or integer values with different<br>errors, because they use an exponential representation internally.<br>However what is interesting for indexing purposes is that the score is<br>always able to represent without any error numbers between -9007199254740992<br>and 9007199254740992, which is <code>-/+ 2^53</code>.</p>\n<p>When representing much larger numbers, you need a different form of indexing<br>that is able to index numbers at any precision, called a lexicographical<br>index.</p>\n<h1>Lexicographical indexes</h1>\n<p>Sorted Sets have an interesting property. When elements are added<br>with the same score, they are sorted lexicographically, comparing the<br>strings as binary data with the <code>memcmp()</code> function.</p>\n<p>For people that don&#39;t know the C language nor the <code>memcmp</code> function, what<br>it means is that elements with the same score are sorted comparing the<br>raw values of their bytes, byte after byte. If the first byte is the same,<br>the second is checked and so forth. If the common prefix of two strings is<br>the same then the longer string is considered the greater of the two,<br>so &quot;foobar&quot; is greater than &quot;foo&quot;.</p>\n<p>There are commands such as <code>ZRANGE</code> and <code>ZLEXCOUNT</code> that<br>are able to query and count ranges in a lexicographically fashion, assuming<br>they are used with sorted sets where all the elements have the same score.</p>\n<p>This Valkey feature is basically equivalent to a <code>b-tree</code> data structure which<br>is often used in order to implement indexes with traditional databases.<br>As you can guess, because of this, it is possible to use this Valkey data<br>structure in order to implement pretty fancy indexes.</p>\n<p>Before we dive into using lexicographical indexes, let&#39;s check how<br>sorted sets behave in this special mode of operation. Since we need to<br>add elements with the same score, we&#39;ll always use the special score of<br>zero.</p>\n<pre><code>ZADD myindex 0 baaa\nZADD myindex 0 abbb\nZADD myindex 0 aaaa\nZADD myindex 0 bbbb\n</code></pre>\n<p>Fetching all the elements from the sorted set immediately reveals that they<br>are ordered lexicographically.</p>\n<pre><code>ZRANGE myindex 0 -1\n1) &quot;aaaa&quot;\n2) &quot;abbb&quot;\n3) &quot;baaa&quot;\n4) &quot;bbbb&quot;\n</code></pre>\n<p>Now we can use <code>ZRANGE</code> with the <code>BYLEX</code> argument in order to perform range queries.</p>\n<pre><code>ZRANGE myindex [a (b BYLEX\n1) &quot;aaaa&quot;\n2) &quot;abbb&quot;\n</code></pre>\n<p>Note that in the range queries we prefixed the <code>min</code> and <code>max</code> elements<br>identifying the range with the special characters <code>[</code> and <code>(</code>.<br>This prefixes are mandatory, and they specify if the elements<br>of the range are inclusive or exclusive. So the range <code>[a (b</code> means give me<br>all the elements lexicographically between <code>a</code> inclusive and <code>b</code> exclusive,<br>which are all the elements starting with <code>a</code>.</p>\n<p>There are also two more special characters indicating the infinitely negative<br>string and the infinitely positive string, which are <code>-</code> and <code>+</code>.</p>\n<pre><code>ZRANGE myindex [b + BYLEX\n1) &quot;baaa&quot;\n2) &quot;bbbb&quot;\n</code></pre>\n<p>That&#39;s it basically. Let&#39;s see how to use these features to build indexes.</p>\n<h2>A first example: completion</h2>\n<p>An interesting application of indexing is completion. Completion is what<br>happens when you start typing your query into a search engine: the user<br>interface will anticipate what you are likely typing, providing common<br>queries that start with the same characters.</p>\n<p>A naive approach to completion is to just add every single query we<br>get from the user into the index. For example if the user searches <code>banana</code><br>we&#39;ll just do:</p>\n<pre><code>ZADD myindex 0 banana\n</code></pre>\n<p>And so forth for each search query ever encountered. Then when we want to<br>complete the user input, we execute a range query using <code>ZRANGE</code> with the <code>BYLEX</code> argument.<br>Imagine the user is typing &quot;bit&quot; inside the search form, and we want to<br>offer possible search keywords starting for &quot;bit&quot;. We send Valkey a command<br>like that:</p>\n<pre><code>ZRANGE myindex &quot;[bit&quot; &quot;[bit\\xff&quot; BYLEX\n</code></pre>\n<p>Basically we create a range using the string the user is typing right now<br>as start, and the same string plus a trailing byte set to 255, which is <code>\\xff</code> in the example, as the end of the range. This way we get all the strings that start for the string the user is typing.</p>\n<p>Note that we don&#39;t want too many items returned, so we may use the <strong>LIMIT</strong> option in order to reduce the number of results.</p>\n<h2>Adding frequency into the mix</h2>\n<p>The above approach is a bit naive, because all the user searches are the same<br>in this way. In a real system we want to complete strings according to their<br>frequency: very popular searches will be proposed with a higher probability<br>compared to search strings typed very rarely.</p>\n<p>In order to implement something which depends on the frequency, and at the<br>same time automatically adapts to future inputs, by purging searches that<br>are no longer popular, we can use a very simple <em>streaming algorithm</em>.</p>\n<p>To start, we modify our index in order to store not just the search term,<br>but also the frequency the term is associated with. So instead of just adding<br><code>banana</code> we add <code>banana:1</code>, where 1 is the frequency.</p>\n<pre><code>ZADD myindex 0 banana:1\n</code></pre>\n<p>We also need logic in order to increment the index if the search term<br>already exists in the index, so what we&#39;ll actually do is something like<br>that:</p>\n<pre><code>ZRANGE myindex &quot;[banana:&quot; + BYLEX LIMIT 0 1\n1) &quot;banana:1&quot;\n</code></pre>\n<p>This will return the single entry of <code>banana</code> if it exists. Then we<br>can increment the associated frequency and send the following two<br>commands:</p>\n<pre><code>ZREM myindex 0 banana:1\nZADD myindex 0 banana:2\n</code></pre>\n<p>Note that because it is possible that there are concurrent updates, the<br>above three commands should be send via a <a href=\"../commands/eval\">Lua script</a><br>instead, so that the Lua script will atomically get the old count and<br>re-add the item with incremented score.</p>\n<p>So the result will be that, every time a user searches for <code>banana</code> we&#39;ll<br>get our entry updated.</p>\n<p>There is more: our goal is to just have items searched very frequently.<br>So we need some form of purging. When we actually query the index<br>in order to complete the user input, we may see something like that:</p>\n<pre><code>ZRANGE myindex &quot;[banana:&quot; + BYLEX LIMIT 0 10\n1) &quot;banana:123&quot;\n2) &quot;banaooo:1&quot;\n3) &quot;banned user:49&quot;\n4) &quot;banning:89&quot;\n</code></pre>\n<p>Apparently nobody searches for &quot;banaooo&quot;, for example, but the query was<br>performed a single time, so we end presenting it to the user.</p>\n<p>This is what we can do. Out of the returned items, we pick a random one,<br>decrement its score by one, and re-add it with the new score.<br>However if the score reaches 0, we simply remove the item from the list.<br>You can use much more advanced systems, but the idea is that the index in<br>the long run will contain top searches, and if top searches will change over<br>the time it will adapt automatically.</p>\n<p>A refinement to this algorithm is to pick entries in the list according to<br>their weight: the higher the score, the less likely entries are picked<br>in order to decrement its score, or evict them.</p>\n<h2>Normalizing strings for case and accents</h2>\n<p>In the completion examples we always used lowercase strings. However<br>reality is much more complex than that: languages have capitalized names,<br>accents, and so forth.</p>\n<p>One simple way do deal with this issues is to actually normalize the<br>string the user searches. Whatever the user searches for &quot;Banana&quot;,<br>&quot;BANANA&quot; or &quot;Ba&#39;nana&quot; we may always turn it into &quot;banana&quot;.</p>\n<p>However sometimes we may like to present the user with the original<br>item typed, even if we normalize the string for indexing. In order to<br>do this, what we do is to change the format of the index so that instead<br>of just storing <code>term:frequency</code> we store <code>normalized:frequency:original</code><br>like in the following example:</p>\n<pre><code>ZADD myindex 0 banana:273:Banana\n</code></pre>\n<p>Basically we add another field that we&#39;ll extract and use only for<br>visualization. Ranges will always be computed using the normalized strings<br>instead. This is a common trick which has multiple applications.</p>\n<h2>Adding auxiliary information in the index</h2>\n<p>When using a sorted set in a direct way, we have two different attributes<br>for each object: the score, which we use as an index, and an associated<br>value. When using lexicographical indexes instead, the score is always<br>set to 0 and basically not used at all. We are left with a single string,<br>which is the element itself.</p>\n<p>Like we did in the previous completion examples, we are still able to<br>store associated data using separators. For example we used the colon in<br>order to add the frequency and the original word for completion.</p>\n<p>In general we can add any kind of associated value to our indexing key.<br>In order to use a lexicographical index to implement a simple key-value store<br>we just store the entry as <code>key:value</code>:</p>\n<pre><code>ZADD myindex 0 mykey:myvalue\n</code></pre>\n<p>And search for the key with:</p>\n<pre><code>ZRANGE myindex [mykey: + BYLEX LIMIT 0 1\n1) &quot;mykey:myvalue&quot;\n</code></pre>\n<p>Then we extract the part after the colon to retrieve the value.<br>However a problem to solve in this case is collisions. The colon character<br>may be part of the key itself, so it must be chosen in order to never<br>collide with the key we add.</p>\n<p>Since lexicographical ranges in Valkey are binary safe you can use any<br>byte or any sequence of bytes. However if you receive untrusted user<br>input, it is better to use some form of escaping in order to guarantee<br>that the separator will never happen to be part of the key.</p>\n<p>For example if you use two null bytes as separator <code>&quot;\\0\\0&quot;</code>, you may<br>want to always escape null bytes into two bytes sequences in your strings.</p>\n<h2>Numerical padding</h2>\n<p>Lexicographical indexes may look like good only when the problem at hand<br>is to index strings. Actually it is very simple to use this kind of index<br>in order to perform indexing of arbitrary precision numbers.</p>\n<p>In the ASCII character set, digits appear in the order from 0 to 9, so<br>if we left-pad numbers with leading zeroes, the result is that comparing<br>them as strings will order them by their numerical value.</p>\n<pre><code>ZADD myindex 0 00324823481:foo\nZADD myindex 0 12838349234:bar\nZADD myindex 0 00000000111:zap\n\nZRANGE myindex 0 -1\n1) &quot;00000000111:zap&quot;\n2) &quot;00324823481:foo&quot;\n3) &quot;12838349234:bar&quot;\n</code></pre>\n<p>We effectively created an index using a numerical field which can be as<br>big as we want. This also works with floating point numbers of any precision<br>by making sure we left pad the numerical part with leading zeroes and the<br>decimal part with trailing zeroes like in the following list of numbers:</p>\n<pre><code>    01000000000000.11000000000000\n    01000000000000.02200000000000\n    00000002121241.34893482930000\n    00999999999999.00000000000000\n</code></pre>\n<h2>Using numbers in binary form</h2>\n<p>Storing numbers in decimal may use too much memory. An alternative approach<br>is just to store numbers, for example 128 bit integers, directly in their<br>binary form. However for this to work, you need to store the numbers in<br><em>big endian format</em>, so that the most significant bytes are stored before<br>the least significant bytes. This way when Valkey compares the strings with<br><code>memcmp()</code>, it will effectively sort the numbers by their value.</p>\n<p>Keep in mind that data stored in binary format is less observable for<br>debugging, harder to parse and export. So it is definitely a trade off.</p>\n<h1>Composite indexes</h1>\n<p>So far we explored ways to index single fields. However we all know that<br>SQL stores are able to create indexes using multiple fields. For example<br>I may index products in a very large store by room number and price.</p>\n<p>I need to run queries in order to retrieve all the products in a given<br>room having a given price range. What I can do is to index each product<br>in the following way:</p>\n<pre><code>ZADD myindex 0 0056:0028.44:90\nZADD myindex 0 0034:0011.00:832\n</code></pre>\n<p>Here the fields are <code>room:price:product_id</code>. I used just four digits padding<br>in the example for simplicity. The auxiliary data (the product ID) does not<br>need any padding.</p>\n<p>With an index like that, to get all the products in room 56 having a price<br>between 10 and 30 dollars is very easy. We can just run the following<br>command:</p>\n<pre><code>ZRANGE myindex [0056:0010.00 [0056:0030.00 BYLEX\n</code></pre>\n<p>The above is called a composed index. Its effectiveness depends on the<br>order of the fields and the queries I want to run. For example the above<br>index cannot be used efficiently in order to get all the products having<br>a specific price range regardless of the room number. However I can use<br>the primary key in order to run queries regardless of the price, like<br><em>give me all the products in room 44</em>.</p>\n<p>Composite indexes are very powerful, and are used in traditional stores<br>in order to optimize complex queries. In Valkey they could be useful both<br>to implement a very fast in-memory Valkey index of something stored into<br>a traditional data store, or in order to directly index Valkey data.</p>\n<h1>Updating lexicographical indexes</h1>\n<p>The value of the index in a lexicographical index can get pretty fancy<br>and hard or slow to rebuild from what we store about the object. So one<br>approach to simplify the handling of the index, at the cost of using more<br>memory, is to also take alongside to the sorted set representing the index<br>a hash mapping the object ID to the current index value.</p>\n<p>So for example, when we index we also add to a hash:</p>\n<pre><code>MULTI\nZADD myindex 0 0056:0028.44:90\nHSET index.content 90 0056:0028.44:90\nEXEC\n</code></pre>\n<p>This is not always needed, but simplifies the operations of updating<br>the index. In order to remove the old information we indexed for the object<br>ID 90, regardless of the <em>current</em> fields values of the object, we just<br>have to retrieve the hash value by object ID and <code>ZREM</code> it in the sorted<br>set view.</p>\n<h1>Representing and querying graphs using a hexastore</h1>\n<p>One cool thing about composite indexes is that they are handy in order<br>to represent graphs, using a data structure which is called<br><a href=\"https://www.vldb.org/pvldb/vol1/1453965.pdf\">Hexastore</a>.</p>\n<p>The hexastore provides a representation for relations between objects,<br>formed by a <em>subject</em>, a <em>predicate</em> and an <em>object</em>.<br>A simple relation between objects could be:</p>\n<pre><code>antirez is-friend-of matteocollina\n</code></pre>\n<p>In order to represent this relation I can store the following element<br>in my lexicographical index:</p>\n<pre><code>ZADD myindex 0 spo:antirez:is-friend-of:matteocollina\n</code></pre>\n<p>Note that I prefixed my item with the string <strong>spo</strong>. It means that<br>the item represents a subject,predicate,object relation.</p>\n<p>In can add 5 more entries for the same relation, but in a different order:</p>\n<pre><code>ZADD myindex 0 sop:antirez:matteocollina:is-friend-of\nZADD myindex 0 ops:matteocollina:is-friend-of:antirez\nZADD myindex 0 osp:matteocollina:antirez:is-friend-of\nZADD myindex 0 pso:is-friend-of:antirez:matteocollina\nZADD myindex 0 pos:is-friend-of:matteocollina:antirez\n</code></pre>\n<p>Now things start to be interesting, and I can query the graph in many<br>different ways. For example, who are all the people <code>antirez</code><br><em>is friend of</em>?</p>\n<pre><code>ZRANGE myindex &quot;[spo:antirez:is-friend-of:&quot; &quot;[spo:antirez:is-friend-of:\\xff&quot; BYLEX\n1) &quot;spo:antirez:is-friend-of:matteocollina&quot;\n2) &quot;spo:antirez:is-friend-of:wonderwoman&quot;\n3) &quot;spo:antirez:is-friend-of:spiderman&quot;\n</code></pre>\n<p>Or, what are all the relationships <code>antirez</code> and <code>matteocollina</code> have where<br>the first is the subject and the second is the object?</p>\n<pre><code>ZRANGE myindex &quot;[sop:antirez:matteocollina:&quot; &quot;[sop:antirez:matteocollina:\\xff&quot; BYLEX\n1) &quot;sop:antirez:matteocollina:is-friend-of&quot;\n2) &quot;sop:antirez:matteocollina:was-at-conference-with&quot;\n3) &quot;sop:antirez:matteocollina:talked-with&quot;\n</code></pre>\n<p>By combining different queries, I can ask fancy questions. For example:<br><em>Who are all my friends that, like beer, live in Barcelona, and matteocollina consider friends as well?</em><br>To get this information I start with an <code>spo</code> query to find all the people<br>I&#39;m friend with. Then for each result I get I perform an <code>spo</code> query<br>to check if they like beer, removing the ones for which I can&#39;t find<br>this relation. I do it again to filter by city. Finally I perform an <code>ops</code><br>query to find, of the list I obtained, who is considered friend by<br>matteocollina.</p>\n<p>Make sure to check <a href=\"https://nodejsconfit.levelgraph.io/\">Matteo Collina&#39;s slides about Levelgraph</a> in order to better understand these ideas.</p>\n<h1>Multi dimensional indexes</h1>\n<p>A more complex type of index is an index that allows you to perform queries<br>where two or more variables are queried at the same time for specific<br>ranges. For example I may have a data set representing persons age and<br>salary, and I want to retrieve all the people between 50 and 55 years old<br>having a salary between 70000 and 85000.</p>\n<p>This query may be performed with a multi column index, but this requires<br>us to select the first variable and then scan the second, which means we<br>may do a lot more work than needed. It is possible to perform these kinds of<br>queries involving multiple variables using different data structures.<br>For example, multi-dimensional trees such as <em>k-d trees</em> or <em>r-trees</em> are<br>sometimes used. Here we&#39;ll describe a different way to index data into<br>multiple dimensions, using a representation trick that allows us to perform<br>the query in a very efficient way using Valkey lexicographical ranges.</p>\n<p>Let&#39;s say we have points in the space, which represent our data samples, where <code>x</code> and <code>y</code> are our coordinates. The max value of both variables is 400.</p>\n<p>In the next figure, the blue box represents our query. We want all the points where <code>x</code> is between 50 and 100, and where <code>y</code> is between 100 and 300.</p>\n<p><img src=\"2idx_0.png\" alt=\"Points in the space\"></p>\n<p>In order to represent data that makes these kinds of queries fast to perform,<br>we start by padding our numbers with 0. So for example imagine we want to<br>add the point 10,25 (x,y) to our index. Given that the maximum range in the<br>example is 400 we can just pad to three digits, so we obtain:</p>\n<pre><code>x = 010\ny = 025\n</code></pre>\n<p>Now what we do is to interleave the digits, taking the leftmost digit<br>in x, and the leftmost digit in y, and so forth, in order to create a single<br>number:</p>\n<pre><code>001205\n</code></pre>\n<p>This is our index, however in order to more easily reconstruct the original<br>representation, if we want (at the cost of space), we may also add the<br>original values as additional columns:</p>\n<pre><code>001205:10:25\n</code></pre>\n<p>Now, let&#39;s reason about this representation and why it is useful in the<br>context of range queries. For example let&#39;s take the center of our blue<br>box, which is at <code>x=75</code> and <code>y=200</code>. We can encode this number as we did<br>earlier by interleaving the digits, obtaining:</p>\n<pre><code>027050\n</code></pre>\n<p>What happens if we substitute the last two digits respectively with 00 and 99?<br>We obtain a range which is lexicographically continuous:</p>\n<pre><code>027000 to 027099\n</code></pre>\n<p>What this maps to is to a square representing all values where the <code>x</code><br>variable is between 70 and 79, and the <code>y</code> variable is between 200 and 209.<br>To identify this specific area, we can write random points in that interval.</p>\n<p><img src=\"2idx_1.png\" alt=\"Small area\"></p>\n<p>So the above lexicographic query allows us to easily query for points in<br>a specific square in the picture. However the square may be too small for<br>the box we are searching, so that too many queries are needed.<br>So we can do the same but instead of replacing the last two digits with 00<br>and 99, we can do it for the last four digits, obtaining the following<br>range:</p>\n<pre><code>020000 029999\n</code></pre>\n<p>This time the range represents all the points where <code>x</code> is between 0 and 99<br>and <code>y</code> is between 200 and 299. Drawing random points in this interval<br>shows us this larger area.</p>\n<p><img src=\"2idx_2.png\" alt=\"Large area\"></p>\n<p>So now our area is too big for our query, and still our search box is<br>not completely included. We need more granularity, but we can easily obtain<br>it by representing our numbers in binary form. This time, when we replace<br>digits instead of getting squares which are ten times bigger, we get squares<br>which are just two times bigger.</p>\n<p>Our numbers in binary form, assuming we need just 9 bits for each variable<br>(in order to represent numbers up to 400 in value) would be:</p>\n<pre><code>x = 75  -&gt; 001001011\ny = 200 -&gt; 011001000\n</code></pre>\n<p>So by interleaving digits, our representation in the index would be:</p>\n<pre><code>000111000011001010:75:200\n</code></pre>\n<p>Let&#39;s see what are our ranges as we substitute the last 2, 4, 6, 8, ...<br>bits with 0s ad 1s in the interleaved representation:</p>\n<pre><code>2 bits: x between 74 and 75, y between 200 and 201 (range=2)\n4 bits: x between 72 and 75, y between 200 and 203 (range=4)\n6 bits: x between 72 and 79, y between 200 and 207 (range=8)\n8 bits: x between 64 and 79, y between 192 and 207 (range=16)\n</code></pre>\n<p>And so forth. Now we have definitely better granularity!<br>As you can see substituting N bits from the index gives us<br>search boxes of side <code>2^(N/2)</code>.</p>\n<p>So what we do is check the dimension where our search box is smaller,<br>and check the nearest power of two to this number. Our search box<br>was 50,100 to 100,300, so it has a width of 50 and a height of 200.<br>We take the smaller of the two, 50, and check the nearest power of two<br>which is 64. 64 is 2^6, so we would work with indexes obtained replacing<br>the latest 12 bits from the interleaved representation (so that we end<br>replacing just 6 bits of each variable).</p>\n<p>However single squares may not cover all our search, so we may need more.<br>What we do is to start with the left bottom corner of our search box,<br>which is 50,100, and find the first range by substituting the last 6 bits<br>in each number with 0. Then we do the same with the right top corner.</p>\n<p>With two trivial nested for loops where we increment only the significant<br>bits, we can find all the squares between these two. For each square we<br>convert the two numbers into our interleaved representation, and create<br>the range using the converted representation as our start, and the same<br>representation but with the latest 12 bits turned on as end range.</p>\n<p>For each square found we perform our query and get the elements inside,<br>removing the elements which are outside our search box.</p>\n<p>Turning this into code is simple. Here is a Ruby example:</p>\n<pre><code class=\"language-ruby\">def spacequery(x0,y0,x1,y1,exp)\n    bits=exp*2\n    x_start = x0/(2**exp)\n    x_end = x1/(2**exp)\n    y_start = y0/(2**exp)\n    y_end = y1/(2**exp)\n    (x_start..x_end).each{|x|\n        (y_start..y_end).each{|y|\n            x_range_start = x*(2**exp)\n            x_range_end = x_range_start | ((2**exp)-1)\n            y_range_start = y*(2**exp)\n            y_range_end = y_range_start | ((2**exp)-1)\n            puts &quot;#{x},#{y} x from #{x_range_start} to #{x_range_end}, y from #{y_range_start} to #{y_range_end}&quot;\n\n            # Turn it into interleaved form for ZRANGE query.\n            # We assume we need 9 bits for each integer, so the final\n            # interleaved representation will be 18 bits.\n            xbin = x_range_start.to_s(2).rjust(9,&#39;0&#39;)\n            ybin = y_range_start.to_s(2).rjust(9,&#39;0&#39;)\n            s = xbin.split(&quot;&quot;).zip(ybin.split(&quot;&quot;)).flatten.compact.join(&quot;&quot;)\n            # Now that we have the start of the range, calculate the end\n            # by replacing the specified number of bits from 0 to 1.\n            e = s[0..-(bits+1)]+(&quot;1&quot;*bits)\n            puts &quot;ZRANGE myindex [#{s} [#{e} BYLEX&quot;\n        }\n    }\nend\n\nspacequery(50,100,100,300,6)\n</code></pre>\n<p>While non immediately trivial this is a very useful indexing strategy that<br>in the future may be implemented in Valkey in a native way.<br>For now, the good thing is that the complexity may be easily encapsulated<br>inside a library that can be used in order to perform indexing and queries.<br>One example of such library is <a href=\"https://github.com/antirez/redimension\">Redimension</a>, a proof of concept Ruby library which indexes N-dimensional data inside Valkey using the technique described here.</p>\n<h1>Multi dimensional indexes with negative or floating point numbers</h1>\n<p>The simplest way to represent negative values is just to work with unsigned<br>integers and represent them using an offset, so that when you index, before<br>translating numbers in the indexed representation, you add the absolute value<br>of your smaller negative integer.</p>\n<p>For floating point numbers, the simplest approach is probably to convert them<br>to integers by multiplying the integer for a power of ten proportional to the<br>number of digits after the dot you want to retain.</p>\n<h1>Non range indexes</h1>\n<p>So far we checked indexes which are useful to query by range or by single<br>item. However other Valkey data structures such as Sets or Lists can be used<br>in order to build other kind of indexes. They are very commonly used but<br>maybe we don&#39;t always realize they are actually a form of indexing.</p>\n<p>For instance I can index object IDs into a Set data type in order to use<br>the <em>get random elements</em> operation via <code>SRANDMEMBER</code> in order to retrieve<br>a set of random objects. Sets can also be used to check for existence when<br>all I need is to test if a given item exists or not or has a single boolean<br>property or not.</p>\n<p>Similarly lists can be used in order to index items into a fixed order.<br>I can add all my items into a List and rotate the list with<br><code>RPOPLPUSH</code> using the same key name as source and destination. This is useful<br>when I want to process a given set of items again and again forever in the<br>same order. Think of an RSS feed system that needs to refresh the local copy<br>periodically.</p>\n<p>Another popular index often used with Valkey is a <strong>capped list</strong>, where items<br>are added with <code>LPUSH</code> and trimmed with <code>LTRIM</code>, in order to create a view<br>with just the latest N items encountered, in the same order they were<br>seen.</p>\n<h1>Index inconsistency</h1>\n<p>Keeping the index updated may be challenging, in the course of months<br>or years it is possible that inconsistencies are added because of software<br>bugs, network partitions or other events.</p>\n<p>Different strategies could be used. If the index data is outside Valkey<br><em>read repair</em> can be a solution, where data is fixed in a lazy way when<br>it is requested. When we index data which is stored in Valkey itself<br>the <code>SCAN</code> family of commands can be used in order to verify, update or<br>rebuild the index from scratch, incrementally.</p>\n"
  },
  {
    "id": "installation",
    "topicName": "Installation",
    "description": "Install Valkey on Linux, macOS, and Windows\n",
    "htmlContent": "<p>This is a an installation guide. You&#39;ll learn how to install, run, and experiment with the Valkey server process.</p>\n<p>The download page <a href=\"https://valkey.io/download\">valkey.io/download</a> lists the latest releases.</p>\n<h2>Install Valkey</h2>\n<p>These are some ways to install Valkey.<br>Refer to <a href=\"admin\">Valkey Administration</a> for detailed setup tips.</p>\n<h3>From source</h3>\n<p>Source releases are available from the GitHub <a href=\"https://github.com/valkey-io/valkey/releases\">Releases</a> page.</p>\n<p>Unpack the tarball (e.g. <code>tar -xzvf valkey-8.0.1.tar.gz</code>) and follow the instructions in the included README.md.</p>\n<h3>Containers</h3>\n<p>Containers on <a href=\"https://hub.docker.com/r/valkey/valkey/\">Docker Hub</a>.</p>\n<h3>MacOS</h3>\n<h4>Using <a href=\"https://brew.sh/\">Homebrew</a> to install and run Valkey:</h4>\n<pre><code class=\"language-bash\">brew install valkey\n# To run Valkey as a service, use\nbrew services start valkey\n# Check that it&#39;s running using\nbrew services info valkey\n# and stop it using\nbrew services stop valkey\n</code></pre>\n<h4>Using <a href=\"https://www.macports.org/\">MacPorts</a>:</h4>\n<pre><code class=\"language-bash\">sudo port install valkey\n</code></pre>\n<h3>Linux/BSD package managers</h3>\n<p>The following package managers are known to be supported, but the list is not exhaustive and may not be up to date.<br>If you see an issue, feel free to submit a PR to update this list.<br>You can use the <a href=\"https://pkgs.org/download/valkey\">pkgs.org</a> website (linux/unix only) or <a href=\"https://repology.org/project/valkey/versions\">repology.org</a> to check which versions of Valkey are available for your distributions.</p>\n<h4>apt (Debian based)</h4>\n<p>Currently available on:<br>Debian/Ubuntu/Mint/Devuan/Raspbian/PureOS</p>\n<pre><code class=\"language-bash\">sudo apt update\nsudo apt install valkey\n# For symlinked binaries to redis-cli and redis-server\nsudo apt install valkey-compat\n</code></pre>\n<h4>apk (Alpine Linux/Kali Linux/Wolfi)</h4>\n<pre><code class=\"language-bash\">sudo apk update\nsudo apk add valkey\n# Below relevant for Alpine.\n# For valkey-cli\nsudo apk add valkey-cli\n# For symlinked binaries to redis-cli and redis-server\nsudo apk add valkey-compat\n</code></pre>\n<h4>yum (CentOS/RHEL/Fedora)</h4>\n<pre><code class=\"language-bash\">sudo yum install valkey\n# For symlinked binaries to redis-cli and redis-server\nsudo yum install valkey-compat\n# For valkey-doc (can be used with man, e.g. `man hgetall`, `man valkey.conf`, etc.)\nsudo yum install valkey-doc\n</code></pre>\n<p>Some versions of CentOS and RHEL may not have Valkey in their default repositories.<br>You can use the EPEL repository - <a href=\"https://fedoraproject.org/wiki/EPEL\">https://fedoraproject.org/wiki/EPEL</a> to install Valkey.</p>\n<h4>dnf (Fedora)</h4>\n<pre><code class=\"language-bash\">sudo dnf install valkey\n# For symlinked binaries to redis-cli and redis-server\nsudo dnf install valkey-compat\n# For valkey-doc (can be used with man, e.g. `man hgetall`, `man valkey.conf`, etc.)\nsudo dnf install valkey-doc\n</code></pre>\n<h4>Other distributions</h4>\n<pre><code class=\"language-bash\"># ALT Linux\nsudo apt-get install valkey\n# Arch Linux/Manjaro\nsudo pacman -Sy valkey\n# FreeBSD\nsudo pkg install valkey\n# NixOS\nnix-env -i valkey\n# openSUSE\nsudo zypper install valkey\n# Solus\nsudo eopkg install valkey\n# Void Linux\nsudo xbps-install -Su valkey\n# Exherbo\ncave resolve -x dev-db/valkey\n</code></pre>\n<h4>Miscellaneous</h4>\n<p>Available on <a href=\"https://slackbuilds.org/repository/15.0/system/valkey/\">SlackBuilds</a><br>and openpkg on <a href=\"https://openpkg.com/\">OpenPKG</a>.</p>\n<h3>Windows</h3>\n<p>Valkey is not officially supported on Windows. However, you can install Valkey<br>on Windows for development using WSL (Windows Subsystem for Linux).</p>\n<h2>Test if you can connect using the CLI</h2>\n<p>If you&#39;re not yet running Valkey as a system service,<br>you can run Valkey in the foreground using <code>valkey-server</code> and stop it using Ctrl-C.</p>\n<p>When you have Valkey up and running, you can connect using <code>valkey-cli</code>.</p>\n<p>External programs talk to Valkey using a TCP socket and a Valkey specific protocol. This protocol is implemented in the Valkey client libraries for the different programming languages. However, to make hacking with Valkey simpler, Valkey provides a command line utility that can be used to send commands to Valkey. This program is called <strong>valkey-cli</strong>.</p>\n<p>The first thing to do to check if Valkey is working properly is sending a <strong>PING</strong> command using <code>valkey-cli</code>:</p>\n<pre><code>$ valkey-cli ping\nPONG\n</code></pre>\n<p>Running <strong>valkey-cli</strong> followed by a command name and its arguments will send this command to the Valkey instance running on localhost at port 6379. You can change the host and port used by <code>valkey-cli</code> - just try the <code>--help</code> option to check the usage information.</p>\n<p>Another interesting way to run <code>valkey-cli</code> is without arguments: the program will start in interactive mode. You can type different commands and see their replies.</p>\n<pre><code>$ valkey-cli\n127.0.0.1:6379&gt; ping\nPONG\n</code></pre>\n<h2>Securing Valkey</h2>\n<p>By default Valkey binds to <strong>all the interfaces</strong> and has no authentication at all. If you use Valkey in a very controlled environment, separated from the external internet and in general from attackers, that&#39;s fine. However, if an unhardened Valkey is exposed to the internet, it is a big security concern. If you are not 100% sure your environment is secured properly, please check the following steps in order to make Valkey more secure:</p>\n<ol>\n<li>Make sure the port Valkey uses to listen for connections (by default 6379 and additionally 16379 if you run Valkey in cluster mode, plus 26379 for Sentinel) is firewalled, so that it is not possible to contact Valkey from the outside world.</li>\n<li>Use a configuration file where the <code>bind</code> directive is set in order to guarantee that Valkey listens on only the network interfaces you are using. For example, only the loopback interface (127.0.0.1) if you are accessing Valkey locally from the same computer.</li>\n<li>Set up authentication using <a href=\"acl\">Access Control List (ACL)</a> or use the <code>requirepass</code> option to add an additional layer of security so that clients will be required to authenticate using the <code>AUTH</code> command.</li>\n<li>Use <a href=\"encryption\">TLS</a> to encrypt traffic between Valkey servers and Valkey clients if your environment requires encryption.</li>\n</ol>\n<p>Make sure you understand the above and apply <strong>at least</strong> a firewall layer. After the firewall is in place, try to connect with <code>valkey-cli</code> from an external host to confirm that the instance is not reachable.</p>\n<h2>Use Valkey from your application</h2>\n<p>Of course using Valkey just from the command line interface is not enough as the goal is to use it from your application. To do so, you need to download and install a Valkey client library for your programming language.</p>\n<p>You&#39;ll find a <a href=\"../clients/\">full list of clients for different languages in this page</a>.</p>\n<h2>Valkey persistence</h2>\n<p>You can learn <a href=\"persistence\">how Valkey persistence works on this page</a>.<br>It is important to understand that, if you start Valkey with the default configuration, Valkey will spontaneously save the dataset only from time to time.<br>For example, after at least five minutes if you have at least 100 changes in your data.<br>If you want your database to persist and be reloaded after a restart, make sure to call the <a href=\"../commands/save\">SAVE</a> command manually every time you want to force a data set snapshot.<br>Alternatively, you can save the data on disk before quitting by using the <a href=\"../commands/shutdown\">SHUTDOWN</a> command:</p>\n<pre><code>$ valkey-cli shutdown\n</code></pre>\n<p>This way, Valkey will save the data on disk before quitting. Reading the <a href=\"persistence\">persistence page</a> is strongly suggested to better understand how Valkey persistence works.</p>\n<h2>Install Valkey as a system service</h2>\n<p>Running Valkey from the command line is fine just to hack a bit or for development. However, at some point you&#39;ll have some actual application to run on a real server.<br>For this kind of usage, it&#39;s highly recommended to install Valkey as a system service so that everything will start properly after a system restart.<br>The available packages for supported Linux distributions already include the capability of starting the Valkey server as a service.</p>\n<p>Valkey supports systemd, but this document was written for init scripts, before systemd was widely adapted.<br>There are many guides online for how to set up a systemd service.</p>\n<p>The remainder of this section explains how to set up Valkey using an init script, for distros like Alpine Linux that don&#39;t use systemd.</p>\n<p>If you have not yet run <code>make install</code> after building the Valkey source, you will need to do so before continuing. By default, <code>make install</code> will copy the <code>valkey-server</code> and <code>valkey-cli</code> binaries to <code>/usr/local/bin</code>.</p>\n<ul>\n<li><p>Create a directory in which to store your Valkey config files and your data:</p>\n<pre><code>sudo mkdir /etc/valkey\nsudo mkdir /var/valkey\n</code></pre>\n</li>\n<li><p>Copy the init script that you&#39;ll find in the Valkey distribution under the <strong>utils</strong> directory into <code>/etc/init.d</code>. We suggest calling it with the name of the port where you are running this instance of Valkey. Make sure the resulting file has <code>0755</code> permissions.</p>\n<pre><code>sudo cp utils/valkey_init_script /etc/init.d/valkey_6379\n</code></pre>\n</li>\n<li><p>Edit the init script.</p>\n<pre><code>sudo vi /etc/init.d/valkey_6379\n</code></pre>\n</li>\n</ul>\n<p>Make sure to set the <code>VALKEYPORT</code> variable to the port you are using.<br>Both the pid file path and the configuration file name depend on the port number.</p>\n<ul>\n<li><p>Copy the template configuration file you&#39;ll find in the root directory of the Valkey distribution into <code>/etc/valkey/</code> using the port number as the name, for instance:</p>\n<pre><code>sudo cp valkey.conf /etc/valkey/6379.conf\n</code></pre>\n</li>\n<li><p>Create a directory inside <code>/var/valkey</code> that will work as both data and working directory for this Valkey instance:</p>\n<pre><code>sudo mkdir /var/valkey/6379\n</code></pre>\n</li>\n<li><p>Edit the configuration file, making sure to perform the following changes:</p>\n<ul>\n<li>Set <strong>daemonize</strong> to yes (by default it is set to no).</li>\n<li>Set the <strong>pidfile</strong> to <code>/var/run/valkey_6379.pid</code>, modifying the port as necessary.</li>\n<li>Change the <strong>port</strong> accordingly. In our example it is not needed as the default port is already <code>6379</code>.</li>\n<li>Set your preferred <strong>loglevel</strong>.</li>\n<li>Set the <strong>logfile</strong> to <code>/var/log/valkey_6379.log</code>.</li>\n<li>Set the <strong>dir</strong> to <code>/var/valkey/6379</code> (very important step!).</li>\n</ul>\n</li>\n<li><p>Finally, add the new Valkey init script to all the default runlevels using the following command:</p>\n<pre><code>sudo update-rc.d valkey_6379 defaults\n</code></pre>\n</li>\n</ul>\n<p>You are done! Now you can try running your instance with:</p>\n<pre><code>sudo /etc/init.d/valkey_6379 start\n</code></pre>\n<p>Make sure that everything is working as expected:</p>\n<ol>\n<li>Try pinging your instance within a <code>valkey-cli</code> session using the <code>PING</code> command.</li>\n<li>Do a test save with <code>valkey-cli save</code> and check that a dump file is correctly saved to <code>/var/valkey/6379/dump.rdb</code>.</li>\n<li>Check that your Valkey instance is logging to the <code>/var/log/valkey_6379.log</code> file.</li>\n<li>If it&#39;s a new machine where you can try it without problems, make sure that after a reboot everything is still working.</li>\n</ol>\n<h2>Configuring Valkey</h2>\n<p>The above instructions don&#39;t include all of the Valkey configuration parameters that you could change. For example, to use AOF persistence instead of RDB persistence, or to set up replication, and so forth.</p>\n<p>You should also read the example <a href=\"https://github.com/valkey-io/valkey/blob/unstable/valkey.conf\">valkey.conf</a> file, which is heavily annotated to help guide you on making changes. Further details can also be found in the <a href=\"valkey.conf\">configuration article on this site</a>.</p>\n"
  },
  {
    "id": "introduction",
    "topicName": "Introduction",
    "description": "Learn about the Valkey open source project",
    "htmlContent": "<p>Valkey is an open source (BSD licensed), in-memory <strong>data structure store</strong> used as a database, cache, message broker, and streaming engine. Valkey provides <a href=\"data-types\">data structures</a> such as<br><a href=\"strings\">strings</a>, <a href=\"hashes\">hashes</a>, <a href=\"lists\">lists</a>, <a href=\"sets\">sets</a>, <a href=\"sorted-sets\">sorted sets</a> with range queries, <a href=\"bitmaps\">bitmaps</a>, <a href=\"hyperloglogs\">hyperloglogs</a>, <a href=\"geospatial\">geospatial indexes</a>, and <a href=\"streams-intro\">streams</a>. Valkey has built-in <a href=\"replication\">replication</a>, <a href=\"eval-intro\">Lua scripting</a>, <a href=\"lru-cache\">LRU eviction</a>, <a href=\"transactions\">transactions</a>, and different levels of <a href=\"persistence\">on-disk persistence</a>, and provides high availability via <a href=\"sentinel\">Valkey Sentinel</a> and automatic partitioning with <a href=\"cluster-tutorial\">Valkey Cluster</a>.</p>\n<p>You can run <strong>atomic operations</strong><br>on these types, like <a href=\"../commands/append\">appending to a string</a>;<br><a href=\"../commands/hincrby\">incrementing the value in a hash</a>; <a href=\"../commands/lpush\">pushing an element to a<br>list</a>; <a href=\"../commands/sinter\">computing set intersection</a>,<br><a href=\"../commands/sunion\">union</a> and <a href=\"../commands/sdiff\">difference</a>;<br>or <a href=\"../commands/zrange\">getting the member with highest ranking in a sorted set</a>.</p>\n<p>To achieve top performance, Valkey works with an<br><strong>in-memory dataset</strong>. Depending on your use case, Valkey can persist your data either<br>by periodically <a href=\"persistence#snapshotting\">dumping the dataset to disk</a><br>or by <a href=\"persistence#append-only-file\">appending each command to a disk-based log</a>. You can also disable persistence if you just need a feature-rich, networked, in-memory cache.</p>\n<p>Valkey supports <a href=\"replication\">asynchronous replication</a>, with fast non-blocking synchronization and auto-reconnection with partial resynchronization on net split.</p>\n<p>Valkey also includes:</p>\n<ul>\n<li><a href=\"transactions\">Transactions</a></li>\n<li><a href=\"pubsub\">Pub/Sub</a></li>\n<li><a href=\"../commands/eval\">Lua scripting</a></li>\n<li><a href=\"../commands/expire\">Keys with a limited time-to-live</a></li>\n<li><a href=\"lru-cache\">LRU eviction of keys</a></li>\n<li><a href=\"sentinel\">Automatic failover</a></li>\n</ul>\n<p>You can use Valkey from most programming languages. See <a href=\"../clients/\">clients</a>.</p>\n<p>Valkey is written in <strong>ANSI C 11</strong> with Atomics and a few GCC/Clang built-ins like <code>__builtin_clz()</code>.<br>It works on most POSIX systems like Linux, *BSD and MacOS, without external dependencies.<br>Linux and MacOS are the two operating systems where Valkey is developed and tested the most, and we <strong>recommend using Linux for deployment</strong>.<br>Valkey may work on Solaris-derived systems like Illumos, but support is <em>best effort</em>.<br>Supported hardware includes x86-64 (AKA amd64), x86 (32-bit) and AArch64 (64-bit ARM).<br>It is also known to work on IBM z/Architecture like s390x and builds for this system are available from the Fedora distro.<br>There is no official support for Windows builds.</p>\n"
  },
  {
    "id": "key-specs",
    "topicName": "Command key specifications",
    "description": "What are command key specification and how to use them in your client",
    "htmlContent": "<p>Many of the commands in Valkey accept key names as input arguments.<br>The 9th element in the reply of <code>COMMAND</code> (and <code>COMMAND INFO</code>) is an array that consists of the command&#39;s key specifications.</p>\n<p>A <em>key specification</em> describes a rule for extracting the names of one or more keys from the arguments of a given command.<br>Key specifications provide a robust and flexible mechanism, compared to the <em>first key</em>, <em>last key</em> and <em>step</em> scheme employed until Redis OSS 7.0.<br>Before introducing these specifications, Valkey clients had no trivial programmatic means to extract key names for all commands.</p>\n<p>Cluster-aware Valkey clients had to have the keys&#39; extraction logic hard-coded in the cases of commands such as <code>EVAL</code> and <code>ZUNIONSTORE</code> that rely on a <em>numkeys</em> argument or <code>SORT</code> and its many clauses.<br>Alternatively, the <code>COMMAND GETKEYS</code> can be used to achieve a similar extraction effect but at a higher latency.</p>\n<p>A Valkey client isn&#39;t obligated to support key specifications.<br>It can continue using the legacy <em>first key</em>, <em>last key</em> and <em>step</em> scheme along with the <a href=\"../commands/command#flags\"><em>movablekeys</em> flag</a> that remain unchanged.</p>\n<p>However, a Valkey client that implements key specifications support can consolidate most of its keys&#39; extraction logic.<br>Even if the client encounters an unfamiliar type of key specification, it can always revert to the <code>COMMAND GETKEYS</code> command.</p>\n<p>That said, most cluster-aware clients only require a single key name to perform correct command routing, so it is possible that although a command features one unfamiliar specification, its other specification may still be usable by the client.</p>\n<p>Key specifications are maps with the following keys:</p>\n<ol>\n<li><strong>begin_search:</strong>: the starting index for keys&#39; extraction.</li>\n<li><strong>find_keys:</strong> the rule for identifying the keys relative to the BS.</li>\n<li><strong>notes</strong>: notes about this key spec, if there are any.</li>\n<li><strong>flags</strong>: indicate the type of data access.</li>\n</ol>\n<h2>begin_search</h2>\n<p>The <em>begin_search</em> value of a specification informs the client of the extraction&#39;s beginning.<br>The value is a map.<br>There are three types of <code>begin_search</code>:</p>\n<ol>\n<li><strong>index:</strong> key name arguments begin at a constant index.</li>\n<li><strong>keyword:</strong> key names start after a specific keyword (token).</li>\n<li><strong>unknown:</strong> an unknown type of specification - see the <a href=\"#incomplete\">incomplete flag section</a> for more details.</li>\n</ol>\n<h3>index</h3>\n<p>The <em>index</em> type of <code>begin_search</code> indicates that input keys appear at a constant index.<br>It is a map under the <em>spec</em> key with a single key:</p>\n<ol>\n<li><strong>index:</strong> the 0-based index from which the client should start extracting key names.</li>\n</ol>\n<h3>keyword</h3>\n<p>The <em>keyword</em> type of <code>begin_search</code> means a literal token precedes key name arguments.<br>It is a map under the <em>spec</em> with two keys:</p>\n<ol>\n<li><strong>keyword:</strong> the keyword (token) that marks the beginning of key name arguments.</li>\n<li><strong>startfrom:</strong> an index to the arguments array from which the client should begin searching.<br>  This can be a negative value, which means the search should start from the end of the arguments&#39; array, in reverse order.<br>  For example, <em>-2</em>&#39;s meaning is to search reverse from the penultimate argument.</li>\n</ol>\n<p>More examples of the <em>keyword</em> search type include:</p>\n<ul>\n<li><code>SET</code> has a <code>begin_search</code> specification of type <em>index</em> with a value of <em>1</em>.</li>\n<li><code>XREAD</code> has a <code>begin_search</code> specification of type <em>keyword</em> with the values <em>&quot;STREAMS&quot;</em> and <em>1</em> as <em>keyword</em> and <em>startfrom</em>, respectively.</li>\n<li><code>MIGRATE</code> has a <em>start_search</em> specification of type <em>keyword</em> with the values of <em>&quot;KEYS&quot;</em> and <em>-2</em>.</li>\n</ul>\n<h2>find_keys</h2>\n<p>The <code>find_keys</code> value of a key specification tells the client how to continue the search for key names.<br><code>find_keys</code> has three possible types:</p>\n<ol>\n<li><strong>range:</strong> keys stop at a specific index or relative to the last argument.</li>\n<li><strong>keynum:</strong> an additional argument specifies the number of input keys.</li>\n<li><strong>unknown:</strong> an unknown type of specification - see the <a href=\"#incomplete\">incomplete flag section</a> for more details.</li>\n</ol>\n<h3>range</h3>\n<p>The <em>range</em> type of <code>find_keys</code> is a map under the <em>spec</em> key with three keys:</p>\n<ol>\n<li><strong>lastkey:</strong> the index, relative to <code>begin_search</code>, of the last key argument.<br>  This can be a negative value, in which case it isn&#39;t relative.<br>  For example, <em>-1</em> indicates to keep extracting keys until the last argument, <em>-2</em> until one before the last, and so on.</li>\n<li><strong>keystep:</strong> the number of arguments that should be skipped, after finding a key, to find the next one.</li>\n<li><strong>limit:</strong> if <em>lastkey</em> is has the value of <em>-1</em>, we use the <em>limit</em> to stop the search by a factor.<br>  <em>0</em> and <em>1</em> mean no limit.<br>  <em>2</em> means half of the remaining arguments, 3 means a third, and so on.</li>\n</ol>\n<h3>keynum</h3>\n<p>The <em>keynum</em> type of <code>find_keys</code> is a map under the <em>spec</em> key with three keys:</p>\n<ul>\n<li><strong>keynumidx:</strong> the index, relative to <code>begin_search</code>, of the argument containing the number of keys.</li>\n<li><strong>firstkey:</strong> the index, relative to <code>begin_search</code>, of the first key.<br>This is usually the next argument after <em>keynumidx</em>, and its value, in this case, is greater by one.</li>\n<li><strong>keystep:</strong> Tthe number of arguments that should be skipped, after finding a key, to find the next one.</li>\n</ul>\n<p>Examples:</p>\n<ul>\n<li>The <code>SET</code> command has a <em>range</em> of <em>0</em>, <em>1</em> and <em>0</em>.</li>\n<li>The <code>MSET</code> command has a <em>range</em> of <em>-1</em>, <em>2</em> and <em>0</em>.</li>\n<li>The <code>XREAD</code> command has a <em>range</em> of <em>-1</em>, <em>1</em> and <em>2</em>.</li>\n<li>The <code>ZUNION</code> command has a <em>start_search</em> type <em>index</em> with the value <em>1</em>, and <code>find_keys</code> of type <em>keynum</em> with values of <em>0</em>, <em>1</em> and <em>1</em>.</li>\n</ul>\n<p><strong>Note:</strong><br>this isn&#39;t a perfect solution as the module writers can come up with anything.<br>However, this mechanism should allow the extraction of key name arguments for the vast majority of commands.</p>\n<h2>notes</h2>\n<p>Notes about non-obvious key specs considerations, if applicable.</p>\n<h2>flags</h2>\n<p>A key specification can have additional flags that provide more details about the key.<br>These flags are divided into three groups, as described below.</p>\n<h3>Access type flags</h3>\n<p>The following flags declare the type of access the command uses to a key&#39;s value or its metadata.<br>A key&#39;s metadata includes LRU/LFU counters, type, and cardinality.<br>These flags do not relate to the reply sent back to the client.</p>\n<p>Every key specification has precisely one of the following flags:</p>\n<ul>\n<li><strong>RW:</strong> the read-write flag.<br>The command modifies the data stored in the value of the key or its metadata.<br>This flag marks every operation that isn&#39;t distinctly a delete, an overwrite, or read-only.</li>\n<li><strong>RO:</strong> the read-only flag.<br>The command only reads the value of the key (although it doesn&#39;t necessarily return it).</li>\n<li><strong>OW:</strong> the overwrite flag.<br>The command overwrites the data stored in the value of the key.</li>\n<li><strong>RM:</strong> the remove flag.<br>The command deletes the key.</li>\n</ul>\n<h3>Logical operation flags</h3>\n<p>The following flags declare the type of operations performed on the data stored as the key&#39;s value and its TTL (if any), not the metadata.<br>These flags describe the logical operation that the command executes on data, driven by the input arguments.<br>The flags do not relate to modifying or returning metadata (such as a key&#39;s type, cardinality, or existence).</p>\n<p>Every key specification may include the following flag:</p>\n<ul>\n<li><strong>access:</strong> the access flag.<br>This flag indicates that the command returns, copies, or somehow uses the user&#39;s data that&#39;s stored in the key.</li>\n</ul>\n<p>In addition, the specification may include precisely one of the following:</p>\n<ul>\n<li><strong>update:</strong> the update flag.<br>The command updates the data stored in the key&#39;s value.<br>The new value may depend on the old value.<br>This flag marks every operation that isn&#39;t distinctly an insert or a delete.</li>\n<li><strong>insert:</strong> the insert flag.<br>The command only adds data to the value; existing data isn&#39;t modified or deleted.</li>\n<li><strong>delete:</strong> the delete flag.<br>The command explicitly deletes data from the value stored at the key.</li>\n</ul>\n<h3>Miscellaneous flags</h3>\n<p>Key specifications may have the following flags:</p>\n<ul>\n<li><strong>not_key:</strong> this flag indicates that the specified argument isn&#39;t a key.<br>This argument is treated the same as a key when computing which slot a command should be assigned to for Valkey cluster.<br>For all other purposes this argument should not be considered a key.</li>\n<li><strong>incomplete:</strong> this flag is explained below.</li>\n<li><strong>variable_flags:</strong> this flag is explained below.</li>\n</ul>\n<h3>incomplete</h3>\n<p>Some commands feature exotic approaches when it comes to specifying their keys, which makes extraction difficult.<br>Consider, for example, what would happen with a call to <code>MIGRATE</code> that includes the literal string <em>&quot;KEYS&quot;</em> as an argument to its <em>AUTH</em> clause.<br>Our key specifications would miss the mark, and extraction would begin at the wrong index.</p>\n<p>Thus, we recognize that key specifications are incomplete and may fail to extract all keys.<br>However, we assure that even incomplete specifications never yield the wrong names of keys, providing that the command is syntactically correct.</p>\n<p>In the case of <code>MIGRATE</code>, the search begins at the end (<em>startfrom</em> has the value of <em>-1</em>).<br>If and when we encounter a key named <em>&quot;KEYS&quot;</em>, we&#39;ll only extract the subset of the key name arguments after it.<br>That&#39;s why <code>MIGRATE</code> has the <em>incomplete</em> flag in its key specification.</p>\n<p>Another case of incompleteness is the <code>SORT</code> command.<br>Here, the <code>begin_search</code> and <code>find_keys</code> are of type <em>unknown</em>.<br>The client should revert to calling the <code>COMMAND GETKEYS</code> command to extract key names from the arguments, short of implementing it natively.<br>The difficulty arises, for example, because the string <em>&quot;STORE&quot;</em> is both a keyword (token) and a valid literal argument for <code>SORT</code>.</p>\n<p><strong>Note:</strong><br>the only commands with <em>incomplete</em> key specifications are <code>SORT</code> and <code>MIGRATE</code>.<br>We don&#39;t expect the addition of such commands in the future.</p>\n<h3>variable_flags</h3>\n<p>In some commands, the flags for the same key name argument can depend on other arguments.<br>For example, consider the <code>SET</code> command and its optional  <em>GET</em> argument.<br>Without the <em>GET</em> argument, <code>SET</code> is write-only, but it becomes a read and write command with it.<br>When this flag is present, it means that the key specification flags cover all possible options, but the effective flags depend on other arguments.</p>\n<h2>Examples</h2>\n<h3><code>SET</code>&#39;s key specifications</h3>\n<pre><code>  1) 1) &quot;flags&quot;\n     2) 1) RW\n        2) access\n        3) update\n     3) &quot;begin_search&quot;\n     4) 1) &quot;type&quot;\n        2) &quot;index&quot;\n        3) &quot;spec&quot;\n        4) 1) &quot;index&quot;\n           2) (integer) 1\n     5) &quot;find_keys&quot;\n     6) 1) &quot;type&quot;\n        2) &quot;range&quot;\n        3) &quot;spec&quot;\n        4) 1) &quot;lastkey&quot;\n           2) (integer) 0\n           3) &quot;keystep&quot;\n           4) (integer) 1\n           5) &quot;limit&quot;\n           6) (integer) 0\n</code></pre>\n<h3><code>ZUNION</code>&#39;s key specifications</h3>\n<pre><code>  1) 1) &quot;flags&quot;\n     2) 1) RO\n        2) access\n     3) &quot;begin_search&quot;\n     4) 1) &quot;type&quot;\n        2) &quot;index&quot;\n        3) &quot;spec&quot;\n        4) 1) &quot;index&quot;\n           2) (integer) 1\n     5) &quot;find_keys&quot;\n     6) 1) &quot;type&quot;\n        2) &quot;keynum&quot;\n        3) &quot;spec&quot;\n        4) 1) &quot;keynumidx&quot;\n           2) (integer) 0\n           3) &quot;firstkey&quot;\n           4) (integer) 1\n           5) &quot;keystep&quot;\n           6) (integer) 1\n</code></pre>\n"
  },
  {
    "id": "keyspace",
    "topicName": "Keyspace",
    "description": "Managing keys in Valkey: Key expiration, scanning, altering and querying the key space\n",
    "htmlContent": "<p>Valkey keys are binary safe; this means that you can use any binary sequence as a<br>key, from a string like &quot;foo&quot; to the content of a JPEG file.<br>The empty string is also a valid key.</p>\n<p>A few other rules about keys: </p>\n<ul>\n<li>Very long keys are not a good idea. For instance a key of 1024 bytes is a bad<br>idea not only memory-wise, but also because the lookup of the key in the<br>dataset may require several costly key-comparisons. Even when the task at hand<br>is to match the existence of a large value, hashing it (for example<br>with SHA1) is a better idea, especially from the perspective of memory<br>and bandwidth.</li>\n<li>Very short keys are often not a good idea. There is little point in writing<br>&quot;u1000flw&quot; as a key if you can instead write &quot;user:1000:followers&quot;.  The latter<br>is more readable and the added space is minor compared to the space used by<br>the key object itself and the value object. While short keys will obviously<br>consume a bit less memory, your job is to find the right balance.</li>\n<li>Try to stick with a schema. For instance &quot;object-type:id&quot; is a good<br>idea, as in &quot;user:1000&quot;. Dots or dashes are often used for multi-word<br>fields, as in &quot;comment:4321:reply.to&quot; or &quot;comment:4321:reply-to&quot;.</li>\n<li>The maximum allowed key size is 512 MB.</li>\n</ul>\n<h2>Altering and querying the key space</h2>\n<p>There are commands that are not defined on particular types, but are useful<br>in order to interact with the space of keys, and thus, can be used with<br>keys of any type.</p>\n<p>For example the <code>EXISTS</code> command returns 1 or 0 to signal if a given key<br>exists or not in the database, while the <code>DEL</code> command deletes a key<br>and associated value, whatever the value is.</p>\n<pre><code>&gt; set mykey hello\nOK\n&gt; exists mykey\n(integer) 1\n&gt; del mykey\n(integer) 1\n&gt; exists mykey\n(integer) 0\n</code></pre>\n<p>From the examples you can also see how <code>DEL</code> itself returns 1 or 0 depending on whether<br>the key was removed (it existed) or not (there was no such key with that<br>name).</p>\n<p>There are many key space related commands, but the above two are the<br>essential ones together with the <code>TYPE</code> command, which returns the kind<br>of value stored at the specified key:</p>\n<pre><code>&gt; set mykey x\nOK\n&gt; type mykey\nstring\n&gt; del mykey\n(integer) 1\n&gt; type mykey\nnone\n</code></pre>\n<h2>Key expiration</h2>\n<p>Before moving on, we should look at an important Valkey feature that works regardless of the type of value you&#39;re storing: key expiration. Key expiration lets you set a timeout for a key, also known as a &quot;time to live&quot;, or &quot;TTL&quot;. When the time to live elapses, the key is automatically destroyed. </p>\n<p>A few important notes about key expiration:</p>\n<ul>\n<li>They can be set both using seconds or milliseconds precision.</li>\n<li>However the expire time resolution is always 1 millisecond.</li>\n<li>Information about expires are replicated and persisted on disk, the time virtually passes when your Valkey server remains stopped (this means that Valkey saves the date at which a key will expire).</li>\n</ul>\n<p>Use the <code>EXPIRE</code> command to set a key&#39;s expiration:</p>\n<pre><code>&gt; set key some-value\nOK\n&gt; expire key 5\n(integer) 1\n&gt; get key (immediately)\n&quot;some-value&quot;\n&gt; get key (after some time)\n(nil)\n</code></pre>\n<p>The key vanished between the two <code>GET</code> calls, since the second call was<br>delayed more than 5 seconds. In the example above we used <code>EXPIRE</code> in<br>order to set the expire (it can also be used in order to set a different<br>expire to a key already having one, like <code>PERSIST</code> can be used in order<br>to remove the expire and make the key persistent forever). However we<br>can also create keys with expires using other Valkey commands. For example<br>using <code>SET</code> options:</p>\n<pre><code>&gt; set key 100 ex 10\nOK\n&gt; ttl key\n(integer) 9\n</code></pre>\n<p>The example above sets a key with the string value <code>100</code>, having an expire<br>of ten seconds. Later the <code>TTL</code> command is called in order to check the<br>remaining time to live for the key.</p>\n<p>In order to set and check expires in milliseconds, check the <code>PEXPIRE</code> and<br>the <code>PTTL</code> commands, and the full list of <code>SET</code> options.</p>\n<h2>Navigating the keyspace</h2>\n<h3>Scan</h3>\n<p>To incrementally  iterate over the keys in a Valkey database in an efficient manner, you can use the <code>SCAN</code> command.</p>\n<p>Since <code>SCAN</code> allows for incremental iteration, returning only a small number of elements per call, it can be used in production without the downside of commands like <code>KEYS</code> or <code>SMEMBERS</code> that may block the server for a long time (even several seconds) when called against big collections of keys or elements.</p>\n<p>However while blocking commands like <code>SMEMBERS</code> are able to provide all the elements that are part of a Set in a given moment.<br>The <code>SCAN</code> family of commands only offer limited guarantees about the returned elements since the collection that we incrementally iterate can change during the iteration process.</p>\n<h3>Keys</h3>\n<p>Another way to iterate over the keyspace is to use the <code>KEYS</code> command, but this approach should be used with care, since <code>KEYS</code> will block the Valkey server until all keys are returned.</p>\n<p><strong>Warning</strong>: consider <code>KEYS</code> as a command that should only be used in production<br>environments with extreme care.</p>\n<p><code>KEYS</code> may ruin performance when it is executed against large databases.<br>This command is intended for debugging and special operations, such as changing<br>your keyspace layout.<br>Don&#39;t use <code>KEYS</code> in your regular application code.<br>If you&#39;re looking for a way to find keys in a subset of your keyspace, consider<br>using <code>SCAN</code> or <a href=\"data-types#sets\">sets</a>.</p>\n<p>Supported glob-style patterns:</p>\n<ul>\n<li><code>h?llo</code> matches <code>hello</code>, <code>hallo</code> and <code>hxllo</code></li>\n<li><code>h*llo</code> matches <code>hllo</code> and <code>heeeello</code></li>\n<li><code>h[ae]llo</code> matches <code>hello</code> and <code>hallo,</code> but not <code>hillo</code></li>\n<li><code>h[^e]llo</code> matches <code>hallo</code>, <code>hbllo</code>, ... but not <code>hello</code></li>\n<li><code>h[a-b]llo</code> matches <code>hallo</code> and <code>hbllo</code></li>\n</ul>\n<p>Use <code>\\</code> to escape special characters if you want to match them verbatim.</p>\n"
  },
  {
    "id": "latency-monitor",
    "topicName": "Latency monitoring",
    "description": "Discovering slow server events in Valkey",
    "htmlContent": "<p>Valkey is often used for demanding use cases, where it<br>serves a large number of queries per second per instance, but also has strict latency requirements for the average response<br>time and the worst-case latency.</p>\n<p>While Valkey is an in-memory system, it deals with the operating system in<br>different ways, for example, in the context of persisting to disk.<br>Moreover Valkey implements a rich set of commands. Certain commands<br>are fast and run in constant or logarithmic time. Other commands are slower<br>O(N) commands that can cause latency spikes.</p>\n<p>Finally, Valkey is single threaded. This is usually an advantage<br>from the point of view of the amount of work it can perform per core, and in<br>the latency figures it is able to provide. However, it poses<br>a challenge for latency, since the single<br>thread must be able to perform certain tasks incrementally, for<br>example key expiration, in a way that does not impact the other clients<br>that are served.</p>\n<p>For all these reasons, there is a feature called<br><strong>Latency Monitoring</strong>, that helps the user to check and troubleshoot possible<br>latency problems. Latency monitoring is composed of the following conceptual<br>parts:</p>\n<ul>\n<li>Latency hooks that sample different latency-sensitive code paths.</li>\n<li>Time series recording of latency spikes, split by different events.</li>\n<li>Reporting engine to fetch raw data from the time series.</li>\n<li>Analysis engine to provide human-readable reports and hints according to the measurements.</li>\n</ul>\n<p>The rest of this document covers the latency monitoring subsystem<br>details. For more information about the general topic of Valkey<br>and latency, see <a href=\"latency\">Valkey latency problems troubleshooting</a>.</p>\n<h2>Events and time series</h2>\n<p>Different monitored code paths have different names and are called <em>events</em>.<br>For example, <code>command</code> is an event that measures latency spikes of possibly slow<br>command executions, while <code>fast-command</code> is the event name for the monitoring<br>of the O(1) and O(log N) commands. Other events are less generic and monitor<br>specific operations performed by Valkey. For example, the <code>fork</code> event<br>only monitors the time taken by Valkey to execute the <code>fork(2)</code> system call.</p>\n<p>A latency spike is an event that takes more time to run than the configured latency<br>threshold. There is a separate time series associated with every monitored<br>event. This is how the time series work:</p>\n<ul>\n<li>Every time a latency spike happens, it is logged in the appropriate time series.</li>\n<li>Every time series is composed of 160 elements.</li>\n<li>Each element is a pair made of a Unix timestamp of the time the latency spike was measured and the number of milliseconds the event took to execute.</li>\n<li>Latency spikes for the same event that occur in the same second are merged by taking the maximum latency. Even if continuous latency spikes are measured for a given event, which could happen with a low threshold, at least 160 seconds of history are available.</li>\n<li>Records the all-time maximum latency for every element.</li>\n</ul>\n<p>The framework monitors and logs latency spikes in the execution time of these events:</p>\n<ul>\n<li><code>command</code>: regular commands.</li>\n<li><code>fast-command</code>: O(1) and O(log N) commands.</li>\n<li><code>fork</code>: the <code>fork(2)</code> system call.</li>\n<li><code>rdb-unlink-temp-file</code>: the <code>unlink(2)</code> system call.</li>\n<li><code>aof-fsync-always</code>: the <code>fsync(2)</code> system call when invoked by the <code>appendfsync allways</code> policy.</li>\n<li><code>aof-write</code>: writing to the AOF - a catchall event for <code>write(2)</code> system calls.</li>\n<li><code>aof-write-pending-fsync</code>: the <code>write(2)</code> system call when there is a pending fsync.</li>\n<li><code>aof-write-active-child</code>: the <code>write(2)</code> system call when there are active child processes.</li>\n<li><code>aof-write-alone</code>: the <code>write(2)</code> system call when no pending fsync and no active child process.</li>\n<li><code>aof-fstat</code>: the <code>fstat(2)</code> system call.</li>\n<li><code>aof-rename</code>: the <code>rename(2)</code> system call for renaming the temporary file after completing <code>BGREWRITEAOF</code>.</li>\n<li><code>aof-rewrite-diff-write</code>: writing the differences accumulated while performing <code>BGREWRITEAOF</code>.</li>\n<li><code>active-defrag-cycle</code>: the active defragmentation cycle.</li>\n<li><code>expire-cycle</code>: the expiration cycle.</li>\n<li><code>eviction-cycle</code>: the eviction cycle.</li>\n<li><code>eviction-del</code>: deletes during the eviction cycle.</li>\n</ul>\n<h2>How to enable latency monitoring</h2>\n<p>What is high latency for one use case may not be considered high latency for another. Some applications may require that all queries be served in less than 1 millisecond. For other applications, it may be acceptable for a small amount of clients to experience a 2 second latency on occasion.</p>\n<p>The first step to enable the latency monitor is to set a <strong>latency threshold</strong> in milliseconds. Only events that take longer than the specified threshold will be logged as latency spikes. The user should set the threshold according to their needs. For example, if the application requires a maximum acceptable latency of 100 milliseconds, the threshold should be set to log all the events blocking the server for a time equal or greater to 100 milliseconds.</p>\n<p>Enable the latency monitor at runtime in a production server<br>with the following command:</p>\n<pre><code>CONFIG SET latency-monitor-threshold 100\n</code></pre>\n<p>Monitoring is turned off by default (threshold set to 0), even if the actual cost of latency monitoring is near zero. While the memory requirements of latency monitoring are very small, there is no good reason to raise the baseline memory usage of a Valkey instance that is working well.</p>\n<h2>Report information with the LATENCY command</h2>\n<p>The user interface to the latency monitoring subsystem is the <code>LATENCY</code> command.<br>Like many other Valkey commands, <code>LATENCY</code> accepts subcommands that modify its behavior. These subcommands are:</p>\n<ul>\n<li><code>LATENCY LATEST</code> - returns the latest latency samples for all events.</li>\n<li><code>LATENCY HISTORY</code> - returns latency time series for a given event.</li>\n<li><code>LATENCY RESET</code> - resets latency time series data for one or more events.</li>\n<li><code>LATENCY GRAPH</code> - renders an ASCII-art graph of an event&#39;s latency samples.</li>\n<li><code>LATENCY DOCTOR</code> - replies with a human-readable latency analysis report.</li>\n</ul>\n<p>Refer to each subcommand&#39;s documentation page for further information.</p>\n"
  },
  {
    "id": "latency",
    "topicName": "Diagnosing latency issues",
    "description": "Finding the causes of slow responses",
    "htmlContent": "<p>This document will help you understand what the problem could be if you<br>are experiencing latency problems with Valkey.</p>\n<p>In this context <em>latency</em> is the maximum delay between the time a client<br>issues a command and the time the reply to the command is received by the<br>client. Usually Valkey processing time is extremely low, in the sub microsecond<br>range, but there are certain conditions leading to higher latency figures.</p>\n<h2>I&#39;ve little time, give me the checklist</h2>\n<p>The following documentation is very important in order to run Valkey in<br>a low latency fashion. However I understand that we are busy people, so<br>let&#39;s start with a quick checklist. If you fail following these steps, please<br>return here to read the full documentation.</p>\n<ol>\n<li>Make sure you are not running slow commands that are blocking the server. Use the Valkey <a href=\"../commands/slowlog\">Slow Log feature</a> to check this.</li>\n<li>For EC2 users, make sure you use HVM based modern EC2 instances, like m3.medium. Otherwise fork() is too slow.</li>\n<li>Transparent huge pages must be disabled from your kernel. Use <code>echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</code> to disable them, and restart your Valkey process.</li>\n<li>If you are using a virtual machine, it is possible that you have an intrinsic latency that has nothing to do with Valkey. Check the minimum latency you can expect from your runtime environment using <code>./valkey-cli --intrinsic-latency 100</code>. Note: you need to run this command in <em>the server</em> not in the client.</li>\n<li>Enable and use the <a href=\"latency-monitor\">Latency monitor</a> feature of Valkey in order to get a human readable description of the latency events and causes in your Valkey instance.</li>\n</ol>\n<p>In general, use the following table for durability VS latency/performance tradeoffs, ordered from stronger safety to better latency.</p>\n<ol>\n<li>AOF + fsync always: this is very slow, you should use it only if you know what you are doing.</li>\n<li>AOF + fsync every second: this is a good compromise.</li>\n<li>AOF + fsync every second + no-appendfsync-on-rewrite option set to yes: this is as the above, but avoids to fsync during rewrites to lower the disk pressure.</li>\n<li>AOF + fsync never. Fsyncing is up to the kernel in this setup, even less disk pressure and risk of latency spikes.</li>\n<li>RDB. Here you have a vast spectrum of tradeoffs depending on the save triggers you configure.</li>\n</ol>\n<p>And now for people with 15 minutes to spend, the details...</p>\n<h2>Measuring latency</h2>\n<p>If you are experiencing latency problems, you probably know how to measure<br>it in the context of your application, or maybe your latency problem is very<br>evident even macroscopically. However valkey-cli can be used to measure the<br>latency of a Valkey server in milliseconds, just try:</p>\n<pre><code>valkey-cli --latency -h `host` -p `port`\n</code></pre>\n<h2>Using the internal Valkey latency monitoring subsystem</h2>\n<p>Valkey provides latency monitoring capabilities that<br>are able to sample different execution paths to understand where the<br>server is blocking. This makes debugging of the problems illustrated in<br>this documentation much simpler, so we suggest enabling latency monitoring<br>ASAP. Please refer to the <a href=\"latency-monitor\">Latency monitor documentation</a>.</p>\n<p>While the latency monitoring sampling and reporting capabilities will make<br>it simpler to understand the source of latency in your Valkey system, it is still<br>advised that you read this documentation extensively to better understand<br>the topic of Valkey and latency spikes.</p>\n<h2>Latency baseline</h2>\n<p>There is a kind of latency that is inherently part of the environment where<br>you run Valkey, that is the latency provided by your operating system kernel<br>and, if you are using virtualization, by the hypervisor you are using.</p>\n<p>While this latency can&#39;t be removed it is important to study it because<br>it is the baseline, or in other words, you won&#39;t be able to achieve a Valkey<br>latency that is better than the latency that every process running in your<br>environment will experience because of the kernel or hypervisor implementation<br>or setup.</p>\n<p>We call this kind of latency <strong>intrinsic latency</strong>, and <code>valkey-cli</code><br>is able to measure it. This is an example run.</p>\n<p>Note: the argument <code>100</code> is the number of seconds the test will be executed.<br>The more time we run the test, the more likely we&#39;ll be able to spot<br>latency spikes. 100 seconds is usually appropriate, however you may want<br>to perform a few runs at different times. Please note that the test is CPU<br>intensive and will likely saturate a single core in your system.</p>\n<pre><code>$ ./valkey-cli --intrinsic-latency 100\nMax latency so far: 1 microseconds.\nMax latency so far: 16 microseconds.\nMax latency so far: 50 microseconds.\nMax latency so far: 53 microseconds.\nMax latency so far: 83 microseconds.\nMax latency so far: 115 microseconds.\n</code></pre>\n<p>Note: valkey-cli in this special case needs to <strong>run in the server</strong> where you run or plan to run Valkey, not in the client. In this special mode valkey-cli does not connect to a Valkey server at all: it will just try to measure the largest time the kernel does not provide CPU time to run to the valkey-cli process itself.</p>\n<p>In the above example, the intrinsic latency of the system is just 0.115<br>milliseconds (or 115 microseconds), which is a good news, however keep in mind<br>that the intrinsic latency may change over time depending on the load of the<br>system.</p>\n<p>In a virtualized environments with high load or if there are noisy neighbors,<br>you may get numbers like these:</p>\n<pre><code>$ ./valkey-cli --intrinsic-latency 100\nMax latency so far: 573 microseconds.\nMax latency so far: 695 microseconds.\nMax latency so far: 919 microseconds.\nMax latency so far: 1606 microseconds.\nMax latency so far: 3191 microseconds.\nMax latency so far: 9243 microseconds.\nMax latency so far: 9671 microseconds.\n</code></pre>\n<p>Here we have an intrinsic latency of 9.7 milliseconds: this means that we can&#39;t ask better than that to Valkey. However other runs at different times in different virtualization environments with higher load or with noisy neighbors can easily show even worse values. We were able to measure up to 40 milliseconds in<br>systems otherwise apparently running normally.</p>\n<h2>Latency induced by network and communication</h2>\n<p>Clients connect to Valkey using a TCP/IP connection or a Unix domain connection.<br>The typical latency of a 1 Gbit/s network is about 200 us, while the latency<br>with a Unix domain socket can be as low as 30 us. It actually depends on your<br>network and system hardware. On top of the communication itself, the system<br>adds some more latency (due to thread scheduling, CPU caches, NUMA placement,<br>etc ...). System induced latencies are significantly higher on a virtualized<br>environment than on a physical machine.</p>\n<p>The consequence is even if Valkey processes most commands in sub microsecond<br>range, a client performing many roundtrips to the server will have to pay<br>for these network and system related latencies.</p>\n<p>An efficient client will therefore try to limit the number of roundtrips by<br>pipelining several commands together. This is fully supported by the servers<br>and most clients. Aggregated commands like MSET/MGET can be also used for<br>that purpose. A number of commands also support<br>variadic parameters for all data types.</p>\n<p>Here are some guidelines:</p>\n<ul>\n<li>If you can afford it, prefer a physical machine over a VM to host the server.</li>\n<li>Do not systematically connect/disconnect to the server (especially true<br>for web based applications). Keep your connections as long lived as possible.</li>\n<li>If your client is on the same host than the server, use Unix domain sockets.</li>\n<li>Prefer to use aggregated commands (MSET/MGET), or commands with variadic<br>parameters (if possible) over pipelining.</li>\n<li>Prefer to use pipelining (if possible) over sequence of roundtrips.</li>\n<li>Valkey supports Lua server-side scripting to cover cases that are not suitable<br>for raw pipelining (for instance when the result of a command is an input for<br>the following commands).</li>\n</ul>\n<p>On Linux, some people can achieve better latencies by playing with process<br>placement (taskset), cgroups, real-time priorities (chrt), NUMA<br>configuration (numactl), or by using a low-latency kernel. Please note<br>vanilla Valkey is not really suitable to be bound on a <strong>single</strong> CPU core.<br>Valkey can fork background tasks that can be extremely CPU consuming<br>like <code>BGSAVE</code> or <code>BGREWRITEAOF</code>. These tasks must <strong>never</strong> run on the same core<br>as the main event loop.</p>\n<p>In most situations, these kind of system level optimizations are not needed.<br>Only do them if you require them, and if you are familiar with them.</p>\n<h2>Valkey sequential command execution</h2>\n<p>Valkey uses a <em>mostly</em> single threaded design for command execution. This means that a single process<br>executes all the client commands sequentially, using a technique called <strong>multiplexing</strong>.<br>While multiple commands can have their I/O operations processed concurrently in the background,<br>only one command can be executed at any given moment. This is similar to how Node.js<br>works as well. However, both products are not often perceived as being slow.<br>This is caused in part by the small amount of time to complete a single command execution,<br>but primarily because these products are designed to not block on system calls,<br>such as reading data from or writing data to a socket.</p>\n<h2>Latency generated by slow commands</h2>\n<p>A consequence of being single thread is that when a request is slow to serve<br>all the other clients will wait for this request to be served. When executing<br>normal commands, like <code>GET</code> or <code>SET</code> or <code>LPUSH</code> this is not a problem<br>at all since these commands are executed in constant (and very small) time.<br>However there are commands operating on many elements, like <code>SORT</code>, <code>LREM</code>,<br><code>SUNION</code> and others. For instance taking the intersection of two big sets<br>can take a considerable amount of time.</p>\n<p>The algorithmic complexity of all commands is documented. A good practice<br>is to systematically check it when using commands you are not familiar with.</p>\n<p>If you have latency concerns you should either not use slow commands against<br>values composed of many elements, or you should run a replica using Valkey<br>replication where you run all your slow queries.</p>\n<p>It is possible to monitor slow commands using the Valkey<br><a href=\"../commands/slowlog\">Slow Log feature</a>.</p>\n<p>Additionally, you can use your favorite per-process monitoring program<br>(top, htop, prstat, etc ...) to quickly check the CPU consumption of the<br>main Valkey process. If it is high while the traffic is not, it is usually<br>a sign that slow commands are used.</p>\n<p><strong>IMPORTANT NOTE</strong>: a VERY common source of latency generated by the execution<br>of slow commands is the use of the <code>KEYS</code> command in production environments.<br><code>KEYS</code>, as documented in the Valkey documentation, should only be used for<br>debugging purposes. To<br>iterate the key space and other large collections incrementally, please check<br>the <code>SCAN</code>, <code>SSCAN</code>, <code>HSCAN</code> and <code>ZSCAN</code> commands for more information.</p>\n<h2>Latency generated by fork</h2>\n<p>In order to generate the RDB file in background, or to rewrite the Append Only File if AOF persistence is enabled, Valkey has to fork background processes.<br>The fork operation (running in the main thread) can induce latency by itself.</p>\n<p>Forking is an expensive operation on most Unix-like systems, since it involves<br>copying a good number of objects linked to the process. This is especially<br>true for the page table associated to the virtual memory mechanism.</p>\n<p>For instance on a Linux/AMD64 system, the memory is divided in 4 kB pages.<br>To convert virtual addresses to physical addresses, each process stores<br>a page table (actually represented as a tree) containing at least a pointer<br>per page of the address space of the process. So a large 24 GB Valkey instance<br>requires a page table of 24 GB / 4 kB * 8 = 48 MB.</p>\n<p>When a background save is performed, this instance will have to be forked,<br>which will involve allocating and copying 48 MB of memory. It takes time<br>and CPU, especially on virtual machines where allocation and initialization<br>of a large memory chunk can be expensive.</p>\n<h2>Fork time in different systems</h2>\n<p>Modern hardware is pretty fast at copying the page table.<br>So are modern hardware-assisted virtualized environments,<br>but fork can be really slow in older virtualized environments without hardware support.<br>As of 2024, this is hardly a problem.</p>\n<p>You can measure the fork time for a Valkey instance by<br>performing a BGSAVE and looking at the <code>latest_fork_usec</code> field in the <code>INFO</code> command output.</p>\n<h2>Latency induced by transparent huge pages</h2>\n<p>Unfortunately when a Linux kernel has transparent huge pages enabled, Valkey<br>incurs to a big latency penalty after the <code>fork</code> call is used in order to<br>persist on disk. Huge pages are the cause of the following issue:</p>\n<ol>\n<li>Fork is called, two processes with shared huge pages are created.</li>\n<li>In a busy instance, a few event loops runs will cause commands to target a few thousand of pages, causing the copy on write of almost the whole process memory.</li>\n<li>This will result in big latency and big memory usage.</li>\n</ol>\n<p>Make sure to <strong>disable transparent huge pages</strong> using the following command:</p>\n<pre><code>echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled\n</code></pre>\n<h2>Latency induced by swapping (operating system paging)</h2>\n<p>Linux (and many other modern operating systems) is able to relocate memory<br>pages from the memory to the disk, and vice versa, in order to use the<br>system memory efficiently.</p>\n<p>If a Valkey page is moved by the kernel from the memory to the swap file, when<br>the data stored in this memory page is used by Valkey (for example accessing<br>a key stored into this memory page) the kernel will stop the Valkey process<br>in order to move the page back into the main memory. This is a slow operation<br>involving random I/Os (compared to accessing a page that is already in memory)<br>and will result into anomalous latency experienced by Valkey clients.</p>\n<p>The kernel relocates Valkey memory pages on disk mainly because of three reasons:</p>\n<ul>\n<li>The system is under memory pressure since the running processes are demanding<br>more physical memory than the amount that is available. The simplest instance of<br>this problem is simply Valkey using more memory than is available.</li>\n<li>The Valkey instance data set, or part of the data set, is mostly completely idle<br>(never accessed by clients), so the kernel could swap idle memory pages on disk.<br>This problem is very rare since even a moderately slow instance will touch all<br>the memory pages often, forcing the kernel to retain all the pages in memory.</li>\n<li>Some processes are generating massive read or write I/Os on the system. Because<br>files are generally cached, it tends to put pressure on the kernel to increase<br>the filesystem cache, and therefore generate swapping activity. Please note it<br>includes Valkey RDB and/or AOF background threads which can produce large files.</li>\n</ul>\n<p>Fortunately Linux offers good tools to investigate the problem, so the simplest<br>thing to do is when latency due to swapping is suspected is just to check if<br>this is the case.</p>\n<p>The first thing to do is to checking the amount of Valkey memory that is swapped<br>on disk. In order to do so you need to obtain the Valkey instance pid:</p>\n<pre><code>$ valkey-cli info | grep process_id\nprocess_id:5454\n</code></pre>\n<p>Now enter the /proc file system directory for this process:</p>\n<pre><code>$ cd /proc/5454\n</code></pre>\n<p>Here you&#39;ll find a file called <strong>smaps</strong> that describes the memory layout of<br>the Valkey process (assuming you are using Linux 2.6.16 or newer).<br>This file contains very detailed information about our process memory maps,<br>and one field called <strong>Swap</strong> is exactly what we are looking for. However<br>there is not just a single swap field since the smaps file contains the<br>different memory maps of our Valkey process (The memory layout of a process<br>is more complex than a simple linear array of pages).</p>\n<p>Since we are interested in all the memory swapped by our process the first thing<br>to do is to grep for the Swap field across all the file:</p>\n<pre><code>$ cat smaps | grep &#39;Swap:&#39;\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                 12 kB\nSwap:                156 kB\nSwap:                  8 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  4 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  4 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  4 kB\nSwap:                  4 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\n</code></pre>\n<p>If everything is 0 kB, or if there are sporadic 4k entries, everything is<br>perfectly normal. Actually in our example instance (the one of a real web<br>site running Valkey and serving hundreds of users every second) there are a<br>few entries that show more swapped pages. To investigate if this is a serious<br>problem or not we change our command in order to also print the size of the<br>memory map:</p>\n<pre><code>$ cat smaps | egrep &#39;^(Swap|Size)&#39;\nSize:                316 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  0 kB\nSize:                  8 kB\nSwap:                  0 kB\nSize:                 40 kB\nSwap:                  0 kB\nSize:                132 kB\nSwap:                  0 kB\nSize:             720896 kB\nSwap:                 12 kB\nSize:               4096 kB\nSwap:                156 kB\nSize:               4096 kB\nSwap:                  8 kB\nSize:               4096 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  0 kB\nSize:               1272 kB\nSwap:                  0 kB\nSize:                  8 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  0 kB\nSize:                 16 kB\nSwap:                  0 kB\nSize:                 84 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  0 kB\nSize:                  8 kB\nSwap:                  4 kB\nSize:                  8 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  4 kB\nSize:                144 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  4 kB\nSize:                 12 kB\nSwap:                  4 kB\nSize:                108 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  0 kB\nSize:                272 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  0 kB\n</code></pre>\n<p>As you can see from the output, there is a map of 720896 kB<br>(with just 12 kB swapped) and 156 kB more swapped in another map:<br>basically a very small amount of our memory is swapped so this is not<br>going to create any problem at all.</p>\n<p>If instead a non trivial amount of the process memory is swapped on disk your<br>latency problems are likely related to swapping. If this is the case with your<br>Valkey instance you can further verify it using the <strong>vmstat</strong> command:</p>\n<pre><code>$ vmstat 1\nprocs -----------memory---------- ---swap-- -----io---- -system-- ----cpu----\n r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa\n 0  0   3980 697932 147180 1406456    0    0     2     2    2    0  4  4 91  0\n 0  0   3980 697428 147180 1406580    0    0     0     0 19088 16104  9  6 84  0\n 0  0   3980 697296 147180 1406616    0    0     0    28 18936 16193  7  6 87  0\n 0  0   3980 697048 147180 1406640    0    0     0     0 18613 15987  6  6 88  0\n 2  0   3980 696924 147180 1406656    0    0     0     0 18744 16299  6  5 88  0\n 0  0   3980 697048 147180 1406688    0    0     0     4 18520 15974  6  6 88  0\n^C\n</code></pre>\n<p>The interesting part of the output for our needs are the two columns <strong>si</strong><br>and <strong>so</strong>, that counts the amount of memory swapped from/to the swap file. If<br>you see non zero counts in those two columns then there is swapping activity<br>in your system.</p>\n<p>Finally, the <strong>iostat</strong> command can be used to check the global I/O activity of<br>the system.</p>\n<pre><code>$ iostat -xk 1\navg-cpu:  %user   %nice %system %iowait  %steal   %idle\n          13.55    0.04    2.92    0.53    0.00   82.95\n\nDevice:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await  svctm  %util\nsda               0.77     0.00    0.01    0.00     0.40     0.00    73.65     0.00    3.62   2.58   0.00\nsdb               1.27     4.75    0.82    3.54    38.00    32.32    32.19     0.11   24.80   4.24   1.85\n</code></pre>\n<p>If your latency problem is due to Valkey memory being swapped on disk you need<br>to lower the memory pressure in your system, either adding more RAM if Valkey<br>is using more memory than the available, or avoiding running other memory<br>hungry processes in the same system.</p>\n<h2>Latency due to AOF and disk I/O</h2>\n<p>Another source of latency is due to the Append Only File support on Valkey.<br>The AOF basically uses two system calls to accomplish its work. One is<br>write(2) that is used in order to write data to the append only file, and<br>the other one is fdatasync(2) that is used in order to flush the kernel<br>file buffer on disk in order to ensure the durability level specified by<br>the user.</p>\n<p>Both the write(2) and fdatasync(2) calls can be source of latency.<br>For instance write(2) can block both when there is a system wide sync<br>in progress, or when the output buffers are full and the kernel requires<br>to flush on disk in order to accept new writes.</p>\n<p>The fdatasync(2) call is a worse source of latency as with many combinations<br>of kernels and file systems used it can take from a few milliseconds to<br>a few seconds to complete, especially in the case of some other process<br>doing I/O. For this reason when possible Valkey does the fdatasync(2) call<br>in a different thread.</p>\n<p>We&#39;ll see how configuration can affect the amount and source of latency<br>when using the AOF file.</p>\n<p>The AOF can be configured to perform a fsync on disk in three different<br>ways using the <strong>appendfsync</strong> configuration option (this setting can be<br>modified at runtime using the <strong>CONFIG SET</strong> command).</p>\n<ul>\n<li><p>When appendfsync is set to the value of <strong>no</strong> Valkey performs no fsync.<br>In this configuration the only source of latency can be write(2).<br>When this happens usually there is no solution since simply the disk can&#39;t<br>cope with the speed at which Valkey is receiving data, however this is<br>uncommon if the disk is not seriously slowed down by other processes doing<br>I/O.</p>\n</li>\n<li><p>When appendfsync is set to the value of <strong>everysec</strong> Valkey performs a<br>fsync every second. It uses a different thread, and if the fsync is still<br>in progress Valkey uses a buffer to delay the write(2) call up to two seconds<br>(since write would block on Linux if a fsync is in progress against the<br>same file). However if the fsync is taking too long Valkey will eventually<br>perform the write(2) call even if the fsync is still in progress, and this<br>can be a source of latency.</p>\n</li>\n<li><p>When appendfsync is set to the value of <strong>always</strong> a fsync is performed<br>at every write operation before replying back to the client with an OK code<br>(actually Valkey will try to cluster many commands executed at the same time<br>into a single fsync). In this mode performances are very low in general and<br>it is strongly recommended to use a fast disk and a file system implementation<br>that can perform the fsync in short time.</p>\n</li>\n</ul>\n<p>Most Valkey users will use either the <strong>no</strong> or <strong>everysec</strong> setting for the<br>appendfsync configuration directive. The suggestion for minimum latency is<br>to avoid other processes doing I/O in the same system.<br>Using an SSD disk can help as well, but usually even non SSD disks perform<br>well with the append only file if the disk is spare as Valkey writes<br>to the append only file without performing any seek.</p>\n<p>If you want to investigate your latency issues related to the append only<br>file you can use the strace command under Linux:</p>\n<pre><code>sudo strace -p $(pidof valkey-server) -T -e trace=fdatasync\n</code></pre>\n<p>The above command will show all the fdatasync(2) system calls performed by<br>Valkey in the main thread. With the above command you&#39;ll not see the<br>fdatasync system calls performed by the background thread when the<br>appendfsync config option is set to <strong>everysec</strong>. In order to do so<br>just add the -f switch to strace.</p>\n<p>If you wish you can also see both fdatasync and write system calls with the<br>following command:</p>\n<pre><code>sudo strace -p $(pidof valkey-server) -T -e trace=fdatasync,write\n</code></pre>\n<p>However since write(2) is also used in order to write data to the client<br>sockets this will likely show too many things unrelated to disk I/O.<br>Apparently there is no way to tell strace to just show slow system calls so<br>I use the following command:</p>\n<pre><code>sudo strace -f -p $(pidof valkey-server) -T -e trace=fdatasync,write 2&gt;&amp;1 | grep -v &#39;0.0&#39; | grep -v unfinished\n</code></pre>\n<h2>Latency generated by expires</h2>\n<p>Valkey evict expired keys in two ways:</p>\n<ul>\n<li>One <em>lazy</em> way expires a key when it is requested by a command, but it is found to be already expired.</li>\n<li>One <em>active</em> way expires a few keys every 100 milliseconds.</li>\n</ul>\n<p>The active expiring is designed to be adaptive. An expire cycle is started every 100 milliseconds (10 times per second), and will do the following:</p>\n<ul>\n<li>Sample <code>ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP</code> keys, evicting all the keys already expired.</li>\n<li>If the more than 25% of the keys were found expired, repeat.</li>\n</ul>\n<p>Given that <code>ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP</code> is set to 20 by default, and the process is performed ten times per second, usually just 200 keys per second are actively expired. This is enough to clean the DB fast enough even when already expired keys are not accessed for a long time, so that the <em>lazy</em> algorithm does not help. At the same time expiring just 200 keys per second has no effects in the latency a Valkey instance.</p>\n<p>However the algorithm is adaptive and will loop if it finds more than 25% of keys already expired in the set of sampled keys. But given that we run the algorithm ten times per second, this means that the unlucky event of more than 25% of the keys in our random sample are expiring at least <em>in the same second</em>.</p>\n<p>Basically this means that <strong>if the database has many, many keys expiring in the same second, and these make up at least 25% of the current population of keys with an expire set</strong>, Valkey can block in order to get the percentage of keys already expired below 25%.</p>\n<p>This approach is needed in order to avoid using too much memory for keys that are already expired, and usually is absolutely harmless since it&#39;s strange that a big number of keys are going to expire in the same exact second, but it is not impossible that the user used <code>EXPIREAT</code> extensively with the same Unix time.</p>\n<p>In short: be aware that many keys expiring at the same moment can be a source of latency.</p>\n<h2>Valkey software watchdog</h2>\n<p>The <em>Valkey Software Watchdog</em> is a debugging tool<br>designed to track those latency problems that for one reason or the other<br>escaped an analysis using normal tools.</p>\n<p>The software watchdog is an experimental feature. While it is designed to<br>be used in production environments care should be taken to backup the database<br>before proceeding as it could possibly have unexpected interactions with the<br>normal execution of the Valkey server.</p>\n<p>It is important to use it only as <em>last resort</em> when there is no way to track the issue by other means.</p>\n<p>This is how this feature works:</p>\n<ul>\n<li>The user enables the software watchdog using the <code>CONFIG SET</code> command.</li>\n<li>Valkey starts monitoring itself constantly.</li>\n<li>If Valkey detects that the server is blocked into some operation that is not returning fast enough, and that may be the source of the latency issue, a low level report about where the server is blocked is dumped on the log file.</li>\n<li>The user contacts the developers by opening an issue on GitHub, including the watchdog report in the message.</li>\n</ul>\n<p>Note that this feature cannot be enabled using the valkey.conf file, because it is designed to be enabled only in already running instances and only for debugging purposes.</p>\n<p>To enable the feature just use the following:</p>\n<pre><code>CONFIG SET watchdog-period 500\n</code></pre>\n<p>The period is specified in milliseconds. In the above example I specified to log latency issues only if the server detects a delay of 500 milliseconds or greater. The minimum configurable period is 200 milliseconds.</p>\n<p>When you are done with the software watchdog you can turn it off setting the <code>watchdog-period</code> parameter to 0. <strong>Important:</strong> remember to do this because keeping the instance with the watchdog turned on for a longer time than needed is generally not a good idea.</p>\n<p>The following is an example of what you&#39;ll see printed in the log file once the software watchdog detects a delay longer than the configured one:</p>\n<pre><code>[8547 | signal handler] (1333114359)\n--- WATCHDOG TIMER EXPIRED ---\n/lib/libc.so.6(nanosleep+0x2d) [0x7f16b5c2d39d]\n/lib/libpthread.so.0(+0xf8f0) [0x7f16b5f158f0]\n/lib/libc.so.6(nanosleep+0x2d) [0x7f16b5c2d39d]\n/lib/libc.so.6(usleep+0x34) [0x7f16b5c62844]\n./valkey-server(debugCommand+0x3e1) [0x43ab41]\n./valkey-server(call+0x5d) [0x415a9d]\n./valkey-server(processCommand+0x375) [0x415fc5]\n./valkey-server(processInputBuffer+0x4f) [0x4203cf]\n./valkey-server(readQueryFromClient+0xa0) [0x4204e0]\n./valkey-server(aeProcessEvents+0x128) [0x411b48]\n./valkey-server(aeMain+0x2b) [0x411dbb]\n./valkey-server(main+0x2b6) [0x418556]\n/lib/libc.so.6(__libc_start_main+0xfd) [0x7f16b5ba1c4d]\n./valkey-server() [0x411099]\n------\n</code></pre>\n<p>Note: in the example the <strong>DEBUG SLEEP</strong> command was used in order to block the server. The stack trace is different if the server blocks in a different context.</p>\n<p>If you happen to collect multiple watchdog stack traces you are encouraged to post everything in a GitHub issue.<br>The more traces we obtain, the simpler it will be to understand what the problem with your instance is.</p>\n"
  },
  {
    "id": "ldb",
    "topicName": "Debugging Lua scripts",
    "description": "How to use the built-in Lua debugger",
    "htmlContent": "<p>Valkey includes a complete Lua debugger, that can be<br>used to make the task of writing complex Lua scripts much simpler.</p>\n<p>The Valkey Lua debugger, codenamed LDB, has the following important features:</p>\n<ul>\n<li>It uses a server-client model, so it&#39;s a remote debugger.<br>The Valkey server acts as the debugging server, while the default client is <code>valkey-cli</code>.<br>However other clients can be developed by following the simple protocol implemented by the server.</li>\n<li>By default every new debugging session is a forked session.<br>It means that while the Valkey Lua script is being debugged, the server does not block and is usable for development or in order to execute multiple debugging sessions in parallel.<br>This also means that changes are <strong>rolled back</strong> after the script debugging session finished, so that&#39;s possible to restart a new debugging session again, using exactly the same Valkey data set as the previous debugging session.</li>\n<li>An alternative synchronous (non forked) debugging model is available on demand, so that changes to the dataset can be retained.<br>In this mode the server blocks for the time the debugging session is active.</li>\n<li>Support for step by step execution.</li>\n<li>Support for static and dynamic breakpoints.</li>\n<li>Support from logging the debugged script into the debugger console.</li>\n<li>Inspection of Lua variables.</li>\n<li>Tracing of Valkey commands executed by the script.</li>\n<li>Pretty printing of Valkey and Lua values.</li>\n<li>Infinite loops and long execution detection, which simulates a breakpoint.</li>\n</ul>\n<h2>Quick start</h2>\n<p>A simple way to get started with the Lua debugger is to watch this video<br>introduction:</p>\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IMvRfStaoyM\" frameborder=\"0\" allowfullscreen></iframe>\n\n<blockquote>\n<p>Important Note:  please make sure to avoid debugging Lua scripts using your Valkey production server.<br>Use a development server instead.<br>Also note that using the synchronous debugging mode (which is NOT the default) results in the Valkey server blocking for all the time the debugging session lasts.</p>\n</blockquote>\n<p>To start a new debugging session using <code>valkey-cli</code> do the following:</p>\n<ol>\n<li><p>Create your script in some file with your preferred editor. Let&#39;s assume you are editing your Valkey Lua script located at <code>/tmp/script.lua</code>.</p>\n</li>\n<li><p>Start a debugging session with:</p>\n<p> ./valkey-cli --ldb --eval /tmp/script.lua</p>\n</li>\n</ol>\n<p>Note that with the <code>--eval</code> option of <code>valkey-cli</code> you can pass key names and arguments to the script, separated by a comma, like in the following example:</p>\n<pre><code>./valkey-cli --ldb --eval /tmp/script.lua mykey somekey , arg1 arg2\n</code></pre>\n<p>You&#39;ll enter a special mode where <code>valkey-cli</code> no longer accepts its normal<br>commands, but instead prints a help screen and passes the unmodified debugging<br>commands directly to Valkey.</p>\n<p>The only commands which are not passed to the Valkey debugger are:</p>\n<ul>\n<li><code>quit</code> -- this will terminate the debugging session.<br>It&#39;s like removing all the breakpoints and using the <code>continue</code> debugging command.<br>Moreover the command will exit from <code>valkey-cli</code>.</li>\n<li><code>restart</code> -- the debugging session will restart from scratch, <strong>reloading the new version of the script from the file</strong>.<br>So a normal debugging cycle involves modifying the script after some debugging, and calling <code>restart</code> in order to start debugging again with the new script changes.</li>\n<li><code>help</code> -- this command is passed to the Valkey Lua debugger, that will print a list of commands like the following:</li>\n</ul>\n<pre><code>lua debugger&gt; help\nValkey Lua debugger help:\n[h]elp               Show this help.\n[s]tep               Run current line and stop again.\n[n]ext               Alias for step.\n[c]ontinue           Run till next breakpoint.\n[l]ist               List source code around current line.\n[l]ist [line]        List source code around [line].\n                     line = 0 means: current position.\n[l]ist [line] [ctx]  In this form [ctx] specifies how many lines\n                     to show before/after [line].\n[w]hole              List all source code. Alias for &#39;list 1 1000000&#39;.\n[p]rint              Show all the local variables.\n[p]rint &lt;var&gt;        Show the value of the specified variable.\n                     Can also show global vars KEYS and ARGV.\n[b]reak              Show all breakpoints.\n[b]reak &lt;line&gt;       Add a breakpoint to the specified line.\n[b]reak -&lt;line&gt;      Remove breakpoint from the specified line.\n[b]reak 0            Remove all breakpoints.\n[t]race              Show a backtrace.\n[e]val &lt;code&gt;        Execute some Lua code (in a different callframe).\n[r]edis &lt;cmd&gt;        Execute a Valkey command.\n[m]axlen [len]       Trim logged Valkey replies and Lua var dumps to len.\n                     Specifying zero as &lt;len&gt; means unlimited.\n[a]bort              Stop the execution of the script. In sync\n                     mode dataset changes will be retained.\n\nDebugger functions you can call from Lua scripts:\nserver.debug()        Produce logs in the debugger console.\nserver.breakpoint()   Stop execution as if there was a breakpoint in the\n                     next line of code.\n</code></pre>\n<p>Note that when you start the debugger it will start in <strong>stepping mode</strong>.<br>It will stop at the first line of the script that actually does something before executing it.</p>\n<p>From this point you usually call <code>step</code> in order to execute the line and go to the next line.<br>While you step Valkey will show all the commands executed by the server like in the following example:</p>\n<pre><code>* Stopped at 1, stop reason = step over\n-&gt; 1   server.call(&#39;ping&#39;)\nlua debugger&gt; step\n&lt;redis&gt; ping\n&lt;reply&gt; &quot;+PONG&quot;\n* Stopped at 2, stop reason = step over\n</code></pre>\n<p>The <code>&lt;redis&gt;</code> and <code>&lt;reply&gt;</code> lines show the command executed by the line just<br>executed, and the reply from the server. Note that this happens only in stepping mode.<br>If you use <code>continue</code> in order to execute the script till the next breakpoint, commands will not be dumped on the screen to prevent too much output.</p>\n<h2>Termination of the debugging session</h2>\n<p>When the scripts terminates naturally, the debugging session ends and<br><code>valkey-cli</code> returns in its normal non-debugging mode. You can restart the<br>session using the <code>restart</code> command as usual.</p>\n<p>Another way to stop a debugging session is just interrupting <code>valkey-cli</code><br>manually by pressing <code>Ctrl+C</code>. Note that also any event breaking the<br>connection between <code>valkey-cli</code> and the <code>valkey-server</code> will interrupt the<br>debugging session.</p>\n<p>All the forked debugging sessions are terminated when the server is shut<br>down.</p>\n<h2>Abbreviating debugging commands</h2>\n<p>Debugging can be a very repetitive task. For this reason every Valkey<br>debugger command starts with a different character, and you can use the single<br>initial character in order to refer to the command.</p>\n<p>So for example instead of typing <code>step</code> you can just type <code>s</code>.</p>\n<h2>Breakpoints</h2>\n<p>Adding and removing breakpoints is trivial as described in the online help.<br>Just use <code>b 1 2 3 4</code> to add a breakpoint in line 1, 2, 3, 4.<br>The command <code>b 0</code> removes all the breakpoints. Selected breakpoints can be<br>removed using as argument the line where the breakpoint we want to remove is, but prefixed by a minus sign.<br>So for example <code>b -3</code> removes the breakpoint from line 3.</p>\n<p>Note that adding breakpoints to lines that Lua never executes, like declaration of local variables or comments, will not work.<br>The breakpoint will be added but since this part of the script will never be executed, the program will never stop.</p>\n<h2>Dynamic breakpoints</h2>\n<p>Using the <code>breakpoint</code> command it is possible to add breakpoints into specific<br>lines. However sometimes we want to stop the execution of the program only<br>when something special happens. In order to do so, you can use the<br><code>server.breakpoint()</code> function inside your Lua script. When called it simulates<br>a breakpoint in the next line that will be executed.</p>\n<pre><code>if counter &gt; 10 then server.breakpoint() end\n</code></pre>\n<p>This feature is extremely useful when debugging, so that we can avoid<br>continuing the script execution manually multiple times until a given condition<br>is encountered.</p>\n<h2>Synchronous mode</h2>\n<p>As explained previously, but default LDB uses forked sessions with rollback<br>of all the data changes operated by the script while it has being debugged.<br>Determinism is usually a good thing to have during debugging, so that successive<br>debugging sessions can be started without having to reset the database content<br>to its original state.</p>\n<p>However for tracking certain bugs, you may want to retain the changes performed<br>to the key space by each debugging session. When this is a good idea you<br>should start the debugger using a special option, <code>ldb-sync-mode</code>, in <code>valkey-cli</code>.</p>\n<pre><code>./valkey-cli --ldb-sync-mode --eval /tmp/script.lua\n</code></pre>\n<blockquote>\n<p>Note: Valkey server will be unreachable during the debugging session in this mode, so use with care.</p>\n</blockquote>\n<p>In this special mode, the <code>abort</code> command can stop the script half-way taking the changes operated to the dataset.<br>Note that this is different compared to ending the debugging session normally.<br>If you just interrupt <code>valkey-cli</code> the script will be fully executed and then the session terminated.<br>Instead with <code>abort</code> you can interrupt the script execution in the middle and start a new debugging session if needed.</p>\n<h2>Logging from scripts</h2>\n<p>The <code>server.debug()</code> command is a powerful debugging facility that can be<br>called inside the Valkey Lua script in order to log things into the debug<br>console:</p>\n<pre><code>lua debugger&gt; list\n-&gt; 1   local a = {1,2,3}\n   2   local b = false\n   3   server.debug(a,b)\nlua debugger&gt; continue\n&lt;debug&gt; line 3: {1; 2; 3}, false\n</code></pre>\n<p>If the script is executed outside of a debugging session, <code>server.debug()</code> has no effects at all.<br>Note that the function accepts multiple arguments, that are separated by a comma and a space in the output.</p>\n<p>Tables and nested tables are displayed correctly in order to make values simple to observe for the programmer debugging the script.</p>\n<h2>Inspecting the program state with <code>print</code> and <code>eval</code></h2>\n<p>While the <code>server.debug()</code> function can be used in order to print values<br>directly from within the Lua script, often it is useful to observe the local<br>variables of a program while stepping or when stopped into a breakpoint.</p>\n<p>The <code>print</code> command does just that, and performs lookup in the call frames<br>starting from the current one back to the previous ones, up to top-level.<br>This means that even if we are into a nested function inside a Lua script,<br>we can still use <code>print foo</code> to look at the value of <code>foo</code> in the context<br>of the calling function. When called without a variable name, <code>print</code> will<br>print all variables and their respective values.</p>\n<p>The <code>eval</code> command executes small pieces of Lua scripts <strong>outside the context of the current call frame</strong> (evaluating inside the context of the current call frame is not possible with the current Lua internals).<br>However you can use this command in order to test Lua functions.</p>\n<pre><code>lua debugger&gt; e server.sha1hex(&#39;foo&#39;)\n&lt;retval&gt; &quot;0beec7b5ea3f0fdbc95d0dd47f3c5bc275da8a33&quot;\n</code></pre>\n<h2>Debugging clients</h2>\n<p>LDB uses the client-server model where the Valkey server acts as a debugging server that communicates using <a href=\"protocol\">RESP</a>. While <code>valkey-cli</code> is the default debug client, any <a href=\"../clients/\">client</a> can be used for debugging as long as it meets one of the following conditions:</p>\n<ol>\n<li>The client provides a native interface for setting the debug mode and controlling the debug session.</li>\n<li>The client provides an interface for sending arbitrary commands over RESP.</li>\n<li>The client allows sending raw messages to the Valkey server.</li>\n</ol>\n"
  },
  {
    "id": "license",
    "topicName": "License",
    "description": "License and trademark information\n",
    "htmlContent": "<ul>\n<li><p>Valkey is <strong>open source software</strong> released under the terms of the <strong>three clause BSD license</strong>. Most of the Valkey source code was written by Salvatore Sanfilippo and Pieter Noordhuis. A list of other contributors can be found in the git history.</p>\n</li>\n<li><p>Valkey is based on the formerly open source Redis, as it was before the<br>license of Redis was changed to one that is not open source.<br>Read more about this in the <a href=\"history\">History of Valkey</a>.<br>Redis is a trademark of Redis Ltd. Whenever we use the name Redis in the<br>Valkey documentation, we&#39;re trying our best to use it in accordance with the<br><a href=\"https://redis.com/legal/trademark-guidelines/\">Redis Trademark Guidelines</a>.</p>\n</li>\n</ul>\n<h2>Licences:</h2>\n<h3>Three clause BSD license</h3>\n<p>Every file in the Valkey distribution, with the exception of third party files<br>specified in the list below, is provided under the following license:</p>\n<pre><code>Redistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice,\n  this list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright\n  notice, this list of conditions and the following disclaimer in the\n  documentation and/or other materials provided with the distribution.\n\n* Neither the name of the copyright holder nor the names of its contributors\n  may be used to endorse or promote products derived from this software\n  without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\nARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\nLIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\nCONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\nSUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\nINTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\nCONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\nARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\nPOSSIBILITY OF SUCH DAMAGE.\n</code></pre>\n<p>Files in the Valkey distribution that were originally created for Redis when<br>Redis was still under the three-clause BSD license contain the following license<br>(which differs from the above text only in one occurrence of &quot;Redis&quot; in the 3rd<br>clause):</p>\n<pre><code>Redistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice,\n  this list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright\n  notice, this list of conditions and the following disclaimer in the\n  documentation and/or other materials provided with the distribution.\n\n* Neither the name of Redis nor the names of its contributors may be used\n  to endorse or promote products derived from this software without\n  specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\nARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\nLIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\nCONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\nSUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\nINTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\nCONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\nARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\nPOSSIBILITY OF SUCH DAMAGE.\n</code></pre>\n<h3>Third-party files and licenses</h3>\n<p>Valkey uses source code from third parties. All this code contains a BSD or BSD-compatible license. The following is a list of third-party files and information about their copyright.</p>\n<ul>\n<li><p>Valkey uses the <a href=\"http://oldhome.schmorp.de/marc/liblzf.html\">LHF compression library</a>. LibLZF is copyright Marc Alexander Lehmann and is released under the terms of the <strong>two-clause BSD license</strong>.</p>\n</li>\n<li><p>Valkey uses the <code>sha1.c</code> file that is copyright by Steve Reid and released under the <strong>public domain</strong>. This file is extremely popular and used among open source and proprietary code.</p>\n</li>\n<li><p>When compiled on Linux, Valkey uses the <a href=\"https://github.com/jemalloc/jemalloc\">Jemalloc allocator</a>, which is copyrighted by Jason Evans, Mozilla Foundation, and Facebook, Inc and released under the <strong>two-clause BSD license</strong>.</p>\n</li>\n<li><p>Inside Jemalloc, the file <code>pprof</code> is copyrighted by Google Inc. and released under the <strong>three-clause BSD license</strong>.</p>\n</li>\n<li><p>Inside Jemalloc the files <code>inttypes.h</code>, <code>stdbool.h</code>, <code>stdint.h</code>, <code>strings.h</code> under the <code>msvc_compat</code> directory are copyright Alexander Chemeris and released under the <strong>three-clause BSD license</strong>.</p>\n</li>\n<li><p>The libraries <strong>hiredis</strong> and <strong>linenoise</strong> also included inside the Valkey distribution are copyright Salvatore Sanfilippo and Pieter Noordhuis and released under the terms respectively of the <strong>three-clause BSD license</strong> and <strong>two-clause BSD license</strong>.</p>\n</li>\n</ul>\n"
  },
  {
    "id": "lists",
    "topicName": "Lists",
    "description": "Introduction to Lists\n",
    "htmlContent": "<p>Lists are linked lists of string values.<br>Lists are frequently used to:</p>\n<ul>\n<li>Implement stacks and queues.</li>\n<li>Build queue management for background worker systems.</li>\n</ul>\n<h2>Basic commands</h2>\n<ul>\n<li><code>LPUSH</code> adds a new element to the head of a list; <code>RPUSH</code> adds to the tail.</li>\n<li><code>LPOP</code> removes and returns an element from the head of a list; <code>RPOP</code> does the same but from the tails of a list. </li>\n<li><code>LLEN</code> returns the length of a list.</li>\n<li><code>LMOVE</code> atomically moves elements from one list to another.</li>\n<li><code>LTRIM</code> reduces a list to the specified range of elements.</li>\n</ul>\n<h3>Blocking commands</h3>\n<p>Lists support several blocking commands.<br>For example:</p>\n<ul>\n<li><code>BLPOP</code> removes and returns an element from the head of a list.<br>If the list is empty, the command blocks until an element becomes available or until the specified timeout is reached.</li>\n<li><code>BLMOVE</code> atomically moves elements from a source list to a target list.<br>If the source list is empty, the command will block until a new element becomes available.</li>\n</ul>\n<p>See the <a href=\"../commands/#list\">complete series of list commands</a>.</p>\n<h2>Examples</h2>\n<ul>\n<li>Treat a list like a queue (first in, first out):</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; LPUSH bikes:repairs bike:1\n(integer) 1\n127.0.0.1:6379&gt; LPUSH bikes:repairs bike:2\n(integer) 2\n127.0.0.1:6379&gt; RPOP bikes:repairs\n&quot;bike:1&quot;\n127.0.0.1:6379&gt; RPOP bikes:repairs\n&quot;bike:2&quot;\n</code></pre>\n<ul>\n<li>Treat a list like a stack (first in, last out):</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; LPUSH bikes:repairs bike:1\n(integer) 1\n127.0.0.1:6379&gt; LPUSH bikes:repairs bike:2\n(integer) 2\n127.0.0.1:6379&gt; LPOP bikes:repairs\n&quot;bike:2&quot;\n127.0.0.1:6379&gt; LPOP bikes:repairs\n&quot;bike:1&quot;\n</code></pre>\n<ul>\n<li>Check the length of a list:</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; LLEN bikes:repairs\n(integer) 0\n</code></pre>\n<ul>\n<li>Atomically pop an element from one list and push to another:</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; LPUSH bikes:repairs bike:1\n(integer) 1\n127.0.0.1:6379&gt; LPUSH bikes:repairs bike:2\n(integer) 2\n127.0.0.1:6379&gt; LMOVE bikes:repairs bikes:finished LEFT LEFT\n&quot;bike:2&quot;\n127.0.0.1:6379&gt; LRANGE bikes:repairs 0 -1\n1) &quot;bike:1&quot;\n127.0.0.1:6379&gt; LRANGE bikes:finished 0 -1\n1) &quot;bike:2&quot;\n</code></pre>\n<ul>\n<li>To limit the length of a list you can call <code>LTRIM</code>:</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; RPUSH bikes:repairs bike:1 bike:2 bike:3 bike:4 bike:5\n(integer) 5\n127.0.0.1:6379&gt; LTRIM bikes:repairs 0 2\nOK\n127.0.0.1:6379&gt; LRANGE bikes:repairs 0 -1\n1) &quot;bike:1&quot;\n2) &quot;bike:2&quot;\n3) &quot;bike:3&quot;\n</code></pre>\n<h3>What are Lists?</h3>\n<p>To explain the List data type it&#39;s better to start with a little bit of theory,<br>as the term <em>List</em> is often used in an improper way by information technology<br>folks. For instance &quot;Python Lists&quot; are not what the name may suggest (Linked<br>Lists), but rather Arrays (the same data type is called Array in<br>Ruby actually).</p>\n<p>From a very general point of view a List is just a sequence of ordered<br>elements: 10,20,1,2,3 is a list. But the properties of a List implemented using<br>an Array are very different from the properties of a List implemented using a<br><em>Linked List</em>.</p>\n<p>Lists are implemented via Linked Lists. This means that even if you have<br>millions of elements inside a list, the operation of adding a new element in<br>the head or in the tail of the list is performed <em>in constant time</em>. The speed of adding a<br>new element with the <code>LPUSH</code> command to the head of a list with ten<br>elements is the same as adding an element to the head of list with 10<br>million elements.</p>\n<p>What&#39;s the downside? Accessing an element <em>by index</em> is very fast in lists<br>implemented with an Array (constant time indexed access) and not so fast in<br>lists implemented by linked lists (where the operation requires an amount of<br>work proportional to the index of the accessed element).</p>\n<p>Lists are implemented with linked lists because for a database system it<br>is crucial to be able to add elements to a very long list in a very fast way.<br>Another strong advantage, as you&#39;ll see in a moment, is that Lists can be<br>taken at constant length in constant time.</p>\n<p>When fast access to the middle of a large collection of elements is important,<br>there is a different data structure that can be used, called sorted sets.<br>Sorted sets are covered in the <a href=\"sorted-sets\">Sorted sets</a> tutorial page.</p>\n<h3>First steps with Lists</h3>\n<p>The <code>LPUSH</code> command adds a new element into a list, on the<br>left (at the head), while the <code>RPUSH</code> command adds a new<br>element into a list, on the right (at the tail). Finally the<br><code>LRANGE</code> command extracts ranges of elements from lists:</p>\n<pre><code>127.0.0.1:6379&gt; RPUSH bikes:repairs bike:1\n(integer) 1\n127.0.0.1:6379&gt; RPUSH bikes:repairs bike:2\n(integer) 2\n127.0.0.1:6379&gt; LPUSH bikes:repairs bike:important_bike\n(integer) 3\n127.0.0.1:6379&gt; LRANGE bikes:repairs 0 -1\n1) &quot;bike:important_bike&quot;\n2) &quot;bike:1&quot;\n3) &quot;bike:2&quot;\n</code></pre>\n<p>Note that <code>LRANGE</code> takes two indexes, the first and the last<br>element of the range to return. Both the indexes can be negative, telling Valkey<br>to start counting from the end: so -1 is the last element, -2 is the<br>penultimate element of the list, and so forth.</p>\n<p>As you can see <code>RPUSH</code> appended the elements on the right of the list, while<br>the final <code>LPUSH</code> appended the element on the left.</p>\n<p>Both commands are <em>variadic commands</em>, meaning that you are free to push<br>multiple elements into a list in a single call:</p>\n<pre><code>127.0.0.1:6379&gt; RPUSH bikes:repairs bike:1 bike:2 bike:3\n(integer) 3\n127.0.0.1:6379&gt; LPUSH bikes:repairs bike:important_bike bike:very_important_bike\n127.0.0.1:6379&gt; LRANGE mylist 0 -1\n1) &quot;bike:very_important_bike&quot;\n2) &quot;bike:important_bike&quot;\n3) &quot;bike:1&quot;\n4) &quot;bike:2&quot;\n5) &quot;bike:3&quot;\n</code></pre>\n<p>An important operation defined on Lists is the ability to <em>pop elements</em>.<br>Popping elements is the operation of both retrieving the element from the list,<br>and eliminating it from the list, at the same time. You can pop elements<br>from left and right, similarly to how you can push elements in both sides<br>of the list. We&#39;ll add three elements and pop three elements, so at the end of this<br>sequence of commands the list is empty and there are no more elements to<br>pop:</p>\n<pre><code>127.0.0.1:6379&gt; RPUSH bikes:repairs bike:1 bike:2 bike:3\n(integer) 3\n127.0.0.1:6379&gt; RPOP bikes:repairs\n&quot;bike:3&quot;\n127.0.0.1:6379&gt; LPOP bikes:repairs\n&quot;bike:1&quot;\n127.0.0.1:6379&gt; RPOP bikes:repairs\n&quot;bike:2&quot;\n127.0.0.1:6379&gt; RPOP bikes:repairs\n(nil)\n</code></pre>\n<p>Valkey returned a NULL value to signal that there are no elements in the<br>list.</p>\n<h3>Common use cases for lists</h3>\n<p>Lists are useful for a number of tasks, two very representative use cases<br>are the following:</p>\n<ul>\n<li>Remember the latest updates posted by users into a social network.</li>\n<li>Communication between processes, using a consumer-producer pattern where the producer pushes items into a list, and a consumer (usually a <em>worker</em>) consumes those items and executes actions. Valkey has special list commands to make this use case both more reliable and efficient.</li>\n</ul>\n<p>For example both the popular Ruby libraries <a href=\"https://github.com/resque/resque\">resque</a> and<br><a href=\"https://github.com/mperham/sidekiq\">sidekiq</a> use Lists under the hood in order to<br>implement background jobs.</p>\n<p>The popular Twitter social network <a href=\"https://www.infoq.com/presentations/Real-Time-Delivery-Twitter\">takes the latest tweets</a><br>posted by users into Lists.</p>\n<p>To describe a common use case step by step, imagine your home page shows the latest<br>photos published in a photo sharing social network and you want to speedup access.</p>\n<ul>\n<li>Every time a user posts a new photo, we add its ID into a list with <code>LPUSH</code>.</li>\n<li>When users visit the home page, we use <code>LRANGE 0 9</code> in order to get the latest 10 posted items.</li>\n</ul>\n<h3>Capped lists</h3>\n<p>In many use cases we just want to use lists to store the <em>latest items</em>,<br>whatever they are: social network updates, logs, or anything else.</p>\n<p>Valkey allows us to use lists as a capped collection, only remembering the latest<br>N items and discarding all the oldest items using the <code>LTRIM</code> command.</p>\n<p>The <code>LTRIM</code> command is similar to <code>LRANGE</code>, but <strong>instead of displaying the<br>specified range of elements</strong> it sets this range as the new list value. All<br>the elements outside the given range are removed.</p>\n<p>For example, if you&#39;re adding bikes on the end of a list of repairs, but only<br>want to worry about the 3 that have been on the list the longest:</p>\n<pre><code>127.0.0.1:6379&gt; RPUSH bikes:repairs bike:1 bike:2 bike:3 bike:4 bike:5\n(integer) 5\n127.0.0.1:6379&gt; LTRIM bikes:repairs 0 2\nOK\n127.0.0.1:6379&gt; LRANGE bikes:repairs 0 -1\n1) &quot;bike:1&quot;\n2) &quot;bike:2&quot;\n3) &quot;bike:3&quot;\n</code></pre>\n<p>The above <code>LTRIM</code> command tells Valkey to keep just list elements from index<br>0 to 2, everything else will be discarded. This allows for a very simple but<br>useful pattern: doing a List push operation + a List trim operation together<br>to add a new element and discard elements exceeding a limit. Using<br><code>LTRIM</code> with negative indexes can then be used to keep only the 3 most recently added:</p>\n<pre><code>127.0.0.1:6379&gt; RPUSH bikes:repairs bike:1 bike:2 bike:3 bike:4 bike:5\n(integer) 5\n127.0.0.1:6379&gt; LTRIM bikes:repairs -3 -1\nOK\n127.0.0.1:6379&gt; LRANGE bikes:repairs 0 -1\n1) &quot;bike:3&quot;\n2) &quot;bike:4&quot;\n3) &quot;bike:5&quot;\n</code></pre>\n<p>The above combination adds new elements and keeps only the 3<br>newest elements into the list. With <code>LRANGE</code> you can access the top items<br>without any need to remember very old data.</p>\n<p>Note: while <code>LRANGE</code> is technically an O(N) command, accessing small ranges<br>towards the head or the tail of the list is a constant time operation.</p>\n<h2>Blocking operations on lists</h2>\n<p>Lists have a special feature that make them suitable to implement queues,<br>and in general as a building block for inter process communication systems:<br>blocking operations.</p>\n<p>Imagine you want to push items into a list with one process, and use<br>a different process in order to actually do some kind of work with those<br>items. This is the usual producer / consumer setup, and can be implemented<br>in the following simple way:</p>\n<ul>\n<li>To push items into the list, producers call <code>LPUSH</code>.</li>\n<li>To extract / process items from the list, consumers call <code>RPOP</code>.</li>\n</ul>\n<p>However it is possible that sometimes the list is empty and there is nothing<br>to process, so <code>RPOP</code> just returns NULL. In this case a consumer is forced to wait<br>some time and retry again with <code>RPOP</code>. This is called <em>polling</em>, and is not<br>a good idea in this context because it has several drawbacks:</p>\n<ol>\n<li>Forces Valkey and clients to process useless commands (all the requests when the list is empty will get no actual work done, they&#39;ll just return NULL).</li>\n<li>Adds a delay to the processing of items, since after a worker receives a NULL, it waits some time. To make the delay smaller, we could wait less between calls to <code>RPOP</code>, with the effect of amplifying problem number 1, i.e. more useless calls to Valkey.</li>\n</ol>\n<p>So Valkey implements commands called <code>BRPOP</code> and <code>BLPOP</code> which are versions<br>of <code>RPOP</code> and <code>LPOP</code> able to block if the list is empty: they&#39;ll return to<br>the caller only when a new element is added to the list, or when a user-specified<br>timeout is reached.</p>\n<p>This is an example of a <code>BRPOP</code> call we could use in the worker:</p>\n<pre><code>127.0.0.1:6379&gt; RPUSH bikes:repairs bike:1 bike:2\n(integer) 2\n127.0.0.1:6379&gt; BRPOP bikes:repairs 1\n1) &quot;bikes:repairs&quot;\n2) &quot;bike:2&quot;\n127.0.0.1:6379&gt; BRPOP bikes:repairs 1\n1) &quot;bikes:repairs&quot;\n2) &quot;bike:1&quot;\n127.0.0.1:6379&gt; BRPOP bikes:repairs 1\n(nil)\n(2.01s)\n</code></pre>\n<p>It means: &quot;wait for elements in the list <code>bikes:repairs</code>, but return if after 1 second<br>no element is available&quot;.</p>\n<p>Note that you can use 0 as timeout to wait for elements forever, and you can<br>also specify multiple lists and not just one, in order to wait on multiple<br>lists at the same time, and get notified when the first list receives an<br>element.</p>\n<p>A few things to note about <code>BRPOP</code>:</p>\n<ol>\n<li>Clients are served in an ordered way: the first client that blocked waiting for a list, is served first when an element is pushed by some other client, and so forth.</li>\n<li>The return value is different compared to <code>RPOP</code>: it is a two-element array since it also includes the name of the key, because <code>BRPOP</code> and <code>BLPOP</code> are able to block waiting for elements from multiple lists.</li>\n<li>If the timeout is reached, NULL is returned.</li>\n</ol>\n<p>There are more things you should know about lists and blocking ops. We<br>suggest that you read more on the following:</p>\n<ul>\n<li>It is possible to build safer queues or rotating queues using <code>LMOVE</code>.</li>\n<li>There is also a blocking variant of the command, called <code>BLMOVE</code>.</li>\n</ul>\n<h2>Automatic creation and removal of keys</h2>\n<p>So far in our examples we never had to create empty lists before pushing<br>elements, or removing empty lists when they no longer have elements inside.<br>It is Valkey&#39; responsibility to delete keys when lists are left empty, or to create<br>an empty list if the key does not exist and we are trying to add elements<br>to it, for example, with <code>LPUSH</code>.</p>\n<p>This is not specific to lists, it applies to all the Valkey data types<br>composed of multiple elements -- Streams, Sets, Sorted Sets and Hashes.</p>\n<p>Basically we can summarize the behavior with three rules:</p>\n<ol>\n<li>When we add an element to an aggregate data type, if the target key does not exist, an empty aggregate data type is created before adding the element.</li>\n<li>When we remove elements from an aggregate data type, if the value remains empty, the key is automatically destroyed. The Stream data type is the only exception to this rule.</li>\n<li>Calling a read-only command such as <code>LLEN</code> (which returns the length of the list), or a write command removing elements, with an empty key, always produces the same result as if the key is holding an empty aggregate type of the type the command expects to find.</li>\n</ol>\n<p>Examples of rule 1:</p>\n<pre><code>127.0.0.1:6379&gt; DEL new_bikes\n(integer) 0\n127.0.0.1:6379&gt; LPUSH new_bikes bike:1 bike:2 bike:3\n(integer) 3\n</code></pre>\n<p>However we can&#39;t perform operations against the wrong type if the key exists:</p>\n<pre><code>127.0.0.1:6379&gt; SET new_bikes bike:1\nOK\n127.0.0.1:6379&gt; TYPE new_bikes\nstring\n127.0.0.1:6379&gt; LPUSH new_bikes bike:2 bike:3\n(error) WRONGTYPE Operation against a key holding the wrong kind of value\n</code></pre>\n<p>Example of rule 2:</p>\n<pre><code>127.0.0.1:6379&gt; RPUSH bikes:repairs bike:1 bike:2 bike:3\n(integer) 3\n127.0.0.1:6379&gt; EXISTS bikes:repairs\n(integer) 1\n127.0.0.1:6379&gt; LPOP bikes:repairs\n&quot;bike:3&quot;\n127.0.0.1:6379&gt; LPOP bikes:repairs\n&quot;bike:2&quot;\n127.0.0.1:6379&gt; LPOP bikes:repairs\n&quot;bike:1&quot;\n127.0.0.1:6379&gt; EXISTS bikes:repairs\n(integer) 0\n</code></pre>\n<p>The key no longer exists after all the elements are popped.</p>\n<p>Example of rule 3:</p>\n<pre><code>127.0.0.1:6379&gt; DEL bikes:repairs\n(integer) 0\n127.0.0.1:6379&gt; LLEN bikes:repairs\n(integer) 0\n127.0.0.1:6379&gt; LPOP bikes:repairs\n(nil)\n</code></pre>\n<h2>Limits</h2>\n<p>The max length of a List is 2^32 - 1 (4,294,967,295) elements.</p>\n<h2>Performance</h2>\n<p>List operations that access its head or tail are O(1), which means they&#39;re highly efficient.<br>However, commands that manipulate elements within a list are usually O(n).<br>Examples of these include <code>LINDEX</code>, <code>LINSERT</code>, and <code>LSET</code>.<br>Exercise caution when running these commands, mainly when operating on large lists.</p>\n<h2>Alternatives</h2>\n<p>Consider <a href=\"streams-intro\">Streams</a> as an alternative to lists when you need to store and process an indeterminate series of events.</p>\n"
  },
  {
    "id": "lru-cache",
    "topicName": "Key eviction",
    "description": "Overview of Valkey key eviction policies (LRU, LFU, etc.)",
    "htmlContent": "<p>When Valkey is used as a cache, it is often convenient to let it automatically<br>evict old data as you add new data. This behavior is well known in the<br>developer community, since it is the default behavior for the popular<br><em>memcached</em> system.</p>\n<p>This page covers the more general topic of the Valkey <code>maxmemory</code> directive used to limit the memory usage to a fixed amount. It also extensively covers the LRU eviction algorithm used by Valkey, which is actually an approximation of<br>the exact LRU.</p>\n<h2><code>Maxmemory</code> configuration directive</h2>\n<p>The <code>maxmemory</code> configuration directive configures Valkey<br>to use a specified amount of memory for the data set. You can<br>set the configuration directive using the <code>valkey.conf</code> file, or later using<br>the <code>CONFIG SET</code> command at runtime.</p>\n<p>For example, to configure a memory limit of 100 megabytes, you can use the<br>following directive inside the <code>valkey.conf</code> file:</p>\n<pre><code>maxmemory 100mb\n</code></pre>\n<p>Setting <code>maxmemory</code> to zero results into no memory limits. This is the<br>default behavior for 64 bit systems, while 32 bit systems use an implicit<br>memory limit of 3GB.<br>When the specified amount of memory is reached, how <strong>eviction policies</strong> are configured determines the default behavior.<br>Valkey can return errors for commands that could result in more memory<br>being used, or it can evict some old data to return back to the<br>specified limit every time new data is added.</p>\n<h3>Considerations for <code>maxmemory</code> when using replication</h3>\n<p>If you have set up replication, Valkey needs some RAM as a buffer to send data to the replicas and AOF files. This memory is not included in the used memory count that is compared against the <code>maxmemory</code> to trigger eviction. </p>\n<p>The reason for that is that the key eviction process itself generates some changes that need to be added to the replication and AOF buffers. If these buffers were counted for the key eviction, this would result in a loop where a freed memory would immediately be used up by these updates causing more keys to be deleted repeatedly until the database is empty.</p>\n<p>For Valkey with replication configured, it&#39;s recommended to set the <code>maxmemory</code> value lower than for a single instance without replication. This way you ensure there&#39;s enough memory for AOF and replication buffers, and other processes. </p>\n<p>You can estimate how much memory is used by the replication and AOF buffers using the <code>mem_not_counted_for_evict</code> value of the INFO memory command output. </p>\n<h2>Eviction policies</h2>\n<p>The exact behavior Valkey follows when the <code>maxmemory</code> limit is reached is<br>configured using the <code>maxmemory-policy</code> configuration directive.</p>\n<p>The following policies are available:</p>\n<ul>\n<li><strong>noeviction</strong>: New values aren&#39;t saved when memory limit is reached. When a database uses replication, this applies to the primary database</li>\n<li><strong>allkeys-lru</strong>: Keeps most recently used keys; removes least recently used (LRU) keys</li>\n<li><strong>allkeys-lfu</strong>: Keeps frequently used keys; removes least frequently used (LFU) keys</li>\n<li><strong>volatile-lru</strong>: Removes least recently used keys with a time-to-live (TTL) set.</li>\n<li><strong>volatile-lfu</strong>: Removes least frequently used keys with a TTL set.</li>\n<li><strong>allkeys-random</strong>: Randomly removes keys to make space for the new data added.</li>\n<li><strong>volatile-random</strong>: Randomly removes keys with a TTL set.</li>\n<li><strong>volatile-ttl</strong>: Removes keys with a TTL set, the keys with the shortest remaining time-to-live value first.</li>\n</ul>\n<p>The policies <strong>volatile-lru</strong>, <strong>volatile-lfu</strong>, <strong>volatile-random</strong>, and <strong>volatile-ttl</strong> behave like <strong>noeviction</strong> if there are no keys to evict matching the prerequisites.</p>\n<p><strong>LRU</strong>, <strong>LFU</strong> and <strong>volatile-ttl</strong> are implemented using approximated randomized algorithms.</p>\n<p>Picking the right eviction policy is important depending on the access pattern<br>of your application, however you can reconfigure the policy at runtime while<br>the application is running, and monitor the number of cache misses and hits<br>using the Valkey <code>INFO</code> output to tune your setup.</p>\n<p>In general as a rule of thumb:</p>\n<ul>\n<li><p>Use the <strong>allkeys-lru</strong> policy when you expect a power-law distribution in the popularity of your requests. That is, you expect a subset of elements will be accessed far more often than the rest. <strong>This is a good pick if you are unsure</strong>.</p>\n</li>\n<li><p>Use the <strong>allkeys-random</strong> if you have a cyclic access where all the keys are scanned continuously, or when you expect the distribution to be uniform.</p>\n</li>\n<li><p>Use the <strong>volatile-ttl</strong> if you want to be able to provide hints to Valkey about what are good candidate for expiration by using different TTL values when you create your cache objects.</p>\n</li>\n</ul>\n<p>The <strong>volatile-lru</strong> and <strong>volatile-random</strong> policies are mainly useful when you want to use a single instance for both caching and to have a set of persistent keys. However it is usually a better idea to run two Valkey instances to solve such a problem.</p>\n<p>It is also worth noting that setting a TTL value to a key costs memory, so using a policy like <strong>allkeys-lru</strong> is more memory efficient since there is no need for a TTL configuration for the key to be evicted under memory pressure.</p>\n<h2>How the eviction process works</h2>\n<p>It is important to understand that the eviction process works like this:</p>\n<ul>\n<li>A client runs a new command, resulting in more data added.</li>\n<li>Valkey checks the memory usage, and if it is greater than the <code>maxmemory</code> limit , it evicts keys according to the policy.</li>\n<li>A new command is executed, and so forth.</li>\n</ul>\n<p>So we continuously cross the boundaries of the memory limit, by going over it, and then by evicting keys to return back under the limits.</p>\n<p>If a command results in a lot of memory being used (like a big set intersection stored into a new key) for some time, the memory limit can be surpassed by a noticeable amount.</p>\n<h2>Monitor eviction</h2>\n<p>To monitor the point when Valkey starts to evict data, use the <code>INFO MEMORY</code> command. The following fields provide the information about the memory usage and the condition to trigger key eviction:</p>\n<ul>\n<li><code>used_memory</code>: The total number of bytes that the server allocated for storing data. It is the sum of the <code>used_memory_overhead</code> and the <code>used_memory_dataset</code> outputs.</li>\n<li><code>mem_not_counted_for_evict</code>: The amount of memory not counted for eviction. This includes the replication buffer and AOF buffer.</li>\n</ul>\n<p>Thus, the memory usage to trigger eviction is calculated as follows:</p>\n<pre><code>used_memory - mem_not_counted_for_evict &gt; maxmemory\n</code></pre>\n<p>Let&#39;s see how this works in practice. </p>\n<p>Consider the following INFO memory output:</p>\n<pre><code># Memory\nused_memory:12498952\n...\nmaxmemory:10737418240\n...\nmem_not_counted_for_evict:12336\n...\n</code></pre>\n<p>In this example, Valkey will not start data eviction because the actual memory usage is <code>12498952 - 12336 = 12486616</code> which is considerably less than <code>maxmemory</code>.</p>\n<p>The following example shows that we&#39;re nearing eviction:</p>\n<pre><code># Memory\nused_memory:12498952\n...\nmaxmemory:12500000\n...\nmem_not_counted_for_evict:12336\n</code></pre>\n<p>Once eviction happens, additional information is available through the <code>INFO STATS</code> metrics. The <code>total_eviction_exceeded_time</code> metric shows the total time in milliseconds that <code>used_memory</code> exceeded <code>maxmemory</code>.</p>\n<h2>Approximated LRU algorithm</h2>\n<p>Valkey LRU algorithm is not an exact implementation. This means that Valkey is<br>not able to pick the <em>best candidate</em> for eviction, that is, the key that<br>was accessed the furthest in the past. Instead it will try to run an approximation<br>of the LRU algorithm, by sampling a small number of keys, and evicting the<br>one that is the best (with the oldest access time) among the sampled keys, while<br>also managing a pool of good candidates for eviction.<br>This algorithm consumes less memory than an exact LRU algorithm.</p>\n<p>What is important about the Valkey LRU algorithm is that you <strong>are able to tune</strong> the precision of the algorithm by changing the number of samples to check for every eviction. This parameter is controlled by the following configuration directive:</p>\n<pre><code>maxmemory-samples 5\n</code></pre>\n<p>The reason Valkey does not use a true LRU implementation is because it<br>costs more memory. However, the approximation is virtually equivalent for an<br>application using Valkey. This figure compares<br>the LRU approximation used by Valkey with true LRU.</p>\n<p><img src=\"lru_comparison.png\" alt=\"LRU comparison\"></p>\n<p>The test to generate the above graphs filled a server with a given number of keys. The keys were accessed from the first to the last. The first keys are the best candidates for eviction using an LRU algorithm. Later more 50% of keys are added, in order to force half of the old keys to be evicted.</p>\n<p>You can see three kind of dots in the graphs, forming three distinct bands.</p>\n<ul>\n<li>The light gray band are objects that were evicted.</li>\n<li>The gray band are objects that were not evicted.</li>\n<li>The green band are objects that were added.</li>\n</ul>\n<p>In a theoretical LRU implementation we expect that, among the old keys, the first half will be evicted.<br>The Valkey LRU algorithm will instead only <em>probabilistically</em> evicts the older keys.</p>\n<p>As you can see, Redis OSS 3.0 does a reasonable job with 5 samples.<br>Using a sample size of 10, the approximation is very close to an exact LRU implementation.<br>(The LRU algorithm hasn&#39;t changed considerably since this test was performed, so the performance of Valkey is similar in this regard.)</p>\n<p>Note that LRU is just a model to predict how likely a given key will be accessed in the future. Moreover, if your data access pattern closely<br>resembles the power law; most of the accesses will be in the set of keys<br>the LRU approximated algorithm can handle well.</p>\n<p>In simulations we found that using a power law access pattern, the difference between true LRU and Valkey approximation were minimal or non-existent.</p>\n<p>However you can raise the sample size to 10 at the cost of some additional CPU<br>usage to closely approximate true LRU, and check if this makes a<br>difference in your cache misses rate.</p>\n<p>To experiment in production with different values for the sample size by using<br>the <code>CONFIG SET maxmemory-samples &lt;count&gt;</code> command, is very simple.</p>\n<h2>The LFU mode</h2>\n<p>The <a href=\"https://web.archive.org/web/20241019222228/http://antirez.com/news/109\">Least Frequently Used eviction mode</a> is available as an alternative to LRU.<br>This mode may work better (provide a better<br>hits/misses ratio) in certain cases. In LFU mode, Valkey will try to track<br>the frequency of access of items, so the ones used rarely are evicted. This means<br>the keys used often have a higher chance of remaining in memory.</p>\n<p>To configure the LFU mode, the following policies are available:</p>\n<ul>\n<li><code>volatile-lfu</code> Evict using approximated LFU among the keys with a time-to-live (TTL) set.</li>\n<li><code>allkeys-lfu</code> Evict any key using approximated LFU.</li>\n</ul>\n<p>LFU is approximated like LRU: it uses a probabilistic counter, called a <a href=\"https://en.wikipedia.org/wiki/Approximate_counting_algorithm\">Morris counter</a> to estimate the object access frequency using just a few bits per object, combined with a decay period so that the counter is reduced over time. At some point we no longer want to consider keys as frequently accessed, even if they were in the past, so that the algorithm can adapt to a shift in the access pattern.</p>\n<p>That information is sampled similarly to what happens for LRU (as explained in the previous section of this documentation) to select a candidate for eviction.</p>\n<p>However unlike LRU, LFU has certain tunable parameters: for example, how fast<br>should a frequent item lower in rank if it gets no longer accessed? It is also possible to tune the Morris counters range to better adapt the algorithm to specific use cases.</p>\n<p>By default Valkey is configured to:</p>\n<ul>\n<li>Saturate the counter at, around, one million requests.</li>\n<li>Decay the counter every one minute.</li>\n</ul>\n<p>Those should be reasonable values and were tested experimentally, but the user may want to play with these configuration settings to pick optimal values.</p>\n<p>Instructions about how to tune these parameters can be found inside the example <code>valkey.conf</code> file in the source distribution. Briefly, they are:</p>\n<pre><code>lfu-log-factor 10\nlfu-decay-time 1\n</code></pre>\n<p>The decay time is the obvious one, it is the amount of minutes a counter should be decayed, when sampled and found to be older than that value. A special value of <code>0</code> means: we will never decay the counter.</p>\n<p>The counter <em>logarithm factor</em> changes how many hits are needed to saturate the frequency counter, which is just in the range 0-255. The higher the factor, the more accesses are needed to reach the maximum. The lower the factor, the better is the resolution of the counter for low accesses, according to the following table:</p>\n<pre><code>+--------+------------+------------+------------+------------+------------+\n| factor | 100 hits   | 1000 hits  | 100K hits  | 1M hits    | 10M hits   |\n+--------+------------+------------+------------+------------+------------+\n| 0      | 104        | 255        | 255        | 255        | 255        |\n+--------+------------+------------+------------+------------+------------+\n| 1      | 18         | 49         | 255        | 255        | 255        |\n+--------+------------+------------+------------+------------+------------+\n| 10     | 10         | 18         | 142        | 255        | 255        |\n+--------+------------+------------+------------+------------+------------+\n| 100    | 8          | 11         | 49         | 143        | 255        |\n+--------+------------+------------+------------+------------+------------+\n</code></pre>\n<p>So basically the factor is a trade off between better distinguishing items with low accesses VS distinguishing items with high accesses. More information is available in the example <code>valkey.conf</code> file.</p>\n"
  },
  {
    "id": "lua-api",
    "topicName": "Lua API reference",
    "description": "Executing Lua in Valkey\n",
    "htmlContent": "<p>Valkey includes an embedded <a href=\"https://www.lua.org/\">Lua 5.1</a> interpreter.<br>The interpreter runs user-defined <a href=\"eval-intro\">ephemeral scripts</a> and <a href=\"functions-intro\">functions</a>. Scripts run in a sandboxed context and can only access specific Lua packages. This page describes the packages and APIs available inside the execution&#39;s context.</p>\n<h2>Sandbox context</h2>\n<p>The sandboxed Lua context attempts to prevent accidental misuse and reduce potential threats from the server&#39;s environment.</p>\n<p>Scripts should never try to access the Valkey server&#39;s underlying host systems.<br>That includes the file system, network, and any other attempt to perform a system call other than those supported by the API.</p>\n<p>Scripts should operate solely on data stored in Valkey and data provided as arguments to their execution.</p>\n<h3>Global variables and functions</h3>\n<p>The sandboxed Lua execution context blocks the declaration of global variables and functions.<br>The blocking of global variables is in place to ensure that scripts and functions don&#39;t attempt to maintain any runtime context other than the data stored in Valkey.<br>In the (somewhat uncommon) use case that a context needs to be maintain between executions,<br>you should store the context in Valkey&#39; keyspace.</p>\n<p>Valkey will return an error when trying to execute the following snippet:</p>\n<pre><code class=\"language-lua\">my_global_variable = &#39;some value&#39;\n</code></pre>\n<p>And similarly for the following global function declaration:</p>\n<pre><code class=\"language-lua\">function my_global_function()\n  -- Do something amazing\nend\n</code></pre>\n<p>You&#39;ll also get a similar error when your script attempts to access any global variables that are undefined in the runtime&#39;s context:</p>\n<pre><code class=\"language-lua\">-- The following will surely raise an error\nreturn an_undefined_global_variable\n</code></pre>\n<p>Instead, all variable and function definitions are required to be declared as local.<br>To do so, you&#39;ll need to prepend the <a href=\"https://www.lua.org/manual/5.1/manual.html#2.4.7\"><code>local</code></a> keyword to your declarations.<br>For example, the following snippet will be considered perfectly valid by Valkey:</p>\n<pre><code class=\"language-lua\">local my_local_variable = &#39;some value&#39;\n\nlocal function my_local_function()\n  -- Do something else, but equally amazing\nend\n</code></pre>\n<p><strong>Note:</strong><br>the sandbox attempts to prevent the use of globals.<br>Using Lua&#39;s debugging functionality or other approaches such as altering the meta table used for implementing the globals&#39; protection to circumvent the sandbox isn&#39;t hard.<br>However, it is difficult to circumvent the protection by accident.<br>If the user messes with the Lua global state, the consistency of AOF and replication can&#39;t be guaranteed.<br>In other words, just don&#39;t do it.</p>\n<h3>Imported Lua modules</h3>\n<p>Using imported Lua modules is not supported inside the sandboxed execution context.<br>The sandboxed execution context prevents the loading modules by disabling Lua&#39;s <a href=\"https://www.lua.org/pil/8.1.html\"><code>require</code> function</a>.</p>\n<p>The only libraries that Valkey ships with and that you can use in scripts are listed under the <a href=\"#runtime-libraries\">Runtime libraries</a> section.</p>\n<h2>Runtime globals</h2>\n<p>While the sandbox prevents users from declaring globals, the execution context is pre-populated with several of these.</p>\n<p>For some of them, a &quot;since version&quot; is specified.<br>The ones without &quot;since version&quot; specified are available in all maintained versions.</p>\n<h3><a name=\"the-keys-global-variable\"></a>The <code>KEYS</code> global variable</h3>\n<ul>\n<li>Available in scripts: yes</li>\n<li>Available in functions: no</li>\n</ul>\n<p><strong>Important:</strong><br>to ensure the correct execution of scripts, both in standalone and clustered deployments, all names of keys that a function accesses must be explicitly provided as input key arguments.<br>The script <strong>should only</strong> access keys whose names are given as input arguments.<br>Scripts <strong>should never</strong> access keys with programmatically-generated names or based on the contents of data structures stored in the database.</p>\n<p>The <code>KEYS</code> global variable is available only for <a href=\"eval-intro\">ephemeral scripts</a>.<br>It is pre-populated with all key name input arguments.</p>\n<h3><a name=\"the-argv-global-variable\"></a>The <code>ARGV</code> global variable</h3>\n<ul>\n<li>Available in scripts: yes</li>\n<li>Available in functions: no</li>\n</ul>\n<p>The <code>ARGV</code> global variable is available only in <a href=\"eval-intro\">ephemeral scripts</a>.<br>It is pre-populated with all regular input arguments.</p>\n<h3>The <code>server</code> singleton</h3>\n<ul>\n<li>Since version: 7.2.5</li>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>The <code>server</code> singleton is an object instance that&#39;s accessible from all scripts.<br>It provides the API to interact with Valkey from scripts.<br>Following is the API provided by the <code>server</code> object instance.</p>\n<p><strong>Note:</strong><br>For compatibility with Redis, Valkey also exposes a <code>redis</code> top-level object, that exposes the exact same set of APIs as the <code>server</code> object.<br>Valkey does not intend to drop compatibility for this <code>redis</code> API, but it is recommended to use the <code>server</code> object for newly developed scripts.</p>\n<h2><a name=\"server_object\"></a> <code>server</code> object fields (functions and variables)</h2>\n<h3><a name=\"server.call\"></a> <code>server.call(command [,arg...])</code></h3>\n<ul>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>The <code>server.call()</code> function calls a given Valkey command and returns its reply.<br>Its inputs are the command and arguments, and once called, it executes the command in Valkey and returns the reply.</p>\n<p>For example, we can call the <code>ECHO</code> command from a script and return its reply like so:</p>\n<pre><code class=\"language-lua\">return server.call(&#39;ECHO&#39;, &#39;Echo, echo... eco... o...&#39;)\n</code></pre>\n<p>If and when <code>server.call()</code> triggers a runtime exception, the raw exception is raised back to the user as an error, automatically.<br>Therefore, attempting to execute the following ephemeral script will fail and generate a runtime exception because <code>ECHO</code> accepts exactly one argument:</p>\n<pre><code class=\"language-lua\">127.0.0.1:6379&gt; EVAL &quot;return server.call(&#39;ECHO&#39;, &#39;Echo,&#39;, &#39;echo... &#39;, &#39;eco... &#39;, &#39;o...&#39;)&quot; 0\n(error) ERR Wrong number of args calling Valkey command from script script: b0345693f4b77517a711221050e76d24ae60b7f7, on @user_script:1.\n</code></pre>\n<p>Note that the call can fail due to various reasons, see <a href=\"eval-intro#execution-under-low-memory-conditions\">Execution under low memory conditions</a> and <a href=\"#script_flags\">Script flags</a></p>\n<p>To handle Valkey runtime errors use <code>server.pcall()</code> instead.</p>\n<h3><a name=\"server.pcall\"></a> <code>server.pcall(command [,arg...])</code></h3>\n<ul>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>This function enables handling runtime errors raised by the Valkey server.<br>The <code>server.pcall()</code> function  behaves exactly like <a href=\"#server.call\"><code>server.call()</code></a>, except that it:</p>\n<ul>\n<li>Always returns a reply.</li>\n<li>Never throws a runtime exception, and returns in its stead a <a href=\"#server.error_reply\"><code>server.error_reply</code></a> in case that a runtime exception is thrown by the server.</li>\n</ul>\n<p>The following demonstrates how to use <code>server.pcall()</code> to intercept and handle runtime exceptions from within the context of an ephemeral script.</p>\n<pre><code class=\"language-lua\">local reply = server.pcall(&#39;ECHO&#39;, unpack(ARGV))\nif reply[&#39;err&#39;] ~= nil then\n  -- Handle the error sometime, but for now just log it\n  server.log(server.LOG_WARNING, reply[&#39;err&#39;])\n  reply[&#39;err&#39;] = &#39;ERR Something is wrong, but no worries, everything is under control&#39;\nend\nreturn reply\n</code></pre>\n<p>Evaluating this script with more than one argument will return:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &quot;...&quot; 0 hello world\n(error) ERR Something is wrong, but no worries, everything is under control\n</code></pre>\n<h3><a name=\"server.error_reply\"></a> <code>server.error_reply(x)</code></h3>\n<ul>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>This is a helper function that returns an <a href=\"protocol#simply-errors\">error reply</a>.<br>The helper accepts a single string argument and returns a Lua table with the <code>err</code> field set to that string.</p>\n<p>The outcome of the following code is that <code>error1</code> and <code>error2</code> are identical for all intents and purposes:</p>\n<pre><code class=\"language-lua\">local text = &#39;ERR My very special error&#39;\nlocal reply1 = { err = text }\nlocal reply2 = server.error_reply(text)\n</code></pre>\n<p>Therefore, both forms are valid as means for returning an error reply from scripts:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &quot;return { err = &#39;ERR My very special table error&#39; }&quot; 0\n(error) ERR My very special table error\n127.0.0.1:6379&gt; EVAL &quot;return server.error_reply(&#39;ERR My very special reply error&#39;)&quot; 0\n(error) ERR My very special reply error\n</code></pre>\n<p>For returning Valkey status replies refer to <a href=\"#server.status_reply\"><code>server.status_reply()</code></a>.<br>Refer to the <a href=\"#data-type-conversion\">Data type conversion</a> for returning other response types.</p>\n<p><strong>Note:</strong><br>By convention, Valkey uses the first word of an error string as a unique error code for specific errors or <code>ERR</code> for general-purpose errors.<br>Scripts are advised to follow this convention, as shown in the example above, but this is not mandatory.</p>\n<h3><a name=\"server.status_reply\"></a> <code>server.status_reply(x)</code></h3>\n<ul>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>This is a helper function that returns a <a href=\"protocol#simple-strings\">simple string reply</a>.<br>&quot;OK&quot; is an example of a standard Valkey status reply.<br>The Lua API represents status replies as tables with a single field, <code>ok</code>, set with a simple status string.</p>\n<p>The outcome of the following code is that <code>status1</code> and <code>status2</code> are identical for all intents and purposes:</p>\n<pre><code class=\"language-lua\">local text = &#39;Frosty&#39;\nlocal status1 = { ok = text }\nlocal status2 = server.status_reply(text)\n</code></pre>\n<p>Therefore, both forms are valid as means for returning status replies from scripts:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &quot;return { ok = &#39;TICK&#39; }&quot; 0\nTICK\n127.0.0.1:6379&gt; EVAL &quot;return server.status_reply(&#39;TOCK&#39;)&quot; 0\nTOCK\n</code></pre>\n<p>For returning Valkey error replies refer to <a href=\"#server.error_reply\"><code>server.error_reply()</code></a>.<br>Refer to the <a href=\"#data-type-conversion\">Data type conversion</a> for returning other response types.</p>\n<h3><a name=\"server.sha1hex\"></a> <code>server.sha1hex(x)</code></h3>\n<ul>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>This function returns the SHA1 hexadecimal digest of its single string argument.</p>\n<p>You can, for example, obtain the empty string&#39;s SHA1 digest:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &quot;return server.sha1hex(&#39;&#39;)&quot; 0\n&quot;da39a3ee5e6b4b0d3255bfef95601890afd80709&quot;\n</code></pre>\n<h3><a name=\"server.log\"></a> <code>server.log(level, message)</code></h3>\n<ul>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>This function writes to the Valkey server log.</p>\n<p>It expects two input arguments: the log level and a message.<br>The message is a string to write to the log file.<br>Log level can be on of these:</p>\n<ul>\n<li><code>server.LOG_DEBUG</code></li>\n<li><code>server.LOG_VERBOSE</code></li>\n<li><code>server.LOG_NOTICE</code></li>\n<li><code>server.LOG_WARNING</code></li>\n</ul>\n<p>These levels map to the server&#39;s log levels.<br>The log only records messages equal or greater in level than the server&#39;s <code>loglevel</code> configuration directive.</p>\n<p>The following snippet:</p>\n<pre><code class=\"language-lua\">server.log(server.LOG_WARNING, &#39;Something is terribly wrong&#39;)\n</code></pre>\n<p>will produce a line similar to the following in your server&#39;s log:</p>\n<pre><code>[32343] 22 Mar 15:21:39 # Something is terribly wrong\n</code></pre>\n<h3><a name=\"server.setresp\"></a> <code>server.setresp(x)</code></h3>\n<ul>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>This function allows the executing script to switch between <a href=\"protocol\">RESP</a> protocol versions for the replies returned by <a href=\"#server.call\"><code>server.call()</code></a> and <a href=\"#server.pcall\"><code>server.pcall()</code></a>.<br>It expects a single numerical argument as the protocol&#39;s version.<br>The default protocol version is <em>2</em>, but it can be switched to version <em>3</em>.</p>\n<p>Here&#39;s an example of switching to RESP3 replies:</p>\n<pre><code class=\"language-lua\">server.setresp(3)\n</code></pre>\n<p>Please refer to the <a href=\"#data-type-conversion\">Data type conversion</a> for more information about type conversions.</p>\n<h3><a name=\"server.set_repl\"></a> <code>server.set_repl(x)</code></h3>\n<ul>\n<li>Available in scripts: yes</li>\n<li>Available in functions: no</li>\n</ul>\n<p><strong>Note:</strong><br>Prior to Redis OSS 7.0, scripts were replicated verbatim by default.<br>Since Redis OSS 7.0 (and Valkey), script effects replication is the only replication mode available.</p>\n<p>The <code>server.set_repl()</code> function instructs the server how to treat subsequent write commands in terms of replication.<br>It accepts a single input argument that only be one of the following:</p>\n<ul>\n<li><code>server.REPL_ALL</code>: replicates the effects to the AOF and replicas.</li>\n<li><code>server.REPL_AOF</code>: replicates the effects to the AOF alone.</li>\n<li><code>server.REPL_REPLICA</code>: replicates the effects to the replicas alone.</li>\n<li><code>server.REPL_SLAVE</code>: same as <code>REPL_REPLICA</code>, maintained for backward compatibility.</li>\n<li><code>server.REPL_NONE</code>: disables effect replication entirely.</li>\n</ul>\n<p>By default, the scripting engine is initialized to the <code>server.REPL_ALL</code> setting when a script begins its execution.<br>You can call the <code>server.set_repl()</code> function at any time during the script&#39;s execution to switch between the different replication modes.</p>\n<p>A simple example follows:</p>\n<pre><code class=\"language-lua\">server.replicate_commands() -- Enable effects replication in versions lower than Redis OSS v7.0\nserver.call(&#39;SET&#39;, KEYS[1], ARGV[1])\nserver.set_repl(server.REPL_NONE)\nserver.call(&#39;SET&#39;, KEYS[2], ARGV[2])\nserver.set_repl(server.REPL_ALL)\nserver.call(&#39;SET&#39;, KEYS[3], ARGV[3])\n</code></pre>\n<p>If you run this script by calling <code>EVAL &quot;...&quot; 3 A B C 1 2 3</code>, the result will be that only the keys <em>A</em> and <em>C</em> are created on the replicas and AOF.</p>\n<h3><a name=\"server.replicate_commands\"></a> <code>server.replicate_commands()</code></h3>\n<ul>\n<li>Until version: 7.0.0</li>\n<li>Available in scripts: yes</li>\n<li>Available in functions: no</li>\n</ul>\n<p>This function switches the script&#39;s replication mode from verbatim replication to effects replication.<br>You can use it to override the default verbatim script replication mode used by Redis OSS until version 7.0.</p>\n<p><strong>Note:</strong><br>Verbatim script replication is no longer supported.<br>The only script replication mode supported is script effects&#39; replication.<br>For more information, please refer to <a href=\"eval-intro#replicating-commands-instead-of-scripts\"><code>Replicating commands instead of scripts</code></a></p>\n<h3><a name=\"server.breakpoint\"></a>  <code>server.breakpoint()</code></h3>\n<ul>\n<li>Available in scripts: yes</li>\n<li>Available in functions: no</li>\n</ul>\n<p>This function triggers a breakpoint when using the <a href=\"ldb\">Valkey Lua debugger</a>.</p>\n<h3><a name=\"server.debug\"></a> <code>server.debug(x)</code></h3>\n<ul>\n<li>Available in scripts: yes</li>\n<li>Available in functions: no</li>\n</ul>\n<p>This function prints its argument in the <a href=\"ldb\">Valkey Lua debugger</a> console.</p>\n<h3><a name=\"server.acl_check_cmd\"></a> <code>server.acl_check_cmd(command [,arg...])</code></h3>\n<ul>\n<li>Since version: 7.0.0</li>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>This function is used for checking if the current user running the script has <a href=\"acl\">ACL</a> permissions to execute the given command with the given arguments.</p>\n<p>The return value is a boolean <code>true</code> in case the current user has permissions to execute the command (via a call to <a href=\"#server.call\">server.call</a> or <a href=\"#server.pcall\">server.pcall</a>) or <code>false</code> in case they don&#39;t.</p>\n<p>The function will raise an error if the passed command or its arguments are invalid.</p>\n<h3><a name=\"server.register_function\"></a> <code>server.register_function</code></h3>\n<ul>\n<li>Since version: 7.0.0</li>\n<li>Available in scripts: no</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>This function is only available from the context of the <code>FUNCTION LOAD</code> command.<br>When called, it registers a function to the loaded library.<br>The function can be called either with positional or named arguments.</p>\n<h4><a name=\"server.register_function_pos_args\"></a> positional arguments: <code>server.register_function(name, callback)</code></h4>\n<p>The first argument to <code>server.register_function</code> is a Lua string representing the function name.<br>The second argument to <code>server.register_function</code> is a Lua function.</p>\n<p>Usage example:</p>\n<pre><code>127.0.0.1:6379&gt; FUNCTION LOAD &quot;#!lua name=mylib\\n server.register_function(&#39;noop&#39;, function() end)&quot;\n</code></pre>\n<h4><a name=\"server.register_function_named_args\"></a> Named arguments:  <code>server.register_function{function_name=name, callback=callback, flags={flag1, flag2, ..}, description=description}</code></h4>\n<p>The named arguments variant accepts the following arguments:</p>\n<ul>\n<li><em>function_name</em>: the function&#39;s name.</li>\n<li><em>callback</em>: the function&#39;s callback.</li>\n<li><em>flags</em>: an array of strings, each a function flag (optional).</li>\n<li><em>description</em>: function&#39;s description (optional).</li>\n</ul>\n<p>Both <em>function_name</em> and <em>callback</em> are mandatory.</p>\n<p>Usage example:</p>\n<pre><code>127.0.0.1:6379&gt; FUNCTION LOAD &quot;#!lua name=mylib\\n server.register_function{function_name=&#39;noop&#39;, callback=function() end, flags={ &#39;no-writes&#39; }, description=&#39;Does nothing&#39;}&quot;\n</code></pre>\n<h4><a name=\"script_flags\"></a> Script flags</h4>\n<p><strong>Important:</strong><br>Use script flags with care, which may negatively impact if misused.<br>Note that the default for Eval scripts are different than the default for functions that are mentioned below, see <a href=\"eval-intro#eval-flags\">Eval Flags</a></p>\n<p>When you register a function or load an Eval script, the server does not know how it accesses the database.<br>By default, Valkey assumes that all scripts read and write data.<br>This results in the following behavior:</p>\n<ol>\n<li>They can read and write data.</li>\n<li>They can run in cluster mode, and are not able to run commands accessing keys of different hash slots.</li>\n<li>Execution against a stale replica is denied to avoid inconsistent reads.</li>\n<li>Execution under low memory is denied to avoid exceeding the configured threshold.</li>\n</ol>\n<p>You can use the following flags and instruct the server to treat the scripts&#39; execution differently:</p>\n<ul>\n<li><p><code>no-writes</code>: this flag indicates that the script only reads data but never writes.</p>\n<p>  By default, Valkey will deny the execution of flagged scripts (Functions and Eval scripts with <a href=\"eval-intro#eval-flags\">shebang</a>) against read-only replicas, as they may attempt to perform writes.<br>  Similarly, the server will not allow calling scripts with <code>FCALL_RO</code> / <code>EVAL_RO</code>.<br>  Lastly, when data persistence is at risk due to a disk error, execution is blocked as well.</p>\n<p>  Using this flag allows executing the script:</p>\n<ol>\n<li>With <code>FCALL_RO</code> / <code>EVAL_RO</code></li>\n<li>On read-only replicas.</li>\n<li>Even if there&#39;s a disk error (Valkey is unable to persist so it rejects writes).</li>\n<li>When over the memory limit since it implies the script doesn&#39;t increase memory consumption (see <code>allow-oom</code> below)</li>\n</ol>\n<p>  However, note that the server will return an error if the script attempts to call a write command.<br>  Also note that currently <code>PUBLISH</code>, <code>SPUBLISH</code> and <code>PFCOUNT</code> are also considered write commands in scripts, because they could attempt to propagate commands to replicas and AOF file.</p>\n<p>  For more information please refer to <a href=\"programmability#read-only_scripts\">Read-only scripts</a></p>\n</li>\n<li><p><code>allow-oom</code>: use this flag to allow a script to execute when the server is out of memory (OOM).</p>\n<p>  Unless used, Valkey will deny the execution of flagged scripts (Functions and Eval scripts with <a href=\"eval-intro#eval-flags\">shebang</a>) when in an OOM state.<br>  Furthermore, when you use this flag, the script can call any Valkey command, including commands that aren&#39;t usually allowed in this state.<br>  Specifying <code>no-writes</code> or using <code>FCALL_RO</code> / <code>EVAL_RO</code> also implies the script can run in OOM state (without specifying <code>allow-oom</code>)</p>\n</li>\n<li><p><code>allow-stale</code>: a flag that enables running the flagged scripts (Functions and Eval scripts with <a href=\"eval-intro#eval-flags\">shebang</a>) against a stale replica when the <code>replica-serve-stale-data</code> config is set to <code>no</code> .</p>\n<p>  Valkey can be set to prevent data consistency problems from using old data by having stale replicas return a runtime error.<br>  For scripts that do not access the data, this flag can be set to allow stale Valkey replicas to run the script.<br>  Note however that the script will still be unable to execute any command that accesses stale data.</p>\n</li>\n<li><p><code>no-cluster</code>: the flag causes the script to return an error in Valkey cluster mode.</p>\n<p>  Valkey allows scripts to be executed both in standalone and cluster modes.<br>  Setting this flag prevents executing the script against nodes in the cluster.</p>\n</li>\n<li><p><code>allow-cross-slot-keys</code>: The flag that allows a script to access keys from multiple slots.</p>\n<p>  Valkey typically prevents any single command from accessing keys that hash to multiple slots.<br>  This flag allows scripts to break this rule and access keys within the script that access multiple slots.<br>  Declared keys to the script are still always required to hash to a single slot.<br>  Accessing keys from multiple slots is discouraged as applications should be designed to only access keys from a single slot at a time, allowing slots to move between Valkey servers.</p>\n<p>  This flag has no effect when cluster mode is disabled.</p>\n</li>\n</ul>\n<p>Please refer to <a href=\"functions-intro#function-flags\">Function Flags</a> and <a href=\"eval-intro#eval-flags\">Eval Flags</a> for a detailed example.</p>\n<h3><a name=\"server.server_version\"></a> <code>server.SERVER_VERSION</code></h3>\n<ul>\n<li>Since version: 7.2.5</li>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>Returns the current Valkey server version as a Lua string.<br>The reply&#39;s format is <code>MM.mm.PP</code>, where:</p>\n<ul>\n<li><strong>MM:</strong> is the major version.</li>\n<li><strong>mm:</strong> is the minor version.</li>\n<li><strong>PP:</strong> is the patch level.</li>\n</ul>\n<h3><a name=\"server.redis_version\"></a> <code>server.REDIS_VERSION</code></h3>\n<ul>\n<li>Since version: 7.0.0</li>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>Returns the current Redis compatibility version as a Lua string.<br>The reply&#39;s format is <code>MM.mm.PP</code>, where:</p>\n<ul>\n<li><strong>MM:</strong> is the major version.</li>\n<li><strong>mm:</strong> is the minor version.</li>\n<li><strong>PP:</strong> is the patch level.</li>\n</ul>\n<h3><a name=\"server.redis_version_num\"></a> <code>server.SERVER_VERSION_NUM</code></h3>\n<ul>\n<li>Since version: 7.2.5</li>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>Returns the current Valkey server version as a number.<br>The reply is a hexadecimal value structured as <code>0x00MMmmPP</code>, where:</p>\n<ul>\n<li><strong>MM:</strong> is the major version.</li>\n<li><strong>mm:</strong> is the minor version.</li>\n<li><strong>PP:</strong> is the patch level.</li>\n</ul>\n<h3><a name=\"server.redis_version_num\"></a> <code>server.REDIS_VERSION_NUM</code></h3>\n<ul>\n<li>Since version: 7.0.0</li>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>Returns the current Redis compatibility version as a number.<br>The reply is a hexadecimal value structured as <code>0x00MMmmPP</code>, where:</p>\n<ul>\n<li><strong>MM:</strong> is the major version.</li>\n<li><strong>mm:</strong> is the minor version.</li>\n<li><strong>PP:</strong> is the patch level.</li>\n</ul>\n<h2>Data type conversion</h2>\n<p>Unless a runtime exception is raised, <code>server.call()</code> and <code>server.pcall()</code> return the reply from the executed command to the Lua script.<br>Valkey&#39;s replies from these functions are converted automatically into Lua&#39;s native data types.</p>\n<p>Similarly, when a Lua script returns a reply with the <code>return</code> keyword,<br>that reply is automatically converted to RESP protocol.</p>\n<p>Put differently: There&#39;s a one-to-one mapping between Valkey&#39;s replies and Lua&#39;s data types and a one-to-one mapping between Lua&#39;s data types and the <a href=\"protocol\">RESP Protocol</a> data types.<br>The underlying design is such that if a RESP type is converted into a Lua type and converted back into a RESP type, the result is the same as the initial value.</p>\n<p>Type conversion from Valkey replies (i.e. the replies from <code>server.call()</code> and <code>server.pcall()</code>) to Lua data types depends on the RESP protocol version used by the script.<br>The default protocol version during script executions is RESP2.<br>The script may switch the replies&#39; protocol versions by calling the <code>server.setresp()</code> function.</p>\n<p>Type conversion from a script&#39;s returned Lua data type depends on the user&#39;s choice of protocol (see the <code>HELLO</code> command).</p>\n<p>The following sections describe the type conversion rules between Lua and Valkey per the protocol&#39;s version.</p>\n<h3>RESP2 to Lua type conversion</h3>\n<p>The following type conversion rules apply to the execution&#39;s context by default as well as after calling <code>server.setresp(2)</code>:</p>\n<ul>\n<li><a href=\"protocol#integers\">RESP2 integer reply</a> -&gt; Lua number</li>\n<li><a href=\"protocol#bulk-strings\">RESP2 bulk string reply</a> -&gt; Lua string</li>\n<li><a href=\"protocol#arrays\">RESP2 array reply</a> -&gt; Lua table (may have other Valkey data types nested)</li>\n<li><a href=\"protocol#simple-strings\">RESP2 status reply</a> -&gt; Lua table with a single <em>ok</em> field containing the status string</li>\n<li><a href=\"protocol#simple-errors\">RESP2 error reply</a> -&gt; Lua table with a single <em>err</em> field containing the error string</li>\n<li><a href=\"protocol#nulls\">RESP2 null bulk reply and null multi bulk reply</a> -&gt; Lua false boolean type</li>\n</ul>\n<h2>Lua to RESP2 type conversion</h2>\n<p>The following type conversion rules apply by default as well as after the user had called <code>HELLO 2</code>:</p>\n<ul>\n<li>Lua number -&gt; <a href=\"protocol#integers\">RESP2 integer reply</a> (the number is converted into an integer)</li>\n<li>Lua string -&gt; <a href=\"protocol#bulk-strings\">RESP bulk string reply</a></li>\n<li>Lua table (indexed, non-associative array) -&gt; <a href=\"protocol#arrays\">RESP2 array reply</a> (truncated at the first Lua <code>nil</code> value encountered in the table, if any)</li>\n<li>Lua table with a single <em>ok</em> field -&gt; <a href=\"protocol#simple-strings\">RESP2 status reply</a></li>\n<li>Lua table with a single <em>err</em> field -&gt; <a href=\"protocol#simple-errors\">RESP2 error reply</a></li>\n<li>Lua boolean false -&gt; <a href=\"protocol#nulls\">RESP2 null bulk reply</a></li>\n</ul>\n<p>There is an additional Lua-to-Valkey conversion rule that has no corresponding Valkey-to-Lua conversion rule:</p>\n<ul>\n<li>Lua Boolean <code>true</code> -&gt; <a href=\"protocol#integers\">RESP2 integer reply</a> with value of 1.</li>\n</ul>\n<p>There are three additional rules to note about converting Lua to Valkey data types:</p>\n<ul>\n<li>Lua has a single numerical type, Lua numbers.<br>There is no distinction between integers and floats.<br>So we always convert Lua numbers into integer replies, removing the decimal part of the number, if any.<br><strong>If you want to return a Lua float, it should be returned as a string</strong>,<br>exactly like Valkey itself does (see, for instance, the <code>ZSCORE</code> command).</li>\n<li>There&#39;s <a href=\"https://www.lua.org/pil/19.1.html\">no simple way to have nils inside Lua arrays</a> due<br>to Lua&#39;s table semantics.<br>Therefore, when Valkey converts a Lua array to RESP, the conversion stops when it encounters a Lua <code>nil</code> value.</li>\n<li>When a Lua table is an associative array that contains keys and their respective values, the converted Valkey reply will <strong>not</strong> include them.</li>\n</ul>\n<p>Lua to RESP2 type conversion examples:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &quot;return 10&quot; 0\n(integer) 10\n\n127.0.0.1:6379&gt; EVAL &quot;return { 1, 2, { 3, &#39;Hello World!&#39; } }&quot; 0\n1) (integer) 1\n2) (integer) 2\n3) 1) (integer) 3\n   1) &quot;Hello World!&quot;\n\n127.0.0.1:6379&gt; EVAL &quot;return server.call(&#39;get&#39;,&#39;foo&#39;)&quot; 0\n&quot;bar&quot;\n</code></pre>\n<p>The last example demonstrates receiving and returning the exact return value of <code>server.call()</code> (or <code>server.pcall()</code>) in Lua as it would be returned if the command had been called directly.</p>\n<p>The following example shows how floats and arrays that cont nils and keys are handled:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &quot;return { 1, 2, 3.3333, somekey = &#39;somevalue&#39;, &#39;foo&#39;, nil , &#39;bar&#39; }&quot; 0\n1) (integer) 1\n2) (integer) 2\n3) (integer) 3\n4) &quot;foo&quot;\n</code></pre>\n<p>As you can see, the float value of <em>3.333</em> gets converted to an integer <em>3</em>, the <em>somekey</em> key and its value are omitted, and the string &quot;bar&quot; isn&#39;t returned as there is a <code>nil</code> value that precedes it.</p>\n<h3>RESP3 to Lua type conversion</h3>\n<p>RESP3 is a newer version of the <a href=\"protocol\">protocol</a> used by Valkey.<br>It is available as an opt-in choice.</p>\n<p>An executing script may call the <a href=\"#server.setresp\"><code>server.setresp</code></a> function during its execution and switch the protocol version that&#39;s used for returning replies from Valkey&#39;s commands (that can be invoked via <a href=\"#server.call\"><code>server.call()</code></a> or <a href=\"#server.pcall\"><code>server.pcall()</code></a>).</p>\n<p>Once Valkey&#39;s replies are in RESP3 protocol, all of the <a href=\"#resp2-to-lua-type-conversion\">RESP2 to Lua conversion</a> rules apply, with the following additions:</p>\n<ul>\n<li><a href=\"protocol#maps\">Map reply</a> -&gt; Lua table with a single <em>map</em> field containing a Lua table representing the fields and values of the map.</li>\n<li><a href=\"protocol#sets\">Set reply</a> -&gt; Lua table with a single <em>set</em> field containing a Lua table representing the elements of the set as fields, each with the Lua Boolean value of <code>true</code>.</li>\n<li><a href=\"protocol#nulls\">Null</a> -&gt; Lua <code>nil</code>.</li>\n<li><a href=\"protocol#booleans\">True reply</a> -&gt; Lua true boolean value.</li>\n<li><a href=\"protocol#booleans\">False reply</a> -&gt; Lua false boolean value.</li>\n<li><a href=\"protocol#doubles\">Double reply</a> -&gt; Lua table with a single <code>double</code> field containing a Lua number representing the double value.</li>\n<li><a href=\"protocol#big-numbers\">Big number reply</a> -&gt; Lua table with a single <code>big_number</code> field containing a Lua string representing the big number value (since Redis OSS 7.0).</li>\n<li><a href=\"protocol#verbatim-strings\">Verbatim string reply</a> -&gt; Lua table with a single <code>verbatim_string</code> field containing a Lua table with two fields, <code>string</code> and <code>format</code>, representing the verbatim string and its format, respectively (since Redis OSS 7.0).</li>\n</ul>\n<h3>Lua to RESP3 type conversion</h3>\n<p>Regardless of the script&#39;s choice of protocol version set for replies with the [<code>server.setresp()</code> function] when it calls <code>server.call()</code> or <code>server.pcall()</code>, the user may opt-in to using RESP3 (with the <code>HELLO 3</code> command) for the connection.<br>Although the default protocol for incoming client connections is RESP2, the script should honor the user&#39;s preference and return adequately-typed RESP3 replies, so the following rules apply on top of those specified in the <a href=\"#lua-to-resp2-type-conversion\">Lua to RESP2 type conversion</a> section when that is the case.</p>\n<ul>\n<li>Lua Boolean -&gt; <a href=\"protocol#booleans\">RESP3 Boolean reply</a> (note that this is a change compared to the RESP2, in which returning a Boolean Lua <code>true</code> returned the number 1 to the Valkey client, and returning a <code>false</code> used to return a <code>null</code>.</li>\n<li>Lua table with a single <code>map</code> field set to an associative Lua table -&gt; <a href=\"protocol#maps\">RESP3 map reply</a>.</li>\n<li>Lua table with a single <code>set</code> field set to an associative Lua table -&gt; <a href=\"protocol#sets\">RESP3 set reply</a>. Values can be set to anything and are discarded anyway.</li>\n<li>Lua table with a single <code>double</code> field to an associative Lua table -&gt; <a href=\"protocol#doubles\">RESP3 double reply</a>.</li>\n<li>Lua nil -&gt; <a href=\"protocol#nulls\">RESP3 null</a>.</li>\n</ul>\n<p>However, if the connection is set use the RESP2 protocol, and even if the script replies with RESP3-typed responses, Valkey will automatically perform a RESP3 to RESP2 conversion of the reply as is the case for regular commands.<br>That means, for example, that returning the RESP3 map type to a RESP2 connection will result in the reply being converted to a flat RESP2 array that consists of alternating field names and their values, rather than a RESP3 map.</p>\n<h2>Additional notes about scripting</h2>\n<h3>Using <code>SELECT</code> inside scripts</h3>\n<p>You can call the <code>SELECT</code> command from your Lua scripts, like you can with any normal client connection.<br>The database selected by the Lua script only affects the execution context of the script, and does not modify the database that&#39;s selected by the client calling the script.</p>\n<h2>Runtime libraries</h2>\n<p>The Valkey Lua runtime context always comes with several pre-imported libraries.</p>\n<p>The following <a href=\"https://www.lua.org/manual/5.1/manual.html#5\">standard Lua libraries</a> are available to use:</p>\n<ul>\n<li>The <a href=\"https://www.lua.org/manual/5.1/manual.html#5.4\"><em>String Manipulation (string)</em> library</a></li>\n<li>The <a href=\"https://www.lua.org/manual/5.1/manual.html#5.5\"><em>Table Manipulation (table)</em> library</a></li>\n<li>The <a href=\"https://www.lua.org/manual/5.1/manual.html#5.6\"><em>Mathematical Functions (math)</em> library</a></li>\n<li>The <a href=\"#os-library\"><em>Operating System Facilities (os)</em> library</a></li>\n</ul>\n<p>In addition, the following external libraries are loaded and accessible to scripts:</p>\n<ul>\n<li>The <a href=\"#struct-library\"><em>struct</em> library</a></li>\n<li>The <a href=\"#cjson-library\"><em>cjson</em> library</a></li>\n<li>The <a href=\"#cmsgpack-library\"><em>cmsgpack</em> library</a></li>\n<li>The <a href=\"#bitop-library\"><em>bitop</em> library</a></li>\n</ul>\n<h3><a name=\"os-library\"></a> <em>os</em> library</h3>\n<ul>\n<li>Since version: 8.0.0</li>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p><em>os</em> provides a set of functions for dealing with date, time, and system commands.<br>More details can be found in the <a href=\"https://www.lua.org/manual/5.1/manual.html#5.8\">Operating System Facilities</a>.<br>Note that for sandbox security, currently only the following os functions is exposed:</p>\n<ul>\n<li><code>os.clock()</code></li>\n</ul>\n<h3><a name=\"struct-library\"></a> <em>struct</em> library</h3>\n<ul>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p><em>struct</em> is a library for packing and unpacking C-like structures in Lua.<br>It provides the following functions:</p>\n<ul>\n<li><a href=\"#struct.pack\"><code>struct.pack()</code></a></li>\n<li><a href=\"#struct.unpack\"><code>struct.unpack()</code></a></li>\n<li><a href=\"#struct.size\"><code>struct.size()</code></a></li>\n</ul>\n<p>All of <em>struct</em>&#39;s functions expect their first argument to be a <a href=\"#struct-formats\">format string</a>.</p>\n<h4><a name=\"struct-formats\"></a> <em>struct</em> formats</h4>\n<p>The following are valid format strings for <em>struct</em>&#39;s functions:</p>\n<ul>\n<li><code>&gt;</code>: big endian</li>\n<li><code>&lt;</code>: little endian</li>\n<li><code>![num]</code>: alignment</li>\n<li><code>x</code>: padding</li>\n<li><code>b/B</code>: signed/unsigned byte</li>\n<li><code>h/H</code>: signed/unsigned short</li>\n<li><code>l/L</code>: signed/unsigned long</li>\n<li><code>T</code>: size_t</li>\n<li><code>i/In</code>: signed/unsigned integer with size <em>n</em> (defaults to the size of int)</li>\n<li><code>cn</code>: sequence of <em>n</em> chars (from/to a string); when packing, n == 0 means the<br>whole string; when unpacking, n == 0 means use the previously read number as<br>the string&#39;s length.</li>\n<li><code>s</code>: zero-terminated string</li>\n<li><code>f</code>: float</li>\n<li><code>d</code>: double</li>\n<li><code> </code> (space): ignored</li>\n</ul>\n<h4><a name=\"struct.pack\"></a> <code>struct.pack(x)</code></h4>\n<p>This function returns a struct-encoded string from values.<br>It accepts a <a href=\"#struct-formats\"><em>struct</em> format string</a> as its first argument, followed by the values that are to be encoded.</p>\n<p>Usage example:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &quot;return struct.pack(&#39;HH&#39;, 1, 2)&quot; 0\n&quot;\\x01\\x00\\x02\\x00&quot;\n</code></pre>\n<h4><a name=\"struct.unpack\"></a> <code>struct.unpack(x)</code></h4>\n<p>This function returns the decoded values from a struct.<br>It accepts a <a href=\"#struct-formats\"><em>struct</em> format string</a> as its first argument, followed by encoded struct&#39;s string.</p>\n<p>Usage example:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &quot;return { struct.unpack(&#39;HH&#39;, ARGV[1]) }&quot; 0 &quot;\\x01\\x00\\x02\\x00&quot;\n1) (integer) 1\n2) (integer) 2\n3) (integer) 5\n</code></pre>\n<h4><a name=\"struct.size\"></a> <code>struct.size(x)</code></h4>\n<p>This function returns the size, in bytes, of a struct.<br>It accepts a <a href=\"#struct-formats\"><em>struct</em> format string</a> as its only argument.</p>\n<p>Usage example:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &quot;return struct.size(&#39;HH&#39;)&quot; 0\n(integer) 4\n</code></pre>\n<h3><a name=\"cjson-library\"></a> <em>cjson</em> library</h3>\n<ul>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>The <em>cjson</em> library provides fast <a href=\"https://json.org\">JSON</a> encoding and decoding from Lua.<br>It provides these functions.</p>\n<h4><a name=\"cjson.encode()\"></a> <code>cjson.encode(x)</code></h4>\n<p>This function returns a JSON-encoded string for the Lua data type provided as its argument.</p>\n<p>Usage example:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &quot;return cjson.encode({ [&#39;foo&#39;] = &#39;bar&#39; })&quot; 0\n&quot;{\\&quot;foo\\&quot;:\\&quot;bar\\&quot;}&quot;\n</code></pre>\n<h4><a name=\"cjson.decode()\"></a> <code>cjson.decode(x)</code></h4>\n<p>This function returns a Lua data type from the JSON-encoded string provided as its argument.</p>\n<p>Usage example:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &quot;return cjson.decode(ARGV[1])[&#39;foo&#39;]&quot; 0 &#39;{&quot;foo&quot;:&quot;bar&quot;}&#39;\n&quot;bar&quot;\n</code></pre>\n<h3><a name=\"cmsgpack-library\"></a> <em>cmsgpack</em> library</h3>\n<ul>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>The <em>cmsgpack</em> library provides fast <a href=\"https://msgpack.org/index.html\">MessagePack</a> encoding and decoding from Lua.<br>It provides these functions.</p>\n<h4><a name=\"cmsgpack.pack()\"></a> <code>cmsgpack.pack(x)</code></h4>\n<p>This function returns the packed string encoding of the Lua data type it is given as an argument.</p>\n<p>Usage example:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &quot;return cmsgpack.pack({&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;})&quot; 0\n&quot;\\x93\\xa3foo\\xa3bar\\xa3baz&quot;\n</code></pre>\n<h4><a name=\"cmsgpack.unpack()\"></a> <code>cmsgpack.unpack(x)</code></h4>\n<p>This function returns the unpacked values from decoding its input string argument.</p>\n<p>Usage example:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &quot;return cmsgpack.unpack(ARGV[1])&quot; 0 &quot;\\x93\\xa3foo\\xa3bar\\xa3baz&quot;\n1) &quot;foo&quot;\n2) &quot;bar&quot;\n3) &quot;baz&quot;\n</code></pre>\n<h3><a name=\"bitop-library\"></a> <em>bit</em> library</h3>\n<ul>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>The <em>bit</em> library provides bitwise operations on numbers.<br>Its documentation resides at <a href=\"https://bitop.luajit.org/api.html\">Lua BitOp documentation</a><br>It provides the following functions.</p>\n<h4><a name=\"bit.tobit()\"></a> <code>bit.tobit(x)</code></h4>\n<p>Normalizes a number to the numeric range for bit operations and returns it.</p>\n<p>Usage example:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &#39;return bit.tobit(1)&#39; 0\n(integer) 1\n</code></pre>\n<h4><a name=\"bit.tohex()\"></a> <code>bit.tohex(x [,n])</code></h4>\n<p>Converts its first argument to a hex string. The number of hex digits is given by the absolute value of the optional second argument.</p>\n<p>Usage example:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &#39;return bit.tohex(422342)&#39; 0\n&quot;000671c6&quot;\n</code></pre>\n<h4><a name=\"bit.bnot()\"></a> <code>bit.bnot(x)</code></h4>\n<p>Returns the bitwise <strong>not</strong> of its argument.</p>\n<h4><a name=\"bit.ops\"></a> <code>bit.bnot(x)</code> <code>bit.bor(x1 [,x2...])</code>, <code>bit.band(x1 [,x2...])</code> and <code>bit.bxor(x1 [,x2...])</code></h4>\n<p>Returns either the bitwise <strong>or</strong>, bitwise <strong>and</strong>, or bitwise <strong>xor</strong> of all of its arguments.<br>Note that more than two arguments are allowed.</p>\n<p>Usage example:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &#39;return bit.bor(1,2,4,8,16,32,64,128)&#39; 0\n(integer) 255\n</code></pre>\n<h4><a name=\"bit.shifts\"></a> <code>bit.lshift(x, n)</code>, <code>bit.rshift(x, n)</code> and <code>bit.arshift(x, n)</code></h4>\n<p>Returns either the bitwise logical <strong>left-shift</strong>, bitwise logical <strong>right-shift</strong>, or bitwise <strong>arithmetic right-shift</strong> of its first argument by the number of bits given by the second argument.</p>\n<h4><a name=\"bit.ro\"></a> <code>bit.rol(x, n)</code> and <code>bit.ror(x, n)</code></h4>\n<p>Returns either the bitwise <strong>left rotation</strong>, or bitwise <strong>right rotation</strong> of its first argument by the number of bits given by the second argument.<br>Bits shifted out on one side are shifted back in on the other side.</p>\n<h4><a name=\"bit.bswap()\"></a> <code>bit.bswap(x)</code></h4>\n<p>Swaps the bytes of its argument and returns it.<br>This can be used to convert little-endian 32-bit numbers to big-endian 32-bit numbers and vice versa.</p>\n"
  },
  {
    "id": "mass-insertion",
    "topicName": "Bulk loading",
    "description": "Writing data in bulk using the RESP protocol\n",
    "htmlContent": "<p>Bulk loading is the process of loading Valkey with a large amount of pre-existing data. Ideally, you want to perform this operation quickly and efficiently. This document describes some strategies for bulk loading data in Valkey.</p>\n<h2>Bulk loading using the RESP protocol</h2>\n<p>Using a normal Valkey client to perform bulk loading is not a good idea<br>for a few reasons: the naive approach of sending one command after the other<br>is slow because you have to pay for the round trip time for every command.<br>It is possible to use pipelining, but for bulk loading of many records<br>you need to write new commands while you read replies at the same time to<br>make sure you are inserting as fast as possible.</p>\n<p>Only a small percentage of clients support non-blocking I/O, and not all the<br>clients are able to parse the replies in an efficient way in order to maximize<br>throughput. For all of these reasons the preferred way to mass import data into<br>Valkey is to generate a text file containing the Valkey protocol, in raw format,<br>in order to call the commands needed to insert the required data.</p>\n<p>For instance if I need to generate a large data set where there are billions<br>of keys in the form: `keyN -&gt; ValueN&#39; I will create a file containing the<br>following commands in the Valkey protocol format:</p>\n<pre><code>SET Key0 Value0\nSET Key1 Value1\n...\nSET KeyN ValueN\n</code></pre>\n<p>Once this file is created, the remaining action is to feed it to Valkey<br>as fast as possible. In the past the way to do this was to use the<br><code>netcat</code> with the following command:</p>\n<pre><code>(cat data.txt; sleep 10) | nc localhost 6379 &gt; /dev/null\n</code></pre>\n<p>However this is not a very reliable way to perform mass import because netcat<br>does not really know when all the data was transferred and can&#39;t check for<br>errors. The <code>valkey-cli</code> utility<br>supports a <strong>pipe mode</strong> that was designed to perform<br>bulk loading.</p>\n<p>Using the pipe mode the command to run looks like the following:</p>\n<pre><code>cat data.txt | valkey-cli --pipe\n</code></pre>\n<p>That will produce an output similar to this:</p>\n<pre><code>All data transferred. Waiting for the last reply...\nLast reply received from server.\nerrors: 0, replies: 1000000\n</code></pre>\n<p>The valkey-cli utility will also make sure to only redirect errors received<br>from the Valkey instance to the standard output.</p>\n<h3>Generating RESP protocol</h3>\n<p>The RESP protocol is extremely simple to generate and parse, and is<br><a href=\"protocol\">Documented here</a>. However in order to generate protocol for<br>the goal of bulk loading you don&#39;t need to understand every detail of the<br>protocol, but just that every command is represented in the following way:</p>\n<pre><code>*&lt;args&gt;&lt;cr&gt;&lt;lf&gt;\n$&lt;len&gt;&lt;cr&gt;&lt;lf&gt;\n&lt;arg0&gt;&lt;cr&gt;&lt;lf&gt;\n&lt;arg1&gt;&lt;cr&gt;&lt;lf&gt;\n...\n&lt;argN&gt;&lt;cr&gt;&lt;lf&gt;\n</code></pre>\n<p>Where <code>&lt;cr&gt;</code> means &quot;\\r&quot; (or ASCII character 13) and <code>&lt;lf&gt;</code> means &quot;\\n&quot; (or ASCII character 10).</p>\n<p>For instance the command <strong>SET key value</strong> is represented by the following protocol:</p>\n<pre><code>*3&lt;cr&gt;&lt;lf&gt;\n$3&lt;cr&gt;&lt;lf&gt;\nSET&lt;cr&gt;&lt;lf&gt;\n$3&lt;cr&gt;&lt;lf&gt;\nkey&lt;cr&gt;&lt;lf&gt;\n$5&lt;cr&gt;&lt;lf&gt;\nvalue&lt;cr&gt;&lt;lf&gt;\n</code></pre>\n<p>Or represented as a quoted string:</p>\n<pre><code>&quot;*3\\r\\n$3\\r\\nSET\\r\\n$3\\r\\nkey\\r\\n$5\\r\\nvalue\\r\\n&quot;\n</code></pre>\n<p>The file you need to generate for bulk loading is just composed of commands<br>represented in the above way, one after the other.</p>\n<p>The following Ruby function generates valid protocol:</p>\n<pre><code class=\"language-ruby\">def gen_redis_proto(*cmd)\n    proto = &quot;&quot;\n    proto &lt;&lt; &quot;*&quot;+cmd.length.to_s+&quot;\\r\\n&quot;\n    cmd.each{|arg|\n        proto &lt;&lt; &quot;$&quot;+arg.to_s.bytesize.to_s+&quot;\\r\\n&quot;\n        proto &lt;&lt; arg.to_s+&quot;\\r\\n&quot;\n    }\n    proto\nend\n\nputs gen_redis_proto(&quot;SET&quot;,&quot;mykey&quot;,&quot;Hello World!&quot;).inspect\n</code></pre>\n<p>Using the above function it is possible to easily generate the key value pairs<br>in the above example, with this program:</p>\n<pre><code class=\"language-ruby\">(0...1000).each{|n|\n    STDOUT.write(gen_redis_proto(&quot;SET&quot;,&quot;Key#{n}&quot;,&quot;Value#{n}&quot;))\n}\n</code></pre>\n<p>We can run the program directly in pipe to valkey-cli in order to perform our<br>first mass import session.</p>\n<pre><code>$ ruby proto.rb | valkey-cli --pipe\nAll data transferred. Waiting for the last reply...\nLast reply received from server.\nerrors: 0, replies: 1000\n</code></pre>\n<h3>How the pipe mode works under the hood</h3>\n<p>The magic needed inside the pipe mode of valkey-cli is to be as fast as netcat<br>and still be able to understand when the last reply was sent by the server<br>at the same time.</p>\n<p>This is obtained in the following way:</p>\n<ul>\n<li>valkey-cli --pipe tries to send data as fast as possible to the server.</li>\n<li>At the same time it reads data when available, trying to parse it.</li>\n<li>Once there is no more data to read from stdin, it sends a special <strong>ECHO</strong><br>command with a random 20 byte string: we are sure this is the latest command<br>sent, and we are sure we can match the reply checking if we receive the same<br>20 bytes as a bulk reply.</li>\n<li>Once this special final command is sent, the code receiving replies starts<br>to match replies with these 20 bytes. When the matching reply is reached it<br>can exit with success.</li>\n</ul>\n<p>Using this trick we don&#39;t need to parse the protocol we send to the server<br>in order to understand how many commands we are sending, but just the replies.</p>\n<p>However while parsing the replies we take a counter of all the replies parsed<br>so that at the end we are able to tell the user the amount of commands<br>transferred to the server by the mass insert session.</p>\n"
  },
  {
    "id": "memory-optimization",
    "topicName": "Memory optimization",
    "description": "Strategies for optimizing memory usage in Valkey",
    "htmlContent": "<h2>Special encoding of small aggregate data types</h2>\n<p>Many data types are optimized to use less space up to a certain size.<br>Hashes, Lists, Sets composed of just integers, and Sorted Sets, when smaller than a given number of elements, and up to a maximum element size, are encoded in a very memory-efficient way that uses <em>up to 10 times less memory</em> (with 5 times less memory used being the average saving).</p>\n<p>This is completely transparent from the point of view of the user and API.<br>Since this is a CPU / memory tradeoff it is possible to tune the maximum<br>number of elements and maximum element size for special encoded types<br>using the following valkey.conf directives (defaults for Valkey 7.2 are shown):</p>\n<pre><code>hash-max-listpack-entries 512\nhash-max-listpack-value 64\nzset-max-listpack-entries 128\nzset-max-listpack-value 64\nset-max-intset-entries 512\nset-max-listpack-entries 128\nset-max-listpack-value 64\n</code></pre>\n<p>If a specially encoded value overflows the configured max size,<br>Valkey will automatically convert it into normal encoding.<br>This operation is very fast for small values,<br>but if you change the setting in order to use specially encoded values<br>for much larger aggregate types the suggestion is to run some<br>benchmarks and tests to check the conversion time.</p>\n<h2>Using 32-bit instances</h2>\n<p>When Valkey is compiled as a 32-bit target, it uses a lot less memory per key, since pointers are small,<br>but such an instance will be limited to 4 GB of maximum memory usage.<br>To compile Valkey as 32-bit binary use <em>make 32bit</em>.<br>RDB and AOF files are compatible between 32-bit and 64-bit instances<br>(and between little and big endian of course) so you can switch from 32 to 64-bit, or the contrary, without problems.</p>\n<h2>Bit and byte level operations</h2>\n<p>Valkey has bit and byte level operations: <code>GETRANGE</code>, <code>SETRANGE</code>, <code>GETBIT</code> and <code>SETBIT</code>.<br>Using these commands you can treat the String type as a random access array.<br>For instance, if you have an application where users are identified by a unique progressive integer number,<br>you can use a bitmap to save information about the subscription of users in a mailing list,<br>setting the bit for subscribed and clearing it for unsubscribed, or the other way around.<br>With 100 million users this data will take just 12 megabytes of RAM in a Valkey instance.<br>You can do the same using <code>GETRANGE</code> and <code>SETRANGE</code> to store one byte of information for each user.<br>This is just an example but it is possible to model several problems in very little space with these new primitives.</p>\n<h2>Use hashes when possible</h2>\n<p>Small hashes are encoded in a very small space, so you should try representing your data using hashes whenever possible.<br>For instance, if you have objects representing users in a web application,<br>instead of using different keys for name, surname, email, password, use a single hash with all the required fields.</p>\n<p>If you want to know more about this, read the next section.</p>\n<h2>Using hashes to abstract a very memory-efficient plain key-value store on top of Valkey</h2>\n<p>I understand the title of this section is a bit scary, but I&#39;m going to explain in detail what this is about.</p>\n<p>Basically it is possible to model a plain key-value store using Valkey<br>where values can just be just strings, which is not just more memory efficient<br>than Valkey plain keys but also much more memory efficient than memcached.</p>\n<p>Let&#39;s start with some facts: a few keys use a lot more memory than a single key<br>containing a hash with a few fields. How is this possible? We use a trick.<br>In theory to guarantee that we perform lookups in constant time<br>(also known as O(1) in big O notation) there is the need to use a data structure<br>with a constant time complexity in the average case, like a hash table.</p>\n<p>But many times hashes contain just a few fields. When hashes are small we can<br>instead just encode them in an O(N) data structure, like a linear<br>array with length-prefixed key-value pairs. Since we do this only when N<br>is small, the amortized time for <code>HGET</code> and <code>HSET</code> commands is still O(1): the<br>hash will be converted into a real hash table as soon as the number of elements<br>it contains grows too large (you can configure the limit in valkey.conf).</p>\n<p>This does not only work well from the point of view of time complexity, but<br>also from the point of view of constant times since a linear array of key-value pairs happens to play very well with the CPU cache (it has a better<br>cache locality than a hash table).</p>\n<p>However since hash fields and values are not (always) represented as full-featured Valkey objects, hash fields can&#39;t have an associated time to live<br>(expire) like a real key, and can only contain a string. But we are okay with<br>this, this was the intention anyway when the hash data type API was<br>designed (we trust simplicity more than features, so nested data structures<br>are not allowed, as expires of single fields are not allowed).</p>\n<p>So hashes are memory efficient. This is useful when using hashes<br>to represent objects or to model other problems when there are group of<br>related fields. But what about if we have a plain key value business?</p>\n<p>Imagine we want to use Valkey as a cache for many small objects, which can be JSON encoded objects, small HTML fragments, simple key -&gt; boolean values<br>and so forth. Basically, anything is a string -&gt; string map with small keys<br>and values.</p>\n<p>Now let&#39;s assume the objects we want to cache are numbered, like:</p>\n<ul>\n<li>object:102393</li>\n<li>object:1234</li>\n<li>object:5</li>\n</ul>\n<p>This is what we can do. Every time we perform a<br>SET operation to set a new value, we actually split the key into two parts,<br>one part used as a key, and the other part used as the field name for the hash. For instance, the<br>object named &quot;object:1234&quot; is actually split into:</p>\n<ul>\n<li>a Key named object:12</li>\n<li>a Field named 34</li>\n</ul>\n<p>So we use all the characters but the last two for the key, and the final<br>two characters for the hash field name. To set our key we use the following<br>command:</p>\n<pre><code>HSET object:12 34 somevalue\n</code></pre>\n<p>As you can see every hash will end up containing 100 fields, which is an optimal compromise between CPU and memory saved.</p>\n<p>There is another important thing to note, with this schema<br>every hash will have more or<br>less 100 fields regardless of the number of objects we cached. This is because our objects will always end with a number and not a random string. In some way, the final number can be considered as a form of implicit pre-sharding.</p>\n<p>What about small numbers? Like object:2? We handle this case using just<br>&quot;object:&quot; as a key name, and the whole number as the hash field name.<br>So object:2 and object:10 will both end inside the key &quot;object:&quot;, but one<br>as field name &quot;2&quot; and one as &quot;10&quot;.</p>\n<p>Every time a hash exceeds the number of elements or element size specified<br>it will be converted into a real hash table, and the memory saving will be lost.</p>\n<p>You may ask, why don&#39;t you do this implicitly in the normal key space so that<br>I don&#39;t have to care? There are two reasons: one is that we tend to make<br>tradeoffs explicit, and this is a clear tradeoff between many things: CPU,<br>memory, and max element size. The second is that the top-level key space must<br>support a lot of interesting things like expires, LRU data, and so<br>forth so it is not practical to do this in a general way.</p>\n<p>But the Valkey Way is that the user must understand how things work so that he can pick the best compromise and to understand how the system will<br>behave exactly.</p>\n<h2>Memory allocation</h2>\n<p>To store user keys, Valkey allocates at most as much memory as the <code>maxmemory</code><br>setting enables (however there are small extra allocations possible).</p>\n<p>The exact value can be set in the configuration file or set later via<br><code>CONFIG SET</code> (for more info, see <a href=\"lru-cache\">Using memory as an LRU cache</a>).<br>There are a few things that should be noted about how Valkey manages memory:</p>\n<ul>\n<li>Valkey will not always free up (return) memory to the OS when keys are removed.<br>This is not something special about Valkey, but it is how most malloc() implementations work.<br>For example, if you fill an instance with 5GB worth of data, and then<br>remove the equivalent of 2GB of data, the Resident Set Size (also known as<br>the RSS, which is the number of memory pages consumed by the process)<br>will probably still be around 5GB, even if Valkey will claim that the user<br>memory is around 3GB.  This happens because the underlying allocator can&#39;t easily release the memory.<br>For example, often most of the removed keys were allocated on the same pages as the other keys that still exist.</li>\n<li>The previous point means that you need to provision memory based on your<br><strong>peak memory usage</strong>. If your workload from time to time requires 10GB, even if<br>most of the time 5GB could do, you need to provision for 10GB.</li>\n<li>However allocators are smart and are able to reuse free chunks of memory,<br>so after you free 2GB of your 5GB data set, when you start adding more keys<br>again, you&#39;ll see the RSS (Resident Set Size) stay steady and not grow<br>more, as you add up to 2GB of additional keys. The allocator is basically<br>trying to reuse the 2GB of memory previously (logically) freed.</li>\n<li>Because of all this, the fragmentation ratio is not reliable when you<br>had a memory usage that at the peak is much larger than the currently used memory.<br>The fragmentation is calculated as the physical memory actually used (the RSS<br>value) divided by the amount of memory currently in use (as the sum of all<br>the allocations performed by Valkey). Because the RSS reflects the peak memory,<br>when the (virtually) used memory is low since a lot of keys/values were freed, but the RSS is high, the ratio <code>RSS / mem_used</code> will be very high.</li>\n</ul>\n<p>If <code>maxmemory</code> is not set Valkey will keep allocating memory as it sees<br>fit and thus it can (gradually) eat up all your free memory.<br>Therefore it is generally advisable to configure some limits. You may also<br>want to set <code>maxmemory-policy</code> to <code>noeviction</code> (which is <em>not</em> the default<br>value in some older versions of Valkey).</p>\n<p>It makes Valkey return an out-of-memory error for write commands if and when it reaches the<br>limit - which in turn may result in errors in the application but will not render the<br>whole machine dead because of memory starvation.</p>\n"
  },
  {
    "id": "migration",
    "topicName": "Migration from Redis to Valkey",
    "description": "How to migrate from Redis to Valkey",
    "htmlContent": "<p>This is a migration guide from Redis open source versions to Valkey.<br>You will learn how to migrate a standalone Redis server instance and a Redis Cluster. </p>\n<p>This guide provides migration steps for Redis server and Valkey deployed in Docker; however, they should also apply for other deployments.<br>Refer to <a href=\"installation\">install Valkey</a> for installation options.</p>\n<h2>Why to migrate to Valkey?</h2>\n<ul>\n<li>Valkey is the vendor-neutral and open-source software</li>\n<li>Enhanced performance with multi-threading and dual-channel replication</li>\n<li>Improved memory efficiency by using one dictionary per slot in cluster mode and embedding keys in dictionaries.</li>\n</ul>\n<h3>Migration compatibility matrix</h3>\n<p>You can migrate a Redis server to Valkey.<br>Valkey is compatible with Redis OSS 7.2 and all earlier open source Redis versions, as Valkey 7.2.4 is a fork of Redis 7.2.4.<br>Migrating from any open source Redis version to Valkey is effectively an upgrade.</p>\n<blockquote>\n<p>NOTE: In this guide, whenever a reference to a <code>redis-cli</code> or <code>valkey-cli</code> command is provided, the reference will only point to the Valkey version of the documentation.</p>\n</blockquote>\n<p>Redis Community Edition (CE), versions 7.4 and later, are not open source and the data files are not compatible with Valkey.<br>It may be possible to migrate the data to Valkey from proprietary Redis versions and other Redis-like software, but it requires another method and is not covered by this document.</p>\n<p>The following table provides migration options depending on the Redis version you run:</p>\n<table>\n<thead>\n<tr>\n<th>Redis</th>\n<th>Valkey</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>OSS 2.x - 7.2.x</td>\n<td>7.2.x</td>\n</tr>\n<tr>\n<td>OSS 2.x - 7.2.x</td>\n<td>8.0</td>\n</tr>\n<tr>\n<td>CE 7.4</td>\n<td>n/a</td>\n</tr>\n</tbody></table>\n<h2>Migrate a standalone instance</h2>\n<p>To migrate a standalone Redis server to Valkey, you have the following options:</p>\n<ul>\n<li><a href=\"#physical-migration\">Physical migration</a> by copying the most recent on-disk snapshot from the Redis server to Valkey and starting Valkey server with it</li>\n<li><a href=\"#replication\">Setting up replication</a> between Redis and Valkey </li>\n<li><a href=\"#migrate-specific-keys\">Migrating specific keys</a></li>\n</ul>\n<p>The example migration steps are provided for Redis 7.2.5 and Valkey version 7.2.6. </p>\n<p>Note that Redis and Valkey Docker containers are considered stand-alone servers, if they are not part of a cluster.</p>\n<h3>Physical migration</h3>\n<p>This is the easiest and fastest migration method. You make a fresh snapshot of your Redis instance and copy it over to Valkey. Valkey reads the data from the snapshot on startup and restores its contents into memory. The tradeoffs for this method are:</p>\n<ul>\n<li>The downtime to shutdown Redis and wait for Valkey to load the data. </li>\n<li>Potential risk of data loss on instances with heavy writes. To prevent it, you must disconnect all active connections before starting the migration.</li>\n</ul>\n<p>To perform a physical migration:</p>\n<ol>\n<li><p>Disconnect all active connections to the Redis instance.</p>\n</li>\n<li><p>Connect to your Redis container using <code>redis-cli</code>, and check the number of keys, using the <code>INFO KEYSPACE</code> command. This will be used later to verify that the entire database has been successfully migrated. In this example, <code>keys=6286</code> indicates that there are 6,286 keys in the database.</p>\n<pre><code>$ redis-cli -h 127.0.0.1 -p 6379\nredis 127.0.0.1:6379&gt; INFO KEYSPACE\n# Keyspace\ndb0:keys=6286,expires=0,avg_ttl=0\n</code></pre>\n</li>\n<li><p>Check the configuration for the directory (<code>dir</code>) where Redis stores its database files and the name of the database file (<code>dbfilename</code>). In this example, Redis saves the backup into the <code>/data/dump.rdb</code> file</p>\n<blockquote>\n<p>NOTE: If your Redis Docker container <code>/data</code> directory is mounted to a directory on your host, the RDB file is also written to that host directory.</p>\n</blockquote>\n<pre><code>redis 127.0.0.1:6379&gt; CONFIG GET dir dbfilename\n1) &quot;dir&quot;\n2) &quot;/data&quot;\n3) &quot;dbfilename&quot;\n4) &quot;dump.rdb&quot;\n</code></pre>\n</li>\n<li><p>Create the backup file. Since all active connections have been disconnected for this example, the <code>redis-cli</code> <a href=\"../commands/save\">SAVE</a> command can be used to create the backup file.</p>\n<pre><code>redis 127.0.0.1:6379&gt; SAVE\nOK\n</code></pre>\n</li>\n<li><p>Exit  <code>redis-cli</code> by pressing <code>CTRL-D</code> or typing <code>exit</code>.</p>\n</li>\n<li><p>Create a directory on your host to which you will mount the <code>/data</code> directory of the Valkey container.</p>\n</li>\n<li><p>Copy the RDB file from Redis to Valkey, using one of the following:</p>\n<ul>\n<li><p>If the Redis and Valkey containers are both mounted to a host directory: </p>\n<p>Copy the RDB file from the host directory mounted to the Redis container to the host directory being mounted to the Valkey container.</p>\n</li>\n<li><p>If the Redis container is not mounted to a host directory but the Valkey container is:</p>\n<p>Use <code>docker cp</code> to copy the RDB file from within the Redis container to the host directory that will be mounted to your Valkey container.</p>\n<blockquote>\n<p>NOTE: You may also want to copy the RDB file to a second location as a backup.</p>\n</blockquote>\n<pre><code>docker cp redis-container-name:/dir-name/dbfilename &lt;path/on/host&gt;/dbfilename\n</code></pre>\n</li>\n</ul>\n</li>\n<li><p>Stop the Redis server.</p>\n</li>\n<li><p>Start Valkey:</p>\n<blockquote>\n<p>NOTE: If you enabled AOF in your Valkey configuration, disable it on the first start. Otherwise, the copied RDB file will not be imported into Valkey.</p>\n</blockquote>\n<p>Run the following command:</p>\n<pre><code>docker run -d --name valkey-container-name -v &lt;path/on/host&gt;:&lt;path/in/Valkey/container&gt; image-name\n</code></pre>\n</li>\n<li><p>To verify that the data has been successfully migrated, determine the number of keys in the Valkey database. If the migration is successful, then the number of keys in the Valkey database match the number of keys in the Redis database that you obtained in step 2:</p>\n<pre><code>$ docker exec -it somevalkey valkey-cli\nvalkey 127.0.0.1:6379&gt; INFO KEYSPACE\n# Keyspace\ndb0:keys=6286,expires=0,avg_ttl=0\n</code></pre>\n</li>\n<li><p>To exit <code>valkey-cli</code>, press <code>Ctrl-D</code> or type <code>exit</code>.</p>\n</li>\n</ol>\n<h3>Replication</h3>\n<p>To minimize the downtime during migration, you can use replication. Both Redis and Valkey allow replaying data on another server to handle the workload.</p>\n<p>In this scenario we will configure Valkey to be the replica of Redis. For illustrative purposes, both Redis and Valkey are running in separate Docker containers connected to the same network.</p>\n<ol>\n<li><p>Retrieve the IP address of the Redis container. Replace the <code>myredis</code> placeholder with the name of your container. In this example, <code>172.17.0.2</code> is returned as the IP address of the <code>myredis</code> container.</p>\n<pre><code>$ docker inspect -f &#39;{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}&#39; myredis\n172.17.0.2\n</code></pre>\n</li>\n<li><p>Determine the port on which your Redis container is exposed. Note that for clarity, not all of the fields are shown in the response. In this example, the <code>myredis</code> container is exposed on port <code>6379</code>.</p>\n<pre><code>docker container ls\nCONTAINER ID   ...     PORTS      NAMES\nbffc575f261a   ...     6379/tcp   myvalkey\nab18318ce820   ...     6379/tcp   myredis\n</code></pre>\n</li>\n<li><p>Connect to your Valkey container and start the <code>valkey-cli</code> to configure replication using the <a href=\"../commands/replicaof\">REPLICAOF</a> command. In this example, the Redis IP address is <code>172.17.0.2</code> and the port is <code>6379</code>. Replace with the IP address and port of your Redis container obtained in steps 1 and 2.</p>\n<pre><code>docker exec -it myvalkey valkey-cli\nvalkey 127.0.0.1:6379&gt; REPLICAOF 172.17.0.2 6379\nOK\n</code></pre>\n</li>\n<li><p>Check the replication status in Valkey using the <code>INFO REPLICATION</code> command. If <code>master_link_status:up</code> is present, then the Redis and Valkey servers are synchronized. <a href=\"../commands/info\">INFO Command</a> describes the different output fields.</p>\n<pre><code>valkey 127.0.0.1:6379&gt; INFO REPLICATION\n# Replication\nrole:slave\nmaster_host:172.17.0.2\nmaster_port:6379\nmaster_link_status:up\nmaster_last_io_seconds_ago:4\nmaster_sync_in_progress:0\n....\n</code></pre>\n</li>\n<li><p>Once Redis and Valkey are synchronized, verify that your applications connect to Valkey and shut down your Redis instance.</p>\n<blockquote>\n<p>NOTE: Since the Redis 7.0 release, the <code>SHUTDOWN</code> command waits for a time period, set by the <code>shutdown-timeout</code> configuration variable, for any lagging replicas to sync. There may be potential data loss in the case where there are writes active on the Redis primary while it is syncing with the replica.</p>\n</blockquote>\n<p>You can shut down Redis in one of the following ways:</p>\n<ul>\n<li><p>Using <code>redis-cli</code>:</p>\n<pre><code>$ redis-cli SHUTDOWN\n</code></pre>\n</li>\n<li><p>If Redis was started directly in the foreground (using redis-server), you can simply stop it by pressing <code>Ctrl-C</code> in the terminal where it is running.</p>\n</li>\n</ul>\n</li>\n<li><p>In your Valkey container, stop the Valkey replication using the <code>REPLICAOF</code> command with <code>NO ONE</code> as the options:</p>\n<pre><code>valkey 127.0.0.1:6379&gt; REPLICAOF NO ONE\nOK\n</code></pre>\n</li>\n<li><p>You can verify that replication has stopped by running the <code>valkey-cli</code> command, <code>INFO REPLICATION</code>. If you see <code>role:master</code> and <code>connected_slaves:0</code>, then the Valkey container is now the master and is no longer connected to the Redis server. <a href=\"../commands/info\">INFO Command</a> describes the different output fields.</p>\n<pre><code>127.0.0.1:6379&gt; INFO REPLICATION\n# Replication\nrole:master\nconnected_slaves:0\nmaster_failover_state:no-failover\nmaster_replid:8d48c4667129cdb5933f9a12a1d5e6a24899602b\nmaster_replid2:602b7046ada6d2d6f0e89657e646d5932cc42791\nmaster_repl_offset:1336\nsecond_repl_offset:1337\nrepl_backlog_active:1\nrepl_backlog_size:1048576\nrepl_backlog_first_byte_offset:1\nrepl_backlog_histlen:1336\n</code></pre>\n</li>\n</ol>\n<blockquote>\n<p>NOTE: If not for backward compatibility, the Valkey project no longer uses the words &quot;master&quot; and &quot;slave&quot;. Unfortunately, in this command these words are part of the protocol, so we’ll be able to remove such occurrences only when this API is naturally deprecated.</p>\n</blockquote>\n<h3>Migrate specific keys</h3>\n<p>Both physical migration and replication migrate the entire keyspace over to Valkey. </p>\n<p>There may be cases when you need to migrate only a specific set of critical keys.<br>The <code>redis-cli</code> command, <a href=\"../commands/migrate\">MIGRATE</a> is used to migrate one or more keys.</p>\n<p>Requirements for this example:</p>\n<ul>\n<li><p>The Redis and Valkey Docker containers are on the same network and can communicate with each other.</p>\n</li>\n<li><p>The Redis and Valkey containers are running without authentication.</p>\n</li>\n</ul>\n<p>Perform the following steps:</p>\n<ol>\n<li><p>Determine the keys you wish to migrate. In this example, the <code>message</code> and  <code>mydata</code> keys are being migrated from the <code>myredis</code> container, and the <code>redis-cli</code> is used to view their current values.</p>\n<pre><code>$ docker exec -it myredis redis-cli\nredis 127.0.0.1:6379&gt; GET message\n&quot;Hello Valkey&quot;\nredis 127.0.0.1:6379&gt; HGETALL  mydata\n1) &quot;name&quot;\n2) &quot;Alice&quot;\n3) &quot;age&quot;\n4) &quot;33&quot;\n5) &quot;country&quot;\n6) &quot;Brazil&quot;\n7) &quot;favorite food&quot;\n8) &quot;beans&quot;\n</code></pre>\n</li>\n<li><p>Retrieve the IP address of your Valkey container. Replace <code>myvalkey</code> with the name of your Valkey container.</p>\n<pre><code>$ docker inspect -f &#39;{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}&#39; myvalkey\n172.21.0.3\n</code></pre>\n</li>\n<li><p>Start the <code>valkey-cli</code> in your Valkey container and get the database number using the <code>INFO KEYSPACE</code> command. In this example, the database number is <code>0</code> (db0).</p>\n<pre><code>valkey 127.0.0.1:6379&gt; INFO KEYSPACE\n# Keyspace\ndb0:keys=3,expires=0,avg_ttl=0\n</code></pre>\n<blockquote>\n<p>NOTE: If you haven&#39;t migrated or added any data to your Valkey database, then the <code>INFO KEYSPACE</code> command will not return any database number. You can use <code>0</code> for the <code>MIGRATE</code> command in step 4.</p>\n</blockquote>\n</li>\n<li><p>From the Redis server, run the <code>MIGRATE</code> command:</p>\n<pre><code>MIGRATE valkey-ip valkey-port &lt;key | &quot;&quot;&gt; valkey-db-number timeout-value [COPY] [REPLACE] [AUTH password | AUTH2 username password] [KEYS key [key ...]]\n</code></pre>\n<p> For example, to migrate the <code>message</code> and <code>mydata</code> keys to the Valkey instance with the IP address 172.21.0.3 and port 6379, the command would look similar to:</p>\n<pre><code>redis 127.0.0.1:6379&gt; MIGRATE 172.21.0.3 6379 &quot;&quot; 0 10 COPY REPLACE KEYS message mydata\n</code></pre>\n<p>where:</p>\n<ul>\n<li><code>&quot;&quot;</code> = Indicates that we are migrating multiple keys. You can use <code>key</code> name here if you are only migrating a single key.</li>\n<li><code>0</code> = The database number.</li>\n<li><code>10</code>= The maximum idle time, in milliseconds, allowed when communicating with the destination server.</li>\n<li><code>COPY</code> = Do not remove the key from the Redis database.</li>\n<li><code>REPLACE</code> = Replace existing key on the Valkey database.</li>\n<li><code>KEYS</code> = We are migrating multiple keys, and it is followed by the key names.</li>\n</ul>\n</li>\n<li><p>Exit <code>redis-cli</code> by pressing <code>Ctrl-D</code> or typing <code>exit</code>.</p>\n</li>\n<li><p>Connect to Valkey and check the migrated keys. replace <code>myvalkey</code> with the name of your Valkey container.</p>\n<pre><code>$ docker exec -it myvalkey valkey-cli\nvalkey 127.0.0.1:6379&gt; GET message\n&quot;Hello Valkey&quot;\nvalkey 127.0.0.1:6379&gt; HGETALL mydata\n1) &quot;name&quot;\n2) &quot;Alice&quot;\n3) &quot;age&quot;\n4) &quot;33&quot;\n5) &quot;country&quot;\n6) &quot;Brazil&quot;\n7) &quot;favorite food&quot;\n8) &quot;beans&quot;\n....\n</code></pre>\n</li>\n</ol>\n<h2>Migrate a Cluster</h2>\n<p>This section demonstrates how to migrate a cluster. The first step is to add the required number of Valkey nodes to the existing cluster as replicas. Once the new Valkey nodes replicate the data, one Valkey replica is promoted to be a new primary for each Redis primary. After the migration, the Redis nodes are removed from the cluster.</p>\n<blockquote>\n<p>NOTE: You can also use data migration tools such as <a href=\"https://redis.github.io/riot/#_introduction\">RIOT</a>, <a href=\"https://github.com/tair-opensource/RedisShake\">RedisShake</a>, and <a href=\"https://github.com/vipshop/redis-migrate-tool\">Redis-Migrate-Tool</a> but that is beyond the scope of this document.</p>\n</blockquote>\n<p>Requirements for this example:</p>\n<ul>\n<li>The Redis and Valkey cluster nodes are on the same network and can communicate with each other.</li>\n</ul>\n<p>For this scenario, there is a Redis Cluster consisting of 3 primary and 3 replica nodes up and running. </p>\n<p>To perform the migration:</p>\n<ol>\n<li><p>Use the <code>redis-cli</code> on one of the cluster nodes to check the current state of the cluster and to ensure all nodes are connected and active. In this cluster, there are three primary (master) and three replica (slave) nodes.</p>\n<pre><code>$ redis-cli -h 127.0.0.1 -p 6379 -c CLUSTER NODES\n70beedebe43e422b275ee1a7bac0d3819dedca98 172.22.0.3:6379@16379 master - 0 1725450849000 1 connected 0-5460\n8bbe836c59644f7395bbab09c6f8b36bc277e902 172.22.0.5:6379@16379 slave 58061fb2836bdb2f5a0973e1ccfd74a66166f329 0 1725450849510 3 connected\n65061b94da5b481dc35c2df7dae13c233d4b3ad2 172.22.0.4:6379@16379 master - 0 1725450848000 2 connected 5461-10922\na242941d0e3edad27a954bc14ac3a3413f3040aa 172.22.0.7:6379@16379 slave 65061b94da5b481dc35c2df7dae13c233d4b3ad2 0 1725450849000 2 connected\n3499854656f085ebb77b5b921389a91b7ae9d703 172.22.0.6:6379@16379 slave 70beedebe43e422b275ee1a7bac0d3819dedca98 0 1725450849829 1 connected\n58061fb2836bdb2f5a0973e1ccfd74a66166f329 172.22.0.2:6379@16379 myself,master - 0 1725450846000 3 connected 10923-16383\n</code></pre>\n</li>\n<li><p>Create a valkey.conf configuration file and specify the following parameters. Note that this configuration file enables clustering. <a href=\"https://raw.githubusercontent.com/valkey-io/valkey/7.2/valkey.conf\">Valkey configuration file example</a> provides a description of the various configuration arguments:</p>\n<pre><code># valkey.conf file\nport 6379\ncluster-enabled yes\ncluster-config-file nodes.conf\ncluster-node-timeout 5000\nappendonly yes\n</code></pre>\n</li>\n<li><p>Start a Valkey instance with your custom configuration file. The following command starts Valkey in Docker:</p>\n<pre><code>$ docker run  -d -v myvalkey/conf:/usr/local/etc/valkey --name valkey-1 --net mynetwork valkey/valkey valkey-server /usr/local/etc/valkey/valkey.conf\n</code></pre>\n<p>where:</p>\n<ul>\n<li><code>myvalkey/conf</code> is a local directory containing your <code>valkey.conf</code> configuration file that is being mapped to the <code>/usr/local/etc/valkey</code> directory within the Docker Valkey container.</li>\n<li><code>valkey-1</code> is the name of your container</li>\n<li><code>mynetwork</code> is the name of the network where Redis cluster is running.</li>\n<li><code>valkey/valkey</code> is the name of the Valkey image</li>\n</ul>\n</li>\n<li><p>Retrieve the IP address of the Valkey instance; replacing <code>valkey-1</code> with the name of your container.</p>\n<pre><code>$ docker inspect -f &#39;{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}&#39; valkey-1\n</code></pre>\n</li>\n<li><p>Add your new Valkey node to the Redis Cluster as a replica. Replace the <code>redis-1</code>, <code>valkey-node-ip</code>, and <code>existing-node-ip</code> placeholders with your values:</p>\n<pre><code>$ docker exec -it redis-1 bash\n$ redis-cli --cluster add-node valkey-node-ip:6379 existing-node-ip:6379 --cluster-replica\n</code></pre>\n</li>\n<li><p>Check the cluster status. The output of the <code>CLUSTER NODES</code> command is described in <a href=\"../commands/cluster-nodes\">CLUSTER NODES</a>.</p>\n<pre><code>$ redis-cli -c CLUSTER NODES\n</code></pre>\n<p> In the output, you will see the newly added node as a replica (slave). For example, we have added a Valkey node with the IP address <code>172.22.0.8:6379</code>. The cluster nodes list now includes a new entry as follows:</p>\n<pre><code>a98d5bac59672597b8509f24970e413002f896b6 172.22.0.8:6379@16379 slave 58061fb2836bdb2f5a0973e1ccfd74a66166f329 0 1725451086000 3 connected\n</code></pre>\n</li>\n<li><p>Verify that your newly added Valkey node is recognized as a replica by running the <code>INFO REPLICATION</code> command. The output displays information about the node&#39;s primary.</p>\n</li>\n<li><p>Start the <code>valkey-cli</code> in your new Valkey container and enter the following command to promote it to be primary. <a href=\"../commands/cluster-failover\">CLUSTER FAILOVER</a> provides additional information.</p>\n<pre><code>docker exec -it valkey-container-name valkey-cli\nvalkey 127.0.0.1:6379&gt; CLUSTER FAILOVER\nOK\n</code></pre>\n</li>\n<li><p>Use the <code>CLUSTER NODES</code> command to display the cluster state and verify that your new Valkey node is now a new primary.</p>\n</li>\n<li><p>Repeat steps 3-9 to add 2 more Valkey nodes and replace the Redis primary nodes.</p>\n</li>\n<li><p>Repeat steps 3-7 to add 3 Valkey replica nodes.</p>\n<p>To add a replica to a specific primary, do the following:</p>\n<p>a. Filter primary nodes. Connect to any node in the Cluster and run the following command, replacing <code>valkey-1</code> with then name of your Valkey container:</p>\n<pre><code>$ docker exec -it valkey-1 bash\n$ valkey-cli -c cluster nodes | grep master\n70beedebe43e422b275ee1a7bac0d3819dedca98 172.22.0.3:6379@16379 master - 0 1725451135799 1 connected 0-5460\n65061b94da5b481dc35c2df7dae13c233d4b3ad2 172.22.0.4:6379@16379 master - 0 1725451136000 2 connected 5461-10922\n58061fb2836bdb2f5a0973e1ccfd74a66166f329 172.22.0.2:6379@16379 myself,master - 0 1725451136000 3 connected 10923-16383\n</code></pre>\n<blockquote>\n<p>NOTE: The node ID is the 40-character globally unique string that is generated when the node is created. In this example, <code>70beedebe43e422b275ee1a7bac0d3819dedca98</code> is the ID of the primary (master) node with the IP address <code>172.22.0.3:6379</code>. The ID of a node is required when adding a new Valkey replica to a specific primary in step b.</p>\n</blockquote>\n<p>b. Add a new node to a specific primary, replacing node-id with your node ID:</p>\n<pre><code>$ valkey-cli --cluster add-node 172.22.0.10:6379 172.22.0.2:6379 --cluster-replica --cluster-master-id node-id\n</code></pre>\n</li>\n<li><p>Remove Redis nodes:</p>\n<pre><code>redis-cli --cluster del-node 127.0.0.1:6379 node-id\n</code></pre>\n<p> The first argument is just a random node in the cluster, the second argument is the ID of the node you want to remove.</p>\n</li>\n</ol>\n<blockquote>\n<p>NOTE: If not for backward compatibility, the Valkey project no longer uses the words &quot;master&quot; and &quot;slave&quot;. Unfortunately, in the given commands these words are part of the protocol, so we&#39;ll be able to remove such occurrences only when this API is naturally deprecated.</p>\n</blockquote>\n"
  },
  {
    "id": "modules-api-ref",
    "topicName": "Modules API reference",
    "description": "Reference for the Valkey Modules API\n",
    "htmlContent": "<!-- This file is generated from module.c using\n     utils/generate-module-api-doc.rb -->\n\n<h2>Sections</h2>\n<ul>\n<li><a href=\"#section-heap-allocation-raw-functions\">Heap allocation raw functions</a></li>\n<li><a href=\"#section-commands-api\">Commands API</a></li>\n<li><a href=\"#section-module-information-and-time-measurement\">Module information and time measurement</a></li>\n<li><a href=\"#section-automatic-memory-management-for-modules\">Automatic memory management for modules</a></li>\n<li><a href=\"#section-string-objects-apis\">String objects APIs</a></li>\n<li><a href=\"#section-reply-apis\">Reply APIs</a></li>\n<li><a href=\"#section-commands-replication-api\">Commands replication API</a></li>\n<li><a href=\"#section-db-and-key-apis-generic-api\">DB and Key APIs – Generic API</a></li>\n<li><a href=\"#section-key-api-for-string-type\">Key API for String type</a></li>\n<li><a href=\"#section-key-api-for-list-type\">Key API for List type</a></li>\n<li><a href=\"#section-key-api-for-sorted-set-type\">Key API for Sorted Set type</a></li>\n<li><a href=\"#section-key-api-for-sorted-set-iterator\">Key API for Sorted Set iterator</a></li>\n<li><a href=\"#section-key-api-for-hash-type\">Key API for Hash type</a></li>\n<li><a href=\"#section-key-api-for-stream-type\">Key API for Stream type</a></li>\n<li><a href=\"#section-calling-commands-from-modules\">Calling commands from modules</a></li>\n<li><a href=\"#section-modules-data-types\">Modules data types</a></li>\n<li><a href=\"#section-rdb-loading-and-saving-functions\">RDB loading and saving functions</a></li>\n<li><a href=\"#section-key-digest-api-debug-digest-interface-for-modules-types\">Key digest API (DEBUG DIGEST interface for modules types)</a></li>\n<li><a href=\"#section-aof-api-for-modules-data-types\">AOF API for modules data types</a></li>\n<li><a href=\"#section-io-context-handling\">IO context handling</a></li>\n<li><a href=\"#section-logging\">Logging</a></li>\n<li><a href=\"#section-blocking-clients-from-modules\">Blocking clients from modules</a></li>\n<li><a href=\"#section-thread-safe-contexts\">Thread Safe Contexts</a></li>\n<li><a href=\"#section-module-keyspace-notifications-api\">Module Keyspace Notifications API</a></li>\n<li><a href=\"#section-modules-cluster-api\">Modules Cluster API</a></li>\n<li><a href=\"#section-modules-timers-api\">Modules Timers API</a></li>\n<li><a href=\"#section-modules-eventloop-api\">Modules EventLoop API</a></li>\n<li><a href=\"#section-modules-acl-api\">Modules ACL API</a></li>\n<li><a href=\"#section-modules-dictionary-api\">Modules Dictionary API</a></li>\n<li><a href=\"#section-modules-info-fields\">Modules Info fields</a></li>\n<li><a href=\"#section-modules-utility-apis\">Modules utility APIs</a></li>\n<li><a href=\"#section-modules-api-exporting-importing\">Modules API exporting / importing</a></li>\n<li><a href=\"#section-module-command-filter-api\">Module Command Filter API</a></li>\n<li><a href=\"#section-scanning-keyspace-and-hashes\">Scanning keyspace and hashes</a></li>\n<li><a href=\"#section-module-fork-api\">Module fork API</a></li>\n<li><a href=\"#section-server-hooks-implementation\">Server hooks implementation</a></li>\n<li><a href=\"#section-module-configurations-api\">Module Configurations API</a></li>\n<li><a href=\"#section-rdb-load-save-api\">RDB load/save API</a></li>\n<li><a href=\"#section-key-eviction-api\">Key eviction API</a></li>\n<li><a href=\"#section-miscellaneous-apis\">Miscellaneous APIs</a></li>\n<li><a href=\"#section-defrag-api\">Defrag API</a></li>\n<li><a href=\"#section-function-index\">Function index</a></li>\n</ul>\n<p><span id=\"section-heap-allocation-raw-functions\"></span></p>\n<h2>Heap allocation raw functions</h2>\n<p>Memory allocated with these functions are taken into account by key<br>eviction algorithms and are reported in memory usage information.</p>\n<p><span id=\"ValkeyModule_Alloc\"></span></p>\n<h3><code>ValkeyModule_Alloc</code></h3>\n<pre><code>void *ValkeyModule_Alloc(size_t bytes);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Use like <code>malloc()</code>. Memory allocated with this function is reported in<br>INFO memory, used for keys eviction according to maxmemory settings<br>and in general is taken into account as memory allocated by the server.<br>You should avoid using <code>malloc()</code>.<br>This function panics if unable to allocate enough memory.</p>\n<p><span id=\"ValkeyModule_TryAlloc\"></span></p>\n<h3><code>ValkeyModule_TryAlloc</code></h3>\n<pre><code>void *ValkeyModule_TryAlloc(size_t bytes);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Similar to <a href=\"#ValkeyModule_Alloc\"><code>ValkeyModule_Alloc</code></a>, but returns NULL in case of allocation failure, instead<br>of panicking.</p>\n<p><span id=\"ValkeyModule_Calloc\"></span></p>\n<h3><code>ValkeyModule_Calloc</code></h3>\n<pre><code>void *ValkeyModule_Calloc(size_t nmemb, size_t size);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Use like <code>calloc()</code>. Memory allocated with this function is reported in<br>INFO memory, used for keys eviction according to maxmemory settings<br>and in general is taken into account as memory allocated by the server.<br>You should avoid using <code>calloc()</code> directly.</p>\n<p><span id=\"ValkeyModule_TryCalloc\"></span></p>\n<h3><code>ValkeyModule_TryCalloc</code></h3>\n<pre><code>void *ValkeyModule_TryCalloc(size_t nmemb, size_t size);\n</code></pre>\n<p><strong>Available since:</strong> 8.0.0</p>\n<p>Similar to <a href=\"#ValkeyModule_Calloc\"><code>ValkeyModule_Calloc</code></a>, but returns NULL in case of allocation failure, instead<br>of panicking.</p>\n<p><span id=\"ValkeyModule_Realloc\"></span></p>\n<h3><code>ValkeyModule_Realloc</code></h3>\n<pre><code>void *ValkeyModule_Realloc(void *ptr, size_t bytes);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Use like <code>realloc()</code> for memory obtained with <a href=\"#ValkeyModule_Alloc\"><code>ValkeyModule_Alloc()</code></a>.</p>\n<p><span id=\"ValkeyModule_TryRealloc\"></span></p>\n<h3><code>ValkeyModule_TryRealloc</code></h3>\n<pre><code>void *ValkeyModule_TryRealloc(void *ptr, size_t bytes);\n</code></pre>\n<p><strong>Available since:</strong> 8.0.0</p>\n<p>Similar to <a href=\"#ValkeyModule_Realloc\"><code>ValkeyModule_Realloc</code></a>, but returns NULL in case of allocation failure,<br>instead of panicking.</p>\n<p><span id=\"ValkeyModule_Free\"></span></p>\n<h3><code>ValkeyModule_Free</code></h3>\n<pre><code>void ValkeyModule_Free(void *ptr);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Use like <code>free()</code> for memory obtained by <a href=\"#ValkeyModule_Alloc\"><code>ValkeyModule_Alloc()</code></a> and<br><a href=\"#ValkeyModule_Realloc\"><code>ValkeyModule_Realloc()</code></a>. However you should never try to free with<br><a href=\"#ValkeyModule_Free\"><code>ValkeyModule_Free()</code></a> memory allocated with <code>malloc()</code> inside your module.</p>\n<p><span id=\"ValkeyModule_Strdup\"></span></p>\n<h3><code>ValkeyModule_Strdup</code></h3>\n<pre><code>char *ValkeyModule_Strdup(const char *str);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Like <code>strdup()</code> but returns memory allocated with <a href=\"#ValkeyModule_Alloc\"><code>ValkeyModule_Alloc()</code></a>.</p>\n<p><span id=\"ValkeyModule_PoolAlloc\"></span></p>\n<h3><code>ValkeyModule_PoolAlloc</code></h3>\n<pre><code>void *ValkeyModule_PoolAlloc(ValkeyModuleCtx *ctx, size_t bytes);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return heap allocated memory that will be freed automatically when the<br>module callback function returns. Mostly suitable for small allocations<br>that are short living and must be released when the callback returns<br>anyway. The returned memory is aligned to the architecture word size<br>if at least word size bytes are requested, otherwise it is just<br>aligned to the next power of two, so for example a 3 bytes request is<br>4 bytes aligned while a 2 bytes request is 2 bytes aligned.</p>\n<p>There is no realloc style function since when this is needed to use the<br>pool allocator is not a good idea.</p>\n<p>The function returns NULL if <code>bytes</code> is 0.</p>\n<p><span id=\"section-commands-api\"></span></p>\n<h2>Commands API</h2>\n<p>These functions are used to implement custom commands.</p>\n<p>For examples, see <a href=\"https://valkey.io/topics/modules-intro\">https://valkey.io/topics/modules-intro</a>.</p>\n<p><span id=\"ValkeyModule_IsKeysPositionRequest\"></span></p>\n<h3><code>ValkeyModule_IsKeysPositionRequest</code></h3>\n<pre><code>int ValkeyModule_IsKeysPositionRequest(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return non-zero if a module command, that was declared with the<br>flag &quot;getkeys-api&quot;, is called in a special way to get the keys positions<br>and not to get executed. Otherwise zero is returned.</p>\n<p><span id=\"ValkeyModule_KeyAtPosWithFlags\"></span></p>\n<h3><code>ValkeyModule_KeyAtPosWithFlags</code></h3>\n<pre><code>void ValkeyModule_KeyAtPosWithFlags(ValkeyModuleCtx *ctx, int pos, int flags);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>When a module command is called in order to obtain the position of<br>keys, since it was flagged as &quot;getkeys-api&quot; during the registration,<br>the command implementation checks for this special call using the<br><a href=\"#ValkeyModule_IsKeysPositionRequest\"><code>ValkeyModule_IsKeysPositionRequest()</code></a> API and uses this function in<br>order to report keys.</p>\n<p>The supported flags are the ones used by <a href=\"#ValkeyModule_SetCommandInfo\"><code>ValkeyModule_SetCommandInfo</code></a>, see <code>VALKEYMODULE_CMD_KEY_</code>*.</p>\n<p>The following is an example of how it could be used:</p>\n<pre><code>if (ValkeyModule_IsKeysPositionRequest(ctx)) {\n    ValkeyModule_KeyAtPosWithFlags(ctx, 2, VALKEYMODULE_CMD_KEY_RO | VALKEYMODULE_CMD_KEY_ACCESS);\n    ValkeyModule_KeyAtPosWithFlags(ctx, 1, VALKEYMODULE_CMD_KEY_RW | VALKEYMODULE_CMD_KEY_UPDATE |\n</code></pre>\n<p><code>VALKEYMODULE_CMD_KEY_ACCESS</code>);<br>    }</p>\n<p> Note: in the example above the get keys API could have been handled by key-specs (preferred).<br> Implementing the getkeys-api is required only when is it not possible to declare key-specs that cover all keys.</p>\n<p><span id=\"ValkeyModule_KeyAtPos\"></span></p>\n<h3><code>ValkeyModule_KeyAtPos</code></h3>\n<pre><code>void ValkeyModule_KeyAtPos(ValkeyModuleCtx *ctx, int pos);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>This API existed before <a href=\"#ValkeyModule_KeyAtPosWithFlags\"><code>ValkeyModule_KeyAtPosWithFlags</code></a> was added, now deprecated and<br>can be used for compatibility with older versions, before key-specs and flags<br>were introduced.</p>\n<p><span id=\"ValkeyModule_IsChannelsPositionRequest\"></span></p>\n<h3><code>ValkeyModule_IsChannelsPositionRequest</code></h3>\n<pre><code>int ValkeyModule_IsChannelsPositionRequest(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Return non-zero if a module command, that was declared with the<br>flag &quot;getchannels-api&quot;, is called in a special way to get the channel positions<br>and not to get executed. Otherwise zero is returned.</p>\n<p><span id=\"ValkeyModule_ChannelAtPosWithFlags\"></span></p>\n<h3><code>ValkeyModule_ChannelAtPosWithFlags</code></h3>\n<pre><code>void ValkeyModule_ChannelAtPosWithFlags(ValkeyModuleCtx *ctx,\n                                        int pos,\n                                        int flags);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>When a module command is called in order to obtain the position of<br>channels, since it was flagged as &quot;getchannels-api&quot; during the<br>registration, the command implementation checks for this special call<br>using the <a href=\"#ValkeyModule_IsChannelsPositionRequest\"><code>ValkeyModule_IsChannelsPositionRequest()</code></a> API and uses this<br>function in order to report the channels.</p>\n<p>The supported flags are:</p>\n<ul>\n<li><code>VALKEYMODULE_CMD_CHANNEL_SUBSCRIBE</code>: This command will subscribe to the channel.</li>\n<li><code>VALKEYMODULE_CMD_CHANNEL_UNSUBSCRIBE</code>: This command will unsubscribe from this channel.</li>\n<li><code>VALKEYMODULE_CMD_CHANNEL_PUBLISH</code>: This command will publish to this channel.</li>\n<li><code>VALKEYMODULE_CMD_CHANNEL_PATTERN</code>: Instead of acting on a specific channel, will act on any<br>                             channel specified by the pattern. This is the same access<br>                             used by the PSUBSCRIBE and PUNSUBSCRIBE commands.<br>                             Not intended to be used with PUBLISH permissions.</li>\n</ul>\n<p>The following is an example of how it could be used:</p>\n<pre><code>if (ValkeyModule_IsChannelsPositionRequest(ctx)) {\n    ValkeyModule_ChannelAtPosWithFlags(ctx, 1, VALKEYMODULE_CMD_CHANNEL_SUBSCRIBE | VALKEYMODULE_CMD_CHANNEL_PATTERN); \n    ValkeyModule_ChannelAtPosWithFlags(ctx, 1, `VALKEYMODULE_CMD_CHANNEL_PUBLISH`);\n}\n</code></pre>\n<p>Note: One usage of declaring channels is for evaluating ACL permissions. In this context,<br>unsubscribing is always allowed, so commands will only be checked against subscribe and<br>publish permissions. This is preferred over using <a href=\"#ValkeyModule_ACLCheckChannelPermissions\"><code>ValkeyModule_ACLCheckChannelPermissions</code></a>, since<br>it allows the ACLs to be checked before the command is executed.</p>\n<p><span id=\"ValkeyModule_CreateCommand\"></span></p>\n<h3><code>ValkeyModule_CreateCommand</code></h3>\n<pre><code>int ValkeyModule_CreateCommand(ValkeyModuleCtx *ctx,\n                               const char *name,\n                               ValkeyModuleCmdFunc cmdfunc,\n                               const char *strflags,\n                               int firstkey,\n                               int lastkey,\n                               int keystep);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Register a new command in the server, that will be handled by<br>calling the function pointer &#39;cmdfunc&#39; using the ValkeyModule calling<br>convention.</p>\n<p>The function returns <code>VALKEYMODULE_ERR</code> in these cases:</p>\n<ul>\n<li>If creation of module command is called outside the <code>ValkeyModule_OnLoad</code>.</li>\n<li>The specified command is already busy.</li>\n<li>The command name contains some chars that are not allowed.</li>\n<li>A set of invalid flags were passed.</li>\n</ul>\n<p>Otherwise <code>VALKEYMODULE_OK</code> is returned and the new command is registered.</p>\n<p>This function must be called during the initialization of the module<br>inside the <code>ValkeyModule_OnLoad()</code> function. Calling this function outside<br>of the initialization function is not defined.</p>\n<p>The command function type is the following:</p>\n<pre><code> int MyCommand_ValkeyCommand(ValkeyModuleCtx *ctx, ValkeyModuleString **argv, int argc);\n</code></pre>\n<p>And is supposed to always return <code>VALKEYMODULE_OK</code>.</p>\n<p>The set of flags &#39;strflags&#39; specify the behavior of the command, and should<br>be passed as a C string composed of space separated words, like for<br>example &quot;write deny-oom&quot;. The set of flags are:</p>\n<ul>\n<li><strong>&quot;write&quot;</strong>:     The command may modify the data set (it may also read<br>             from it).</li>\n<li><strong>&quot;readonly&quot;</strong>:  The command returns data from keys but never writes.</li>\n<li><strong>&quot;admin&quot;</strong>:     The command is an administrative command (may change<br>             replication or perform similar tasks).</li>\n<li><strong>&quot;deny-oom&quot;</strong>:  The command may use additional memory and should be<br>             denied during out of memory conditions.</li>\n<li><strong>&quot;deny-script&quot;</strong>:   Don&#39;t allow this command in Lua scripts.</li>\n<li><strong>&quot;allow-loading&quot;</strong>: Allow this command while the server is loading data.<br>                 Only commands not interacting with the data set<br>                 should be allowed to run in this mode. If not sure<br>                 don&#39;t use this flag.</li>\n<li><strong>&quot;pubsub&quot;</strong>:    The command publishes things on Pub/Sub channels.</li>\n<li><strong>&quot;random&quot;</strong>:    The command may have different outputs even starting<br>             from the same input arguments and key values.<br>             Starting from Redis OSS 7.0 this flag has been deprecated.<br>             Declaring a command as &quot;random&quot; can be done using<br>             command tips, see <a href=\"https://valkey.io/topics/command-tips\">https://valkey.io/topics/command-tips</a>.</li>\n<li><strong>&quot;allow-stale&quot;</strong>: The command is allowed to run on replicas that don&#39;t<br>               serve stale data. Don&#39;t use if you don&#39;t know what<br>               this means.</li>\n<li><strong>&quot;no-monitor&quot;</strong>: Don&#39;t propagate the command on monitor. Use this if<br>              the command has sensitive data among the arguments.</li>\n<li><strong>&quot;no-slowlog&quot;</strong>: Deprecated, please use &quot;no-commandlog&quot;.</li>\n<li><strong>&quot;no-commandlog&quot;</strong>: Don&#39;t log this command in the commandlog. Use this if<br>              the command has sensitive data among the arguments.</li>\n<li><strong>&quot;fast&quot;</strong>:      The command time complexity is not greater<br>             than O(log(N)) where N is the size of the collection or<br>             anything else representing the normal scalability<br>             issue with the command.</li>\n<li><strong>&quot;getkeys-api&quot;</strong>: The command implements the interface to return<br>               the arguments that are keys. Used when start/stop/step<br>               is not enough because of the command syntax.</li>\n<li><strong>&quot;no-cluster&quot;</strong>: The command should not register in Cluster<br>              since is not designed to work with it because, for<br>              example, is unable to report the position of the<br>              keys, programmatically creates key names, or any<br>              other reason.</li>\n<li><strong>&quot;no-auth&quot;</strong>:    This command can be run by an un-authenticated client.<br>              Normally this is used by a command that is used<br>              to authenticate a client.</li>\n<li><strong>&quot;may-replicate&quot;</strong>: This command may generate replication traffic, even<br>                 though it&#39;s not a write command.</li>\n<li><strong>&quot;no-mandatory-keys&quot;</strong>: All the keys this command may take are optional</li>\n<li><strong>&quot;blocking&quot;</strong>: The command has the potential to block the client.</li>\n<li><strong>&quot;allow-busy&quot;</strong>: Permit the command while the server is blocked either by<br>              a script or by a slow module command, see<br>              ValkeyModule_Yield.</li>\n<li><strong>&quot;getchannels-api&quot;</strong>: The command implements the interface to return<br>                   the arguments that are channels.</li>\n</ul>\n<p>The last three parameters specify which arguments of the new command are<br>keys. See <a href=\"https://valkey.io/commands/command\">https://valkey.io/commands/command</a> for more information.</p>\n<ul>\n<li><code>firstkey</code>: One-based index of the first argument that&#39;s a key.<br>        Position 0 is always the command name itself.<br>        0 for commands with no keys.</li>\n<li><code>lastkey</code>:  One-based index of the last argument that&#39;s a key.<br>        Negative numbers refer to counting backwards from the last<br>        argument (-1 means the last argument provided)<br>        0 for commands with no keys.</li>\n<li><code>keystep</code>:  Step between first and last key indexes.<br>        0 for commands with no keys.</li>\n</ul>\n<p>This information is used by ACL, Cluster and the <code>COMMAND</code> command.</p>\n<p>NOTE: The scheme described above serves a limited purpose and can<br>only be used to find keys that exist at constant indices.<br>For non-trivial key arguments, you may pass 0,0,0 and use<br><a href=\"#ValkeyModule_SetCommandInfo\"><code>ValkeyModule_SetCommandInfo</code></a> to set key specs using a more advanced scheme and use<br><a href=\"#ValkeyModule_SetCommandACLCategories\"><code>ValkeyModule_SetCommandACLCategories</code></a> to set ACL categories of the commands.</p>\n<p><span id=\"ValkeyModule_GetCommand\"></span></p>\n<h3><code>ValkeyModule_GetCommand</code></h3>\n<pre><code>ValkeyModuleCommand *ValkeyModule_GetCommand(ValkeyModuleCtx *ctx,\n                                             const char *name);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Get an opaque structure, representing a module command, by command name.<br>This structure is used in some of the command-related APIs.</p>\n<p>NULL is returned in case of the following errors:</p>\n<ul>\n<li>Command not found</li>\n<li>The command is not a module command</li>\n<li>The command doesn&#39;t belong to the calling module</li>\n</ul>\n<p><span id=\"ValkeyModule_CreateSubcommand\"></span></p>\n<h3><code>ValkeyModule_CreateSubcommand</code></h3>\n<pre><code>int ValkeyModule_CreateSubcommand(ValkeyModuleCommand *parent,\n                                  const char *name,\n                                  ValkeyModuleCmdFunc cmdfunc,\n                                  const char *strflags,\n                                  int firstkey,\n                                  int lastkey,\n                                  int keystep);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Very similar to <a href=\"#ValkeyModule_CreateCommand\"><code>ValkeyModule_CreateCommand</code></a> except that it is used to create<br>a subcommand, associated with another, container, command.</p>\n<p>Example: If a module has a configuration command, MODULE.CONFIG, then<br>GET and SET should be individual subcommands, while MODULE.CONFIG is<br>a command, but should not be registered with a valid <code>funcptr</code>:</p>\n<pre><code> if (ValkeyModule_CreateCommand(ctx,&quot;module.config&quot;,NULL,&quot;&quot;,0,0,0) == VALKEYMODULE_ERR)\n     return VALKEYMODULE_ERR;\n\n ValkeyModuleCommand *parent = ValkeyModule_GetCommand(ctx,,&quot;module.config&quot;);\n\n if (ValkeyModule_CreateSubcommand(parent,&quot;set&quot;,cmd_config_set,&quot;&quot;,0,0,0) == VALKEYMODULE_ERR)\n    return VALKEYMODULE_ERR;\n\n if (ValkeyModule_CreateSubcommand(parent,&quot;get&quot;,cmd_config_get,&quot;&quot;,0,0,0) == VALKEYMODULE_ERR)\n    return VALKEYMODULE_ERR;\n</code></pre>\n<p>Returns <code>VALKEYMODULE_OK</code> on success and <code>VALKEYMODULE_ERR</code> in case of the following errors:</p>\n<ul>\n<li>Error while parsing <code>strflags</code></li>\n<li>Command is marked as <code>no-cluster</code> but cluster mode is enabled</li>\n<li><code>parent</code> is already a subcommand (we do not allow more than one level of command nesting)</li>\n<li><code>parent</code> is a command with an implementation (<code>ValkeyModuleCmdFunc</code>) (A parent command should be a pure container of<br>subcommands)</li>\n<li><code>parent</code> already has a subcommand called <code>name</code></li>\n<li>Creating a subcommand is called outside of <code>ValkeyModule_OnLoad</code>.</li>\n</ul>\n<p><span id=\"ValkeyModule_AddACLCategory\"></span></p>\n<h3><code>ValkeyModule_AddACLCategory</code></h3>\n<pre><code>int ValkeyModule_AddACLCategory(ValkeyModuleCtx *ctx, const char *name);\n</code></pre>\n<p><strong>Available since:</strong> 8.0.0</p>\n<p><a href=\"#ValkeyModule_AddACLCategory\"><code>ValkeyModule_AddACLCategory</code></a> can be used to add new ACL command categories. Category names<br>can only contain alphanumeric characters, underscores, or dashes. Categories can only be added<br>during the <code>ValkeyModule_OnLoad</code> function. Once a category has been added, it can not be removed.<br>Any module can register a command to any added categories using <a href=\"#ValkeyModule_SetCommandACLCategories\"><code>ValkeyModule_SetCommandACLCategories</code></a>.</p>\n<p>Returns:</p>\n<ul>\n<li><code>VALKEYMODULE_OK</code> on successfully adding the new ACL category.</li>\n<li><code>VALKEYMODULE_ERR</code> on failure.</li>\n</ul>\n<p>On error the errno is set to:</p>\n<ul>\n<li>EINVAL if the name contains invalid characters.</li>\n<li>EBUSY if the category name already exists.</li>\n<li>ENOMEM if the number of categories reached the max limit of 64 categories.</li>\n</ul>\n<p><span id=\"ValkeyModule_SetCommandACLCategories\"></span></p>\n<h3><code>ValkeyModule_SetCommandACLCategories</code></h3>\n<pre><code>int ValkeyModule_SetCommandACLCategories(ValkeyModuleCommand *command,\n                                         const char *aclflags);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p><a href=\"#ValkeyModule_SetCommandACLCategories\"><code>ValkeyModule_SetCommandACLCategories</code></a> can be used to set ACL categories to module<br>commands and subcommands. The set of ACL categories should be passed as<br>a space separated C string &#39;aclflags&#39;.</p>\n<p>Example, the acl flags &#39;write slow&#39; marks the command as part of the write and<br>slow ACL categories.</p>\n<p>On success <code>VALKEYMODULE_OK</code> is returned. On error <code>VALKEYMODULE_ERR</code> is returned.</p>\n<p>This function can only be called during the <code>ValkeyModule_OnLoad</code> function. If called<br>outside of this function, an error is returned.</p>\n<p><span id=\"ValkeyModule_SetCommandInfo\"></span></p>\n<h3><code>ValkeyModule_SetCommandInfo</code></h3>\n<pre><code>int ValkeyModule_SetCommandInfo(ValkeyModuleCommand *command,\n                                const ValkeyModuleCommandInfo *info);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Set additional command information.</p>\n<p>Affects the output of <code>COMMAND</code>, <code>COMMAND INFO</code> and <code>COMMAND DOCS</code>, Cluster,<br>ACL and is used to filter commands with the wrong number of arguments before<br>the call reaches the module code.</p>\n<p>This function can be called after creating a command using <a href=\"#ValkeyModule_CreateCommand\"><code>ValkeyModule_CreateCommand</code></a><br>and fetching the command pointer using <a href=\"#ValkeyModule_GetCommand\"><code>ValkeyModule_GetCommand</code></a>. The information can<br>only be set once for each command and has the following structure:</p>\n<pre><code>typedef struct ValkeyModuleCommandInfo {\n    const ValkeyModuleCommandInfoVersion *version;\n    const char *summary;\n    const char *complexity;\n    const char *since;\n    ValkeyModuleCommandHistoryEntry *history;\n    const char *tips;\n    int arity;\n    ValkeyModuleCommandKeySpec *key_specs;\n    ValkeyModuleCommandArg *args;\n} ValkeyModuleCommandInfo;\n</code></pre>\n<p>All fields except <code>version</code> are optional. Explanation of the fields:</p>\n<ul>\n<li><p><code>version</code>: This field enables compatibility with different server versions.<br>Always set this field to <code>VALKEYMODULE_COMMAND_INFO_VERSION</code>.</p>\n</li>\n<li><p><code>summary</code>: A short description of the command (optional).</p>\n</li>\n<li><p><code>complexity</code>: Complexity description (optional).</p>\n</li>\n<li><p><code>since</code>: The version where the command was introduced (optional).<br>Note: The version specified should be the module&#39;s, not the server version.</p>\n</li>\n<li><p><code>history</code>: An array of <code>ValkeyModuleCommandHistoryEntry</code> (optional), which is<br>a struct with the following fields:</p>\n<pre><code>  const char *since;\n  const char *changes;\n</code></pre>\n<p>  <code>since</code> is a version string and <code>changes</code> is a string describing the<br>  changes. The array is terminated by a zeroed entry, i.e. an entry with<br>  both strings set to NULL.</p>\n</li>\n<li><p><code>tips</code>: A string of space-separated tips regarding this command, meant for<br>clients and proxies. See <a href=\"https://valkey.io/topics/command-tips\">https://valkey.io/topics/command-tips</a>.</p>\n</li>\n<li><p><code>arity</code>: Number of arguments, including the command name itself. A positive<br>number specifies an exact number of arguments and a negative number<br>specifies a minimum number of arguments, so use -N to say &gt;= N. The server<br>validates a call before passing it to a module, so this can replace an<br>arity check inside the module command implementation. A value of 0 (or an<br>omitted arity field) is equivalent to -2 if the command has sub commands<br>and -1 otherwise.</p>\n</li>\n<li><p><code>key_specs</code>: An array of <code>ValkeyModuleCommandKeySpec</code>, terminated by an<br>element memset to zero. This is a scheme that tries to describe the<br>positions of key arguments better than the old <a href=\"#ValkeyModule_CreateCommand\"><code>ValkeyModule_CreateCommand</code></a> arguments<br><code>firstkey</code>, <code>lastkey</code>, <code>keystep</code> and is needed if those three are not<br>enough to describe the key positions. There are two steps to retrieve key<br>positions: <em>begin search</em> (BS) in which index should find the first key and<br><em>find keys</em> (FK) which, relative to the output of BS, describes how can we<br>will which arguments are keys. Additionally, there are key specific flags.</p>\n<p>  Key-specs cause the triplet (firstkey, lastkey, keystep) given in<br>  ValkeyModule_CreateCommand to be recomputed, but it is still useful to provide<br>  these three parameters in ValkeyModule_CreateCommand, to better support old server<br>  versions where ValkeyModule_SetCommandInfo is not available.</p>\n<p>  Note that key-specs don&#39;t fully replace the &quot;getkeys-api&quot; (see<br>  ValkeyModule_CreateCommand, ValkeyModule_IsKeysPositionRequest and ValkeyModule_KeyAtPosWithFlags) so<br>  it may be a good idea to supply both key-specs and implement the<br>  getkeys-api.</p>\n<p>  A key-spec has the following structure:</p>\n<pre><code>  typedef struct ValkeyModuleCommandKeySpec {\n      const char *notes;\n      uint64_t flags;\n      ValkeyModuleKeySpecBeginSearchType begin_search_type;\n      union {\n          struct {\n              int pos;\n          } index;\n          struct {\n              const char *keyword;\n              int startfrom;\n          } keyword;\n      } bs;\n      ValkeyModuleKeySpecFindKeysType find_keys_type;\n      union {\n          struct {\n              int lastkey;\n              int keystep;\n              int limit;\n          } range;\n          struct {\n              int keynumidx;\n              int firstkey;\n              int keystep;\n          } keynum;\n      } fk;\n  } ValkeyModuleCommandKeySpec;\n</code></pre>\n<p>  Explanation of the fields of ValkeyModuleCommandKeySpec:</p>\n<ul>\n<li><p><code>notes</code>: Optional notes or clarifications about this key spec.</p>\n</li>\n<li><p><code>flags</code>: A bitwise or of key-spec flags described below.</p>\n</li>\n<li><p><code>begin_search_type</code>: This describes how the first key is discovered.<br>There are two ways to determine the first key:</p>\n<ul>\n<li><code>VALKEYMODULE_KSPEC_BS_UNKNOWN</code>: There is no way to tell where the<br>key args start.</li>\n<li><code>VALKEYMODULE_KSPEC_BS_INDEX</code>: Key args start at a constant index.</li>\n<li><code>VALKEYMODULE_KSPEC_BS_KEYWORD</code>: Key args start just after a<br>specific keyword.</li>\n</ul>\n</li>\n<li><p><code>bs</code>: This is a union in which the <code>index</code> or <code>keyword</code> branch is used<br>depending on the value of the <code>begin_search_type</code> field.</p>\n<ul>\n<li><p><code>bs.index.pos</code>: The index from which we start the search for keys.<br>(<code>VALKEYMODULE_KSPEC_BS_INDEX</code> only.)</p>\n</li>\n<li><p><code>bs.keyword.keyword</code>: The keyword (string) that indicates the<br>beginning of key arguments. (<code>VALKEYMODULE_KSPEC_BS_KEYWORD</code> only.)</p>\n</li>\n<li><p><code>bs.keyword.startfrom</code>: An index in argv from which to start<br>searching. Can be negative, which means start search from the end,<br>in reverse. Example: -2 means to start in reverse from the<br>penultimate argument. (<code>VALKEYMODULE_KSPEC_BS_KEYWORD</code> only.)</p>\n</li>\n</ul>\n</li>\n<li><p><code>find_keys_type</code>: After the &quot;begin search&quot;, this describes which<br>arguments are keys. The strategies are:</p>\n<ul>\n<li><code>VALKEYMODULE_KSPEC_BS_UNKNOWN</code>: There is no way to tell where the<br>key args are located.</li>\n<li><code>VALKEYMODULE_KSPEC_FK_RANGE</code>: Keys end at a specific index (or<br>relative to the last argument).</li>\n<li><code>VALKEYMODULE_KSPEC_FK_KEYNUM</code>: There&#39;s an argument that contains<br>the number of key args somewhere before the keys themselves.</li>\n</ul>\n<p><code>find_keys_type</code> and <code>fk</code> can be omitted if this keyspec describes<br>exactly one key.</p>\n</li>\n<li><p><code>fk</code>: This is a union in which the <code>range</code> or <code>keynum</code> branch is used<br>depending on the value of the <code>find_keys_type</code> field.</p>\n<ul>\n<li><p><code>fk.range</code> (for <code>VALKEYMODULE_KSPEC_FK_RANGE</code>): A struct with the<br>following fields:</p>\n<ul>\n<li><p><code>lastkey</code>: Index of the last key relative to the result of the<br>begin search step. Can be negative, in which case it&#39;s not<br>relative. -1 indicates the last argument, -2 one before the<br>last and so on.</p>\n</li>\n<li><p><code>keystep</code>: How many arguments should we skip after finding a<br>key, in order to find the next one?</p>\n</li>\n<li><p><code>limit</code>: If <code>lastkey</code> is -1, we use <code>limit</code> to stop the search<br>by a factor. 0 and 1 mean no limit. 2 means 1/2 of the<br>remaining args, 3 means 1/3, and so on.</p>\n</li>\n</ul>\n</li>\n<li><p><code>fk.keynum</code> (for <code>VALKEYMODULE_KSPEC_FK_KEYNUM</code>): A struct with the<br>following fields:</p>\n<ul>\n<li><p><code>keynumidx</code>: Index of the argument containing the number of<br>keys to come, relative to the result of the begin search step.</p>\n</li>\n<li><p><code>firstkey</code>: Index of the fist key relative to the result of the<br>begin search step. (Usually it&#39;s just after <code>keynumidx</code>, in<br>which case it should be set to <code>keynumidx + 1</code>.)</p>\n</li>\n<li><p><code>keystep</code>: How many arguments should we skip after finding a<br>key, in order to find the next one?</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>  Key-spec flags:</p>\n<p>  The first four refer to what the command actually does with the <em>value or<br>  metadata of the key</em>, and not necessarily the user data or how it affects<br>  it. Each key-spec may must have exactly one of these. Any operation<br>  that&#39;s not distinctly deletion, overwrite or read-only would be marked as<br>  RW.</p>\n<ul>\n<li><p><code>VALKEYMODULE_CMD_KEY_RO</code>: Read-Only. Reads the value of the key, but<br>doesn&#39;t necessarily return it.</p>\n</li>\n<li><p><code>VALKEYMODULE_CMD_KEY_RW</code>: Read-Write. Modifies the data stored in the<br>value of the key or its metadata.</p>\n</li>\n<li><p><code>VALKEYMODULE_CMD_KEY_OW</code>: Overwrite. Overwrites the data stored in the<br>value of the key.</p>\n</li>\n<li><p><code>VALKEYMODULE_CMD_KEY_RM</code>: Deletes the key.</p>\n</li>\n</ul>\n<p>  The next four refer to <em>user data inside the value of the key</em>, not the<br>  metadata like LRU, type, cardinality. It refers to the logical operation<br>  on the user&#39;s data (actual input strings or TTL), being<br>  used/returned/copied/changed. It doesn&#39;t refer to modification or<br>  returning of metadata (like type, count, presence of data). ACCESS can be<br>  combined with one of the write operations INSERT, DELETE or UPDATE. Any<br>  write that&#39;s not an INSERT or a DELETE would be UPDATE.</p>\n<ul>\n<li><p><code>VALKEYMODULE_CMD_KEY_ACCESS</code>: Returns, copies or uses the user data<br>from the value of the key.</p>\n</li>\n<li><p><code>VALKEYMODULE_CMD_KEY_UPDATE</code>: Updates data to the value, new value may<br>depend on the old value.</p>\n</li>\n<li><p><code>VALKEYMODULE_CMD_KEY_INSERT</code>: Adds data to the value with no chance of<br>modification or deletion of existing data.</p>\n</li>\n<li><p><code>VALKEYMODULE_CMD_KEY_DELETE</code>: Explicitly deletes some content from the<br>value of the key.</p>\n</li>\n</ul>\n<p>  Other flags:</p>\n<ul>\n<li><p><code>VALKEYMODULE_CMD_KEY_NOT_KEY</code>: The key is not actually a key, but<br>should be routed in cluster mode as if it was a key.</p>\n</li>\n<li><p><code>VALKEYMODULE_CMD_KEY_INCOMPLETE</code>: The keyspec might not point out all<br>the keys it should cover.</p>\n</li>\n<li><p><code>VALKEYMODULE_CMD_KEY_VARIABLE_FLAGS</code>: Some keys might have different<br>flags depending on arguments.</p>\n</li>\n</ul>\n</li>\n<li><p><code>args</code>: An array of <code>ValkeyModuleCommandArg</code>, terminated by an element memset<br>to zero. <code>ValkeyModuleCommandArg</code> is a structure with at the fields described<br>below.</p>\n<pre><code>  typedef struct ValkeyModuleCommandArg {\n      const char *name;\n      ValkeyModuleCommandArgType type;\n      int key_spec_index;\n      const char *token;\n      const char *summary;\n      const char *since;\n      int flags;\n      struct ValkeyModuleCommandArg *subargs;\n  } ValkeyModuleCommandArg;\n</code></pre>\n<p>  Explanation of the fields:</p>\n<ul>\n<li><p><code>name</code>: Name of the argument.</p>\n</li>\n<li><p><code>type</code>: The type of the argument. See below for details. The types<br><code>VALKEYMODULE_ARG_TYPE_ONEOF</code> and <code>VALKEYMODULE_ARG_TYPE_BLOCK</code> require<br>an argument to have sub-arguments, i.e. <code>subargs</code>.</p>\n</li>\n<li><p><code>key_spec_index</code>: If the <code>type</code> is <code>VALKEYMODULE_ARG_TYPE_KEY</code> you must<br>provide the index of the key-spec associated with this argument. See<br><code>key_specs</code> above. If the argument is not a key, you may specify -1.</p>\n</li>\n<li><p><code>token</code>: The token preceding the argument (optional). Example: the<br>argument <code>seconds</code> in <code>SET</code> has a token <code>EX</code>. If the argument consists<br>of only a token (for example <code>NX</code> in <code>SET</code>) the type should be<br><code>VALKEYMODULE_ARG_TYPE_PURE_TOKEN</code> and <code>value</code> should be NULL.</p>\n</li>\n<li><p><code>summary</code>: A short description of the argument (optional).</p>\n</li>\n<li><p><code>since</code>: The first version which included this argument (optional).</p>\n</li>\n<li><p><code>flags</code>: A bitwise or of the macros <code>VALKEYMODULE_CMD_ARG_*</code>. See below.</p>\n</li>\n<li><p><code>value</code>: The display-value of the argument. This string is what should<br>be displayed when creating the command syntax from the output of<br><code>COMMAND</code>. If <code>token</code> is not NULL, it should also be displayed.</p>\n</li>\n</ul>\n<p>  Explanation of <code>ValkeyModuleCommandArgType</code>:</p>\n<ul>\n<li><code>VALKEYMODULE_ARG_TYPE_STRING</code>: String argument.</li>\n<li><code>VALKEYMODULE_ARG_TYPE_INTEGER</code>: Integer argument.</li>\n<li><code>VALKEYMODULE_ARG_TYPE_DOUBLE</code>: Double-precision float argument.</li>\n<li><code>VALKEYMODULE_ARG_TYPE_KEY</code>: String argument representing a keyname.</li>\n<li><code>VALKEYMODULE_ARG_TYPE_PATTERN</code>: String, but regex pattern.</li>\n<li><code>VALKEYMODULE_ARG_TYPE_UNIX_TIME</code>: Integer, but Unix timestamp.</li>\n<li><code>VALKEYMODULE_ARG_TYPE_PURE_TOKEN</code>: Argument doesn&#39;t have a placeholder.<br>It&#39;s just a token without a value. Example: the <code>KEEPTTL</code> option of the<br><code>SET</code> command.</li>\n<li><code>VALKEYMODULE_ARG_TYPE_ONEOF</code>: Used when the user can choose only one of<br>a few sub-arguments. Requires <code>subargs</code>. Example: the <code>NX</code> and <code>XX</code><br>options of <code>SET</code>.</li>\n<li><code>VALKEYMODULE_ARG_TYPE_BLOCK</code>: Used when one wants to group together<br>several sub-arguments, usually to apply something on all of them, like<br>making the entire group &quot;optional&quot;. Requires <code>subargs</code>. Example: the<br><code>LIMIT offset count</code> parameters in <code>ZRANGE</code>.</li>\n</ul>\n<p>  Explanation of the command argument flags:</p>\n<ul>\n<li><code>VALKEYMODULE_CMD_ARG_OPTIONAL</code>: The argument is optional (like GET in<br>the SET command).</li>\n<li><code>VALKEYMODULE_CMD_ARG_MULTIPLE</code>: The argument may repeat itself (like<br>key in DEL).</li>\n<li><code>VALKEYMODULE_CMD_ARG_MULTIPLE_TOKEN</code>: The argument may repeat itself,<br>and so does its token (like <code>GET pattern</code> in SORT).</li>\n</ul>\n</li>\n</ul>\n<p>On success <code>VALKEYMODULE_OK</code> is returned. On error <code>VALKEYMODULE_ERR</code> is returned<br>and <code>errno</code> is set to EINVAL if invalid info was provided or EEXIST if info<br>has already been set. If the info is invalid, a warning is logged explaining<br>which part of the info is invalid and why.</p>\n<p><span id=\"ValkeyModule_UpdateRuntimeArgs\"></span></p>\n<h3><code>ValkeyModule_UpdateRuntimeArgs</code></h3>\n<pre><code>int ValkeyModule_UpdateRuntimeArgs(ValkeyModuleCtx *ctx,\n                                   ValkeyModuleString **argv,\n                                   int argc);\n</code></pre>\n<p><strong>Available since:</strong> 8.1.0</p>\n<p><a href=\"#ValkeyModule_UpdateRuntimeArgs\"><code>ValkeyModule_UpdateRuntimeArgs</code></a> can be used to update the module argument values.<br>The function parameter &#39;argc&#39; indicates the number of updated arguments, and &#39;argv&#39;<br>represents the values of the updated arguments.<br>Once &#39;CONFIG REWRITE&#39; command is called, the updated argument values can be saved into conf file.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"section-module-information-and-time-measurement\"></span></p>\n<h2>Module information and time measurement</h2>\n<p><span id=\"ValkeyModule_IsModuleNameBusy\"></span></p>\n<h3><code>ValkeyModule_IsModuleNameBusy</code></h3>\n<pre><code>int ValkeyModule_IsModuleNameBusy(const char *name);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.3</p>\n<p>Return non-zero if the module name is busy.<br>Otherwise zero is returned.</p>\n<p><span id=\"ValkeyModule_Milliseconds\"></span></p>\n<h3><code>ValkeyModule_Milliseconds</code></h3>\n<pre><code>mstime_t ValkeyModule_Milliseconds(void);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return the current UNIX time in milliseconds.</p>\n<p><span id=\"ValkeyModule_MonotonicMicroseconds\"></span></p>\n<h3><code>ValkeyModule_MonotonicMicroseconds</code></h3>\n<pre><code>uint64_t ValkeyModule_MonotonicMicroseconds(void);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Return counter of micro-seconds relative to an arbitrary point in time.</p>\n<p><span id=\"ValkeyModule_Microseconds\"></span></p>\n<h3><code>ValkeyModule_Microseconds</code></h3>\n<pre><code>ustime_t ValkeyModule_Microseconds(void);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Return the current UNIX time in microseconds</p>\n<p><span id=\"ValkeyModule_CachedMicroseconds\"></span></p>\n<h3><code>ValkeyModule_CachedMicroseconds</code></h3>\n<pre><code>ustime_t ValkeyModule_CachedMicroseconds(void);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Return the cached UNIX time in microseconds.<br>It is updated in the server cron job and before executing a command.<br>It is useful for complex call stacks, such as a command causing a<br>key space notification, causing a module to execute a <a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call</code></a>,<br>causing another notification, etc.<br>It makes sense that all this callbacks would use the same clock.</p>\n<p><span id=\"ValkeyModule_BlockedClientMeasureTimeStart\"></span></p>\n<h3><code>ValkeyModule_BlockedClientMeasureTimeStart</code></h3>\n<pre><code>int ValkeyModule_BlockedClientMeasureTimeStart(ValkeyModuleBlockedClient *bc);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Mark a point in time that will be used as the start time to calculate<br>the elapsed execution time when <a href=\"#ValkeyModule_BlockedClientMeasureTimeEnd\"><code>ValkeyModule_BlockedClientMeasureTimeEnd()</code></a> is called.<br>Within the same command, you can call multiple times<br><a href=\"#ValkeyModule_BlockedClientMeasureTimeStart\"><code>ValkeyModule_BlockedClientMeasureTimeStart()</code></a> and <a href=\"#ValkeyModule_BlockedClientMeasureTimeEnd\"><code>ValkeyModule_BlockedClientMeasureTimeEnd()</code></a><br>to accumulate independent time intervals to the background duration.<br>This method always return <code>VALKEYMODULE_OK</code>.</p>\n<p>This function is not thread safe, If used in module thread and blocked callback (possibly main thread)<br>simultaneously, it&#39;s recommended to protect them with lock owned by caller instead of GIL.</p>\n<p><span id=\"ValkeyModule_BlockedClientMeasureTimeEnd\"></span></p>\n<h3><code>ValkeyModule_BlockedClientMeasureTimeEnd</code></h3>\n<pre><code>int ValkeyModule_BlockedClientMeasureTimeEnd(ValkeyModuleBlockedClient *bc);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Mark a point in time that will be used as the end time<br>to calculate the elapsed execution time.<br>On success <code>VALKEYMODULE_OK</code> is returned.<br>This method only returns <code>VALKEYMODULE_ERR</code> if no start time was<br>previously defined ( meaning <a href=\"#ValkeyModule_BlockedClientMeasureTimeStart\"><code>ValkeyModule_BlockedClientMeasureTimeStart</code></a> was not called ).</p>\n<p>This function is not thread safe, If used in module thread and blocked callback (possibly main thread)<br>simultaneously, it&#39;s recommended to protect them with lock owned by caller instead of GIL.</p>\n<p><span id=\"ValkeyModule_Yield\"></span></p>\n<h3><code>ValkeyModule_Yield</code></h3>\n<pre><code>void ValkeyModule_Yield(ValkeyModuleCtx *ctx,\n                        int flags,\n                        const char *busy_reply);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>This API allows modules to let the server process background tasks, and some<br>commands during long blocking execution of a module command.<br>The module can call this API periodically.<br>The flags is a bit mask of these:</p>\n<ul>\n<li><code>VALKEYMODULE_YIELD_FLAG_NONE</code>: No special flags, can perform some background<br>                           operations, but not process client commands.</li>\n<li><code>VALKEYMODULE_YIELD_FLAG_CLIENTS</code>: The server can also process client commands.</li>\n</ul>\n<p>The <code>busy_reply</code> argument is optional, and can be used to control the verbose<br>error string after the <code>-BUSY</code> error code.</p>\n<p>When the <code>VALKEYMODULE_YIELD_FLAG_CLIENTS</code> is used, the server will only start<br>processing client commands after the time defined by the<br><code>busy-reply-threshold</code> config, in which case the server will start rejecting most<br>commands with <code>-BUSY</code> error, but allow the ones marked with the <code>allow-busy</code><br>flag to be executed.<br>This API can also be used in thread safe context (while locked), and during<br>loading (in the <code>rdb_load</code> callback, in which case it&#39;ll reject commands with<br>the -LOADING error)</p>\n<p><span id=\"ValkeyModule_SetModuleOptions\"></span></p>\n<h3><code>ValkeyModule_SetModuleOptions</code></h3>\n<pre><code>void ValkeyModule_SetModuleOptions(ValkeyModuleCtx *ctx, int options);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Set flags defining capabilities or behavior bit flags.</p>\n<p><code>VALKEYMODULE_OPTIONS_HANDLE_IO_ERRORS</code>:<br>Generally, modules don&#39;t need to bother with this, as the process will just<br>terminate if a read error happens, however, setting this flag would allow<br>repl-diskless-load to work if enabled.<br>The module should use <a href=\"#ValkeyModule_IsIOError\"><code>ValkeyModule_IsIOError</code></a> after reads, before using the<br>data that was read, and in case of error, propagate it upwards, and also be<br>able to release the partially populated value and all it&#39;s allocations.</p>\n<p><code>VALKEYMODULE_OPTION_NO_IMPLICIT_SIGNAL_MODIFIED</code>:<br>See <a href=\"#ValkeyModule_SignalModifiedKey\"><code>ValkeyModule_SignalModifiedKey()</code></a>.</p>\n<p><code>VALKEYMODULE_OPTIONS_HANDLE_REPL_ASYNC_LOAD</code>:<br>Setting this flag indicates module awareness of diskless async replication (repl-diskless-load=swapdb)<br>and that the server could be serving reads during replication instead of blocking with LOADING status.</p>\n<p><code>VALKEYMODULE_OPTIONS_ALLOW_NESTED_KEYSPACE_NOTIFICATIONS</code>:<br>Declare that the module wants to get nested key-space notifications.<br>By default, the server will not fire key-space notifications that happened inside<br>a key-space notification callback. This flag allows to change this behavior<br>and fire nested key-space notifications. Notice: if enabled, the module<br>should protected itself from infinite recursion.</p>\n<p><code>VALKEYMODULE_OPTIONS_SKIP_COMMAND_VALIDATION</code>:<br>When set, this option allows the module to skip command validation.<br>This is useful in scenarios where the module needs to bypass<br>command validation for specific operations<br>to reduce overhead or handle trusted custom command logic.<br><a href=\"#ValkeyModule_Replicate\"><code>ValkeyModule_Replicate</code></a> and <a href=\"#ValkeyModule_EmitAOF\"><code>ValkeyModule_EmitAOF</code></a><br>are affected by this option, allowing them to operate without<br>command validation check.</p>\n<p><span id=\"ValkeyModule_SignalModifiedKey\"></span></p>\n<h3><code>ValkeyModule_SignalModifiedKey</code></h3>\n<pre><code>int ValkeyModule_SignalModifiedKey(ValkeyModuleCtx *ctx,\n                                   ValkeyModuleString *keyname);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Signals that the key is modified from user&#39;s perspective (i.e. invalidate WATCH<br>and client side caching).</p>\n<p>This is done automatically when a key opened for writing is closed, unless<br>the option <code>VALKEYMODULE_OPTION_NO_IMPLICIT_SIGNAL_MODIFIED</code> has been set using<br><a href=\"#ValkeyModule_SetModuleOptions\"><code>ValkeyModule_SetModuleOptions()</code></a>.</p>\n<p><span id=\"section-automatic-memory-management-for-modules\"></span></p>\n<h2>Automatic memory management for modules</h2>\n<p><span id=\"ValkeyModule_AutoMemory\"></span></p>\n<h3><code>ValkeyModule_AutoMemory</code></h3>\n<pre><code>void ValkeyModule_AutoMemory(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Enable automatic memory management.</p>\n<p>The function must be called as the first function of a command implementation<br>that wants to use automatic memory.</p>\n<p>When enabled, automatic memory management tracks and automatically frees<br>keys, call replies and <code>ValkeyModuleString</code> objects once the command returns. In most<br>cases this eliminates the need of calling the following functions:</p>\n<ol>\n<li><a href=\"#ValkeyModule_CloseKey\"><code>ValkeyModule_CloseKey()</code></a></li>\n<li><a href=\"#ValkeyModule_FreeCallReply\"><code>ValkeyModule_FreeCallReply()</code></a></li>\n<li><a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a></li>\n</ol>\n<p>These functions can still be used with automatic memory management enabled,<br>to optimize loops that make numerous allocations for example.</p>\n<p><span id=\"section-string-objects-apis\"></span></p>\n<h2>String objects APIs</h2>\n<p><span id=\"ValkeyModule_CreateString\"></span></p>\n<h3><code>ValkeyModule_CreateString</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_CreateString(ValkeyModuleCtx *ctx,\n                                              const char *ptr,\n                                              size_t len);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Create a new module string object. The returned string must be freed<br>with <a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a>, unless automatic memory is enabled.</p>\n<p>The string is created by copying the <code>len</code> bytes starting<br>at <code>ptr</code>. No reference is retained to the passed buffer.</p>\n<p>The module context &#39;ctx&#39; is optional and may be NULL if you want to create<br>a string out of the context scope. However in that case, the automatic<br>memory management will not be available, and the string memory must be<br>managed manually.</p>\n<p><span id=\"ValkeyModule_CreateStringPrintf\"></span></p>\n<h3><code>ValkeyModule_CreateStringPrintf</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_CreateStringPrintf(ValkeyModuleCtx *ctx,\n                                                    const char *fmt,\n                                                    ...);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Create a new module string object from a printf format and arguments.<br>The returned string must be freed with <a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a>, unless<br>automatic memory is enabled.</p>\n<p>The string is created using the sds formatter function <code>sdscatvprintf()</code>.</p>\n<p>The passed context &#39;ctx&#39; may be NULL if necessary, see the<br><a href=\"#ValkeyModule_CreateString\"><code>ValkeyModule_CreateString()</code></a> documentation for more info.</p>\n<p><span id=\"ValkeyModule_CreateStringFromLongLong\"></span></p>\n<h3><code>ValkeyModule_CreateStringFromLongLong</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_CreateStringFromLongLong(ValkeyModuleCtx *ctx,\n                                                          long long ll);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Like <a href=\"#ValkeyModule_CreateString\"><code>ValkeyModule_CreateString()</code></a>, but creates a string starting from a <code>long long</code><br>integer instead of taking a buffer and its length.</p>\n<p>The returned string must be released with <a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a> or by<br>enabling automatic memory management.</p>\n<p>The passed context &#39;ctx&#39; may be NULL if necessary, see the<br><a href=\"#ValkeyModule_CreateString\"><code>ValkeyModule_CreateString()</code></a> documentation for more info.</p>\n<p><span id=\"ValkeyModule_CreateStringFromULongLong\"></span></p>\n<h3><code>ValkeyModule_CreateStringFromULongLong</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_CreateStringFromULongLong(ValkeyModuleCtx *ctx,\n                                                           unsigned long long ull);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.3</p>\n<p>Like <a href=\"#ValkeyModule_CreateString\"><code>ValkeyModule_CreateString()</code></a>, but creates a string starting from a <code>unsigned long long</code><br>integer instead of taking a buffer and its length.</p>\n<p>The returned string must be released with <a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a> or by<br>enabling automatic memory management.</p>\n<p>The passed context &#39;ctx&#39; may be NULL if necessary, see the<br><a href=\"#ValkeyModule_CreateString\"><code>ValkeyModule_CreateString()</code></a> documentation for more info.</p>\n<p><span id=\"ValkeyModule_CreateStringFromDouble\"></span></p>\n<h3><code>ValkeyModule_CreateStringFromDouble</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_CreateStringFromDouble(ValkeyModuleCtx *ctx,\n                                                        double d);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Like <a href=\"#ValkeyModule_CreateString\"><code>ValkeyModule_CreateString()</code></a>, but creates a string starting from a double<br>instead of taking a buffer and its length.</p>\n<p>The returned string must be released with <a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a> or by<br>enabling automatic memory management.</p>\n<p><span id=\"ValkeyModule_CreateStringFromLongDouble\"></span></p>\n<h3><code>ValkeyModule_CreateStringFromLongDouble</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_CreateStringFromLongDouble(ValkeyModuleCtx *ctx,\n                                                            long double ld,\n                                                            int humanfriendly);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Like <a href=\"#ValkeyModule_CreateString\"><code>ValkeyModule_CreateString()</code></a>, but creates a string starting from a long<br>double.</p>\n<p>The returned string must be released with <a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a> or by<br>enabling automatic memory management.</p>\n<p>The passed context &#39;ctx&#39; may be NULL if necessary, see the<br><a href=\"#ValkeyModule_CreateString\"><code>ValkeyModule_CreateString()</code></a> documentation for more info.</p>\n<p><span id=\"ValkeyModule_CreateStringFromString\"></span></p>\n<h3><code>ValkeyModule_CreateStringFromString</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_CreateStringFromString(ValkeyModuleCtx *ctx,\n                                                        const ValkeyModuleString *str);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Like <a href=\"#ValkeyModule_CreateString\"><code>ValkeyModule_CreateString()</code></a>, but creates a string starting from another<br><code>ValkeyModuleString</code>.</p>\n<p>The returned string must be released with <a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a> or by<br>enabling automatic memory management.</p>\n<p>The passed context &#39;ctx&#39; may be NULL if necessary, see the<br><a href=\"#ValkeyModule_CreateString\"><code>ValkeyModule_CreateString()</code></a> documentation for more info.</p>\n<p><span id=\"ValkeyModule_CreateStringFromStreamID\"></span></p>\n<h3><code>ValkeyModule_CreateStringFromStreamID</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_CreateStringFromStreamID(ValkeyModuleCtx *ctx,\n                                                          const ValkeyModuleStreamID *id);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Creates a string from a stream ID. The returned string must be released with<br><a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a>, unless automatic memory is enabled.</p>\n<p>The passed context <code>ctx</code> may be NULL if necessary. See the<br><a href=\"#ValkeyModule_CreateString\"><code>ValkeyModule_CreateString()</code></a> documentation for more info.</p>\n<p><span id=\"ValkeyModule_FreeString\"></span></p>\n<h3><code>ValkeyModule_FreeString</code></h3>\n<pre><code>void ValkeyModule_FreeString(ValkeyModuleCtx *ctx, ValkeyModuleString *str);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Free a module string object obtained with one of the module API calls<br>that return new string objects.</p>\n<p>It is possible to call this function even when automatic memory management<br>is enabled. In that case the string will be released ASAP and removed<br>from the pool of string to release at the end.</p>\n<p>If the string was created with a NULL context &#39;ctx&#39;, it is also possible to<br>pass ctx as NULL when releasing the string (but passing a context will not<br>create any issue). Strings created with a context should be freed also passing<br>the context, so if you want to free a string out of context later, make sure<br>to create it using a NULL context.</p>\n<p>This API is not thread safe, access to these retained strings (if they originated<br>from a client command arguments) must be done with GIL locked.</p>\n<p><span id=\"ValkeyModule_RetainString\"></span></p>\n<h3><code>ValkeyModule_RetainString</code></h3>\n<pre><code>void ValkeyModule_RetainString(ValkeyModuleCtx *ctx, ValkeyModuleString *str);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Every call to this function, will make the string &#39;str&#39; requiring<br>an additional call to <a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a> in order to really<br>free the string. Note that the automatic freeing of the string obtained<br>enabling modules automatic memory management counts for one<br><a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a> call (it is just executed automatically).</p>\n<p>Normally you want to call this function when, at the same time<br>the following conditions are true:</p>\n<ol>\n<li>You have automatic memory management enabled.</li>\n<li>You want to create string objects.</li>\n<li>Those string objects you create need to live <em>after</em> the callback<br>function(for example a command implementation) creating them returns.</li>\n</ol>\n<p>Usually you want this in order to store the created string object<br>into your own data structure, for example when implementing a new data<br>type.</p>\n<p>Note that when memory management is turned off, you don&#39;t need<br>any call to RetainString() since creating a string will always result<br>into a string that lives after the callback function returns, if<br>no FreeString() call is performed.</p>\n<p>It is possible to call this function with a NULL context.</p>\n<p>When strings are going to be retained for an extended duration, it is good<br>practice to also call <a href=\"#ValkeyModule_TrimStringAllocation\"><code>ValkeyModule_TrimStringAllocation()</code></a> in order to<br>optimize memory usage.</p>\n<p>Threaded modules that reference retained strings from other threads <em>must</em><br>explicitly trim the allocation as soon as the string is retained. Not doing<br>so may result with automatic trimming which is not thread safe.</p>\n<p>This API is not thread safe, access to these retained strings (if they originated<br>from a client command arguments) must be done with GIL locked.</p>\n<p><span id=\"ValkeyModule_HoldString\"></span></p>\n<h3><code>ValkeyModule_HoldString</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_HoldString(ValkeyModuleCtx *ctx,\n                                            ValkeyModuleString *str);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.7</p>\n<p>This function can be used instead of <a href=\"#ValkeyModule_RetainString\"><code>ValkeyModule_RetainString()</code></a>.<br>The main difference between the two is that this function will always<br>succeed, whereas <a href=\"#ValkeyModule_RetainString\"><code>ValkeyModule_RetainString()</code></a> may fail because of an<br>assertion.</p>\n<p>The function returns a pointer to <code>ValkeyModuleString</code>, which is owned<br>by the caller. It requires a call to <a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a> to free<br>the string when automatic memory management is disabled for the context.<br>When automatic memory management is enabled, you can either call<br><a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a> or let the automation free it.</p>\n<p>This function is more efficient than <a href=\"#ValkeyModule_CreateStringFromString\"><code>ValkeyModule_CreateStringFromString()</code></a><br>because whenever possible, it avoids copying the underlying<br><code>ValkeyModuleString</code>. The disadvantage of using this function is that it<br>might not be possible to use <a href=\"#ValkeyModule_StringAppendBuffer\"><code>ValkeyModule_StringAppendBuffer()</code></a> on the<br>returned <code>ValkeyModuleString</code>.</p>\n<p>It is possible to call this function with a NULL context.</p>\n<p>When strings are going to be held for an extended duration, it is good<br>practice to also call <a href=\"#ValkeyModule_TrimStringAllocation\"><code>ValkeyModule_TrimStringAllocation()</code></a> in order to<br>optimize memory usage.</p>\n<p>Threaded modules that reference held strings from other threads <em>must</em><br>explicitly trim the allocation as soon as the string is held. Not doing<br>so may result with automatic trimming which is not thread safe.</p>\n<p>This API is not thread safe, access to these retained strings (if they originated<br>from a client command arguments) must be done with GIL locked.</p>\n<p><span id=\"ValkeyModule_StringPtrLen\"></span></p>\n<h3><code>ValkeyModule_StringPtrLen</code></h3>\n<pre><code>const char *ValkeyModule_StringPtrLen(const ValkeyModuleString *str,\n                                      size_t *len);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Given a string module object, this function returns the string pointer<br>and length of the string. The returned pointer and length should only<br>be used for read only accesses and never modified.</p>\n<p><span id=\"ValkeyModule_StringToLongLong\"></span></p>\n<h3><code>ValkeyModule_StringToLongLong</code></h3>\n<pre><code>int ValkeyModule_StringToLongLong(const ValkeyModuleString *str,\n                                  long long *ll);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Convert the string into a <code>long long</code> integer, storing it at <code>*ll</code>.<br>Returns <code>VALKEYMODULE_OK</code> on success. If the string can&#39;t be parsed<br>as a valid, strict <code>long long</code> (no spaces before/after), <code>VALKEYMODULE_ERR</code><br>is returned.</p>\n<p><span id=\"ValkeyModule_StringToULongLong\"></span></p>\n<h3><code>ValkeyModule_StringToULongLong</code></h3>\n<pre><code>int ValkeyModule_StringToULongLong(const ValkeyModuleString *str,\n                                   unsigned long long *ull);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.3</p>\n<p>Convert the string into a <code>unsigned long long</code> integer, storing it at <code>*ull</code>.<br>Returns <code>VALKEYMODULE_OK</code> on success. If the string can&#39;t be parsed<br>as a valid, strict <code>unsigned long long</code> (no spaces before/after), <code>VALKEYMODULE_ERR</code><br>is returned.</p>\n<p><span id=\"ValkeyModule_StringToDouble\"></span></p>\n<h3><code>ValkeyModule_StringToDouble</code></h3>\n<pre><code>int ValkeyModule_StringToDouble(const ValkeyModuleString *str, double *d);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Convert the string into a double, storing it at <code>*d</code>.<br>Returns <code>VALKEYMODULE_OK</code> on success or <code>VALKEYMODULE_ERR</code> if the string is<br>not a valid string representation of a double value.</p>\n<p><span id=\"ValkeyModule_StringToLongDouble\"></span></p>\n<h3><code>ValkeyModule_StringToLongDouble</code></h3>\n<pre><code>int ValkeyModule_StringToLongDouble(const ValkeyModuleString *str,\n                                    long double *ld);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Convert the string into a long double, storing it at <code>*ld</code>.<br>Returns <code>VALKEYMODULE_OK</code> on success or <code>VALKEYMODULE_ERR</code> if the string is<br>not a valid string representation of a double value.</p>\n<p><span id=\"ValkeyModule_StringToStreamID\"></span></p>\n<h3><code>ValkeyModule_StringToStreamID</code></h3>\n<pre><code>int ValkeyModule_StringToStreamID(const ValkeyModuleString *str,\n                                  ValkeyModuleStreamID *id);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Convert the string into a stream ID, storing it at <code>*id</code>.<br>Returns <code>VALKEYMODULE_OK</code> on success and returns <code>VALKEYMODULE_ERR</code> if the string<br>is not a valid string representation of a stream ID. The special IDs &quot;+&quot; and<br>&quot;-&quot; are allowed.</p>\n<p><span id=\"ValkeyModule_StringCompare\"></span></p>\n<h3><code>ValkeyModule_StringCompare</code></h3>\n<pre><code>int ValkeyModule_StringCompare(const ValkeyModuleString *a,\n                               const ValkeyModuleString *b);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Compare two string objects, returning -1, 0 or 1 respectively if<br>a &lt; b, a == b, a &gt; b. Strings are compared byte by byte as two<br>binary blobs without any encoding care / collation attempt.</p>\n<p><span id=\"ValkeyModule_StringAppendBuffer\"></span></p>\n<h3><code>ValkeyModule_StringAppendBuffer</code></h3>\n<pre><code>int ValkeyModule_StringAppendBuffer(ValkeyModuleCtx *ctx,\n                                    ValkeyModuleString *str,\n                                    const char *buf,\n                                    size_t len);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Append the specified buffer to the string &#39;str&#39;. The string must be a<br>string created by the user that is referenced only a single time, otherwise<br><code>VALKEYMODULE_ERR</code> is returned and the operation is not performed.</p>\n<p><span id=\"ValkeyModule_TrimStringAllocation\"></span></p>\n<h3><code>ValkeyModule_TrimStringAllocation</code></h3>\n<pre><code>void ValkeyModule_TrimStringAllocation(ValkeyModuleString *str);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Trim possible excess memory allocated for a <code>ValkeyModuleString</code>.</p>\n<p>Sometimes a <code>ValkeyModuleString</code> may have more memory allocated for<br>it than required, typically for argv arguments that were constructed<br>from network buffers. This function optimizes such strings by reallocating<br>their memory, which is useful for strings that are not short lived but<br>retained for an extended duration.</p>\n<p>This operation is <em>not thread safe</em> and should only be called when<br>no concurrent access to the string is guaranteed. Using it for an argv<br>string in a module command before the string is potentially available<br>to other threads is generally safe.</p>\n<p>Currently, the server may also automatically trim retained strings when a<br>module command returns. However, doing this explicitly should still be<br>a preferred option:</p>\n<ol>\n<li>Future versions of the server may abandon auto-trimming.</li>\n<li>Auto-trimming as currently implemented is <em>not thread safe</em>.<br>A background thread manipulating a recently retained string may end up<br>in a race condition with the auto-trim, which could result with<br>data corruption.</li>\n</ol>\n<p><span id=\"section-reply-apis\"></span></p>\n<h2>Reply APIs</h2>\n<p>These functions are used for sending replies to the client.</p>\n<p>Most functions always return <code>VALKEYMODULE_OK</code> so you can use it with<br>&#39;return&#39; in order to return from the command implementation with:</p>\n<pre><code>if (... some condition ...)\n    return ValkeyModule_ReplyWithLongLong(ctx,mycount);\n</code></pre>\n<h3>Reply with collection functions</h3>\n<p>After starting a collection reply, the module must make calls to other<br><code>ReplyWith*</code> style functions in order to emit the elements of the collection.<br>Collection types include: Array, Map, Set and Attribute.</p>\n<p>When producing collections with a number of elements that is not known<br>beforehand, the function can be called with a special flag<br><code>VALKEYMODULE_POSTPONED_LEN</code> (<code>VALKEYMODULE_POSTPONED_ARRAY_LEN</code> in the past),<br>and the actual number of elements can be later set with <code>ValkeyModule_ReplySet</code>*Length()<br>call (which will set the latest &quot;open&quot; count if there are multiple ones).</p>\n<p><span id=\"ValkeyModule_WrongArity\"></span></p>\n<h3><code>ValkeyModule_WrongArity</code></h3>\n<pre><code>int ValkeyModule_WrongArity(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Send an error about the number of arguments given to the command,<br>citing the command name in the error message. Returns <code>VALKEYMODULE_OK</code>.</p>\n<p>Example:</p>\n<pre><code>if (argc != 3) return ValkeyModule_WrongArity(ctx);\n</code></pre>\n<p><span id=\"ValkeyModule_ReplyWithLongLong\"></span></p>\n<h3><code>ValkeyModule_ReplyWithLongLong</code></h3>\n<pre><code>int ValkeyModule_ReplyWithLongLong(ValkeyModuleCtx *ctx, long long ll);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Send an integer reply to the client, with the specified <code>long long</code> value.<br>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithError\"></span></p>\n<h3><code>ValkeyModule_ReplyWithError</code></h3>\n<pre><code>int ValkeyModule_ReplyWithError(ValkeyModuleCtx *ctx, const char *err);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Reply with the error &#39;err&#39;.</p>\n<p>Note that &#39;err&#39; must contain all the error, including<br>the initial error code. The function only provides the initial &quot;-&quot;, so<br>the usage is, for example:</p>\n<pre><code>ValkeyModule_ReplyWithError(ctx,&quot;ERR Wrong Type&quot;);\n</code></pre>\n<p>and not just:</p>\n<pre><code>ValkeyModule_ReplyWithError(ctx,&quot;Wrong Type&quot;);\n</code></pre>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithErrorFormat\"></span></p>\n<h3><code>ValkeyModule_ReplyWithErrorFormat</code></h3>\n<pre><code>int ValkeyModule_ReplyWithErrorFormat(ValkeyModuleCtx *ctx,\n                                      const char *fmt,\n                                      ...);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Reply with the error create from a printf format and arguments.</p>\n<p>Note that &#39;fmt&#39; must contain all the error, including<br>the initial error code. The function only provides the initial &quot;-&quot;, so<br>the usage is, for example:</p>\n<pre><code>ValkeyModule_ReplyWithErrorFormat(ctx,&quot;ERR Wrong Type: %s&quot;,type);\n</code></pre>\n<p>and not just:</p>\n<pre><code>ValkeyModule_ReplyWithErrorFormat(ctx,&quot;Wrong Type: %s&quot;,type);\n</code></pre>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithSimpleString\"></span></p>\n<h3><code>ValkeyModule_ReplyWithSimpleString</code></h3>\n<pre><code>int ValkeyModule_ReplyWithSimpleString(ValkeyModuleCtx *ctx, const char *msg);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Reply with a simple string (<code>+... \\r\\n</code> in RESP protocol). This replies<br>are suitable only when sending a small non-binary string with small<br>overhead, like &quot;OK&quot; or similar replies.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithArray\"></span></p>\n<h3><code>ValkeyModule_ReplyWithArray</code></h3>\n<pre><code>int ValkeyModule_ReplyWithArray(ValkeyModuleCtx *ctx, long len);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Reply with an array type of &#39;len&#39; elements.</p>\n<p>After starting an array reply, the module must make <code>len</code> calls to other<br><code>ReplyWith*</code> style functions in order to emit the elements of the array.<br>See Reply APIs section for more details.</p>\n<p>Use <a href=\"#ValkeyModule_ReplySetArrayLength\"><code>ValkeyModule_ReplySetArrayLength()</code></a> to set deferred length.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithMap\"></span></p>\n<h3><code>ValkeyModule_ReplyWithMap</code></h3>\n<pre><code>int ValkeyModule_ReplyWithMap(ValkeyModuleCtx *ctx, long len);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Reply with a RESP3 Map type of &#39;len&#39; pairs.<br>Visit <a href=\"https://valkey.io/topics/protocol\">https://valkey.io/topics/protocol</a> for more info about RESP3.</p>\n<p>After starting a map reply, the module must make <code>len*2</code> calls to other<br><code>ReplyWith*</code> style functions in order to emit the elements of the map.<br>See Reply APIs section for more details.</p>\n<p>If the connected client is using RESP2, the reply will be converted to a flat<br>array.</p>\n<p>Use <a href=\"#ValkeyModule_ReplySetMapLength\"><code>ValkeyModule_ReplySetMapLength()</code></a> to set deferred length.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithSet\"></span></p>\n<h3><code>ValkeyModule_ReplyWithSet</code></h3>\n<pre><code>int ValkeyModule_ReplyWithSet(ValkeyModuleCtx *ctx, long len);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Reply with a RESP3 Set type of &#39;len&#39; elements.<br>Visit <a href=\"https://valkey.io/topics/protocol\">https://valkey.io/topics/protocol</a> for more info about RESP3.</p>\n<p>After starting a set reply, the module must make <code>len</code> calls to other<br><code>ReplyWith*</code> style functions in order to emit the elements of the set.<br>See Reply APIs section for more details.</p>\n<p>If the connected client is using RESP2, the reply will be converted to an<br>array type.</p>\n<p>Use <a href=\"#ValkeyModule_ReplySetSetLength\"><code>ValkeyModule_ReplySetSetLength()</code></a> to set deferred length.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithAttribute\"></span></p>\n<h3><code>ValkeyModule_ReplyWithAttribute</code></h3>\n<pre><code>int ValkeyModule_ReplyWithAttribute(ValkeyModuleCtx *ctx, long len);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Add attributes (metadata) to the reply. Should be done before adding the<br>actual reply. see <a href=\"https://valkey.io/topics/protocol#attribute-type\">https://valkey.io/topics/protocol#attribute-type</a></p>\n<p>After starting an attribute&#39;s reply, the module must make <code>len*2</code> calls to other<br><code>ReplyWith*</code> style functions in order to emit the elements of the attribute map.<br>See Reply APIs section for more details.</p>\n<p>Use <a href=\"#ValkeyModule_ReplySetAttributeLength\"><code>ValkeyModule_ReplySetAttributeLength()</code></a> to set deferred length.</p>\n<p>Not supported by RESP2 and will return <code>VALKEYMODULE_ERR</code>, otherwise<br>the function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithNullArray\"></span></p>\n<h3><code>ValkeyModule_ReplyWithNullArray</code></h3>\n<pre><code>int ValkeyModule_ReplyWithNullArray(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Reply to the client with a null array, simply null in RESP3,<br>null array in RESP2.</p>\n<p>Note: In RESP3 there&#39;s no difference between Null reply and<br>NullArray reply, so to prevent ambiguity it&#39;s better to avoid<br>using this API and use <a href=\"#ValkeyModule_ReplyWithNull\"><code>ValkeyModule_ReplyWithNull</code></a> instead.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithEmptyArray\"></span></p>\n<h3><code>ValkeyModule_ReplyWithEmptyArray</code></h3>\n<pre><code>int ValkeyModule_ReplyWithEmptyArray(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Reply to the client with an empty array.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplySetArrayLength\"></span></p>\n<h3><code>ValkeyModule_ReplySetArrayLength</code></h3>\n<pre><code>void ValkeyModule_ReplySetArrayLength(ValkeyModuleCtx *ctx, long len);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>When <a href=\"#ValkeyModule_ReplyWithArray\"><code>ValkeyModule_ReplyWithArray()</code></a> is used with the argument<br><code>VALKEYMODULE_POSTPONED_LEN</code>, because we don&#39;t know beforehand the number<br>of items we are going to output as elements of the array, this function<br>will take care to set the array length.</p>\n<p>Since it is possible to have multiple array replies pending with unknown<br>length, this function guarantees to always set the latest array length<br>that was created in a postponed way.</p>\n<p>For example in order to output an array like [1,[10,20,30]] we<br>could write:</p>\n<pre><code> ValkeyModule_ReplyWithArray(ctx,VALKEYMODULE_POSTPONED_LEN);\n ValkeyModule_ReplyWithLongLong(ctx,1);\n ValkeyModule_ReplyWithArray(ctx,VALKEYMODULE_POSTPONED_LEN);\n ValkeyModule_ReplyWithLongLong(ctx,10);\n ValkeyModule_ReplyWithLongLong(ctx,20);\n ValkeyModule_ReplyWithLongLong(ctx,30);\n ValkeyModule_ReplySetArrayLength(ctx,3); // Set len of 10,20,30 array.\n ValkeyModule_ReplySetArrayLength(ctx,2); // Set len of top array\n</code></pre>\n<p>Note that in the above example there is no reason to postpone the array<br>length, since we produce a fixed number of elements, but in the practice<br>the code may use an iterator or other ways of creating the output so<br>that is not easy to calculate in advance the number of elements.</p>\n<p><span id=\"ValkeyModule_ReplySetMapLength\"></span></p>\n<h3><code>ValkeyModule_ReplySetMapLength</code></h3>\n<pre><code>void ValkeyModule_ReplySetMapLength(ValkeyModuleCtx *ctx, long len);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Very similar to <a href=\"#ValkeyModule_ReplySetArrayLength\"><code>ValkeyModule_ReplySetArrayLength</code></a> except <code>len</code> should<br>exactly half of the number of <code>ReplyWith*</code> functions called in the<br>context of the map.<br>Visit <a href=\"https://valkey.io/topics/protocol\">https://valkey.io/topics/protocol</a> for more info about RESP3.</p>\n<p><span id=\"ValkeyModule_ReplySetSetLength\"></span></p>\n<h3><code>ValkeyModule_ReplySetSetLength</code></h3>\n<pre><code>void ValkeyModule_ReplySetSetLength(ValkeyModuleCtx *ctx, long len);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Very similar to <a href=\"#ValkeyModule_ReplySetArrayLength\"><code>ValkeyModule_ReplySetArrayLength</code></a><br>Visit <a href=\"https://valkey.io/topics/protocol\">https://valkey.io/topics/protocol</a> for more info about RESP3.</p>\n<p><span id=\"ValkeyModule_ReplySetAttributeLength\"></span></p>\n<h3><code>ValkeyModule_ReplySetAttributeLength</code></h3>\n<pre><code>void ValkeyModule_ReplySetAttributeLength(ValkeyModuleCtx *ctx, long len);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Very similar to <a href=\"#ValkeyModule_ReplySetMapLength\"><code>ValkeyModule_ReplySetMapLength</code></a><br>Visit <a href=\"https://valkey.io/topics/protocol\">https://valkey.io/topics/protocol</a> for more info about RESP3.</p>\n<p>Must not be called if <a href=\"#ValkeyModule_ReplyWithAttribute\"><code>ValkeyModule_ReplyWithAttribute</code></a> returned an error.</p>\n<p><span id=\"ValkeyModule_ReplyWithStringBuffer\"></span></p>\n<h3><code>ValkeyModule_ReplyWithStringBuffer</code></h3>\n<pre><code>int ValkeyModule_ReplyWithStringBuffer(ValkeyModuleCtx *ctx,\n                                       const char *buf,\n                                       size_t len);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Reply with a bulk string, taking in input a C buffer pointer and length.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithCString\"></span></p>\n<h3><code>ValkeyModule_ReplyWithCString</code></h3>\n<pre><code>int ValkeyModule_ReplyWithCString(ValkeyModuleCtx *ctx, const char *buf);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.6</p>\n<p>Reply with a bulk string, taking in input a C buffer pointer that is<br>assumed to be null-terminated.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithString\"></span></p>\n<h3><code>ValkeyModule_ReplyWithString</code></h3>\n<pre><code>int ValkeyModule_ReplyWithString(ValkeyModuleCtx *ctx,\n                                 ValkeyModuleString *str);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Reply with a bulk string, taking in input a <code>ValkeyModuleString</code> object.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithEmptyString\"></span></p>\n<h3><code>ValkeyModule_ReplyWithEmptyString</code></h3>\n<pre><code>int ValkeyModule_ReplyWithEmptyString(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Reply with an empty string.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithVerbatimStringType\"></span></p>\n<h3><code>ValkeyModule_ReplyWithVerbatimStringType</code></h3>\n<pre><code>int ValkeyModule_ReplyWithVerbatimStringType(ValkeyModuleCtx *ctx,\n                                             const char *buf,\n                                             size_t len,\n                                             const char *ext);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Reply with a binary safe string, which should not be escaped or filtered<br>taking in input a C buffer pointer, length and a 3 character type/extension.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithVerbatimString\"></span></p>\n<h3><code>ValkeyModule_ReplyWithVerbatimString</code></h3>\n<pre><code>int ValkeyModule_ReplyWithVerbatimString(ValkeyModuleCtx *ctx,\n                                         const char *buf,\n                                         size_t len);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Reply with a binary safe string, which should not be escaped or filtered<br>taking in input a C buffer pointer and length.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithNull\"></span></p>\n<h3><code>ValkeyModule_ReplyWithNull</code></h3>\n<pre><code>int ValkeyModule_ReplyWithNull(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Reply to the client with a NULL.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithBool\"></span></p>\n<h3><code>ValkeyModule_ReplyWithBool</code></h3>\n<pre><code>int ValkeyModule_ReplyWithBool(ValkeyModuleCtx *ctx, int b);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Reply with a RESP3 Boolean type.<br>Visit <a href=\"https://valkey.io/topics/protocol\">https://valkey.io/topics/protocol</a> for more info about RESP3.</p>\n<p>In RESP3, this is boolean type<br>In RESP2, it&#39;s a string response of &quot;1&quot; and &quot;0&quot; for true and false respectively.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithCallReply\"></span></p>\n<h3><code>ValkeyModule_ReplyWithCallReply</code></h3>\n<pre><code>int ValkeyModule_ReplyWithCallReply(ValkeyModuleCtx *ctx,\n                                    ValkeyModuleCallReply *reply);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Reply exactly what a command returned us with <a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call()</code></a>.<br>This function is useful when we use <a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call()</code></a> in order to<br>execute some command, as we want to reply to the client exactly the<br>same reply we obtained by the command.</p>\n<p>Return:</p>\n<ul>\n<li><code>VALKEYMODULE_OK</code> on success.</li>\n<li><code>VALKEYMODULE_ERR</code> if the given reply is in RESP3 format but the client expects RESP2.<br>In case of an error, it&#39;s the module writer responsibility to translate the reply<br>to RESP2 (or handle it differently by returning an error). Notice that for<br>module writer convenience, it is possible to pass <code>0</code> as a parameter to the fmt<br>argument of <a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call</code></a> so that the <code>ValkeyModuleCallReply</code> will return in the same<br>protocol (RESP2 or RESP3) as set in the current client&#39;s context.</li>\n</ul>\n<p><span id=\"ValkeyModule_ReplyWithDouble\"></span></p>\n<h3><code>ValkeyModule_ReplyWithDouble</code></h3>\n<pre><code>int ValkeyModule_ReplyWithDouble(ValkeyModuleCtx *ctx, double d);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Reply with a RESP3 Double type.<br>Visit <a href=\"https://valkey.io/topics/protocol\">https://valkey.io/topics/protocol</a> for more info about RESP3.</p>\n<p>Send a string reply obtained converting the double &#39;d&#39; into a bulk string.<br>This function is basically equivalent to converting a double into<br>a string into a C buffer, and then calling the function<br><a href=\"#ValkeyModule_ReplyWithStringBuffer\"><code>ValkeyModule_ReplyWithStringBuffer()</code></a> with the buffer and length.</p>\n<p>In RESP3 the string is tagged as a double, while in RESP2 it&#39;s just a plain string<br>that the user will have to parse.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithBigNumber\"></span></p>\n<h3><code>ValkeyModule_ReplyWithBigNumber</code></h3>\n<pre><code>int ValkeyModule_ReplyWithBigNumber(ValkeyModuleCtx *ctx,\n                                    const char *bignum,\n                                    size_t len);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Reply with a RESP3 BigNumber type.<br>Visit <a href=\"https://valkey.io/topics/protocol\">https://valkey.io/topics/protocol</a> for more info about RESP3.</p>\n<p>In RESP3, this is a string of length <code>len</code> that is tagged as a BigNumber,<br>however, it&#39;s up to the caller to ensure that it&#39;s a valid BigNumber.<br>In RESP2, this is just a plain bulk string response.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithLongDouble\"></span></p>\n<h3><code>ValkeyModule_ReplyWithLongDouble</code></h3>\n<pre><code>int ValkeyModule_ReplyWithLongDouble(ValkeyModuleCtx *ctx, long double ld);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Send a string reply obtained converting the long double &#39;ld&#39; into a bulk<br>string. This function is basically equivalent to converting a long double<br>into a string into a C buffer, and then calling the function<br><a href=\"#ValkeyModule_ReplyWithStringBuffer\"><code>ValkeyModule_ReplyWithStringBuffer()</code></a> with the buffer and length.<br>The double string uses human readable formatting (see<br><code>addReplyHumanLongDouble</code> in networking.c).</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"section-commands-replication-api\"></span></p>\n<h2>Commands replication API</h2>\n<p><span id=\"ValkeyModule_Replicate\"></span></p>\n<h3><code>ValkeyModule_Replicate</code></h3>\n<pre><code>int ValkeyModule_Replicate(ValkeyModuleCtx *ctx,\n                           const char *cmdname,\n                           const char *fmt,\n                           ...);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Replicate the specified command and arguments to replicas and AOF, as effect<br>of execution of the calling command implementation.</p>\n<p>The replicated commands are always wrapped into the MULTI/EXEC that<br>contains all the commands replicated in a given module command<br>execution. However the commands replicated with <a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call()</code></a><br>are the first items, the ones replicated with <a href=\"#ValkeyModule_Replicate\"><code>ValkeyModule_Replicate()</code></a><br>will all follow before the EXEC.</p>\n<p>Modules should try to use one interface or the other.</p>\n<p>This command follows exactly the same interface of <a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call()</code></a>,<br>so a set of format specifiers must be passed, followed by arguments<br>matching the provided format specifiers.</p>\n<p>Please refer to <a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call()</code></a> for more information.</p>\n<p>Using the special &quot;A&quot; and &quot;R&quot; modifiers, the caller can exclude either<br>the AOF or the replicas from the propagation of the specified command.<br>Otherwise, by default, the command will be propagated in both channels.</p>\n<h4>Note about calling this function from a thread safe context:</h4>\n<p>Normally when you call this function from the callback implementing a<br>module command, or any other callback provided by the Module API,<br>The server will accumulate all the calls to this function in the context of<br>the callback, and will propagate all the commands wrapped in a MULTI/EXEC<br>transaction. However when calling this function from a threaded safe context<br>that can live an undefined amount of time, and can be locked/unlocked in<br>at will, the behavior is different: MULTI/EXEC wrapper is not emitted<br>and the command specified is inserted in the AOF and replication stream<br>immediately.</p>\n<h4>Return value</h4>\n<p>The command returns <code>VALKEYMODULE_ERR</code> if the format specifiers are invalid<br>or the command name does not belong to a known command.</p>\n<p><span id=\"ValkeyModule_ReplicateVerbatim\"></span></p>\n<h3><code>ValkeyModule_ReplicateVerbatim</code></h3>\n<pre><code>int ValkeyModule_ReplicateVerbatim(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>This function will replicate the command exactly as it was invoked<br>by the client. Note that this function will not wrap the command into<br>a MULTI/EXEC stanza, so it should not be mixed with other replication<br>commands.</p>\n<p>Basically this form of replication is useful when you want to propagate<br>the command to the replicas and AOF file exactly as it was called, since<br>the command can just be re-executed to deterministically re-create the<br>new state starting from the old one.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"section-db-and-key-apis-generic-api\"></span></p>\n<h2>DB and Key APIs – Generic API</h2>\n<p><span id=\"ValkeyModule_GetClientId\"></span></p>\n<h3><code>ValkeyModule_GetClientId</code></h3>\n<pre><code>unsigned long long ValkeyModule_GetClientId(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return the ID of the current client calling the currently active module<br>command. The returned ID has a few guarantees:</p>\n<ol>\n<li>The ID is different for each different client, so if the same client<br>executes a module command multiple times, it can be recognized as<br>having the same ID, otherwise the ID will be different.</li>\n<li>The ID increases monotonically. Clients connecting to the server later<br>are guaranteed to get IDs greater than any past ID previously seen.</li>\n</ol>\n<p>Valid IDs are from 1 to 2^64 - 1. If 0 is returned it means there is no way<br>to fetch the ID in the context the function was currently called.</p>\n<p>After obtaining the ID, it is possible to check if the command execution<br>is actually happening in the context of AOF loading, using this macro:</p>\n<pre><code> if (ValkeyModule_IsAOFClient(ValkeyModule_GetClientId(ctx)) {\n     // Handle it differently.\n }\n</code></pre>\n<p><span id=\"ValkeyModule_GetClientUserNameById\"></span></p>\n<h3><code>ValkeyModule_GetClientUserNameById</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_GetClientUserNameById(ValkeyModuleCtx *ctx,\n                                                       uint64_t id);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.1</p>\n<p>Return the ACL user name used by the client with the specified client ID.<br>Client ID can be obtained with <a href=\"#ValkeyModule_GetClientId\"><code>ValkeyModule_GetClientId()</code></a> API. If the client does not<br>exist, NULL is returned and errno is set to ENOENT. If the client isn&#39;t<br>using an ACL user, NULL is returned and errno is set to ENOTSUP</p>\n<p><span id=\"ValkeyModule_MustObeyClient\"></span></p>\n<h3><code>ValkeyModule_MustObeyClient</code></h3>\n<pre><code>int ValkeyModule_MustObeyClient(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 8.1.0</p>\n<p>Returns 1 if commands are arriving from the primary client or AOF client<br>and should never be rejected.<br>This check can be used in places such as skipping validation of commands<br>on replicas (to not diverge from primary) or from AOF files.<br>Returns 0 otherwise (and also if ctx or if the client is NULL).</p>\n<p><span id=\"ValkeyModule_GetClientInfoById\"></span></p>\n<h3><code>ValkeyModule_GetClientInfoById</code></h3>\n<pre><code>int ValkeyModule_GetClientInfoById(void *ci, uint64_t id);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Return information about the client with the specified ID (that was<br>previously obtained via the <a href=\"#ValkeyModule_GetClientId\"><code>ValkeyModule_GetClientId()</code></a> API). If the<br>client exists, <code>VALKEYMODULE_OK</code> is returned, otherwise <code>VALKEYMODULE_ERR</code><br>is returned.</p>\n<p>When the client exist and the <code>ci</code> pointer is not NULL, but points to<br>a structure of type <code>ValkeyModuleClientInfoV</code>1, previously initialized with<br>the correct <code>VALKEYMODULE_CLIENTINFO_INITIALIZER_V1</code>, the structure is populated<br>with the following fields:</p>\n<pre><code> uint64_t flags;         // VALKEYMODULE_CLIENTINFO_FLAG_*\n uint64_t id;            // Client ID\n char addr[46];          // IPv4 or IPv6 address.\n uint16_t port;          // TCP port.\n uint16_t db;            // Selected DB.\n</code></pre>\n<p>Note: the client ID is useless in the context of this call, since we<br>      already know, however the same structure could be used in other<br>      contexts where we don&#39;t know the client ID, yet the same structure<br>      is returned.</p>\n<p>With flags having the following meaning:</p>\n<pre><code>VALKEYMODULE_CLIENTINFO_FLAG_SSL          Client using SSL connection.\nVALKEYMODULE_CLIENTINFO_FLAG_PUBSUB       Client in Pub/Sub mode.\nVALKEYMODULE_CLIENTINFO_FLAG_BLOCKED      Client blocked in command.\nVALKEYMODULE_CLIENTINFO_FLAG_TRACKING     Client with keys tracking on.\nVALKEYMODULE_CLIENTINFO_FLAG_UNIXSOCKET   Client using unix domain socket.\nVALKEYMODULE_CLIENTINFO_FLAG_MULTI        Client in MULTI state.\n</code></pre>\n<p>However passing NULL is a way to just check if the client exists in case<br>we are not interested in any additional information.</p>\n<p>This is the correct usage when we want the client info structure<br>returned:</p>\n<pre><code> ValkeyModuleClientInfo ci = VALKEYMODULE_CLIENTINFO_INITIALIZER;\n int retval = ValkeyModule_GetClientInfoById(&amp;ci,client_id);\n if (retval == VALKEYMODULE_OK) {\n     printf(&quot;Address: %s\\n&quot;, ci.addr);\n }\n</code></pre>\n<p><span id=\"ValkeyModule_GetClientNameById\"></span></p>\n<h3><code>ValkeyModule_GetClientNameById</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_GetClientNameById(ValkeyModuleCtx *ctx,\n                                                   uint64_t id);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.3</p>\n<p>Returns the name of the client connection with the given ID.</p>\n<p>If the client ID does not exist or if the client has no name associated with<br>it, NULL is returned.</p>\n<p><span id=\"ValkeyModule_SetClientNameById\"></span></p>\n<h3><code>ValkeyModule_SetClientNameById</code></h3>\n<pre><code>int ValkeyModule_SetClientNameById(uint64_t id, ValkeyModuleString *name);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.3</p>\n<p>Sets the name of the client with the given ID. This is equivalent to the client calling<br><code>CLIENT SETNAME name</code>.</p>\n<p>Returns <code>VALKEYMODULE_OK</code> on success. On failure, <code>VALKEYMODULE_ERR</code> is returned<br>and errno is set as follows:</p>\n<ul>\n<li>ENOENT if the client does not exist</li>\n<li>EINVAL if the name contains invalid characters</li>\n</ul>\n<p><span id=\"ValkeyModule_PublishMessage\"></span></p>\n<h3><code>ValkeyModule_PublishMessage</code></h3>\n<pre><code>int ValkeyModule_PublishMessage(ValkeyModuleCtx *ctx,\n                                ValkeyModuleString *channel,\n                                ValkeyModuleString *message);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Publish a message to subscribers (see PUBLISH command).</p>\n<p><span id=\"ValkeyModule_PublishMessageShard\"></span></p>\n<h3><code>ValkeyModule_PublishMessageShard</code></h3>\n<pre><code>int ValkeyModule_PublishMessageShard(ValkeyModuleCtx *ctx,\n                                     ValkeyModuleString *channel,\n                                     ValkeyModuleString *message);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Publish a message to shard-subscribers (see SPUBLISH command).</p>\n<p><span id=\"ValkeyModule_GetSelectedDb\"></span></p>\n<h3><code>ValkeyModule_GetSelectedDb</code></h3>\n<pre><code>int ValkeyModule_GetSelectedDb(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return the currently selected DB.</p>\n<p><span id=\"ValkeyModule_GetContextFlags\"></span></p>\n<h3><code>ValkeyModule_GetContextFlags</code></h3>\n<pre><code>int ValkeyModule_GetContextFlags(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.3</p>\n<p>Return the current context&#39;s flags. The flags provide information on the<br>current request context (whether the client is a Lua script or in a MULTI),<br>and about the instance in general, i.e replication and persistence.</p>\n<p>It is possible to call this function even with a NULL context, however<br>in this case the following flags will not be reported:</p>\n<ul>\n<li>LUA, MULTI, REPLICATED, DIRTY (see below for more info).</li>\n</ul>\n<p>Available flags and their meaning:</p>\n<ul>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_LUA</code>: The command is running in a Lua script</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_MULTI</code>: The command is running inside a transaction</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_REPLICATED</code>: The command was sent over the replication<br>link by the PRIMARY</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_PRIMARY</code>: The instance is a primary</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_REPLICA</code>: The instance is a replica</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_READONLY</code>: The instance is read-only</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_CLUSTER</code>: The instance is in cluster mode</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_AOF</code>: The instance has AOF enabled</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_RDB</code>: The instance has RDB enabled</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_MAXMEMORY</code>:  The instance has Maxmemory set</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_EVICT</code>:  Maxmemory is set and has an eviction<br>policy that may delete keys</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_OOM</code>: The server is out of memory according to the<br>maxmemory setting.</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_OOM_WARNING</code>: Less than 25% of memory remains before<br>                               reaching the maxmemory level.</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_LOADING</code>: Server is loading RDB/AOF</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_REPLICA_IS_STALE</code>: No active link with the primary.</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_REPLICA_IS_CONNECTING</code>: The replica is trying to<br>                                         connect with the primary.</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_REPLICA_IS_TRANSFERRING</code>: primary -&gt; Replica RDB<br>                                           transfer is in progress.</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_REPLICA_IS_ONLINE</code>: The replica has an active link<br>                                     with its primary. This is the<br>                                     contrary of STALE state.</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_ACTIVE_CHILD</code>: There is currently some background<br>                                process active (RDB, AUX or module).</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_MULTI_DIRTY</code>: The next EXEC will fail due to dirty<br>                               CAS (touched keys).</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_IS_CHILD</code>: The server is currently running inside<br>                            background child process.</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_RESP3</code>: Indicate the that client attached to this<br>                         context is using RESP3.</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_SERVER_STARTUP</code>: The instance is starting</p>\n</li>\n</ul>\n<p><span id=\"ValkeyModule_AvoidReplicaTraffic\"></span></p>\n<h3><code>ValkeyModule_AvoidReplicaTraffic</code></h3>\n<pre><code>int ValkeyModule_AvoidReplicaTraffic(void);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Returns true if a client sent the CLIENT PAUSE command to the server or<br>if the Cluster does a manual failover, pausing the clients.<br>This is needed when we have a primary with replicas, and want to write,<br>without adding further data to the replication channel, that the replicas<br>replication offset, match the one of the primary. When this happens, it is<br>safe to failover the primary without data loss.</p>\n<p>However modules may generate traffic by calling <a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call()</code></a> with<br>the &quot;!&quot; flag, or by calling <a href=\"#ValkeyModule_Replicate\"><code>ValkeyModule_Replicate()</code></a>, in a context outside<br>commands execution, for instance in timeout callbacks, threads safe<br>contexts, and so forth. When modules will generate too much traffic, it<br>will be hard for the primary and replicas offset to match, because there<br>is more data to send in the replication channel.</p>\n<p>So modules may want to try to avoid very heavy background work that has<br>the effect of creating data to the replication channel, when this function<br>returns true. This is mostly useful for modules that have background<br>garbage collection tasks, or that do writes and replicate such writes<br>periodically in timer callbacks or other periodic callbacks.</p>\n<p><span id=\"ValkeyModule_SelectDb\"></span></p>\n<h3><code>ValkeyModule_SelectDb</code></h3>\n<pre><code>int ValkeyModule_SelectDb(ValkeyModuleCtx *ctx, int newid);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Change the currently selected DB. Returns an error if the id<br>is out of range.</p>\n<p>Note that the client will retain the currently selected DB even after<br>the command implemented by the module calling this function<br>returns.</p>\n<p>If the module command wishes to change something in a different DB and<br>returns back to the original one, it should call <a href=\"#ValkeyModule_GetSelectedDb\"><code>ValkeyModule_GetSelectedDb()</code></a><br>before in order to restore the old DB number before returning.</p>\n<p><span id=\"ValkeyModule_KeyExists\"></span></p>\n<h3><code>ValkeyModule_KeyExists</code></h3>\n<pre><code>int ValkeyModule_KeyExists(ValkeyModuleCtx *ctx, robj *keyname);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Check if a key exists, without affecting its last access time.</p>\n<p>This is equivalent to calling <a href=\"#ValkeyModule_OpenKey\"><code>ValkeyModule_OpenKey</code></a> with the mode <code>VALKEYMODULE_READ</code> |<br><code>VALKEYMODULE_OPEN_KEY_NOTOUCH</code>, then checking if NULL was returned and, if not,<br>calling <a href=\"#ValkeyModule_CloseKey\"><code>ValkeyModule_CloseKey</code></a> on the opened key.</p>\n<p><span id=\"ValkeyModule_OpenKey\"></span></p>\n<h3><code>ValkeyModule_OpenKey</code></h3>\n<pre><code>ValkeyModuleKey *ValkeyModule_OpenKey(ValkeyModuleCtx *ctx,\n                                      robj *keyname,\n                                      int mode);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return a handle representing a key, so that it is possible<br>to call other APIs with the key handle as argument to perform<br>operations on the key.</p>\n<p>The return value is the handle representing the key, that must be<br>closed with <a href=\"#ValkeyModule_CloseKey\"><code>ValkeyModule_CloseKey()</code></a>.</p>\n<p>If the key does not exist and <code>VALKEYMODULE_WRITE</code> mode is requested, the handle<br>is still returned, since it is possible to perform operations on<br>a yet not existing key (that will be created, for example, after<br>a list push operation). If the mode is just <code>VALKEYMODULE_READ</code> instead, and the<br>key does not exist, NULL is returned. However it is still safe to<br>call <a href=\"#ValkeyModule_CloseKey\"><code>ValkeyModule_CloseKey()</code></a> and <a href=\"#ValkeyModule_KeyType\"><code>ValkeyModule_KeyType()</code></a> on a NULL<br>value.</p>\n<p>Extra flags that can be pass to the API under the mode argument:</p>\n<ul>\n<li><code>VALKEYMODULE_OPEN_KEY_NOTOUCH</code> - Avoid touching the LRU/LFU of the key when opened.</li>\n<li><code>VALKEYMODULE_OPEN_KEY_NONOTIFY</code> - Don&#39;t trigger keyspace event on key misses.</li>\n<li><code>VALKEYMODULE_OPEN_KEY_NOSTATS</code> - Don&#39;t update keyspace hits/misses counters.</li>\n<li><code>VALKEYMODULE_OPEN_KEY_NOEXPIRE</code> - Avoid deleting lazy expired keys.</li>\n<li><code>VALKEYMODULE_OPEN_KEY_NOEFFECTS</code> - Avoid any effects from fetching the key.</li>\n</ul>\n<p><span id=\"ValkeyModule_GetOpenKeyModesAll\"></span></p>\n<h3><code>ValkeyModule_GetOpenKeyModesAll</code></h3>\n<pre><code>int ValkeyModule_GetOpenKeyModesAll(void);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Returns the full OpenKey modes mask, using the return value<br>the module can check if a certain set of OpenKey modes are supported<br>by the server version in use.<br>Example:</p>\n<pre><code>   int supportedMode = ValkeyModule_GetOpenKeyModesAll();\n   if (supportedMode &amp; VALKEYMODULE_OPEN_KEY_NOTOUCH) {\n         // VALKEYMODULE_OPEN_KEY_NOTOUCH is supported\n   } else{\n         // VALKEYMODULE_OPEN_KEY_NOTOUCH is not supported\n   }\n</code></pre>\n<p><span id=\"ValkeyModule_CloseKey\"></span></p>\n<h3><code>ValkeyModule_CloseKey</code></h3>\n<pre><code>void ValkeyModule_CloseKey(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Close a key handle. The key handle is freed and should not be accessed anymore.</p>\n<p><span id=\"ValkeyModule_KeyType\"></span></p>\n<h3><code>ValkeyModule_KeyType</code></h3>\n<pre><code>int ValkeyModule_KeyType(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return the type of the key. If the key pointer is NULL then<br><code>VALKEYMODULE_KEYTYPE_EMPTY</code> is returned.</p>\n<p><span id=\"ValkeyModule_ValueLength\"></span></p>\n<h3><code>ValkeyModule_ValueLength</code></h3>\n<pre><code>size_t ValkeyModule_ValueLength(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return the length of the value associated with the key.<br>For strings this is the length of the string. For all the other types<br>is the number of elements (just counting keys for hashes).</p>\n<p>If the key pointer is NULL or the key is empty, zero is returned.</p>\n<p><span id=\"ValkeyModule_DeleteKey\"></span></p>\n<h3><code>ValkeyModule_DeleteKey</code></h3>\n<pre><code>int ValkeyModule_DeleteKey(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>If the key is open for writing, remove it, and setup the key to<br>accept new writes as an empty key (that will be created on demand).<br>On success <code>VALKEYMODULE_OK</code> is returned. If the key is not open for<br>writing <code>VALKEYMODULE_ERR</code> is returned.</p>\n<p><span id=\"ValkeyModule_UnlinkKey\"></span></p>\n<h3><code>ValkeyModule_UnlinkKey</code></h3>\n<pre><code>int ValkeyModule_UnlinkKey(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.7</p>\n<p>If the key is open for writing, unlink it (that is delete it in a<br>non-blocking way, not reclaiming memory immediately) and setup the key to<br>accept new writes as an empty key (that will be created on demand).<br>On success <code>VALKEYMODULE_OK</code> is returned. If the key is not open for<br>writing <code>VALKEYMODULE_ERR</code> is returned.</p>\n<p><span id=\"ValkeyModule_GetExpire\"></span></p>\n<h3><code>ValkeyModule_GetExpire</code></h3>\n<pre><code>mstime_t ValkeyModule_GetExpire(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return the key expire value, as milliseconds of remaining TTL.<br>If no TTL is associated with the key or if the key is empty,<br><code>VALKEYMODULE_NO_EXPIRE</code> is returned.</p>\n<p><span id=\"ValkeyModule_SetExpire\"></span></p>\n<h3><code>ValkeyModule_SetExpire</code></h3>\n<pre><code>int ValkeyModule_SetExpire(ValkeyModuleKey *key, mstime_t expire);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Set a new expire for the key. If the special expire<br><code>VALKEYMODULE_NO_EXPIRE</code> is set, the expire is cancelled if there was<br>one (the same as the PERSIST command).</p>\n<p>Note that the expire must be provided as a positive integer representing<br>the number of milliseconds of TTL the key should have.</p>\n<p>The function returns <code>VALKEYMODULE_OK</code> on success or <code>VALKEYMODULE_ERR</code> if<br>the key was not open for writing or is an empty key.</p>\n<p><span id=\"ValkeyModule_GetAbsExpire\"></span></p>\n<h3><code>ValkeyModule_GetAbsExpire</code></h3>\n<pre><code>mstime_t ValkeyModule_GetAbsExpire(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.2</p>\n<p>Return the key expire value, as absolute Unix timestamp.<br>If no TTL is associated with the key or if the key is empty,<br><code>VALKEYMODULE_NO_EXPIRE</code> is returned.</p>\n<p><span id=\"ValkeyModule_SetAbsExpire\"></span></p>\n<h3><code>ValkeyModule_SetAbsExpire</code></h3>\n<pre><code>int ValkeyModule_SetAbsExpire(ValkeyModuleKey *key, mstime_t expire);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.2</p>\n<p>Set a new expire for the key. If the special expire<br><code>VALKEYMODULE_NO_EXPIRE</code> is set, the expire is cancelled if there was<br>one (the same as the PERSIST command).</p>\n<p>Note that the expire must be provided as a positive integer representing<br>the absolute Unix timestamp the key should have.</p>\n<p>The function returns <code>VALKEYMODULE_OK</code> on success or <code>VALKEYMODULE_ERR</code> if<br>the key was not open for writing or is an empty key.</p>\n<p><span id=\"ValkeyModule_ResetDataset\"></span></p>\n<h3><code>ValkeyModule_ResetDataset</code></h3>\n<pre><code>void ValkeyModule_ResetDataset(int restart_aof, int async);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Performs similar operation to FLUSHALL, and optionally start a new AOF file (if enabled)<br>If <code>restart_aof</code> is true, you must make sure the command that triggered this call is not<br>propagated to the AOF file.<br>When async is set to true, db contents will be freed by a background thread.</p>\n<p><span id=\"ValkeyModule_DbSize\"></span></p>\n<h3><code>ValkeyModule_DbSize</code></h3>\n<pre><code>unsigned long long ValkeyModule_DbSize(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Returns the number of keys in the current db.</p>\n<p><span id=\"ValkeyModule_RandomKey\"></span></p>\n<h3><code>ValkeyModule_RandomKey</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_RandomKey(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Returns a name of a random key, or NULL if current db is empty.</p>\n<p><span id=\"ValkeyModule_GetKeyNameFromOptCtx\"></span></p>\n<h3><code>ValkeyModule_GetKeyNameFromOptCtx</code></h3>\n<pre><code>const ValkeyModuleString *ValkeyModule_GetKeyNameFromOptCtx(ValkeyModuleKeyOptCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Returns the name of the key currently being processed.</p>\n<p><span id=\"ValkeyModule_GetToKeyNameFromOptCtx\"></span></p>\n<h3><code>ValkeyModule_GetToKeyNameFromOptCtx</code></h3>\n<pre><code>const ValkeyModuleString *ValkeyModule_GetToKeyNameFromOptCtx(ValkeyModuleKeyOptCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Returns the name of the target key currently being processed.</p>\n<p><span id=\"ValkeyModule_GetDbIdFromOptCtx\"></span></p>\n<h3><code>ValkeyModule_GetDbIdFromOptCtx</code></h3>\n<pre><code>int ValkeyModule_GetDbIdFromOptCtx(ValkeyModuleKeyOptCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Returns the dbid currently being processed.</p>\n<p><span id=\"ValkeyModule_GetToDbIdFromOptCtx\"></span></p>\n<h3><code>ValkeyModule_GetToDbIdFromOptCtx</code></h3>\n<pre><code>int ValkeyModule_GetToDbIdFromOptCtx(ValkeyModuleKeyOptCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Returns the target dbid currently being processed.</p>\n<p><span id=\"section-key-api-for-string-type\"></span></p>\n<h2>Key API for String type</h2>\n<p>See also <a href=\"#ValkeyModule_ValueLength\"><code>ValkeyModule_ValueLength()</code></a>, which returns the length of a string.</p>\n<p><span id=\"ValkeyModule_StringSet\"></span></p>\n<h3><code>ValkeyModule_StringSet</code></h3>\n<pre><code>int ValkeyModule_StringSet(ValkeyModuleKey *key, ValkeyModuleString *str);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>If the key is open for writing, set the specified string &#39;str&#39; as the<br>value of the key, deleting the old value if any.<br>On success <code>VALKEYMODULE_OK</code> is returned. If the key is not open for<br>writing or there is an active iterator, <code>VALKEYMODULE_ERR</code> is returned.</p>\n<p><span id=\"ValkeyModule_StringDMA\"></span></p>\n<h3><code>ValkeyModule_StringDMA</code></h3>\n<pre><code>char *ValkeyModule_StringDMA(ValkeyModuleKey *key, size_t *len, int mode);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Prepare the key associated string value for DMA access, and returns<br>a pointer and size (by reference), that the user can use to read or<br>modify the string in-place accessing it directly via pointer.</p>\n<p>The &#39;mode&#39; is composed by bitwise OR-ing the following flags:</p>\n<pre><code>VALKEYMODULE_READ -- Read access\nVALKEYMODULE_WRITE -- Write access\n</code></pre>\n<p>If the DMA is not requested for writing, the pointer returned should<br>only be accessed in a read-only fashion.</p>\n<p>On error (wrong type) NULL is returned.</p>\n<p>DMA access rules:</p>\n<ol>\n<li><p>No other key writing function should be called since the moment<br>the pointer is obtained, for all the time we want to use DMA access<br>to read or modify the string.</p>\n</li>\n<li><p>Each time <a href=\"#ValkeyModule_StringTruncate\"><code>ValkeyModule_StringTruncate()</code></a> is called, to continue with the DMA<br>access, <a href=\"#ValkeyModule_StringDMA\"><code>ValkeyModule_StringDMA()</code></a> should be called again to re-obtain<br>a new pointer and length.</p>\n</li>\n<li><p>If the returned pointer is not NULL, but the length is zero, no<br>byte can be touched (the string is empty, or the key itself is empty)<br>so a <a href=\"#ValkeyModule_StringTruncate\"><code>ValkeyModule_StringTruncate()</code></a> call should be used if there is to enlarge<br>the string, and later call StringDMA() again to get the pointer.</p>\n</li>\n</ol>\n<p><span id=\"ValkeyModule_StringTruncate\"></span></p>\n<h3><code>ValkeyModule_StringTruncate</code></h3>\n<pre><code>int ValkeyModule_StringTruncate(ValkeyModuleKey *key, size_t newlen);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>If the key is open for writing and is of string type, resize it, padding<br>with zero bytes if the new length is greater than the old one.</p>\n<p>After this call, <a href=\"#ValkeyModule_StringDMA\"><code>ValkeyModule_StringDMA()</code></a> must be called again to continue<br>DMA access with the new pointer.</p>\n<p>The function returns <code>VALKEYMODULE_OK</code> on success, and <code>VALKEYMODULE_ERR</code> on<br>error, that is, the key is not open for writing, is not a string<br>or resizing for more than 512 MB is requested.</p>\n<p>If the key is empty, a string key is created with the new string value<br>unless the new length value requested is zero.</p>\n<p><span id=\"section-key-api-for-list-type\"></span></p>\n<h2>Key API for List type</h2>\n<p>Many of the list functions access elements by index. Since a list is in<br>essence a doubly-linked list, accessing elements by index is generally an<br>O(N) operation. However, if elements are accessed sequentially or with<br>indices close together, the functions are optimized to seek the index from<br>the previous index, rather than seeking from the ends of the list.</p>\n<p>This enables iteration to be done efficiently using a simple for loop:</p>\n<pre><code>long n = ValkeyModule_ValueLength(key);\nfor (long i = 0; i &lt; n; i++) {\n    ValkeyModuleString *elem = ValkeyModule_ListGet(key, i);\n    // Do stuff...\n}\n</code></pre>\n<p>Note that after modifying a list using <a href=\"#ValkeyModule_ListPop\"><code>ValkeyModule_ListPop</code></a>, <a href=\"#ValkeyModule_ListSet\"><code>ValkeyModule_ListSet</code></a> or<br><a href=\"#ValkeyModule_ListInsert\"><code>ValkeyModule_ListInsert</code></a>, the internal iterator is invalidated so the next operation<br>will require a linear seek.</p>\n<p>Modifying a list in any another way, for example using <a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call()</code></a>, while a key<br>is open will confuse the internal iterator and may cause trouble if the key<br>is used after such modifications. The key must be reopened in this case.</p>\n<p>See also <a href=\"#ValkeyModule_ValueLength\"><code>ValkeyModule_ValueLength()</code></a>, which returns the length of a list.</p>\n<p><span id=\"ValkeyModule_ListPush\"></span></p>\n<h3><code>ValkeyModule_ListPush</code></h3>\n<pre><code>int ValkeyModule_ListPush(ValkeyModuleKey *key,\n                          int where,\n                          ValkeyModuleString *ele);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Push an element into a list, on head or tail depending on &#39;where&#39; argument<br>(<code>VALKEYMODULE_LIST_HEAD</code> or <code>VALKEYMODULE_LIST_TAIL</code>). If the key refers to an<br>empty key opened for writing, the key is created. On success, <code>VALKEYMODULE_OK</code><br>is returned. On failure, <code>VALKEYMODULE_ERR</code> is returned and <code>errno</code> is set as<br>follows:</p>\n<ul>\n<li>EINVAL if key or ele is NULL.</li>\n<li>ENOTSUP if the key is of another type than list.</li>\n<li>EBADF if the key is not opened for writing.</li>\n</ul>\n<p>Note: Before Redis OSS 7.0, <code>errno</code> was not set by this function.</p>\n<p><span id=\"ValkeyModule_ListPop\"></span></p>\n<h3><code>ValkeyModule_ListPop</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_ListPop(ValkeyModuleKey *key, int where);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Pop an element from the list, and returns it as a module string object<br>that the user should be free with <a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a> or by enabling<br>automatic memory. The <code>where</code> argument specifies if the element should be<br>popped from the beginning or the end of the list (<code>VALKEYMODULE_LIST_HEAD</code> or<br><code>VALKEYMODULE_LIST_TAIL</code>). On failure, the command returns NULL and sets<br><code>errno</code> as follows:</p>\n<ul>\n<li>EINVAL if key is NULL.</li>\n<li>ENOTSUP if the key is empty or of another type than list.</li>\n<li>EBADF if the key is not opened for writing.</li>\n</ul>\n<p>Note: Before Redis OSS 7.0, <code>errno</code> was not set by this function.</p>\n<p><span id=\"ValkeyModule_ListGet\"></span></p>\n<h3><code>ValkeyModule_ListGet</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_ListGet(ValkeyModuleKey *key, long index);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Returns the element at index <code>index</code> in the list stored at <code>key</code>, like the<br>LINDEX command. The element should be free&#39;d using <a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a> or using<br>automatic memory management.</p>\n<p>The index is zero-based, so 0 means the first element, 1 the second element<br>and so on. Negative indices can be used to designate elements starting at the<br>tail of the list. Here, -1 means the last element, -2 means the penultimate<br>and so forth.</p>\n<p>When no value is found at the given key and index, NULL is returned and<br><code>errno</code> is set as follows:</p>\n<ul>\n<li>EINVAL if key is NULL.</li>\n<li>ENOTSUP if the key is not a list.</li>\n<li>EBADF if the key is not opened for reading.</li>\n<li>EDOM if the index is not a valid index in the list.</li>\n</ul>\n<p><span id=\"ValkeyModule_ListSet\"></span></p>\n<h3><code>ValkeyModule_ListSet</code></h3>\n<pre><code>int ValkeyModule_ListSet(ValkeyModuleKey *key,\n                         long index,\n                         ValkeyModuleString *value);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Replaces the element at index <code>index</code> in the list stored at <code>key</code>.</p>\n<p>The index is zero-based, so 0 means the first element, 1 the second element<br>and so on. Negative indices can be used to designate elements starting at the<br>tail of the list. Here, -1 means the last element, -2 means the penultimate<br>and so forth.</p>\n<p>On success, <code>VALKEYMODULE_OK</code> is returned. On failure, <code>VALKEYMODULE_ERR</code> is<br>returned and <code>errno</code> is set as follows:</p>\n<ul>\n<li>EINVAL if key or value is NULL.</li>\n<li>ENOTSUP if the key is not a list.</li>\n<li>EBADF if the key is not opened for writing.</li>\n<li>EDOM if the index is not a valid index in the list.</li>\n</ul>\n<p><span id=\"ValkeyModule_ListInsert\"></span></p>\n<h3><code>ValkeyModule_ListInsert</code></h3>\n<pre><code>int ValkeyModule_ListInsert(ValkeyModuleKey *key,\n                            long index,\n                            ValkeyModuleString *value);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Inserts an element at the given index.</p>\n<p>The index is zero-based, so 0 means the first element, 1 the second element<br>and so on. Negative indices can be used to designate elements starting at the<br>tail of the list. Here, -1 means the last element, -2 means the penultimate<br>and so forth. The index is the element&#39;s index after inserting it.</p>\n<p>On success, <code>VALKEYMODULE_OK</code> is returned. On failure, <code>VALKEYMODULE_ERR</code> is<br>returned and <code>errno</code> is set as follows:</p>\n<ul>\n<li>EINVAL if key or value is NULL.</li>\n<li>ENOTSUP if the key of another type than list.</li>\n<li>EBADF if the key is not opened for writing.</li>\n<li>EDOM if the index is not a valid index in the list.</li>\n</ul>\n<p><span id=\"ValkeyModule_ListDelete\"></span></p>\n<h3><code>ValkeyModule_ListDelete</code></h3>\n<pre><code>int ValkeyModule_ListDelete(ValkeyModuleKey *key, long index);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Removes an element at the given index. The index is 0-based. A negative index<br>can also be used, counting from the end of the list.</p>\n<p>On success, <code>VALKEYMODULE_OK</code> is returned. On failure, <code>VALKEYMODULE_ERR</code> is<br>returned and <code>errno</code> is set as follows:</p>\n<ul>\n<li>EINVAL if key or value is NULL.</li>\n<li>ENOTSUP if the key is not a list.</li>\n<li>EBADF if the key is not opened for writing.</li>\n<li>EDOM if the index is not a valid index in the list.</li>\n</ul>\n<p><span id=\"section-key-api-for-sorted-set-type\"></span></p>\n<h2>Key API for Sorted Set type</h2>\n<p>See also <a href=\"#ValkeyModule_ValueLength\"><code>ValkeyModule_ValueLength()</code></a>, which returns the length of a sorted set.</p>\n<p><span id=\"ValkeyModule_ZsetAdd\"></span></p>\n<h3><code>ValkeyModule_ZsetAdd</code></h3>\n<pre><code>int ValkeyModule_ZsetAdd(ValkeyModuleKey *key,\n                         double score,\n                         ValkeyModuleString *ele,\n                         int *flagsptr);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Add a new element into a sorted set, with the specified &#39;score&#39;.<br>If the element already exists, the score is updated.</p>\n<p>A new sorted set is created at value if the key is an empty open key<br>setup for writing.</p>\n<p>Additional flags can be passed to the function via a pointer, the flags<br>are both used to receive input and to communicate state when the function<br>returns. &#39;flagsptr&#39; can be NULL if no special flags are used.</p>\n<p>The input flags are:</p>\n<pre><code>VALKEYMODULE_ZADD_XX: Element must already exist. Do nothing otherwise.\nVALKEYMODULE_ZADD_NX: Element must not exist. Do nothing otherwise.\nVALKEYMODULE_ZADD_GT: If element exists, new score must be greater than the current score.\n                     Do nothing otherwise. Can optionally be combined with XX.\nVALKEYMODULE_ZADD_LT: If element exists, new score must be less than the current score.\n                     Do nothing otherwise. Can optionally be combined with XX.\n</code></pre>\n<p>The output flags are:</p>\n<pre><code>VALKEYMODULE_ZADD_ADDED: The new element was added to the sorted set.\nVALKEYMODULE_ZADD_UPDATED: The score of the element was updated.\nVALKEYMODULE_ZADD_NOP: No operation was performed because XX or NX flags.\n</code></pre>\n<p>On success the function returns <code>VALKEYMODULE_OK</code>. On the following errors<br><code>VALKEYMODULE_ERR</code> is returned:</p>\n<ul>\n<li>The key was not opened for writing.</li>\n<li>The key is of the wrong type.</li>\n<li>&#39;score&#39; double value is not a number (NaN).</li>\n</ul>\n<p><span id=\"ValkeyModule_ZsetIncrby\"></span></p>\n<h3><code>ValkeyModule_ZsetIncrby</code></h3>\n<pre><code>int ValkeyModule_ZsetIncrby(ValkeyModuleKey *key,\n                            double score,\n                            ValkeyModuleString *ele,\n                            int *flagsptr,\n                            double *newscore);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>This function works exactly like <a href=\"#ValkeyModule_ZsetAdd\"><code>ValkeyModule_ZsetAdd()</code></a>, but instead of setting<br>a new score, the score of the existing element is incremented, or if the<br>element does not already exist, it is added assuming the old score was<br>zero.</p>\n<p>The input and output flags, and the return value, have the same exact<br>meaning, with the only difference that this function will return<br><code>VALKEYMODULE_ERR</code> even when &#39;score&#39; is a valid double number, but adding it<br>to the existing score results into a NaN (not a number) condition.</p>\n<p>This function has an additional field &#39;newscore&#39;, if not NULL is filled<br>with the new score of the element after the increment, if no error<br>is returned.</p>\n<p><span id=\"ValkeyModule_ZsetRem\"></span></p>\n<h3><code>ValkeyModule_ZsetRem</code></h3>\n<pre><code>int ValkeyModule_ZsetRem(ValkeyModuleKey *key,\n                         ValkeyModuleString *ele,\n                         int *deleted);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Remove the specified element from the sorted set.<br>The function returns <code>VALKEYMODULE_OK</code> on success, and <code>VALKEYMODULE_ERR</code><br>on one of the following conditions:</p>\n<ul>\n<li>The key was not opened for writing.</li>\n<li>The key is of the wrong type.</li>\n</ul>\n<p>The return value does NOT indicate the fact the element was really<br>removed (since it existed) or not, just if the function was executed<br>with success.</p>\n<p>In order to know if the element was removed, the additional argument<br>&#39;deleted&#39; must be passed, that populates the integer by reference<br>setting it to 1 or 0 depending on the outcome of the operation.<br>The &#39;deleted&#39; argument can be NULL if the caller is not interested<br>to know if the element was really removed.</p>\n<p>Empty keys will be handled correctly by doing nothing.</p>\n<p><span id=\"ValkeyModule_ZsetScore\"></span></p>\n<h3><code>ValkeyModule_ZsetScore</code></h3>\n<pre><code>int ValkeyModule_ZsetScore(ValkeyModuleKey *key,\n                           ValkeyModuleString *ele,\n                           double *score);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>On success retrieve the double score associated at the sorted set element<br>&#39;ele&#39; and returns <code>VALKEYMODULE_OK</code>. Otherwise <code>VALKEYMODULE_ERR</code> is returned<br>to signal one of the following conditions:</p>\n<ul>\n<li>There is no such element &#39;ele&#39; in the sorted set.</li>\n<li>The key is not a sorted set.</li>\n<li>The key is an open empty key.</li>\n</ul>\n<p><span id=\"section-key-api-for-sorted-set-iterator\"></span></p>\n<h2>Key API for Sorted Set iterator</h2>\n<p><span id=\"ValkeyModule_ZsetRangeStop\"></span></p>\n<h3><code>ValkeyModule_ZsetRangeStop</code></h3>\n<pre><code>void ValkeyModule_ZsetRangeStop(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Stop a sorted set iteration.</p>\n<p><span id=\"ValkeyModule_ZsetRangeEndReached\"></span></p>\n<h3><code>ValkeyModule_ZsetRangeEndReached</code></h3>\n<pre><code>int ValkeyModule_ZsetRangeEndReached(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return the &quot;End of range&quot; flag value to signal the end of the iteration.</p>\n<p><span id=\"ValkeyModule_ZsetFirstInScoreRange\"></span></p>\n<h3><code>ValkeyModule_ZsetFirstInScoreRange</code></h3>\n<pre><code>int ValkeyModule_ZsetFirstInScoreRange(ValkeyModuleKey *key,\n                                       double min,\n                                       double max,\n                                       int minex,\n                                       int maxex);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Setup a sorted set iterator seeking the first element in the specified<br>range. Returns <code>VALKEYMODULE_OK</code> if the iterator was correctly initialized<br>otherwise <code>VALKEYMODULE_ERR</code> is returned in the following conditions:</p>\n<ol>\n<li>The value stored at key is not a sorted set or the key is empty.</li>\n</ol>\n<p>The range is specified according to the two double values &#39;min&#39; and &#39;max&#39;.<br>Both can be infinite using the following two macros:</p>\n<ul>\n<li><code>VALKEYMODULE_POSITIVE_INFINITE</code> for positive infinite value</li>\n<li><code>VALKEYMODULE_NEGATIVE_INFINITE</code> for negative infinite value</li>\n</ul>\n<p>&#39;minex&#39; and &#39;maxex&#39; parameters, if true, respectively setup a range<br>where the min and max value are exclusive (not included) instead of<br>inclusive.</p>\n<p><span id=\"ValkeyModule_ZsetLastInScoreRange\"></span></p>\n<h3><code>ValkeyModule_ZsetLastInScoreRange</code></h3>\n<pre><code>int ValkeyModule_ZsetLastInScoreRange(ValkeyModuleKey *key,\n                                      double min,\n                                      double max,\n                                      int minex,\n                                      int maxex);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Exactly like <a href=\"#ValkeyModule_ZsetFirstInScoreRange\"><code>ValkeyModule_ZsetFirstInScoreRange()</code></a> but the last element of<br>the range is selected for the start of the iteration instead.</p>\n<p><span id=\"ValkeyModule_ZsetFirstInLexRange\"></span></p>\n<h3><code>ValkeyModule_ZsetFirstInLexRange</code></h3>\n<pre><code>int ValkeyModule_ZsetFirstInLexRange(ValkeyModuleKey *key,\n                                     ValkeyModuleString *min,\n                                     ValkeyModuleString *max);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Setup a sorted set iterator seeking the first element in the specified<br>lexicographical range. Returns <code>VALKEYMODULE_OK</code> if the iterator was correctly<br>initialized otherwise <code>VALKEYMODULE_ERR</code> is returned in the<br>following conditions:</p>\n<ol>\n<li>The value stored at key is not a sorted set or the key is empty.</li>\n<li>The lexicographical range &#39;min&#39; and &#39;max&#39; format is invalid.</li>\n</ol>\n<p>&#39;min&#39; and &#39;max&#39; should be provided as two <code>ValkeyModuleString</code> objects<br>in the same format as the parameters passed to the ZRANGEBYLEX command.<br>The function does not take ownership of the objects, so they can be released<br>ASAP after the iterator is setup.</p>\n<p><span id=\"ValkeyModule_ZsetLastInLexRange\"></span></p>\n<h3><code>ValkeyModule_ZsetLastInLexRange</code></h3>\n<pre><code>int ValkeyModule_ZsetLastInLexRange(ValkeyModuleKey *key,\n                                    ValkeyModuleString *min,\n                                    ValkeyModuleString *max);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Exactly like <a href=\"#ValkeyModule_ZsetFirstInLexRange\"><code>ValkeyModule_ZsetFirstInLexRange()</code></a> but the last element of<br>the range is selected for the start of the iteration instead.</p>\n<p><span id=\"ValkeyModule_ZsetRangeCurrentElement\"></span></p>\n<h3><code>ValkeyModule_ZsetRangeCurrentElement</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_ZsetRangeCurrentElement(ValkeyModuleKey *key,\n                                                         double *score);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return the current sorted set element of an active sorted set iterator<br>or NULL if the range specified in the iterator does not include any<br>element.</p>\n<p><span id=\"ValkeyModule_ZsetRangeNext\"></span></p>\n<h3><code>ValkeyModule_ZsetRangeNext</code></h3>\n<pre><code>int ValkeyModule_ZsetRangeNext(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Go to the next element of the sorted set iterator. Returns 1 if there was<br>a next element, 0 if we are already at the latest element or the range<br>does not include any item at all.</p>\n<p><span id=\"ValkeyModule_ZsetRangePrev\"></span></p>\n<h3><code>ValkeyModule_ZsetRangePrev</code></h3>\n<pre><code>int ValkeyModule_ZsetRangePrev(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Go to the previous element of the sorted set iterator. Returns 1 if there was<br>a previous element, 0 if we are already at the first element or the range<br>does not include any item at all.</p>\n<p><span id=\"section-key-api-for-hash-type\"></span></p>\n<h2>Key API for Hash type</h2>\n<p>See also <a href=\"#ValkeyModule_ValueLength\"><code>ValkeyModule_ValueLength()</code></a>, which returns the number of fields in a hash.</p>\n<p><span id=\"ValkeyModule_HashSet\"></span></p>\n<h3><code>ValkeyModule_HashSet</code></h3>\n<pre><code>int ValkeyModule_HashSet(ValkeyModuleKey *key, int flags, ...);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Set the field of the specified hash field to the specified value.<br>If the key is an empty key open for writing, it is created with an empty<br>hash value, in order to set the specified field.</p>\n<p>The function is variadic and the user must specify pairs of field<br>names and values, both as <code>ValkeyModuleString</code> pointers (unless the<br>CFIELD option is set, see later). At the end of the field/value-ptr pairs,<br>NULL must be specified as last argument to signal the end of the arguments<br>in the variadic function.</p>\n<p>Example to set the hash argv[1] to the value argv[2]:</p>\n<pre><code> ValkeyModule_HashSet(key,VALKEYMODULE_HASH_NONE,argv[1],argv[2],NULL);\n</code></pre>\n<p>The function can also be used in order to delete fields (if they exist)<br>by setting them to the specified value of <code>VALKEYMODULE_HASH_DELETE</code>:</p>\n<pre><code> ValkeyModule_HashSet(key,VALKEYMODULE_HASH_NONE,argv[1],\n                     VALKEYMODULE_HASH_DELETE,NULL);\n</code></pre>\n<p>The behavior of the command changes with the specified flags, that can be<br>set to <code>VALKEYMODULE_HASH_NONE</code> if no special behavior is needed.</p>\n<pre><code>VALKEYMODULE_HASH_NX: The operation is performed only if the field was not\n                     already existing in the hash.\nVALKEYMODULE_HASH_XX: The operation is performed only if the field was\n                     already existing, so that a new value could be\n                     associated to an existing filed, but no new fields\n                     are created.\nVALKEYMODULE_HASH_CFIELDS: The field names passed are null terminated C\n                          strings instead of ValkeyModuleString objects.\nVALKEYMODULE_HASH_COUNT_ALL: Include the number of inserted fields in the\n                            returned number, in addition to the number of\n                            updated and deleted fields. (Added in Redis OSS\n                            6.2.)\n</code></pre>\n<p>Unless NX is specified, the command overwrites the old field value with<br>the new one.</p>\n<p>When using <code>VALKEYMODULE_HASH_CFIELDS</code>, field names are reported using<br>normal C strings, so for example to delete the field &quot;foo&quot; the following<br>code can be used:</p>\n<pre><code> ValkeyModule_HashSet(key,VALKEYMODULE_HASH_CFIELDS,&quot;foo&quot;,\n                     VALKEYMODULE_HASH_DELETE,NULL);\n</code></pre>\n<p>Return value:</p>\n<p>The number of fields existing in the hash prior to the call, which have been<br>updated (its old value has been replaced by a new value) or deleted. If the<br>flag <code>VALKEYMODULE_HASH_COUNT_ALL</code> is set, inserted fields not previously<br>existing in the hash are also counted.</p>\n<p>If the return value is zero, <code>errno</code> is set (since Redis OSS 6.2) as follows:</p>\n<ul>\n<li>EINVAL if any unknown flags are set or if key is NULL.</li>\n<li>ENOTSUP if the key is associated with a non Hash value.</li>\n<li>EBADF if the key was not opened for writing.</li>\n<li>ENOENT if no fields were counted as described under Return value above.<br>This is not actually an error. The return value can be zero if all fields<br>were just created and the <code>COUNT_ALL</code> flag was unset, or if changes were held<br>back due to the NX and XX flags.</li>\n</ul>\n<p>NOTICE: The return value semantics of this function are very different<br>between Redis OSS 6.2 and older versions. Modules that use it should determine<br>the server version and handle it accordingly.</p>\n<p><span id=\"ValkeyModule_HashGet\"></span></p>\n<h3><code>ValkeyModule_HashGet</code></h3>\n<pre><code>int ValkeyModule_HashGet(ValkeyModuleKey *key, int flags, ...);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Get fields from a hash value. This function is called using a variable<br>number of arguments, alternating a field name (as a <code>ValkeyModuleString</code><br>pointer) with a pointer to a <code>ValkeyModuleString</code> pointer, that is set to the<br>value of the field if the field exists, or NULL if the field does not exist.<br>At the end of the field/value-ptr pairs, NULL must be specified as last<br>argument to signal the end of the arguments in the variadic function.</p>\n<p>This is an example usage:</p>\n<pre><code> ValkeyModuleString *first, *second;\n ValkeyModule_HashGet(mykey,VALKEYMODULE_HASH_NONE,argv[1],&amp;first,\n                     argv[2],&amp;second,NULL);\n</code></pre>\n<p>As with <a href=\"#ValkeyModule_HashSet\"><code>ValkeyModule_HashSet()</code></a> the behavior of the command can be specified<br>passing flags different than <code>VALKEYMODULE_HASH_NONE</code>:</p>\n<p><code>VALKEYMODULE_HASH_CFIELDS</code>: field names as null terminated C strings.</p>\n<p><code>VALKEYMODULE_HASH_EXISTS</code>: instead of setting the value of the field<br>expecting a <code>ValkeyModuleString</code> pointer to pointer, the function just<br>reports if the field exists or not and expects an integer pointer<br>as the second element of each pair.</p>\n<p>Example of <code>VALKEYMODULE_HASH_CFIELDS</code>:</p>\n<pre><code> ValkeyModuleString *username, *hashedpass;\n ValkeyModule_HashGet(mykey,VALKEYMODULE_HASH_CFIELDS,&quot;username&quot;,&amp;username,&quot;hp&quot;,&amp;hashedpass, NULL);\n</code></pre>\n<p>Example of <code>VALKEYMODULE_HASH_EXISTS</code>:</p>\n<pre><code> int exists;\n ValkeyModule_HashGet(mykey,VALKEYMODULE_HASH_EXISTS,argv[1],&amp;exists,NULL);\n</code></pre>\n<p>The function returns <code>VALKEYMODULE_OK</code> on success and <code>VALKEYMODULE_ERR</code> if<br>the key is not a hash value.</p>\n<p>Memory management:</p>\n<p>The returned <code>ValkeyModuleString</code> objects should be released with<br><a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a>, or by enabling automatic memory management.</p>\n<p><span id=\"section-key-api-for-stream-type\"></span></p>\n<h2>Key API for Stream type</h2>\n<p>For an introduction to streams, see <a href=\"https://valkey.io/topics/streams-intro\">https://valkey.io/topics/streams-intro</a>.</p>\n<p>The type <code>ValkeyModuleStreamID</code>, which is used in stream functions, is a struct<br>with two 64-bit fields and is defined as</p>\n<pre><code>typedef struct ValkeyModuleStreamID {\n    uint64_t ms;\n    uint64_t seq;\n} ValkeyModuleStreamID;\n</code></pre>\n<p>See also <a href=\"#ValkeyModule_ValueLength\"><code>ValkeyModule_ValueLength()</code></a>, which returns the length of a stream, and the<br>conversion functions <a href=\"#ValkeyModule_StringToStreamID\"><code>ValkeyModule_StringToStreamID()</code></a> and <a href=\"#ValkeyModule_CreateStringFromStreamID\"><code>ValkeyModule_CreateStringFromStreamID()</code></a>.</p>\n<p><span id=\"ValkeyModule_StreamAdd\"></span></p>\n<h3><code>ValkeyModule_StreamAdd</code></h3>\n<pre><code>int ValkeyModule_StreamAdd(ValkeyModuleKey *key,\n                           int flags,\n                           ValkeyModuleStreamID *id,\n                           ValkeyModuleString **argv,\n                           long numfields);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Adds an entry to a stream. Like XADD without trimming.</p>\n<ul>\n<li><code>key</code>: The key where the stream is (or will be) stored</li>\n<li><code>flags</code>: A bit field of<ul>\n<li><code>VALKEYMODULE_STREAM_ADD_AUTOID</code>: Assign a stream ID automatically, like<br><code>*</code> in the XADD command.</li>\n</ul>\n</li>\n<li><code>id</code>: If the <code>AUTOID</code> flag is set, this is where the assigned ID is<br>returned. Can be NULL if <code>AUTOID</code> is set, if you don&#39;t care to receive the<br>ID. If <code>AUTOID</code> is not set, this is the requested ID.</li>\n<li><code>argv</code>: A pointer to an array of size <code>numfields * 2</code> containing the<br>fields and values.</li>\n<li><code>numfields</code>: The number of field-value pairs in <code>argv</code>.</li>\n</ul>\n<p>Returns <code>VALKEYMODULE_OK</code> if an entry has been added. On failure,<br><code>VALKEYMODULE_ERR</code> is returned and <code>errno</code> is set as follows:</p>\n<ul>\n<li>EINVAL if called with invalid arguments</li>\n<li>ENOTSUP if the key refers to a value of a type other than stream</li>\n<li>EBADF if the key was not opened for writing</li>\n<li>EDOM if the given ID was 0-0 or not greater than all other IDs in the<br>stream (only if the AUTOID flag is unset)</li>\n<li>EFBIG if the stream has reached the last possible ID</li>\n<li>ERANGE if the elements are too large to be stored.</li>\n</ul>\n<p><span id=\"ValkeyModule_StreamDelete\"></span></p>\n<h3><code>ValkeyModule_StreamDelete</code></h3>\n<pre><code>int ValkeyModule_StreamDelete(ValkeyModuleKey *key, ValkeyModuleStreamID *id);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Deletes an entry from a stream.</p>\n<ul>\n<li><code>key</code>: A key opened for writing, with no stream iterator started.</li>\n<li><code>id</code>: The stream ID of the entry to delete.</li>\n</ul>\n<p>Returns <code>VALKEYMODULE_OK</code> on success. On failure, <code>VALKEYMODULE_ERR</code> is returned<br>and <code>errno</code> is set as follows:</p>\n<ul>\n<li>EINVAL if called with invalid arguments</li>\n<li>ENOTSUP if the key refers to a value of a type other than stream or if the<br>key is empty</li>\n<li>EBADF if the key was not opened for writing or if a stream iterator is<br>associated with the key</li>\n<li>ENOENT if no entry with the given stream ID exists</li>\n</ul>\n<p>See also <a href=\"#ValkeyModule_StreamIteratorDelete\"><code>ValkeyModule_StreamIteratorDelete()</code></a> for deleting the current entry while<br>iterating using a stream iterator.</p>\n<p><span id=\"ValkeyModule_StreamIteratorStart\"></span></p>\n<h3><code>ValkeyModule_StreamIteratorStart</code></h3>\n<pre><code>int ValkeyModule_StreamIteratorStart(ValkeyModuleKey *key,\n                                     int flags,\n                                     ValkeyModuleStreamID *start,\n                                     ValkeyModuleStreamID *end);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Sets up a stream iterator.</p>\n<ul>\n<li><code>key</code>: The stream key opened for reading using <a href=\"#ValkeyModule_OpenKey\"><code>ValkeyModule_OpenKey()</code></a>.</li>\n<li><code>flags</code>:<ul>\n<li><code>VALKEYMODULE_STREAM_ITERATOR_EXCLUSIVE</code>: Don&#39;t include <code>start</code> and <code>end</code><br>in the iterated range.</li>\n<li><code>VALKEYMODULE_STREAM_ITERATOR_REVERSE</code>: Iterate in reverse order, starting<br>from the <code>end</code> of the range.</li>\n</ul>\n</li>\n<li><code>start</code>: The lower bound of the range. Use NULL for the beginning of the<br>stream.</li>\n<li><code>end</code>: The upper bound of the range. Use NULL for the end of the stream.</li>\n</ul>\n<p>Returns <code>VALKEYMODULE_OK</code> on success. On failure, <code>VALKEYMODULE_ERR</code> is returned<br>and <code>errno</code> is set as follows:</p>\n<ul>\n<li>EINVAL if called with invalid arguments</li>\n<li>ENOTSUP if the key refers to a value of a type other than stream or if the<br>key is empty</li>\n<li>EBADF if the key was not opened for writing or if a stream iterator is<br>already associated with the key</li>\n<li>EDOM if <code>start</code> or <code>end</code> is outside the valid range</li>\n</ul>\n<p>Returns <code>VALKEYMODULE_OK</code> on success and <code>VALKEYMODULE_ERR</code> if the key doesn&#39;t<br>refer to a stream or if invalid arguments were given.</p>\n<p>The stream IDs are retrieved using <a href=\"#ValkeyModule_StreamIteratorNextID\"><code>ValkeyModule_StreamIteratorNextID()</code></a> and<br>for each stream ID, the fields and values are retrieved using<br><a href=\"#ValkeyModule_StreamIteratorNextField\"><code>ValkeyModule_StreamIteratorNextField()</code></a>. The iterator is freed by calling<br><a href=\"#ValkeyModule_StreamIteratorStop\"><code>ValkeyModule_StreamIteratorStop()</code></a>.</p>\n<p>Example (error handling omitted):</p>\n<pre><code>ValkeyModule_StreamIteratorStart(key, 0, startid_ptr, endid_ptr);\nValkeyModuleStreamID id;\nlong numfields;\nwhile (ValkeyModule_StreamIteratorNextID(key, &amp;id, &amp;numfields) ==\n       VALKEYMODULE_OK) {\n    ValkeyModuleString *field, *value;\n    while (ValkeyModule_StreamIteratorNextField(key, &amp;field, &amp;value) ==\n           VALKEYMODULE_OK) {\n        //\n        // ... Do stuff ...\n        //\n        ValkeyModule_FreeString(ctx, field);\n        ValkeyModule_FreeString(ctx, value);\n    }\n}\nValkeyModule_StreamIteratorStop(key);\n</code></pre>\n<p><span id=\"ValkeyModule_StreamIteratorStop\"></span></p>\n<h3><code>ValkeyModule_StreamIteratorStop</code></h3>\n<pre><code>int ValkeyModule_StreamIteratorStop(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Stops a stream iterator created using <a href=\"#ValkeyModule_StreamIteratorStart\"><code>ValkeyModule_StreamIteratorStart()</code></a> and<br>reclaims its memory.</p>\n<p>Returns <code>VALKEYMODULE_OK</code> on success. On failure, <code>VALKEYMODULE_ERR</code> is returned<br>and <code>errno</code> is set as follows:</p>\n<ul>\n<li>EINVAL if called with a NULL key</li>\n<li>ENOTSUP if the key refers to a value of a type other than stream or if the<br>key is empty</li>\n<li>EBADF if the key was not opened for writing or if no stream iterator is<br>associated with the key</li>\n</ul>\n<p><span id=\"ValkeyModule_StreamIteratorNextID\"></span></p>\n<h3><code>ValkeyModule_StreamIteratorNextID</code></h3>\n<pre><code>int ValkeyModule_StreamIteratorNextID(ValkeyModuleKey *key,\n                                      ValkeyModuleStreamID *id,\n                                      long *numfields);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Finds the next stream entry and returns its stream ID and the number of<br>fields.</p>\n<ul>\n<li><code>key</code>: Key for which a stream iterator has been started using<br><a href=\"#ValkeyModule_StreamIteratorStart\"><code>ValkeyModule_StreamIteratorStart()</code></a>.</li>\n<li><code>id</code>: The stream ID returned. NULL if you don&#39;t care.</li>\n<li><code>numfields</code>: The number of fields in the found stream entry. NULL if you<br>don&#39;t care.</li>\n</ul>\n<p>Returns <code>VALKEYMODULE_OK</code> and sets <code>*id</code> and <code>*numfields</code> if an entry was found.<br>On failure, <code>VALKEYMODULE_ERR</code> is returned and <code>errno</code> is set as follows:</p>\n<ul>\n<li>EINVAL if called with a NULL key</li>\n<li>ENOTSUP if the key refers to a value of a type other than stream or if the<br>key is empty</li>\n<li>EBADF if no stream iterator is associated with the key</li>\n<li>ENOENT if there are no more entries in the range of the iterator</li>\n</ul>\n<p>In practice, if <a href=\"#ValkeyModule_StreamIteratorNextID\"><code>ValkeyModule_StreamIteratorNextID()</code></a> is called after a successful call<br>to <a href=\"#ValkeyModule_StreamIteratorStart\"><code>ValkeyModule_StreamIteratorStart()</code></a> and with the same key, it is safe to assume that<br>an <code>VALKEYMODULE_ERR</code> return value means that there are no more entries.</p>\n<p>Use <a href=\"#ValkeyModule_StreamIteratorNextField\"><code>ValkeyModule_StreamIteratorNextField()</code></a> to retrieve the fields and values.<br>See the example at <a href=\"#ValkeyModule_StreamIteratorStart\"><code>ValkeyModule_StreamIteratorStart()</code></a>.</p>\n<p><span id=\"ValkeyModule_StreamIteratorNextField\"></span></p>\n<h3><code>ValkeyModule_StreamIteratorNextField</code></h3>\n<pre><code>int ValkeyModule_StreamIteratorNextField(ValkeyModuleKey *key,\n                                         ValkeyModuleString **field_ptr,\n                                         ValkeyModuleString **value_ptr);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Retrieves the next field of the current stream ID and its corresponding value<br>in a stream iteration. This function should be called repeatedly after calling<br><a href=\"#ValkeyModule_StreamIteratorNextID\"><code>ValkeyModule_StreamIteratorNextID()</code></a> to fetch each field-value pair.</p>\n<ul>\n<li><code>key</code>: Key where a stream iterator has been started.</li>\n<li><code>field_ptr</code>: This is where the field is returned.</li>\n<li><code>value_ptr</code>: This is where the value is returned.</li>\n</ul>\n<p>Returns <code>VALKEYMODULE_OK</code> and points <code>*field_ptr</code> and <code>*value_ptr</code> to freshly<br>allocated <code>ValkeyModuleString</code> objects. The string objects are freed<br>automatically when the callback finishes if automatic memory is enabled. On<br>failure, <code>VALKEYMODULE_ERR</code> is returned and <code>errno</code> is set as follows:</p>\n<ul>\n<li>EINVAL if called with a NULL key</li>\n<li>ENOTSUP if the key refers to a value of a type other than stream or if the<br>key is empty</li>\n<li>EBADF if no stream iterator is associated with the key</li>\n<li>ENOENT if there are no more fields in the current stream entry</li>\n</ul>\n<p>In practice, if <a href=\"#ValkeyModule_StreamIteratorNextField\"><code>ValkeyModule_StreamIteratorNextField()</code></a> is called after a successful<br>call to <a href=\"#ValkeyModule_StreamIteratorNextID\"><code>ValkeyModule_StreamIteratorNextID()</code></a> and with the same key, it is safe to assume<br>that an <code>VALKEYMODULE_ERR</code> return value means that there are no more fields.</p>\n<p>See the example at <a href=\"#ValkeyModule_StreamIteratorStart\"><code>ValkeyModule_StreamIteratorStart()</code></a>.</p>\n<p><span id=\"ValkeyModule_StreamIteratorDelete\"></span></p>\n<h3><code>ValkeyModule_StreamIteratorDelete</code></h3>\n<pre><code>int ValkeyModule_StreamIteratorDelete(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Deletes the current stream entry while iterating.</p>\n<p>This function can be called after <a href=\"#ValkeyModule_StreamIteratorNextID\"><code>ValkeyModule_StreamIteratorNextID()</code></a> or after any<br>calls to <a href=\"#ValkeyModule_StreamIteratorNextField\"><code>ValkeyModule_StreamIteratorNextField()</code></a>.</p>\n<p>Returns <code>VALKEYMODULE_OK</code> on success. On failure, <code>VALKEYMODULE_ERR</code> is returned<br>and <code>errno</code> is set as follows:</p>\n<ul>\n<li>EINVAL if key is NULL</li>\n<li>ENOTSUP if the key is empty or is of another type than stream</li>\n<li>EBADF if the key is not opened for writing, if no iterator has been started</li>\n<li>ENOENT if the iterator has no current stream entry</li>\n</ul>\n<p><span id=\"ValkeyModule_StreamTrimByLength\"></span></p>\n<h3><code>ValkeyModule_StreamTrimByLength</code></h3>\n<pre><code>long long ValkeyModule_StreamTrimByLength(ValkeyModuleKey *key,\n                                          int flags,\n                                          long long length);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Trim a stream by length, similar to XTRIM with MAXLEN.</p>\n<ul>\n<li><code>key</code>: Key opened for writing.</li>\n<li><code>flags</code>: A bitfield of<ul>\n<li><code>VALKEYMODULE_STREAM_TRIM_APPROX</code>: Trim less if it improves performance,<br>like XTRIM with <code>~</code>.</li>\n</ul>\n</li>\n<li><code>length</code>: The number of stream entries to keep after trimming.</li>\n</ul>\n<p>Returns the number of entries deleted. On failure, a negative value is<br>returned and <code>errno</code> is set as follows:</p>\n<ul>\n<li>EINVAL if called with invalid arguments</li>\n<li>ENOTSUP if the key is empty or of a type other than stream</li>\n<li>EBADF if the key is not opened for writing</li>\n</ul>\n<p><span id=\"ValkeyModule_StreamTrimByID\"></span></p>\n<h3><code>ValkeyModule_StreamTrimByID</code></h3>\n<pre><code>long long ValkeyModule_StreamTrimByID(ValkeyModuleKey *key,\n                                      int flags,\n                                      ValkeyModuleStreamID *id);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Trim a stream by ID, similar to XTRIM with MINID.</p>\n<ul>\n<li><code>key</code>: Key opened for writing.</li>\n<li><code>flags</code>: A bitfield of<ul>\n<li><code>VALKEYMODULE_STREAM_TRIM_APPROX</code>: Trim less if it improves performance,<br>like XTRIM with <code>~</code>.</li>\n</ul>\n</li>\n<li><code>id</code>: The smallest stream ID to keep after trimming.</li>\n</ul>\n<p>Returns the number of entries deleted. On failure, a negative value is<br>returned and <code>errno</code> is set as follows:</p>\n<ul>\n<li>EINVAL if called with invalid arguments</li>\n<li>ENOTSUP if the key is empty or of a type other than stream</li>\n<li>EBADF if the key is not opened for writing</li>\n</ul>\n<p><span id=\"section-calling-commands-from-modules\"></span></p>\n<h2>Calling commands from modules</h2>\n<p><a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call()</code></a> sends a command to the server. The remaining functions handle the reply.</p>\n<p><span id=\"ValkeyModule_FreeCallReply\"></span></p>\n<h3><code>ValkeyModule_FreeCallReply</code></h3>\n<pre><code>void ValkeyModule_FreeCallReply(ValkeyModuleCallReply *reply);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Free a Call reply and all the nested replies it contains if it&#39;s an<br>array.</p>\n<p><span id=\"ValkeyModule_CallReplyType\"></span></p>\n<h3><code>ValkeyModule_CallReplyType</code></h3>\n<pre><code>int ValkeyModule_CallReplyType(ValkeyModuleCallReply *reply);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return the reply type as one of the following:</p>\n<ul>\n<li><code>VALKEYMODULE_REPLY_UNKNOWN</code></li>\n<li><code>VALKEYMODULE_REPLY_STRING</code></li>\n<li><code>VALKEYMODULE_REPLY_ERROR</code></li>\n<li><code>VALKEYMODULE_REPLY_INTEGER</code></li>\n<li><code>VALKEYMODULE_REPLY_ARRAY</code></li>\n<li><code>VALKEYMODULE_REPLY_NULL</code></li>\n<li><code>VALKEYMODULE_REPLY_MAP</code></li>\n<li><code>VALKEYMODULE_REPLY_SET</code></li>\n<li><code>VALKEYMODULE_REPLY_BOOL</code></li>\n<li><code>VALKEYMODULE_REPLY_DOUBLE</code></li>\n<li><code>VALKEYMODULE_REPLY_BIG_NUMBER</code></li>\n<li><code>VALKEYMODULE_REPLY_VERBATIM_STRING</code></li>\n<li><code>VALKEYMODULE_REPLY_ATTRIBUTE</code></li>\n<li><code>VALKEYMODULE_REPLY_PROMISE</code></li>\n</ul>\n<p><span id=\"ValkeyModule_CallReplyLength\"></span></p>\n<h3><code>ValkeyModule_CallReplyLength</code></h3>\n<pre><code>size_t ValkeyModule_CallReplyLength(ValkeyModuleCallReply *reply);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return the reply type length, where applicable.</p>\n<p><span id=\"ValkeyModule_CallReplyArrayElement\"></span></p>\n<h3><code>ValkeyModule_CallReplyArrayElement</code></h3>\n<pre><code>ValkeyModuleCallReply *ValkeyModule_CallReplyArrayElement(ValkeyModuleCallReply *reply,\n                                                          size_t idx);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return the &#39;idx&#39;-th nested call reply element of an array reply, or NULL<br>if the reply type is wrong or the index is out of range.</p>\n<p><span id=\"ValkeyModule_CallReplyInteger\"></span></p>\n<h3><code>ValkeyModule_CallReplyInteger</code></h3>\n<pre><code>long long ValkeyModule_CallReplyInteger(ValkeyModuleCallReply *reply);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return the <code>long long</code> of an integer reply.</p>\n<p><span id=\"ValkeyModule_CallReplyDouble\"></span></p>\n<h3><code>ValkeyModule_CallReplyDouble</code></h3>\n<pre><code>double ValkeyModule_CallReplyDouble(ValkeyModuleCallReply *reply);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Return the double value of a double reply.</p>\n<p><span id=\"ValkeyModule_CallReplyBigNumber\"></span></p>\n<h3><code>ValkeyModule_CallReplyBigNumber</code></h3>\n<pre><code>const char *ValkeyModule_CallReplyBigNumber(ValkeyModuleCallReply *reply,\n                                            size_t *len);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Return the big number value of a big number reply.</p>\n<p><span id=\"ValkeyModule_CallReplyVerbatim\"></span></p>\n<h3><code>ValkeyModule_CallReplyVerbatim</code></h3>\n<pre><code>const char *ValkeyModule_CallReplyVerbatim(ValkeyModuleCallReply *reply,\n                                           size_t *len,\n                                           const char **format);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Return the value of a verbatim string reply,<br>An optional output argument can be given to get verbatim reply format.</p>\n<p><span id=\"ValkeyModule_CallReplyBool\"></span></p>\n<h3><code>ValkeyModule_CallReplyBool</code></h3>\n<pre><code>int ValkeyModule_CallReplyBool(ValkeyModuleCallReply *reply);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Return the Boolean value of a Boolean reply.</p>\n<p><span id=\"ValkeyModule_CallReplySetElement\"></span></p>\n<h3><code>ValkeyModule_CallReplySetElement</code></h3>\n<pre><code>ValkeyModuleCallReply *ValkeyModule_CallReplySetElement(ValkeyModuleCallReply *reply,\n                                                        size_t idx);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Return the &#39;idx&#39;-th nested call reply element of a set reply, or NULL<br>if the reply type is wrong or the index is out of range.</p>\n<p><span id=\"ValkeyModule_CallReplyMapElement\"></span></p>\n<h3><code>ValkeyModule_CallReplyMapElement</code></h3>\n<pre><code>int ValkeyModule_CallReplyMapElement(ValkeyModuleCallReply *reply,\n                                     size_t idx,\n                                     ValkeyModuleCallReply **key,\n                                     ValkeyModuleCallReply **val);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Retrieve the &#39;idx&#39;-th key and value of a map reply.</p>\n<p>Returns:</p>\n<ul>\n<li><code>VALKEYMODULE_OK</code> on success.</li>\n<li><code>VALKEYMODULE_ERR</code> if idx out of range or if the reply type is wrong.</li>\n</ul>\n<p>The <code>key</code> and <code>value</code> arguments are used to return by reference, and may be<br>NULL if not required.</p>\n<p><span id=\"ValkeyModule_CallReplyAttribute\"></span></p>\n<h3><code>ValkeyModule_CallReplyAttribute</code></h3>\n<pre><code>ValkeyModuleCallReply *ValkeyModule_CallReplyAttribute(ValkeyModuleCallReply *reply);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Return the attribute of the given reply, or NULL if no attribute exists.</p>\n<p><span id=\"ValkeyModule_CallReplyAttributeElement\"></span></p>\n<h3><code>ValkeyModule_CallReplyAttributeElement</code></h3>\n<pre><code> int ValkeyModule_CallReplyAttributeElement(ValkeyModuleCallReply *reply,\n                                           size_t idx,\n                                           ValkeyModuleCallReply **key,\n                                           ValkeyModuleCallReply **val);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Retrieve the &#39;idx&#39;-th key and value of an attribute reply.</p>\n<p>Returns:</p>\n<ul>\n<li><code>VALKEYMODULE_OK</code> on success.</li>\n<li><code>VALKEYMODULE_ERR</code> if idx out of range or if the reply type is wrong.</li>\n</ul>\n<p>The <code>key</code> and <code>value</code> arguments are used to return by reference, and may be<br>NULL if not required.</p>\n<p><span id=\"ValkeyModule_CallReplyPromiseSetUnblockHandler\"></span></p>\n<h3><code>ValkeyModule_CallReplyPromiseSetUnblockHandler</code></h3>\n<pre><code> void ValkeyModule_CallReplyPromiseSetUnblockHandler(ValkeyModuleCallReply *reply,\n                                                    ValkeyModuleOnUnblocked on_unblock,\n                                                    void *private_data);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Set unblock handler (callback and private data) on the given promise <code>ValkeyModuleCallReply</code>.<br>The given reply must be of promise type (<code>VALKEYMODULE_REPLY_PROMISE</code>).</p>\n<p><span id=\"ValkeyModule_CallReplyPromiseAbort\"></span></p>\n<h3><code>ValkeyModule_CallReplyPromiseAbort</code></h3>\n<pre><code>int ValkeyModule_CallReplyPromiseAbort(ValkeyModuleCallReply *reply,\n                                       void **private_data);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Abort the execution of a given promise <code>ValkeyModuleCallReply</code>.<br>return <code>REDMODULE_OK</code> in case the abort was done successfully and <code>VALKEYMODULE_ERR</code><br>if its not possible to abort the execution (execution already finished).<br>In case the execution was aborted (<code>REDMODULE_OK</code> was returned), the <code>private_data</code> out parameter<br>will be set with the value of the private data that was given on &#39;<a href=\"#ValkeyModule_CallReplyPromiseSetUnblockHandler\"><code>ValkeyModule_CallReplyPromiseSetUnblockHandler</code></a>&#39;<br>so the caller will be able to release the private data.</p>\n<p>If the execution was aborted successfully, it is promised that the unblock handler will not be called.<br>That said, it is possible that the abort operation will successes but the operation will still continue.<br>This can happened if, for example, a module implements some blocking command and does not respect the<br>disconnect callback. For server-provided commands this can not happened.</p>\n<p><span id=\"ValkeyModule_CallReplyStringPtr\"></span></p>\n<h3><code>ValkeyModule_CallReplyStringPtr</code></h3>\n<pre><code>const char *ValkeyModule_CallReplyStringPtr(ValkeyModuleCallReply *reply,\n                                            size_t *len);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return the pointer and length of a string or error reply.</p>\n<p><span id=\"ValkeyModule_CreateStringFromCallReply\"></span></p>\n<h3><code>ValkeyModule_CreateStringFromCallReply</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_CreateStringFromCallReply(ValkeyModuleCallReply *reply);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return a new string object from a call reply of type string, error or<br>integer. Otherwise (wrong reply type) return NULL.</p>\n<p><span id=\"ValkeyModule_SetContextUser\"></span></p>\n<h3><code>ValkeyModule_SetContextUser</code></h3>\n<pre><code>void ValkeyModule_SetContextUser(ValkeyModuleCtx *ctx,\n                                 const ValkeyModuleUser *user);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.6</p>\n<p>Modifies the user that <a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call</code></a> will use (e.g. for ACL checks)</p>\n<p><span id=\"ValkeyModule_Call\"></span></p>\n<h3><code>ValkeyModule_Call</code></h3>\n<pre><code>ValkeyModuleCallReply *ValkeyModule_Call(ValkeyModuleCtx *ctx,\n                                         const char *cmdname,\n                                         const char *fmt,\n                                         ...);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Exported API to call any command from modules.</p>\n<ul>\n<li><p><strong>cmdname</strong>: The command to call.</p>\n</li>\n<li><p><strong>fmt</strong>: A format specifier string for the command&#39;s arguments. Each<br>of the arguments should be specified by a valid type specification. The<br>format specifier can also contain the modifiers <code>!</code>, <code>A</code>, <code>3</code> and <code>R</code> which<br>don&#39;t have a corresponding argument.</p>\n<ul>\n<li><code>b</code> -- The argument is a buffer and is immediately followed by another<br>   argument that is the buffer&#39;s length.</li>\n<li><code>c</code> -- The argument is a pointer to a plain C string (null-terminated).</li>\n<li><code>l</code> -- The argument is a <code>long long</code> integer.</li>\n<li><code>s</code> -- The argument is a ValkeyModuleString.</li>\n<li><code>v</code> -- The argument(s) is a vector of ValkeyModuleString.</li>\n<li><code>!</code> -- Sends the command and its arguments to replicas and AOF.</li>\n<li><code>A</code> -- Suppress AOF propagation, send only to replicas (requires <code>!</code>).</li>\n<li><code>R</code> -- Suppress replicas propagation, send only to AOF (requires <code>!</code>).</li>\n<li><code>3</code> -- Return a RESP3 reply. This will change the command reply.<br>   e.g., HGETALL returns a map instead of a flat array.</li>\n<li><code>0</code> -- Return the reply in auto mode, i.e. the reply format will be the<br>   same as the client attached to the given ValkeyModuleCtx. This will<br>   probably used when you want to pass the reply directly to the client.</li>\n<li><code>C</code> -- Run a command as the user attached to the context.<br>   User is either attached automatically via the client that directly<br>   issued the command and created the context or via ValkeyModule_SetContextUser.<br>   If the context is not directly created by an issued command (such as a<br>   background context and no user was set on it via ValkeyModule_SetContextUser,<br>   ValkeyModule_Call will fail.<br>   Checks if the command can be executed according to ACL rules and causes<br>   the command to run as the determined user, so that any future user<br>   dependent activity, such as ACL checks within scripts will proceed as<br>   expected.<br>   Otherwise, the command will run as the unrestricted user.</li>\n<li><code>S</code> -- Run the command in a script mode, this means that it will raise<br>   an error if a command which are not allowed inside a script<br>   (flagged with the <code>deny-script</code> flag) is invoked (like SHUTDOWN).<br>   In addition, on script mode, write commands are not allowed if there are<br>   not enough good replicas (as configured with <code>min-replicas-to-write</code>)<br>   or when the server is unable to persist to the disk.</li>\n<li><code>W</code> -- Do not allow to run any write command (flagged with the <code>write</code> flag).</li>\n<li><code>M</code> -- Do not allow <code>deny-oom</code> flagged commands when over the memory limit.</li>\n<li><code>E</code> -- Return error as ValkeyModuleCallReply. If there is an error before<br>   invoking the command, the error is returned using errno mechanism.<br>   This flag allows to get the error also as an error CallReply with<br>   relevant error message.</li>\n<li>&#39;D&#39; -- A &quot;Dry Run&quot; mode. Return before executing the underlying call().<br>   If everything succeeded, it will return with a NULL, otherwise it will<br>   return with a CallReply object denoting the error, as if it was called with<br>   the &#39;E&#39; code.</li>\n<li>&#39;K&#39; -- Allow running blocking commands. If enabled and the command gets blocked, a<br>   special VALKEYMODULE_REPLY_PROMISE will be returned. This reply type<br>   indicates that the command was blocked and the reply will be given asynchronously.<br>   The module can use this reply object to set a handler which will be called when<br>   the command gets unblocked using ValkeyModule_CallReplyPromiseSetUnblockHandler.<br>   The handler must be set immediately after the command invocation (without releasing<br>   the lock in between). If the handler is not set, the blocking command will<br>   still continue its execution but the reply will be ignored (fire and forget),<br>   notice that this is dangerous in case of role change, as explained below.<br>   The module can use ValkeyModule_CallReplyPromiseAbort to abort the command invocation<br>   if it was not yet finished (see ValkeyModule_CallReplyPromiseAbort documentation for more<br>   details). It is also the module&#39;s responsibility to abort the execution on role change, either by using<br>   server event (to get notified when the instance becomes a replica) or relying on the disconnect<br>   callback of the original client. Failing to do so can result in a write operation on a replica.<br>   Unlike other call replies, promise call reply <strong>must</strong> be freed while the GIL is locked.<br>   Notice that on unblocking, the only promise is that the unblock handler will be called,<br>   If the blocking ValkeyModule_Call caused the module to also block some real client (using ValkeyModule_BlockClient),<br>   it is the module responsibility to unblock this client on the unblock handler.<br>   On the unblock handler it is only allowed to perform the following:<br>   * Calling additional commands using ValkeyModule_Call<br>   * Open keys using ValkeyModule_OpenKey<br>   * Replicate data to the replica or AOF<br><br>   Specifically, it is not allowed to call any module API which are client related such as:<br>   * ValkeyModule_Reply* API&#39;s<br>   * ValkeyModule_BlockClient<br>   * ValkeyModule_GetCurrentUserName</li>\n</ul>\n</li>\n<li><p><strong>...</strong>: The actual arguments to the command.</p>\n</li>\n</ul>\n<p>On success a <code>ValkeyModuleCallReply</code> object is returned, otherwise<br>NULL is returned and errno is set to the following values:</p>\n<ul>\n<li>EBADF: wrong format specifier.</li>\n<li>EINVAL: wrong command arity.</li>\n<li>ENOENT: command does not exist.</li>\n<li>EPERM: operation in Cluster instance with key in non local slot.</li>\n<li>EROFS: operation in Cluster instance when a write command is sent<br>   in a readonly state.</li>\n<li>ENETDOWN: operation in Cluster instance when cluster is down.</li>\n<li>ENOTSUP: No ACL user for the specified module context</li>\n<li>EACCES: Command cannot be executed, according to ACL rules</li>\n<li>ENOSPC: Write or deny-oom command is not allowed</li>\n<li>ESPIPE: Command not allowed on script mode</li>\n</ul>\n<p>Example code fragment:</p>\n<pre><code> reply = ValkeyModule_Call(ctx,&quot;INCRBY&quot;,&quot;sc&quot;,argv[1],&quot;10&quot;);\n if (ValkeyModule_CallReplyType(reply) == VALKEYMODULE_REPLY_INTEGER) {\n   long long myval = ValkeyModule_CallReplyInteger(reply);\n   // Do something with myval.\n }\n</code></pre>\n<p>This API is documented here: <a href=\"https://valkey.io/topics/modules-intro\">https://valkey.io/topics/modules-intro</a></p>\n<p><span id=\"ValkeyModule_CallReplyProto\"></span></p>\n<h3><code>ValkeyModule_CallReplyProto</code></h3>\n<pre><code>const char *ValkeyModule_CallReplyProto(ValkeyModuleCallReply *reply,\n                                        size_t *len);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return a pointer, and a length, to the protocol returned by the command<br>that returned the reply object.</p>\n<p><span id=\"section-modules-data-types\"></span></p>\n<h2>Modules data types</h2>\n<p>When String DMA or using existing data structures is not enough, it is<br>possible to create new data types from scratch.<br>The module must provide a set of callbacks for handling the<br>new values exported (for example in order to provide RDB saving/loading,<br>AOF rewrite, and so forth). In this section we define this API.</p>\n<p><span id=\"ValkeyModule_CreateDataType\"></span></p>\n<h3><code>ValkeyModule_CreateDataType</code></h3>\n<pre><code>moduleType *ValkeyModule_CreateDataType(ValkeyModuleCtx *ctx,\n                                        const char *name,\n                                        int encver,\n                                        void *typemethods_ptr);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Register a new data type exported by the module. The parameters are the<br>following. Please for in depth documentation check the modules API<br>documentation, especially <a href=\"https://valkey.io/topics/modules-native-types\">https://valkey.io/topics/modules-native-types</a>.</p>\n<ul>\n<li><p><strong>name</strong>: A 9 characters data type name that MUST be unique in the<br>Modules ecosystem. Be creative... and there will be no collisions. Use<br>the charset A-Z a-z 9-0, plus the two &quot;-_&quot; characters. A good<br>idea is to use, for example <code>&lt;typename&gt;-&lt;vendor&gt;</code>. For example<br>&quot;tree-AntZ&quot; may mean &quot;Tree data structure by @antirez&quot;. To use both<br>lower case and upper case letters helps in order to prevent collisions.</p>\n</li>\n<li><p><strong>encver</strong>: Encoding version, which is, the version of the serialization<br>that a module used in order to persist data. As long as the &quot;name&quot;<br>matches, the RDB loading will be dispatched to the type callbacks<br>whatever &#39;encver&#39; is used, however the module can understand if<br>the encoding it must load are of an older version of the module.<br>For example the module &quot;tree-AntZ&quot; initially used encver=0. Later<br>after an upgrade, it started to serialize data in a different format<br>and to register the type with encver=1. However this module may<br>still load old data produced by an older version if the <code>rdb_load</code><br>callback is able to check the encver value and act accordingly.<br>The encver must be a positive value between 0 and 1023.</p>\n</li>\n<li><p><strong>typemethods_ptr</strong> is a pointer to a <code>ValkeyModuleTypeMethods</code> structure<br>that should be populated with the methods callbacks and structure<br>version, like in the following example:</p>\n<pre><code>  ValkeyModuleTypeMethods tm = {\n      .version = VALKEYMODULE_TYPE_METHOD_VERSION,\n      .rdb_load = myType_RDBLoadCallBack,\n      .rdb_save = myType_RDBSaveCallBack,\n      .aof_rewrite = myType_AOFRewriteCallBack,\n      .free = myType_FreeCallBack,\n\n      // Optional fields\n      .digest = myType_DigestCallBack,\n      .mem_usage = myType_MemUsageCallBack,\n      .aux_load = myType_AuxRDBLoadCallBack,\n      .aux_save = myType_AuxRDBSaveCallBack,\n      .free_effort = myType_FreeEffortCallBack,\n      .unlink = myType_UnlinkCallBack,\n      .copy = myType_CopyCallback,\n      .defrag = myType_DefragCallback\n\n      // Enhanced optional fields\n      .mem_usage2 = myType_MemUsageCallBack2,\n      .free_effort2 = myType_FreeEffortCallBack2,\n      .unlink2 = myType_UnlinkCallBack2,\n      .copy2 = myType_CopyCallback2,\n  }\n</code></pre>\n</li>\n<li><p><strong>rdb_load</strong>: A callback function pointer that loads data from RDB files.</p>\n</li>\n<li><p><strong>rdb_save</strong>: A callback function pointer that saves data to RDB files.</p>\n</li>\n<li><p><strong>aof_rewrite</strong>: A callback function pointer that rewrites data as commands.</p>\n</li>\n<li><p><strong>digest</strong>: A callback function pointer that is used for <code>DEBUG DIGEST</code>.</p>\n</li>\n<li><p><strong>free</strong>: A callback function pointer that can free a type value.</p>\n</li>\n<li><p><strong>aux_save</strong>: A callback function pointer that saves out of keyspace data to RDB files.<br>&#39;when&#39; argument is either <code>VALKEYMODULE_AUX_BEFORE_RDB</code> or <code>VALKEYMODULE_AUX_AFTER_RDB</code>.</p>\n</li>\n<li><p><strong>aux_load</strong>: A callback function pointer that loads out of keyspace data from RDB files.<br>Similar to <code>aux_save</code>, returns <code>VALKEYMODULE_OK</code> on success, and ERR otherwise.</p>\n</li>\n<li><p><strong>free_effort</strong>: A callback function pointer that used to determine whether the module&#39;s<br>memory needs to be lazy reclaimed. The module should return the complexity involved by<br>freeing the value. for example: how many pointers are gonna be freed. Note that if it<br>returns 0, we&#39;ll always do an async free.</p>\n</li>\n<li><p><strong>unlink</strong>: A callback function pointer that used to notifies the module that the key has<br>been removed from the DB by the server, and may soon be freed by a background thread. Note that<br>it won&#39;t be called on FLUSHALL/FLUSHDB (both sync and async), and the module can use the<br><code>ValkeyModuleEvent_FlushDB</code> to hook into that.</p>\n</li>\n<li><p><strong>copy</strong>: A callback function pointer that is used to make a copy of the specified key.<br>The module is expected to perform a deep copy of the specified value and return it.<br>In addition, hints about the names of the source and destination keys is provided.<br>A NULL return value is considered an error and the copy operation fails.<br>Note: if the target key exists and is being overwritten, the copy callback will be<br>called first, followed by a free callback to the value that is being replaced.</p>\n</li>\n<li><p><strong>defrag</strong>: A callback function pointer that is used to request the module to defrag<br>a key. The module should then iterate pointers and call the relevant <code>ValkeyModule_Defrag*()</code><br>functions to defragment pointers or complex types. The module should continue<br>iterating as long as <a href=\"#ValkeyModule_DefragShouldStop\"><code>ValkeyModule_DefragShouldStop()</code></a> returns a zero value, and return a<br>zero value if finished or non-zero value if more work is left to be done. If more work<br>needs to be done, <a href=\"#ValkeyModule_DefragCursorSet\"><code>ValkeyModule_DefragCursorSet()</code></a> and <a href=\"#ValkeyModule_DefragCursorGet\"><code>ValkeyModule_DefragCursorGet()</code></a> can be used to track<br>this work across different calls.<br>Normally, the defrag mechanism invokes the callback without a time limit, so<br><a href=\"#ValkeyModule_DefragShouldStop\"><code>ValkeyModule_DefragShouldStop()</code></a> always returns zero. The &quot;late defrag&quot; mechanism which has<br>a time limit and provides cursor support is used only for keys that are determined<br>to have significant internal complexity. To determine this, the defrag mechanism<br>uses the <code>free_effort</code> callback and the &#39;active-defrag-max-scan-fields&#39; config directive.<br>NOTE: The value is passed as a <code>void**</code> and the function is expected to update the<br>pointer if the top-level value pointer is defragmented and consequently changes.</p>\n</li>\n<li><p><strong>mem_usage2</strong>: Similar to <code>mem_usage</code>, but provides the <code>ValkeyModuleKeyOptCtx</code> parameter<br>so that meta information such as key name and db id can be obtained, and<br>the <code>sample_size</code> for size estimation (see MEMORY USAGE command).</p>\n</li>\n<li><p><strong>free_effort2</strong>: Similar to <code>free_effort</code>, but provides the <code>ValkeyModuleKeyOptCtx</code> parameter<br>so that meta information such as key name and db id can be obtained.</p>\n</li>\n<li><p><strong>unlink2</strong>: Similar to <code>unlink</code>, but provides the <code>ValkeyModuleKeyOptCtx</code> parameter<br>so that meta information such as key name and db id can be obtained.</p>\n</li>\n<li><p><strong>copy2</strong>: Similar to <code>copy</code>, but provides the <code>ValkeyModuleKeyOptCtx</code> parameter<br>so that meta information such as key names and db ids can be obtained.</p>\n</li>\n<li><p><strong>aux_save2</strong>: Similar to <code>aux_save</code>, but with small semantic change, if the module<br>saves nothing on this callback then no data about this aux field will be written to the<br>RDB and it will be possible to load the RDB even if the module is not loaded.</p>\n</li>\n</ul>\n<p>Note: the module name &quot;AAAAAAAAA&quot; is reserved and produces an error, it<br>happens to be pretty lame as well.</p>\n<p>If <a href=\"#ValkeyModule_CreateDataType\"><code>ValkeyModule_CreateDataType()</code></a> is called outside of <code>ValkeyModule_OnLoad()</code> function,<br>there is already a module registering a type with the same name,<br>or if the module name or encver is invalid, NULL is returned.<br>Otherwise the new type is registered into the server, and a reference of<br>type <code>ValkeyModuleType</code> is returned: the caller of the function should store<br>this reference into a global variable to make future use of it in the<br>modules type API, since a single module may register multiple types.<br>Example code fragment:</p>\n<pre><code> static ValkeyModuleType *BalancedTreeType;\n\n int ValkeyModule_OnLoad(ValkeyModuleCtx *ctx) {\n     // some code here ...\n     BalancedTreeType = ValkeyModule_CreateDataType(...);\n }\n</code></pre>\n<p><span id=\"ValkeyModule_ModuleTypeSetValue\"></span></p>\n<h3><code>ValkeyModule_ModuleTypeSetValue</code></h3>\n<pre><code>int ValkeyModule_ModuleTypeSetValue(ValkeyModuleKey *key,\n                                    moduleType *mt,\n                                    void *value);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>If the key is open for writing, set the specified module type object<br>as the value of the key, deleting the old value if any.<br>On success <code>VALKEYMODULE_OK</code> is returned. If the key is not open for<br>writing or there is an active iterator, <code>VALKEYMODULE_ERR</code> is returned.</p>\n<p><span id=\"ValkeyModule_ModuleTypeGetType\"></span></p>\n<h3><code>ValkeyModule_ModuleTypeGetType</code></h3>\n<pre><code>moduleType *ValkeyModule_ModuleTypeGetType(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Assuming <a href=\"#ValkeyModule_KeyType\"><code>ValkeyModule_KeyType()</code></a> returned <code>VALKEYMODULE_KEYTYPE_MODULE</code> on<br>the key, returns the module type pointer of the value stored at key.</p>\n<p>If the key is NULL, is not associated with a module type, or is empty,<br>then NULL is returned instead.</p>\n<p><span id=\"ValkeyModule_ModuleTypeGetValue\"></span></p>\n<h3><code>ValkeyModule_ModuleTypeGetValue</code></h3>\n<pre><code>void *ValkeyModule_ModuleTypeGetValue(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Assuming <a href=\"#ValkeyModule_KeyType\"><code>ValkeyModule_KeyType()</code></a> returned <code>VALKEYMODULE_KEYTYPE_MODULE</code> on<br>the key, returns the module type low-level value stored at key, as<br>it was set by the user via <a href=\"#ValkeyModule_ModuleTypeSetValue\"><code>ValkeyModule_ModuleTypeSetValue()</code></a>.</p>\n<p>If the key is NULL, is not associated with a module type, or is empty,<br>then NULL is returned instead.</p>\n<p><span id=\"section-rdb-loading-and-saving-functions\"></span></p>\n<h2>RDB loading and saving functions</h2>\n<p><span id=\"ValkeyModule_IsIOError\"></span></p>\n<h3><code>ValkeyModule_IsIOError</code></h3>\n<pre><code>int ValkeyModule_IsIOError(ValkeyModuleIO *io);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Returns true if any previous IO API failed.<br>for <code>Load*</code> APIs the <code>VALKEYMODULE_OPTIONS_HANDLE_IO_ERRORS</code> flag must be set with<br><a href=\"#ValkeyModule_SetModuleOptions\"><code>ValkeyModule_SetModuleOptions</code></a> first.</p>\n<p><span id=\"ValkeyModule_SaveUnsigned\"></span></p>\n<h3><code>ValkeyModule_SaveUnsigned</code></h3>\n<pre><code>void ValkeyModule_SaveUnsigned(ValkeyModuleIO *io, uint64_t value);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Save an unsigned 64 bit value into the RDB file. This function should only<br>be called in the context of the <code>rdb_save</code> method of modules implementing new<br>data types.</p>\n<p><span id=\"ValkeyModule_LoadUnsigned\"></span></p>\n<h3><code>ValkeyModule_LoadUnsigned</code></h3>\n<pre><code>uint64_t ValkeyModule_LoadUnsigned(ValkeyModuleIO *io);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Load an unsigned 64 bit value from the RDB file. This function should only<br>be called in the context of the <code>rdb_load</code> method of modules implementing<br>new data types.</p>\n<p><span id=\"ValkeyModule_SaveSigned\"></span></p>\n<h3><code>ValkeyModule_SaveSigned</code></h3>\n<pre><code>void ValkeyModule_SaveSigned(ValkeyModuleIO *io, int64_t value);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Like <a href=\"#ValkeyModule_SaveUnsigned\"><code>ValkeyModule_SaveUnsigned()</code></a> but for signed 64 bit values.</p>\n<p><span id=\"ValkeyModule_LoadSigned\"></span></p>\n<h3><code>ValkeyModule_LoadSigned</code></h3>\n<pre><code>int64_t ValkeyModule_LoadSigned(ValkeyModuleIO *io);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Like <a href=\"#ValkeyModule_LoadUnsigned\"><code>ValkeyModule_LoadUnsigned()</code></a> but for signed 64 bit values.</p>\n<p><span id=\"ValkeyModule_SaveString\"></span></p>\n<h3><code>ValkeyModule_SaveString</code></h3>\n<pre><code>void ValkeyModule_SaveString(ValkeyModuleIO *io, ValkeyModuleString *s);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>In the context of the <code>rdb_save</code> method of a module type, saves a<br>string into the RDB file taking as input a <code>ValkeyModuleString</code>.</p>\n<p>The string can be later loaded with <a href=\"#ValkeyModule_LoadString\"><code>ValkeyModule_LoadString()</code></a> or<br>other Load family functions expecting a serialized string inside<br>the RDB file.</p>\n<p><span id=\"ValkeyModule_SaveStringBuffer\"></span></p>\n<h3><code>ValkeyModule_SaveStringBuffer</code></h3>\n<pre><code>void ValkeyModule_SaveStringBuffer(ValkeyModuleIO *io,\n                                   const char *str,\n                                   size_t len);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Like <a href=\"#ValkeyModule_SaveString\"><code>ValkeyModule_SaveString()</code></a> but takes a raw C pointer and length<br>as input.</p>\n<p><span id=\"ValkeyModule_LoadString\"></span></p>\n<h3><code>ValkeyModule_LoadString</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_LoadString(ValkeyModuleIO *io);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>In the context of the <code>rdb_load</code> method of a module data type, loads a string<br>from the RDB file, that was previously saved with <a href=\"#ValkeyModule_SaveString\"><code>ValkeyModule_SaveString()</code></a><br>functions family.</p>\n<p>The returned string is a newly allocated <code>ValkeyModuleString</code> object, and<br>the user should at some point free it with a call to <a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a>.</p>\n<p>If the data structure does not store strings as <code>ValkeyModuleString</code> objects,<br>the similar function <a href=\"#ValkeyModule_LoadStringBuffer\"><code>ValkeyModule_LoadStringBuffer()</code></a> could be used instead.</p>\n<p><span id=\"ValkeyModule_LoadStringBuffer\"></span></p>\n<h3><code>ValkeyModule_LoadStringBuffer</code></h3>\n<pre><code>char *ValkeyModule_LoadStringBuffer(ValkeyModuleIO *io, size_t *lenptr);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Like <a href=\"#ValkeyModule_LoadString\"><code>ValkeyModule_LoadString()</code></a> but returns a heap allocated string that<br>was allocated with <a href=\"#ValkeyModule_Alloc\"><code>ValkeyModule_Alloc()</code></a>, and can be resized or freed with<br><a href=\"#ValkeyModule_Realloc\"><code>ValkeyModule_Realloc()</code></a> or <a href=\"#ValkeyModule_Free\"><code>ValkeyModule_Free()</code></a>.</p>\n<p>The size of the string is stored at &#39;*lenptr&#39; if not NULL.<br>The returned string is not automatically NULL terminated, it is loaded<br>exactly as it was stored inside the RDB file.</p>\n<p><span id=\"ValkeyModule_SaveDouble\"></span></p>\n<h3><code>ValkeyModule_SaveDouble</code></h3>\n<pre><code>void ValkeyModule_SaveDouble(ValkeyModuleIO *io, double value);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>In the context of the <code>rdb_save</code> method of a module data type, saves a double<br>value to the RDB file. The double can be a valid number, a NaN or infinity.<br>It is possible to load back the value with <a href=\"#ValkeyModule_LoadDouble\"><code>ValkeyModule_LoadDouble()</code></a>.</p>\n<p><span id=\"ValkeyModule_LoadDouble\"></span></p>\n<h3><code>ValkeyModule_LoadDouble</code></h3>\n<pre><code>double ValkeyModule_LoadDouble(ValkeyModuleIO *io);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>In the context of the <code>rdb_save</code> method of a module data type, loads back the<br>double value saved by <a href=\"#ValkeyModule_SaveDouble\"><code>ValkeyModule_SaveDouble()</code></a>.</p>\n<p><span id=\"ValkeyModule_SaveFloat\"></span></p>\n<h3><code>ValkeyModule_SaveFloat</code></h3>\n<pre><code>void ValkeyModule_SaveFloat(ValkeyModuleIO *io, float value);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>In the context of the <code>rdb_save</code> method of a module data type, saves a float<br>value to the RDB file. The float can be a valid number, a NaN or infinity.<br>It is possible to load back the value with <a href=\"#ValkeyModule_LoadFloat\"><code>ValkeyModule_LoadFloat()</code></a>.</p>\n<p><span id=\"ValkeyModule_LoadFloat\"></span></p>\n<h3><code>ValkeyModule_LoadFloat</code></h3>\n<pre><code>float ValkeyModule_LoadFloat(ValkeyModuleIO *io);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>In the context of the <code>rdb_save</code> method of a module data type, loads back the<br>float value saved by <a href=\"#ValkeyModule_SaveFloat\"><code>ValkeyModule_SaveFloat()</code></a>.</p>\n<p><span id=\"ValkeyModule_SaveLongDouble\"></span></p>\n<h3><code>ValkeyModule_SaveLongDouble</code></h3>\n<pre><code>void ValkeyModule_SaveLongDouble(ValkeyModuleIO *io, long double value);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>In the context of the <code>rdb_save</code> method of a module data type, saves a long double<br>value to the RDB file. The double can be a valid number, a NaN or infinity.<br>It is possible to load back the value with <a href=\"#ValkeyModule_LoadLongDouble\"><code>ValkeyModule_LoadLongDouble()</code></a>.</p>\n<p><span id=\"ValkeyModule_LoadLongDouble\"></span></p>\n<h3><code>ValkeyModule_LoadLongDouble</code></h3>\n<pre><code>long double ValkeyModule_LoadLongDouble(ValkeyModuleIO *io);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>In the context of the <code>rdb_save</code> method of a module data type, loads back the<br>long double value saved by <a href=\"#ValkeyModule_SaveLongDouble\"><code>ValkeyModule_SaveLongDouble()</code></a>.</p>\n<p><span id=\"section-key-digest-api-debug-digest-interface-for-modules-types\"></span></p>\n<h2>Key digest API (DEBUG DIGEST interface for modules types)</h2>\n<p><span id=\"ValkeyModule_DigestAddStringBuffer\"></span></p>\n<h3><code>ValkeyModule_DigestAddStringBuffer</code></h3>\n<pre><code>void ValkeyModule_DigestAddStringBuffer(ValkeyModuleDigest *md,\n                                        const char *ele,\n                                        size_t len);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Add a new element to the digest. This function can be called multiple times<br>one element after the other, for all the elements that constitute a given<br>data structure. The function call must be followed by the call to<br><a href=\"#ValkeyModule_DigestEndSequence\"><code>ValkeyModule_DigestEndSequence</code></a> eventually, when all the elements that are<br>always in a given order are added. See the Modules data types<br>documentation for more info. However this is a quick example that uses the<br>Set, Hash and List data types as an example.</p>\n<p>To add a sequence of unordered elements (for example in the case of a<br>Set), the pattern to use is:</p>\n<pre><code>foreach element {\n    AddElement(element);\n    EndSequence();\n}\n</code></pre>\n<p>Because Sets are not ordered, so every element added has a position that<br>does not depend from the other. However if instead our elements are<br>ordered in pairs, like field-value pairs of a Hash, then one should<br>use:</p>\n<pre><code>foreach key,value {\n    AddElement(key);\n    AddElement(value);\n    EndSequence();\n}\n</code></pre>\n<p>Because the key and value will be always in the above order, while instead<br>the single key-value pairs, can appear in any position into a hash.</p>\n<p>A list of ordered elements would be implemented with:</p>\n<pre><code>foreach element {\n    AddElement(element);\n}\nEndSequence();\n</code></pre>\n<p><span id=\"ValkeyModule_DigestAddLongLong\"></span></p>\n<h3><code>ValkeyModule_DigestAddLongLong</code></h3>\n<pre><code>void ValkeyModule_DigestAddLongLong(ValkeyModuleDigest *md, long long ll);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Like <a href=\"#ValkeyModule_DigestAddStringBuffer\"><code>ValkeyModule_DigestAddStringBuffer()</code></a> but takes a <code>long long</code> as input<br>that gets converted into a string before adding it to the digest.</p>\n<p><span id=\"ValkeyModule_DigestEndSequence\"></span></p>\n<h3><code>ValkeyModule_DigestEndSequence</code></h3>\n<pre><code>void ValkeyModule_DigestEndSequence(ValkeyModuleDigest *md);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>See the documentation for <code>ValkeyModule_DigestAddElement()</code>.</p>\n<p><span id=\"ValkeyModule_LoadDataTypeFromStringEncver\"></span></p>\n<h3><code>ValkeyModule_LoadDataTypeFromStringEncver</code></h3>\n<pre><code>void *ValkeyModule_LoadDataTypeFromStringEncver(const ValkeyModuleString *str,\n                                                const moduleType *mt,\n                                                int encver);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Decode a serialized representation of a module data type &#39;mt&#39;, in a specific encoding version &#39;encver&#39;<br>from string &#39;str&#39; and return a newly allocated value, or NULL if decoding failed.</p>\n<p>This call basically reuses the &#39;<code>rdb_load</code>&#39; callback which module data types<br>implement in order to allow a module to arbitrarily serialize/de-serialize<br>keys, similar to how the &#39;DUMP&#39; and &#39;RESTORE&#39; commands are implemented.</p>\n<p>Modules should generally use the <code>VALKEYMODULE_OPTIONS_HANDLE_IO_ERRORS</code> flag and<br>make sure the de-serialization code properly checks and handles IO errors<br>(freeing allocated buffers and returning a NULL).</p>\n<p>If this is NOT done, the server will handle corrupted (or just truncated) serialized<br>data by producing an error message and terminating the process.</p>\n<p><span id=\"ValkeyModule_LoadDataTypeFromString\"></span></p>\n<h3><code>ValkeyModule_LoadDataTypeFromString</code></h3>\n<pre><code>void *ValkeyModule_LoadDataTypeFromString(const ValkeyModuleString *str,\n                                          const moduleType *mt);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Similar to <a href=\"#ValkeyModule_LoadDataTypeFromStringEncver\"><code>ValkeyModule_LoadDataTypeFromStringEncver</code></a>, original version of the API, kept<br>for backward compatibility.</p>\n<p><span id=\"ValkeyModule_SaveDataTypeToString\"></span></p>\n<h3><code>ValkeyModule_SaveDataTypeToString</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_SaveDataTypeToString(ValkeyModuleCtx *ctx,\n                                                      void *data,\n                                                      const moduleType *mt);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Encode a module data type &#39;mt&#39; value &#39;data&#39; into serialized form, and return it<br>as a newly allocated <code>ValkeyModuleString</code>.</p>\n<p>This call basically reuses the &#39;<code>rdb_save</code>&#39; callback which module data types<br>implement in order to allow a module to arbitrarily serialize/de-serialize<br>keys, similar to how the &#39;DUMP&#39; and &#39;RESTORE&#39; commands are implemented.</p>\n<p><span id=\"ValkeyModule_GetKeyNameFromDigest\"></span></p>\n<h3><code>ValkeyModule_GetKeyNameFromDigest</code></h3>\n<pre><code>const ValkeyModuleString *ValkeyModule_GetKeyNameFromDigest(ValkeyModuleDigest *dig);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Returns the name of the key currently being processed.</p>\n<p><span id=\"ValkeyModule_GetDbIdFromDigest\"></span></p>\n<h3><code>ValkeyModule_GetDbIdFromDigest</code></h3>\n<pre><code>int ValkeyModule_GetDbIdFromDigest(ValkeyModuleDigest *dig);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Returns the database id of the key currently being processed.</p>\n<p><span id=\"section-aof-api-for-modules-data-types\"></span></p>\n<h2>AOF API for modules data types</h2>\n<p><span id=\"ValkeyModule_EmitAOF\"></span></p>\n<h3><code>ValkeyModule_EmitAOF</code></h3>\n<pre><code>void ValkeyModule_EmitAOF(ValkeyModuleIO *io,\n                          const char *cmdname,\n                          const char *fmt,\n                          ...);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Emits a command into the AOF during the AOF rewriting process. This function<br>is only called in the context of the <code>aof_rewrite</code> method of data types exported<br>by a module. The command works exactly like <a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call()</code></a> in the way<br>the parameters are passed, but it does not return anything as the error<br>handling is performed by the server itself.</p>\n<p><span id=\"section-io-context-handling\"></span></p>\n<h2>IO context handling</h2>\n<p><span id=\"ValkeyModule_GetKeyNameFromIO\"></span></p>\n<h3><code>ValkeyModule_GetKeyNameFromIO</code></h3>\n<pre><code>const ValkeyModuleString *ValkeyModule_GetKeyNameFromIO(ValkeyModuleIO *io);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.5</p>\n<p>Returns the name of the key currently being processed.<br>There is no guarantee that the key name is always available, so this may return NULL.</p>\n<p><span id=\"ValkeyModule_GetKeyNameFromModuleKey\"></span></p>\n<h3><code>ValkeyModule_GetKeyNameFromModuleKey</code></h3>\n<pre><code>const ValkeyModuleString *ValkeyModule_GetKeyNameFromModuleKey(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Returns a <code>ValkeyModuleString</code> with the name of the key from <code>ValkeyModuleKey</code>.</p>\n<p><span id=\"ValkeyModule_GetDbIdFromModuleKey\"></span></p>\n<h3><code>ValkeyModule_GetDbIdFromModuleKey</code></h3>\n<pre><code>int ValkeyModule_GetDbIdFromModuleKey(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Returns a database id of the key from <code>ValkeyModuleKey</code>.</p>\n<p><span id=\"ValkeyModule_GetDbIdFromIO\"></span></p>\n<h3><code>ValkeyModule_GetDbIdFromIO</code></h3>\n<pre><code>int ValkeyModule_GetDbIdFromIO(ValkeyModuleIO *io);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Returns the database id of the key currently being processed.<br>There is no guarantee that this info is always available, so this may return -1.</p>\n<p><span id=\"section-logging\"></span></p>\n<h2>Logging</h2>\n<p><span id=\"ValkeyModule_Log\"></span></p>\n<h3><code>ValkeyModule_Log</code></h3>\n<pre><code>void ValkeyModule_Log(ValkeyModuleCtx *ctx,\n                      const char *levelstr,\n                      const char *fmt,\n                      ...);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Produces a log message to the standard server log, the format accepts<br>printf-alike specifiers, while level is a string describing the log<br>level to use when emitting the log, and must be one of the following:</p>\n<ul>\n<li>&quot;debug&quot; (<code>VALKEYMODULE_LOGLEVEL_DEBUG</code>)</li>\n<li>&quot;verbose&quot; (<code>VALKEYMODULE_LOGLEVEL_VERBOSE</code>)</li>\n<li>&quot;notice&quot; (<code>VALKEYMODULE_LOGLEVEL_NOTICE</code>)</li>\n<li>&quot;warning&quot; (<code>VALKEYMODULE_LOGLEVEL_WARNING</code>)</li>\n</ul>\n<p>If the specified log level is invalid, verbose is used by default.<br>There is a fixed limit to the length of the log line this function is able<br>to emit, this limit is not specified but is guaranteed to be more than<br>a few lines of text.</p>\n<p>The ctx argument may be NULL if cannot be provided in the context of the<br>caller for instance threads or callbacks, in which case a generic &quot;module&quot;<br>will be used instead of the module name.</p>\n<p><span id=\"ValkeyModule_LogIOError\"></span></p>\n<h3><code>ValkeyModule_LogIOError</code></h3>\n<pre><code>void ValkeyModule_LogIOError(ValkeyModuleIO *io,\n                             const char *levelstr,\n                             const char *fmt,\n                             ...);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Log errors from RDB / AOF serialization callbacks.</p>\n<p>This function should be used when a callback is returning a critical<br>error to the caller since cannot load or save the data for some<br>critical reason.</p>\n<p><span id=\"ValkeyModule__Assert\"></span></p>\n<h3><code>ValkeyModule__Assert</code></h3>\n<pre><code>void ValkeyModule__Assert(const char *estr, const char *file, int line);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Valkey assert function.</p>\n<p>The macro <code>ValkeyModule_Assert(expression)</code> is recommended, rather than<br>calling this function directly.</p>\n<p>A failed assertion will shut down the server and produce logging information<br>that looks identical to information generated by the server itself.</p>\n<p><span id=\"ValkeyModule_LatencyAddSample\"></span></p>\n<h3><code>ValkeyModule_LatencyAddSample</code></h3>\n<pre><code>void ValkeyModule_LatencyAddSample(const char *event, mstime_t latency);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Allows adding event to the latency monitor to be observed by the LATENCY<br>command. The call is skipped if the latency is smaller than the configured<br>latency-monitor-threshold.</p>\n<p><span id=\"section-blocking-clients-from-modules\"></span></p>\n<h2>Blocking clients from modules</h2>\n<p>For a guide about blocking commands in modules, see<br><a href=\"https://valkey.io/topics/modules-blocking-ops\">https://valkey.io/topics/modules-blocking-ops</a>.</p>\n<p><span id=\"ValkeyModule_RegisterAuthCallback\"></span></p>\n<h3><code>ValkeyModule_RegisterAuthCallback</code></h3>\n<pre><code>void ValkeyModule_RegisterAuthCallback(ValkeyModuleCtx *ctx,\n                                       ValkeyModuleAuthCallback cb);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>This API registers a callback to execute in addition to normal password based authentication.<br>Multiple callbacks can be registered across different modules. When a Module is unloaded, all the<br>auth callbacks registered by it are unregistered.<br>The callbacks are attempted (in the order of most recently registered first) when the AUTH/HELLO<br>(with AUTH field provided) commands are called.<br>The callbacks will be called with a module context along with a username and a password, and are<br>expected to take one of the following actions:<br>(1) Authenticate - Use the <code>ValkeyModule_AuthenticateClient</code>* API and return <code>VALKEYMODULE_AUTH_HANDLED</code>.<br>This will immediately end the auth chain as successful and add the OK reply.<br>(2) Deny Authentication - Return <code>VALKEYMODULE_AUTH_HANDLED</code> without authenticating or blocking the<br>client. Optionally, <code>err</code> can be set to a custom error message and <code>err</code> will be automatically<br>freed by the server.<br>This will immediately end the auth chain as unsuccessful and add the ERR reply.<br>(3) Block a client on authentication - Use the <a href=\"#ValkeyModule_BlockClientOnAuth\"><code>ValkeyModule_BlockClientOnAuth</code></a> API and return<br><code>VALKEYMODULE_AUTH_HANDLED</code>. Here, the client will be blocked until the <a href=\"#ValkeyModule_UnblockClient\"><code>ValkeyModule_UnblockClient</code></a> API is used<br>which will trigger the auth reply callback (provided through the <a href=\"#ValkeyModule_BlockClientOnAuth\"><code>ValkeyModule_BlockClientOnAuth</code></a>).<br>In this reply callback, the Module should authenticate, deny or skip handling authentication.<br>(4) Skip handling Authentication - Return <code>VALKEYMODULE_AUTH_NOT_HANDLED</code> without blocking the<br>client. This will allow the engine to attempt the next module auth callback.<br>If none of the callbacks authenticate or deny auth, then password based auth is attempted and<br>will authenticate or add failure logs and reply to the clients accordingly.</p>\n<p>Note: If a client is disconnected while it was in the middle of blocking module auth, that<br>occurrence of the AUTH or HELLO command will not be tracked in the INFO command stats.</p>\n<p>The following is an example of how non-blocking module based authentication can be used:</p>\n<pre><code> int auth_cb(ValkeyModuleCtx *ctx, ValkeyModuleString *username, ValkeyModuleString *password, ValkeyModuleString\n</code></pre>\n<p>**err) { const char *user = <a href=\"#ValkeyModule_StringPtrLen\"><code>ValkeyModule_StringPtrLen</code></a>(username, NULL); const char *pwd =<br><a href=\"#ValkeyModule_StringPtrLen\"><code>ValkeyModule_StringPtrLen</code></a>(password, NULL); if (!strcmp(user,&quot;foo&quot;) &amp;&amp; !strcmp(pwd,&quot;<code>valid_password</code>&quot;)) {<br>             ValkeyModule_AuthenticateClientWithACLUser(ctx, &quot;foo&quot;, 3, NULL, NULL, NULL);<br>             return VALKEYMODULE_AUTH_HANDLED;<br>         }</p>\n<pre><code>     else if (!strcmp(user,&quot;foo&quot;) &amp;&amp; !strcmp(pwd,&quot;wrong_password&quot;)) {\n         ValkeyModuleString *log = ValkeyModule_CreateString(ctx, &quot;Module Auth&quot;, 11);\n         ValkeyModule_ACLAddLogEntryByUserName(ctx, username, log, VALKEYMODULE_ACL_LOG_AUTH);\n         ValkeyModule_FreeString(ctx, log);\n         const char *err_msg = &quot;Auth denied by Misc Module.&quot;;\n         *err = ValkeyModule_CreateString(ctx, err_msg, strlen(err_msg));\n         return VALKEYMODULE_AUTH_HANDLED;\n     }\n     return VALKEYMODULE_AUTH_NOT_HANDLED;\n  }\n\n int ValkeyModule_OnLoad(ValkeyModuleCtx *ctx, ValkeyModuleString **argv, int argc) {\n     if (ValkeyModule_Init(ctx,&quot;authmodule&quot;,1,VALKEYMODULE_APIVER_1)== VALKEYMODULE_ERR)\n         return VALKEYMODULE_ERR;\n     ValkeyModule_RegisterAuthCallback(ctx, auth_cb);\n     return VALKEYMODULE_OK;\n }\n</code></pre>\n<p><span id=\"ValkeyModule_BlockClient\"></span></p>\n<h3><code>ValkeyModule_BlockClient</code></h3>\n<pre><code>ValkeyModuleBlockedClient *ValkeyModule_BlockClient(ValkeyModuleCtx *ctx,\n                                      ValkeyModuleCmdFunc reply_callback,\n                                      ValkeyModuleCmdFunc timeout_callback,\n                                      void (*free_privdata)(ValkeyModuleCtx *, void *),\n                                      long long timeout_ms);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Block a client in the context of a blocking command, returning a handle<br>which will be used, later, in order to unblock the client with a call to<br><a href=\"#ValkeyModule_UnblockClient\"><code>ValkeyModule_UnblockClient()</code></a>. The arguments specify callback functions<br>and a timeout after which the client is unblocked.</p>\n<p>The callbacks are called in the following contexts:</p>\n<pre><code>reply_callback:   called after a successful ValkeyModule_UnblockClient()\n                  call in order to reply to the client and unblock it.\n\ntimeout_callback: called when the timeout is reached or if `CLIENT UNBLOCK`\n                  is invoked, in order to send an error to the client.\n\nfree_privdata:    called in order to free the private data that is passed\n                  by ValkeyModule_UnblockClient() call.\n</code></pre>\n<p>Note: <a href=\"#ValkeyModule_UnblockClient\"><code>ValkeyModule_UnblockClient</code></a> should be called for every blocked client,<br>      even if client was killed, timed-out or disconnected. Failing to do so<br>      will result in memory leaks.</p>\n<p>There are some cases where <a href=\"#ValkeyModule_BlockClient\"><code>ValkeyModule_BlockClient()</code></a> cannot be used:</p>\n<ol>\n<li>If the client is a Lua script.</li>\n<li>If the client is executing a MULTI block.</li>\n</ol>\n<p>In these cases, a call to <a href=\"#ValkeyModule_BlockClient\"><code>ValkeyModule_BlockClient()</code></a> will <strong>not</strong> block the<br>client, but instead produce a specific error reply.</p>\n<p>A module that registers a <code>timeout_callback</code> function can also be unblocked<br>using the <code>CLIENT UNBLOCK</code> command, which will trigger the timeout callback.<br>If a callback function is not registered, then the blocked client will be<br>treated as if it is not in a blocked state and <code>CLIENT UNBLOCK</code> will return<br>a zero value.</p>\n<p>Measuring background time: By default the time spent in the blocked command<br>is not account for the total command duration. To include such time you should<br>use <a href=\"#ValkeyModule_BlockedClientMeasureTimeStart\"><code>ValkeyModule_BlockedClientMeasureTimeStart()</code></a> and <a href=\"#ValkeyModule_BlockedClientMeasureTimeEnd\"><code>ValkeyModule_BlockedClientMeasureTimeEnd()</code></a> one,<br>or multiple times within the blocking command background work.</p>\n<p><span id=\"ValkeyModule_BlockClientOnAuth\"></span></p>\n<h3><code>ValkeyModule_BlockClientOnAuth</code></h3>\n<pre><code>ValkeyModuleBlockedClient *ValkeyModule_BlockClientOnAuth(ValkeyModuleCtx *ctx,\n                                            ValkeyModuleAuthCallback reply_callback,\n                                            void (*free_privdata)(ValkeyModuleCtx *, void *));\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Block the current client for module authentication in the background. If module auth is not in<br>progress on the client, the API returns NULL. Otherwise, the client is blocked and the <code>ValkeyModule_BlockedClient</code><br>is returned similar to the <a href=\"#ValkeyModule_BlockClient\"><code>ValkeyModule_BlockClient</code></a> API.<br>Note: Only use this API from the context of a module auth callback.</p>\n<p><span id=\"ValkeyModule_BlockClientGetPrivateData\"></span></p>\n<h3><code>ValkeyModule_BlockClientGetPrivateData</code></h3>\n<pre><code>void *ValkeyModule_BlockClientGetPrivateData(ValkeyModuleBlockedClient *blocked_client);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Get the private data that was previusely set on a blocked client</p>\n<p><span id=\"ValkeyModule_BlockClientSetPrivateData\"></span></p>\n<h3><code>ValkeyModule_BlockClientSetPrivateData</code></h3>\n<pre><code>void ValkeyModule_BlockClientSetPrivateData(ValkeyModuleBlockedClient *blocked_client,\n                                            void *private_data);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Set private data on a blocked client</p>\n<p><span id=\"ValkeyModule_BlockClientOnKeys\"></span></p>\n<h3><code>ValkeyModule_BlockClientOnKeys</code></h3>\n<pre><code>ValkeyModuleBlockedClient *ValkeyModule_BlockClientOnKeys(ValkeyModuleCtx *ctx,\n                                                          ValkeyModuleCmdFunc reply_callback,\n                                                          ValkeyModuleCmdFunc timeout_callback,\n                                                          void (*free_privdata)(ValkeyModuleCtx *, void *),\n                                                          long long timeout_ms,\n                                                          ValkeyModuleString **keys,\n                                                          int numkeys,\n                                                          void *privdata);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>This call is similar to <a href=\"#ValkeyModule_BlockClient\"><code>ValkeyModule_BlockClient()</code></a>, however in this case we<br>don&#39;t just block the client, but also ask the server to unblock it automatically<br>once certain keys become &quot;ready&quot;, that is, contain more data.</p>\n<p>Basically this is similar to what a typical command usually does,<br>like BLPOP or BZPOPMAX: the client blocks if it cannot be served ASAP,<br>and later when the key receives new data (a list push for instance), the<br>client is unblocked and served.</p>\n<p>However in the case of this module API, when the client is unblocked?</p>\n<ol>\n<li>If you block on a key of a type that has blocking operations associated,<br>like a list, a sorted set, a stream, and so forth, the client may be<br>unblocked once the relevant key is targeted by an operation that normally<br>unblocks the native blocking operations for that type. So if we block<br>on a list key, an RPUSH command may unblock our client and so forth.</li>\n<li>If you are implementing your native data type, or if you want to add new<br>unblocking conditions in addition to &quot;1&quot;, you can call the modules API<br><a href=\"#ValkeyModule_SignalKeyAsReady\"><code>ValkeyModule_SignalKeyAsReady()</code></a>.</li>\n</ol>\n<p>Anyway we can&#39;t be sure if the client should be unblocked just because the<br>key is signaled as ready: for instance a successive operation may change the<br>key, or a client in queue before this one can be served, modifying the key<br>as well and making it empty again. So when a client is blocked with<br><a href=\"#ValkeyModule_BlockClientOnKeys\"><code>ValkeyModule_BlockClientOnKeys()</code></a> the reply callback is not called after<br><a href=\"#ValkeyModule_UnblockClient\"><code>ValkeyModule_UnblockClient()</code></a> is called, but every time a key is signaled as ready:<br>if the reply callback can serve the client, it returns <code>VALKEYMODULE_OK</code><br>and the client is unblocked, otherwise it will return <code>VALKEYMODULE_ERR</code><br>and we&#39;ll try again later.</p>\n<p>The reply callback can access the key that was signaled as ready by<br>calling the API <a href=\"#ValkeyModule_GetBlockedClientReadyKey\"><code>ValkeyModule_GetBlockedClientReadyKey()</code></a>, that returns<br>just the string name of the key as a <code>ValkeyModuleString</code> object.</p>\n<p>Thanks to this system we can setup complex blocking scenarios, like<br>unblocking a client only if a list contains at least 5 items or other<br>more fancy logics.</p>\n<p>Note that another difference with <a href=\"#ValkeyModule_BlockClient\"><code>ValkeyModule_BlockClient()</code></a>, is that here<br>we pass the private data directly when blocking the client: it will<br>be accessible later in the reply callback. Normally when blocking with<br><a href=\"#ValkeyModule_BlockClient\"><code>ValkeyModule_BlockClient()</code></a> the private data to reply to the client is<br>passed when calling <a href=\"#ValkeyModule_UnblockClient\"><code>ValkeyModule_UnblockClient()</code></a> but here the unblocking<br>is performed by the server itself, so we need to have some private data before<br>hand. The private data is used to store any information about the specific<br>unblocking operation that you are implementing. Such information will be<br>freed using the <code>free_privdata</code> callback provided by the user.</p>\n<p>However the reply callback will be able to access the argument vector of<br>the command, so the private data is often not needed.</p>\n<p>Note: Under normal circumstances <a href=\"#ValkeyModule_UnblockClient\"><code>ValkeyModule_UnblockClient</code></a> should not be<br>      called for clients that are blocked on keys (Either the key will<br>      become ready or a timeout will occur). If for some reason you do want<br>      to call ValkeyModule_UnblockClient it is possible: Client will be<br>      handled as if it were timed-out (You must implement the timeout<br>      callback in that case).</p>\n<p><span id=\"ValkeyModule_BlockClientOnKeysWithFlags\"></span></p>\n<h3><code>ValkeyModule_BlockClientOnKeysWithFlags</code></h3>\n<pre><code>ValkeyModuleBlockedClient *ValkeyModule_BlockClientOnKeysWithFlags(ValkeyModuleCtx *ctx,\n                                                                   ValkeyModuleCmdFunc reply_callback,\n                                                                   ValkeyModuleCmdFunc timeout_callback,\n                                                                   void (*free_privdata)(ValkeyModuleCtx *, void *),\n                                                                   long long timeout_ms,\n                                                                   ValkeyModuleString **keys,\n                                                                   int numkeys,\n                                                                   void *privdata,\n                                                                   int flags);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Same as <a href=\"#ValkeyModule_BlockClientOnKeys\"><code>ValkeyModule_BlockClientOnKeys</code></a>, but can take <code>VALKEYMODULE_BLOCK_</code>* flags<br>Can be either <code>VALKEYMODULE_BLOCK_UNBLOCK_DEFAULT</code>, which means default behavior (same<br>as calling <a href=\"#ValkeyModule_BlockClientOnKeys\"><code>ValkeyModule_BlockClientOnKeys</code></a>)</p>\n<p>The flags is a bit mask of these:</p>\n<ul>\n<li><code>VALKEYMODULE_BLOCK_UNBLOCK_DELETED</code>: The clients should to be awakened in case any of <code>keys</code> are deleted.<br>                                 Mostly useful for commands that require the key to exist (like XREADGROUP)</li>\n</ul>\n<p><span id=\"ValkeyModule_SignalKeyAsReady\"></span></p>\n<h3><code>ValkeyModule_SignalKeyAsReady</code></h3>\n<pre><code>void ValkeyModule_SignalKeyAsReady(ValkeyModuleCtx *ctx,\n                                   ValkeyModuleString *key);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>This function is used in order to potentially unblock a client blocked<br>on keys with <a href=\"#ValkeyModule_BlockClientOnKeys\"><code>ValkeyModule_BlockClientOnKeys()</code></a>. When this function is called,<br>all the clients blocked for this key will get their <code>reply_callback</code> called.</p>\n<p><span id=\"ValkeyModule_UnblockClient\"></span></p>\n<h3><code>ValkeyModule_UnblockClient</code></h3>\n<pre><code>int ValkeyModule_UnblockClient(ValkeyModuleBlockedClient *bc, void *privdata);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Unblock a client blocked by <code>ValkeyModule_BlockedClient</code>. This will trigger<br>the reply callbacks to be called in order to reply to the client.<br>The &#39;privdata&#39; argument will be accessible by the reply callback, so<br>the caller of this function can pass any value that is needed in order to<br>actually reply to the client.</p>\n<p>A common usage for &#39;privdata&#39; is a thread that computes something that<br>needs to be passed to the client, included but not limited some slow<br>to compute reply or some reply obtained via networking.</p>\n<p>Note 1: this function can be called from threads spawned by the module.</p>\n<p>Note 2: when we unblock a client that is blocked for keys using the API<br><a href=\"#ValkeyModule_BlockClientOnKeys\"><code>ValkeyModule_BlockClientOnKeys()</code></a>, the privdata argument here is not used.<br>Unblocking a client that was blocked for keys using this API will still<br>require the client to get some reply, so the function will use the<br>&quot;timeout&quot; handler in order to do so (The privdata provided in<br><a href=\"#ValkeyModule_BlockClientOnKeys\"><code>ValkeyModule_BlockClientOnKeys()</code></a> is accessible from the timeout<br>callback via <a href=\"#ValkeyModule_GetBlockedClientPrivateData\"><code>ValkeyModule_GetBlockedClientPrivateData</code></a>).</p>\n<p><span id=\"ValkeyModule_AbortBlock\"></span></p>\n<h3><code>ValkeyModule_AbortBlock</code></h3>\n<pre><code>int ValkeyModule_AbortBlock(ValkeyModuleBlockedClient *bc);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Abort a blocked client blocking operation: the client will be unblocked<br>without firing any callback.</p>\n<p><span id=\"ValkeyModule_SetDisconnectCallback\"></span></p>\n<h3><code>ValkeyModule_SetDisconnectCallback</code></h3>\n<pre><code>void ValkeyModule_SetDisconnectCallback(ValkeyModuleBlockedClient *bc,\n                                        ValkeyModuleDisconnectFunc callback);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Set a callback that will be called if a blocked client disconnects<br>before the module has a chance to call <a href=\"#ValkeyModule_UnblockClient\"><code>ValkeyModule_UnblockClient()</code></a></p>\n<p>Usually what you want to do there, is to cleanup your module state<br>so that you can call <a href=\"#ValkeyModule_UnblockClient\"><code>ValkeyModule_UnblockClient()</code></a> safely, otherwise<br>the client will remain blocked forever if the timeout is large.</p>\n<p>Notes:</p>\n<ol>\n<li><p>It is not safe to call Reply* family functions here, it is also<br>useless since the client is gone.</p>\n</li>\n<li><p>This callback is not called if the client disconnects because of<br>a timeout. In such a case, the client is unblocked automatically<br>and the timeout callback is called.</p>\n</li>\n</ol>\n<p><span id=\"ValkeyModule_IsBlockedReplyRequest\"></span></p>\n<h3><code>ValkeyModule_IsBlockedReplyRequest</code></h3>\n<pre><code>int ValkeyModule_IsBlockedReplyRequest(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return non-zero if a module command was called in order to fill the<br>reply for a blocked client.</p>\n<p><span id=\"ValkeyModule_IsBlockedTimeoutRequest\"></span></p>\n<h3><code>ValkeyModule_IsBlockedTimeoutRequest</code></h3>\n<pre><code>int ValkeyModule_IsBlockedTimeoutRequest(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return non-zero if a module command was called in order to fill the<br>reply for a blocked client that timed out.</p>\n<p><span id=\"ValkeyModule_GetBlockedClientPrivateData\"></span></p>\n<h3><code>ValkeyModule_GetBlockedClientPrivateData</code></h3>\n<pre><code>void *ValkeyModule_GetBlockedClientPrivateData(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Get the private data set by <a href=\"#ValkeyModule_UnblockClient\"><code>ValkeyModule_UnblockClient()</code></a></p>\n<p><span id=\"ValkeyModule_GetBlockedClientReadyKey\"></span></p>\n<h3><code>ValkeyModule_GetBlockedClientReadyKey</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_GetBlockedClientReadyKey(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Get the key that is ready when the reply callback is called in the context<br>of a client blocked by <a href=\"#ValkeyModule_BlockClientOnKeys\"><code>ValkeyModule_BlockClientOnKeys()</code></a>.</p>\n<p><span id=\"ValkeyModule_GetBlockedClientHandle\"></span></p>\n<h3><code>ValkeyModule_GetBlockedClientHandle</code></h3>\n<pre><code>ValkeyModuleBlockedClient *ValkeyModule_GetBlockedClientHandle(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Get the blocked client associated with a given context.<br>This is useful in the reply and timeout callbacks of blocked clients,<br>before sometimes the module has the blocked client handle references<br>around, and wants to cleanup it.</p>\n<p><span id=\"ValkeyModule_BlockedClientDisconnected\"></span></p>\n<h3><code>ValkeyModule_BlockedClientDisconnected</code></h3>\n<pre><code>int ValkeyModule_BlockedClientDisconnected(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Return true if when the free callback of a blocked client is called,<br>the reason for the client to be unblocked is that it disconnected<br>while it was blocked.</p>\n<p><span id=\"section-thread-safe-contexts\"></span></p>\n<h2>Thread Safe Contexts</h2>\n<p><span id=\"ValkeyModule_GetThreadSafeContext\"></span></p>\n<h3><code>ValkeyModule_GetThreadSafeContext</code></h3>\n<pre><code>ValkeyModuleCtx *ValkeyModule_GetThreadSafeContext(ValkeyModuleBlockedClient *bc);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return a context which can be used inside threads to make calls requiring a<br>context with certain modules APIs. If &#39;bc&#39; is not NULL then the module will<br>be bound to a blocked client, and it will be possible to use the<br><code>ValkeyModule_Reply*</code> family of functions to accumulate a reply for when the<br>client will be unblocked. Otherwise the thread safe context will be<br>detached by a specific client.</p>\n<p>To call non-reply APIs, the thread safe context must be prepared with:</p>\n<pre><code>ValkeyModule_ThreadSafeContextLock(ctx);\n... make your call here ...\nValkeyModule_ThreadSafeContextUnlock(ctx);\n</code></pre>\n<p>This is not needed when using <code>ValkeyModule_Reply*</code> functions, assuming<br>that a blocked client was used when the context was created, otherwise<br>no <code>ValkeyModule_Reply</code>* call should be made at all.</p>\n<p>NOTE: If you&#39;re creating a detached thread safe context (bc is NULL),<br>consider using <a href=\"#ValkeyModule_GetDetachedThreadSafeContext\"><code>ValkeyModule_GetDetachedThreadSafeContext</code></a> which will also retain<br>the module ID and thus be more useful for logging.</p>\n<p><span id=\"ValkeyModule_GetDetachedThreadSafeContext\"></span></p>\n<h3><code>ValkeyModule_GetDetachedThreadSafeContext</code></h3>\n<pre><code>ValkeyModuleCtx *ValkeyModule_GetDetachedThreadSafeContext(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.9</p>\n<p>Return a detached thread safe context that is not associated with any<br>specific blocked client, but is associated with the module&#39;s context.</p>\n<p>This is useful for modules that wish to hold a global context over<br>a long term, for purposes such as logging.</p>\n<p><span id=\"ValkeyModule_FreeThreadSafeContext\"></span></p>\n<h3><code>ValkeyModule_FreeThreadSafeContext</code></h3>\n<pre><code>void ValkeyModule_FreeThreadSafeContext(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Release a thread safe context.</p>\n<p><span id=\"ValkeyModule_ThreadSafeContextLock\"></span></p>\n<h3><code>ValkeyModule_ThreadSafeContextLock</code></h3>\n<pre><code>void ValkeyModule_ThreadSafeContextLock(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Acquire the server lock before executing a thread safe API call.<br>This is not needed for <code>ValkeyModule_Reply*</code> calls when there is<br>a blocked client connected to the thread safe context.</p>\n<p><span id=\"ValkeyModule_ThreadSafeContextTryLock\"></span></p>\n<h3><code>ValkeyModule_ThreadSafeContextTryLock</code></h3>\n<pre><code>int ValkeyModule_ThreadSafeContextTryLock(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.8</p>\n<p>Similar to <a href=\"#ValkeyModule_ThreadSafeContextLock\"><code>ValkeyModule_ThreadSafeContextLock</code></a> but this function<br>would not block if the server lock is already acquired.</p>\n<p>If successful (lock acquired) <code>VALKEYMODULE_OK</code> is returned,<br>otherwise <code>VALKEYMODULE_ERR</code> is returned and errno is set<br>accordingly.</p>\n<p><span id=\"ValkeyModule_ThreadSafeContextUnlock\"></span></p>\n<h3><code>ValkeyModule_ThreadSafeContextUnlock</code></h3>\n<pre><code>void ValkeyModule_ThreadSafeContextUnlock(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Release the server lock after a thread safe API call was executed.</p>\n<p><span id=\"section-module-keyspace-notifications-api\"></span></p>\n<h2>Module Keyspace Notifications API</h2>\n<p><span id=\"ValkeyModule_SubscribeToKeyspaceEvents\"></span></p>\n<h3><code>ValkeyModule_SubscribeToKeyspaceEvents</code></h3>\n<pre><code>int ValkeyModule_SubscribeToKeyspaceEvents(ValkeyModuleCtx *ctx,\n                                           int types,\n                                           ValkeyModuleNotificationFunc callback);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.9</p>\n<p>Subscribe to keyspace notifications. This is a low-level version of the<br>keyspace-notifications API. A module can register callbacks to be notified<br>when keyspace events occur.</p>\n<p>Notification events are filtered by their type (string events, set events,<br>etc), and the subscriber callback receives only events that match a specific<br>mask of event types.</p>\n<p>When subscribing to notifications with <a href=\"#ValkeyModule_SubscribeToKeyspaceEvents\"><code>ValkeyModule_SubscribeToKeyspaceEvents</code></a><br>the module must provide an event type-mask, denoting the events the subscriber<br>is interested in. This can be an ORed mask of any of the following flags:</p>\n<ul>\n<li><code>VALKEYMODULE_NOTIFY_GENERIC</code>: Generic commands like DEL, EXPIRE, RENAME</li>\n<li><code>VALKEYMODULE_NOTIFY_STRING</code>: String events</li>\n<li><code>VALKEYMODULE_NOTIFY_LIST</code>: List events</li>\n<li><code>VALKEYMODULE_NOTIFY_SET</code>: Set events</li>\n<li><code>VALKEYMODULE_NOTIFY_HASH</code>: Hash events</li>\n<li><code>VALKEYMODULE_NOTIFY_ZSET</code>: Sorted Set events</li>\n<li><code>VALKEYMODULE_NOTIFY_EXPIRED</code>: Expiration events</li>\n<li><code>VALKEYMODULE_NOTIFY_EVICTED</code>: Eviction events</li>\n<li><code>VALKEYMODULE_NOTIFY_STREAM</code>: Stream events</li>\n<li><code>VALKEYMODULE_NOTIFY_MODULE</code>: Module types events</li>\n<li><code>VALKEYMODULE_NOTIFY_KEYMISS</code>: Key-miss events<br>                        Notice, key-miss event is the only type<br>                        of event that is fired from within a read command.<br>                        Performing ValkeyModule_Call with a write command from within<br>                        this notification is wrong and discourage. It will<br>                        cause the read command that trigger the event to be<br>                        replicated to the AOF/Replica.</li>\n<li><code>VALKEYMODULE_NOTIFY_ALL</code>: All events (Excluding <code>VALKEYMODULE_NOTIFY_KEYMISS</code>)</li>\n<li><code>VALKEYMODULE_NOTIFY_LOADED</code>: A special notification available only for modules,<br>                       indicates that the key was loaded from persistence.<br>                       Notice, when this event fires, the given key<br>                       can not be retained, use ValkeyModule_CreateStringFromString<br>                       instead.</li>\n</ul>\n<p>We do not distinguish between key events and keyspace events, and it is up<br>to the module to filter the actions taken based on the key.</p>\n<p>The subscriber signature is:</p>\n<pre><code>int (*ValkeyModuleNotificationFunc) (ValkeyModuleCtx *ctx, int type,\n                                    const char *event,\n                                    ValkeyModuleString *key);\n</code></pre>\n<p><code>type</code> is the event type bit, that must match the mask given at registration<br>time. The event string is the actual command being executed, and key is the<br>relevant key.</p>\n<p>Notification callback gets executed with a context that can not be<br>used to send anything to the client, and has the db number where the event<br>occurred as its selected db number.</p>\n<p>Notice that it is not necessary to enable notifications in valkey.conf for<br>module notifications to work.</p>\n<p>Warning: the notification callbacks are performed in a synchronous manner,<br>so notification callbacks must to be fast, or they would slow the server down.<br>If you need to take long actions, use threads to offload them.</p>\n<p>Moreover, the fact that the notification is executed synchronously means<br>that the notification code will be executed in the middle of server logic<br>(commands logic, eviction, expire). Changing the key space while the logic<br>runs is dangerous and discouraged. In order to react to key space events with<br>write actions, please refer to <a href=\"#ValkeyModule_AddPostNotificationJob\"><code>ValkeyModule_AddPostNotificationJob</code></a>.</p>\n<p>See <a href=\"https://valkey.io/topics/notifications\">https://valkey.io/topics/notifications</a> for more information.</p>\n<p><span id=\"ValkeyModule_AddPostNotificationJob\"></span></p>\n<h3><code>ValkeyModule_AddPostNotificationJob</code></h3>\n<pre><code>int ValkeyModule_AddPostNotificationJob(ValkeyModuleCtx *ctx,\n                                        ValkeyModulePostNotificationJobFunc callback,\n                                        void *privdata,\n                                        void (*free_privdata)(void *));\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>When running inside a key space notification callback, it is dangerous and highly discouraged to perform any write<br>operation (See <a href=\"#ValkeyModule_SubscribeToKeyspaceEvents\"><code>ValkeyModule_SubscribeToKeyspaceEvents</code></a>). In order to still perform write actions in this scenario,<br>the server provides <a href=\"#ValkeyModule_AddPostNotificationJob\"><code>ValkeyModule_AddPostNotificationJob</code></a> API. The API allows to register a job callback which the server will<br>call when the following condition are promised to be fulfilled:</p>\n<ol>\n<li>It is safe to perform any write operation.</li>\n<li>The job will be called atomically along side the key space notification.</li>\n</ol>\n<p>Notice, one job might trigger key space notifications that will trigger more jobs.<br>This raises a concerns of entering an infinite loops, we consider infinite loops<br>as a logical bug that need to be fixed in the module, an attempt to protect against<br>infinite loops by halting the execution could result in violation of the feature correctness<br>and so the server will make no attempt to protect the module from infinite loops.</p>\n<p>&#39;<code>free_pd</code>&#39; can be NULL and in such case will not be used.</p>\n<p>Return <code>VALKEYMODULE_OK</code> on success and <code>VALKEYMODULE_ERR</code> if was called while loading data from disk (AOF or RDB) or<br>if the instance is a readonly replica.</p>\n<p><span id=\"ValkeyModule_GetNotifyKeyspaceEvents\"></span></p>\n<h3><code>ValkeyModule_GetNotifyKeyspaceEvents</code></h3>\n<pre><code>int ValkeyModule_GetNotifyKeyspaceEvents(void);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Get the configured bitmap of notify-keyspace-events (Could be used<br>for additional filtering in <code>ValkeyModuleNotificationFunc</code>)</p>\n<p><span id=\"ValkeyModule_NotifyKeyspaceEvent\"></span></p>\n<h3><code>ValkeyModule_NotifyKeyspaceEvent</code></h3>\n<pre><code>int ValkeyModule_NotifyKeyspaceEvent(ValkeyModuleCtx *ctx,\n                                     int type,\n                                     const char *event,\n                                     ValkeyModuleString *key);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Expose notifyKeyspaceEvent to modules</p>\n<p><span id=\"section-modules-cluster-api\"></span></p>\n<h2>Modules Cluster API</h2>\n<p><span id=\"ValkeyModule_RegisterClusterMessageReceiver\"></span></p>\n<h3><code>ValkeyModule_RegisterClusterMessageReceiver</code></h3>\n<pre><code>void ValkeyModule_RegisterClusterMessageReceiver(ValkeyModuleCtx *ctx,\n                                                 uint8_t type,\n                                                 ValkeyModuleClusterMessageReceiver callback);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Register a callback receiver for cluster messages of type &#39;type&#39;. If there<br>was already a registered callback, this will replace the callback function<br>with the one provided, otherwise if the callback is set to NULL and there<br>is already a callback for this function, the callback is unregistered<br>(so this API call is also used in order to delete the receiver).</p>\n<p>When a message of this type is received, the registered callback function<br>will be invoked with details, including the 40-byte node ID of the sender.</p>\n<p>In Valkey 8.1 and later, the node ID is null-terminated. Prior to 8.1, it was<br>not null-terminated</p>\n<p><span id=\"ValkeyModule_SendClusterMessage\"></span></p>\n<h3><code>ValkeyModule_SendClusterMessage</code></h3>\n<pre><code>int ValkeyModule_SendClusterMessage(ValkeyModuleCtx *ctx,\n                                    const char *target_id,\n                                    uint8_t type,\n                                    const char *msg,\n                                    uint32_t len);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Send a message to all the nodes in the cluster if <code>target</code> is NULL, otherwise<br>at the specified target, which is a <code>VALKEYMODULE_NODE_ID_LEN</code> bytes node ID, as<br>returned by the receiver callback or by the nodes iteration functions.</p>\n<p>In Valkey 8.1 and later, the cluster protocol overhead for this message is<br>~30B, to compare with earlier versions where it&#39;s ~2KB.</p>\n<p>The function returns <code>VALKEYMODULE_OK</code> if the message was successfully sent,<br>otherwise if the node is not connected or such node ID does not map to any<br>known cluster node, <code>VALKEYMODULE_ERR</code> is returned.</p>\n<p><span id=\"ValkeyModule_GetClusterNodesList\"></span></p>\n<h3><code>ValkeyModule_GetClusterNodesList</code></h3>\n<pre><code>char **ValkeyModule_GetClusterNodesList(ValkeyModuleCtx *ctx,\n                                        size_t *numnodes);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Return an array of string pointers, each string pointer points to a cluster<br>node ID of exactly <code>VALKEYMODULE_NODE_ID_LEN</code> bytes (without any null term).<br>The number of returned node IDs is stored into <code>*numnodes</code>.<br>However if this function is called by a module not running an an<br>instance with Cluster enabled, NULL is returned instead.</p>\n<p>The IDs returned can be used with <a href=\"#ValkeyModule_GetClusterNodeInfo\"><code>ValkeyModule_GetClusterNodeInfo()</code></a> in order<br>to get more information about single node.</p>\n<p>The array returned by this function must be freed using the function<br><a href=\"#ValkeyModule_FreeClusterNodesList\"><code>ValkeyModule_FreeClusterNodesList()</code></a>.</p>\n<p>Example:</p>\n<pre><code>size_t count, j;\nchar **ids = ValkeyModule_GetClusterNodesList(ctx,&amp;count);\nfor (j = 0; j &lt; count; j++) {\n    ValkeyModule_Log(ctx,&quot;notice&quot;,&quot;Node %.*s&quot;,\n        VALKEYMODULE_NODE_ID_LEN,ids[j]);\n}\nValkeyModule_FreeClusterNodesList(ids);\n</code></pre>\n<p><span id=\"ValkeyModule_FreeClusterNodesList\"></span></p>\n<h3><code>ValkeyModule_FreeClusterNodesList</code></h3>\n<pre><code>void ValkeyModule_FreeClusterNodesList(char **ids);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Free the node list obtained with <a href=\"#ValkeyModule_GetClusterNodesList\"><code>ValkeyModule_GetClusterNodesList</code></a>.</p>\n<p><span id=\"ValkeyModule_GetMyClusterID\"></span></p>\n<h3><code>ValkeyModule_GetMyClusterID</code></h3>\n<pre><code>const char *ValkeyModule_GetMyClusterID(void);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Return this node ID (<code>VALKEYMODULE_CLUSTER_ID_LEN</code> bytes) or NULL if the cluster<br>is disabled.</p>\n<p><span id=\"ValkeyModule_GetClusterSize\"></span></p>\n<h3><code>ValkeyModule_GetClusterSize</code></h3>\n<pre><code>size_t ValkeyModule_GetClusterSize(void);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Return the number of nodes in the cluster, regardless of their state<br>(handshake, noaddress, ...) so that the number of active nodes may actually<br>be smaller, but not greater than this number. If the instance is not in<br>cluster mode, zero is returned.</p>\n<p><span id=\"ValkeyModule_GetClusterNodeInfo\"></span></p>\n<h3><code>ValkeyModule_GetClusterNodeInfo</code></h3>\n<pre><code>int ValkeyModule_GetClusterNodeInfo(ValkeyModuleCtx *ctx,\n                                    const char *id,\n                                    char *ip,\n                                    char *primary_id,\n                                    int *port,\n                                    int *flags);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Populate the specified info for the node having as ID the specified &#39;id&#39;,<br>then returns <code>VALKEYMODULE_OK</code>. Otherwise if the format of node ID is invalid<br>or the node ID does not exist from the POV of this local node, <code>VALKEYMODULE_ERR</code><br>is returned.</p>\n<p>The arguments <code>ip</code>, <code>primary_id</code>, <code>port</code> and <code>flags</code> can be NULL in case we don&#39;t<br>need to populate back certain info. If an <code>ip</code> and <code>primary_id</code> (only populated<br>if the instance is a replica) are specified, they point to buffers holding<br>at least <code>VALKEYMODULE_NODE_ID_LEN</code> bytes. The strings written back as <code>ip</code><br>and <code>primary_id</code> are not null terminated.</p>\n<p>The list of flags reported is the following:</p>\n<ul>\n<li><code>VALKEYMODULE_NODE_MYSELF</code>:       This node</li>\n<li><code>VALKEYMODULE_NODE_PRIMARY</code>:      The node is a primary</li>\n<li><code>VALKEYMODULE_NODE_REPLICA</code>:      The node is a replica</li>\n<li><code>VALKEYMODULE_NODE_PFAIL</code>:        We see the node as failing</li>\n<li><code>VALKEYMODULE_NODE_FAIL</code>:         The cluster agrees the node is failing</li>\n<li><code>VALKEYMODULE_NODE_NOFAILOVER</code>:   The replica is configured to never failover</li>\n</ul>\n<p><span id=\"ValkeyModule_GetClusterNodeInfoForClient\"></span></p>\n<h3><code>ValkeyModule_GetClusterNodeInfoForClient</code></h3>\n<pre><code>int ValkeyModule_GetClusterNodeInfoForClient(ValkeyModuleCtx *ctx,;\n</code></pre>\n<p><strong>Available since:</strong> 8.0.0</p>\n<p>Like <a href=\"#ValkeyModule_GetClusterNodeInfo\"><code>ValkeyModule_GetClusterNodeInfo()</code></a>, but returns IP address specifically for the given<br>client, depending on whether the client is connected over IPv4 or IPv6.</p>\n<p>See also <a href=\"#ValkeyModule_GetClientId\"><code>ValkeyModule_GetClientId()</code></a>.</p>\n<p><span id=\"ValkeyModule_SetClusterFlags\"></span></p>\n<h3><code>ValkeyModule_SetClusterFlags</code></h3>\n<pre><code>void ValkeyModule_SetClusterFlags(ValkeyModuleCtx *ctx, uint64_t flags);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Set Cluster flags in order to change the normal behavior of<br>Cluster, especially with the goal of disabling certain functions.<br>This is useful for modules that use the Cluster API in order to create<br>a different distributed system, but still want to use the Cluster<br>message bus. Flags that can be set:</p>\n<ul>\n<li><code>CLUSTER_MODULE_FLAG_NO_FAILOVER</code></li>\n<li><code>CLUSTER_MODULE_FLAG_NO_REDIRECTION</code></li>\n</ul>\n<p>With the following effects:</p>\n<ul>\n<li><p><code>NO_FAILOVER</code>: prevent Cluster replicas from failing over a dead primary.<br>         Also disables the replica migration feature.</p>\n</li>\n<li><p><code>NO_REDIRECTION</code>: Every node will accept any key, without trying to perform<br>            partitioning according to the Cluster algorithm.<br>            Slots information will still be propagated across the<br>            cluster, but without effect.</p>\n</li>\n</ul>\n<p><span id=\"ValkeyModule_ClusterKeySlot\"></span></p>\n<h3><code>ValkeyModule_ClusterKeySlot</code></h3>\n<pre><code>unsigned int ValkeyModule_ClusterKeySlot(ValkeyModuleString *key);\n</code></pre>\n<p><strong>Available since:</strong> 8.0.0</p>\n<p>Returns the cluster slot of a key, similar to the <code>CLUSTER KEYSLOT</code> command.<br>This function works even if cluster mode is not enabled.</p>\n<p><span id=\"ValkeyModule_ClusterCanonicalKeyNameInSlot\"></span></p>\n<h3><code>ValkeyModule_ClusterCanonicalKeyNameInSlot</code></h3>\n<pre><code>const char *ValkeyModule_ClusterCanonicalKeyNameInSlot(unsigned int slot);\n</code></pre>\n<p><strong>Available since:</strong> 8.0.0</p>\n<p>Returns a short string that can be used as a key or as a hash tag in a key,<br>such that the key maps to the given cluster slot. Returns NULL if slot is not<br>a valid slot.</p>\n<p><span id=\"section-modules-timers-api\"></span></p>\n<h2>Modules Timers API</h2>\n<p>Module timers are a high precision &quot;green timers&quot; abstraction where<br>every module can register even millions of timers without problems, even if<br>the actual event loop will just have a single timer that is used to awake the<br>module timers subsystem in order to process the next event.</p>\n<p>All the timers are stored into a radix tree, ordered by expire time, when<br>the main server event loop timer callback is called, we try to process all<br>the timers already expired one after the other. Then we re-enter the event<br>loop registering a timer that will expire when the next to process module<br>timer will expire.</p>\n<p>Every time the list of active timers drops to zero, we unregister the<br>main event loop timer, so that there is no overhead when such feature is<br>not used.</p>\n<p><span id=\"ValkeyModule_CreateTimer\"></span></p>\n<h3><code>ValkeyModule_CreateTimer</code></h3>\n<pre><code>ValkeyModuleTimerID ValkeyModule_CreateTimer(ValkeyModuleCtx *ctx,\n                                             mstime_t period,\n                                             ValkeyModuleTimerProc callback,\n                                             void *data);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Create a new timer that will fire after <code>period</code> milliseconds, and will call<br>the specified function using <code>data</code> as argument. The returned timer ID can be<br>used to get information from the timer or to stop it before it fires.<br>Note that for the common use case of a repeating timer (Re-registration<br>of the timer inside the <code>ValkeyModuleTimerProc</code> callback) it matters when<br>this API is called:<br>If it is called at the beginning of &#39;callback&#39; it means<br>the event will triggered every &#39;period&#39;.<br>If it is called at the end of &#39;callback&#39; it means<br>there will &#39;period&#39; milliseconds gaps between events.<br>(If the time it takes to execute &#39;callback&#39; is negligible the two<br>statements above mean the same)</p>\n<p><span id=\"ValkeyModule_StopTimer\"></span></p>\n<h3><code>ValkeyModule_StopTimer</code></h3>\n<pre><code>int ValkeyModule_StopTimer(ValkeyModuleCtx *ctx,\n                           ValkeyModuleTimerID id,\n                           void **data);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Stop a timer, returns <code>VALKEYMODULE_OK</code> if the timer was found, belonged to the<br>calling module, and was stopped, otherwise <code>VALKEYMODULE_ERR</code> is returned.<br>If not NULL, the data pointer is set to the value of the data argument when<br>the timer was created.</p>\n<p><span id=\"ValkeyModule_GetTimerInfo\"></span></p>\n<h3><code>ValkeyModule_GetTimerInfo</code></h3>\n<pre><code>int ValkeyModule_GetTimerInfo(ValkeyModuleCtx *ctx,\n                              ValkeyModuleTimerID id,\n                              uint64_t *remaining,\n                              void **data);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Obtain information about a timer: its remaining time before firing<br>(in milliseconds), and the private data pointer associated with the timer.<br>If the timer specified does not exist or belongs to a different module<br>no information is returned and the function returns <code>VALKEYMODULE_ERR</code>, otherwise<br><code>VALKEYMODULE_OK</code> is returned. The arguments remaining or data can be NULL if<br>the caller does not need certain information.</p>\n<p><span id=\"section-modules-eventloop-api\"></span></p>\n<h2>Modules EventLoop API</h2>\n<p><span id=\"ValkeyModule_EventLoopAdd\"></span></p>\n<h3><code>ValkeyModule_EventLoopAdd</code></h3>\n<pre><code>int ValkeyModule_EventLoopAdd(int fd,\n                              int mask,\n                              ValkeyModuleEventLoopFunc func,\n                              void *user_data);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Add a pipe / socket event to the event loop.</p>\n<ul>\n<li><p><code>mask</code> must be one of the following values:</p>\n<ul>\n<li><code>VALKEYMODULE_EVENTLOOP_READABLE</code></li>\n<li><code>VALKEYMODULE_EVENTLOOP_WRITABLE</code></li>\n<li><code>VALKEYMODULE_EVENTLOOP_READABLE | VALKEYMODULE_EVENTLOOP_WRITABLE</code></li>\n</ul>\n</li>\n</ul>\n<p>On success <code>VALKEYMODULE_OK</code> is returned, otherwise<br><code>VALKEYMODULE_ERR</code> is returned and errno is set to the following values:</p>\n<ul>\n<li>ERANGE: <code>fd</code> is negative or higher than <code>maxclients</code> server config.</li>\n<li>EINVAL: <code>callback</code> is NULL or <code>mask</code> value is invalid.</li>\n</ul>\n<p><code>errno</code> might take other values in case of an internal error.</p>\n<p>Example:</p>\n<pre><code>void onReadable(int fd, void *user_data, int mask) {\n    char buf[32];\n    int bytes = read(fd,buf,sizeof(buf));\n    printf(&quot;Read %d bytes \\n&quot;, bytes);\n}\nValkeyModule_EventLoopAdd(fd, VALKEYMODULE_EVENTLOOP_READABLE, onReadable, NULL);\n</code></pre>\n<p><span id=\"ValkeyModule_EventLoopDel\"></span></p>\n<h3><code>ValkeyModule_EventLoopDel</code></h3>\n<pre><code>int ValkeyModule_EventLoopDel(int fd, int mask);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Delete a pipe / socket event from the event loop.</p>\n<ul>\n<li><p><code>mask</code> must be one of the following values:</p>\n<ul>\n<li><code>VALKEYMODULE_EVENTLOOP_READABLE</code></li>\n<li><code>VALKEYMODULE_EVENTLOOP_WRITABLE</code></li>\n<li><code>VALKEYMODULE_EVENTLOOP_READABLE | VALKEYMODULE_EVENTLOOP_WRITABLE</code></li>\n</ul>\n</li>\n</ul>\n<p>On success <code>VALKEYMODULE_OK</code> is returned, otherwise<br><code>VALKEYMODULE_ERR</code> is returned and errno is set to the following values:</p>\n<ul>\n<li>ERANGE: <code>fd</code> is negative or higher than <code>maxclients</code> server config.</li>\n<li>EINVAL: <code>mask</code> value is invalid.</li>\n</ul>\n<p><span id=\"ValkeyModule_EventLoopAddOneShot\"></span></p>\n<h3><code>ValkeyModule_EventLoopAddOneShot</code></h3>\n<pre><code>int ValkeyModule_EventLoopAddOneShot(ValkeyModuleEventLoopOneShotFunc func,\n                                     void *user_data);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>This function can be called from other threads to trigger callback on the server<br>main thread. On success <code>VALKEYMODULE_OK</code> is returned. If <code>func</code> is NULL<br><code>VALKEYMODULE_ERR</code> is returned and errno is set to EINVAL.</p>\n<p><span id=\"section-modules-acl-api\"></span></p>\n<h2>Modules ACL API</h2>\n<p>Implements a hook into the authentication and authorization within the server.</p>\n<p><span id=\"ValkeyModule_CreateModuleUser\"></span></p>\n<h3><code>ValkeyModule_CreateModuleUser</code></h3>\n<pre><code>ValkeyModuleUser *ValkeyModule_CreateModuleUser(const char *name);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Creates an ACL user that the module can use to authenticate a client.<br>After obtaining the user, the module should set what such user can do<br>using the <code>ValkeyModule_SetUserACL()</code> function. Once configured, the user<br>can be used in order to authenticate a connection, with the specified<br>ACL rules, using the <code>ValkeyModule_AuthClientWithUser()</code> function.</p>\n<p>Note that:</p>\n<ul>\n<li>Users created here are not listed by the ACL command.</li>\n<li>Users created here are not checked for duplicated name, so it&#39;s up to<br>the module calling this function to take care of not creating users<br>with the same name.</li>\n<li>The created user can be used to authenticate multiple connections.</li>\n</ul>\n<p>The caller can later free the user using the function<br><a href=\"#ValkeyModule_FreeModuleUser\"><code>ValkeyModule_FreeModuleUser()</code></a>. When this function is called, if there are<br>still clients authenticated with this user, they are disconnected.<br>The function to free the user should only be used when the caller really<br>wants to invalidate the user to define a new one with different<br>capabilities.</p>\n<p><span id=\"ValkeyModule_FreeModuleUser\"></span></p>\n<h3><code>ValkeyModule_FreeModuleUser</code></h3>\n<pre><code>int ValkeyModule_FreeModuleUser(ValkeyModuleUser *user);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Frees a given user and disconnects all of the clients that have been<br>authenticated with it. See <a href=\"#ValkeyModule_CreateModuleUser\"><code>ValkeyModule_CreateModuleUser</code></a> for detailed usage.</p>\n<p><span id=\"ValkeyModule_SetModuleUserACL\"></span></p>\n<h3><code>ValkeyModule_SetModuleUserACL</code></h3>\n<pre><code>int ValkeyModule_SetModuleUserACL(ValkeyModuleUser *user, const char *acl);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Sets the permissions of a user created through the module<br>interface. The syntax is the same as ACL SETUSER, so refer to the<br>documentation in acl.c for more information. See <a href=\"#ValkeyModule_CreateModuleUser\"><code>ValkeyModule_CreateModuleUser</code></a><br>for detailed usage.</p>\n<p>Returns <code>VALKEYMODULE_OK</code> on success and <code>VALKEYMODULE_ERR</code> on failure<br>and will set an errno describing why the operation failed.</p>\n<p><span id=\"ValkeyModule_SetModuleUserACLString\"></span></p>\n<h3><code>ValkeyModule_SetModuleUserACLString</code></h3>\n<pre><code>int ValkeyModule_SetModuleUserACLString(ValkeyModuleCtx *ctx,\n                                        ValkeyModuleUser *user,\n                                        const char *acl,\n                                        ValkeyModuleString **error);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.6</p>\n<p>Sets the permission of a user with a complete ACL string, such as one<br>would use on the ACL SETUSER command line API. This differs from<br><a href=\"#ValkeyModule_SetModuleUserACL\"><code>ValkeyModule_SetModuleUserACL</code></a>, which only takes single ACL operations at a time.</p>\n<p>Returns <code>VALKEYMODULE_OK</code> on success and <code>VALKEYMODULE_ERR</code> on failure<br>if a <code>ValkeyModuleString</code> is provided in error, a string describing the error<br>will be returned</p>\n<p><span id=\"ValkeyModule_GetModuleUserACLString\"></span></p>\n<h3><code>ValkeyModule_GetModuleUserACLString</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_GetModuleUserACLString(ValkeyModuleUser *user);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.6</p>\n<p>Get the ACL string for a given user<br>Returns a <code>ValkeyModuleString</code></p>\n<p><span id=\"ValkeyModule_GetCurrentUserName\"></span></p>\n<h3><code>ValkeyModule_GetCurrentUserName</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_GetCurrentUserName(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Retrieve the user name of the client connection behind the current context.<br>The user name can be used later, in order to get a <code>ValkeyModuleUser</code>.<br>See more information in <a href=\"#ValkeyModule_GetModuleUserFromUserName\"><code>ValkeyModule_GetModuleUserFromUserName</code></a>.</p>\n<p>The returned string must be released with <a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a> or by<br>enabling automatic memory management.</p>\n<p>If the context is not associated with a client connection, NULL is returned<br>and errno is set to EINVAL.</p>\n<p><span id=\"ValkeyModule_GetModuleUserFromUserName\"></span></p>\n<h3><code>ValkeyModule_GetModuleUserFromUserName</code></h3>\n<pre><code>ValkeyModuleUser *ValkeyModule_GetModuleUserFromUserName(ValkeyModuleString *name);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>A <code>ValkeyModuleUser</code> can be used to check if command, key or channel can be executed or<br>accessed according to the ACLs rules associated with that user.<br>When a Module wants to do ACL checks on a general ACL user (not created by <a href=\"#ValkeyModule_CreateModuleUser\"><code>ValkeyModule_CreateModuleUser</code></a>),<br>it can get the <code>ValkeyModuleUser</code> from this API, based on the user name retrieved by <a href=\"#ValkeyModule_GetCurrentUserName\"><code>ValkeyModule_GetCurrentUserName</code></a>.</p>\n<p>Since a general ACL user can be deleted at any time, this <code>ValkeyModuleUser</code> should be used only in the context<br>where this function was called. In order to do ACL checks out of that context, the Module can store the user name,<br>and call this API at any other context.</p>\n<p>Returns NULL if the user is disabled or the user does not exist.<br>The caller should later free the user using the function <a href=\"#ValkeyModule_FreeModuleUser\"><code>ValkeyModule_FreeModuleUser()</code></a>.</p>\n<p><span id=\"ValkeyModule_ACLCheckCommandPermissions\"></span></p>\n<h3><code>ValkeyModule_ACLCheckCommandPermissions</code></h3>\n<pre><code>int ValkeyModule_ACLCheckCommandPermissions(ValkeyModuleUser *user,\n                                            ValkeyModuleString **argv,\n                                            int argc);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Checks if the command can be executed by the user, according to the ACLs associated with it.</p>\n<p>On success a <code>VALKEYMODULE_OK</code> is returned, otherwise<br><code>VALKEYMODULE_ERR</code> is returned and errno is set to the following values:</p>\n<ul>\n<li>ENOENT: Specified command does not exist.</li>\n<li>EACCES: Command cannot be executed, according to ACL rules</li>\n</ul>\n<p><span id=\"ValkeyModule_ACLCheckKeyPermissions\"></span></p>\n<h3><code>ValkeyModule_ACLCheckKeyPermissions</code></h3>\n<pre><code>int ValkeyModule_ACLCheckKeyPermissions(ValkeyModuleUser *user,\n                                        ValkeyModuleString *key,\n                                        int flags);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Check if the key can be accessed by the user according to the ACLs attached to the user<br>and the flags representing the key access. The flags are the same that are used in the<br>keyspec for logical operations. These flags are documented in <a href=\"#ValkeyModule_SetCommandInfo\"><code>ValkeyModule_SetCommandInfo</code></a> as<br>the <code>VALKEYMODULE_CMD_KEY_ACCESS</code>, <code>VALKEYMODULE_CMD_KEY_UPDATE</code>, <code>VALKEYMODULE_CMD_KEY_INSERT</code>,<br>and <code>VALKEYMODULE_CMD_KEY_DELETE</code> flags.</p>\n<p>If no flags are supplied, the user is still required to have some access to the key for<br>this command to return successfully.</p>\n<p>If the user is able to access the key then <code>VALKEYMODULE_OK</code> is returned, otherwise<br><code>VALKEYMODULE_ERR</code> is returned and errno is set to one of the following values:</p>\n<ul>\n<li>EINVAL: The provided flags are invalid.</li>\n<li>EACCESS: The user does not have permission to access the key.</li>\n</ul>\n<p><span id=\"ValkeyModule_ACLCheckChannelPermissions\"></span></p>\n<h3><code>ValkeyModule_ACLCheckChannelPermissions</code></h3>\n<pre><code>int ValkeyModule_ACLCheckChannelPermissions(ValkeyModuleUser *user,\n                                            ValkeyModuleString *ch,\n                                            int flags);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Check if the pubsub channel can be accessed by the user based off of the given<br>access flags. See <a href=\"#ValkeyModule_ChannelAtPosWithFlags\"><code>ValkeyModule_ChannelAtPosWithFlags</code></a> for more information about the<br>possible flags that can be passed in.</p>\n<p>If the user is able to access the pubsub channel then <code>VALKEYMODULE_OK</code> is returned, otherwise<br><code>VALKEYMODULE_ERR</code> is returned and errno is set to one of the following values:</p>\n<ul>\n<li>EINVAL: The provided flags are invalid.</li>\n<li>EACCESS: The user does not have permission to access the pubsub channel.</li>\n</ul>\n<p><span id=\"ValkeyModule_ACLAddLogEntry\"></span></p>\n<h3><code>ValkeyModule_ACLAddLogEntry</code></h3>\n<pre><code>int ValkeyModule_ACLAddLogEntry(ValkeyModuleCtx *ctx,\n                                ValkeyModuleUser *user,\n                                ValkeyModuleString *object,\n                                ValkeyModuleACLLogEntryReason reason);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Adds a new entry in the ACL log.<br>Returns <code>VALKEYMODULE_OK</code> on success and <code>VALKEYMODULE_ERR</code> on error.</p>\n<p>For more information about ACL log, please refer to <a href=\"https://valkey.io/commands/acl-log\">https://valkey.io/commands/acl-log</a></p>\n<p><span id=\"ValkeyModule_ACLAddLogEntryByUserName\"></span></p>\n<h3><code>ValkeyModule_ACLAddLogEntryByUserName</code></h3>\n<pre><code>int ValkeyModule_ACLAddLogEntryByUserName(ValkeyModuleCtx *ctx,\n                                          ValkeyModuleString *username,\n                                          ValkeyModuleString *object,\n                                          ValkeyModuleACLLogEntryReason reason);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Adds a new entry in the ACL log with the <code>username</code> <code>ValkeyModuleString</code> provided.<br>Returns <code>VALKEYMODULE_OK</code> on success and <code>VALKEYMODULE_ERR</code> on error.</p>\n<p>For more information about ACL log, please refer to <a href=\"https://valkey.io/commands/acl-log\">https://valkey.io/commands/acl-log</a></p>\n<p><span id=\"ValkeyModule_AuthenticateClientWithUser\"></span></p>\n<h3><code>ValkeyModule_AuthenticateClientWithUser</code></h3>\n<pre><code>int ValkeyModule_AuthenticateClientWithUser(ValkeyModuleCtx *ctx,\n                                            ValkeyModuleUser *module_user,\n                                            ValkeyModuleUserChangedFunc callback,\n                                            void *privdata,\n                                            uint64_t *client_id);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Authenticate the current context&#39;s user with the provided acl user.<br>Returns <code>VALKEYMODULE_ERR</code> if the user is disabled.</p>\n<p>See authenticateClientWithUser for information about callback, <code>client_id</code>,<br>and general usage for authentication.</p>\n<p><span id=\"ValkeyModule_AuthenticateClientWithACLUser\"></span></p>\n<h3><code>ValkeyModule_AuthenticateClientWithACLUser</code></h3>\n<pre><code>int ValkeyModule_AuthenticateClientWithACLUser(ValkeyModuleCtx *ctx,\n                                               const char *name,\n                                               size_t len,\n                                               ValkeyModuleUserChangedFunc callback,\n                                               void *privdata,\n                                               uint64_t *client_id);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Authenticate the current context&#39;s user with the provided acl user.<br>Returns <code>VALKEYMODULE_ERR</code> if the user is disabled or the user does not exist.</p>\n<p>See authenticateClientWithUser for information about callback, <code>client_id</code>,<br>and general usage for authentication.</p>\n<p><span id=\"ValkeyModule_DeauthenticateAndCloseClient\"></span></p>\n<h3><code>ValkeyModule_DeauthenticateAndCloseClient</code></h3>\n<pre><code>int ValkeyModule_DeauthenticateAndCloseClient(ValkeyModuleCtx *ctx,\n                                              uint64_t client_id);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Deauthenticate and close the client. The client resources will not be<br>immediately freed, but will be cleaned up in a background job. This is<br>the recommended way to deauthenticate a client since most clients can&#39;t<br>handle users becoming deauthenticated. Returns <code>VALKEYMODULE_ERR</code> when the<br>client doesn&#39;t exist and <code>VALKEYMODULE_OK</code> when the operation was successful.</p>\n<p>The client ID is returned from the <a href=\"#ValkeyModule_AuthenticateClientWithUser\"><code>ValkeyModule_AuthenticateClientWithUser</code></a> and<br><a href=\"#ValkeyModule_AuthenticateClientWithACLUser\"><code>ValkeyModule_AuthenticateClientWithACLUser</code></a> APIs, but can be obtained through<br>the CLIENT api or through server events.</p>\n<p>This function is not thread safe, and must be executed within the context<br>of a command or thread safe context.</p>\n<p><span id=\"ValkeyModule_RedactClientCommandArgument\"></span></p>\n<h3><code>ValkeyModule_RedactClientCommandArgument</code></h3>\n<pre><code>int ValkeyModule_RedactClientCommandArgument(ValkeyModuleCtx *ctx, int pos);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Redact the client command argument specified at the given position. Redacted arguments<br>are obfuscated in user facing commands such as SLOWLOG or MONITOR, as well as<br>never being written to server logs. This command may be called multiple times on the<br>same position.</p>\n<p>Note that the command name, position 0, can not be redacted.</p>\n<p>Returns <code>VALKEYMODULE_OK</code> if the argument was redacted and <code>VALKEYMODULE_ERR</code> if there<br>was an invalid parameter passed in or the position is outside the client<br>argument range.</p>\n<p><span id=\"ValkeyModule_GetClientCertificate\"></span></p>\n<h3><code>ValkeyModule_GetClientCertificate</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_GetClientCertificate(ValkeyModuleCtx *ctx,\n                                                      uint64_t client_id);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.9</p>\n<p>Return the X.509 client-side certificate used by the client to authenticate<br>this connection.</p>\n<p>The return value is an allocated <code>ValkeyModuleString</code> that is a X.509 certificate<br>encoded in PEM (Base64) format. It should be freed (or auto-freed) by the caller.</p>\n<p>A NULL value is returned in the following conditions:</p>\n<ul>\n<li>Connection ID does not exist</li>\n<li>Connection is not a TLS connection</li>\n<li>Connection is a TLS connection but no client certificate was used</li>\n</ul>\n<p><span id=\"section-modules-dictionary-api\"></span></p>\n<h2>Modules Dictionary API</h2>\n<p>Implements a sorted dictionary (actually backed by a radix tree) with<br>the usual get / set / del / num-items API, together with an iterator<br>capable of going back and forth.</p>\n<p><span id=\"ValkeyModule_CreateDict\"></span></p>\n<h3><code>ValkeyModule_CreateDict</code></h3>\n<pre><code>ValkeyModuleDict *ValkeyModule_CreateDict(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Create a new dictionary. The &#39;ctx&#39; pointer can be the current module context<br>or NULL, depending on what you want. Please follow the following rules:</p>\n<ol>\n<li>Use a NULL context if you plan to retain a reference to this dictionary<br>that will survive the time of the module callback where you created it.</li>\n<li>Use a NULL context if no context is available at the time you are creating<br>the dictionary (of course...).</li>\n<li>However use the current callback context as &#39;ctx&#39; argument if the<br>dictionary time to live is just limited to the callback scope. In this<br>case, if enabled, you can enjoy the automatic memory management that will<br>reclaim the dictionary memory, as well as the strings returned by the<br>Next / Prev dictionary iterator calls.</li>\n</ol>\n<p><span id=\"ValkeyModule_FreeDict\"></span></p>\n<h3><code>ValkeyModule_FreeDict</code></h3>\n<pre><code>void ValkeyModule_FreeDict(ValkeyModuleCtx *ctx, ValkeyModuleDict *d);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Free a dictionary created with <a href=\"#ValkeyModule_CreateDict\"><code>ValkeyModule_CreateDict()</code></a>. You need to pass the<br>context pointer &#39;ctx&#39; only if the dictionary was created using the<br>context instead of passing NULL.</p>\n<p><span id=\"ValkeyModule_DictSize\"></span></p>\n<h3><code>ValkeyModule_DictSize</code></h3>\n<pre><code>uint64_t ValkeyModule_DictSize(ValkeyModuleDict *d);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Return the size of the dictionary (number of keys).</p>\n<p><span id=\"ValkeyModule_DictSetC\"></span></p>\n<h3><code>ValkeyModule_DictSetC</code></h3>\n<pre><code>int ValkeyModule_DictSetC(ValkeyModuleDict *d,\n                          void *key,\n                          size_t keylen,\n                          void *ptr);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Store the specified key into the dictionary, setting its value to the<br>pointer &#39;ptr&#39;. If the key was added with success, since it did not<br>already exist, <code>VALKEYMODULE_OK</code> is returned. Otherwise if the key already<br>exists the function returns <code>VALKEYMODULE_ERR</code>.</p>\n<p><span id=\"ValkeyModule_DictReplaceC\"></span></p>\n<h3><code>ValkeyModule_DictReplaceC</code></h3>\n<pre><code>int ValkeyModule_DictReplaceC(ValkeyModuleDict *d,\n                              void *key,\n                              size_t keylen,\n                              void *ptr);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Like <a href=\"#ValkeyModule_DictSetC\"><code>ValkeyModule_DictSetC()</code></a> but will replace the key with the new<br>value if the key already exists.</p>\n<p><span id=\"ValkeyModule_DictSet\"></span></p>\n<h3><code>ValkeyModule_DictSet</code></h3>\n<pre><code>int ValkeyModule_DictSet(ValkeyModuleDict *d,\n                         ValkeyModuleString *key,\n                         void *ptr);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Like <a href=\"#ValkeyModule_DictSetC\"><code>ValkeyModule_DictSetC()</code></a> but takes the key as a <code>ValkeyModuleString</code>.</p>\n<p><span id=\"ValkeyModule_DictReplace\"></span></p>\n<h3><code>ValkeyModule_DictReplace</code></h3>\n<pre><code>int ValkeyModule_DictReplace(ValkeyModuleDict *d,\n                             ValkeyModuleString *key,\n                             void *ptr);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Like <a href=\"#ValkeyModule_DictReplaceC\"><code>ValkeyModule_DictReplaceC()</code></a> but takes the key as a <code>ValkeyModuleString</code>.</p>\n<p><span id=\"ValkeyModule_DictGetC\"></span></p>\n<h3><code>ValkeyModule_DictGetC</code></h3>\n<pre><code>void *ValkeyModule_DictGetC(ValkeyModuleDict *d,\n                            void *key,\n                            size_t keylen,\n                            int *nokey);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Return the value stored at the specified key. The function returns NULL<br>both in the case the key does not exist, or if you actually stored<br>NULL at key. So, optionally, if the &#39;nokey&#39; pointer is not NULL, it will<br>be set by reference to 1 if the key does not exist, or to 0 if the key<br>exists.</p>\n<p><span id=\"ValkeyModule_DictGet\"></span></p>\n<h3><code>ValkeyModule_DictGet</code></h3>\n<pre><code>void *ValkeyModule_DictGet(ValkeyModuleDict *d,\n                           ValkeyModuleString *key,\n                           int *nokey);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Like <a href=\"#ValkeyModule_DictGetC\"><code>ValkeyModule_DictGetC()</code></a> but takes the key as a <code>ValkeyModuleString</code>.</p>\n<p><span id=\"ValkeyModule_DictDelC\"></span></p>\n<h3><code>ValkeyModule_DictDelC</code></h3>\n<pre><code>int ValkeyModule_DictDelC(ValkeyModuleDict *d,\n                          void *key,\n                          size_t keylen,\n                          void *oldval);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Remove the specified key from the dictionary, returning <code>VALKEYMODULE_OK</code> if<br>the key was found and deleted, or <code>VALKEYMODULE_ERR</code> if instead there was<br>no such key in the dictionary. When the operation is successful, if<br>&#39;oldval&#39; is not NULL, then &#39;*oldval&#39; is set to the value stored at the<br>key before it was deleted. Using this feature it is possible to get<br>a pointer to the value (for instance in order to release it), without<br>having to call <a href=\"#ValkeyModule_DictGet\"><code>ValkeyModule_DictGet()</code></a> before deleting the key.</p>\n<p><span id=\"ValkeyModule_DictDel\"></span></p>\n<h3><code>ValkeyModule_DictDel</code></h3>\n<pre><code>int ValkeyModule_DictDel(ValkeyModuleDict *d,\n                         ValkeyModuleString *key,\n                         void *oldval);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Like <a href=\"#ValkeyModule_DictDelC\"><code>ValkeyModule_DictDelC()</code></a> but gets the key as a <code>ValkeyModuleString</code>.</p>\n<p><span id=\"ValkeyModule_DictIteratorStartC\"></span></p>\n<h3><code>ValkeyModule_DictIteratorStartC</code></h3>\n<pre><code>ValkeyModuleDictIter *ValkeyModule_DictIteratorStartC(ValkeyModuleDict *d,\n                                                      const char *op,\n                                                      void *key,\n                                                      size_t keylen);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Return an iterator, setup in order to start iterating from the specified<br>key by applying the operator &#39;op&#39;, which is just a string specifying the<br>comparison operator to use in order to seek the first element. The<br>operators available are:</p>\n<ul>\n<li><code>^</code>   – Seek the first (lexicographically smaller) key.</li>\n<li><code>$</code>   – Seek the last  (lexicographically bigger) key.</li>\n<li><code>&gt;</code>   – Seek the first element greater than the specified key.</li>\n<li><code>&gt;=</code>  – Seek the first element greater or equal than the specified key.</li>\n<li><code>&lt;</code>   – Seek the first element smaller than the specified key.</li>\n<li><code>&lt;=</code>  – Seek the first element smaller or equal than the specified key.</li>\n<li><code>==</code>  – Seek the first element matching exactly the specified key.</li>\n</ul>\n<p>Note that for <code>^</code> and <code>$</code> the passed key is not used, and the user may<br>just pass NULL with a length of 0.</p>\n<p>If the element to start the iteration cannot be seeked based on the<br>key and operator passed, <a href=\"#ValkeyModule_DictNext\"><code>ValkeyModule_DictNext()</code></a> / Prev() will just return<br><code>VALKEYMODULE_ERR</code> at the first call, otherwise they&#39;ll produce elements.</p>\n<p><span id=\"ValkeyModule_DictIteratorStart\"></span></p>\n<h3><code>ValkeyModule_DictIteratorStart</code></h3>\n<pre><code>ValkeyModuleDictIter *ValkeyModule_DictIteratorStart(ValkeyModuleDict *d,\n                                                     const char *op,\n                                                     ValkeyModuleString *key);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Exactly like <a href=\"#ValkeyModule_DictIteratorStartC\"><code>ValkeyModule_DictIteratorStartC</code></a>, but the key is passed as a<br><code>ValkeyModuleString</code>.</p>\n<p><span id=\"ValkeyModule_DictIteratorStop\"></span></p>\n<h3><code>ValkeyModule_DictIteratorStop</code></h3>\n<pre><code>void ValkeyModule_DictIteratorStop(ValkeyModuleDictIter *di);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Release the iterator created with <a href=\"#ValkeyModule_DictIteratorStart\"><code>ValkeyModule_DictIteratorStart()</code></a>. This call<br>is mandatory otherwise a memory leak is introduced in the module.</p>\n<p><span id=\"ValkeyModule_DictIteratorReseekC\"></span></p>\n<h3><code>ValkeyModule_DictIteratorReseekC</code></h3>\n<pre><code>int ValkeyModule_DictIteratorReseekC(ValkeyModuleDictIter *di,\n                                     const char *op,\n                                     void *key,\n                                     size_t keylen);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>After its creation with <a href=\"#ValkeyModule_DictIteratorStart\"><code>ValkeyModule_DictIteratorStart()</code></a>, it is possible to<br>change the currently selected element of the iterator by using this<br>API call. The result based on the operator and key is exactly like<br>the function <a href=\"#ValkeyModule_DictIteratorStart\"><code>ValkeyModule_DictIteratorStart()</code></a>, however in this case the<br>return value is just <code>VALKEYMODULE_OK</code> in case the seeked element was found,<br>or <code>VALKEYMODULE_ERR</code> in case it was not possible to seek the specified<br>element. It is possible to reseek an iterator as many times as you want.</p>\n<p><span id=\"ValkeyModule_DictIteratorReseek\"></span></p>\n<h3><code>ValkeyModule_DictIteratorReseek</code></h3>\n<pre><code>int ValkeyModule_DictIteratorReseek(ValkeyModuleDictIter *di,\n                                    const char *op,\n                                    ValkeyModuleString *key);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Like <a href=\"#ValkeyModule_DictIteratorReseekC\"><code>ValkeyModule_DictIteratorReseekC()</code></a> but takes the key as a<br><code>ValkeyModuleString</code>.</p>\n<p><span id=\"ValkeyModule_DictNextC\"></span></p>\n<h3><code>ValkeyModule_DictNextC</code></h3>\n<pre><code>void *ValkeyModule_DictNextC(ValkeyModuleDictIter *di,\n                             size_t *keylen,\n                             void **dataptr);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Return the current item of the dictionary iterator <code>di</code> and steps to the<br>next element. If the iterator already yield the last element and there<br>are no other elements to return, NULL is returned, otherwise a pointer<br>to a string representing the key is provided, and the <code>*keylen</code> length<br>is set by reference (if keylen is not NULL). The <code>*dataptr</code>, if not NULL<br>is set to the value of the pointer stored at the returned key as auxiliary<br>data (as set by the <a href=\"#ValkeyModule_DictSet\"><code>ValkeyModule_DictSet</code></a> API).</p>\n<p>Usage example:</p>\n<pre><code> ... create the iterator here ...\n char *key;\n void *data;\n while((key = ValkeyModule_DictNextC(iter,&amp;keylen,&amp;data)) != NULL) {\n     printf(&quot;%.*s %p\\n&quot;, (int)keylen, key, data);\n }\n</code></pre>\n<p>The returned pointer is of type void because sometimes it makes sense<br>to cast it to a <code>char*</code> sometimes to an unsigned <code>char*</code> depending on the<br>fact it contains or not binary data, so this API ends being more<br>comfortable to use.</p>\n<p>The validity of the returned pointer is until the next call to the<br>next/prev iterator step. Also the pointer is no longer valid once the<br>iterator is released.</p>\n<p><span id=\"ValkeyModule_DictPrevC\"></span></p>\n<h3><code>ValkeyModule_DictPrevC</code></h3>\n<pre><code>void *ValkeyModule_DictPrevC(ValkeyModuleDictIter *di,\n                             size_t *keylen,\n                             void **dataptr);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>This function is exactly like <a href=\"#ValkeyModule_DictNext\"><code>ValkeyModule_DictNext()</code></a> but after returning<br>the currently selected element in the iterator, it selects the previous<br>element (lexicographically smaller) instead of the next one.</p>\n<p><span id=\"ValkeyModule_DictNext\"></span></p>\n<h3><code>ValkeyModule_DictNext</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_DictNext(ValkeyModuleCtx *ctx,\n                                          ValkeyModuleDictIter *di,\n                                          void **dataptr);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Like <code>ValkeyModuleNextC()</code>, but instead of returning an internally allocated<br>buffer and key length, it returns directly a module string object allocated<br>in the specified context &#39;ctx&#39; (that may be NULL exactly like for the main<br>API <a href=\"#ValkeyModule_CreateString\"><code>ValkeyModule_CreateString</code></a>).</p>\n<p>The returned string object should be deallocated after use, either manually<br>or by using a context that has automatic memory management active.</p>\n<p><span id=\"ValkeyModule_DictPrev\"></span></p>\n<h3><code>ValkeyModule_DictPrev</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_DictPrev(ValkeyModuleCtx *ctx,\n                                          ValkeyModuleDictIter *di,\n                                          void **dataptr);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Like <a href=\"#ValkeyModule_DictNext\"><code>ValkeyModule_DictNext()</code></a> but after returning the currently selected<br>element in the iterator, it selects the previous element (lexicographically<br>smaller) instead of the next one.</p>\n<p><span id=\"ValkeyModule_DictCompareC\"></span></p>\n<h3><code>ValkeyModule_DictCompareC</code></h3>\n<pre><code>int ValkeyModule_DictCompareC(ValkeyModuleDictIter *di,\n                              const char *op,\n                              void *key,\n                              size_t keylen);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Compare the element currently pointed by the iterator to the specified<br>element given by key/keylen, according to the operator &#39;op&#39; (the set of<br>valid operators are the same valid for <a href=\"#ValkeyModule_DictIteratorStart\"><code>ValkeyModule_DictIteratorStart</code></a>).<br>If the comparison is successful the command returns <code>VALKEYMODULE_OK</code><br>otherwise <code>VALKEYMODULE_ERR</code> is returned.</p>\n<p>This is useful when we want to just emit a lexicographical range, so<br>in the loop, as we iterate elements, we can also check if we are still<br>on range.</p>\n<p>The function return <code>VALKEYMODULE_ERR</code> if the iterator reached the<br>end of elements condition as well.</p>\n<p><span id=\"ValkeyModule_DictCompare\"></span></p>\n<h3><code>ValkeyModule_DictCompare</code></h3>\n<pre><code>int ValkeyModule_DictCompare(ValkeyModuleDictIter *di,\n                             const char *op,\n                             ValkeyModuleString *key);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Like <a href=\"#ValkeyModule_DictCompareC\"><code>ValkeyModule_DictCompareC</code></a> but gets the key to compare with the current<br>iterator key as a <code>ValkeyModuleString</code>.</p>\n<p><span id=\"section-modules-info-fields\"></span></p>\n<h2>Modules Info fields</h2>\n<p><span id=\"ValkeyModule_InfoAddSection\"></span></p>\n<h3><code>ValkeyModule_InfoAddSection</code></h3>\n<pre><code>int ValkeyModule_InfoAddSection(ValkeyModuleInfoCtx *ctx, const char *name);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Used to start a new section, before adding any fields. the section name will<br>be prefixed by <code>&lt;modulename&gt;_</code> and must only include A-Z,a-z,0-9.<br>NULL or empty string indicates the default section (only <code>&lt;modulename&gt;</code>) is used.<br>When return value is <code>VALKEYMODULE_ERR</code>, the section should and will be skipped.</p>\n<p><span id=\"ValkeyModule_InfoBeginDictField\"></span></p>\n<h3><code>ValkeyModule_InfoBeginDictField</code></h3>\n<pre><code>int ValkeyModule_InfoBeginDictField(ValkeyModuleInfoCtx *ctx,\n                                    const char *name);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Starts a dict field, similar to the ones in INFO KEYSPACE. Use normal<br><code>ValkeyModule_InfoAddField</code>* functions to add the items to this field, and<br>terminate with <a href=\"#ValkeyModule_InfoEndDictField\"><code>ValkeyModule_InfoEndDictField</code></a>.</p>\n<p><span id=\"ValkeyModule_InfoEndDictField\"></span></p>\n<h3><code>ValkeyModule_InfoEndDictField</code></h3>\n<pre><code>int ValkeyModule_InfoEndDictField(ValkeyModuleInfoCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Ends a dict field, see <a href=\"#ValkeyModule_InfoBeginDictField\"><code>ValkeyModule_InfoBeginDictField</code></a></p>\n<p><span id=\"ValkeyModule_InfoAddFieldString\"></span></p>\n<h3><code>ValkeyModule_InfoAddFieldString</code></h3>\n<pre><code>int ValkeyModule_InfoAddFieldString(ValkeyModuleInfoCtx *ctx,\n                                    const char *field,\n                                    ValkeyModuleString *value);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Used by <code>ValkeyModuleInfoFunc</code> to add info fields.<br>Each field will be automatically prefixed by <code>&lt;modulename&gt;_</code>.<br>Field names or values must not include <code>\\r\\n</code> or <code>:</code>.</p>\n<p><span id=\"ValkeyModule_InfoAddFieldCString\"></span></p>\n<h3><code>ValkeyModule_InfoAddFieldCString</code></h3>\n<pre><code>int ValkeyModule_InfoAddFieldCString(ValkeyModuleInfoCtx *ctx,\n                                     const char *field,\n                                     const char *value);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>See <a href=\"#ValkeyModule_InfoAddFieldString\"><code>ValkeyModule_InfoAddFieldString()</code></a>.</p>\n<p><span id=\"ValkeyModule_InfoAddFieldDouble\"></span></p>\n<h3><code>ValkeyModule_InfoAddFieldDouble</code></h3>\n<pre><code>int ValkeyModule_InfoAddFieldDouble(ValkeyModuleInfoCtx *ctx,\n                                    const char *field,\n                                    double value);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>See <a href=\"#ValkeyModule_InfoAddFieldString\"><code>ValkeyModule_InfoAddFieldString()</code></a>.</p>\n<p><span id=\"ValkeyModule_InfoAddFieldLongLong\"></span></p>\n<h3><code>ValkeyModule_InfoAddFieldLongLong</code></h3>\n<pre><code>int ValkeyModule_InfoAddFieldLongLong(ValkeyModuleInfoCtx *ctx,\n                                      const char *field,\n                                      long long value);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>See <a href=\"#ValkeyModule_InfoAddFieldString\"><code>ValkeyModule_InfoAddFieldString()</code></a>.</p>\n<p><span id=\"ValkeyModule_InfoAddFieldULongLong\"></span></p>\n<h3><code>ValkeyModule_InfoAddFieldULongLong</code></h3>\n<pre><code>int ValkeyModule_InfoAddFieldULongLong(ValkeyModuleInfoCtx *ctx,\n                                       const char *field,\n                                       unsigned long long value);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>See <a href=\"#ValkeyModule_InfoAddFieldString\"><code>ValkeyModule_InfoAddFieldString()</code></a>.</p>\n<p><span id=\"ValkeyModule_RegisterInfoFunc\"></span></p>\n<h3><code>ValkeyModule_RegisterInfoFunc</code></h3>\n<pre><code>int ValkeyModule_RegisterInfoFunc(ValkeyModuleCtx *ctx,\n                                  ValkeyModuleInfoFunc cb);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Registers callback for the INFO command. The callback should add INFO fields<br>by calling the <code>ValkeyModule_InfoAddField*()</code> functions.</p>\n<p><span id=\"ValkeyModule_GetServerInfo\"></span></p>\n<h3><code>ValkeyModule_GetServerInfo</code></h3>\n<pre><code>ValkeyModuleServerInfoData *ValkeyModule_GetServerInfo(ValkeyModuleCtx *ctx,\n                                                       const char *section);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Get information about the server similar to the one that returns from the<br>INFO command. This function takes an optional &#39;section&#39; argument that may<br>be NULL. The return value holds the output and can be used with<br><a href=\"#ValkeyModule_ServerInfoGetField\"><code>ValkeyModule_ServerInfoGetField</code></a> and alike to get the individual fields.<br>When done, it needs to be freed with <a href=\"#ValkeyModule_FreeServerInfo\"><code>ValkeyModule_FreeServerInfo</code></a> or with the<br>automatic memory management mechanism if enabled.</p>\n<p><span id=\"ValkeyModule_FreeServerInfo\"></span></p>\n<h3><code>ValkeyModule_FreeServerInfo</code></h3>\n<pre><code>void ValkeyModule_FreeServerInfo(ValkeyModuleCtx *ctx,\n                                 ValkeyModuleServerInfoData *data);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Free data created with <a href=\"#ValkeyModule_GetServerInfo\"><code>ValkeyModule_GetServerInfo()</code></a>. You need to pass the<br>context pointer &#39;ctx&#39; only if the dictionary was created using the<br>context instead of passing NULL.</p>\n<p><span id=\"ValkeyModule_ServerInfoGetField\"></span></p>\n<h3><code>ValkeyModule_ServerInfoGetField</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_ServerInfoGetField(ValkeyModuleCtx *ctx,\n                                                    ValkeyModuleServerInfoData *data,\n                                                    const char *field);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Get the value of a field from data collected with <a href=\"#ValkeyModule_GetServerInfo\"><code>ValkeyModule_GetServerInfo()</code></a>. You<br>need to pass the context pointer &#39;ctx&#39; only if you want to use auto memory<br>mechanism to release the returned string. Return value will be NULL if the<br>field was not found.</p>\n<p><span id=\"ValkeyModule_ServerInfoGetFieldC\"></span></p>\n<h3><code>ValkeyModule_ServerInfoGetFieldC</code></h3>\n<pre><code>const char *ValkeyModule_ServerInfoGetFieldC(ValkeyModuleServerInfoData *data,\n                                             const char *field);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Similar to <a href=\"#ValkeyModule_ServerInfoGetField\"><code>ValkeyModule_ServerInfoGetField</code></a>, but returns a char* which should not be freed but the caller.</p>\n<p><span id=\"ValkeyModule_ServerInfoGetFieldSigned\"></span></p>\n<h3><code>ValkeyModule_ServerInfoGetFieldSigned</code></h3>\n<pre><code>long long ValkeyModule_ServerInfoGetFieldSigned(ValkeyModuleServerInfoData *data,\n                                                const char *field,\n                                                int *out_err);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Get the value of a field from data collected with <a href=\"#ValkeyModule_GetServerInfo\"><code>ValkeyModule_GetServerInfo()</code></a>. If the<br>field is not found, or is not numerical or out of range, return value will be<br>0, and the optional <code>out_err</code> argument will be set to <code>VALKEYMODULE_ERR</code>.</p>\n<p><span id=\"ValkeyModule_ServerInfoGetFieldUnsigned\"></span></p>\n<h3><code>ValkeyModule_ServerInfoGetFieldUnsigned</code></h3>\n<pre><code>unsigned long long ValkeyModule_ServerInfoGetFieldUnsigned(ValkeyModuleServerInfoData *data,\n                                                           const char *field,\n                                                           int *out_err);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Get the value of a field from data collected with <a href=\"#ValkeyModule_GetServerInfo\"><code>ValkeyModule_GetServerInfo()</code></a>. If the<br>field is not found, or is not numerical or out of range, return value will be<br>0, and the optional <code>out_err</code> argument will be set to <code>VALKEYMODULE_ERR</code>.</p>\n<p><span id=\"ValkeyModule_ServerInfoGetFieldDouble\"></span></p>\n<h3><code>ValkeyModule_ServerInfoGetFieldDouble</code></h3>\n<pre><code>double ValkeyModule_ServerInfoGetFieldDouble(ValkeyModuleServerInfoData *data,\n                                             const char *field,\n                                             int *out_err);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Get the value of a field from data collected with <a href=\"#ValkeyModule_GetServerInfo\"><code>ValkeyModule_GetServerInfo()</code></a>. If the<br>field is not found, or is not a double, return value will be 0, and the<br>optional <code>out_err</code> argument will be set to <code>VALKEYMODULE_ERR</code>.</p>\n<p><span id=\"section-modules-utility-apis\"></span></p>\n<h2>Modules utility APIs</h2>\n<p><span id=\"ValkeyModule_GetRandomBytes\"></span></p>\n<h3><code>ValkeyModule_GetRandomBytes</code></h3>\n<pre><code>void ValkeyModule_GetRandomBytes(unsigned char *dst, size_t len);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Return random bytes using SHA1 in counter mode with a /dev/urandom<br>initialized seed. This function is fast so can be used to generate<br>many bytes without any effect on the operating system entropy pool.<br>Currently this function is not thread safe.</p>\n<p><span id=\"ValkeyModule_GetRandomHexChars\"></span></p>\n<h3><code>ValkeyModule_GetRandomHexChars</code></h3>\n<pre><code>void ValkeyModule_GetRandomHexChars(char *dst, size_t len);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Like <a href=\"#ValkeyModule_GetRandomBytes\"><code>ValkeyModule_GetRandomBytes()</code></a> but instead of setting the string to<br>random bytes the string is set to random characters in the in the<br>hex charset [0-9a-f].</p>\n<p><span id=\"section-modules-api-exporting-importing\"></span></p>\n<h2>Modules API exporting / importing</h2>\n<p><span id=\"ValkeyModule_ExportSharedAPI\"></span></p>\n<h3><code>ValkeyModule_ExportSharedAPI</code></h3>\n<pre><code>int ValkeyModule_ExportSharedAPI(ValkeyModuleCtx *ctx,\n                                 const char *apiname,\n                                 void *func);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.4</p>\n<p>This function is called by a module in order to export some API with a<br>given name. Other modules will be able to use this API by calling the<br>symmetrical function <a href=\"#ValkeyModule_GetSharedAPI\"><code>ValkeyModule_GetSharedAPI()</code></a> and casting the return value to<br>the right function pointer.</p>\n<p>The function will return <code>VALKEYMODULE_OK</code> if the name is not already taken,<br>otherwise <code>VALKEYMODULE_ERR</code> will be returned and no operation will be<br>performed.</p>\n<p>IMPORTANT: the apiname argument should be a string literal with static<br>lifetime. The API relies on the fact that it will always be valid in<br>the future.</p>\n<p><span id=\"ValkeyModule_GetSharedAPI\"></span></p>\n<h3><code>ValkeyModule_GetSharedAPI</code></h3>\n<pre><code>void *ValkeyModule_GetSharedAPI(ValkeyModuleCtx *ctx, const char *apiname);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.4</p>\n<p>Request an exported API pointer. The return value is just a void pointer<br>that the caller of this function will be required to cast to the right<br>function pointer, so this is a private contract between modules.</p>\n<p>If the requested API is not available then NULL is returned. Because<br>modules can be loaded at different times with different order, this<br>function calls should be put inside some module generic API registering<br>step, that is called every time a module attempts to execute a<br>command that requires external APIs: if some API cannot be resolved, the<br>command should return an error.</p>\n<p>Here is an example:</p>\n<pre><code>int ... myCommandImplementation(void) {\n   if (getExternalAPIs() == 0) {\n        reply with an error here if we cannot have the APIs\n   }\n   // Use the API:\n   myFunctionPointer(foo);\n}\n</code></pre>\n<p>And the function registerAPI() is:</p>\n<pre><code>int getExternalAPIs(void) {\n    static int api_loaded = 0;\n    if (api_loaded != 0) return 1; // APIs already resolved.\n\n    myFunctionPointer = ValkeyModule_GetSharedAPI(&quot;...&quot;);\n    if (myFunctionPointer == NULL) return 0;\n\n    return 1;\n}\n</code></pre>\n<p><span id=\"section-module-command-filter-api\"></span></p>\n<h2>Module Command Filter API</h2>\n<p><span id=\"ValkeyModule_RegisterCommandFilter\"></span></p>\n<h3><code>ValkeyModule_RegisterCommandFilter</code></h3>\n<pre><code>ValkeyModuleCommandFilter *ValkeyModule_RegisterCommandFilter(ValkeyModuleCtx *ctx,\n                                                              ValkeyModuleCommandFilterFunc callback,\n                                                              int flags);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.5</p>\n<p>Register a new command filter function.</p>\n<p>Command filtering makes it possible for modules to extend the server by plugging<br>into the execution flow of all commands.</p>\n<p>A registered filter gets called before the server executes <em>any</em> command.  This<br>includes both core server commands and commands registered by any module.  The<br>filter applies in all execution paths including:</p>\n<ol>\n<li>Invocation by a client.</li>\n<li>Invocation through <a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call()</code></a> by any module.</li>\n<li>Invocation through Lua <code>server.call()</code>.</li>\n<li>Replication of a command from a primary.</li>\n</ol>\n<p>The filter executes in a special filter context, which is different and more<br>limited than a <code>ValkeyModuleCtx</code>.  Because the filter affects any command, it<br>must be implemented in a very efficient way to reduce the performance impact<br>on the server.  All Module API calls that require a valid context (such as<br><a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call()</code></a>, <a href=\"#ValkeyModule_OpenKey\"><code>ValkeyModule_OpenKey()</code></a>, etc.) are not supported in a<br>filter context.</p>\n<p>The <code>ValkeyModuleCommandFilterCtx</code> can be used to inspect or modify the<br>executed command and its arguments.  As the filter executes before the server<br>begins processing the command, any change will affect the way the command is<br>processed.  For example, a module can override server commands this way:</p>\n<ol>\n<li>Register a <code>MODULE.SET</code> command which implements an extended version of<br>the <code>SET</code> command.</li>\n<li>Register a command filter which detects invocation of <code>SET</code> on a specific<br>pattern of keys.  Once detected, the filter will replace the first<br>argument from <code>SET</code> to <code>MODULE.SET</code>.</li>\n<li>When filter execution is complete, the server considers the new command name<br>and therefore executes the module&#39;s own command.</li>\n</ol>\n<p>Note that in the above use case, if <code>MODULE.SET</code> itself uses<br><a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call()</code></a> the filter will be applied on that call as well.  If<br>that is not desired, the <code>VALKEYMODULE_CMDFILTER_NOSELF</code> flag can be set when<br>registering the filter.</p>\n<p>The <code>VALKEYMODULE_CMDFILTER_NOSELF</code> flag prevents execution flows that<br>originate from the module&#39;s own <a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call()</code></a> from reaching the filter.  This<br>flag is effective for all execution flows, including nested ones, as long as<br>the execution begins from the module&#39;s command context or a thread-safe<br>context that is associated with a blocking command.</p>\n<p>Detached thread-safe contexts are <em>not</em> associated with the module and cannot<br>be protected by this flag.</p>\n<p>If multiple filters are registered (by the same or different modules), they<br>are executed in the order of registration.</p>\n<p><span id=\"ValkeyModule_UnregisterCommandFilter\"></span></p>\n<h3><code>ValkeyModule_UnregisterCommandFilter</code></h3>\n<pre><code>int ValkeyModule_UnregisterCommandFilter(ValkeyModuleCtx *ctx,\n                                         ValkeyModuleCommandFilter *filter);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.5</p>\n<p>Unregister a command filter.</p>\n<p><span id=\"ValkeyModule_CommandFilterArgsCount\"></span></p>\n<h3><code>ValkeyModule_CommandFilterArgsCount</code></h3>\n<pre><code>int ValkeyModule_CommandFilterArgsCount(ValkeyModuleCommandFilterCtx *fctx);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.5</p>\n<p>Return the number of arguments a filtered command has.  The number of<br>arguments include the command itself.</p>\n<p><span id=\"ValkeyModule_CommandFilterArgGet\"></span></p>\n<h3><code>ValkeyModule_CommandFilterArgGet</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_CommandFilterArgGet(ValkeyModuleCommandFilterCtx *fctx,\n                                                     int pos);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.5</p>\n<p>Return the specified command argument.  The first argument (position 0) is<br>the command itself, and the rest are user-provided args.</p>\n<p><span id=\"ValkeyModule_CommandFilterArgInsert\"></span></p>\n<h3><code>ValkeyModule_CommandFilterArgInsert</code></h3>\n<pre><code>int ValkeyModule_CommandFilterArgInsert(ValkeyModuleCommandFilterCtx *fctx,\n                                        int pos,\n                                        ValkeyModuleString *arg);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.5</p>\n<p>Modify the filtered command by inserting a new argument at the specified<br>position.  The specified <code>ValkeyModuleString</code> argument may be used by the server<br>after the filter context is destroyed, so it must not be auto-memory<br>allocated, freed or used elsewhere.</p>\n<p><span id=\"ValkeyModule_CommandFilterArgReplace\"></span></p>\n<h3><code>ValkeyModule_CommandFilterArgReplace</code></h3>\n<pre><code>int ValkeyModule_CommandFilterArgReplace(ValkeyModuleCommandFilterCtx *fctx,\n                                         int pos,\n                                         ValkeyModuleString *arg);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.5</p>\n<p>Modify the filtered command by replacing an existing argument with a new one.<br>The specified <code>ValkeyModuleString</code> argument may be used by the server after the<br>filter context is destroyed, so it must not be auto-memory allocated, freed<br>or used elsewhere.</p>\n<p><span id=\"ValkeyModule_CommandFilterArgDelete\"></span></p>\n<h3><code>ValkeyModule_CommandFilterArgDelete</code></h3>\n<pre><code>int ValkeyModule_CommandFilterArgDelete(ValkeyModuleCommandFilterCtx *fctx,\n                                        int pos);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.5</p>\n<p>Modify the filtered command by deleting an argument at the specified<br>position.</p>\n<p><span id=\"ValkeyModule_CommandFilterGetClientId\"></span></p>\n<h3><code>ValkeyModule_CommandFilterGetClientId</code></h3>\n<pre><code>unsigned long long ValkeyModule_CommandFilterGetClientId(ValkeyModuleCommandFilterCtx *fctx);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Get Client ID for client that issued the command we are filtering</p>\n<p><span id=\"ValkeyModule_MallocSize\"></span></p>\n<h3><code>ValkeyModule_MallocSize</code></h3>\n<pre><code>size_t ValkeyModule_MallocSize(void *ptr);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>For a given pointer allocated via <a href=\"#ValkeyModule_Alloc\"><code>ValkeyModule_Alloc()</code></a> or<br><a href=\"#ValkeyModule_Realloc\"><code>ValkeyModule_Realloc()</code></a>, return the amount of memory allocated for it.<br>Note that this may be different (larger) than the memory we allocated<br>with the allocation calls, since sometimes the underlying allocator<br>will allocate more memory.</p>\n<p><span id=\"ValkeyModule_MallocUsableSize\"></span></p>\n<h3><code>ValkeyModule_MallocUsableSize</code></h3>\n<pre><code>size_t ValkeyModule_MallocUsableSize(void *ptr);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.1</p>\n<p>Similar to <a href=\"#ValkeyModule_MallocSize\"><code>ValkeyModule_MallocSize</code></a>, the difference is that <a href=\"#ValkeyModule_MallocUsableSize\"><code>ValkeyModule_MallocUsableSize</code></a><br>returns the usable size of memory by the module.</p>\n<p><span id=\"ValkeyModule_MallocSizeString\"></span></p>\n<h3><code>ValkeyModule_MallocSizeString</code></h3>\n<pre><code>size_t ValkeyModule_MallocSizeString(ValkeyModuleString *str);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Same as <a href=\"#ValkeyModule_MallocSize\"><code>ValkeyModule_MallocSize</code></a>, except it works on <code>ValkeyModuleString</code> pointers.</p>\n<p><span id=\"ValkeyModule_MallocSizeDict\"></span></p>\n<h3><code>ValkeyModule_MallocSizeDict</code></h3>\n<pre><code>size_t ValkeyModule_MallocSizeDict(ValkeyModuleDict *dict);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Same as <a href=\"#ValkeyModule_MallocSize\"><code>ValkeyModule_MallocSize</code></a>, except it works on <code>ValkeyModuleDict</code> pointers.<br>Note that the returned value is only the overhead of the underlying structures,<br>it does not include the allocation size of the keys and values.</p>\n<p><span id=\"ValkeyModule_GetUsedMemoryRatio\"></span></p>\n<h3><code>ValkeyModule_GetUsedMemoryRatio</code></h3>\n<pre><code>float ValkeyModule_GetUsedMemoryRatio(void);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Return the a number between 0 to 1 indicating the amount of memory<br>currently used, relative to the server &quot;maxmemory&quot; configuration.</p>\n<ul>\n<li>0 - No memory limit configured.</li>\n<li>Between 0 and 1 - The percentage of the memory used normalized in 0-1 range.</li>\n<li>Exactly 1 - Memory limit reached.</li>\n<li>Greater 1 - More memory used than the configured limit.</li>\n</ul>\n<p><span id=\"section-scanning-keyspace-and-hashes\"></span></p>\n<h2>Scanning keyspace and hashes</h2>\n<p><span id=\"ValkeyModule_ScanCursorCreate\"></span></p>\n<h3><code>ValkeyModule_ScanCursorCreate</code></h3>\n<pre><code>ValkeyModuleScanCursor *ValkeyModule_ScanCursorCreate(void);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Create a new cursor to be used with <a href=\"#ValkeyModule_Scan\"><code>ValkeyModule_Scan</code></a></p>\n<p><span id=\"ValkeyModule_ScanCursorRestart\"></span></p>\n<h3><code>ValkeyModule_ScanCursorRestart</code></h3>\n<pre><code>void ValkeyModule_ScanCursorRestart(ValkeyModuleScanCursor *cursor);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Restart an existing cursor. The keys will be rescanned.</p>\n<p><span id=\"ValkeyModule_ScanCursorDestroy\"></span></p>\n<h3><code>ValkeyModule_ScanCursorDestroy</code></h3>\n<pre><code>void ValkeyModule_ScanCursorDestroy(ValkeyModuleScanCursor *cursor);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Destroy the cursor struct.</p>\n<p><span id=\"ValkeyModule_Scan\"></span></p>\n<h3><code>ValkeyModule_Scan</code></h3>\n<pre><code>int ValkeyModule_Scan(ValkeyModuleCtx *ctx,\n                      ValkeyModuleScanCursor *cursor,\n                      ValkeyModuleScanCB fn,\n                      void *privdata);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Scan API that allows a module to scan all the keys and value in<br>the selected db.</p>\n<p>Callback for scan implementation.</p>\n<pre><code>void scan_callback(ValkeyModuleCtx *ctx, ValkeyModuleString *keyname,\n                   ValkeyModuleKey *key, void *privdata);\n</code></pre>\n<ul>\n<li><code>ctx</code>: the module context provided to for the scan.</li>\n<li><code>keyname</code>: owned by the caller and need to be retained if used after this<br>function.</li>\n<li><code>key</code>: holds info on the key and value, it is provided as best effort, in<br>some cases it might be NULL, in which case the user should (can) use<br><a href=\"#ValkeyModule_OpenKey\"><code>ValkeyModule_OpenKey()</code></a> (and CloseKey too).<br>when it is provided, it is owned by the caller and will be free when the<br>callback returns.</li>\n<li><code>privdata</code>: the user data provided to <a href=\"#ValkeyModule_Scan\"><code>ValkeyModule_Scan()</code></a>.</li>\n</ul>\n<p>The way it should be used:</p>\n<pre><code> ValkeyModuleScanCursor *c = ValkeyModule_ScanCursorCreate();\n while(ValkeyModule_Scan(ctx, c, callback, privateData));\n ValkeyModule_ScanCursorDestroy(c);\n</code></pre>\n<p>It is also possible to use this API from another thread while the lock<br>is acquired during the actual call to <a href=\"#ValkeyModule_Scan\"><code>ValkeyModule_Scan</code></a>:</p>\n<pre><code> ValkeyModuleScanCursor *c = ValkeyModule_ScanCursorCreate();\n ValkeyModule_ThreadSafeContextLock(ctx);\n while(ValkeyModule_Scan(ctx, c, callback, privateData)){\n     ValkeyModule_ThreadSafeContextUnlock(ctx);\n     // do some background job\n     ValkeyModule_ThreadSafeContextLock(ctx);\n }\n ValkeyModule_ScanCursorDestroy(c);\n</code></pre>\n<p>The function will return 1 if there are more elements to scan and<br>0 otherwise, possibly setting errno if the call failed.</p>\n<p>It is also possible to restart an existing cursor using <a href=\"#ValkeyModule_ScanCursorRestart\"><code>ValkeyModule_ScanCursorRestart</code></a>.</p>\n<p>IMPORTANT: This API is very similar to the SCAN command from the<br>point of view of the guarantees it provides. This means that the API<br>may report duplicated keys, but guarantees to report at least one time<br>every key that was there from the start to the end of the scanning process.</p>\n<p>NOTE: If you do database changes within the callback, you should be aware<br>that the internal state of the database may change. For instance it is safe<br>to delete or modify the current key, but may not be safe to delete any<br>other key.<br>Moreover playing with the keyspace while iterating may have the<br>effect of returning more duplicates. A safe pattern is to store the keys<br>names you want to modify elsewhere, and perform the actions on the keys<br>later when the iteration is complete. However this can cost a lot of<br>memory, so it may make sense to just operate on the current key when<br>possible during the iteration, given that this is safe.</p>\n<p><span id=\"ValkeyModule_ScanKey\"></span></p>\n<h3><code>ValkeyModule_ScanKey</code></h3>\n<pre><code>int ValkeyModule_ScanKey(ValkeyModuleKey *key,\n                         ValkeyModuleScanCursor *cursor,\n                         ValkeyModuleScanKeyCB fn,\n                         void *privdata);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Scan api that allows a module to scan the elements in a hash, set or sorted set key</p>\n<p>Callback for scan implementation.</p>\n<pre><code>void scan_callback(ValkeyModuleKey *key, ValkeyModuleString* field, ValkeyModuleString* value, void *privdata);\n</code></pre>\n<ul>\n<li>key - the key context provided to for the scan.</li>\n<li>field - field name, owned by the caller and need to be retained if used<br>after this function.</li>\n<li>value - value string or NULL for set type, owned by the caller and need to<br>be retained if used after this function.</li>\n<li>privdata - the user data provided to <a href=\"#ValkeyModule_ScanKey\"><code>ValkeyModule_ScanKey</code></a>.</li>\n</ul>\n<p>The way it should be used:</p>\n<pre><code> ValkeyModuleScanCursor *c = ValkeyModule_ScanCursorCreate();\n ValkeyModuleKey *key = ValkeyModule_OpenKey(...)\n while(ValkeyModule_ScanKey(key, c, callback, privateData));\n ValkeyModule_CloseKey(key);\n ValkeyModule_ScanCursorDestroy(c);\n</code></pre>\n<p>It is also possible to use this API from another thread while the lock is acquired during<br>the actual call to <a href=\"#ValkeyModule_ScanKey\"><code>ValkeyModule_ScanKey</code></a>, and re-opening the key each time:</p>\n<pre><code> ValkeyModuleScanCursor *c = ValkeyModule_ScanCursorCreate();\n ValkeyModule_ThreadSafeContextLock(ctx);\n ValkeyModuleKey *key = ValkeyModule_OpenKey(...)\n while(ValkeyModule_ScanKey(ctx, c, callback, privateData)){\n     ValkeyModule_CloseKey(key);\n     ValkeyModule_ThreadSafeContextUnlock(ctx);\n     // do some background job\n     ValkeyModule_ThreadSafeContextLock(ctx);\n     ValkeyModuleKey *key = ValkeyModule_OpenKey(...)\n }\n ValkeyModule_CloseKey(key);\n ValkeyModule_ScanCursorDestroy(c);\n</code></pre>\n<p>The function will return 1 if there are more elements to scan and 0 otherwise,<br>possibly setting errno if the call failed.<br>It is also possible to restart an existing cursor using <a href=\"#ValkeyModule_ScanCursorRestart\"><code>ValkeyModule_ScanCursorRestart</code></a>.</p>\n<p>NOTE: Certain operations are unsafe while iterating the object. For instance<br>while the API guarantees to return at least one time all the elements that<br>are present in the data structure consistently from the start to the end<br>of the iteration (see HSCAN and similar commands documentation), the more<br>you play with the elements, the more duplicates you may get. In general<br>deleting the current element of the data structure is safe, while removing<br>the key you are iterating is not safe.</p>\n<p><span id=\"section-module-fork-api\"></span></p>\n<h2>Module fork API</h2>\n<p><span id=\"ValkeyModule_Fork\"></span></p>\n<h3><code>ValkeyModule_Fork</code></h3>\n<pre><code>int ValkeyModule_Fork(ValkeyModuleForkDoneHandler cb, void *user_data);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Create a background child process with the current frozen snapshot of the<br>main process where you can do some processing in the background without<br>affecting / freezing the traffic and no need for threads and GIL locking.<br>Note that the server allows for only one concurrent fork.<br>When the child wants to exit, it should call <a href=\"#ValkeyModule_ExitFromChild\"><code>ValkeyModule_ExitFromChild</code></a>.<br>If the parent wants to kill the child it should call <a href=\"#ValkeyModule_KillForkChild\"><code>ValkeyModule_KillForkChild</code></a><br>The done handler callback will be executed on the parent process when the<br>child existed (but not when killed)<br>Return: -1 on failure, on success the parent process will get a positive PID<br>of the child, and the child process will get 0.</p>\n<p><span id=\"ValkeyModule_SendChildHeartbeat\"></span></p>\n<h3><code>ValkeyModule_SendChildHeartbeat</code></h3>\n<pre><code>void ValkeyModule_SendChildHeartbeat(double progress);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>The module is advised to call this function from the fork child once in a while,<br>so that it can report progress and COW memory to the parent which will be<br>reported in INFO.<br>The <code>progress</code> argument should between 0 and 1, or -1 when not available.</p>\n<p><span id=\"ValkeyModule_ExitFromChild\"></span></p>\n<h3><code>ValkeyModule_ExitFromChild</code></h3>\n<pre><code>int ValkeyModule_ExitFromChild(int retcode);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Call from the child process when you want to terminate it.<br>retcode will be provided to the done handler executed on the parent process.</p>\n<p><span id=\"ValkeyModule_KillForkChild\"></span></p>\n<h3><code>ValkeyModule_KillForkChild</code></h3>\n<pre><code>int ValkeyModule_KillForkChild(int child_pid);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Can be used to kill the forked child process from the parent process.<br><code>child_pid</code> would be the return value of <a href=\"#ValkeyModule_Fork\"><code>ValkeyModule_Fork</code></a>.</p>\n<p><span id=\"section-server-hooks-implementation\"></span></p>\n<h2>Server hooks implementation</h2>\n<p><span id=\"ValkeyModule_SubscribeToServerEvent\"></span></p>\n<h3><code>ValkeyModule_SubscribeToServerEvent</code></h3>\n<pre><code>int ValkeyModule_SubscribeToServerEvent(ValkeyModuleCtx *ctx,\n                                        ValkeyModuleEvent event,\n                                        ValkeyModuleEventCallback callback);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Register to be notified, via a callback, when the specified server event<br>happens. The callback is called with the event as argument, and an additional<br>argument which is a void pointer and should be cased to a specific type<br>that is event-specific (but many events will just use NULL since they do not<br>have additional information to pass to the callback).</p>\n<p>If the callback is NULL and there was a previous subscription, the module<br>will be unsubscribed. If there was a previous subscription and the callback<br>is not null, the old callback will be replaced with the new one.</p>\n<p>The callback must be of this type:</p>\n<pre><code>int (*ValkeyModuleEventCallback)(ValkeyModuleCtx *ctx,\n                                ValkeyModuleEvent eid,\n                                uint64_t subevent,\n                                void *data);\n</code></pre>\n<p>The &#39;ctx&#39; is a normal module context that the callback can use in<br>order to call other modules APIs. The &#39;eid&#39; is the event itself, this<br>is only useful in the case the module subscribed to multiple events: using<br>the &#39;id&#39; field of this structure it is possible to check if the event<br>is one of the events we registered with this callback. The &#39;subevent&#39; field<br>depends on the event that fired.</p>\n<p>Finally the &#39;data&#39; pointer may be populated, only for certain events, with<br>more relevant data.</p>\n<p>Here is a list of events you can use as &#39;eid&#39; and related sub events:</p>\n<ul>\n<li><p><code>ValkeyModuleEvent_ReplicationRoleChanged</code>:</p>\n<p>  This event is called when the instance switches from primary<br>  to replica or the other way around, however the event is<br>  also called when the replica remains a replica but starts to<br>  replicate with a different primary.</p>\n<p>  The following sub events are available:</p>\n<ul>\n<li><code>VALKEYMODULE_SUBEVENT_REPLROLECHANGED_NOW_PRIMARY</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_REPLROLECHANGED_NOW_REPLICA</code></li>\n</ul>\n<p>  The &#39;data&#39; field can be casted by the callback to a<br>  <code>ValkeyModuleReplicationInfo</code> structure with the following fields:</p>\n<pre><code>  int primary; // true if primary, false if replica\n  char *primary_host; // primary instance hostname for NOW_REPLICA\n  int primary_port; // primary instance port for NOW_REPLICA\n  char *replid1; // Main replication ID\n  char *replid2; // Secondary replication ID\n  uint64_t repl1_offset; // Main replication offset\n  uint64_t repl2_offset; // Offset of replid2 validity\n</code></pre>\n</li>\n<li><p><code>ValkeyModuleEvent_Persistence</code></p>\n<p>  This event is called when RDB saving or AOF rewriting starts<br>  and ends. The following sub events are available:</p>\n<ul>\n<li><code>VALKEYMODULE_SUBEVENT_PERSISTENCE_RDB_START</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_PERSISTENCE_AOF_START</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_PERSISTENCE_SYNC_RDB_START</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_PERSISTENCE_SYNC_AOF_START</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_PERSISTENCE_ENDED</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_PERSISTENCE_FAILED</code></li>\n</ul>\n<p>  The above events are triggered not just when the user calls the<br>  relevant commands like BGSAVE, but also when a saving operation<br>  or AOF rewriting occurs because of internal server triggers.<br>  The SYNC_RDB_START sub events are happening in the foreground due to<br>  SAVE command, FLUSHALL, or server shutdown, and the other RDB and<br>  AOF sub events are executed in a background fork child, so any<br>  action the module takes can only affect the generated AOF or RDB,<br>  but will not be reflected in the parent process and affect connected<br>  clients and commands. Also note that the AOF_START sub event may end<br>  up saving RDB content in case of an AOF with rdb-preamble.</p>\n</li>\n<li><p><code>ValkeyModuleEvent_FlushDB</code></p>\n<p>  The FLUSHALL, FLUSHDB or an internal flush (for instance<br>  because of replication, after the replica synchronization)<br>  happened. The following sub events are available:</p>\n<ul>\n<li><code>VALKEYMODULE_SUBEVENT_FLUSHDB_START</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_FLUSHDB_END</code></li>\n</ul>\n<p>  The data pointer can be casted to a ValkeyModuleFlushInfo<br>  structure with the following fields:</p>\n<pre><code>  int32_t async;  // True if the flush is done in a thread.\n                  // See for instance FLUSHALL ASYNC.\n                  // In this case the END callback is invoked\n                  // immediately after the database is put\n                  // in the free list of the thread.\n  int32_t dbnum;  // Flushed database number, -1 for all the DBs\n                  // in the case of the FLUSHALL operation.\n</code></pre>\n<p>  The start event is called <em>before</em> the operation is initiated, thus<br>  allowing the callback to call DBSIZE or other operation on the<br>  yet-to-free keyspace.</p>\n</li>\n<li><p><code>ValkeyModuleEvent_Loading</code></p>\n<p>  Called on loading operations: at startup when the server is<br>  started, but also after a first synchronization when the<br>  replica is loading the RDB file from the primary.<br>  The following sub events are available:</p>\n<ul>\n<li><code>VALKEYMODULE_SUBEVENT_LOADING_RDB_START</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_LOADING_AOF_START</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_LOADING_REPL_START</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_LOADING_ENDED</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_LOADING_FAILED</code></li>\n</ul>\n<p>  Note that AOF loading may start with an RDB data in case of<br>  rdb-preamble, in which case you&#39;ll only receive an AOF_START event.</p>\n</li>\n<li><p><code>ValkeyModuleEvent_ClientChange</code></p>\n<p>  Called when a client connects or disconnects.<br>  The data pointer can be casted to a ValkeyModuleClientInfo<br>  structure, documented in ValkeyModule_GetClientInfoById().<br>  The following sub events are available:</p>\n<ul>\n<li><code>VALKEYMODULE_SUBEVENT_CLIENT_CHANGE_CONNECTED</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_CLIENT_CHANGE_DISCONNECTED</code></li>\n</ul>\n</li>\n<li><p><code>ValkeyModuleEvent_Shutdown</code></p>\n<p>  The server is shutting down. No subevents are available.</p>\n</li>\n<li><p><code>ValkeyModuleEvent_ReplicaChange</code></p>\n<p>  This event is called when the instance (that can be both a<br>  primary or a replica) get a new online replica, or lose a<br>  replica since it gets disconnected.<br>  The following sub events are available:</p>\n<ul>\n<li><code>VALKEYMODULE_SUBEVENT_REPLICA_CHANGE_ONLINE</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_REPLICA_CHANGE_OFFLINE</code></li>\n</ul>\n<p>  No additional information is available so far: future versions<br>  of the server will have an API in order to enumerate the replicas<br>  connected and their state.</p>\n</li>\n<li><p><code>ValkeyModuleEvent_CronLoop</code></p>\n<p>  This event is called every time the server calls the serverCron()<br>  function in order to do certain bookkeeping. Modules that are<br>  required to do operations from time to time may use this callback.<br>  Normally the server calls this function 10 times per second, but<br>  this changes depending on the &quot;hz&quot; configuration.<br>  No sub events are available.</p>\n<p>  The data pointer can be casted to a ValkeyModuleCronLoop<br>  structure with the following fields:</p>\n<pre><code>  int32_t hz;  // Approximate number of events per second.\n</code></pre>\n</li>\n<li><p><code>ValkeyModuleEvent_PrimaryLinkChange</code></p>\n<p>  This is called for replicas in order to notify when the<br>  replication link becomes functional (up) with our primary,<br>  or when it goes down. Note that the link is not considered<br>  up when we just connected to the primary, but only if the<br>  replication is happening correctly.<br>  The following sub events are available:</p>\n<ul>\n<li><code>VALKEYMODULE_SUBEVENT_PRIMARY_LINK_UP</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_PRIMARY_LINK_DOWN</code></li>\n</ul>\n</li>\n<li><p><code>ValkeyModuleEvent_ModuleChange</code></p>\n<p>  This event is called when a new module is loaded or one is unloaded.<br>  The following sub events are available:</p>\n<ul>\n<li><code>VALKEYMODULE_SUBEVENT_MODULE_LOADED</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_MODULE_UNLOADED</code></li>\n</ul>\n<p>  The data pointer can be casted to a ValkeyModuleModuleChange<br>  structure with the following fields:</p>\n<pre><code>  const char* module_name;  // Name of module loaded or unloaded.\n  int32_t module_version;  // Module version.\n</code></pre>\n</li>\n<li><p><code>ValkeyModuleEvent_LoadingProgress</code></p>\n<p>  This event is called repeatedly called while an RDB or AOF file<br>  is being loaded.<br>  The following sub events are available:</p>\n<ul>\n<li><code>VALKEYMODULE_SUBEVENT_LOADING_PROGRESS_RDB</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_LOADING_PROGRESS_AOF</code></li>\n</ul>\n<p>  The data pointer can be casted to a ValkeyModuleLoadingProgress<br>  structure with the following fields:</p>\n<pre><code>  int32_t hz;  // Approximate number of events per second.\n  int32_t progress;  // Approximate progress between 0 and 1024,\n                     // or -1 if unknown.\n</code></pre>\n</li>\n<li><p><code>ValkeyModuleEvent_SwapDB</code></p>\n<p>  This event is called when a SWAPDB command has been successfully<br>  Executed.<br>  For this event call currently there is no subevents available.</p>\n<p>  The data pointer can be casted to a ValkeyModuleSwapDbInfo<br>  structure with the following fields:</p>\n<pre><code>  int32_t dbnum_first;    // Swap Db first dbnum\n  int32_t dbnum_second;   // Swap Db second dbnum\n</code></pre>\n</li>\n<li><p><code>ValkeyModuleEvent_ReplBackup</code></p>\n<p>  WARNING: Replication Backup events are deprecated since Redis OSS 7.0 and are never fired.<br>  See ValkeyModuleEvent_ReplAsyncLoad for understanding how Async Replication Loading events<br>  are now triggered when repl-diskless-load is set to swapdb.</p>\n<p>  Called when repl-diskless-load config is set to swapdb,<br>  And the server needs to backup the current database for the<br>  possibility to be restored later. A module with global data and<br>  maybe with aux_load and aux_save callbacks may need to use this<br>  notification to backup / restore / discard its globals.<br>  The following sub events are available:</p>\n<ul>\n<li><code>VALKEYMODULE_SUBEVENT_REPL_BACKUP_CREATE</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_REPL_BACKUP_RESTORE</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_REPL_BACKUP_DISCARD</code></li>\n</ul>\n</li>\n<li><p><code>ValkeyModuleEvent_ReplAsyncLoad</code></p>\n<p>  Called when repl-diskless-load config is set to swapdb and a replication with a primary of same<br>  data set history (matching replication ID) occurs.<br>  In which case the server serves current data set while loading new database in memory from socket.<br>  Modules must have declared they support this mechanism in order to activate it, through<br>  VALKEYMODULE_OPTIONS_HANDLE_REPL_ASYNC_LOAD flag.<br>  The following sub events are available:</p>\n<ul>\n<li><code>VALKEYMODULE_SUBEVENT_REPL_ASYNC_LOAD_STARTED</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_REPL_ASYNC_LOAD_ABORTED</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_REPL_ASYNC_LOAD_COMPLETED</code></li>\n</ul>\n</li>\n<li><p><code>ValkeyModuleEvent_ForkChild</code></p>\n<p>  Called when a fork child (AOFRW, RDBSAVE, module fork...) is born/dies<br>  The following sub events are available:</p>\n<ul>\n<li><code>VALKEYMODULE_SUBEVENT_FORK_CHILD_BORN</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_FORK_CHILD_DIED</code></li>\n</ul>\n</li>\n<li><p><code>ValkeyModuleEvent_EventLoop</code></p>\n<p>  Called on each event loop iteration, once just before the event loop goes<br>  to sleep or just after it wakes up.<br>  The following sub events are available:</p>\n<ul>\n<li><code>VALKEYMODULE_SUBEVENT_EVENTLOOP_BEFORE_SLEEP</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_EVENTLOOP_AFTER_SLEEP</code></li>\n</ul>\n</li>\n<li><p><code>ValkeyModule_Event_Config</code></p>\n<p>  Called when a configuration event happens<br>  The following sub events are available:</p>\n<ul>\n<li><code>VALKEYMODULE_SUBEVENT_CONFIG_CHANGE</code></li>\n</ul>\n<p>  The data pointer can be casted to a ValkeyModuleConfigChange<br>  structure with the following fields:</p>\n<pre><code>  const char **config_names; // An array of C string pointers containing the\n                             // name of each modified configuration item\n  uint32_t num_changes;      // The number of elements in the config_names array\n</code></pre>\n</li>\n<li><p><code>ValkeyModule_Event_Key</code></p>\n<p>  Called when a key is removed from the keyspace. We can&#39;t modify any key in<br>  the event.<br>  The following sub events are available:</p>\n<ul>\n<li><code>VALKEYMODULE_SUBEVENT_KEY_DELETED</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_KEY_EXPIRED</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_KEY_EVICTED</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_KEY_OVERWRITTEN</code></li>\n</ul>\n<p>  The data pointer can be casted to a ValkeyModuleKeyInfo<br>  structure with the following fields:</p>\n<pre><code>  ValkeyModuleKey *key;    // Key name\n</code></pre>\n</li>\n</ul>\n<p>The function returns <code>VALKEYMODULE_OK</code> if the module was successfully subscribed<br>for the specified event. If the API is called from a wrong context or unsupported event<br>is given then <code>VALKEYMODULE_ERR</code> is returned.</p>\n<p><span id=\"ValkeyModule_IsSubEventSupported\"></span></p>\n<h3><code>ValkeyModule_IsSubEventSupported</code></h3>\n<pre><code>int ValkeyModule_IsSubEventSupported(ValkeyModuleEvent event,\n                                     int64_t subevent);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.9</p>\n<p>For a given server event and subevent, return zero if the<br>subevent is not supported and non-zero otherwise.</p>\n<p><span id=\"section-module-configurations-api\"></span></p>\n<h2>Module Configurations API</h2>\n<p><span id=\"ValkeyModule_RegisterStringConfig\"></span></p>\n<h3><code>ValkeyModule_RegisterStringConfig</code></h3>\n<pre><code>int ValkeyModule_RegisterStringConfig(ValkeyModuleCtx *ctx,\n                                      const char *name,\n                                      const char *default_val,\n                                      unsigned int flags,\n                                      ValkeyModuleConfigGetStringFunc getfn,\n                                      ValkeyModuleConfigSetStringFunc setfn,\n                                      ValkeyModuleConfigApplyFunc applyfn,\n                                      void *privdata);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Create a string config that users can interact with via the server config file,<br><code>CONFIG SET</code>, <code>CONFIG GET</code>, and <code>CONFIG REWRITE</code> commands.</p>\n<p>The actual config value is owned by the module, and the <code>getfn</code>, <code>setfn</code> and optional<br><code>applyfn</code> callbacks that are provided to the server in order to access or manipulate the<br>value. The <code>getfn</code> callback retrieves the value from the module, while the <code>setfn</code><br>callback provides a value to be stored into the module config.<br>The optional <code>applyfn</code> callback is called after a <code>CONFIG SET</code> command modified one or<br>more configs using the <code>setfn</code> callback and can be used to atomically apply a config<br>after several configs were changed together.<br>If there are multiple configs with <code>applyfn</code> callbacks set by a single <code>CONFIG SET</code><br>command, they will be deduplicated if their <code>applyfn</code> function and <code>privdata</code> pointers<br>are identical, and the callback will only be run once.<br>Both the <code>setfn</code> and <code>applyfn</code> can return an error if the provided value is invalid or<br>cannot be used.<br>The config also declares a type for the value that is validated by the server and<br>provided to the module. The config system provides the following types:</p>\n<ul>\n<li>String: Binary safe string data.</li>\n<li>Enum: One of a finite number of string tokens, provided during registration.</li>\n<li>Numeric: 64 bit signed integer, which also supports min and max values.</li>\n<li>Bool: Yes or no value.</li>\n</ul>\n<p>The <code>setfn</code> callback is expected to return <code>VALKEYMODULE_OK</code> when the value is successfully<br>applied. It can also return <code>VALKEYMODULE_ERR</code> if the value can&#39;t be applied, and the<br>*err pointer can be set with a <code>ValkeyModuleString</code> error message to provide to the client.<br>This <code>ValkeyModuleString</code> will be freed by the server after returning from the set callback.</p>\n<p>All configs are registered with a name, a type, a default value, private data that is made<br>available in the callbacks, as well as several flags that modify the behavior of the config.<br>The name must only contain alphanumeric characters or dashes. The supported flags are:</p>\n<ul>\n<li><code>VALKEYMODULE_CONFIG_DEFAULT</code>: The default flags for a config. This creates a config that can be modified after<br>startup.</li>\n<li><code>VALKEYMODULE_CONFIG_IMMUTABLE</code>: This config can only be provided loading time.</li>\n<li><code>VALKEYMODULE_CONFIG_SENSITIVE</code>: The value stored in this config is redacted from all logging.</li>\n<li><code>VALKEYMODULE_CONFIG_HIDDEN</code>: The name is hidden from <code>CONFIG GET</code> with pattern matching.</li>\n<li><code>VALKEYMODULE_CONFIG_PROTECTED</code>: This config will be only be modifiable based off the value of<br>enable-protected-configs.</li>\n<li><code>VALKEYMODULE_CONFIG_DENY_LOADING</code>: This config is not modifiable while the server is loading data.</li>\n<li><code>VALKEYMODULE_CONFIG_MEMORY</code>: For numeric configs, this config will convert data unit notations into their byte<br>equivalent.</li>\n<li><code>VALKEYMODULE_CONFIG_BITFLAGS</code>: For enum configs, this config will allow multiple entries to be combined as bit<br>flags.</li>\n</ul>\n<p>Default values are used on startup to set the value if it is not provided via the config file<br>or command line. Default values are also used to compare to on a config rewrite.</p>\n<p>Notes:</p>\n<ol>\n<li>On string config sets that the string passed to the set callback will be freed after execution and the module<br>must retain it.</li>\n<li>On string config gets the string will not be consumed and will be valid after execution.</li>\n</ol>\n<p>Example implementation:</p>\n<pre><code>ValkeyModuleString *strval;\nint adjustable = 1;\nValkeyModuleString *getStringConfigCommand(const char *name, void *privdata) {\n    return strval;\n}\n\nint setStringConfigCommand(const char *name, ValkeyModuleString *new, void *privdata, ValkeyModuleString **err) {\n   if (adjustable) {\n       ValkeyModule_Free(strval);\n       ValkeyModule_RetainString(NULL, new);\n       strval = new;\n       return VALKEYMODULE_OK;\n   }\n   *err = ValkeyModule_CreateString(NULL, &quot;Not adjustable.&quot;, 15);\n   return VALKEYMODULE_ERR;\n}\n...\nValkeyModule_RegisterStringConfig(ctx, &quot;string&quot;, NULL, VALKEYMODULE_CONFIG_DEFAULT, getStringConfigCommand,\n</code></pre>\n<p>setStringConfigCommand, NULL, NULL);</p>\n<p>If the registration fails, <code>VALKEYMODULE_ERR</code> is returned and one of the following<br>errno is set:</p>\n<ul>\n<li>EBUSY: Registering the Config outside of <code>ValkeyModule_OnLoad</code>.</li>\n<li>EINVAL: The provided flags are invalid for the registration or the name of the config contains invalid characters.</li>\n<li>EALREADY: The provided configuration name is already used.</li>\n</ul>\n<p><span id=\"ValkeyModule_RegisterBoolConfig\"></span></p>\n<h3><code>ValkeyModule_RegisterBoolConfig</code></h3>\n<pre><code>int ValkeyModule_RegisterBoolConfig(ValkeyModuleCtx *ctx,\n                                    const char *name,\n                                    int default_val,\n                                    unsigned int flags,\n                                    ValkeyModuleConfigGetBoolFunc getfn,\n                                    ValkeyModuleConfigSetBoolFunc setfn,\n                                    ValkeyModuleConfigApplyFunc applyfn,\n                                    void *privdata);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Create a bool config that server clients can interact with via the<br><code>CONFIG SET</code>, <code>CONFIG GET</code>, and <code>CONFIG REWRITE</code> commands. See<br><a href=\"#ValkeyModule_RegisterStringConfig\"><code>ValkeyModule_RegisterStringConfig</code></a> for detailed information about configs.</p>\n<p><span id=\"ValkeyModule_RegisterEnumConfig\"></span></p>\n<h3><code>ValkeyModule_RegisterEnumConfig</code></h3>\n<pre><code>int ValkeyModule_RegisterEnumConfig(ValkeyModuleCtx *ctx,\n                                    const char *name,\n                                    int default_val,\n                                    unsigned int flags,\n                                    const char **enum_values,\n                                    const int *int_values,\n                                    int num_enum_vals,\n                                    ValkeyModuleConfigGetEnumFunc getfn,\n                                    ValkeyModuleConfigSetEnumFunc setfn,\n                                    ValkeyModuleConfigApplyFunc applyfn,\n                                    void *privdata);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Create an enum config that server clients can interact with via the<br><code>CONFIG SET</code>, <code>CONFIG GET</code>, and <code>CONFIG REWRITE</code> commands.<br>Enum configs are a set of string tokens to corresponding integer values, where<br>the string value is exposed to clients but the inter value is passed to the server<br>and the module. These values are defined in <code>enum_values</code>, an array<br>of null-terminated c strings, and <code>int_vals</code>, an array of enum values who has an<br>index partner in <code>enum_values</code>.<br>Example Implementation:<br>     const char *enum_vals[3] = {&quot;first&quot;, &quot;second&quot;, &quot;third&quot;};<br>     const int int_vals[3] = {0, 2, 4};<br>     int enum_val = 0;</p>\n<pre><code> int getEnumConfigCommand(const char *name, void *privdata) {\n     return enum_val;\n }\n\n int setEnumConfigCommand(const char *name, int val, void *privdata, const char **err) {\n     enum_val = val;\n     return VALKEYMODULE_OK;\n }\n ...\n ValkeyModule_RegisterEnumConfig(ctx, &quot;enum&quot;, 0, VALKEYMODULE_CONFIG_DEFAULT, enum_vals, int_vals, 3,\n</code></pre>\n<p>getEnumConfigCommand, setEnumConfigCommand, NULL, NULL);</p>\n<p>Note that you can use <code>VALKEYMODULE_CONFIG_BITFLAGS</code> so that multiple enum string<br>can be combined into one integer as bit flags, in which case you may want to<br>sort your enums so that the preferred combinations are present first.</p>\n<p>See <a href=\"#ValkeyModule_RegisterStringConfig\"><code>ValkeyModule_RegisterStringConfig</code></a> for detailed general information about configs.</p>\n<p><span id=\"ValkeyModule_RegisterNumericConfig\"></span></p>\n<h3><code>ValkeyModule_RegisterNumericConfig</code></h3>\n<pre><code>int ValkeyModule_RegisterNumericConfig(ValkeyModuleCtx *ctx,\n                                       const char *name,\n                                       long long default_val,\n                                       unsigned int flags,\n                                       long long min,\n                                       long long max,\n                                       ValkeyModuleConfigGetNumericFunc getfn,\n                                       ValkeyModuleConfigSetNumericFunc setfn,\n                                       ValkeyModuleConfigApplyFunc applyfn,\n                                       void *privdata);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Create an integer config that server clients can interact with via the<br><code>CONFIG SET</code>, <code>CONFIG GET</code>, and <code>CONFIG REWRITE</code> commands. See<br><a href=\"#ValkeyModule_RegisterStringConfig\"><code>ValkeyModule_RegisterStringConfig</code></a> for detailed information about configs.</p>\n<p><span id=\"ValkeyModule_LoadConfigs\"></span></p>\n<h3><code>ValkeyModule_LoadConfigs</code></h3>\n<pre><code>int ValkeyModule_LoadConfigs(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Applies all pending configurations on the module load. This should be called<br>after all of the configurations have been registered for the module inside of <code>ValkeyModule_OnLoad</code>.<br>This will return <code>VALKEYMODULE_ERR</code> if it is called outside <code>ValkeyModule_OnLoad</code>.<br>This API needs to be called when configurations are provided in either <code>MODULE LOADEX</code><br>or provided as startup arguments.</p>\n<p><span id=\"section-rdb-load-save-api\"></span></p>\n<h2>RDB load/save API</h2>\n<p><span id=\"ValkeyModule_RdbStreamCreateFromFile\"></span></p>\n<h3><code>ValkeyModule_RdbStreamCreateFromFile</code></h3>\n<pre><code>ValkeyModuleRdbStream *ValkeyModule_RdbStreamCreateFromFile(const char *filename);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Create a stream object to save/load RDB to/from a file.</p>\n<p>This function returns a pointer to <code>ValkeyModuleRdbStream</code> which is owned<br>by the caller. It requires a call to <a href=\"#ValkeyModule_RdbStreamFree\"><code>ValkeyModule_RdbStreamFree()</code></a> to free<br>the object.</p>\n<p><span id=\"ValkeyModule_RdbStreamFree\"></span></p>\n<h3><code>ValkeyModule_RdbStreamFree</code></h3>\n<pre><code>void ValkeyModule_RdbStreamFree(ValkeyModuleRdbStream *stream);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Release an RDB stream object.</p>\n<p><span id=\"ValkeyModule_RdbLoad\"></span></p>\n<h3><code>ValkeyModule_RdbLoad</code></h3>\n<pre><code>int ValkeyModule_RdbLoad(ValkeyModuleCtx *ctx,\n                         ValkeyModuleRdbStream *stream,\n                         int flags);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Load RDB file from the <code>stream</code>. Dataset will be cleared first and then RDB<br>file will be loaded.</p>\n<p><code>flags</code> must be zero. This parameter is for future use.</p>\n<p>On success <code>VALKEYMODULE_OK</code> is returned, otherwise <code>VALKEYMODULE_ERR</code> is returned<br>and errno is set accordingly.</p>\n<p>Example:</p>\n<pre><code>ValkeyModuleRdbStream *s = ValkeyModule_RdbStreamCreateFromFile(&quot;exp.rdb&quot;);\nValkeyModule_RdbLoad(ctx, s, 0);\nValkeyModule_RdbStreamFree(s);\n</code></pre>\n<p><span id=\"ValkeyModule_RdbSave\"></span></p>\n<h3><code>ValkeyModule_RdbSave</code></h3>\n<pre><code>int ValkeyModule_RdbSave(ValkeyModuleCtx *ctx,\n                         ValkeyModuleRdbStream *stream,\n                         int flags);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Save dataset to the RDB stream.</p>\n<p><code>flags</code> must be zero. This parameter is for future use.</p>\n<p>On success <code>VALKEYMODULE_OK</code> is returned, otherwise <code>VALKEYMODULE_ERR</code> is returned<br>and errno is set accordingly.</p>\n<p>Example:</p>\n<pre><code>ValkeyModuleRdbStream *s = ValkeyModule_RdbStreamCreateFromFile(&quot;exp.rdb&quot;);\nValkeyModule_RdbSave(ctx, s, 0);\nValkeyModule_RdbStreamFree(s);\n</code></pre>\n<p><span id=\"ValkeyModule_RegisterScriptingEngine\"></span></p>\n<h3><code>ValkeyModule_RegisterScriptingEngine</code></h3>\n<pre><code>int ValkeyModule_RegisterScriptingEngine(ValkeyModuleCtx *module_ctx,;\n</code></pre>\n<p><strong>Available since:</strong> 8.1.0</p>\n<p>Registers a new scripting engine in the server.</p>\n<ul>\n<li><p><code>module_ctx</code>: the module context object.</p>\n</li>\n<li><p><code>engine_name</code>: the name of the scripting engine. This name will match<br>against the engine name specified in the script header using a shebang.</p>\n</li>\n<li><p><code>engine_ctx</code>: engine specific context pointer.</p>\n</li>\n<li><p><code>engine_methods</code>: the struct with the scripting engine callback functions<br>pointers.</p>\n</li>\n</ul>\n<p>Returns <code>VALKEYMODULE_OK</code> if the engine is successfully registered, and<br><code>VALKEYMODULE_ERR</code> in case some failure occurs. In case of a failure, an error<br>message is logged.</p>\n<p><span id=\"ValkeyModule_UnregisterScriptingEngine\"></span></p>\n<h3><code>ValkeyModule_UnregisterScriptingEngine</code></h3>\n<pre><code>int ValkeyModule_UnregisterScriptingEngine(ValkeyModuleCtx *ctx,\n                                           const char *engine_name);\n</code></pre>\n<p><strong>Available since:</strong> 8.1.0</p>\n<p>Removes the scripting engine from the server.</p>\n<p><code>engine_name</code> is the name of the scripting engine.</p>\n<p>Returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_GetFunctionExecutionState\"></span></p>\n<h3><code>ValkeyModule_GetFunctionExecutionState</code></h3>\n<pre><code>ValkeyModuleScriptingEngineExecutionState ValkeyModule_GetFunctionExecutionState(;\n</code></pre>\n<p><strong>Available since:</strong> 8.1.0</p>\n<p>Returns the state of the current function being executed by the scripting<br>engine.</p>\n<p><code>server_ctx</code> is the server runtime context.</p>\n<p>It will return <code>VMSE_STATE_KILLED</code> if the function was already killed either by<br>a <code>SCRIPT KILL</code>, or <code>FUNCTION KILL</code>.</p>\n<p><span id=\"section-key-eviction-api\"></span></p>\n<h2>Key eviction API</h2>\n<p><span id=\"ValkeyModule_SetLRU\"></span></p>\n<h3><code>ValkeyModule_SetLRU</code></h3>\n<pre><code>int ValkeyModule_SetLRU(ValkeyModuleKey *key, mstime_t lru_idle);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Set the key last access time for LRU based eviction. not relevant if the<br>servers&#39;s maxmemory policy is LFU based. Value is idle time in milliseconds.<br>returns <code>VALKEYMODULE_OK</code> if the LRU was updated, <code>VALKEYMODULE_ERR</code> otherwise.</p>\n<p><span id=\"ValkeyModule_GetLRU\"></span></p>\n<h3><code>ValkeyModule_GetLRU</code></h3>\n<pre><code>int ValkeyModule_GetLRU(ValkeyModuleKey *key, mstime_t *lru_idle);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Gets the key last access time.<br>Value is idletime in milliseconds or -1 if the server&#39;s eviction policy is<br>LFU based.<br>returns <code>VALKEYMODULE_OK</code> if when key is valid.</p>\n<p><span id=\"ValkeyModule_SetLFU\"></span></p>\n<h3><code>ValkeyModule_SetLFU</code></h3>\n<pre><code>int ValkeyModule_SetLFU(ValkeyModuleKey *key, long long lfu_freq);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Set the key access frequency. only relevant if the server&#39;s maxmemory policy<br>is LFU based.<br>The frequency is a logarithmic counter that provides an indication of<br>the access frequencyonly (must be &lt;= 255).<br>returns <code>VALKEYMODULE_OK</code> if the LFU was updated, <code>VALKEYMODULE_ERR</code> otherwise.</p>\n<p><span id=\"ValkeyModule_GetLFU\"></span></p>\n<h3><code>ValkeyModule_GetLFU</code></h3>\n<pre><code>int ValkeyModule_GetLFU(ValkeyModuleKey *key, long long *lfu_freq);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Gets the key access frequency or -1 if the server&#39;s eviction policy is not<br>LFU based.<br>returns <code>VALKEYMODULE_OK</code> if when key is valid.</p>\n<p><span id=\"section-miscellaneous-apis\"></span></p>\n<h2>Miscellaneous APIs</h2>\n<p><span id=\"ValkeyModule_GetModuleOptionsAll\"></span></p>\n<h3><code>ValkeyModule_GetModuleOptionsAll</code></h3>\n<pre><code>int ValkeyModule_GetModuleOptionsAll(void);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Returns the full module options flags mask, using the return value<br>the module can check if a certain set of module options are supported<br>by the server version in use.<br>Example:</p>\n<pre><code>   int supportedFlags = ValkeyModule_GetModuleOptionsAll();\n   if (supportedFlags &amp; VALKEYMODULE_OPTIONS_ALLOW_NESTED_KEYSPACE_NOTIFICATIONS) {\n         // VALKEYMODULE_OPTIONS_ALLOW_NESTED_KEYSPACE_NOTIFICATIONS is supported\n   } else{\n         // VALKEYMODULE_OPTIONS_ALLOW_NESTED_KEYSPACE_NOTIFICATIONS is not supported\n   }\n</code></pre>\n<p><span id=\"ValkeyModule_GetContextFlagsAll\"></span></p>\n<h3><code>ValkeyModule_GetContextFlagsAll</code></h3>\n<pre><code>int ValkeyModule_GetContextFlagsAll(void);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.9</p>\n<p>Returns the full ContextFlags mask, using the return value<br>the module can check if a certain set of flags are supported<br>by the server version in use.<br>Example:</p>\n<pre><code>   int supportedFlags = ValkeyModule_GetContextFlagsAll();\n   if (supportedFlags &amp; VALKEYMODULE_CTX_FLAGS_MULTI) {\n         // VALKEYMODULE_CTX_FLAGS_MULTI is supported\n   } else{\n         // VALKEYMODULE_CTX_FLAGS_MULTI is not supported\n   }\n</code></pre>\n<p><span id=\"ValkeyModule_GetKeyspaceNotificationFlagsAll\"></span></p>\n<h3><code>ValkeyModule_GetKeyspaceNotificationFlagsAll</code></h3>\n<pre><code>int ValkeyModule_GetKeyspaceNotificationFlagsAll(void);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.9</p>\n<p>Returns the full KeyspaceNotification mask, using the return value<br>the module can check if a certain set of flags are supported<br>by the server version in use.<br>Example:</p>\n<pre><code>   int supportedFlags = ValkeyModule_GetKeyspaceNotificationFlagsAll();\n   if (supportedFlags &amp; VALKEYMODULE_NOTIFY_LOADED) {\n         // VALKEYMODULE_NOTIFY_LOADED is supported\n   } else{\n         // VALKEYMODULE_NOTIFY_LOADED is not supported\n   }\n</code></pre>\n<p><span id=\"ValkeyModule_GetServerVersion\"></span></p>\n<h3><code>ValkeyModule_GetServerVersion</code></h3>\n<pre><code>int ValkeyModule_GetServerVersion(void);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.9</p>\n<p>Return the server version in format of 0x00MMmmpp.<br>Example for 6.0.7 the return value will be 0x00060007.</p>\n<p><span id=\"ValkeyModule_GetTypeMethodVersion\"></span></p>\n<h3><code>ValkeyModule_GetTypeMethodVersion</code></h3>\n<pre><code>int ValkeyModule_GetTypeMethodVersion(void);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Return the current server runtime value of <code>VALKEYMODULE_TYPE_METHOD_VERSION</code>.<br>You can use that when calling <a href=\"#ValkeyModule_CreateDataType\"><code>ValkeyModule_CreateDataType</code></a> to know which fields of<br><code>ValkeyModuleTypeMethods</code> are gonna be supported and which will be ignored.</p>\n<p><span id=\"ValkeyModule_ModuleTypeReplaceValue\"></span></p>\n<h3><code>ValkeyModule_ModuleTypeReplaceValue</code></h3>\n<pre><code>int ValkeyModule_ModuleTypeReplaceValue(ValkeyModuleKey *key,\n                                        moduleType *mt,\n                                        void *new_value,\n                                        void **old_value);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Replace the value assigned to a module type.</p>\n<p>The key must be open for writing, have an existing value, and have a moduleType<br>that matches the one specified by the caller.</p>\n<p>Unlike <a href=\"#ValkeyModule_ModuleTypeSetValue\"><code>ValkeyModule_ModuleTypeSetValue()</code></a> which will free the old value, this function<br>simply swaps the old value with the new value.</p>\n<p>The function returns <code>VALKEYMODULE_OK</code> on success, <code>VALKEYMODULE_ERR</code> on errors<br>such as:</p>\n<ol>\n<li>Key is not opened for writing.</li>\n<li>Key is not a module data type key.</li>\n<li>Key is a module datatype other than &#39;mt&#39;.</li>\n</ol>\n<p>If <code>old_value</code> is non-NULL, the old value is returned by reference.</p>\n<p><span id=\"ValkeyModule_GetCommandKeysWithFlags\"></span></p>\n<h3><code>ValkeyModule_GetCommandKeysWithFlags</code></h3>\n<pre><code>int *ValkeyModule_GetCommandKeysWithFlags(ValkeyModuleCtx *ctx,\n                                          ValkeyModuleString **argv,\n                                          int argc,\n                                          int *num_keys,\n                                          int **out_flags);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>For a specified command, parse its arguments and return an array that<br>contains the indexes of all key name arguments. This function is<br>essentially a more efficient way to do <code>COMMAND GETKEYS</code>.</p>\n<p>The <code>out_flags</code> argument is optional, and can be set to NULL.<br>When provided it is filled with <code>VALKEYMODULE_CMD_KEY_</code> flags in matching<br>indexes with the key indexes of the returned array.</p>\n<p>A NULL return value indicates the specified command has no keys, or<br>an error condition. Error conditions are indicated by setting errno<br>as follows:</p>\n<ul>\n<li>ENOENT: Specified command does not exist.</li>\n<li>EINVAL: Invalid command arity specified.</li>\n</ul>\n<p>NOTE: The returned array is not a Module object so it does not<br>get automatically freed even when auto-memory is used. The caller<br>must explicitly call <a href=\"#ValkeyModule_Free\"><code>ValkeyModule_Free()</code></a> to free it, same as the <code>out_flags</code> pointer if<br>used.</p>\n<p><span id=\"ValkeyModule_GetCommandKeys\"></span></p>\n<h3><code>ValkeyModule_GetCommandKeys</code></h3>\n<pre><code>int *ValkeyModule_GetCommandKeys(ValkeyModuleCtx *ctx,\n                                 ValkeyModuleString **argv,\n                                 int argc,\n                                 int *num_keys);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.9</p>\n<p>Identical to <a href=\"#ValkeyModule_GetCommandKeysWithFlags\"><code>ValkeyModule_GetCommandKeysWithFlags</code></a> when flags are not needed.</p>\n<p><span id=\"ValkeyModule_GetCurrentCommandName\"></span></p>\n<h3><code>ValkeyModule_GetCurrentCommandName</code></h3>\n<pre><code>const char *ValkeyModule_GetCurrentCommandName(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.5</p>\n<p>Return the name of the command currently running</p>\n<p><span id=\"section-defrag-api\"></span></p>\n<h2>Defrag API</h2>\n<p><span id=\"ValkeyModule_RegisterDefragFunc\"></span></p>\n<h3><code>ValkeyModule_RegisterDefragFunc</code></h3>\n<pre><code>int ValkeyModule_RegisterDefragFunc(ValkeyModuleCtx *ctx,\n                                    ValkeyModuleDefragFunc cb);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Register a defrag callback for global data, i.e. anything that the module<br>may allocate that is not tied to a specific data type.</p>\n<p><span id=\"ValkeyModule_DefragShouldStop\"></span></p>\n<h3><code>ValkeyModule_DefragShouldStop</code></h3>\n<pre><code>int ValkeyModule_DefragShouldStop(ValkeyModuleDefragCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>When the data type defrag callback iterates complex structures, this<br>function should be called periodically. A zero (false) return<br>indicates the callback may continue its work. A non-zero value (true)<br>indicates it should stop.</p>\n<p>When stopped, the callback may use <a href=\"#ValkeyModule_DefragCursorSet\"><code>ValkeyModule_DefragCursorSet()</code></a> to store its<br>position so it can later use <a href=\"#ValkeyModule_DefragCursorGet\"><code>ValkeyModule_DefragCursorGet()</code></a> to resume defragging.</p>\n<p>When stopped and more work is left to be done, the callback should<br>return 1. Otherwise, it should return 0.</p>\n<p>NOTE: Modules should consider the frequency in which this function is called,<br>so it generally makes sense to do small batches of work in between calls.</p>\n<p><span id=\"ValkeyModule_DefragCursorSet\"></span></p>\n<h3><code>ValkeyModule_DefragCursorSet</code></h3>\n<pre><code>int ValkeyModule_DefragCursorSet(ValkeyModuleDefragCtx *ctx,\n                                 unsigned long cursor);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Store an arbitrary cursor value for future re-use.</p>\n<p>This should only be called if <a href=\"#ValkeyModule_DefragShouldStop\"><code>ValkeyModule_DefragShouldStop()</code></a> has returned a non-zero<br>value and the defrag callback is about to exit without fully iterating its<br>data type.</p>\n<p>This behavior is reserved to cases where late defrag is performed. Late<br>defrag is selected for keys that implement the <code>free_effort</code> callback and<br>return a <code>free_effort</code> value that is larger than the defrag<br>&#39;active-defrag-max-scan-fields&#39; configuration directive.</p>\n<p>Smaller keys, keys that do not implement <code>free_effort</code> or the global<br>defrag callback are not called in late-defrag mode. In those cases, a<br>call to this function will return <code>VALKEYMODULE_ERR</code>.</p>\n<p>The cursor may be used by the module to represent some progress into the<br>module&#39;s data type. Modules may also store additional cursor-related<br>information locally and use the cursor as a flag that indicates when<br>traversal of a new key begins. This is possible because the API makes<br>a guarantee that concurrent defragmentation of multiple keys will<br>not be performed.</p>\n<p><span id=\"ValkeyModule_DefragCursorGet\"></span></p>\n<h3><code>ValkeyModule_DefragCursorGet</code></h3>\n<pre><code>int ValkeyModule_DefragCursorGet(ValkeyModuleDefragCtx *ctx,\n                                 unsigned long *cursor);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Fetch a cursor value that has been previously stored using <a href=\"#ValkeyModule_DefragCursorSet\"><code>ValkeyModule_DefragCursorSet()</code></a>.</p>\n<p>If not called for a late defrag operation, <code>VALKEYMODULE_ERR</code> will be returned and<br>the cursor should be ignored. See <a href=\"#ValkeyModule_DefragCursorSet\"><code>ValkeyModule_DefragCursorSet()</code></a> for more details on<br>defrag cursors.</p>\n<p><span id=\"ValkeyModule_DefragAlloc\"></span></p>\n<h3><code>ValkeyModule_DefragAlloc</code></h3>\n<pre><code>void *ValkeyModule_DefragAlloc(ValkeyModuleDefragCtx *ctx, void *ptr);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Defrag a memory allocation previously allocated by <a href=\"#ValkeyModule_Alloc\"><code>ValkeyModule_Alloc</code></a>, <a href=\"#ValkeyModule_Calloc\"><code>ValkeyModule_Calloc</code></a>, etc.<br>The defragmentation process involves allocating a new memory block and copying<br>the contents to it, like <code>realloc()</code>.</p>\n<p>If defragmentation was not necessary, NULL is returned and the operation has<br>no other effect.</p>\n<p>If a non-NULL value is returned, the caller should use the new pointer instead<br>of the old one and update any reference to the old pointer, which must not<br>be used again.</p>\n<p><span id=\"ValkeyModule_DefragValkeyModuleString\"></span></p>\n<h3><code>ValkeyModule_DefragValkeyModuleString</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_DefragValkeyModuleString(ValkeyModuleDefragCtx *ctx,\n                                                          ValkeyModuleString *str);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.5</p>\n<p>Defrag a <code>ValkeyModuleString</code> previously allocated by <a href=\"#ValkeyModule_Alloc\"><code>ValkeyModule_Alloc</code></a>, <a href=\"#ValkeyModule_Calloc\"><code>ValkeyModule_Calloc</code></a>, etc.<br>See <a href=\"#ValkeyModule_DefragAlloc\"><code>ValkeyModule_DefragAlloc()</code></a> for more information on how the defragmentation process<br>works.</p>\n<p>NOTE: It is only possible to defrag strings that have a single reference.<br>Typically this means strings retained with <a href=\"#ValkeyModule_RetainString\"><code>ValkeyModule_RetainString</code></a> or <a href=\"#ValkeyModule_HoldString\"><code>ValkeyModule_HoldString</code></a><br>may not be defragmentable. One exception is command argvs which, if retained<br>by the module, will end up with a single reference (because the reference<br>on the server side is dropped as soon as the command callback returns).</p>\n<p><span id=\"ValkeyModule_GetKeyNameFromDefragCtx\"></span></p>\n<h3><code>ValkeyModule_GetKeyNameFromDefragCtx</code></h3>\n<pre><code>const ValkeyModuleString *ValkeyModule_GetKeyNameFromDefragCtx(ValkeyModuleDefragCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Returns the name of the key currently being processed.<br>There is no guarantee that the key name is always available, so this may return NULL.</p>\n<p><span id=\"ValkeyModule_GetDbIdFromDefragCtx\"></span></p>\n<h3><code>ValkeyModule_GetDbIdFromDefragCtx</code></h3>\n<pre><code>int ValkeyModule_GetDbIdFromDefragCtx(ValkeyModuleDefragCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Returns the database id of the key currently being processed.<br>There is no guarantee that this info is always available, so this may return -1.</p>\n<p><span id=\"section-function-index\"></span></p>\n<h2>Function index</h2>\n<ul>\n<li><a href=\"#ValkeyModule_ACLAddLogEntry\"><code>ValkeyModule_ACLAddLogEntry</code></a></li>\n<li><a href=\"#ValkeyModule_ACLAddLogEntryByUserName\"><code>ValkeyModule_ACLAddLogEntryByUserName</code></a></li>\n<li><a href=\"#ValkeyModule_ACLCheckChannelPermissions\"><code>ValkeyModule_ACLCheckChannelPermissions</code></a></li>\n<li><a href=\"#ValkeyModule_ACLCheckCommandPermissions\"><code>ValkeyModule_ACLCheckCommandPermissions</code></a></li>\n<li><a href=\"#ValkeyModule_ACLCheckKeyPermissions\"><code>ValkeyModule_ACLCheckKeyPermissions</code></a></li>\n<li><a href=\"#ValkeyModule_AbortBlock\"><code>ValkeyModule_AbortBlock</code></a></li>\n<li><a href=\"#ValkeyModule_AddACLCategory\"><code>ValkeyModule_AddACLCategory</code></a></li>\n<li><a href=\"#ValkeyModule_AddPostNotificationJob\"><code>ValkeyModule_AddPostNotificationJob</code></a></li>\n<li><a href=\"#ValkeyModule_Alloc\"><code>ValkeyModule_Alloc</code></a></li>\n<li><a href=\"#ValkeyModule_AuthenticateClientWithACLUser\"><code>ValkeyModule_AuthenticateClientWithACLUser</code></a></li>\n<li><a href=\"#ValkeyModule_AuthenticateClientWithUser\"><code>ValkeyModule_AuthenticateClientWithUser</code></a></li>\n<li><a href=\"#ValkeyModule_AutoMemory\"><code>ValkeyModule_AutoMemory</code></a></li>\n<li><a href=\"#ValkeyModule_AvoidReplicaTraffic\"><code>ValkeyModule_AvoidReplicaTraffic</code></a></li>\n<li><a href=\"#ValkeyModule_BlockClient\"><code>ValkeyModule_BlockClient</code></a></li>\n<li><a href=\"#ValkeyModule_BlockClientGetPrivateData\"><code>ValkeyModule_BlockClientGetPrivateData</code></a></li>\n<li><a href=\"#ValkeyModule_BlockClientOnAuth\"><code>ValkeyModule_BlockClientOnAuth</code></a></li>\n<li><a href=\"#ValkeyModule_BlockClientOnKeys\"><code>ValkeyModule_BlockClientOnKeys</code></a></li>\n<li><a href=\"#ValkeyModule_BlockClientOnKeysWithFlags\"><code>ValkeyModule_BlockClientOnKeysWithFlags</code></a></li>\n<li><a href=\"#ValkeyModule_BlockClientSetPrivateData\"><code>ValkeyModule_BlockClientSetPrivateData</code></a></li>\n<li><a href=\"#ValkeyModule_BlockedClientDisconnected\"><code>ValkeyModule_BlockedClientDisconnected</code></a></li>\n<li><a href=\"#ValkeyModule_BlockedClientMeasureTimeEnd\"><code>ValkeyModule_BlockedClientMeasureTimeEnd</code></a></li>\n<li><a href=\"#ValkeyModule_BlockedClientMeasureTimeStart\"><code>ValkeyModule_BlockedClientMeasureTimeStart</code></a></li>\n<li><a href=\"#ValkeyModule_CachedMicroseconds\"><code>ValkeyModule_CachedMicroseconds</code></a></li>\n<li><a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call</code></a></li>\n<li><a href=\"#ValkeyModule_CallReplyArrayElement\"><code>ValkeyModule_CallReplyArrayElement</code></a></li>\n<li><a href=\"#ValkeyModule_CallReplyAttribute\"><code>ValkeyModule_CallReplyAttribute</code></a></li>\n<li><a href=\"#ValkeyModule_CallReplyAttributeElement\"><code>ValkeyModule_CallReplyAttributeElement</code></a></li>\n<li><a href=\"#ValkeyModule_CallReplyBigNumber\"><code>ValkeyModule_CallReplyBigNumber</code></a></li>\n<li><a href=\"#ValkeyModule_CallReplyBool\"><code>ValkeyModule_CallReplyBool</code></a></li>\n<li><a href=\"#ValkeyModule_CallReplyDouble\"><code>ValkeyModule_CallReplyDouble</code></a></li>\n<li><a href=\"#ValkeyModule_CallReplyInteger\"><code>ValkeyModule_CallReplyInteger</code></a></li>\n<li><a href=\"#ValkeyModule_CallReplyLength\"><code>ValkeyModule_CallReplyLength</code></a></li>\n<li><a href=\"#ValkeyModule_CallReplyMapElement\"><code>ValkeyModule_CallReplyMapElement</code></a></li>\n<li><a href=\"#ValkeyModule_CallReplyPromiseAbort\"><code>ValkeyModule_CallReplyPromiseAbort</code></a></li>\n<li><a href=\"#ValkeyModule_CallReplyPromiseSetUnblockHandler\"><code>ValkeyModule_CallReplyPromiseSetUnblockHandler</code></a></li>\n<li><a href=\"#ValkeyModule_CallReplyProto\"><code>ValkeyModule_CallReplyProto</code></a></li>\n<li><a href=\"#ValkeyModule_CallReplySetElement\"><code>ValkeyModule_CallReplySetElement</code></a></li>\n<li><a href=\"#ValkeyModule_CallReplyStringPtr\"><code>ValkeyModule_CallReplyStringPtr</code></a></li>\n<li><a href=\"#ValkeyModule_CallReplyType\"><code>ValkeyModule_CallReplyType</code></a></li>\n<li><a href=\"#ValkeyModule_CallReplyVerbatim\"><code>ValkeyModule_CallReplyVerbatim</code></a></li>\n<li><a href=\"#ValkeyModule_Calloc\"><code>ValkeyModule_Calloc</code></a></li>\n<li><a href=\"#ValkeyModule_ChannelAtPosWithFlags\"><code>ValkeyModule_ChannelAtPosWithFlags</code></a></li>\n<li><a href=\"#ValkeyModule_CloseKey\"><code>ValkeyModule_CloseKey</code></a></li>\n<li><a href=\"#ValkeyModule_ClusterCanonicalKeyNameInSlot\"><code>ValkeyModule_ClusterCanonicalKeyNameInSlot</code></a></li>\n<li><a href=\"#ValkeyModule_ClusterKeySlot\"><code>ValkeyModule_ClusterKeySlot</code></a></li>\n<li><a href=\"#ValkeyModule_CommandFilterArgDelete\"><code>ValkeyModule_CommandFilterArgDelete</code></a></li>\n<li><a href=\"#ValkeyModule_CommandFilterArgGet\"><code>ValkeyModule_CommandFilterArgGet</code></a></li>\n<li><a href=\"#ValkeyModule_CommandFilterArgInsert\"><code>ValkeyModule_CommandFilterArgInsert</code></a></li>\n<li><a href=\"#ValkeyModule_CommandFilterArgReplace\"><code>ValkeyModule_CommandFilterArgReplace</code></a></li>\n<li><a href=\"#ValkeyModule_CommandFilterArgsCount\"><code>ValkeyModule_CommandFilterArgsCount</code></a></li>\n<li><a href=\"#ValkeyModule_CommandFilterGetClientId\"><code>ValkeyModule_CommandFilterGetClientId</code></a></li>\n<li><a href=\"#ValkeyModule_CreateCommand\"><code>ValkeyModule_CreateCommand</code></a></li>\n<li><a href=\"#ValkeyModule_CreateDataType\"><code>ValkeyModule_CreateDataType</code></a></li>\n<li><a href=\"#ValkeyModule_CreateDict\"><code>ValkeyModule_CreateDict</code></a></li>\n<li><a href=\"#ValkeyModule_CreateModuleUser\"><code>ValkeyModule_CreateModuleUser</code></a></li>\n<li><a href=\"#ValkeyModule_CreateString\"><code>ValkeyModule_CreateString</code></a></li>\n<li><a href=\"#ValkeyModule_CreateStringFromCallReply\"><code>ValkeyModule_CreateStringFromCallReply</code></a></li>\n<li><a href=\"#ValkeyModule_CreateStringFromDouble\"><code>ValkeyModule_CreateStringFromDouble</code></a></li>\n<li><a href=\"#ValkeyModule_CreateStringFromLongDouble\"><code>ValkeyModule_CreateStringFromLongDouble</code></a></li>\n<li><a href=\"#ValkeyModule_CreateStringFromLongLong\"><code>ValkeyModule_CreateStringFromLongLong</code></a></li>\n<li><a href=\"#ValkeyModule_CreateStringFromStreamID\"><code>ValkeyModule_CreateStringFromStreamID</code></a></li>\n<li><a href=\"#ValkeyModule_CreateStringFromString\"><code>ValkeyModule_CreateStringFromString</code></a></li>\n<li><a href=\"#ValkeyModule_CreateStringFromULongLong\"><code>ValkeyModule_CreateStringFromULongLong</code></a></li>\n<li><a href=\"#ValkeyModule_CreateStringPrintf\"><code>ValkeyModule_CreateStringPrintf</code></a></li>\n<li><a href=\"#ValkeyModule_CreateSubcommand\"><code>ValkeyModule_CreateSubcommand</code></a></li>\n<li><a href=\"#ValkeyModule_CreateTimer\"><code>ValkeyModule_CreateTimer</code></a></li>\n<li><a href=\"#ValkeyModule_DbSize\"><code>ValkeyModule_DbSize</code></a></li>\n<li><a href=\"#ValkeyModule_DeauthenticateAndCloseClient\"><code>ValkeyModule_DeauthenticateAndCloseClient</code></a></li>\n<li><a href=\"#ValkeyModule_DefragAlloc\"><code>ValkeyModule_DefragAlloc</code></a></li>\n<li><a href=\"#ValkeyModule_DefragCursorGet\"><code>ValkeyModule_DefragCursorGet</code></a></li>\n<li><a href=\"#ValkeyModule_DefragCursorSet\"><code>ValkeyModule_DefragCursorSet</code></a></li>\n<li><a href=\"#ValkeyModule_DefragShouldStop\"><code>ValkeyModule_DefragShouldStop</code></a></li>\n<li><a href=\"#ValkeyModule_DefragValkeyModuleString\"><code>ValkeyModule_DefragValkeyModuleString</code></a></li>\n<li><a href=\"#ValkeyModule_DeleteKey\"><code>ValkeyModule_DeleteKey</code></a></li>\n<li><a href=\"#ValkeyModule_DictCompare\"><code>ValkeyModule_DictCompare</code></a></li>\n<li><a href=\"#ValkeyModule_DictCompareC\"><code>ValkeyModule_DictCompareC</code></a></li>\n<li><a href=\"#ValkeyModule_DictDel\"><code>ValkeyModule_DictDel</code></a></li>\n<li><a href=\"#ValkeyModule_DictDelC\"><code>ValkeyModule_DictDelC</code></a></li>\n<li><a href=\"#ValkeyModule_DictGet\"><code>ValkeyModule_DictGet</code></a></li>\n<li><a href=\"#ValkeyModule_DictGetC\"><code>ValkeyModule_DictGetC</code></a></li>\n<li><a href=\"#ValkeyModule_DictIteratorReseek\"><code>ValkeyModule_DictIteratorReseek</code></a></li>\n<li><a href=\"#ValkeyModule_DictIteratorReseekC\"><code>ValkeyModule_DictIteratorReseekC</code></a></li>\n<li><a href=\"#ValkeyModule_DictIteratorStart\"><code>ValkeyModule_DictIteratorStart</code></a></li>\n<li><a href=\"#ValkeyModule_DictIteratorStartC\"><code>ValkeyModule_DictIteratorStartC</code></a></li>\n<li><a href=\"#ValkeyModule_DictIteratorStop\"><code>ValkeyModule_DictIteratorStop</code></a></li>\n<li><a href=\"#ValkeyModule_DictNext\"><code>ValkeyModule_DictNext</code></a></li>\n<li><a href=\"#ValkeyModule_DictNextC\"><code>ValkeyModule_DictNextC</code></a></li>\n<li><a href=\"#ValkeyModule_DictPrev\"><code>ValkeyModule_DictPrev</code></a></li>\n<li><a href=\"#ValkeyModule_DictPrevC\"><code>ValkeyModule_DictPrevC</code></a></li>\n<li><a href=\"#ValkeyModule_DictReplace\"><code>ValkeyModule_DictReplace</code></a></li>\n<li><a href=\"#ValkeyModule_DictReplaceC\"><code>ValkeyModule_DictReplaceC</code></a></li>\n<li><a href=\"#ValkeyModule_DictSet\"><code>ValkeyModule_DictSet</code></a></li>\n<li><a href=\"#ValkeyModule_DictSetC\"><code>ValkeyModule_DictSetC</code></a></li>\n<li><a href=\"#ValkeyModule_DictSize\"><code>ValkeyModule_DictSize</code></a></li>\n<li><a href=\"#ValkeyModule_DigestAddLongLong\"><code>ValkeyModule_DigestAddLongLong</code></a></li>\n<li><a href=\"#ValkeyModule_DigestAddStringBuffer\"><code>ValkeyModule_DigestAddStringBuffer</code></a></li>\n<li><a href=\"#ValkeyModule_DigestEndSequence\"><code>ValkeyModule_DigestEndSequence</code></a></li>\n<li><a href=\"#ValkeyModule_EmitAOF\"><code>ValkeyModule_EmitAOF</code></a></li>\n<li><a href=\"#ValkeyModule_EventLoopAdd\"><code>ValkeyModule_EventLoopAdd</code></a></li>\n<li><a href=\"#ValkeyModule_EventLoopAddOneShot\"><code>ValkeyModule_EventLoopAddOneShot</code></a></li>\n<li><a href=\"#ValkeyModule_EventLoopDel\"><code>ValkeyModule_EventLoopDel</code></a></li>\n<li><a href=\"#ValkeyModule_ExitFromChild\"><code>ValkeyModule_ExitFromChild</code></a></li>\n<li><a href=\"#ValkeyModule_ExportSharedAPI\"><code>ValkeyModule_ExportSharedAPI</code></a></li>\n<li><a href=\"#ValkeyModule_Fork\"><code>ValkeyModule_Fork</code></a></li>\n<li><a href=\"#ValkeyModule_Free\"><code>ValkeyModule_Free</code></a></li>\n<li><a href=\"#ValkeyModule_FreeCallReply\"><code>ValkeyModule_FreeCallReply</code></a></li>\n<li><a href=\"#ValkeyModule_FreeClusterNodesList\"><code>ValkeyModule_FreeClusterNodesList</code></a></li>\n<li><a href=\"#ValkeyModule_FreeDict\"><code>ValkeyModule_FreeDict</code></a></li>\n<li><a href=\"#ValkeyModule_FreeModuleUser\"><code>ValkeyModule_FreeModuleUser</code></a></li>\n<li><a href=\"#ValkeyModule_FreeServerInfo\"><code>ValkeyModule_FreeServerInfo</code></a></li>\n<li><a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString</code></a></li>\n<li><a href=\"#ValkeyModule_FreeThreadSafeContext\"><code>ValkeyModule_FreeThreadSafeContext</code></a></li>\n<li><a href=\"#ValkeyModule_GetAbsExpire\"><code>ValkeyModule_GetAbsExpire</code></a></li>\n<li><a href=\"#ValkeyModule_GetBlockedClientHandle\"><code>ValkeyModule_GetBlockedClientHandle</code></a></li>\n<li><a href=\"#ValkeyModule_GetBlockedClientPrivateData\"><code>ValkeyModule_GetBlockedClientPrivateData</code></a></li>\n<li><a href=\"#ValkeyModule_GetBlockedClientReadyKey\"><code>ValkeyModule_GetBlockedClientReadyKey</code></a></li>\n<li><a href=\"#ValkeyModule_GetClientCertificate\"><code>ValkeyModule_GetClientCertificate</code></a></li>\n<li><a href=\"#ValkeyModule_GetClientId\"><code>ValkeyModule_GetClientId</code></a></li>\n<li><a href=\"#ValkeyModule_GetClientInfoById\"><code>ValkeyModule_GetClientInfoById</code></a></li>\n<li><a href=\"#ValkeyModule_GetClientNameById\"><code>ValkeyModule_GetClientNameById</code></a></li>\n<li><a href=\"#ValkeyModule_GetClientUserNameById\"><code>ValkeyModule_GetClientUserNameById</code></a></li>\n<li><a href=\"#ValkeyModule_GetClusterNodeInfo\"><code>ValkeyModule_GetClusterNodeInfo</code></a></li>\n<li><a href=\"#ValkeyModule_GetClusterNodeInfoForClient\"><code>ValkeyModule_GetClusterNodeInfoForClient</code></a></li>\n<li><a href=\"#ValkeyModule_GetClusterNodesList\"><code>ValkeyModule_GetClusterNodesList</code></a></li>\n<li><a href=\"#ValkeyModule_GetClusterSize\"><code>ValkeyModule_GetClusterSize</code></a></li>\n<li><a href=\"#ValkeyModule_GetCommand\"><code>ValkeyModule_GetCommand</code></a></li>\n<li><a href=\"#ValkeyModule_GetCommandKeys\"><code>ValkeyModule_GetCommandKeys</code></a></li>\n<li><a href=\"#ValkeyModule_GetCommandKeysWithFlags\"><code>ValkeyModule_GetCommandKeysWithFlags</code></a></li>\n<li><a href=\"#ValkeyModule_GetContextFlags\"><code>ValkeyModule_GetContextFlags</code></a></li>\n<li><a href=\"#ValkeyModule_GetContextFlagsAll\"><code>ValkeyModule_GetContextFlagsAll</code></a></li>\n<li><a href=\"#ValkeyModule_GetCurrentCommandName\"><code>ValkeyModule_GetCurrentCommandName</code></a></li>\n<li><a href=\"#ValkeyModule_GetCurrentUserName\"><code>ValkeyModule_GetCurrentUserName</code></a></li>\n<li><a href=\"#ValkeyModule_GetDbIdFromDefragCtx\"><code>ValkeyModule_GetDbIdFromDefragCtx</code></a></li>\n<li><a href=\"#ValkeyModule_GetDbIdFromDigest\"><code>ValkeyModule_GetDbIdFromDigest</code></a></li>\n<li><a href=\"#ValkeyModule_GetDbIdFromIO\"><code>ValkeyModule_GetDbIdFromIO</code></a></li>\n<li><a href=\"#ValkeyModule_GetDbIdFromModuleKey\"><code>ValkeyModule_GetDbIdFromModuleKey</code></a></li>\n<li><a href=\"#ValkeyModule_GetDbIdFromOptCtx\"><code>ValkeyModule_GetDbIdFromOptCtx</code></a></li>\n<li><a href=\"#ValkeyModule_GetDetachedThreadSafeContext\"><code>ValkeyModule_GetDetachedThreadSafeContext</code></a></li>\n<li><a href=\"#ValkeyModule_GetExpire\"><code>ValkeyModule_GetExpire</code></a></li>\n<li><a href=\"#ValkeyModule_GetFunctionExecutionState\"><code>ValkeyModule_GetFunctionExecutionState</code></a></li>\n<li><a href=\"#ValkeyModule_GetKeyNameFromDefragCtx\"><code>ValkeyModule_GetKeyNameFromDefragCtx</code></a></li>\n<li><a href=\"#ValkeyModule_GetKeyNameFromDigest\"><code>ValkeyModule_GetKeyNameFromDigest</code></a></li>\n<li><a href=\"#ValkeyModule_GetKeyNameFromIO\"><code>ValkeyModule_GetKeyNameFromIO</code></a></li>\n<li><a href=\"#ValkeyModule_GetKeyNameFromModuleKey\"><code>ValkeyModule_GetKeyNameFromModuleKey</code></a></li>\n<li><a href=\"#ValkeyModule_GetKeyNameFromOptCtx\"><code>ValkeyModule_GetKeyNameFromOptCtx</code></a></li>\n<li><a href=\"#ValkeyModule_GetKeyspaceNotificationFlagsAll\"><code>ValkeyModule_GetKeyspaceNotificationFlagsAll</code></a></li>\n<li><a href=\"#ValkeyModule_GetLFU\"><code>ValkeyModule_GetLFU</code></a></li>\n<li><a href=\"#ValkeyModule_GetLRU\"><code>ValkeyModule_GetLRU</code></a></li>\n<li><a href=\"#ValkeyModule_GetModuleOptionsAll\"><code>ValkeyModule_GetModuleOptionsAll</code></a></li>\n<li><a href=\"#ValkeyModule_GetModuleUserACLString\"><code>ValkeyModule_GetModuleUserACLString</code></a></li>\n<li><a href=\"#ValkeyModule_GetModuleUserFromUserName\"><code>ValkeyModule_GetModuleUserFromUserName</code></a></li>\n<li><a href=\"#ValkeyModule_GetMyClusterID\"><code>ValkeyModule_GetMyClusterID</code></a></li>\n<li><a href=\"#ValkeyModule_GetNotifyKeyspaceEvents\"><code>ValkeyModule_GetNotifyKeyspaceEvents</code></a></li>\n<li><a href=\"#ValkeyModule_GetOpenKeyModesAll\"><code>ValkeyModule_GetOpenKeyModesAll</code></a></li>\n<li><a href=\"#ValkeyModule_GetRandomBytes\"><code>ValkeyModule_GetRandomBytes</code></a></li>\n<li><a href=\"#ValkeyModule_GetRandomHexChars\"><code>ValkeyModule_GetRandomHexChars</code></a></li>\n<li><a href=\"#ValkeyModule_GetSelectedDb\"><code>ValkeyModule_GetSelectedDb</code></a></li>\n<li><a href=\"#ValkeyModule_GetServerInfo\"><code>ValkeyModule_GetServerInfo</code></a></li>\n<li><a href=\"#ValkeyModule_GetServerVersion\"><code>ValkeyModule_GetServerVersion</code></a></li>\n<li><a href=\"#ValkeyModule_GetSharedAPI\"><code>ValkeyModule_GetSharedAPI</code></a></li>\n<li><a href=\"#ValkeyModule_GetThreadSafeContext\"><code>ValkeyModule_GetThreadSafeContext</code></a></li>\n<li><a href=\"#ValkeyModule_GetTimerInfo\"><code>ValkeyModule_GetTimerInfo</code></a></li>\n<li><a href=\"#ValkeyModule_GetToDbIdFromOptCtx\"><code>ValkeyModule_GetToDbIdFromOptCtx</code></a></li>\n<li><a href=\"#ValkeyModule_GetToKeyNameFromOptCtx\"><code>ValkeyModule_GetToKeyNameFromOptCtx</code></a></li>\n<li><a href=\"#ValkeyModule_GetTypeMethodVersion\"><code>ValkeyModule_GetTypeMethodVersion</code></a></li>\n<li><a href=\"#ValkeyModule_GetUsedMemoryRatio\"><code>ValkeyModule_GetUsedMemoryRatio</code></a></li>\n<li><a href=\"#ValkeyModule_HashGet\"><code>ValkeyModule_HashGet</code></a></li>\n<li><a href=\"#ValkeyModule_HashSet\"><code>ValkeyModule_HashSet</code></a></li>\n<li><a href=\"#ValkeyModule_HoldString\"><code>ValkeyModule_HoldString</code></a></li>\n<li><a href=\"#ValkeyModule_InfoAddFieldCString\"><code>ValkeyModule_InfoAddFieldCString</code></a></li>\n<li><a href=\"#ValkeyModule_InfoAddFieldDouble\"><code>ValkeyModule_InfoAddFieldDouble</code></a></li>\n<li><a href=\"#ValkeyModule_InfoAddFieldLongLong\"><code>ValkeyModule_InfoAddFieldLongLong</code></a></li>\n<li><a href=\"#ValkeyModule_InfoAddFieldString\"><code>ValkeyModule_InfoAddFieldString</code></a></li>\n<li><a href=\"#ValkeyModule_InfoAddFieldULongLong\"><code>ValkeyModule_InfoAddFieldULongLong</code></a></li>\n<li><a href=\"#ValkeyModule_InfoAddSection\"><code>ValkeyModule_InfoAddSection</code></a></li>\n<li><a href=\"#ValkeyModule_InfoBeginDictField\"><code>ValkeyModule_InfoBeginDictField</code></a></li>\n<li><a href=\"#ValkeyModule_InfoEndDictField\"><code>ValkeyModule_InfoEndDictField</code></a></li>\n<li><a href=\"#ValkeyModule_IsBlockedReplyRequest\"><code>ValkeyModule_IsBlockedReplyRequest</code></a></li>\n<li><a href=\"#ValkeyModule_IsBlockedTimeoutRequest\"><code>ValkeyModule_IsBlockedTimeoutRequest</code></a></li>\n<li><a href=\"#ValkeyModule_IsChannelsPositionRequest\"><code>ValkeyModule_IsChannelsPositionRequest</code></a></li>\n<li><a href=\"#ValkeyModule_IsIOError\"><code>ValkeyModule_IsIOError</code></a></li>\n<li><a href=\"#ValkeyModule_IsKeysPositionRequest\"><code>ValkeyModule_IsKeysPositionRequest</code></a></li>\n<li><a href=\"#ValkeyModule_IsModuleNameBusy\"><code>ValkeyModule_IsModuleNameBusy</code></a></li>\n<li><a href=\"#ValkeyModule_IsSubEventSupported\"><code>ValkeyModule_IsSubEventSupported</code></a></li>\n<li><a href=\"#ValkeyModule_KeyAtPos\"><code>ValkeyModule_KeyAtPos</code></a></li>\n<li><a href=\"#ValkeyModule_KeyAtPosWithFlags\"><code>ValkeyModule_KeyAtPosWithFlags</code></a></li>\n<li><a href=\"#ValkeyModule_KeyExists\"><code>ValkeyModule_KeyExists</code></a></li>\n<li><a href=\"#ValkeyModule_KeyType\"><code>ValkeyModule_KeyType</code></a></li>\n<li><a href=\"#ValkeyModule_KillForkChild\"><code>ValkeyModule_KillForkChild</code></a></li>\n<li><a href=\"#ValkeyModule_LatencyAddSample\"><code>ValkeyModule_LatencyAddSample</code></a></li>\n<li><a href=\"#ValkeyModule_ListDelete\"><code>ValkeyModule_ListDelete</code></a></li>\n<li><a href=\"#ValkeyModule_ListGet\"><code>ValkeyModule_ListGet</code></a></li>\n<li><a href=\"#ValkeyModule_ListInsert\"><code>ValkeyModule_ListInsert</code></a></li>\n<li><a href=\"#ValkeyModule_ListPop\"><code>ValkeyModule_ListPop</code></a></li>\n<li><a href=\"#ValkeyModule_ListPush\"><code>ValkeyModule_ListPush</code></a></li>\n<li><a href=\"#ValkeyModule_ListSet\"><code>ValkeyModule_ListSet</code></a></li>\n<li><a href=\"#ValkeyModule_LoadConfigs\"><code>ValkeyModule_LoadConfigs</code></a></li>\n<li><a href=\"#ValkeyModule_LoadDataTypeFromString\"><code>ValkeyModule_LoadDataTypeFromString</code></a></li>\n<li><a href=\"#ValkeyModule_LoadDataTypeFromStringEncver\"><code>ValkeyModule_LoadDataTypeFromStringEncver</code></a></li>\n<li><a href=\"#ValkeyModule_LoadDouble\"><code>ValkeyModule_LoadDouble</code></a></li>\n<li><a href=\"#ValkeyModule_LoadFloat\"><code>ValkeyModule_LoadFloat</code></a></li>\n<li><a href=\"#ValkeyModule_LoadLongDouble\"><code>ValkeyModule_LoadLongDouble</code></a></li>\n<li><a href=\"#ValkeyModule_LoadSigned\"><code>ValkeyModule_LoadSigned</code></a></li>\n<li><a href=\"#ValkeyModule_LoadString\"><code>ValkeyModule_LoadString</code></a></li>\n<li><a href=\"#ValkeyModule_LoadStringBuffer\"><code>ValkeyModule_LoadStringBuffer</code></a></li>\n<li><a href=\"#ValkeyModule_LoadUnsigned\"><code>ValkeyModule_LoadUnsigned</code></a></li>\n<li><a href=\"#ValkeyModule_Log\"><code>ValkeyModule_Log</code></a></li>\n<li><a href=\"#ValkeyModule_LogIOError\"><code>ValkeyModule_LogIOError</code></a></li>\n<li><a href=\"#ValkeyModule_MallocSize\"><code>ValkeyModule_MallocSize</code></a></li>\n<li><a href=\"#ValkeyModule_MallocSizeDict\"><code>ValkeyModule_MallocSizeDict</code></a></li>\n<li><a href=\"#ValkeyModule_MallocSizeString\"><code>ValkeyModule_MallocSizeString</code></a></li>\n<li><a href=\"#ValkeyModule_MallocUsableSize\"><code>ValkeyModule_MallocUsableSize</code></a></li>\n<li><a href=\"#ValkeyModule_Microseconds\"><code>ValkeyModule_Microseconds</code></a></li>\n<li><a href=\"#ValkeyModule_Milliseconds\"><code>ValkeyModule_Milliseconds</code></a></li>\n<li><a href=\"#ValkeyModule_ModuleTypeGetType\"><code>ValkeyModule_ModuleTypeGetType</code></a></li>\n<li><a href=\"#ValkeyModule_ModuleTypeGetValue\"><code>ValkeyModule_ModuleTypeGetValue</code></a></li>\n<li><a href=\"#ValkeyModule_ModuleTypeReplaceValue\"><code>ValkeyModule_ModuleTypeReplaceValue</code></a></li>\n<li><a href=\"#ValkeyModule_ModuleTypeSetValue\"><code>ValkeyModule_ModuleTypeSetValue</code></a></li>\n<li><a href=\"#ValkeyModule_MonotonicMicroseconds\"><code>ValkeyModule_MonotonicMicroseconds</code></a></li>\n<li><a href=\"#ValkeyModule_MustObeyClient\"><code>ValkeyModule_MustObeyClient</code></a></li>\n<li><a href=\"#ValkeyModule_NotifyKeyspaceEvent\"><code>ValkeyModule_NotifyKeyspaceEvent</code></a></li>\n<li><a href=\"#ValkeyModule_OpenKey\"><code>ValkeyModule_OpenKey</code></a></li>\n<li><a href=\"#ValkeyModule_PoolAlloc\"><code>ValkeyModule_PoolAlloc</code></a></li>\n<li><a href=\"#ValkeyModule_PublishMessage\"><code>ValkeyModule_PublishMessage</code></a></li>\n<li><a href=\"#ValkeyModule_PublishMessageShard\"><code>ValkeyModule_PublishMessageShard</code></a></li>\n<li><a href=\"#ValkeyModule_RandomKey\"><code>ValkeyModule_RandomKey</code></a></li>\n<li><a href=\"#ValkeyModule_RdbLoad\"><code>ValkeyModule_RdbLoad</code></a></li>\n<li><a href=\"#ValkeyModule_RdbSave\"><code>ValkeyModule_RdbSave</code></a></li>\n<li><a href=\"#ValkeyModule_RdbStreamCreateFromFile\"><code>ValkeyModule_RdbStreamCreateFromFile</code></a></li>\n<li><a href=\"#ValkeyModule_RdbStreamFree\"><code>ValkeyModule_RdbStreamFree</code></a></li>\n<li><a href=\"#ValkeyModule_Realloc\"><code>ValkeyModule_Realloc</code></a></li>\n<li><a href=\"#ValkeyModule_RedactClientCommandArgument\"><code>ValkeyModule_RedactClientCommandArgument</code></a></li>\n<li><a href=\"#ValkeyModule_RegisterAuthCallback\"><code>ValkeyModule_RegisterAuthCallback</code></a></li>\n<li><a href=\"#ValkeyModule_RegisterBoolConfig\"><code>ValkeyModule_RegisterBoolConfig</code></a></li>\n<li><a href=\"#ValkeyModule_RegisterClusterMessageReceiver\"><code>ValkeyModule_RegisterClusterMessageReceiver</code></a></li>\n<li><a href=\"#ValkeyModule_RegisterCommandFilter\"><code>ValkeyModule_RegisterCommandFilter</code></a></li>\n<li><a href=\"#ValkeyModule_RegisterDefragFunc\"><code>ValkeyModule_RegisterDefragFunc</code></a></li>\n<li><a href=\"#ValkeyModule_RegisterEnumConfig\"><code>ValkeyModule_RegisterEnumConfig</code></a></li>\n<li><a href=\"#ValkeyModule_RegisterInfoFunc\"><code>ValkeyModule_RegisterInfoFunc</code></a></li>\n<li><a href=\"#ValkeyModule_RegisterNumericConfig\"><code>ValkeyModule_RegisterNumericConfig</code></a></li>\n<li><a href=\"#ValkeyModule_RegisterScriptingEngine\"><code>ValkeyModule_RegisterScriptingEngine</code></a></li>\n<li><a href=\"#ValkeyModule_RegisterStringConfig\"><code>ValkeyModule_RegisterStringConfig</code></a></li>\n<li><a href=\"#ValkeyModule_Replicate\"><code>ValkeyModule_Replicate</code></a></li>\n<li><a href=\"#ValkeyModule_ReplicateVerbatim\"><code>ValkeyModule_ReplicateVerbatim</code></a></li>\n<li><a href=\"#ValkeyModule_ReplySetArrayLength\"><code>ValkeyModule_ReplySetArrayLength</code></a></li>\n<li><a href=\"#ValkeyModule_ReplySetAttributeLength\"><code>ValkeyModule_ReplySetAttributeLength</code></a></li>\n<li><a href=\"#ValkeyModule_ReplySetMapLength\"><code>ValkeyModule_ReplySetMapLength</code></a></li>\n<li><a href=\"#ValkeyModule_ReplySetSetLength\"><code>ValkeyModule_ReplySetSetLength</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithArray\"><code>ValkeyModule_ReplyWithArray</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithAttribute\"><code>ValkeyModule_ReplyWithAttribute</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithBigNumber\"><code>ValkeyModule_ReplyWithBigNumber</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithBool\"><code>ValkeyModule_ReplyWithBool</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithCString\"><code>ValkeyModule_ReplyWithCString</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithCallReply\"><code>ValkeyModule_ReplyWithCallReply</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithDouble\"><code>ValkeyModule_ReplyWithDouble</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithEmptyArray\"><code>ValkeyModule_ReplyWithEmptyArray</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithEmptyString\"><code>ValkeyModule_ReplyWithEmptyString</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithError\"><code>ValkeyModule_ReplyWithError</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithErrorFormat\"><code>ValkeyModule_ReplyWithErrorFormat</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithLongDouble\"><code>ValkeyModule_ReplyWithLongDouble</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithLongLong\"><code>ValkeyModule_ReplyWithLongLong</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithMap\"><code>ValkeyModule_ReplyWithMap</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithNull\"><code>ValkeyModule_ReplyWithNull</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithNullArray\"><code>ValkeyModule_ReplyWithNullArray</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithSet\"><code>ValkeyModule_ReplyWithSet</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithSimpleString\"><code>ValkeyModule_ReplyWithSimpleString</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithString\"><code>ValkeyModule_ReplyWithString</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithStringBuffer\"><code>ValkeyModule_ReplyWithStringBuffer</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithVerbatimString\"><code>ValkeyModule_ReplyWithVerbatimString</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithVerbatimStringType\"><code>ValkeyModule_ReplyWithVerbatimStringType</code></a></li>\n<li><a href=\"#ValkeyModule_ResetDataset\"><code>ValkeyModule_ResetDataset</code></a></li>\n<li><a href=\"#ValkeyModule_RetainString\"><code>ValkeyModule_RetainString</code></a></li>\n<li><a href=\"#ValkeyModule_SaveDataTypeToString\"><code>ValkeyModule_SaveDataTypeToString</code></a></li>\n<li><a href=\"#ValkeyModule_SaveDouble\"><code>ValkeyModule_SaveDouble</code></a></li>\n<li><a href=\"#ValkeyModule_SaveFloat\"><code>ValkeyModule_SaveFloat</code></a></li>\n<li><a href=\"#ValkeyModule_SaveLongDouble\"><code>ValkeyModule_SaveLongDouble</code></a></li>\n<li><a href=\"#ValkeyModule_SaveSigned\"><code>ValkeyModule_SaveSigned</code></a></li>\n<li><a href=\"#ValkeyModule_SaveString\"><code>ValkeyModule_SaveString</code></a></li>\n<li><a href=\"#ValkeyModule_SaveStringBuffer\"><code>ValkeyModule_SaveStringBuffer</code></a></li>\n<li><a href=\"#ValkeyModule_SaveUnsigned\"><code>ValkeyModule_SaveUnsigned</code></a></li>\n<li><a href=\"#ValkeyModule_Scan\"><code>ValkeyModule_Scan</code></a></li>\n<li><a href=\"#ValkeyModule_ScanCursorCreate\"><code>ValkeyModule_ScanCursorCreate</code></a></li>\n<li><a href=\"#ValkeyModule_ScanCursorDestroy\"><code>ValkeyModule_ScanCursorDestroy</code></a></li>\n<li><a href=\"#ValkeyModule_ScanCursorRestart\"><code>ValkeyModule_ScanCursorRestart</code></a></li>\n<li><a href=\"#ValkeyModule_ScanKey\"><code>ValkeyModule_ScanKey</code></a></li>\n<li><a href=\"#ValkeyModule_SelectDb\"><code>ValkeyModule_SelectDb</code></a></li>\n<li><a href=\"#ValkeyModule_SendChildHeartbeat\"><code>ValkeyModule_SendChildHeartbeat</code></a></li>\n<li><a href=\"#ValkeyModule_SendClusterMessage\"><code>ValkeyModule_SendClusterMessage</code></a></li>\n<li><a href=\"#ValkeyModule_ServerInfoGetField\"><code>ValkeyModule_ServerInfoGetField</code></a></li>\n<li><a href=\"#ValkeyModule_ServerInfoGetFieldC\"><code>ValkeyModule_ServerInfoGetFieldC</code></a></li>\n<li><a href=\"#ValkeyModule_ServerInfoGetFieldDouble\"><code>ValkeyModule_ServerInfoGetFieldDouble</code></a></li>\n<li><a href=\"#ValkeyModule_ServerInfoGetFieldSigned\"><code>ValkeyModule_ServerInfoGetFieldSigned</code></a></li>\n<li><a href=\"#ValkeyModule_ServerInfoGetFieldUnsigned\"><code>ValkeyModule_ServerInfoGetFieldUnsigned</code></a></li>\n<li><a href=\"#ValkeyModule_SetAbsExpire\"><code>ValkeyModule_SetAbsExpire</code></a></li>\n<li><a href=\"#ValkeyModule_SetClientNameById\"><code>ValkeyModule_SetClientNameById</code></a></li>\n<li><a href=\"#ValkeyModule_SetClusterFlags\"><code>ValkeyModule_SetClusterFlags</code></a></li>\n<li><a href=\"#ValkeyModule_SetCommandACLCategories\"><code>ValkeyModule_SetCommandACLCategories</code></a></li>\n<li><a href=\"#ValkeyModule_SetCommandInfo\"><code>ValkeyModule_SetCommandInfo</code></a></li>\n<li><a href=\"#ValkeyModule_SetContextUser\"><code>ValkeyModule_SetContextUser</code></a></li>\n<li><a href=\"#ValkeyModule_SetDisconnectCallback\"><code>ValkeyModule_SetDisconnectCallback</code></a></li>\n<li><a href=\"#ValkeyModule_SetExpire\"><code>ValkeyModule_SetExpire</code></a></li>\n<li><a href=\"#ValkeyModule_SetLFU\"><code>ValkeyModule_SetLFU</code></a></li>\n<li><a href=\"#ValkeyModule_SetLRU\"><code>ValkeyModule_SetLRU</code></a></li>\n<li><a href=\"#ValkeyModule_SetModuleOptions\"><code>ValkeyModule_SetModuleOptions</code></a></li>\n<li><a href=\"#ValkeyModule_SetModuleUserACL\"><code>ValkeyModule_SetModuleUserACL</code></a></li>\n<li><a href=\"#ValkeyModule_SetModuleUserACLString\"><code>ValkeyModule_SetModuleUserACLString</code></a></li>\n<li><a href=\"#ValkeyModule_SignalKeyAsReady\"><code>ValkeyModule_SignalKeyAsReady</code></a></li>\n<li><a href=\"#ValkeyModule_SignalModifiedKey\"><code>ValkeyModule_SignalModifiedKey</code></a></li>\n<li><a href=\"#ValkeyModule_StopTimer\"><code>ValkeyModule_StopTimer</code></a></li>\n<li><a href=\"#ValkeyModule_Strdup\"><code>ValkeyModule_Strdup</code></a></li>\n<li><a href=\"#ValkeyModule_StreamAdd\"><code>ValkeyModule_StreamAdd</code></a></li>\n<li><a href=\"#ValkeyModule_StreamDelete\"><code>ValkeyModule_StreamDelete</code></a></li>\n<li><a href=\"#ValkeyModule_StreamIteratorDelete\"><code>ValkeyModule_StreamIteratorDelete</code></a></li>\n<li><a href=\"#ValkeyModule_StreamIteratorNextField\"><code>ValkeyModule_StreamIteratorNextField</code></a></li>\n<li><a href=\"#ValkeyModule_StreamIteratorNextID\"><code>ValkeyModule_StreamIteratorNextID</code></a></li>\n<li><a href=\"#ValkeyModule_StreamIteratorStart\"><code>ValkeyModule_StreamIteratorStart</code></a></li>\n<li><a href=\"#ValkeyModule_StreamIteratorStop\"><code>ValkeyModule_StreamIteratorStop</code></a></li>\n<li><a href=\"#ValkeyModule_StreamTrimByID\"><code>ValkeyModule_StreamTrimByID</code></a></li>\n<li><a href=\"#ValkeyModule_StreamTrimByLength\"><code>ValkeyModule_StreamTrimByLength</code></a></li>\n<li><a href=\"#ValkeyModule_StringAppendBuffer\"><code>ValkeyModule_StringAppendBuffer</code></a></li>\n<li><a href=\"#ValkeyModule_StringCompare\"><code>ValkeyModule_StringCompare</code></a></li>\n<li><a href=\"#ValkeyModule_StringDMA\"><code>ValkeyModule_StringDMA</code></a></li>\n<li><a href=\"#ValkeyModule_StringPtrLen\"><code>ValkeyModule_StringPtrLen</code></a></li>\n<li><a href=\"#ValkeyModule_StringSet\"><code>ValkeyModule_StringSet</code></a></li>\n<li><a href=\"#ValkeyModule_StringToDouble\"><code>ValkeyModule_StringToDouble</code></a></li>\n<li><a href=\"#ValkeyModule_StringToLongDouble\"><code>ValkeyModule_StringToLongDouble</code></a></li>\n<li><a href=\"#ValkeyModule_StringToLongLong\"><code>ValkeyModule_StringToLongLong</code></a></li>\n<li><a href=\"#ValkeyModule_StringToStreamID\"><code>ValkeyModule_StringToStreamID</code></a></li>\n<li><a href=\"#ValkeyModule_StringToULongLong\"><code>ValkeyModule_StringToULongLong</code></a></li>\n<li><a href=\"#ValkeyModule_StringTruncate\"><code>ValkeyModule_StringTruncate</code></a></li>\n<li><a href=\"#ValkeyModule_SubscribeToKeyspaceEvents\"><code>ValkeyModule_SubscribeToKeyspaceEvents</code></a></li>\n<li><a href=\"#ValkeyModule_SubscribeToServerEvent\"><code>ValkeyModule_SubscribeToServerEvent</code></a></li>\n<li><a href=\"#ValkeyModule_ThreadSafeContextLock\"><code>ValkeyModule_ThreadSafeContextLock</code></a></li>\n<li><a href=\"#ValkeyModule_ThreadSafeContextTryLock\"><code>ValkeyModule_ThreadSafeContextTryLock</code></a></li>\n<li><a href=\"#ValkeyModule_ThreadSafeContextUnlock\"><code>ValkeyModule_ThreadSafeContextUnlock</code></a></li>\n<li><a href=\"#ValkeyModule_TrimStringAllocation\"><code>ValkeyModule_TrimStringAllocation</code></a></li>\n<li><a href=\"#ValkeyModule_TryAlloc\"><code>ValkeyModule_TryAlloc</code></a></li>\n<li><a href=\"#ValkeyModule_TryCalloc\"><code>ValkeyModule_TryCalloc</code></a></li>\n<li><a href=\"#ValkeyModule_TryRealloc\"><code>ValkeyModule_TryRealloc</code></a></li>\n<li><a href=\"#ValkeyModule_UnblockClient\"><code>ValkeyModule_UnblockClient</code></a></li>\n<li><a href=\"#ValkeyModule_UnlinkKey\"><code>ValkeyModule_UnlinkKey</code></a></li>\n<li><a href=\"#ValkeyModule_UnregisterCommandFilter\"><code>ValkeyModule_UnregisterCommandFilter</code></a></li>\n<li><a href=\"#ValkeyModule_UnregisterScriptingEngine\"><code>ValkeyModule_UnregisterScriptingEngine</code></a></li>\n<li><a href=\"#ValkeyModule_UpdateRuntimeArgs\"><code>ValkeyModule_UpdateRuntimeArgs</code></a></li>\n<li><a href=\"#ValkeyModule_ValueLength\"><code>ValkeyModule_ValueLength</code></a></li>\n<li><a href=\"#ValkeyModule_WrongArity\"><code>ValkeyModule_WrongArity</code></a></li>\n<li><a href=\"#ValkeyModule_Yield\"><code>ValkeyModule_Yield</code></a></li>\n<li><a href=\"#ValkeyModule_ZsetAdd\"><code>ValkeyModule_ZsetAdd</code></a></li>\n<li><a href=\"#ValkeyModule_ZsetFirstInLexRange\"><code>ValkeyModule_ZsetFirstInLexRange</code></a></li>\n<li><a href=\"#ValkeyModule_ZsetFirstInScoreRange\"><code>ValkeyModule_ZsetFirstInScoreRange</code></a></li>\n<li><a href=\"#ValkeyModule_ZsetIncrby\"><code>ValkeyModule_ZsetIncrby</code></a></li>\n<li><a href=\"#ValkeyModule_ZsetLastInLexRange\"><code>ValkeyModule_ZsetLastInLexRange</code></a></li>\n<li><a href=\"#ValkeyModule_ZsetLastInScoreRange\"><code>ValkeyModule_ZsetLastInScoreRange</code></a></li>\n<li><a href=\"#ValkeyModule_ZsetRangeCurrentElement\"><code>ValkeyModule_ZsetRangeCurrentElement</code></a></li>\n<li><a href=\"#ValkeyModule_ZsetRangeEndReached\"><code>ValkeyModule_ZsetRangeEndReached</code></a></li>\n<li><a href=\"#ValkeyModule_ZsetRangeNext\"><code>ValkeyModule_ZsetRangeNext</code></a></li>\n<li><a href=\"#ValkeyModule_ZsetRangePrev\"><code>ValkeyModule_ZsetRangePrev</code></a></li>\n<li><a href=\"#ValkeyModule_ZsetRangeStop\"><code>ValkeyModule_ZsetRangeStop</code></a></li>\n<li><a href=\"#ValkeyModule_ZsetRem\"><code>ValkeyModule_ZsetRem</code></a></li>\n<li><a href=\"#ValkeyModule_ZsetScore\"><code>ValkeyModule_ZsetScore</code></a></li>\n<li><a href=\"#ValkeyModule__Assert\"><code>ValkeyModule__Assert</code></a></li>\n</ul>\n"
  },
  {
    "id": "modules-blocking-ops",
    "topicName": "Modules and blocking commands",
    "description": "How to implement blocking commands in a Valkey module\n",
    "htmlContent": "<p>Valkey has a few blocking commands among the built-in set of commands.<br>One of the most used is <code>BLPOP</code> (or the symmetric <code>BRPOP</code>) which blocks<br>waiting for elements arriving in a list.</p>\n<p>The interesting fact about blocking commands is that they do not block<br>the whole server, but just the client calling them. Usually the reason to<br>block is that we expect some external event to happen: this can be<br>some change in the Valkey data structures like in the <code>BLPOP</code> case, a<br>long computation happening in a thread, to receive some data from the<br>network, and so forth.</p>\n<p>Valkey modules have the ability to implement blocking commands as well,<br>this documentation shows how the API works and describes a few patterns<br>that can be used in order to model blocking commands.</p>\n<h2>How blocking and resuming works.</h2>\n<p><strong>Note:</strong> You may want to check the <code>helloblock.c</code> example in the Valkey source tree<br>inside the <code>src/modules</code> directory, for a simple to understand example<br>on how the blocking API is applied.</p>\n<p>In Valkey modules, commands are implemented by callback functions that<br>are invoked by the Valkey core when the specific command is called<br>by the user. Normally the callback terminates its execution sending<br>some reply to the client. Using the following function instead, the<br>function implementing the module command may request that the client<br>is put into the blocked state:</p>\n<pre><code class=\"language-C\">ValkeyModuleBlockedClient *ValkeyModule_BlockClient(ValkeyModuleCtx *ctx,\n                                                    ValkeyModuleCmdFunc reply_callback,\n                                                    ValkeyModuleCmdFunc timeout_callback,\n                                                    void (*free_privdata)(void*),\n                                                    long long timeout_ms);\n</code></pre>\n<p>The function returns a <code>ValkeyModuleBlockedClient</code> object, which is later<br>used in order to unblock the client. The arguments have the following<br>meaning:</p>\n<ul>\n<li><code>ctx</code> is the command execution context as usually in the rest of the API.</li>\n<li><code>reply_callback</code> is the callback, having the same prototype of a normal command function, that is called when the client is unblocked in order to return a reply to the client.</li>\n<li><code>timeout_callback</code> is the callback, having the same prototype of a normal command function that is called when the client reached the <code>ms</code> timeout.</li>\n<li><code>free_privdata</code> is the callback that is called in order to free the private data. Private data is a pointer to some data that is passed between the API used to unblock the client, to the callback that will send the reply to the client. We&#39;ll see how this mechanism works later in this document.</li>\n<li><code>ms</code> is the timeout in milliseconds. When the timeout is reached, the timeout callback is called and the client is automatically aborted.</li>\n</ul>\n<p>Once a client is blocked, it can be unblocked with the following API:</p>\n<pre><code class=\"language-C\">int ValkeyModule_UnblockClient(ValkeyModuleBlockedClient *bc, void *privdata);\n</code></pre>\n<p>The function takes as argument the blocked client object returned by<br>the previous call to <code>ValkeyModule_BlockClient()</code>, and unblock the client.<br>Immediately before the client gets unblocked, the <code>reply_callback</code> function<br>specified when the client was blocked is called: this function will<br>have access to the <code>privdata</code> pointer used here.</p>\n<p>IMPORTANT: The above function is thread safe, and can be called from within<br>a thread doing some work in order to implement the command that blocked<br>the client.</p>\n<p>The <code>privdata</code> data will be freed automatically using the <code>free_privdata</code><br>callback when the client is unblocked. This is useful <strong>since the reply<br>callback may never be called</strong> in case the client timeouts or disconnects<br>from the server, so it&#39;s important that it&#39;s up to an external function<br>to have the responsibility to free the data passed if needed.</p>\n<p>To better understand how the API works, we can imagine writing a command<br>that blocks a client for one second, and then send as reply &quot;Hello!&quot;.</p>\n<p>Note: arity checks and other non important things are not implemented<br>int his command, in order to take the example simple.</p>\n<pre><code class=\"language-C\">int Example_ValkeyCommand(ValkeyModuleCtx *ctx, ValkeyModuleString **argv,\n                         int argc)\n{\n    ValkeyModuleBlockedClient *bc =\n        ValkeyModule_BlockClient(ctx,reply_func,timeout_func,NULL,0);\n\n    pthread_t tid;\n    pthread_create(&amp;tid,NULL,threadmain,bc);\n\n    return VALKEYMODULE_OK;\n}\n\nvoid *threadmain(void *arg) {\n    ValkeyModuleBlockedClient *bc = arg;\n\n    sleep(1); /* Wait one second and unblock. */\n    ValkeyModule_UnblockClient(bc,NULL);\n}\n</code></pre>\n<p>The above command blocks the client ASAP, spawning a thread that will<br>wait a second and will unblock the client. Let&#39;s check the reply and<br>timeout callbacks, which are in our case very similar, since they<br>just reply the client with a different reply type.</p>\n<pre><code class=\"language-C\">int reply_func(ValkeyModuleCtx *ctx, ValkeyModuleString **argv,\n               int argc)\n{\n    return ValkeyModule_ReplyWithSimpleString(ctx,&quot;Hello!&quot;);\n}\n\nint timeout_func(ValkeyModuleCtx *ctx, ValkeyModuleString **argv,\n               int argc)\n{\n    return ValkeyModule_ReplyWithNull(ctx);\n}\n</code></pre>\n<p>The reply callback just sends the &quot;Hello!&quot; string to the client.<br>The important bit here is that the reply callback is called when the<br>client is unblocked from the thread.</p>\n<p>The timeout command returns <code>NULL</code>, as it often happens with actual<br>Valkey blocking commands timing out.</p>\n<h2>Passing reply data when unblocking</h2>\n<p>The above example is simple to understand but lacks an important<br>real world aspect of an actual blocking command implementation: often<br>the reply function will need to know what to reply to the client,<br>and this information is often provided as the client is unblocked.</p>\n<p>We could modify the above example so that the thread generates a<br>random number after waiting one second. You can think at it as an<br>actually expansive operation of some kind. Then this random number<br>can be passed to the reply function so that we return it to the command<br>caller. In order to make this working, we modify the functions as follow:</p>\n<pre><code class=\"language-C\">void *threadmain(void *arg) {\n    ValkeyModuleBlockedClient *bc = arg;\n\n    sleep(1); /* Wait one second and unblock. */\n\n    long *mynumber = ValkeyModule_Alloc(sizeof(long));\n    *mynumber = rand();\n    ValkeyModule_UnblockClient(bc,mynumber);\n}\n</code></pre>\n<p>As you can see, now the unblocking call is passing some private data,<br>that is the <code>mynumber</code> pointer, to the reply callback. In order to<br>obtain this private data, the reply callback will use the following<br>function:</p>\n<pre><code class=\"language-C\">void *ValkeyModule_GetBlockedClientPrivateData(ValkeyModuleCtx *ctx);\n</code></pre>\n<p>So our reply callback is modified like that:</p>\n<pre><code class=\"language-C\">int reply_func(ValkeyModuleCtx *ctx, ValkeyModuleString **argv,\n               int argc)\n{\n    long *mynumber = ValkeyModule_GetBlockedClientPrivateData(ctx);\n    /* IMPORTANT: don&#39;t free mynumber here, but in the\n     * free privdata callback. */\n    return ValkeyModule_ReplyWithLongLong(ctx,mynumber);\n}\n</code></pre>\n<p>Note that we also need to pass a <code>free_privdata</code> function when blocking<br>the client with <code>ValkeyModule_BlockClient()</code>, since the allocated<br>long value must be freed. Our callback will look like the following:</p>\n<pre><code class=\"language-C\">void free_privdata(void *privdata) {\n    ValkeyModule_Free(privdata);\n}\n</code></pre>\n<p>NOTE: It is important to stress that the private data is best freed in the<br><code>free_privdata</code> callback because the reply function may not be called<br>if the client disconnects or timeout.</p>\n<p>Also note that the private data is also accessible from the timeout<br>callback, always using the <code>GetBlockedClientPrivateData()</code> API.</p>\n<h2>Aborting the blocking of a client</h2>\n<p>One problem that sometimes arises is that we need to allocate resources<br>in order to implement the non blocking command. So we block the client,<br>then, for example, try to create a thread, but the thread creation function<br>returns an error. What to do in such a condition in order to recover? We<br>don&#39;t want to take the client blocked, nor we want to call <code>UnblockClient()</code><br>because this will trigger the reply callback to be called.</p>\n<p>In this case the best thing to do is to use the following function:</p>\n<pre><code class=\"language-C\">int ValkeyModule_AbortBlock(ValkeyModuleBlockedClient *bc);\n</code></pre>\n<p>Practically this is how to use it:</p>\n<pre><code class=\"language-C\">int Example_ValkeyCommand(ValkeyModuleCtx *ctx, ValkeyModuleString **argv,\n                         int argc)\n{\n    ValkeyModuleBlockedClient *bc =\n        ValkeyModule_BlockClient(ctx,reply_func,timeout_func,NULL,0);\n\n    pthread_t tid;\n    if (pthread_create(&amp;tid,NULL,threadmain,bc) != 0) {\n        ValkeyModule_AbortBlock(bc);\n        ValkeyModule_ReplyWithError(ctx,&quot;Sorry can&#39;t create a thread&quot;);\n    }\n\n    return VALKEYMODULE_OK;\n}\n</code></pre>\n<p>The client will be unblocked but the reply callback will not be called.</p>\n<h2>Implementing the command, reply and timeout callback using a single function</h2>\n<p>The following functions can be used in order to implement the reply and<br>callback with the same function that implements the primary command<br>function:</p>\n<pre><code class=\"language-C\">int ValkeyModule_IsBlockedReplyRequest(ValkeyModuleCtx *ctx);\nint ValkeyModule_IsBlockedTimeoutRequest(ValkeyModuleCtx *ctx);\n</code></pre>\n<p>So I could rewrite the example command without using a separated<br>reply and timeout callback:</p>\n<pre><code class=\"language-C\">int Example_ValkeyCommand(ValkeyModuleCtx *ctx, ValkeyModuleString **argv,\n                         int argc)\n{\n    if (ValkeyModule_IsBlockedReplyRequest(ctx)) {\n        long *mynumber = ValkeyModule_GetBlockedClientPrivateData(ctx);\n        return ValkeyModule_ReplyWithLongLong(ctx,mynumber);\n    } else if (ValkeyModule_IsBlockedTimeoutRequest) {\n        return ValkeyModule_ReplyWithNull(ctx);\n    }\n\n    ValkeyModuleBlockedClient *bc =\n        ValkeyModule_BlockClient(ctx,reply_func,timeout_func,NULL,0);\n\n    pthread_t tid;\n    if (pthread_create(&amp;tid,NULL,threadmain,bc) != 0) {\n        ValkeyModule_AbortBlock(bc);\n        ValkeyModule_ReplyWithError(ctx,&quot;Sorry can&#39;t create a thread&quot;);\n    }\n\n    return VALKEYMODULE_OK;\n}\n</code></pre>\n<p>Functionally is the same but there are people that will prefer the less<br>verbose implementation that concentrates most of the command logic in a<br>single function.</p>\n<h2>Working on copies of data inside a thread</h2>\n<p>An interesting pattern in order to work with threads implementing the<br>slow part of a command, is to work with a copy of the data, so that<br>while some operation is performed in a key, the user continues to see<br>the old version. However when the thread terminated its work, the<br>representations are swapped and the new, processed version, is used.</p>\n<p>An example of this approach is the<br><a href=\"https://github.com/antirez/neural-redis\">Neural Redis module</a><br>where neural networks are trained in different threads while the<br>user can still execute and inspect their older versions.</p>\n<h2>Thread safe contexts</h2>\n<p>See <a href=\"modules-api-ref#section-thread-safe-contexts\">Thread Safe Contexts</a> in<br>the Modules API reference for how Valkey modules APIs can be called in a safe<br>way from threads.</p>\n"
  },
  {
    "id": "modules-intro",
    "topicName": "Modules API",
    "description": "Introduction to writing Valkey modules\n",
    "htmlContent": "<p>The modules documentation is composed of the following pages:</p>\n<ul>\n<li>Introduction to Valkey modules (this file). An overview about Valkey Modules system and API. It&#39;s a good idea to start your reading here.</li>\n<li><a href=\"modules-native-types\">Implementing native data types</a> covers the implementation of native data types into modules.</li>\n<li><a href=\"modules-blocking-ops\">Blocking operations</a> shows how to write blocking commands that will not reply immediately, but will block the client, without blocking the Valkey server, and will provide a reply whenever will be possible.</li>\n<li><a href=\"modules-api-ref\">Valkey modules API reference</a> is generated from module.c top comments of ValkeyModule functions. It is a good reference in order to understand how each function works.</li>\n</ul>\n<p>Valkey modules make it possible to extend Valkey functionality using external<br>modules, rapidly implementing new Valkey commands with features<br>similar to what can be done inside the core itself.</p>\n<p>Valkey modules are dynamic libraries that can be loaded into Valkey at<br>startup, or using the <code>MODULE LOAD</code> command. Valkey exports a C API, in the<br>form of a single C header file called <code>valkeymodule.h</code>. Modules are meant<br>to be written in C, however it will be possible to use C++ or other languages<br>that have C binding functionalities.</p>\n<p>Modules are designed in order to be loaded into different versions of Valkey,<br>so a given module does not need to be designed, or recompiled, in order to<br>run with a specific version of Valkey. For this reason, the module will<br>register to the Valkey core using a specific API version. The current API<br>version is &quot;1&quot;.</p>\n<h2>Loading modules</h2>\n<p>In order to test the module you are developing, you can load the module<br>using the following <code>valkey.conf</code> configuration directive:</p>\n<pre><code>loadmodule /path/to/mymodule.so\n</code></pre>\n<p>It is also possible to load a module at runtime using the following command:</p>\n<pre><code>MODULE LOAD /path/to/mymodule.so\n</code></pre>\n<p>In order to list all loaded modules, use:</p>\n<pre><code>MODULE LIST\n</code></pre>\n<p>Finally, you can unload (and later reload if you wish) a module using the<br>following command:</p>\n<pre><code>MODULE UNLOAD mymodule\n</code></pre>\n<p>Note that <code>mymodule</code> above is not the filename without the <code>.so</code> suffix, but<br>instead, the name the module used to register itself into the Valkey core.<br>The name can be obtained using <code>MODULE LIST</code>. However it is good practice<br>that the filename of the dynamic library is the same as the name the module<br>uses to register itself into the Valkey core.</p>\n<h2>The simplest module you can write</h2>\n<p>In order to show the different parts of a module, here we&#39;ll show a very<br>simple module that implements a command that outputs a random number.</p>\n<pre><code class=\"language-C\">#include &quot;valkeymodule.h&quot;\n#include &lt;stdlib.h&gt;\n\nint HelloworldRand_ValkeyCommand(ValkeyModuleCtx *ctx, ValkeyModuleString **argv, int argc) {\n    ValkeyModule_ReplyWithLongLong(ctx,rand());\n    return VALKEYMODULE_OK;\n}\n\nint ValkeyModule_OnLoad(ValkeyModuleCtx *ctx, ValkeyModuleString **argv, int argc) {\n    if (ValkeyModule_Init(ctx,&quot;helloworld&quot;,1,VALKEYMODULE_APIVER_1)\n        == VALKEYMODULE_ERR) return VALKEYMODULE_ERR;\n\n    if (ValkeyModule_CreateCommand(ctx,&quot;helloworld.rand&quot;,\n        HelloworldRand_ValkeyCommand, &quot;fast random&quot;,\n        0, 0, 0) == VALKEYMODULE_ERR)\n        return VALKEYMODULE_ERR;\n\n    return VALKEYMODULE_OK;\n}\n</code></pre>\n<p>The example module has two functions. One implements a command called<br>HELLOWORLD.RAND. This function is specific of that module. However the<br>other function called <code>ValkeyModule_OnLoad()</code> must be present in each<br>Valkey module. It is the entry point for the module to be initialized,<br>register its commands, and potentially other private data structures<br>it uses.</p>\n<p>Note that it is a good idea for modules to call commands with the<br>name of the module followed by a dot, and finally the command name,<br>like in the case of <code>HELLOWORLD.RAND</code>. This way it is less likely to<br>have collisions.</p>\n<p>Note that if different modules have colliding commands, they&#39;ll not be<br>able to work in Valkey at the same time, since the function<br><code>ValkeyModule_CreateCommand</code> will fail in one of the modules, so the module<br>loading will abort returning an error condition.</p>\n<h2>Module initialization</h2>\n<p>The above example shows the usage of the function <code>ValkeyModule_Init()</code>.<br>It should be the first function called by the module <code>OnLoad</code> function.<br>The following is the function prototype:</p>\n<pre><code class=\"language-C\">int ValkeyModule_Init(ValkeyModuleCtx *ctx, const char *modulename,\n                     int module_version, int api_version);\n</code></pre>\n<p>The <code>Init</code> function announces the Valkey core that the module has a given<br>name, its version (that is reported by <code>MODULE LIST</code>), and that is willing<br>to use a specific version of the API.</p>\n<p>If the API version is wrong, the name is already taken, or there are other<br>similar errors, the function will return <code>VALKEYMODULE_ERR</code>, and the module<br><code>OnLoad</code> function should return ASAP with an error.</p>\n<p>Before the <code>Init</code> function is called, no other API function can be called,<br>otherwise the module will segfault and the Valkey instance will crash.</p>\n<p>The second function called, <code>ValkeyModule_CreateCommand</code>, is used in order<br>to register commands into the Valkey core. The following is the prototype:</p>\n<pre><code class=\"language-C\">int ValkeyModule_CreateCommand(ValkeyModuleCtx *ctx, const char *name,\n                              ValkeyModuleCmdFunc cmdfunc, const char *strflags,\n                              int firstkey, int lastkey, int keystep);\n</code></pre>\n<p>As you can see, most Valkey modules API calls all take as first argument<br>the <code>context</code> of the module, so that they have a reference to the module<br>calling it, to the command and client executing a given command, and so forth.</p>\n<p>To create a new command, the above function needs the context, the command&#39;s<br>name, a pointer to the function implementing the command, the command&#39;s flags<br>and the positions of key names in the command&#39;s arguments.</p>\n<p>The function that implements the command must have the following prototype:</p>\n<pre><code class=\"language-C\">int mycommand(ValkeyModuleCtx *ctx, ValkeyModuleString **argv, int argc);\n</code></pre>\n<p>The command function arguments are just the context, that will be passed<br>to all the other API calls, the command argument vector, and total number<br>of arguments, as passed by the user.</p>\n<p>As you can see, the arguments are provided as pointers to a specific data<br>type, the <code>ValkeyModuleString</code>. This is an opaque data type you have API<br>functions to access and use, direct access to its fields is never needed.</p>\n<p>Zooming into the example command implementation, we can find another call:</p>\n<pre><code class=\"language-C\">int ValkeyModule_ReplyWithLongLong(ValkeyModuleCtx *ctx, long long integer);\n</code></pre>\n<p>This function returns an integer to the client that invoked the command,<br>exactly like other Valkey commands do, like for example <code>INCR</code> or <code>SCARD</code>.</p>\n<h2>Module cleanup</h2>\n<p>In most cases, there is no need for special cleanup.<br>When a module is unloaded, Valkey will automatically unregister commands and<br>unsubscribe from notifications.<br>However in the case where a module contains some persistent memory or<br>configuration, a module may include an optional <code>ValkeyModule_OnUnload</code><br>function.<br>If a module provides this function, it will be invoked during the module unload<br>process.<br>The following is the function prototype:</p>\n<pre><code class=\"language-C\">int ValkeyModule_OnUnload(ValkeyModuleCtx *ctx);\n</code></pre>\n<p>The <code>OnUnload</code> function may prevent module unloading by returning<br><code>VALKEYMODULE_ERR</code>.<br>Otherwise, <code>VALKEYMODULE_OK</code> should be returned.</p>\n<h2>Setup and dependencies of a Valkey module</h2>\n<p>Valkey modules don&#39;t depend on Valkey or some other library, nor they<br>need to be compiled with a specific <code>valkeymodule.h</code> file. In order<br>to create a new module, just copy a recent version of <code>valkeymodule.h</code><br>in your source tree, link all the libraries you want, and create<br>a dynamic library having the <code>ValkeyModule_OnLoad()</code> function symbol<br>exported.</p>\n<p>The module will be able to load into different versions of Valkey.</p>\n<p>A module can be designed to support both newer and older Redis OSS versions where certain API functions are not available in all versions.<br>If an API function is not implemented in the currently running Redis OSS version, the function pointer is set to NULL.<br>This allows the module to check if a function exists before using it:</p>\n<pre><code class=\"language-C\">if (ValkeyModule_SetCommandInfo != NULL) {\n    ValkeyModule_SetCommandInfo(cmd, &amp;info);\n}\n</code></pre>\n<p>In recent versions of <code>valkeymodule.h</code>, a convenience macro <code>RMAPI_FUNC_SUPPORTED(funcname)</code> is defined.<br>Using the macro or just comparing with NULL is a matter of personal preference.</p>\n<h1>Passing configuration parameters to Valkey modules</h1>\n<p>When the module is loaded with the <code>MODULE LOAD</code> command, or using the<br><code>loadmodule</code> directive in the <code>valkey.conf</code> file, the user is able to pass<br>configuration parameters to the module by adding arguments after the module<br>file name:</p>\n<pre><code>loadmodule mymodule.so foo bar 1234\n</code></pre>\n<p>In the above example the strings <code>foo</code>, <code>bar</code> and <code>1234</code> will be passed<br>to the module <code>OnLoad()</code> function in the <code>argv</code> argument as an array<br>of ValkeyModuleString pointers. The number of arguments passed is into <code>argc</code>.</p>\n<p>The way you can access those strings will be explained in the rest of this<br>document. Normally the module will store the module configuration parameters<br>in some <code>static</code> global variable that can be accessed module wide, so that<br>the configuration can change the behavior of different commands.</p>\n<h2>Working with ValkeyModuleString objects</h2>\n<p>The command argument vector <code>argv</code> passed to module commands, and the<br>return value of other module APIs functions, are of type <code>ValkeyModuleString</code>.</p>\n<p>Usually you directly pass module strings to other API calls, however sometimes<br>you may need to directly access the string object.</p>\n<p>There are a few functions in order to work with string objects:</p>\n<pre><code class=\"language-C\">const char *ValkeyModule_StringPtrLen(ValkeyModuleString *string, size_t *len);\n</code></pre>\n<p>The above function accesses a string by returning its pointer and setting its<br>length in <code>len</code>.<br>You should never write to a string object pointer, as you can see from the<br><code>const</code> pointer qualifier.</p>\n<p>However, if you want, you can create new string objects using the following<br>API:</p>\n<pre><code class=\"language-C\">ValkeyModuleString *ValkeyModule_CreateString(ValkeyModuleCtx *ctx, const char *ptr, size_t len);\n</code></pre>\n<p>The string returned by the above command must be freed using a corresponding<br>call to <code>ValkeyModule_FreeString()</code>:</p>\n<pre><code class=\"language-C\">void ValkeyModule_FreeString(ValkeyModuleString *str);\n</code></pre>\n<p>However if you want to avoid having to free strings, the automatic memory<br>management, covered later in this document, can be a good alternative, by<br>doing it for you.</p>\n<p>Note that the strings provided via the argument vector <code>argv</code> never need<br>to be freed. You only need to free new strings you create, or new strings<br>returned by other APIs, where it is specified that the returned string must<br>be freed.</p>\n<h2>Creating strings from numbers or parsing strings as numbers</h2>\n<p>Creating a new string from an integer is a very common operation, so there<br>is a function to do this:</p>\n<pre><code class=\"language-C\">ValkeyModuleString *mystr = ValkeyModule_CreateStringFromLongLong(ctx,10);\n</code></pre>\n<p>Similarly in order to parse a string as a number:</p>\n<pre><code class=\"language-C\">long long myval;\nif (ValkeyModule_StringToLongLong(ctx,argv[1],&amp;myval) == VALKEYMODULE_OK) {\n    /* Do something with &#39;myval&#39; */\n}\n</code></pre>\n<h2>Accessing Valkey keys from modules</h2>\n<p>Most Valkey modules, in order to be useful, have to interact with the Valkey<br>data space (this is not always true, for example an ID generator may<br>never touch Valkey keys). Valkey modules have two different APIs in order to<br>access the Valkey data space, one is a low level API that provides very<br>fast access and a set of functions to manipulate Valkey data structures.<br>The other API is more high level, and allows to call Valkey commands and<br>fetch the result, similarly to how Lua scripts access Valkey.</p>\n<p>The high level API is also useful in order to access Valkey functionalities<br>that are not available as APIs.</p>\n<p>In general modules developers should prefer the low level API, because commands<br>implemented using the low level API run at a speed comparable to the speed<br>of native Valkey commands. However there are definitely use cases for the<br>higher level API. For example often the bottleneck could be processing the<br>data and not accessing it.</p>\n<p>Also note that sometimes using the low level API is not harder compared to<br>the higher level one.</p>\n<h2>Calling Valkey commands</h2>\n<p>The high level API to access Valkey is the sum of the <code>ValkeyModule_Call()</code><br>function, together with the functions needed in order to access the<br>reply object returned by <code>Call()</code>.</p>\n<p><code>ValkeyModule_Call</code> uses a special calling convention, with a format specifier<br>that is used to specify what kind of objects you are passing as arguments<br>to the function.</p>\n<p>Valkey commands are invoked just using a command name and a list of arguments.<br>However when calling commands, the arguments may originate from different<br>kind of strings: null-terminated C strings, ValkeyModuleString objects as<br>received from the <code>argv</code> parameter in the command implementation, binary<br>safe C buffers with a pointer and a length, and so forth.</p>\n<p>For example if I want to call <code>INCRBY</code> using a first argument (the key)<br>a string received in the argument vector <code>argv</code>, which is an array<br>of ValkeyModuleString object pointers, and a C string representing the<br>number &quot;10&quot; as second argument (the increment), I&#39;ll use the following<br>function call:</p>\n<pre><code class=\"language-C\">ValkeyModuleCallReply *reply;\nreply = ValkeyModule_Call(ctx,&quot;INCRBY&quot;,&quot;sc&quot;,argv[1],&quot;10&quot;);\n</code></pre>\n<p>The first argument is the context, and the second is always a null terminated<br>C string with the command name. The third argument is the format specifier<br>where each character corresponds to the type of the arguments that will follow.<br>In the above case <code>&quot;sc&quot;</code> means a ValkeyModuleString object, and a null<br>terminated C string. The other arguments are just the two arguments as<br>specified. In fact <code>argv[1]</code> is a ValkeyModuleString and <code>&quot;10&quot;</code> is a null<br>terminated C string.</p>\n<p>This is the full list of format specifiers:</p>\n<ul>\n<li><strong>c</strong> -- Null terminated C string pointer.</li>\n<li><strong>b</strong> -- C buffer, two arguments needed: C string pointer and <code>size_t</code> length.</li>\n<li><strong>s</strong> -- ValkeyModuleString as received in <code>argv</code> or by other Valkey module APIs returning a ValkeyModuleString object.</li>\n<li><strong>l</strong> -- Long long integer.</li>\n<li><strong>v</strong> -- Array of ValkeyModuleString objects.</li>\n<li><strong>!</strong> -- This modifier just tells the function to replicate the command to replicas and AOF. It is ignored from the point of view of arguments parsing.</li>\n<li><strong>A</strong> -- This modifier, when <code>!</code> is given, tells to suppress AOF propagation: the command will be propagated only to replicas.</li>\n<li><strong>R</strong> -- This modifier, when <code>!</code> is given, tells to suppress replicas propagation: the command will be propagated only to the AOF if enabled.</li>\n</ul>\n<p>The function returns a <code>ValkeyModuleCallReply</code> object on success, on<br>error NULL is returned.</p>\n<p>NULL is returned when the command name is invalid, the format specifier uses<br>characters that are not recognized, or when the command is called with the<br>wrong number of arguments. In the above cases the <code>errno</code> var is set to <code>EINVAL</code>. NULL is also returned when, in an instance with Cluster enabled, the target<br>keys are about non local hash slots. In this case <code>errno</code> is set to <code>EPERM</code>.</p>\n<h2>Working with ValkeyModuleCallReply objects.</h2>\n<p><code>ValkeyModuleCall</code> returns reply objects that can be accessed using the<br><code>ValkeyModule_CallReply*</code> family of functions.</p>\n<p>In order to obtain the type or reply (corresponding to one of the data types<br>supported by the Valkey protocol), the function <code>ValkeyModule_CallReplyType()</code><br>is used:</p>\n<pre><code class=\"language-C\">reply = ValkeyModule_Call(ctx,&quot;INCRBY&quot;,&quot;sc&quot;,argv[1],&quot;10&quot;);\nif (ValkeyModule_CallReplyType(reply) == VALKEYMODULE_REPLY_INTEGER) {\n    long long myval = ValkeyModule_CallReplyInteger(reply);\n    /* Do something with myval. */\n}\n</code></pre>\n<p>Valid reply types are:</p>\n<ul>\n<li><code>VALKEYMODULE_REPLY_STRING</code> Bulk string or status replies.</li>\n<li><code>VALKEYMODULE_REPLY_ERROR</code> Errors.</li>\n<li><code>VALKEYMODULE_REPLY_INTEGER</code> Signed 64 bit integers.</li>\n<li><code>VALKEYMODULE_REPLY_ARRAY</code> Array of replies.</li>\n<li><code>VALKEYMODULE_REPLY_NULL</code> NULL reply.</li>\n</ul>\n<p>Strings, errors and arrays have an associated length. For strings and errors<br>the length corresponds to the length of the string. For arrays the length<br>is the number of elements. To obtain the reply length the following function<br>is used:</p>\n<pre><code class=\"language-C\">size_t reply_len = ValkeyModule_CallReplyLength(reply);\n</code></pre>\n<p>In order to obtain the value of an integer reply, the following function is used, as already shown in the example above:</p>\n<pre><code class=\"language-C\">long long reply_integer_val = ValkeyModule_CallReplyInteger(reply);\n</code></pre>\n<p>Called with a reply object of the wrong type, the above function always<br>returns <code>LLONG_MIN</code>.</p>\n<p>Sub elements of array replies are accessed this way:</p>\n<pre><code class=\"language-C\">ValkeyModuleCallReply *subreply;\nsubreply = ValkeyModule_CallReplyArrayElement(reply,idx);\n</code></pre>\n<p>The above function returns NULL if you try to access out of range elements.</p>\n<p>Strings and errors (which are like strings but with a different type) can<br>be accessed using in the following way, making sure to never write to<br>the resulting pointer (that is returned as a <code>const</code> pointer so that<br>misusing must be pretty explicit):</p>\n<pre><code class=\"language-C\">size_t len;\nchar *ptr = ValkeyModule_CallReplyStringPtr(reply,&amp;len);\n</code></pre>\n<p>If the reply type is not a string or an error, NULL is returned.</p>\n<p>ValkeyCallReply objects are not the same as module string objects<br>(ValkeyModuleString types). However sometimes you may need to pass replies<br>of type string or integer, to API functions expecting a module string.</p>\n<p>When this is the case, you may want to evaluate if using the low level<br>API could be a simpler way to implement your command, or you can use<br>the following function in order to create a new string object from a<br>call reply of type string, error or integer:</p>\n<pre><code class=\"language-C\">ValkeyModuleString *mystr = ValkeyModule_CreateStringFromCallReply(myreply);\n</code></pre>\n<p>If the reply is not of the right type, NULL is returned.<br>The returned string object should be released with <code>ValkeyModule_FreeString()</code><br>as usually, or by enabling automatic memory management (see corresponding<br>section).</p>\n<h2>Releasing call reply objects</h2>\n<p>Reply objects must be freed using <code>ValkeyModule_FreeCallReply</code>. For arrays,<br>you need to free only the top level reply, not the nested replies.<br>Currently the module implementation provides a protection in order to avoid<br>crashing if you free a nested reply object for error, however this feature<br>is not guaranteed to be here forever, so should not be considered part<br>of the API.</p>\n<p>If you use automatic memory management (explained later in this document)<br>you don&#39;t need to free replies (but you still could if you wish to release<br>memory ASAP).</p>\n<h2>Returning values from Valkey commands</h2>\n<p>Like normal Valkey commands, new commands implemented via modules must be<br>able to return values to the caller. The API exports a set of functions for<br>this goal, in order to return the usual types of the Valkey protocol, and<br>arrays of such types as elements. Also errors can be returned with any<br>error string and code (the error code is the initial uppercase letters in<br>the error message, like the &quot;BUSY&quot; string in the &quot;BUSY the sever is busy&quot; error<br>message).</p>\n<p>All the functions to send a reply to the client are called<br><code>ValkeyModule_ReplyWith&lt;something&gt;</code>.</p>\n<p>To return an error, use:</p>\n<pre><code class=\"language-C\">ValkeyModule_ReplyWithError(ValkeyModuleCtx *ctx, const char *err);\n</code></pre>\n<p>There is a predefined error string for key of wrong type errors:</p>\n<pre><code>VALKEYMODULE_ERRORMSG_WRONGTYPE\n</code></pre>\n<p>Example usage:</p>\n<pre><code class=\"language-C\">ValkeyModule_ReplyWithError(ctx,&quot;ERR invalid arguments&quot;);\n</code></pre>\n<p>We already saw how to reply with a <code>long long</code> in the examples above:</p>\n<pre><code class=\"language-C\">ValkeyModule_ReplyWithLongLong(ctx,12345);\n</code></pre>\n<p>To reply with a simple string, that can&#39;t contain binary values or newlines,<br>(so it&#39;s suitable to send small words, like &quot;OK&quot;) we use:</p>\n<pre><code class=\"language-C\">ValkeyModule_ReplyWithSimpleString(ctx,&quot;OK&quot;);\n</code></pre>\n<p>It&#39;s possible to reply with &quot;bulk strings&quot; that are binary safe, using<br>two different functions:</p>\n<pre><code class=\"language-C\">int ValkeyModule_ReplyWithStringBuffer(ValkeyModuleCtx *ctx, const char *buf, size_t len);\n\nint ValkeyModule_ReplyWithString(ValkeyModuleCtx *ctx, ValkeyModuleString *str);\n</code></pre>\n<p>The first function gets a C pointer and length. The second a ValkeyModuleString<br>object. Use one or the other depending on the source type you have at hand.</p>\n<p>In order to reply with an array, you just need to use a function to emit the<br>array length, followed by as many calls to the above functions as the number<br>of elements of the array are:</p>\n<pre><code class=\"language-C\">ValkeyModule_ReplyWithArray(ctx,2);\nValkeyModule_ReplyWithStringBuffer(ctx,&quot;age&quot;,3);\nValkeyModule_ReplyWithLongLong(ctx,22);\n</code></pre>\n<p>To return nested arrays is easy, your nested array element just uses another<br>call to <code>ValkeyModule_ReplyWithArray()</code> followed by the calls to emit the<br>sub array elements.</p>\n<h2>Returning arrays with dynamic length</h2>\n<p>Sometimes it is not possible to know beforehand the number of items of<br>an array. As an example, think of a Valkey module implementing a FACTOR<br>command that given a number outputs the prime factors. Instead of<br>factorializing the number, storing the prime factors into an array, and<br>later produce the command reply, a better solution is to start an array<br>reply where the length is not known, and set it later. This is accomplished<br>with a special argument to <code>ValkeyModule_ReplyWithArray()</code>:</p>\n<pre><code class=\"language-C\">ValkeyModule_ReplyWithArray(ctx, VALKEYMODULE_POSTPONED_LEN);\n</code></pre>\n<p>The above call starts an array reply so we can use other <code>ReplyWith</code> calls<br>in order to produce the array items. Finally in order to set the length,<br>use the following call:</p>\n<pre><code class=\"language-C\">ValkeyModule_ReplySetArrayLength(ctx, number_of_items);\n</code></pre>\n<p>In the case of the FACTOR command, this translates to some code similar<br>to this:</p>\n<pre><code class=\"language-C\">ValkeyModule_ReplyWithArray(ctx, VALKEYMODULE_POSTPONED_LEN);\nnumber_of_factors = 0;\nwhile(still_factors) {\n    ValkeyModule_ReplyWithLongLong(ctx, some_factor);\n    number_of_factors++;\n}\nValkeyModule_ReplySetArrayLength(ctx, number_of_factors);\n</code></pre>\n<p>Another common use case for this feature is iterating over the arrays of<br>some collection and only returning the ones passing some kind of filtering.</p>\n<p>It is possible to have multiple nested arrays with postponed reply.<br>Each call to <code>SetArray()</code> will set the length of the latest corresponding<br>call to <code>ReplyWithArray()</code>:</p>\n<pre><code class=\"language-C\">ValkeyModule_ReplyWithArray(ctx, VALKEYMODULE_POSTPONED_LEN);\n// ... generate 100 elements ...\nValkeyModule_ReplyWithArray(ctx, VALKEYMODULE_POSTPONED_LEN);\n// ... generate 10 elements ...\nValkeyModule_ReplySetArrayLength(ctx, 10);\nValkeyModule_ReplySetArrayLength(ctx, 100);\n</code></pre>\n<p>This creates a 100 items array having as last element a 10 items array.</p>\n<h2>Arity and type checks</h2>\n<p>Often commands need to check that the number of arguments and type of the key<br>is correct. In order to report a wrong arity, there is a specific function<br>called <code>ValkeyModule_WrongArity()</code>. The usage is trivial:</p>\n<pre><code class=\"language-C\">if (argc != 2) return ValkeyModule_WrongArity(ctx);\n</code></pre>\n<p>Checking for the wrong type involves opening the key and checking the type:</p>\n<pre><code class=\"language-C\">ValkeyModuleKey *key = ValkeyModule_OpenKey(ctx,argv[1],\n    VALKEYMODULE_READ|VALKEYMODULE_WRITE);\n\nint keytype = ValkeyModule_KeyType(key);\nif (keytype != VALKEYMODULE_KEYTYPE_STRING &amp;&amp;\n    keytype != VALKEYMODULE_KEYTYPE_EMPTY)\n{\n    ValkeyModule_CloseKey(key);\n    return ValkeyModule_ReplyWithError(ctx,VALKEYMODULE_ERRORMSG_WRONGTYPE);\n}\n</code></pre>\n<p>Note that you often want to proceed with a command both if the key<br>is of the expected type, or if it&#39;s empty.</p>\n<h2>Low level access to keys</h2>\n<p>Low level access to keys allow to perform operations on value objects associated<br>to keys directly, with a speed similar to what Valkey uses internally to<br>implement the built-in commands.</p>\n<p>Once a key is opened, a key pointer is returned that will be used with all the<br>other low level API calls in order to perform operations on the key or its<br>associated value.</p>\n<p>Because the API is meant to be very fast, it cannot do too many run-time<br>checks, so the user must be aware of certain rules to follow:</p>\n<ul>\n<li>Opening the same key multiple times where at least one instance is opened for writing, is undefined and may lead to crashes.</li>\n<li>While a key is open, it should only be accessed via the low level key API. For example opening a key, then calling DEL on the same key using the <code>ValkeyModule_Call()</code> API will result into a crash. However it is safe to open a key, perform some operation with the low level API, closing it, then using other APIs to manage the same key, and later opening it again to do some more work.</li>\n</ul>\n<p>In order to open a key the <code>ValkeyModule_OpenKey</code> function is used. It returns<br>a key pointer, that we&#39;ll use with all the next calls to access and modify<br>the value:</p>\n<pre><code class=\"language-C\">ValkeyModuleKey *key;\nkey = ValkeyModule_OpenKey(ctx,argv[1],VALKEYMODULE_READ);\n</code></pre>\n<p>The second argument is the key name, that must be a <code>ValkeyModuleString</code> object.<br>The third argument is the mode: <code>VALKEYMODULE_READ</code> or <code>VALKEYMODULE_WRITE</code>.<br>It is possible to use <code>|</code> to bitwise OR the two modes to open the key in<br>both modes. Currently a key opened for writing can also be accessed for reading<br>but this is to be considered an implementation detail. The right mode should<br>be used in sane modules.</p>\n<p>You can open non existing keys for writing, since the keys will be created<br>when an attempt to write to the key is performed. However when opening keys<br>just for reading, <code>ValkeyModule_OpenKey</code> will return NULL if the key does not<br>exist.</p>\n<p>Once you are done using a key, you can close it with:</p>\n<pre><code class=\"language-C\">ValkeyModule_CloseKey(key);\n</code></pre>\n<p>Note that if automatic memory management is enabled, you are not forced to<br>close keys. When the module function returns, Valkey will take care to close<br>all the keys which are still open.</p>\n<h2>Getting the key type</h2>\n<p>In order to obtain the value of a key, use the <code>ValkeyModule_KeyType()</code> function:</p>\n<pre><code class=\"language-C\">int keytype = ValkeyModule_KeyType(key);\n</code></pre>\n<p>It returns one of the following values:</p>\n<pre><code>VALKEYMODULE_KEYTYPE_EMPTY\nVALKEYMODULE_KEYTYPE_STRING\nVALKEYMODULE_KEYTYPE_LIST\nVALKEYMODULE_KEYTYPE_HASH\nVALKEYMODULE_KEYTYPE_SET\nVALKEYMODULE_KEYTYPE_ZSET\n</code></pre>\n<p>The above are just the usual Valkey key types, with the addition of an empty<br>type, that signals the key pointer is associated with an empty key that<br>does not yet exists.</p>\n<h2>Creating new keys</h2>\n<p>To create a new key, open it for writing and then write to it using one<br>of the key writing functions. Example:</p>\n<pre><code class=\"language-C\">ValkeyModuleKey *key;\nkey = ValkeyModule_OpenKey(ctx,argv[1],VALKEYMODULE_WRITE);\nif (ValkeyModule_KeyType(key) == VALKEYMODULE_KEYTYPE_EMPTY) {\n    ValkeyModule_StringSet(key,argv[2]);\n}\n</code></pre>\n<h2>Deleting keys</h2>\n<p>Just use:</p>\n<pre><code class=\"language-C\">ValkeyModule_DeleteKey(key);\n</code></pre>\n<p>The function returns <code>VALKEYMODULE_ERR</code> if the key is not open for writing.<br>Note that after a key gets deleted, it is setup in order to be targeted<br>by new key commands. For example <code>ValkeyModule_KeyType()</code> will return it is<br>an empty key, and writing to it will create a new key, possibly of another<br>type (depending on the API used).</p>\n<h2>Managing key expires (TTLs)</h2>\n<p>To control key expires two functions are provided, that are able to set,<br>modify, get, and unset the time to live associated with a key.</p>\n<p>One function is used in order to query the current expire of an open key:</p>\n<pre><code class=\"language-C\">mstime_t ValkeyModule_GetExpire(ValkeyModuleKey *key);\n</code></pre>\n<p>The function returns the time to live of the key in milliseconds, or<br><code>VALKEYMODULE_NO_EXPIRE</code> as a special value to signal the key has no associated<br>expire or does not exist at all (you can differentiate the two cases checking<br>if the key type is <code>VALKEYMODULE_KEYTYPE_EMPTY</code>).</p>\n<p>In order to change the expire of a key the following function is used instead:</p>\n<pre><code class=\"language-C\">int ValkeyModule_SetExpire(ValkeyModuleKey *key, mstime_t expire);\n</code></pre>\n<p>When called on a non existing key, <code>VALKEYMODULE_ERR</code> is returned, because<br>the function can only associate expires to existing open keys (non existing<br>open keys are only useful in order to create new values with data type<br>specific write operations).</p>\n<p>Again the <code>expire</code> time is specified in milliseconds. If the key has currently<br>no expire, a new expire is set. If the key already have an expire, it is<br>replaced with the new value.</p>\n<p>If the key has an expire, and the special value <code>VALKEYMODULE_NO_EXPIRE</code> is<br>used as a new expire, the expire is removed, similarly to the Valkey<br><code>PERSIST</code> command. In case the key was already persistent, no operation is<br>performed.</p>\n<h2>Obtaining the length of values</h2>\n<p>There is a single function in order to retrieve the length of the value<br>associated to an open key. The returned length is value-specific, and is<br>the string length for strings, and the number of elements for the aggregated<br>data types (how many elements there is in a list, set, sorted set, hash).</p>\n<pre><code class=\"language-C\">size_t len = ValkeyModule_ValueLength(key);\n</code></pre>\n<p>If the key does not exist, 0 is returned by the function:</p>\n<h2>String type API</h2>\n<p>Setting a new string value, like the Valkey <code>SET</code> command does, is performed<br>using:</p>\n<pre><code class=\"language-C\">int ValkeyModule_StringSet(ValkeyModuleKey *key, ValkeyModuleString *str);\n</code></pre>\n<p>The function works exactly like the Valkey <code>SET</code> command itself, that is, if<br>there is a prior value (of any type) it will be deleted.</p>\n<p>Accessing existing string values is performed using DMA (direct memory<br>access) for speed. The API will return a pointer and a length, so that&#39;s<br>possible to access and, if needed, modify the string directly.</p>\n<pre><code class=\"language-C\">size_t len, j;\nchar *myptr = ValkeyModule_StringDMA(key,&amp;len,VALKEYMODULE_WRITE);\nfor (j = 0; j &lt; len; j++) myptr[j] = &#39;A&#39;;\n</code></pre>\n<p>In the above example we write directly on the string. Note that if you want<br>to write, you must be sure to ask for <code>WRITE</code> mode.</p>\n<p>DMA pointers are only valid if no other operations are performed with the key<br>before using the pointer, after the DMA call.</p>\n<p>Sometimes when we want to manipulate strings directly, we need to change<br>their size as well. For this scope, the <code>ValkeyModule_StringTruncate</code> function<br>is used. Example:</p>\n<pre><code class=\"language-C\">ValkeyModule_StringTruncate(mykey,1024);\n</code></pre>\n<p>The function truncates, or enlarges the string as needed, padding it with<br>zero bytes if the previous length is smaller than the new length we request.<br>If the string does not exist since <code>key</code> is associated to an open empty key,<br>a string value is created and associated to the key.</p>\n<p>Note that every time <code>StringTruncate()</code> is called, we need to re-obtain<br>the DMA pointer again, since the old may be invalid.</p>\n<p>For a complete list of string type functions, see <a href=\"modules-api-ref#section-key-api-for-string-type\">Key API for String<br>type</a> in the Modules API<br>reference.</p>\n<h2>List type API</h2>\n<p>It&#39;s possible to push and pop values from list values:</p>\n<pre><code class=\"language-C\">int ValkeyModule_ListPush(ValkeyModuleKey *key, int where, ValkeyModuleString *ele);\nValkeyModuleString *ValkeyModule_ListPop(ValkeyModuleKey *key, int where);\n</code></pre>\n<p>In both the APIs the <code>where</code> argument specifies if to push or pop from tail<br>or head, using the following macros:</p>\n<pre><code>VALKEYMODULE_LIST_HEAD\nVALKEYMODULE_LIST_TAIL\n</code></pre>\n<p>Elements returned by <code>ValkeyModule_ListPop()</code> are like strings created with<br><code>ValkeyModule_CreateString()</code>, they must be released with<br><code>ValkeyModule_FreeString()</code> or by enabling automatic memory management.</p>\n<p>For a complete list of set type functions, see <a href=\"modules-api-ref#section-key-api-for-list-type\">Key API for List<br>type</a> in the Modules API<br>reference.</p>\n<h2>Set type API</h2>\n<p>A direct API to set type keys is not yet implemented.<br>Use the <code>ValkeyModule_Call</code> API with set commands like SADD to access keys of type set.</p>\n<h2>Sorted set type API</h2>\n<p>See the <a href=\"modules-api-ref#section-key-api-for-sorted-set-type\">Key API for Sorted Set<br>type</a> section in the<br>Modules API reference.</p>\n<h2>Hash type API</h2>\n<p>See <a href=\"modules-api-ref#section-key-api-for-hash-type\">Key API for Hash type</a> in<br>the Modules API reference.</p>\n<h2>Replicating commands</h2>\n<p>If you want to use module commands exactly like normal Valkey commands, in the<br>context of replicated Valkey instances, or using the AOF file for persistence,<br>it is important for module commands to handle their replication in a consistent<br>way.</p>\n<p>When using the higher level APIs to invoke commands, replication happens<br>automatically if you use the &quot;!&quot; modifier in the format string of<br><code>ValkeyModule_Call()</code> as in the following example:</p>\n<pre><code class=\"language-C\">reply = ValkeyModule_Call(ctx,&quot;INCRBY&quot;,&quot;!sc&quot;,argv[1],&quot;10&quot;);\n</code></pre>\n<p>As you can see the format specifier is <code>&quot;!sc&quot;</code>. The bang is not parsed as a<br>format specifier, but it internally flags the command as &quot;must replicate&quot;.</p>\n<p>If you use the above programming style, there are no problems.<br>However sometimes things are more complex than that, and you use the low level<br>API. In this case, if there are no side effects in the command execution, and<br>it consistently always performs the same work, what is possible to do is to<br>replicate the command verbatim as the user executed it. To do that, you just<br>need to call the following function:</p>\n<pre><code class=\"language-C\">ValkeyModule_ReplicateVerbatim(ctx);\n</code></pre>\n<p>When you use the above API, you should not use any other replication function<br>since they are not guaranteed to mix well.</p>\n<p>However this is not the only option. It&#39;s also possible to exactly tell<br>Valkey what commands to replicate as the effect of the command execution, using<br>an API similar to <code>ValkeyModule_Call()</code> but that instead of calling the command<br>sends it to the AOF / replicas stream. Example:</p>\n<pre><code class=\"language-C\">ValkeyModule_Replicate(ctx,&quot;INCRBY&quot;,&quot;cl&quot;,&quot;foo&quot;,my_increment);\n</code></pre>\n<p>It&#39;s possible to call <code>ValkeyModule_Replicate</code> multiple times, and each<br>will emit a command. All the sequence emitted is wrapped between a<br><code>MULTI/EXEC</code> transaction, so that the AOF and replication effects are the<br>same as executing a single command.</p>\n<p>Note that <code>Call()</code> replication and <code>Replicate()</code> replication have a rule,<br>in case you want to mix both forms of replication (not necessarily a good<br>idea if there are simpler approaches). Commands replicated with <code>Call()</code><br>are always the first emitted in the final <code>MULTI/EXEC</code> block, while all<br>the commands emitted with <code>Replicate()</code> will follow.</p>\n<h2>Automatic memory management</h2>\n<p>Normally when writing programs in the C language, programmers need to manage<br>memory manually. This is why the Valkey modules API has functions to release<br>strings, close open keys, free replies, and so forth.</p>\n<p>However given that commands are executed in a contained environment and<br>with a set of strict APIs, Valkey is able to provide automatic memory management<br>to modules, at the cost of some performance (most of the time, a very low<br>cost).</p>\n<p>When automatic memory management is enabled:</p>\n<ol>\n<li>You don&#39;t need to close open keys.</li>\n<li>You don&#39;t need to free replies.</li>\n<li>You don&#39;t need to free ValkeyModuleString objects.</li>\n</ol>\n<p>However you can still do it, if you want. For example, automatic memory<br>management may be active, but inside a loop allocating a lot of strings,<br>you may still want to free strings no longer used.</p>\n<p>In order to enable automatic memory management, just call the following<br>function at the start of the command implementation:</p>\n<pre><code class=\"language-C\">ValkeyModule_AutoMemory(ctx);\n</code></pre>\n<p>Automatic memory management is usually the way to go, however experienced<br>C programmers may not use it in order to gain some speed and memory usage<br>benefit.</p>\n<h2>Allocating memory into modules</h2>\n<p>Normal C programs use <code>malloc()</code> and <code>free()</code> in order to allocate and<br>release memory dynamically. While in Valkey modules the use of malloc is<br>not technically forbidden, it is a lot better to use the Valkey Modules<br>specific functions, that are exact replacements for <code>malloc</code>, <code>free</code>,<br><code>realloc</code> and <code>strdup</code>. These functions are:</p>\n<pre><code class=\"language-C\">void *ValkeyModule_Alloc(size_t bytes);\nvoid* ValkeyModule_Realloc(void *ptr, size_t bytes);\nvoid ValkeyModule_Free(void *ptr);\nvoid ValkeyModule_Calloc(size_t nmemb, size_t size);\nchar *ValkeyModule_Strdup(const char *str);\n</code></pre>\n<p>They work exactly like their <code>libc</code> equivalent calls, however they use<br>the same allocator Valkey uses, and the memory allocated using these<br>functions is reported by the <code>INFO</code> command in the memory section, is<br>accounted when enforcing the <code>maxmemory</code> policy, and in general is<br>a first citizen of the Valkey executable. On the contrary, the method<br>allocated inside modules with libc <code>malloc()</code> is transparent to Valkey.</p>\n<p>Another reason to use the modules functions in order to allocate memory<br>is that, when creating native data types inside modules, the RDB loading<br>functions can return deserialized strings (from the RDB file) directly<br>as <code>ValkeyModule_Alloc()</code> allocations, so they can be used directly to<br>populate data structures after loading, instead of having to copy them<br>to the data structure.</p>\n<h2>Pool allocator</h2>\n<p>Sometimes in commands implementations, it is required to perform many<br>small allocations that will be not retained at the end of the command<br>execution, but are just functional to execute the command itself.</p>\n<p>This work can be more easily accomplished using the Valkey pool allocator:</p>\n<pre><code class=\"language-C\">void *ValkeyModule_PoolAlloc(ValkeyModuleCtx *ctx, size_t bytes);\n</code></pre>\n<p>It works similarly to <code>malloc()</code>, and returns memory aligned to the<br>next power of two of greater or equal to <code>bytes</code> (for a maximum alignment<br>of 8 bytes). However it allocates memory in blocks, so it the overhead<br>of the allocations is small, and more important, the memory allocated<br>is automatically released when the command returns.</p>\n<p>So in general short living allocations are a good candidates for the pool<br>allocator.</p>\n<h2>Writing commands compatible with Valkey Cluster</h2>\n<p>See the Modules API reference for the following commands:</p>\n<ul>\n<li><a href=\"modules-api-ref#ValkeyModule_IsKeysPositionRequest\"><code>ValkeyModule_IsKeysPositionRequest(ctx)</code></a></li>\n<li><a href=\"modules-api-ref#ValkeyModule_KeyAtPos\"><code>ValkeyModule_KeyAtPos(ctx, pos)</code></a></li>\n</ul>\n"
  },
  {
    "id": "modules-native-types",
    "topicName": "Modules API for native types",
    "description": "How to use native types in a Valkey module\n",
    "htmlContent": "<p>Valkey modules can access Valkey built-in data structures both at high level,<br>by calling Valkey commands, and at low level, by manipulating the data structures<br>directly.</p>\n<p>By using these capabilities in order to build new abstractions on top of existing<br>Valkey data structures, or by using strings DMA in order to encode modules<br>data structures into Strings, it is possible to create modules that<br><em>feel like</em> they are exporting new data types. However, for more complex<br>problems, this is not enough, and the implementation of new data structures<br>inside the module is needed.</p>\n<p>We call the ability of Valkey modules to implement new data structures that<br>feel like native Valkey ones <strong>native types support</strong>. This document describes<br>the API exported by the Valkey modules system in order to create new data<br>structures and handle the serialization in RDB files, the rewriting process<br>in AOF, the type reporting via the <code>TYPE</code> command, and so forth.</p>\n<h2>Overview of native types</h2>\n<p>A module exporting a native type is composed of the following main parts:</p>\n<ul>\n<li>The implementation of some kind of new data structure and of commands operating on the new data structure.</li>\n<li>A set of callbacks that handle: RDB saving, RDB loading, AOF rewriting, releasing of a value associated with a key, calculation of a value digest (hash) to be used with the <code>DEBUG DIGEST</code> command.</li>\n<li>A 9 characters name that is unique to each module native data type.</li>\n<li>An encoding version, used to persist into RDB files a module-specific data version, so that a module will be able to load older representations from RDB files.</li>\n</ul>\n<p>While to handle RDB loading, saving and AOF rewriting may look complex as a first glance, the modules API provide very high level function for handling all this, without requiring the user to handle read/write errors, so in practical terms, writing a new data structure for Valkey is a simple task.</p>\n<p>A <strong>very easy</strong> to understand but complete example of native type implementation<br>is available inside the Valkey distribution in the <code>/modules/hellotype.c</code> file.<br>The reader is encouraged to read the documentation by looking at this example<br>implementation to see how things are applied in the practice.</p>\n<h1>Registering a new data type</h1>\n<p>In order to register a new native type into the Valkey core, the module needs<br>to declare a global variable that will hold a reference to the data type.<br>The API to register the data type will return a data type reference that will<br>be stored in the global variable.</p>\n<pre><code class=\"language-C\">static ValkeyModuleType *MyType;\n#define MYTYPE_ENCODING_VERSION 0\n\nint ValkeyModule_OnLoad(ValkeyModuleCtx *ctx) {\nValkeyModuleTypeMethods tm = {\n    .version = VALKEYMODULE_TYPE_METHOD_VERSION,\n    .rdb_load = MyTypeRDBLoad,\n    .rdb_save = MyTypeRDBSave,\n    .aof_rewrite = MyTypeAOFRewrite,\n    .free = MyTypeFree\n};\n\n    MyType = ValkeyModule_CreateDataType(ctx, &quot;MyType-AZ&quot;,\n    MYTYPE_ENCODING_VERSION, &amp;tm);\n    if (MyType == NULL) return VALKEYMODULE_ERR;\n}\n</code></pre>\n<p>As you can see from the example above, a single API call is needed in order to<br>register the new type. However a number of function pointers are passed as<br>arguments. Certain are optionals while some are mandatory. The above set<br>of methods <em>must</em> be passed, while <code>.digest</code> and <code>.mem_usage</code> are optional<br>and are currently not actually supported by the modules internals, so for<br>now you can just ignore them.</p>\n<p>The <code>ctx</code> argument is the context that we receive in the <code>OnLoad</code> function.<br>The type <code>name</code> is a 9 character name in the character set that includes<br>from <code>A-Z</code>, <code>a-z</code>, <code>0-9</code>, plus the underscore <code>_</code> and minus <code>-</code> characters.</p>\n<p>Note that <strong>this name must be unique</strong> for each data type in the Valkey<br>ecosystem, so be creative, use both lower-case and upper case if it makes<br>sense, and try to use the convention of mixing the type name with the name<br>of the author of the module, to create a 9 character unique name.</p>\n<p><strong>NOTE:</strong> It is very important that the name is exactly 9 chars or the<br>registration of the type will fail. Read more to understand why.</p>\n<p>For example if I&#39;m building a <em>b-tree</em> data structure and my name is <em>antirez</em><br>I&#39;ll call my type <strong>btree1-az</strong>. The name, converted to a 64 bit integer,<br>is stored inside the RDB file when saving the type, and will be used when the<br>RDB data is loaded in order to resolve what module can load the data. If Valkey<br>finds no matching module, the integer is converted back to a name in order to<br>provide some clue to the user about what module is missing in order to load<br>the data.</p>\n<p>The type name is also used as a reply for the <code>TYPE</code> command when called<br>with a key holding the registered type.</p>\n<p>The <code>encver</code> argument is the encoding version used by the module to store data<br>inside the RDB file. For example I can start with an encoding version of 0,<br>but later when I release version 2.0 of my module, I can switch encoding to<br>something better. The new module will register with an encoding version of 1,<br>so when it saves new RDB files, the new version will be stored on disk. However<br>when loading RDB files, the module <code>rdb_load</code> method will be called even if<br>there is data found for a different encoding version (and the encoding version<br>is passed as argument to <code>rdb_load</code>), so that the module can still load old<br>RDB files.</p>\n<p>The last argument is a structure used in order to pass the type methods to the<br>registration function: <code>rdb_load</code>, <code>rdb_save</code>, <code>aof_rewrite</code>, <code>digest</code> and<br><code>free</code> and <code>mem_usage</code> are all callbacks with the following prototypes and uses:</p>\n<pre><code class=\"language-C\">typedef void *(*ValkeyModuleTypeLoadFunc)(ValkeyModuleIO *rdb, int encver);\ntypedef void (*ValkeyModuleTypeSaveFunc)(ValkeyModuleIO *rdb, void *value);\ntypedef void (*ValkeyModuleTypeRewriteFunc)(ValkeyModuleIO *aof, ValkeyModuleString *key, void *value);\ntypedef size_t (*ValkeyModuleTypeMemUsageFunc)(void *value);\ntypedef void (*ValkeyModuleTypeDigestFunc)(ValkeyModuleDigest *digest, void *value);\ntypedef void (*ValkeyModuleTypeFreeFunc)(void *value);\n</code></pre>\n<ul>\n<li><code>rdb_load</code> is called when loading data from the RDB file. It loads data in the same format as <code>rdb_save</code> produces.</li>\n<li><code>rdb_save</code> is called when saving data to the RDB file.</li>\n<li><code>aof_rewrite</code> is called when the AOF is being rewritten, and the module needs to tell Valkey what is the sequence of commands to recreate the content of a given key.</li>\n<li><code>digest</code> is called when <code>DEBUG DIGEST</code> is executed and a key holding this module type is found. Currently this is not yet implemented so the function ca be left empty.</li>\n<li><code>mem_usage</code> is called when the <code>MEMORY</code> command asks for the total memory consumed by a specific key, and is used in order to get the amount of bytes used by the module value.</li>\n<li><code>free</code> is called when a key with the module native type is deleted via <code>DEL</code> or in any other mean, in order to let the module reclaim the memory associated with such a value.</li>\n</ul>\n<h2>Ok, but <em>why</em> modules types require a 9 characters name?</h2>\n<p>Oh, I understand you need to understand this, so here is a very specific<br>explanation.</p>\n<p>When Valkey persists to RDB files, modules specific data types require to<br>be persisted as well. Now RDB files are sequences of key-value pairs<br>like the following:</p>\n<pre><code>[1 byte type] [key] [a type specific value]\n</code></pre>\n<p>The 1 byte type identifies strings, lists, sets, and so forth. In the case<br>of modules data, it is set to a special value of <code>module data</code>, but of<br>course this is not enough, we need the information needed to link a specific<br>value with a specific module type that is able to load and handle it.</p>\n<p>So when we save a <code>type specific value</code> about a module, we prefix it with<br>a 64 bit integer. 64 bits is large enough to store the information needed<br>in order to lookup the module that can handle that specific type, but is<br>short enough that we can prefix each module value we store inside the RDB<br>without making the final RDB file too big. At the same time, this solution<br>of prefixing the value with a 64 bit <em>signature</em> does not require to do<br>strange things like defining in the RDB header a list of modules specific<br>types. Everything is pretty simple.</p>\n<p>So, what you can store in 64 bits in order to identify a given module in<br>a reliable way? Well if you build a character set of 64 symbols, you can<br>easily store 9 characters of 6 bits, and you are left with 10 bits, that<br>are used in order to store the <em>encoding version</em> of the type, so that<br>the same type can evolve in the future and provide a different and more<br>efficient or updated serialization format for RDB files.</p>\n<p>So the 64 bit prefix stored before each module value is like the following:</p>\n<pre><code>6|6|6|6|6|6|6|6|6|10\n</code></pre>\n<p>The first 9 elements are 6-bits characters, the final 10 bits is the<br>encoding version.</p>\n<p>When the RDB file is loaded back, it reads the 64 bit value, masks the final<br>10 bits, and searches for a matching module in the modules types cache.<br>When a matching one is found, the method to load the RDB file value is called<br>with the 10 bits encoding version as argument, so that the module knows<br>what version of the data layout to load, if it can support multiple versions.</p>\n<p>Now the interesting thing about all this is that, if instead the module type<br>cannot be resolved, since there is no loaded module having this signature,<br>we can convert back the 64 bit value into a 9 characters name, and print<br>an error to the user that includes the module type name! So that she or he<br>immediately realizes what&#39;s wrong.</p>\n<h2>Setting and getting keys</h2>\n<p>After registering our new data type in the <code>ValkeyModule_OnLoad()</code> function,<br>we also need to be able to set Valkey keys having as value our native type.</p>\n<p>This normally happens in the context of commands that write data to a key.<br>The native types API allow to set and get keys to module native data types,<br>and to test if a given key is already associated to a value of a specific data<br>type.</p>\n<p>The API uses the normal modules <code>ValkeyModule_OpenKey()</code> low level key access<br>interface in order to deal with this. This is an example of setting a<br>native type private data structure to a Valkey key:</p>\n<pre><code class=\"language-C\">ValkeyModuleKey *key = ValkeyModule_OpenKey(ctx,keyname,VALKEYMODULE_WRITE);\nstruct some_private_struct *data = createMyDataStructure();\nValkeyModule_ModuleTypeSetValue(key,MyType,data);\n</code></pre>\n<p>The function <code>ValkeyModule_ModuleTypeSetValue()</code> is used with a key handle open<br>for writing, and gets three arguments: the key handle, the reference to the<br>native type, as obtained during the type registration, and finally a <code>void*</code><br>pointer that contains the private data implementing the module native type.</p>\n<p>Note that Valkey has no clues at all about what your data contains. It will<br>just call the callbacks you provided during the method registration in order<br>to perform operations on the type.</p>\n<p>Similarly we can retrieve the private data from a key using this function:</p>\n<pre><code>struct some_private_struct *data;\ndata = ValkeyModule_ModuleTypeGetValue(key);\n</code></pre>\n<p>We can also test for a key to have our native type as value:</p>\n<pre><code class=\"language-C\">if (ValkeyModule_ModuleTypeGetType(key) == MyType) {\n    /* ... do something ... */\n}\n</code></pre>\n<p>However for the calls to do the right thing, we need to check if the key<br>is empty, if it contains a value of the right kind, and so forth. So<br>the idiomatic code to implement a command writing to our native type<br>is along these lines:</p>\n<pre><code class=\"language-C\">ValkeyModuleKey *key = ValkeyModule_OpenKey(ctx,argv[1],\n    VALKEYMODULE_READ|VALKEYMODULE_WRITE);\nint type = ValkeyModule_KeyType(key);\nif (type != VALKEYMODULE_KEYTYPE_EMPTY &amp;&amp;\n    ValkeyModule_ModuleTypeGetType(key) != MyType)\n{\n    return ValkeyModule_ReplyWithError(ctx,VALKEYMODULE_ERRORMSG_WRONGTYPE);\n}\n</code></pre>\n<p>Then if we successfully verified the key is not of the wrong type, and<br>we are going to write to it, we usually want to create a new data structure if<br>the key is empty, or retrieve the reference to the value associated to the<br>key if there is already one:</p>\n<pre><code class=\"language-C\">/* Create an empty value object if the key is currently empty. */\nstruct some_private_struct *data;\nif (type == VALKEYMODULE_KEYTYPE_EMPTY) {\n    data = createMyDataStructure();\n    ValkeyModule_ModuleTypeSetValue(key,MyTyke,data);\n} else {\n    data = ValkeyModule_ModuleTypeGetValue(key);\n}\n/* Do something with &#39;data&#39;... */\n</code></pre>\n<h2>Free method</h2>\n<p>As already mentioned, when Valkey needs to free a key holding a native type<br>value, it needs help from the module in order to release the memory. This<br>is the reason why we pass a <code>free</code> callback during the type registration:</p>\n<pre><code class=\"language-C\">typedef void (*ValkeyModuleTypeFreeFunc)(void *value);\n</code></pre>\n<p>A trivial implementation of the free method can be something like this,<br>assuming our data structure is composed of a single allocation:</p>\n<pre><code class=\"language-C\">void MyTypeFreeCallback(void *value) {\n    ValkeyModule_Free(value);\n}\n</code></pre>\n<p>However a more real world one will call some function that performs a more<br>complex memory reclaiming, by casting the void pointer to some structure<br>and freeing all the resources composing the value.</p>\n<h2>RDB load and save methods</h2>\n<p>The RDB saving and loading callbacks need to create (and load back) a<br>representation of the data type on disk. Valkey offers a high level API<br>that can automatically store inside the RDB file the following types:</p>\n<ul>\n<li>Unsigned 64 bit integers.</li>\n<li>Signed 64 bit integers.</li>\n<li>Doubles.</li>\n<li>Strings.</li>\n</ul>\n<p>It is up to the module to find a viable representation using the above base<br>types. However note that while the integer and double values are stored<br>and loaded in an architecture and <em>endianness</em> agnostic way, if you use<br>the raw string saving API to, for example, save a structure on disk, you<br>have to care those details yourself.</p>\n<p>This is the list of functions performing RDB saving and loading:</p>\n<pre><code class=\"language-C\">void ValkeyModule_SaveUnsigned(ValkeyModuleIO *io, uint64_t value);\nuint64_t ValkeyModule_LoadUnsigned(ValkeyModuleIO *io);\nvoid ValkeyModule_SaveSigned(ValkeyModuleIO *io, int64_t value);\nint64_t ValkeyModule_LoadSigned(ValkeyModuleIO *io);\nvoid ValkeyModule_SaveString(ValkeyModuleIO *io, ValkeyModuleString *s);\nvoid ValkeyModule_SaveStringBuffer(ValkeyModuleIO *io, const char *str, size_t len);\nValkeyModuleString *ValkeyModule_LoadString(ValkeyModuleIO *io);\nchar *ValkeyModule_LoadStringBuffer(ValkeyModuleIO *io, size_t *lenptr);\nvoid ValkeyModule_SaveDouble(ValkeyModuleIO *io, double value);\ndouble ValkeyModule_LoadDouble(ValkeyModuleIO *io);\n</code></pre>\n<p>The functions don&#39;t require any error checking from the module, that can<br>always assume calls succeed.</p>\n<p>As an example, imagine I&#39;ve a native type that implements an array of<br>double values, with the following structure:</p>\n<pre><code class=\"language-C\">struct double_array {\n    size_t count;\n    double *values;\n};\n</code></pre>\n<p>My <code>rdb_save</code> method may look like the following:</p>\n<pre><code class=\"language-C\">void DoubleArrayRDBSave(ValkeyModuleIO *io, void *ptr) {\n    struct dobule_array *da = ptr;\n    ValkeyModule_SaveUnsigned(io,da-&gt;count);\n    for (size_t j = 0; j &lt; da-&gt;count; j++)\n        ValkeyModule_SaveDouble(io,da-&gt;values[j]);\n}\n</code></pre>\n<p>What we did was to store the number of elements followed by each double<br>value. So when later we&#39;ll have to load the structure in the <code>rdb_load</code><br>method we&#39;ll do something like this:</p>\n<pre><code class=\"language-C\">void *DoubleArrayRDBLoad(ValkeyModuleIO *io, int encver) {\n    if (encver != DOUBLE_ARRAY_ENC_VER) {\n        /* We should actually log an error here, or try to implement\n           the ability to load older versions of our data structure. */\n        return NULL;\n    }\n\n    struct double_array *da;\n    da = ValkeyModule_Alloc(sizeof(*da));\n    da-&gt;count = ValkeyModule_LoadUnsigned(io);\n    da-&gt;values = ValkeyModule_Alloc(da-&gt;count * sizeof(double));\n    for (size_t j = 0; j &lt; da-&gt;count; j++)\n        da-&gt;values[j] = ValkeyModule_LoadDouble(io);\n    return da;\n}\n</code></pre>\n<p>The load callback just reconstruct back the data structure from the data<br>we stored in the RDB file.</p>\n<p>Note that while there is no error handling on the API that writes and reads<br>from disk, still the load callback can return NULL on errors in case what<br>it reads does not look correct. Valkey will just panic in that case.</p>\n<h2>AOF rewriting</h2>\n<pre><code class=\"language-C\">void ValkeyModule_EmitAOF(ValkeyModuleIO *io, const char *cmdname, const char *fmt, ...);\n</code></pre>\n<h2>Allocating memory</h2>\n<p>Modules data types should try to use <code>ValkeyModule_Alloc()</code> functions family<br>in order to allocate, reallocate and release heap memory used to implement the native data structures (see the other Valkey Modules documentation for detailed information).</p>\n<p>This is not just useful in order for Valkey to be able to account for the memory used by the module, but there are also more advantages:</p>\n<ul>\n<li>Valkey uses the <code>jemalloc</code> allocator, that often prevents fragmentation problems that could be caused by using the libc allocator.</li>\n<li>When loading strings from the RDB file, the native types API is able to return strings allocated directly with <code>ValkeyModule_Alloc()</code>, so that the module can directly link this memory into the data structure representation, avoiding a useless copy of the data.</li>\n</ul>\n<p>Even if you are using external libraries implementing your data structures, the<br>allocation functions provided by the module API is exactly compatible with<br><code>malloc()</code>, <code>realloc()</code>, <code>free()</code> and <code>strdup()</code>, so converting the libraries<br>in order to use these functions should be trivial.</p>\n<p>In case you have an external library that uses libc <code>malloc()</code>, and you want<br>to avoid replacing manually all the calls with the Valkey Modules API calls,<br>an approach could be to use simple macros in order to replace the libc calls<br>with the Valkey API calls. Something like this could work:</p>\n<pre><code class=\"language-C\">#define malloc ValkeyModule_Alloc\n#define realloc ValkeyModule_Realloc\n#define free ValkeyModule_Free\n#define strdup ValkeyModule_Strdup\n</code></pre>\n<p>However take in mind that mixing libc calls with Valkey API calls will result<br>into troubles and crashes, so if you replace calls using macros, you need to<br>make sure that all the calls are correctly replaced, and that the code with<br>the substituted calls will never, for example, attempt to call<br><code>ValkeyModule_Free()</code> with a pointer allocated using libc <code>malloc()</code>.</p>\n"
  },
  {
    "id": "notifications",
    "topicName": "Keyspace notifications",
    "description": "Monitor changes to Valkey keys and values in real time\n",
    "htmlContent": "<p>Keyspace notifications allow clients to subscribe to Pub/Sub channels in order<br>to receive events affecting the Valkey data set in some way.</p>\n<p>Examples of events that can be received are:</p>\n<ul>\n<li>All the commands affecting a given key.</li>\n<li>All the keys receiving an LPUSH operation.</li>\n<li>All the keys expiring in the database 0.</li>\n</ul>\n<p>Note: Valkey Pub/Sub is <em>fire and forget</em> that is, if your Pub/Sub client disconnects,<br>and reconnects later, all the events delivered during the time the client was<br>disconnected are lost.</p>\n<h3>Type of events</h3>\n<p>Keyspace notifications are implemented by sending two distinct types of events<br>for every operation affecting the Valkey data space. For instance a <code>DEL</code><br>operation targeting the key named <code>mykey</code> in database <code>0</code> will trigger<br>the delivering of two messages, exactly equivalent to the following two<br><code>PUBLISH</code> commands:</p>\n<pre><code>PUBLISH __keyspace@0__:mykey del\nPUBLISH __keyevent@0__:del mykey\n</code></pre>\n<p>The first channel listens to all the events targeting<br>the key <code>mykey</code> and the other channel listens only to <code>del</code> operation<br>events on the key <code>mykey</code></p>\n<p>The first kind of event, with <code>keyspace</code> prefix in the channel is called<br>a <strong>Key-space notification</strong>, while the second, with the <code>keyevent</code> prefix,<br>is called a <strong>Key-event notification</strong>.</p>\n<p>In the previous example a <code>del</code> event was generated for the key <code>mykey</code> resulting<br>in two messages:</p>\n<ul>\n<li>The Key-space channel receives as message the name of the event.</li>\n<li>The Key-event channel receives as message the name of the key.</li>\n</ul>\n<p>It is possible to enable only one kind of notification in order to deliver<br>just the subset of events we are interested in.</p>\n<h3>Configuration</h3>\n<p>By default keyspace event notifications are disabled because while not<br>very sensible the feature uses some CPU power. Notifications are enabled<br>using the <code>notify-keyspace-events</code> of valkey.conf or via the <strong>CONFIG SET</strong>.</p>\n<p>Setting the parameter to the empty string disables notifications.<br>In order to enable the feature a non-empty string is used, composed of multiple<br>characters, where every character has a special meaning according to the<br>following table:</p>\n<pre><code>K     Keyspace events, published with __keyspace@&lt;db&gt;__ prefix.\nE     Keyevent events, published with __keyevent@&lt;db&gt;__ prefix.\ng     Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ...\n$     String commands\nl     List commands\ns     Set commands\nh     Hash commands\nz     Sorted set commands\nt     Stream commands\nd     Module key type events\nx     Expired events (events generated every time a key expires)\ne     Evicted events (events generated when a key is evicted for maxmemory)\nm     Key miss events (events generated when a key that doesn&#39;t exist is accessed)\nn     New key events (Note: not included in the &#39;A&#39; class)\nA     Alias for &quot;g$lshztxed&quot;, so that the &quot;AKE&quot; string means all the events except &quot;m&quot; and &quot;n&quot;.\n</code></pre>\n<p>At least <code>K</code> or <code>E</code> should be present in the string, otherwise no event<br>will be delivered regardless of the rest of the string.</p>\n<p>For instance to enable just Key-space events for lists, the configuration<br>parameter must be set to <code>Kl</code>, and so forth.</p>\n<p>You can use the string <code>KEA</code> to enable most types of events.</p>\n<h3>Events generated by different commands</h3>\n<p>Different commands generate different kind of events according to the following list.</p>\n<ul>\n<li><code>DEL</code> generates a <code>del</code> event for every deleted key.</li>\n<li><code>RENAME</code> generates two events, a <code>rename_from</code> event for the source key, and a <code>rename_to</code> event for the destination key.</li>\n<li><code>MOVE</code> generates two events, a <code>move_from</code> event for the source key, and a <code>move_to</code> event for the destination key.</li>\n<li><code>COPY</code> generates a <code>copy_to</code> event.</li>\n<li><code>MIGRATE</code> generates a <code>del</code> event if the source key is removed.</li>\n<li><code>RESTORE</code> generates a <code>restore</code> event for the key.</li>\n<li><code>EXPIRE</code> and all its variants (<code>PEXPIRE</code>, <code>EXPIREAT</code>, <code>PEXPIREAT</code>) generate an <code>expire</code> event when called with a positive timeout (or a future timestamp). Note that when these commands are called with a negative timeout value or timestamp in the past, the key is deleted and only a <code>del</code> event is generated instead.</li>\n<li><code>SORT</code> generates a <code>sortstore</code> event when <code>STORE</code> is used to set a new key. If the resulting list is empty, and the <code>STORE</code> option is used, and there was already an existing key with that name, the result is that the key is deleted, so a <code>del</code> event is generated in this condition.</li>\n<li><code>SET</code> and all its variants (<code>SETEX</code>, <code>SETNX</code>,<code>GETSET</code>) generate <code>set</code> events. However <code>SETEX</code> will also generate an <code>expire</code> events.</li>\n<li><code>MSET</code> generates a separate <code>set</code> event for every key.</li>\n<li><code>SETRANGE</code> generates a <code>setrange</code> event.</li>\n<li><code>INCR</code>, <code>DECR</code>, <code>INCRBY</code>, <code>DECRBY</code> commands all generate <code>incrby</code> events.</li>\n<li><code>INCRBYFLOAT</code> generates an <code>incrbyfloat</code> events.</li>\n<li><code>APPEND</code> generates an <code>append</code> event.</li>\n<li><code>LPUSH</code> and <code>LPUSHX</code> generates a single <code>lpush</code> event, even in the variadic case.</li>\n<li><code>RPUSH</code> and <code>RPUSHX</code> generates a single <code>rpush</code> event, even in the variadic case.</li>\n<li><code>RPOP</code> generates an <code>rpop</code> event. Additionally a <code>del</code> event is generated if the key is removed because the last element from the list was popped.</li>\n<li><code>LPOP</code> generates an <code>lpop</code> event. Additionally a <code>del</code> event is generated if the key is removed because the last element from the list was popped.</li>\n<li><code>LINSERT</code> generates an <code>linsert</code> event.</li>\n<li><code>LSET</code> generates an <code>lset</code> event.</li>\n<li><code>LREM</code> generates an <code>lrem</code> event, and additionally a <code>del</code> event if the resulting list is empty and the key is removed.</li>\n<li><code>LTRIM</code> generates an <code>ltrim</code> event, and additionally a <code>del</code> event if the resulting list is empty and the key is removed.</li>\n<li><code>RPOPLPUSH</code> and <code>BRPOPLPUSH</code> generate an <code>rpop</code> event and an <code>lpush</code> event. In both cases the order is guaranteed (the <code>lpush</code> event will always be delivered after the <code>rpop</code> event). Additionally a <code>del</code> event will be generated if the resulting list is zero length and the key is removed.</li>\n<li><code>LMOVE</code> and <code>BLMOVE</code> generate an <code>lpop</code>/<code>rpop</code> event (depending on the wherefrom argument) and an <code>lpush</code>/<code>rpush</code> event (depending on the whereto argument). In both cases the order is guaranteed (the <code>lpush</code>/<code>rpush</code> event will always be delivered after the <code>lpop</code>/<code>rpop</code> event). Additionally a <code>del</code> event will be generated if the resulting list is zero length and the key is removed.</li>\n<li><code>HSET</code>, <code>HSETNX</code> and <code>HMSET</code> all generate a single <code>hset</code> event.</li>\n<li><code>HINCRBY</code> generates an <code>hincrby</code> event.</li>\n<li><code>HINCRBYFLOAT</code> generates an <code>hincrbyfloat</code> event.</li>\n<li><code>HDEL</code> generates a single <code>hdel</code> event, and an additional <code>del</code> event if the resulting hash is empty and the key is removed.</li>\n<li><code>SADD</code> generates a single <code>sadd</code> event, even in the variadic case.</li>\n<li><code>SREM</code> generates a single <code>srem</code> event, and an additional <code>del</code> event if the resulting set is empty and the key is removed.</li>\n<li><code>SMOVE</code> generates an <code>srem</code> event for the source key, and an <code>sadd</code> event for the destination key.</li>\n<li><code>SPOP</code> generates an <code>spop</code> event, and an additional <code>del</code> event if the resulting set is empty and the key is removed.</li>\n<li><code>SINTERSTORE</code>, <code>SUNIONSTORE</code>, <code>SDIFFSTORE</code> generate <code>sinterstore</code>, <code>sunionstore</code>, <code>sdiffstore</code> events respectively. In the special case the resulting set is empty, and the key where the result is stored already exists, a <code>del</code> event is generated since the key is removed.</li>\n<li><code>ZINCR</code> generates a <code>zincr</code> event.</li>\n<li><code>ZADD</code> generates a single <code>zadd</code> event even when multiple elements are added.</li>\n<li><code>ZREM</code> generates a single <code>zrem</code> event even when multiple elements are deleted. When the resulting sorted set is empty and the key is generated, an additional <code>del</code> event is generated.</li>\n<li><code>ZREMBYSCORE</code> generates a single <code>zrembyscore</code> event. When the resulting sorted set is empty and the key is generated, an additional <code>del</code> event is generated.</li>\n<li><code>ZREMBYRANK</code> generates a single <code>zrembyrank</code> event. When the resulting sorted set is empty and the key is generated, an additional <code>del</code> event is generated.</li>\n<li><code>ZDIFFSTORE</code>, <code>ZINTERSTORE</code> and <code>ZUNIONSTORE</code> respectively generate <code>zdiffstore</code>, <code>zinterstore</code> and <code>zunionstore</code> events. In the special case the resulting sorted set is empty, and the key where the result is stored already exists, a <code>del</code> event is generated since the key is removed.</li>\n<li><code>XADD</code> generates an <code>xadd</code> event, possibly followed an <code>xtrim</code> event when used with the <code>MAXLEN</code> subcommand.</li>\n<li><code>XDEL</code> generates a single <code>xdel</code> event even when multiple entries are deleted.</li>\n<li><code>XGROUP CREATE</code> generates an <code>xgroup-create</code> event.</li>\n<li><code>XGROUP CREATECONSUMER</code> generates an <code>xgroup-createconsumer</code> event.</li>\n<li><code>XGROUP DELCONSUMER</code> generates an <code>xgroup-delconsumer</code> event.</li>\n<li><code>XGROUP DESTROY</code> generates an <code>xgroup-destroy</code> event.</li>\n<li><code>XGROUP SETID</code> generates an <code>xgroup-setid</code> event.</li>\n<li><code>XSETID</code> generates an <code>xsetid</code> event.</li>\n<li><code>XTRIM</code> generates an <code>xtrim</code> event.</li>\n<li><code>PERSIST</code> generates a <code>persist</code> event if the expiry time associated with key has been successfully deleted.</li>\n<li>Every time a key with a time to live associated is removed from the data set because it expired, an <code>expired</code> event is generated.</li>\n<li>Every time a key is evicted from the data set in order to free memory as a result of the <code>maxmemory</code> policy, an <code>evicted</code> event is generated.</li>\n<li>Every time a new key is added to the data set, a <code>new</code> event is generated.</li>\n</ul>\n<p><strong>IMPORTANT</strong> all the commands generate events only if the target key is really modified. For instance an <code>SREM</code> deleting a non-existing element from a Set will not actually change the value of the key, so no event will be generated.</p>\n<p>If in doubt about how events are generated for a given command, the simplest<br>thing to do is to watch yourself:</p>\n<pre><code>$ valkey-cli config set notify-keyspace-events KEA\n$ valkey-cli --csv psubscribe &#39;__key*__:*&#39;\nReading messages... (press Ctrl-C to quit)\n&quot;psubscribe&quot;,&quot;__key*__:*&quot;,1\n</code></pre>\n<p>At this point use <code>valkey-cli</code> in another terminal to send commands to the<br>Valkey server and watch the events generated:</p>\n<pre><code>&quot;pmessage&quot;,&quot;__key*__:*&quot;,&quot;__keyspace@0__:foo&quot;,&quot;set&quot;\n&quot;pmessage&quot;,&quot;__key*__:*&quot;,&quot;__keyevent@0__:set&quot;,&quot;foo&quot;\n...\n</code></pre>\n<h3>Timing of expired events</h3>\n<p>Keys with a time to live associated are expired by Valkey in two ways:</p>\n<ul>\n<li>When the key is accessed by a command and is found to be expired.</li>\n<li>Via a background system that looks for expired keys in the background, incrementally, in order to be able to also collect keys that are never accessed.</li>\n</ul>\n<p>The <code>expired</code> events are generated when a key is accessed and is found to be expired by one of the above systems, as a result there are no guarantees that the Valkey server will be able to generate the <code>expired</code> event at the time the key time to live reaches the value of zero.</p>\n<p>If no command targets the key constantly, and there are many keys with a TTL associated, there can be a significant delay between the time the key time to live drops to zero, and the time the <code>expired</code> event is generated.</p>\n<p>Basically <code>expired</code> events <strong>are generated when the Valkey server deletes the key</strong> and not when the time to live theoretically reaches the value of zero.</p>\n<h3>Events in a cluster</h3>\n<p>Every node of a Valkey cluster generates events about its own subset of the keyspace as described above. However, unlike regular Pub/Sub communication in a cluster, events&#39; notifications <strong>are not</strong> broadcasted to all nodes. Put differently, keyspace events are node-specific. This means that to receive all keyspace events of a cluster, clients need to subscribe to each of the nodes.</p>\n"
  },
  {
    "id": "performance-on-cpu",
    "topicName": "CPU profiling",
    "description": "Performance engineering guide for on-CPU profiling and tracing\n",
    "htmlContent": "<h2>Filling the performance checklist</h2>\n<p>Valkey is developed with a great emphasis on performance. We do our best with<br>every release to make sure you&#39;ll experience a very stable and fast product. </p>\n<p>Nevertheless, if you&#39;re finding room to improve the efficiency of Valkey or<br>are pursuing a performance regression investigation you will need a concise<br>methodical way of monitoring and analyzing Valkey performance. </p>\n<p>To do so you can rely on different methodologies (some more suited than other<br>depending on the class of issues/analysis we intend to make). A curated list<br>of methodologies and their steps are enumerated by Brendan Greg at the<br><a href=\"https://www.brendangregg.com/methodology.html\">following link</a>. </p>\n<p>We recommend the Utilization Saturation and Errors (USE) Method for answering<br>the question of what is your bottleneck. Check the following mapping between<br>system resource, metric, and tools for a practical deep dive:<br><a href=\"https://www.brendangregg.com/USEmethod/use-rosetta.html\">USE method</a>. </p>\n<h3>Ensuring the CPU is your bottleneck</h3>\n<p>This guide assumes you&#39;ve followed one of the above methodologies to perform a<br>complete check of system health, and identified the bottleneck being the CPU.<br><strong>If you have identified that most of the time is spent blocked on I/O, locks,<br>timers, paging/swapping, etc., this guide is not for you</strong>. </p>\n<h3>Build Prerequisites</h3>\n<p>For a proper On-CPU analysis, Valkey (and any dynamically loaded library like<br>Valkey Modules) requires stack traces to be available to tracers, which you may<br>need to fix first. </p>\n<p>By default, Valkey is compiled with the <code>-O3</code> optimization flag (which we intent to keep<br>during profiling). This means that compiler optimizations are enabled which significantly<br>enhance the performance. Valkey is also compiled with the <code>-fno-omit-frame-pointer</code> flag<br>by default, ensuring that the frame pointer is preserved across function calls.<br>This combination allows for precise stack walking and call stack tracing,<br>which is essential for accurate profiling and debugging. Keeping the frame pointer<br>intact helps profiling tools like <code>perf</code>, <code>gdb</code>, and others correctly attribute on-CPU<br>time to deeper call stack frames, leading to more reliable insights into performance bottlenecks<br>and hotspots. This setup strikes a balance between maintaining a highly optimized executable<br>and ensuring that profiling and tracing tools provide accurate and actionable data.</p>\n<p>It&#39;s important that you ensure that:</p>\n<ul>\n<li>we still run with optimizations to get an accurate representation of production run times, meaning we will keep: <code>-O3</code></li>\n</ul>\n<p>You can do it as follows within valkey main repo:</p>\n<pre><code>$ make SERVER_CFLAGS=&quot;-g&quot;\n</code></pre>\n<h2>A set of instruments to identify performance regressions and/or potential <strong>on-CPU performance</strong> improvements</h2>\n<p>This document focuses specifically on <strong>on-CPU</strong> resource bottlenecks analysis,<br>meaning we&#39;re interested in understanding where threads are spending CPU cycles<br>while running on-CPU and, as importantly, whether those cycles are effectively<br>being used for computation or stalled waiting (not blocked!) for memory I/O,<br>and cache misses, etc.</p>\n<p>For that we will rely on toolkits (perf, bcc tools), and hardware specific PMCs<br>(Performance Monitoring Counters), to proceed with:</p>\n<ul>\n<li><p>Hotspot analysis (perf or bcc tools): to profile code execution and determine which functions are consuming the most time and thus are targets for optimization. We&#39;ll present two options to collect, report, and visualize hotspots either with perf or bcc/BPF tracing tools.</p>\n</li>\n<li><p>Call counts analysis: to count events including function calls, enabling us to correlate several calls/components at once, relying on bcc/BPF tracing tools.</p>\n</li>\n<li><p>Hardware event sampling: crucial for understanding CPU behavior, including memory I/O, stall cycles, and cache misses.</p>\n</li>\n</ul>\n<h3>Tool prerequisites</h3>\n<p>The following steps rely on Linux perf_events (aka <a href=\"https://man7.org/linux/man-pages/man1/perf.1.html\">&quot;perf&quot;</a>), <a href=\"https://github.com/iovisor/bcc\">bcc/BPF tracing tools</a>, and Brendan Greg’s <a href=\"https://github.com/brendangregg/FlameGraph\">FlameGraph repo</a>.</p>\n<p>We assume beforehand you have:</p>\n<ul>\n<li>Installed the perf tool on your system. Most Linux distributions will likely package this as a package related to the kernel. More information about the perf tool can be found at perf <a href=\"https://perf.wiki.kernel.org/\">wiki</a>.</li>\n<li>Followed the install <a href=\"https://github.com/iovisor/bcc/blob/master/INSTALL#installing-bcc\">bcc/BPF</a> instructions to install bcc toolkit on your machine.</li>\n<li>Cloned Brendan Greg’s <a href=\"https://github.com/brendangregg/FlameGraph\">FlameGraph repo</a> and made accessible the <code>difffolded.pl</code> and <code>flamegraph.pl</code> files, to generated the collapsed stack traces and Flame Graphs.</li>\n</ul>\n<h2>Hotspot analysis with perf or eBPF (stack traces sampling)</h2>\n<p>Profiling CPU usage by sampling stack traces at a timed interval is a fast and<br>easy way to identify performance-critical code sections (hotspots).</p>\n<h3>Sampling stack traces using perf</h3>\n<p>To profile both user- and kernel-level stacks of valkey-server for a specific<br>length of time, for example 60 seconds, at a sampling frequency of 999 samples<br>per second:</p>\n<pre><code>$ perf record -g --pid $(pgrep valkey-server) -F 999 -- sleep 60\n</code></pre>\n<h4>Displaying the recorded profile information using perf report</h4>\n<p>By default perf record will generate a perf.data file in the current working<br>directory. </p>\n<p>You can then report with a call-graph output (call chain, stack backtrace),<br>with a minimum call graph inclusion threshold of 0.5%, with:</p>\n<pre><code>$ perf report -g &quot;graph,0.5,caller&quot;\n</code></pre>\n<p>See the <a href=\"https://man7.org/linux/man-pages/man1/perf-report.1.html\">perf report</a><br>documentation for advanced filtering, sorting and aggregation capabilities.</p>\n<h4>Visualizing the recorded profile information using Flame Graphs</h4>\n<p><a href=\"https://www.brendangregg.com/flamegraphs.html\">Flame graphs</a> allow for a quick<br>and accurate visualization of frequent code-paths. They can be generated using<br>Brendan Greg&#39;s open source programs on <a href=\"https://github.com/brendangregg/FlameGraph\">github</a>,<br>which create interactive SVGs from folded stack files.</p>\n<p>Specifically, for perf we need to convert the generated perf.data into the<br>captured stacks, and fold each of them into single lines. You can then render<br>the on-CPU flame graph with:</p>\n<pre><code>$ perf script &gt; valkey.perf.stacks\n$ stackcollapse-perf.pl valkey.perf.stacks &gt; valkey.folded.stacks\n$ flamegraph.pl valkey.folded.stacks &gt; valkey.svg\n</code></pre>\n<p>By default, perf script will generate a perf.data file in the current working<br>directory. See the <a href=\"https://linux.die.net/man/1/perf-script\">perf script</a><br>documentation for advanced usage.</p>\n<p>See <a href=\"https://github.com/brendangregg/FlameGraph#options\">FlameGraph usage options</a><br>for more advanced stack trace visualizations (like the differential one).</p>\n<h4>Archiving and sharing recorded profile information</h4>\n<p>So that analysis of the perf.data contents can be possible on a machine other<br>than the one on which collection happened, you need to export along with the<br>perf.data file all object files with build-ids found in the record data file.<br>This can be easily done with the help of<br><a href=\"https://github.com/torvalds/linux/blob/master/tools/perf/perf-archive.sh\">perf-archive.sh</a><br>script:</p>\n<pre><code>$ perf-archive.sh perf.data\n</code></pre>\n<p>Now please run:</p>\n<pre><code>$ tar xvf perf.data.tar.bz2 -C ~/.debug\n</code></pre>\n<p>on the machine where you need to run <code>perf report</code>.</p>\n<h3>Sampling stack traces using bcc/BPF&#39;s profile</h3>\n<p>Similarly to perf, as of Linux kernel 4.9, BPF-optimized profiling is now fully<br>available with the promise of lower overhead on CPU (as stack traces are<br>frequency counted in kernel context) and disk I/O resources during profiling. </p>\n<p>Apart from that, and relying solely on bcc/BPF&#39;s profile tool, we have also<br>removed the perf.data and intermediate steps if stack traces analysis is our<br>main goal. You can use bcc&#39;s profile tool to output folded format directly, for<br>flame graph generation:</p>\n<pre><code>$ /usr/share/bcc/tools/profile -F 999 -f --pid $(pgrep valkey-server) --duration 60 &gt; valkey.folded.stacks\n</code></pre>\n<p>In that manner, we&#39;ve remove any preprocessing and can render the on-CPU flame<br>graph with a single command:</p>\n<pre><code>$ flamegraph.pl valkey.folded.stacks &gt; valkey.svg\n</code></pre>\n<h3>Visualizing the recorded profile information using Flame Graphs</h3>\n<h2>Call counts analysis with bcc/BPF</h2>\n<p>A function may consume significant CPU cycles either because its code is slow<br>or because it&#39;s frequently called. To answer at what rate functions are being<br>called, you can rely upon call counts analysis using BCC&#39;s <code>funccount</code> tool:</p>\n<pre><code>$ /usr/share/bcc/tools/funccount &#39;valkey-server:(call*|*Read*|*Write*)&#39; --pid $(pgrep valkey-server) --duration 60\nTracing 64 functions for &quot;valkey-server:(call*|*Read*|*Write*)&quot;... Hit Ctrl-C to end.\n\nFUNC                                    COUNT\ncall                                      334\nhandleClientsWithPendingWrites            388\nclientInstallWriteHandler                 388\npostponeClientRead                        514\nhandleClientsWithPendingReadsUsingThreads      735\nhandleClientsWithPendingWritesUsingThreads      735\nprepareClientToWrite                     1442\nDetaching...\n</code></pre>\n<p>The above output shows that, while tracing, the Valkey&#39;s call() function was<br>called 334 times, handleClientsWithPendingWrites() 388 times, etc.</p>\n<h2>Hardware event counting with Performance Monitoring Counters (PMCs)</h2>\n<p>Many modern processors contain a performance monitoring unit (PMU) exposing<br>Performance Monitoring Counters (PMCs). PMCs are crucial for understanding CPU<br>behavior, including memory I/O, stall cycles, and cache misses, and provide<br>low-level CPU performance statistics that aren&#39;t available anywhere else.</p>\n<p>The design and functionality of a PMU is CPU-specific and you should assess<br>your CPU supported counters and features by using <code>perf list</code>. </p>\n<p>To calculate the number of instructions per cycle, the number of micro ops<br>executed, the number of cycles during which no micro ops were dispatched, the<br>number stalled cycles on memory, including a per memory type stalls, for the<br>duration of 60s, specifically for the valkey-server process: </p>\n<pre><code>$ perf stat -e &quot;cpu-clock,cpu-cycles,instructions,uops_executed.core,uops_executed.stall_cycles,cache-references,cache-misses,cycle_activity.stalls_total,cycle_activity.stalls_mem_any,cycle_activity.stalls_l3_miss,cycle_activity.stalls_l2_miss,cycle_activity.stalls_l1d_miss&quot; --pid $(pgrep valkey-server) -- sleep 60\n\nPerformance counter stats for process id &#39;3038&#39;:\n\n  60046.411437      cpu-clock (msec)          #    1.001 CPUs utilized          \n  168991975443      cpu-cycles                #    2.814 GHz                      (36.40%)\n  388248178431      instructions              #    2.30  insn per cycle           (45.50%)\n  443134227322      uops_executed.core        # 7379.862 M/sec                    (45.51%)\n   30317116399      uops_executed.stall_cycles #  504.895 M/sec                    (45.51%)\n     670821512      cache-references          #   11.172 M/sec                    (45.52%)\n      23727619      cache-misses              #    3.537 % of all cache refs      (45.43%)\n   30278479141      cycle_activity.stalls_total #  504.251 M/sec                    (36.33%)\n   19981138777      cycle_activity.stalls_mem_any #  332.762 M/sec                    (36.33%)\n     725708324      cycle_activity.stalls_l3_miss #   12.086 M/sec                    (36.33%)\n    8487905659      cycle_activity.stalls_l2_miss #  141.356 M/sec                    (36.32%)\n   10011909368      cycle_activity.stalls_l1d_miss #  166.736 M/sec                    (36.31%)\n\n  60.002765665 seconds time elapsed\n</code></pre>\n<p>It&#39;s important to know that there are two very different ways in which PMCs can<br>be used (counting and sampling), and we&#39;ve focused solely on PMCs counting for<br>the sake of this analysis. Brendan Greg clearly explains it on the following<br><a href=\"https://www.brendangregg.com/blog/2017-05-04/the-pmcs-of-ec2.html\">link</a>.</p>\n"
  },
  {
    "id": "persistence",
    "topicName": "Persistence",
    "description": "How Valkey writes data to disk",
    "htmlContent": "<p>Persistence refers to the writing of data to durable storage, such as a solid-state disk (SSD). Valkey provides a range of persistence options. These include:</p>\n<ul>\n<li><strong>RDB</strong> (Valkey Database): RDB persistence performs point-in-time snapshots of your dataset at specified intervals.</li>\n<li><strong>AOF</strong> (Append Only File): AOF persistence logs every write operation received by the server. These operations can then be replayed again at server startup, reconstructing the original dataset. Commands are logged using the same format as the Valkey protocol itself.</li>\n<li><strong>No persistence</strong>: You can disable persistence completely. This is sometimes used when caching.</li>\n<li><strong>RDB + AOF</strong>: You can also combine both AOF and RDB in the same instance.</li>\n</ul>\n<p>To learn more about how to evaluate your Valkey persistence strategy, read on.</p>\n<h2>RDB advantages</h2>\n<ul>\n<li>RDB is a very compact single-file point-in-time representation of your Valkey data. RDB files are perfect for backups. For instance you may want to archive your RDB files every hour for the latest 24 hours, and to save an RDB snapshot every day for 30 days. This allows you to easily restore different versions of the data set in case of disasters.</li>\n<li>RDB is very good for disaster recovery, being a single compact file that can be transferred to far data centers, or onto Amazon S3 (possibly encrypted).</li>\n<li>RDB maximizes Valkey performances since the only work the Valkey parent process needs to do in order to persist is forking a child that will do all the rest. The parent process will never perform disk I/O or alike.</li>\n<li>RDB allows faster restarts with big datasets compared to AOF.</li>\n<li>On replicas, RDB supports <a href=\"replication#partial-resynchronizations-after-restarts-and-failovers\">partial resynchronizations after restarts and failovers</a>.</li>\n</ul>\n<h2>RDB disadvantages</h2>\n<ul>\n<li>RDB is NOT good if you need to minimize the chance of data loss in case Valkey stops working (for example after a power outage). You can configure different <em>save points</em> where an RDB is produced (for instance after at least five minutes and 100 writes against the data set, you can have multiple save points). However you&#39;ll usually create an RDB snapshot every five minutes or more, so in case of Valkey stopping working without a correct shutdown for any reason you should be prepared to lose the latest minutes of data.</li>\n<li>RDB needs to fork() often in order to persist on disk using a child process. fork() can be time consuming if the dataset is big, and may result in Valkey stopping serving clients for some milliseconds or even for one second if the dataset is very big and the CPU performance is not great. AOF also needs to fork() but less frequently and you can tune how often you want to rewrite your logs without any trade-off on durability.</li>\n</ul>\n<h2>AOF advantages</h2>\n<ul>\n<li>Using AOF Valkey is much more durable: you can have different fsync policies: no fsync at all, fsync every second, fsync at every query. With the default policy of fsync every second, write performance is still great. fsync is performed using a background thread and the main thread will try hard to perform writes when no fsync is in progress, so you can only lose one second worth of writes.</li>\n<li>The AOF log is an append-only log, so there are no seeks, nor corruption problems if there is a power outage. Even if the log ends with a half-written command for some reason (disk full or other reasons) the valkey-check-aof tool is able to fix it easily.</li>\n<li>Valkey is able to automatically rewrite the AOF in background when it gets too big. The rewrite is completely safe as while Valkey continues appending to the old file, a completely new one is produced with the minimal set of operations needed to create the current data set, and once this second file is ready Valkey switches the two and starts appending to the new one.</li>\n<li>AOF contains a log of all the operations one after the other in an easy to understand and parse format. You can even easily export an AOF file. For instance even if you&#39;ve accidentally flushed everything using the <code>FLUSHALL</code> command, as long as no rewrite of the log was performed in the meantime, you can still save your data set just by stopping the server, removing the latest command, and restarting Valkey again.</li>\n</ul>\n<h2>AOF disadvantages</h2>\n<ul>\n<li>AOF files are usually bigger than the equivalent RDB files for the same dataset.</li>\n<li>AOF can be slower than RDB depending on the exact fsync policy. In general with fsync set to <em>every second</em> performance is still very high, and with fsync disabled it should be exactly as fast as RDB even under high load. Still RDB is able to provide more guarantees about the maximum latency even in the case of a huge write load.</li>\n</ul>\n<h2>Ok, so what should I use?</h2>\n<p>The general indication you should use both persistence methods is if<br>you want a degree of data safety comparable to what PostgreSQL can provide you.</p>\n<p>If you care a lot about your data, but still can live with a few minutes of<br>data loss in case of disasters, you can simply use RDB alone.</p>\n<p>There are many users using AOF alone, but we discourage it since to have an<br>RDB snapshot from time to time is a great idea for doing database backups,<br>for faster restarts, and in the event of bugs in the AOF engine.</p>\n<p>The following sections will illustrate a few more details about the two persistence models.</p>\n<h2>Snapshotting</h2>\n<p>By default Valkey saves snapshots of the dataset on disk, in a binary<br>file called <code>dump.rdb</code>. You can configure Valkey to have it save the<br>dataset every N seconds if there are at least M changes in the dataset,<br>or you can manually call the <code>SAVE</code> or <code>BGSAVE</code> commands.</p>\n<p>For example, this configuration will make Valkey automatically dump the<br>dataset to disk every 60 seconds if at least 1000 keys changed:</p>\n<pre><code>save 60 1000\n</code></pre>\n<p>This strategy is known as <em>snapshotting</em>.</p>\n<h2>No persistence</h2>\n<p>If you prefer <strong>not</strong> to have persistence (for example when using a Valkey instance solely as a cache) that is also a possibility.</p>\n<p>RDB snapshotting is enabled by default. To disable it, set the <code>save</code> configuration parameter to the empty string <code>&quot;&quot;</code> and remove any excess <code>save</code> lines that are present in the current configuration file.</p>\n<pre><code>save &quot;&quot;\n</code></pre>\n<p>Alternatively, you can also use the <code>--save &quot;&quot;</code> argument on the <code>valkey-server</code> binary.</p>\n<h3>How it works</h3>\n<p>Whenever Valkey needs to dump the dataset to disk, this is what happens:</p>\n<ul>\n<li><p>Valkey <a href=\"https://linux.die.net/man/2/fork\">forks</a>. We now have a child<br>and a parent process.</p>\n</li>\n<li><p>The child starts to write the dataset to a temporary RDB file.</p>\n</li>\n<li><p>When the child is done writing the new RDB file, it replaces the old<br>one.</p>\n</li>\n</ul>\n<p>This method allows Valkey to benefit from copy-on-write semantics.</p>\n<h2>Append-only file</h2>\n<p>Snapshotting is not very durable. If your computer running Valkey stops,<br>your power line fails, or you accidentally <code>kill -9</code> your instance, the<br>latest data written to Valkey will be lost.  While this may not be a big<br>deal for some applications, there are use cases for full durability, and<br>in these cases Valkey snapshotting alone is not a viable option.</p>\n<p>The <em>append-only file</em> is an alternative, fully-durable strategy for<br>Valkey.</p>\n<p>You can turn on the AOF in your configuration file:</p>\n<pre><code>appendonly yes\n</code></pre>\n<p>From now on, every time Valkey receives a command that changes the<br>dataset (e.g. <code>SET</code>) it will append it to the AOF.  When you restart<br>Valkey it will re-play the AOF to rebuild the state.</p>\n<p>Valkey uses a multi part AOF mechanism.<br>That is, the original single AOF file is split into base file (at most one) and incremental files (there may be more than one).<br>The base file represents an initial (RDB or AOF format) snapshot of the data present when the AOF is <a href=\"#log-rewriting\">rewritten</a>.<br>The incremental files contains incremental changes since the last base AOF file was created. All these files are put in a separate directory and are tracked by a manifest file.</p>\n<h3>Log rewriting</h3>\n<p>The AOF gets bigger and bigger as write operations are<br>performed.  For example, if you are incrementing a counter 100 times,<br>you&#39;ll end up with a single key in your dataset containing the final<br>value, but 100 entries in your AOF. 99 of those entries are not needed<br>to rebuild the current state.</p>\n<p>The rewrite is completely safe.<br>While Valkey continues appending to the old file,<br>a completely new one is produced with the minimal set of operations needed to create the current data set,<br>and once this second file is ready Valkey switches the two and starts appending to the new one.</p>\n<p>Valkey supports an interesting feature: it is able to rebuild the AOF in the background without interrupting service to clients.<br>Whenever you issue a <code>BGREWRITEAOF</code>, Valkey will write the shortest sequence of commands needed to rebuild the current dataset in memory.<br>Valkey will automatically trigger log rewriting automatically (see the example configuration file for more information).</p>\n<p>When an AOF rewrite is scheduled, the Valkey parent process opens a new incremental AOF file to continue writing.<br>The child process executes the rewrite logic and generates a new base AOF.<br>Valkey will use a temporary manifest file to track the newly generated base file and incremental file.<br>When they are ready, Valkey will perform an atomic replacement operation to make this temporary manifest file take effect.<br>In order to avoid the problem of creating many incremental files in case of repeated failures and retries of an AOF rewrite,<br>Valkey introduces an AOF rewrite limiting mechanism to ensure that failed AOF rewrites are retried at a slower and slower rate.</p>\n<h3>How durable is the append only file?</h3>\n<p>You can configure how many times Valkey will<br><a href=\"https://linux.die.net/man/2/fsync\"><code>fsync</code></a> data on disk. There are<br>three options:</p>\n<ul>\n<li><code>appendfsync always</code>: <code>fsync</code> every time new commands are appended to the AOF. Very very slow, very safe. Note that the commands are appended to the AOF after a batch of commands from multiple clients or a pipeline are executed, so it means a single write and a single fsync (before sending the replies).</li>\n<li><code>appendfsync everysec</code>: <code>fsync</code> every second. Fast enough and you may lose 1 second of data if there is a disaster.</li>\n<li><code>appendfsync no</code>: Never <code>fsync</code>, just put your data in the hands of the Operating System. The faster and less safe method. Normally Linux will flush data every 30 seconds with this configuration, but it&#39;s up to the kernel&#39;s exact tuning.</li>\n</ul>\n<p>The suggested (and default) policy is to <code>fsync</code> every second. It is<br>both fast and relatively safe. The <code>always</code> policy is very slow in<br>practice, but it supports group commit, so if there are multiple parallel<br>writes Valkey will try to perform a single <code>fsync</code> operation.</p>\n<h3>What should I do if my AOF gets truncated?</h3>\n<p>It is possible the server crashed while writing the AOF file, or the<br>volume where the AOF file is stored was full at the time of writing. When this happens the<br>AOF still contains consistent data representing a given point-in-time version<br>of the dataset (that may be old up to one second with the default AOF fsync<br>policy), but the last command in the AOF could be truncated.<br>The latest major versions of Valkey will be able to load the AOF anyway, just<br>discarding the last non well formed command in the file. In this case the<br>server will emit a log like the following:</p>\n<pre><code>* Reading RDB preamble from AOF file...\n* Reading the remaining AOF tail...\n# !!! Warning: short read while loading the AOF file !!!\n# !!! Truncating the AOF at offset 439 !!!\n# AOF loaded anyway because aof-load-truncated is enabled\n</code></pre>\n<p>You can change the default configuration to force Valkey to stop in such<br>cases if you want, but the default configuration is to continue regardless of<br>the fact the last command in the file is not well-formed, in order to guarantee<br>availability after a restart.</p>\n<p>Older versions of Valkey may not recover, and may require the following steps:</p>\n<ul>\n<li><p>Make a backup copy of your AOF file.</p>\n</li>\n<li><p>Fix the original file using the <code>valkey-check-aof</code> tool that ships with Valkey:</p>\n<pre><code>$ valkey-check-aof --fix &lt;filename&gt;\n</code></pre>\n</li>\n<li><p>Optionally use <code>diff -u</code> to check what is the difference between two files.</p>\n</li>\n<li><p>Restart the server with the fixed file.</p>\n</li>\n</ul>\n<h3>What should I do if my AOF gets corrupted?</h3>\n<p>If the AOF file is not just truncated, but corrupted with invalid byte<br>sequences in the middle, things are more complex. Valkey will complain<br>at startup and will abort:</p>\n<pre><code>* Reading the remaining AOF tail...\n# Bad file format reading the append only file: make a backup of your AOF file, then use ./valkey-check-aof --fix &lt;filename&gt;\n</code></pre>\n<p>The best thing to do is to run the <code>valkey-check-aof</code> utility, initially without<br>the <code>--fix</code> option, then understand the problem, jump to the given<br>offset in the file, and see if it is possible to manually repair the file:<br>The AOF uses the same format of the Valkey protocol and is quite simple to fix<br>manually. Otherwise it is possible to let the utility fix the file for us, but<br>in that case all the AOF portion from the invalid part to the end of the<br>file may be discarded, leading to a massive amount of data loss if the<br>corruption happened to be in the initial part of the file.</p>\n<h3>How it works</h3>\n<p>Log rewriting uses the same copy-on-write trick already in use for<br>snapshotting.  This is how it works:</p>\n<p><strong>Valkey multi-part AOF</strong></p>\n<ul>\n<li><p>Valkey <a href=\"https://linux.die.net/man/2/fork\">forks</a>, so now we have a child<br>and a parent process.</p>\n</li>\n<li><p>The child starts writing the new base AOF in a temporary file.</p>\n</li>\n<li><p>The parent opens a new increments AOF file to continue writing updates.<br>If the rewriting fails, the old base and increment files (if there are any) plus this newly opened increment file represent the complete updated dataset,<br>so we are safe.</p>\n</li>\n<li><p>When the child is done rewriting the base file, the parent gets a signal,<br>and uses the newly opened increment file and child generated base file to build a temp manifest,<br>and persist it.</p>\n</li>\n<li><p>Profit! Now Valkey does an atomic exchange of the manifest files so that the result of this AOF rewrite takes effect. Valkey also cleans up the old base file and any unused increment files.</p>\n</li>\n</ul>\n<h3>How I can switch to AOF, if I&#39;m currently using dump.rdb snapshots?</h3>\n<p>If you want to enable AOF in a server that is currently using RDB snapshots, you need to convert the data by enabling AOF via CONFIG command on the live server first.</p>\n<p><strong>IMPORTANT:</strong> not following this procedure (e.g. just changing the config and restarting the server) can result in data loss!</p>\n<p>Preparations:</p>\n<ul>\n<li>Make a backup of your latest dump.rdb file.</li>\n<li>Transfer this backup to a safe place.</li>\n</ul>\n<p>Switch to AOF on live database:</p>\n<ul>\n<li>Enable AOF: <code>valkey-cli config set appendonly yes</code></li>\n<li>Optionally disable RDB: <code>valkey-cli config set save &quot;&quot;</code></li>\n<li>Make sure writes are appended to the append only file correctly.</li>\n<li><strong>IMPORTANT:</strong> Update your <code>valkey.conf</code> (potentially through <code>CONFIG REWRITE</code>) and ensure that it matches the configuration above.<br>If you forget this step, when you restart the server, the configuration changes will be lost and the server will start again with the old configuration, resulting in a loss of your data.</li>\n</ul>\n<p>Next time you restart the server:</p>\n<ul>\n<li>Before restarting the server, wait for AOF rewrite to finish persisting the data.<br>You can do that by watching <code>INFO persistence</code>, waiting for <code>aof_rewrite_in_progress</code> and <code>aof_rewrite_scheduled</code> to be <code>0</code>, and validating that <code>aof_last_bgrewrite_status</code> is <code>ok</code>.</li>\n<li>After restarting the server, check that your database contains the same number of keys it contained previously.</li>\n</ul>\n<h2>Interactions between AOF and RDB persistence</h2>\n<p>Valkey makes sure to avoid triggering an AOF rewrite when an RDB<br>snapshotting operation is already in progress, or allowing a <code>BGSAVE</code> while the<br>AOF rewrite is in progress. This prevents two Valkey background processes<br>from doing heavy disk I/O at the same time.</p>\n<p>When snapshotting is in progress and the user explicitly requests a log<br>rewrite operation using <code>BGREWRITEAOF</code> the server will reply with an OK<br>status code telling the user the operation is scheduled, and the rewrite<br>will start once the snapshotting is completed.</p>\n<p>In the case both AOF and RDB persistence are enabled and Valkey restarts the<br>AOF file will be used to reconstruct the original dataset since it is<br>guaranteed to be the most complete.</p>\n<h2>Backing up Valkey data</h2>\n<p>Before starting this section, make sure to read the following sentence: <strong>Make Sure to Backup Your Database</strong>. Disks break, instances in the cloud disappear, and so forth: no backups means huge risk of data disappearing into /dev/null.</p>\n<p>Valkey is very data backup friendly since you can copy RDB files while the<br>database is running: the RDB is never modified once produced, and while it<br>gets produced it uses a temporary name and is renamed into its final destination<br>atomically using rename(2) only when the new snapshot is complete.</p>\n<p>This means that copying the RDB file is completely safe while the server is<br>running. This is what we suggest:</p>\n<ul>\n<li>Create a cron job in your server creating hourly snapshots of the RDB file in one directory, and daily snapshots in a different directory.</li>\n<li>Every time the cron script runs, make sure to call the <code>find</code> command to make sure too old snapshots are deleted: for instance you can take hourly snapshots for the latest 48 hours, and daily snapshots for one or two months. Make sure to name the snapshots with date and time information.</li>\n<li>At least one time every day make sure to transfer an RDB snapshot <em>outside your data center</em> or at least <em>outside the physical machine</em> running your Valkey instance.</li>\n</ul>\n<h3>Backing up AOF persistence</h3>\n<p>If you run a Valkey instance with only AOF persistence enabled, you can still perform backups.<br>AOF files are split into multiple files which reside in a single directory determined by the <code>appenddirname</code> configuration.<br>During normal operation all you need to do is copy/tar the files in this directory to achieve a backup. However, if this is done during a <a href=\"#log-rewriting\">rewrite</a>, you might end up with an invalid backup.<br>To work around this you must disable AOF rewrites during the backup:</p>\n<ol>\n<li>Turn off automatic rewrites with<br/><br><code>CONFIG SET</code> <code>auto-aof-rewrite-percentage 0</code><br/><br>Make sure you don&#39;t manually start a rewrite (using <code>BGREWRITEAOF</code>) during this time.</li>\n<li>Check there&#39;s no current rewrite in progress using<br/><br><code>INFO</code> <code>persistence</code><br/><br>and verifying <code>aof_rewrite_in_progress</code> is 0. If it&#39;s 1, then you&#39;ll need to wait for the rewrite to complete.</li>\n<li>Now you can safely copy the files in the <code>appenddirname</code> directory.</li>\n<li>Re-enable rewrites when done:<br/><br><code>CONFIG SET</code> <code>auto-aof-rewrite-percentage &lt;prev-value&gt;</code></li>\n</ol>\n<p><strong>Note:</strong> If you want to minimize the time AOF rewrites are disabled you may create hard links to the files in <code>appenddirname</code> (in step 3 above) and then re-enable rewrites (step 4) after the hard links are created.<br>Now you can copy/tar the hardlinks and delete them when done. This works because Valkey guarantees that it<br>only appends to files in this directory, or completely replaces them if necessary, so the content should be<br>consistent at any given point in time.</p>\n<p><strong>Note:</strong> If you want to handle the case of the server being restarted during the backup and make sure no rewrite will automatically start after the restart you can change step 1 above to also persist the updated configuration via <code>CONFIG REWRITE</code>.<br>Just make sure to re-enable automatic rewrites when done (step 4) and persist it with another <code>CONFIG REWRITE</code>.</p>\n<h2>Disaster recovery</h2>\n<p>Disaster recovery in the context of Valkey is basically the same story as<br>backups, plus the ability to transfer those backups in many different external<br>data centers. This way data is secured even in the case of some catastrophic<br>event affecting the main data center where Valkey is running and producing its<br>snapshots.</p>\n<p>We&#39;ll review the most interesting disaster recovery techniques<br>that don&#39;t have too high costs.</p>\n<ul>\n<li>Amazon S3 and other similar services are a good way for implementing your disaster recovery system. Simply transfer your daily or hourly RDB snapshot to S3 in an encrypted form. You can encrypt your data using <code>gpg -c</code> (in symmetric encryption mode). Make sure to store your password in many different safe places (for instance give a copy to the most important people of your organization). It is recommended to use multiple storage services for improved data safety.</li>\n<li>Transfer your snapshots using SCP (part of SSH) to far servers. This is a fairly simple and safe route: get a small VPS in a place that is very far from you, install ssh there, and generate a ssh client key without passphrase, then add it in the <code>authorized_keys</code> file of your small VPS. You are ready to transfer backups in an automated fashion. Get at least two VPS in two different providers<br>for best results.</li>\n</ul>\n<p>It is important to understand that this system can easily fail if not<br>implemented in the right way. At least, make absolutely sure that after the<br>transfer is completed you are able to verify the file size (that should match<br>the one of the file you copied) and possibly the SHA1 digest, if you are using<br>a VPS.</p>\n<p>You also need some kind of independent alert system if the transfer of fresh<br>backups is not working for some reason.</p>\n"
  },
  {
    "id": "pipelining",
    "topicName": "Pipelining",
    "description": "How to optimize round-trip times by batching Valkey commands",
    "htmlContent": "<p>Valkey pipelining is a technique for improving performance by issuing multiple commands at once without waiting for the response to each individual command. Pipelining is supported by most Valkey clients. This document describes the problem that pipelining is designed to solve and how pipelining works in Valkey.</p>\n<h2>Request/Response protocols and round-trip time (RTT)</h2>\n<p>Valkey is a TCP server using the client-server model and what is called a <em>Request/Response</em> protocol.</p>\n<p>This means that usually a request is accomplished with the following steps:</p>\n<ul>\n<li>The client sends a query to the server, and reads from the socket, usually in a blocking way, for the server response.</li>\n<li>The server processes the command and sends the response back to the client.</li>\n</ul>\n<p>So for instance a four commands sequence is something like this:</p>\n<ul>\n<li><em>Client:</em> INCR X</li>\n<li><em>Server:</em> 1</li>\n<li><em>Client:</em> INCR X</li>\n<li><em>Server:</em> 2</li>\n<li><em>Client:</em> INCR X</li>\n<li><em>Server:</em> 3</li>\n<li><em>Client:</em> INCR X</li>\n<li><em>Server:</em> 4</li>\n</ul>\n<p>Clients and Servers are connected via a network link.<br>Such a link can be very fast (a loopback interface) or very slow (a connection established over the Internet with many hops between the two hosts).<br>Whatever the network latency is, it takes time for the packets to travel from the client to the server, and back from the server to the client to carry the reply.</p>\n<p>This time is called RTT (Round Trip Time).<br>It&#39;s easy to see how this can affect performance when a client needs to perform many requests in a row (for instance adding many elements to the same list, or populating a database with many keys).<br>For instance if the RTT time is 250 milliseconds (in the case of a very slow link over the Internet), even if the server is able to process 100k requests per second, we&#39;ll be able to process at max four requests per second.</p>\n<p>If the interface used is a loopback interface, the RTT is much shorter, typically sub-millisecond, but even this will add up to a lot if you need to perform many writes in a row.</p>\n<p>Fortunately there is a way to improve this use case.</p>\n<h2>Valkey Pipelining</h2>\n<p>A Request/Response server can be implemented so that it is able to process new requests even if the client hasn&#39;t already read the old responses.<br>This way it is possible to send <em>multiple commands</em> to the server without waiting for the replies at all, and finally read the replies in a single step.</p>\n<p>This is called pipelining, and is a technique widely in use for many decades.<br>For instance many POP3 protocol implementations already support this feature, dramatically speeding up the process of downloading new emails from the server.</p>\n<p>Valkey has supported pipelining since its early days, so whatever version you are running, you can use pipelining with Valkey.<br>This is an example using the raw netcat utility:</p>\n<pre><code class=\"language-bash\">$ (printf &quot;PING\\r\\nPING\\r\\nPING\\r\\n&quot;; sleep 1) | nc localhost 6379\n+PONG\n+PONG\n+PONG\n</code></pre>\n<p>This time we don&#39;t pay the cost of RTT for every call, but just once for the three commands.</p>\n<p>To be explicit, with pipelining the order of operations of our very first example will be the following:</p>\n<ul>\n<li><em>Client:</em> INCR X</li>\n<li><em>Client:</em> INCR X</li>\n<li><em>Client:</em> INCR X</li>\n<li><em>Client:</em> INCR X</li>\n<li><em>Server:</em> 1</li>\n<li><em>Server:</em> 2</li>\n<li><em>Server:</em> 3</li>\n<li><em>Server:</em> 4</li>\n</ul>\n<blockquote>\n<p><strong>IMPORTANT NOTE</strong>: While the client sends commands using pipelining, the server will be forced to queue the replies, using memory. So if you need to send a lot of commands with pipelining, it is better to send them as batches each containing a reasonable number, for instance 10k commands, read the replies, and then send another 10k commands again, and so forth. The speed will be nearly the same, but the additional memory used will be at most the amount needed to queue the replies for these 10k commands.</p>\n</blockquote>\n<h2>It&#39;s not just a matter of RTT</h2>\n<p>Pipelining is not just a way to reduce the latency cost associated with the<br>round trip time, it actually greatly improves the number of operations<br>you can perform per second in a given Valkey server.<br>This is because without using pipelining, serving each command is very cheap from<br>the point of view of accessing the data structures and producing the reply,<br>but it is very costly from the point of view of doing the socket I/O. This<br>involves calling the <code>read()</code> and <code>write()</code> syscall, that means going from user<br>land to kernel land.<br>The context switch is a huge speed penalty.</p>\n<p>When pipelining is used, many commands are usually read with a single <code>read()</code><br>system call, and multiple replies are delivered with a single <code>write()</code> system<br>call. Consequently, the number of total queries performed per second<br>initially increases almost linearly with longer pipelines, and eventually<br>reaches 10 times the baseline obtained without pipelining, as shown in this figure.</p>\n<p><img src=\"pipeline_iops.png\" alt=\"Pipeline size and IOPs\"></p>\n<h2>A real world code example</h2>\n<p>In the following benchmark we&#39;ll use a Ruby client, supporting pipelining, to test the speed improvement due to pipelining:</p>\n<pre><code class=\"language-ruby\">require &#39;rubygems&#39;\nrequire &#39;redis&#39;\n\ndef bench(descr)\n  start = Time.now\n  yield\n  puts &quot;#{descr} #{Time.now - start} seconds&quot;\nend\n\ndef without_pipelining\n  r = Redis.new\n  10_000.times do\n    r.ping\n  end\nend\n\ndef with_pipelining\n  r = Redis.new\n  r.pipelined do\n    10_000.times do\n      r.ping\n    end\n  end\nend\n\nbench(&#39;without pipelining&#39;) do\n  without_pipelining\nend\nbench(&#39;with pipelining&#39;) do\n  with_pipelining\nend\n</code></pre>\n<p>Running the above simple script yields the following figures on my MacOS system, running over the loopback interface, where pipelining will provide the smallest improvement as the RTT is already pretty low:</p>\n<pre><code>without pipelining 1.185238 seconds\nwith pipelining 0.250783 seconds\n</code></pre>\n<p>As you can see, using pipelining, we improved the transfer by a factor of five.</p>\n<h2>Pipelining vs Scripting</h2>\n<p>Using <a href=\"../commands/eval\">Valkey scripting</a>, a number of use cases for pipelining can be addressed more efficiently using scripts that perform a lot of the work needed at the server side.<br>A big advantage of scripting is that it is able to both read and write data with minimal latency, making operations like <em>read, compute, write</em> very fast (pipelining can&#39;t help in this scenario since the client needs the reply of the read command before it can call the write command).</p>\n<p>Sometimes the application may also want to send <code>EVAL</code> or <code>EVALSHA</code> commands in a pipeline.<br>This is entirely possible and Valkey explicitly supports it with the <a href=\"../commands/script-load\">SCRIPT LOAD</a> command (it guarantees that <code>EVALSHA</code> can be called without the risk of failing).</p>\n<h2>Appendix: Why are busy loops slow even on the loopback interface?</h2>\n<p>Even with all the background covered in this page, you may still wonder why<br>a Valkey benchmark like the following (in pseudo code), is slow even when<br>executed in the loopback interface, when the server and the client are running<br>in the same physical machine:</p>\n<pre><code class=\"language-sh\">FOR-ONE-SECOND:\n    Valkey.SET(&quot;foo&quot;,&quot;bar&quot;)\nEND\n</code></pre>\n<p>After all, if both the Valkey process and the benchmark are running in the same<br>box, isn&#39;t it just copying messages in memory from one place to another without<br>any actual latency or networking involved?</p>\n<p>The reason is that processes in a system are not always running, actually it is<br>the kernel scheduler that lets the process run.<br>So, for instance, when the benchmark is allowed to run, it reads the reply from the Valkey server (related to the last command executed), and writes a new command.<br>The command is now in the loopback interface buffer, but in order to be read by the server, the kernel should schedule the server process (currently blocked in a system call)<br>to run, and so forth.<br>So in practical terms the loopback interface still involves network-like latency, because of how the kernel scheduler works.</p>\n<p>Basically a busy loop benchmark is the silliest thing that can be done when<br>metering performances on a networked server. The wise thing is just avoiding<br>benchmarking in this way.</p>\n"
  },
  {
    "id": "problems",
    "topicName": "Troubleshooting Valkey",
    "description": "Problems with Valkey? Start here.",
    "htmlContent": "<p>This page tries to help you with what to do if you have issues with Valkey. Part of the Valkey project is helping people that are experiencing problems because we don&#39;t like to leave people alone with their issues.</p>\n<ul>\n<li>If you have <strong>latency problems</strong> with Valkey, that in some way appears to be idle for some time, read our <a href=\"latency\">Valkey latency troubleshooting guide</a>.</li>\n<li>Valkey stable releases are usually very reliable, however in the rare event you are <strong>experiencing crashes</strong> the developers can help a lot more if you provide debugging information. Please read our <a href=\"debugging\">Debugging Valkey guide</a>.</li>\n<li>We have a long history of users experiencing crashes with Valkey that actually turned out to be servers with <strong>broken RAM</strong>. Please test your RAM using <strong>valkey-server --test-memory</strong> in case Valkey is not stable in your system. Valkey built-in memory test is fast and reasonably reliable, but if you can you should reboot your server and use <a href=\"https://memtest86.com\">memtest86</a>.</li>\n</ul>\n"
  },
  {
    "id": "programmability",
    "topicName": "Programmability",
    "description": "Extending Valkey with Lua and Valkey Functions\n",
    "htmlContent": "<p>Valkey provides a programming interface that lets you execute custom scripts on the server itself.<br>You can use <a href=\"functions-intro\">Functions</a> to create, manage and run scripts.<br>You can also use <a href=\"eval-intro\">Lua scripting with the EVAL command</a> to program the server.</p>\n<h2>Background</h2>\n<p>Valkey is a <em>&quot;domain-specific language for abstract data types&quot;</em>.<br>The language that Valkey speaks consists of its <a href=\"../commands/\">commands</a>.<br>Most the commands specialize at manipulating core <a href=\"data-types\">data types</a> in different ways.<br>In many cases, these commands provide all the functionality that a developer requires for managing application data in Valkey.</p>\n<p>The term <strong>programmability</strong> in Valkey means having the ability to execute arbitrary user-defined logic by the server.<br>We refer to such pieces of logic as <strong>scripts</strong>.<br>In our case, scripts enable processing the data where it lives, a.k.a <em>data locality</em>.<br>Furthermore, the responsible embedding of programmatic workflows in the Valkey server can help in reducing network traffic and improving overall performance.<br>Developers can use this capability for implementing robust, application-specific APIs.<br>Such APIs can encapsulate business logic and maintain a data model across multiple keys and different data structures.</p>\n<p>User scripts are executed in Valkey by an embedded, sandboxed scripting engine.<br>Presently, Valkey supports a single scripting engine, the <a href=\"https://www.lua.org/\">Lua 5.1</a> interpreter.</p>\n<p>Please refer to the <a href=\"lua-api\">Valkey Lua API Reference</a> page for complete documentation.</p>\n<h2>Running scripts</h2>\n<p>Valkey provides two means for running scripts.</p>\n<p>Firstly, the <code>EVAL</code> command enables running server-side scripts.<br>Eval scripts provide a quick and straightforward way to have Valkey run your scripts ad-hoc.<br>However, using them means that the scripted logic is a part of your application (not an extension of the Valkey server).<br>Every applicative instance that runs a script must have the script&#39;s source code readily available for loading at any time.<br>That is because scripts are only cached by the server and are volatile.<br>As your application grows, this approach can become harder to develop and maintain.</p>\n<p>Secondly, added in v7.0, Valkey Functions are essentially scripts that are first-class database elements.<br>As such, functions decouple scripting from application logic and enable independent development, testing, and deployment of scripts.<br>To use functions, they need to be loaded first, and then they are available for use by all connected clients.<br>In this case, loading a function to the database becomes an administrative deployment task (such as loading a Valkey module, for example), which separates the script from the application.</p>\n<p>Please refer to the following pages for more information:</p>\n<ul>\n<li><a href=\"eval-intro\">Valkey Eval Scripts</a></li>\n<li><a href=\"functions-intro\">Valkey Functions</a></li>\n</ul>\n<p>When running a script or a function, Valkey guarantees its atomic execution.<br>The script&#39;s execution blocks all server activities during its entire time, similarly to the semantics of <a href=\"transactions\">transactions</a>.<br>These semantics mean that all of the script&#39;s effects either have yet to happen or had already happened.<br>The blocking semantics of an executed script apply to all connected clients at all times.</p>\n<p>Note that the potential downside of this blocking approach is that executing slow scripts is not a good idea.<br>It is not hard to create fast scripts because scripting&#39;s overhead is very low.<br>However, if you intend to use a slow script in your application, be aware that all other clients are blocked and can&#39;t execute any command while it is running.</p>\n<h2>Read-only scripts</h2>\n<p>A read-only script is a script that only executes commands that don&#39;t modify any keys within Valkey.<br>Read-only scripts can be executed either by adding the <code>no-writes</code> <a href=\"lua-api#script_flags\">flag</a> to the script or by executing the script with one of the read-only script command variants: <code>EVAL_RO</code>, <code>EVALSHA_RO</code>, or <code>FCALL_RO</code>.<br>They have the following properties:</p>\n<ul>\n<li>They can always be executed on replicas.</li>\n<li>They can always be killed by the <code>SCRIPT KILL</code> command. </li>\n<li>They never fail with OOM error when Valkey is over the memory limit.</li>\n<li>They are not blocked during write pauses, such as those that occur during coordinated failovers.</li>\n<li>They cannot execute any command that may modify the data set.</li>\n<li>Currently <code>PUBLISH</code>, <code>SPUBLISH</code> and <code>PFCOUNT</code> are also considered write commands in scripts, because they could attempt to propagate commands to replicas and AOF file.</li>\n</ul>\n<p>In addition to the benefits provided by all read-only scripts, the read-only script commands have the following advantages:</p>\n<ul>\n<li>They can be used to configure an ACL user to only be able to execute read-only scripts.</li>\n<li>Many clients also better support routing the read-only script commands to replicas for applications that want to use replicas for read scaling.</li>\n</ul>\n<h4>Read-only script history</h4>\n<p>Read-only scripts and read-only script commands were introduced in Redis OSS 7.0</p>\n<ul>\n<li>Before Redis OSS 7.0.1 <code>PUBLISH</code>, <code>SPUBLISH</code> and <code>PFCOUNT</code> were not considered write commands in scripts</li>\n<li>Before Redis OSS 7.0.1 the <code>no-writes</code> <a href=\"lua-api#script_flags\">flag</a> did not imply <code>allow-oom</code></li>\n<li>Before Redis OSS 7.0.1 the <code>no-writes</code> flag did not permit the script to run during write pauses.</li>\n</ul>\n<p>The recommended approach is to use the standard scripting commands with the <code>no-writes</code> flag unless you need one of the previously mentioned features.</p>\n<h2>Sandboxed script context</h2>\n<p>Valkey places the engine that executes user scripts inside a sandbox.<br>The sandbox attempts to prevent accidental misuse and reduce potential threats from the server&#39;s environment.</p>\n<p>Scripts should never try to access the Valkey server&#39;s underlying host systems, such as the file system, network, or attempt to perform any other system call other than those supported by the API.</p>\n<p>Scripts should operate solely on data stored in Valkey and data provided as arguments to their execution.</p>\n<h2>Maximum execution time</h2>\n<p>Scripts are subject to a maximum execution time (set by default to five seconds).<br>This default timeout is enormous since a script usually runs in less than a millisecond.<br>The limit is in place to handle accidental infinite loops created during development.</p>\n<p>It is possible to modify the maximum time a script can be executed with millisecond precision,<br>either via <code>valkey.conf</code> or by using the <code>CONFIG SET</code> command.<br>The configuration parameter affecting max execution time is called <code>busy-reply-threshold</code>.</p>\n<p>When a script reaches the timeout threshold, it isn&#39;t terminated by Valkey automatically.<br>Doing so would violate the contract between Valkey and the scripting engine that ensures that scripts are atomic.<br>Interrupting the execution of a script has the potential of leaving the dataset with half-written changes.</p>\n<p>Therefore, when a script executes longer than the configured timeout, the following happens:</p>\n<ul>\n<li>Valkey logs that a script is running for too long.</li>\n<li>It starts accepting commands again from other clients but will reply with a BUSY error to all the clients sending normal commands. The only commands allowed in this state are <code>SCRIPT KILL</code>, <code>FUNCTION KILL</code>, and <code>SHUTDOWN NOSAVE</code>.</li>\n<li>It is possible to terminate a script that only executes read-only commands using the <code>SCRIPT KILL</code> and <code>FUNCTION KILL</code> commands. These commands do not violate the scripting semantic as no data was written to the dataset by the script yet.</li>\n<li>If the script had already performed even a single write operation, the only command allowed is <code>SHUTDOWN NOSAVE</code> that stops the server without saving the current data set on disk (basically, the server is aborted).</li>\n</ul>\n"
  },
  {
    "id": "protocol",
    "topicName": "Serialization protocol specification",
    "description": "Valkey's serialization protocol (RESP) is the wire protocol that clients implement",
    "htmlContent": "<p>To communicate with the Valkey server, Valkey clients use a protocol called REdis Serialization Protocol (RESP).<br>While the protocol was designed for Redis, it&#39;s used by many other client-server software projects.</p>\n<p>RESP is a compromise among the following considerations:</p>\n<ul>\n<li>Simple to implement.</li>\n<li>Fast to parse.</li>\n<li>Human readable.</li>\n</ul>\n<p>RESP can serialize different data types including integers, strings, and arrays.<br>It also features an error-specific type.<br>A client sends a request to the Valkey server as an array of strings.<br>The array&#39;s contents are the command and its arguments that the server should execute.<br>The server&#39;s reply type is command-specific.</p>\n<p>RESP is binary-safe and uses prefixed length to transfer bulk data so it does not require processing bulk data transferred from one process to another.</p>\n<p>RESP is the protocol you should implement in your Valkey client.</p>\n<p><strong>Note:</strong><br>The protocol outlined here is used only for client-server communication.<br><a href=\"cluster-spec\">Valkey Cluster</a> uses a different binary protocol for exchanging messages between nodes.</p>\n<h2>RESP versions</h2>\n<p>The first version of the RESP protocol was experimental and was never widely used.</p>\n<p>The next version, RESP2, early became the standard communication method for clients with Redis OSS.</p>\n<p><a href=\"https://github.com/redis/redis-specifications/blob/master/protocol/RESP3\">RESP3</a> is a superset of RESP2 that mainly aims to make a client author&#39;s life a little bit easier.<br>Redis OSS 6.0 introduced experimental opt-in support of RESP3&#39;s features (excluding streaming strings and streaming aggregates).<br>In addition, the introduction of the <code>HELLO</code> command allows clients to handshake and upgrade the connection&#39;s protocol version (see <a href=\"#client-handshake\">Client handshake</a>).</p>\n<p>Up to and including Redis OSS 7, both RESP2 and RESP3 clients can invoke all core commands.<br>However, commands may return differently typed replies for different protocol versions.</p>\n<p>Future versions of Valkey may change the default protocol version, but it is unlikely that RESP2 will become entirely deprecated.<br>It is possible, however, that new features in upcoming versions will require the use of RESP3.</p>\n<h2>Network layer</h2>\n<p>A client connects to a Valkey server by creating a TCP connection to its port (the default is 6379).</p>\n<p>While RESP is technically non-TCP specific, the protocol is used exclusively with TCP connections (or equivalent stream-oriented connections like Unix sockets) in the context of Valkey.</p>\n<h2>Request-Response model</h2>\n<p>The Valkey server accepts commands composed of different arguments.<br>Then, the server processes the command and sends the reply back to the client.</p>\n<p>This is the simplest model possible; however, there are some exceptions:</p>\n<ul>\n<li>Valkey requests can be <a href=\"#multiple-commands-and-pipelining\">pipelined</a>.<br>Pipelining enables clients to send multiple commands at once and wait for replies later.</li>\n<li>When a RESP2 connection subscribes to a <a href=\"pubsub\">Pub/Sub</a> channel, the protocol changes semantics and becomes a <em>push</em> protocol.<br>The client no longer requires sending commands because the server will automatically send new messages to the client (for the channels the client is subscribed to) as soon as they are received.</li>\n<li>The <code>MONITOR</code> command.<br>Invoking the <code>MONITOR</code> command switches the connection to an ad-hoc push mode.<br>The protocol of this mode is not specified but is obvious to parse.</li>\n<li><a href=\"security#protected-mode\">Protected mode</a>.<br>Connections opened from a non-loopback address to a Valkey while in protected mode are denied and terminated by the server.<br>Before terminating the connection, Valkey unconditionally sends a <code>-DENIED</code> reply, regardless of whether the client writes to the socket.</li>\n<li>The <a href=\"#pushes\">RESP3 Push type</a>.<br>As the name suggests, a push type allows the server to send out-of-band data to the connection.<br>The server may push data at any time, and the data isn&#39;t necessarily related to specific commands executed by the client.</li>\n<li>When RESP3 is used, the commands <code>SUBSCRIBE</code>, <code>UNSUBSCRIBE</code> and their pattern and sharded variants,<br>return either an error reply <em>or one or more Push replies, without any regular in-band reply</em>.<br>This is considered a design mistake of these commands but the behaviour is kept for backward compatibility.<br>Clients need to compensate for this behaviour.</li>\n</ul>\n<p>Excluding these exceptions, the Valkey protocol is a simple request-response protocol.</p>\n<h2>RESP protocol description</h2>\n<p>RESP is essentially a serialization protocol that supports several data types.<br>In RESP, the first byte of data determines its type.</p>\n<p>Valkey generally uses RESP as a <a href=\"#request-response-model\">request-response</a> protocol in the following way:</p>\n<ul>\n<li>Clients send commands to a Valkey server as an <a href=\"#arrays\">array</a> of <a href=\"#bulk-strings\">bulk strings</a>.<br>The first (and sometimes also the second) bulk string in the array is the command&#39;s name.<br>Subsequent elements of the array are the arguments for the command.</li>\n<li>The server replies with a RESP type.<br>The reply&#39;s type is determined by the command&#39;s implementation and possibly by the client&#39;s protocol version.</li>\n</ul>\n<p>RESP is a binary protocol that uses control sequences encoded in standard ASCII.<br>The <code>A</code> character, for example, is encoded with the binary byte of value 65.<br>Similarly, the characters CR (<code>\\r</code>), LF (<code>\\n</code>) and SP (<code> </code>) have binary byte values of 13, 10 and 32, respectively.</p>\n<p>The <code>\\r\\n</code> (CRLF) is the protocol&#39;s <em>terminator</em>, which <strong>always</strong> separates its parts.</p>\n<p>The first byte in an RESP-serialized payload always identifies its type.<br>Subsequent bytes constitute the type&#39;s contents.</p>\n<p>We categorize every RESP data type as either <em>simple</em>, <em>bulk</em> or <em>aggregate</em>.</p>\n<p>Simple types are similar to scalars in programming languages that represent plain literal values. Booleans and Integers are such examples.</p>\n<p>RESP strings are either <em>simple</em> or <em>bulk</em>.<br>Simple strings never contain carriage return (<code>\\r</code>) or line feed (<code>\\n</code>) characters.<br>Bulk strings can contain any binary data and may also be referred to as <em>binary</em> or <em>blob</em>.<br>Note that bulk strings may be further encoded and decoded, e.g. with a wide multi-byte encoding, by the client.</p>\n<p>Aggregates, such as Arrays and Maps, can have varying numbers of sub-elements and nesting levels.</p>\n<p>The following table summarizes the RESP data types that Valkey supports:</p>\n<table>\n<thead>\n<tr>\n<th>RESP data type</th>\n<th>Minimal protocol version</th>\n<th>Category</th>\n<th>First byte</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><a href=\"#simple-strings\">Simple strings</a></td>\n<td>RESP2</td>\n<td>Simple</td>\n<td><code>+</code></td>\n</tr>\n<tr>\n<td><a href=\"#simple-errors\">Simple Errors</a></td>\n<td>RESP2</td>\n<td>Simple</td>\n<td><code>-</code></td>\n</tr>\n<tr>\n<td><a href=\"#integers\">Integers</a></td>\n<td>RESP2</td>\n<td>Simple</td>\n<td><code>:</code></td>\n</tr>\n<tr>\n<td><a href=\"#bulk-strings\">Bulk strings</a></td>\n<td>RESP2</td>\n<td>Aggregate</td>\n<td><code>$</code></td>\n</tr>\n<tr>\n<td><a href=\"#arrays\">Arrays</a></td>\n<td>RESP2</td>\n<td>Aggregate</td>\n<td><code>*</code></td>\n</tr>\n<tr>\n<td><a href=\"#nulls\">Nulls</a></td>\n<td>RESP3</td>\n<td>Simple</td>\n<td><code>_</code></td>\n</tr>\n<tr>\n<td><a href=\"#booleans\">Booleans</a></td>\n<td>RESP3</td>\n<td>Simple</td>\n<td><code>#</code></td>\n</tr>\n<tr>\n<td><a href=\"#doubles\">Doubles</a></td>\n<td>RESP3</td>\n<td>Simple</td>\n<td><code>,</code></td>\n</tr>\n<tr>\n<td><a href=\"#big-numbers\">Big numbers</a></td>\n<td>RESP3</td>\n<td>Simple</td>\n<td><code>(</code></td>\n</tr>\n<tr>\n<td><a href=\"#bulk-errors\">Bulk errors</a></td>\n<td>RESP3</td>\n<td>Aggregate</td>\n<td><code>!</code></td>\n</tr>\n<tr>\n<td><a href=\"#verbatim-strings\">Verbatim strings</a></td>\n<td>RESP3</td>\n<td>Aggregate</td>\n<td><code>=</code></td>\n</tr>\n<tr>\n<td><a href=\"#maps\">Maps</a></td>\n<td>RESP3</td>\n<td>Aggregate</td>\n<td><code>%</code></td>\n</tr>\n<tr>\n<td><a href=\"#sets\">Sets</a></td>\n<td>RESP3</td>\n<td>Aggregate</td>\n<td><code>~</code></td>\n</tr>\n<tr>\n<td><a href=\"#pushes\">Pushes</a></td>\n<td>RESP3</td>\n<td>Aggregate</td>\n<td><code>&gt;</code></td>\n</tr>\n</tbody></table>\n<h3>Simple strings</h3>\n<p>Simple strings are encoded as a plus (<code>+</code>) character, followed by a string.<br>The string mustn&#39;t contain a CR (<code>\\r</code>) or LF (<code>\\n</code>) character and is terminated by CRLF (i.e., <code>\\r\\n</code>).</p>\n<p>Simple strings transmit short, non-binary strings with minimal overhead.<br>For example, many Valkey commands reply with just &quot;OK&quot; on success.<br>The encoding of this Simple String is the following 5 bytes:</p>\n<pre><code>+OK\\r\\n\n</code></pre>\n<p>When Valkey replies with a simple string, a client library should return to the caller a string value composed of the first character after the <code>+</code> up to the end of the string, excluding the final CRLF bytes.</p>\n<p>To send binary strings, use <a href=\"#bulk-strings\">bulk strings</a> instead.</p>\n<h3>Simple errors</h3>\n<p>RESP has specific data types for errors.<br>Simple errors, or simply just errors, are similar to <a href=\"#simple-strings\">simple strings</a>, but their first character is the minus (<code>-</code>) character.<br>The difference between simple strings and errors in RESP is that clients should treat errors as exceptions, whereas the string encoded in the error type is the error message itself.</p>\n<p>The basic format is:</p>\n<pre><code>-Error message\\r\\n\n</code></pre>\n<p>Valkey replies with an error only when something goes wrong, for example, when you try to operate against the wrong data type, or when the command does not exist.<br>The client should raise an exception when it receives an Error reply.</p>\n<p>The following are examples of error replies:</p>\n<pre><code>-ERR unknown command &#39;asdf&#39;\n-WRONGTYPE Operation against a key holding the wrong kind of value\n</code></pre>\n<p>The first upper-case word after the <code>-</code>, up to the first space or newline, represents the kind of error returned.<br>This word is called an <em>error prefix</em>.<br>Note that the error prefix is a convention used by Valkey rather than part of the RESP error type.</p>\n<p>For example, in Valkey, <code>ERR</code> is a generic error, whereas <code>WRONGTYPE</code> is a more specific error that implies that the client attempted an operation against the wrong data type.<br>The error prefix allows the client to understand the type of error returned by the server without checking the exact error message.</p>\n<p>A client implementation can return different types of exceptions for various errors, or provide a generic way for trapping errors by directly providing the error name to the caller as a string.</p>\n<p>However, such a feature should not be considered vital as it is rarely useful.<br>Also, simpler client implementations can return a generic error value, such as <code>false</code>.</p>\n<h3>Integers</h3>\n<p>This type is a CRLF-terminated string that represents a signed, base-10, 64-bit integer.</p>\n<p>RESP encodes integers in the following way:</p>\n<pre><code>:[&lt;+|-&gt;]&lt;value&gt;\\r\\n\n</code></pre>\n<ul>\n<li>The colon (<code>:</code>) as the first byte.</li>\n<li>An optional plus (<code>+</code>) or minus (<code>-</code>) as the sign.</li>\n<li>One or more decimal digits (<code>0</code>..<code>9</code>) as the integer&#39;s unsigned, base-10 value.</li>\n<li>The CRLF terminator.</li>\n</ul>\n<p>For example, <code>:0\\r\\n</code> and <code>:1000\\r\\n</code> are integer replies (of zero and one thousand, respectively).</p>\n<p>Many Valkey commands return RESP integers, including <code>INCR</code>, <code>LLEN</code>, and <code>LASTSAVE</code>.<br>An integer, by itself, has no special meaning other than in the context of the command that returned it.<br>For example, it is an incremental number for <code>INCR</code>, a UNIX timestamp for <code>LASTSAVE</code>, and so forth.<br>However, the returned integer is guaranteed to be in the range of a signed 64-bit integer.</p>\n<p>In some cases, integers can represent true and false Boolean values.<br>For instance, <code>SISMEMBER</code> returns 1 for true and 0 for false.</p>\n<p>Other commands, including <code>SADD</code>, <code>SREM</code>, and <code>SETNX</code>, return 1 when the data changes and 0 otherwise.</p>\n<h3>Bulk strings</h3>\n<p>A bulk string represents a single binary string.<br>The string can be of any size, but by default, Valkey limits it to 512 MB (see the <code>proto-max-bulk-len</code> configuration directive).</p>\n<p>RESP encodes bulk strings in the following way:</p>\n<pre><code>$&lt;length&gt;\\r\\n&lt;data&gt;\\r\\n\n</code></pre>\n<ul>\n<li>The dollar sign (<code>$</code>) as the first byte.</li>\n<li>One or more decimal digits (<code>0</code>..<code>9</code>) as the string&#39;s length, in bytes, as an unsigned, base-10 value.</li>\n<li>The CRLF terminator.</li>\n<li>The data.</li>\n<li>A final CRLF.</li>\n</ul>\n<p>So the string &quot;hello&quot; is encoded as follows:</p>\n<pre><code>$5\\r\\nhello\\r\\n\n</code></pre>\n<p>The empty string&#39;s encoding is:</p>\n<pre><code>$0\\r\\n\\r\\n\n</code></pre>\n<p><a name=\"nil-reply\"></a></p>\n<h3>Arrays</h3>\n<p>Clients send commands to the Valkey server as RESP arrays.<br>Similarly, some Valkey commands that return collections of elements use arrays as their replies.<br>An example is the <code>LRANGE</code> command that returns elements of a list.</p>\n<p>RESP Arrays&#39; encoding uses the following format:</p>\n<pre><code>*&lt;number-of-elements&gt;\\r\\n&lt;element-1&gt;...&lt;element-n&gt;\n</code></pre>\n<ul>\n<li>An asterisk (<code>*</code>) as the first byte.</li>\n<li>One or more decimal digits (<code>0</code>..<code>9</code>) as the number of elements in the array as an unsigned, base-10 value.</li>\n<li>The CRLF terminator.</li>\n<li>An additional RESP type for every element of the array.</li>\n</ul>\n<p>So an empty Array is just the following:</p>\n<pre><code>*0\\r\\n\n</code></pre>\n<p>Whereas the encoding of an array consisting of the two bulk strings &quot;hello&quot; and &quot;world&quot; is:</p>\n<pre><code>*2\\r\\n$5\\r\\nhello\\r\\n$5\\r\\nworld\\r\\n\n</code></pre>\n<p>As you can see, after the <code>*&lt;count&gt;CRLF</code> part prefixing the array, the other data types that compose the array are concatenated one after the other.<br>For example, an Array of three integers is encoded as follows:</p>\n<pre><code>*3\\r\\n:1\\r\\n:2\\r\\n:3\\r\\n\n</code></pre>\n<p>Arrays can contain mixed data types.<br>For instance, the following encoding is of a list of four integers and a bulk string:</p>\n<pre><code>*5\\r\\n\n:1\\r\\n\n:2\\r\\n\n:3\\r\\n\n:4\\r\\n\n$5\\r\\n\nhello\\r\\n\n</code></pre>\n<p>(The raw RESP encoding is split into multiple lines for readability).</p>\n<p>The first line the server sent is <code>*5\\r\\n</code>.<br>This numeric value tells the client that five reply types are about to follow it.<br>Then, every successive reply constitutes an element in the array.</p>\n<p>All of the aggregate RESP types support nesting.<br>For example, a nested array of two arrays is encoded as follows:</p>\n<pre><code>*2\\r\\n\n*3\\r\\n\n:1\\r\\n\n:2\\r\\n\n:3\\r\\n\n*2\\r\\n\n+Hello\\r\\n\n-World\\r\\n\n</code></pre>\n<p>(The raw RESP encoding is split into multiple lines for readability).</p>\n<p>The above encodes a two-element array.<br>The first element is an array that, in turn, contains three integers (1, 2, 3).<br>The second element is another array containing a simple string and an error.</p>\n<p><strong>Note:</strong><br>In some places, the RESP Array type may be referred to as <em>multi bulk</em>.<br>The two are the same.</p>\n<h3>Nulls</h3>\n<p>The null data type represents non-existent values.</p>\n<p>In RESP3, null is encoded using the underscore (<code>_</code>) character, followed by the CRLF terminator (<code>\\r\\n</code>).<br>Here&#39;s null&#39;s raw RESP encoding:</p>\n<pre><code>_\\r\\n\n</code></pre>\n<p>RESP2 features two specially crafted values for representing null values,<br>known as &quot;null bulk strings&quot; and &quot;null arrays&quot;.<br>This duality has always been a redundancy that added zero semantical value to the protocol itself.<br>The null type, introduced in RESP3, aims to fix this wrong.<br>Clients should handle all these representations of null in the same way.<br>For example, a Ruby library should return <code>nil</code> while a C library should return <code>NULL</code> (or set a special flag in the reply object).</p>\n<h4>Null bulk strings</h4>\n<p>Whereas RESP3 has a dedicated data type for <a href=\"#nulls\">null values</a>, RESP2 has no such type.<br>Instead, due to historical reasons, the representation of null values in RESP2 is via predetermined forms of the <a href=\"#bulk-strings\">bulk strings</a> and <a href=\"#arrays\">arrays</a> types.</p>\n<p>The null bulk string represents a non-existing value.<br>The <code>GET</code> command returns the Null Bulk String when the target key doesn&#39;t exist.</p>\n<p>It is encoded as a bulk string with the length of negative one (-1), like so:</p>\n<pre><code>$-1\\r\\n\n</code></pre>\n<p>A Valkey client should return a nil object when the server replies with a null bulk string rather than the empty string.</p>\n<h4>Null arrays</h4>\n<p>Whereas RESP3 has a dedicated data type for <a href=\"#nulls\">null values</a>, RESP2 has no such type. Instead, due to historical reasons, the representation of null values in RESP2 is via predetermined forms of the <a href=\"#bulk-strings\">Bulk Strings</a> and <a href=\"#arrays\">arrays</a> types.</p>\n<p>Null arrays exist as an alternative way of representing a null value.<br>For instance, when the <code>BLPOP</code> command times out, it returns a null array.</p>\n<p>The encoding of a null array is that of an array with the length of -1, i.e.</p>\n<pre><code>*-1\\r\\n\n</code></pre>\n<p>When Valkey replies with a null array, the client should return a null object rather than an empty array.</p>\n<h4>Null elements in arrays</h4>\n<p>Single elements of an array may be <a href=\"#nulls\">null</a>.<br>This is used in Valkey replies to signal that these elements are missing and not empty strings. This can happen, for example, with the <code>SORT</code> command when used with the <code>GET pattern</code> option<br>if the specified key is missing.</p>\n<p>Here&#39;s an example of an array reply containing a null element, represented as a RESP2 null bulk string:</p>\n<pre><code>*3\\r\\n\n$5\\r\\n\nhello\\r\\n\n$-1\\r\\n\n$5\\r\\n\nworld\\r\\n\n</code></pre>\n<p>Above, the second element is null.<br>The client library should return to its caller something like this:</p>\n<pre><code>[&quot;hello&quot;,nil,&quot;world&quot;]\n</code></pre>\n<h3>Booleans</h3>\n<p>RESP booleans are encoded as follows:</p>\n<pre><code>#&lt;t|f&gt;\\r\\n\n</code></pre>\n<ul>\n<li>The octothorpe character (<code>#</code>) as the first byte.</li>\n<li>A <code>t</code> character for true values, or an <code>f</code> character for false ones.</li>\n<li>The CRLF terminator.</li>\n</ul>\n<h3>Doubles</h3>\n<p>The Double RESP type encodes a double-precision floating point value.<br>Doubles are encoded as follows:</p>\n<pre><code>,[&lt;+|-&gt;]&lt;integral&gt;[.&lt;fractional&gt;][&lt;E|e&gt;[sign]&lt;exponent&gt;]\\r\\n\n</code></pre>\n<ul>\n<li>The comma character (<code>,</code>) as the first byte.</li>\n<li>An optional plus (<code>+</code>) or minus (<code>-</code>) as the sign.</li>\n<li>One or more decimal digits (<code>0</code>..<code>9</code>) as an unsigned, base-10 integral value.</li>\n<li>An optional dot (<code>.</code>), followed by one or more decimal digits (<code>0</code>..<code>9</code>) as an unsigned, base-10 fractional value.</li>\n<li>An optional capital or lowercase letter E (<code>E</code> or <code>e</code>), followed by an optional plus (<code>+</code>) or minus (<code>-</code>) as the exponent&#39;s sign, ending with one or more decimal digits (<code>0</code>..<code>9</code>) as an unsigned, base-10 exponent value.</li>\n<li>The CRLF terminator.</li>\n</ul>\n<p>Here&#39;s the encoding of the number 1.23:</p>\n<pre><code>,1.23\\r\\n\n</code></pre>\n<p>Because the fractional part is optional, the integer value of ten (10) can, therefore, be RESP-encoded both as an integer as well as a double:</p>\n<pre><code>:10\\r\\n\n,10\\r\\n\n</code></pre>\n<p>In such cases, the Valkey client should return native integer and double values, respectively, providing that these types are supported by the language of its implementation.</p>\n<p>The positive infinity, negative infinity and NaN values are encoded as follows:</p>\n<pre><code>,inf\\r\\n\n,-inf\\r\\n\n,nan\\r\\n\n</code></pre>\n<p><a name=\"big-number-reply\"></a></p>\n<h3>Big numbers</h3>\n<p>This type can encode integer values outside the range of signed 64-bit integers.</p>\n<p>Big numbers use the following encoding:</p>\n<pre><code>([+|-]&lt;number&gt;\\r\\n\n</code></pre>\n<ul>\n<li>The left parenthesis character (<code>(</code>) as the first byte.</li>\n<li>An optional plus (<code>+</code>) or minus (<code>-</code>) as the sign.</li>\n<li>One or more decimal digits (<code>0</code>..<code>9</code>) as an unsigned, base-10 value.</li>\n<li>The CRLF terminator.</li>\n</ul>\n<p>Example:</p>\n<pre><code>(3492890328409238509324850943850943825024385\\r\\n\n</code></pre>\n<p>Big numbers can be positive or negative but can&#39;t include fractionals.<br>Client libraries written in languages with a big number type should return a big number.<br>When big numbers aren&#39;t supported, the client should return a string and, when possible, signal to the caller that the reply is a big integer (depending on the API used by the client library).</p>\n<h3>Bulk errors</h3>\n<p>This type combines the purpose of <a href=\"#simple-errors\">simple errors</a> with the expressive power of <a href=\"#bulk-strings\">bulk strings</a>.</p>\n<p>It is encoded as:</p>\n<pre><code>!&lt;length&gt;\\r\\n&lt;error&gt;\\r\\n\n</code></pre>\n<ul>\n<li>An exclamation mark (<code>!</code>) as the first byte.</li>\n<li>One or more decimal digits (<code>0</code>..<code>9</code>) as the error&#39;s length, in bytes, as an unsigned, base-10 value.</li>\n<li>The CRLF terminator.</li>\n<li>The error itself.</li>\n<li>A final CRLF.</li>\n</ul>\n<p>As a convention, the error begins with an uppercase (space-delimited) word that conveys the error message.</p>\n<p>For instance, the error &quot;SYNTAX invalid syntax&quot; is represented by the following protocol encoding:</p>\n<pre><code>!21\\r\\n\nSYNTAX invalid syntax\\r\\n\n</code></pre>\n<p>(The raw RESP encoding is split into multiple lines for readability).</p>\n<h3>Verbatim strings</h3>\n<p>This type is similar to the <a href=\"#bulk-strings\">bulk string</a>, with the addition of providing a hint about the data&#39;s encoding.</p>\n<p>A verbatim string&#39;s RESP encoding is as follows:</p>\n<pre><code>=&lt;length&gt;\\r\\n&lt;encoding&gt;:&lt;data&gt;\\r\\n\n</code></pre>\n<ul>\n<li>An equal sign (<code>=</code>) as the first byte.</li>\n<li>One or more decimal digits (<code>0</code>..<code>9</code>) as the string&#39;s total length, in bytes, as an unsigned, base-10 value.</li>\n<li>The CRLF terminator.</li>\n<li>Exactly three (3) bytes represent the data&#39;s encoding.</li>\n<li>The colon (<code>:</code>) character separates the encoding and data.</li>\n<li>The data.</li>\n<li>A final CRLF.</li>\n</ul>\n<p>Example:</p>\n<pre><code>=15\\r\\n\ntxt:Some string\\r\\n\n</code></pre>\n<p>(The raw RESP encoding is split into multiple lines for readability).</p>\n<p>Some client libraries may ignore the difference between this type and the string type and return a native string in both cases.<br>However, interactive clients, such as command line interfaces (e.g., <a href=\"cli\"><code>valkey-cli</code></a>), can use this type and know that their output should be presented to the human user as is and without quoting the string.</p>\n<p>For example, the Valkey command <code>INFO</code> outputs a report that includes newlines.<br>When using RESP3, <code>valkey-cli</code> displays it correctly because it is sent as a Verbatim String reply (with its three bytes being &quot;txt&quot;).<br>When using RESP2, however, the <code>valkey-cli</code> is hard-coded to look for the <code>INFO</code> command to ensure its correct display to the user.</p>\n<h3>Maps</h3>\n<p>The RESP map encodes a collection of key-value tuples, i.e., a dictionary or a hash.</p>\n<p>It is encoded as follows:</p>\n<pre><code>%&lt;number-of-entries&gt;\\r\\n&lt;key-1&gt;&lt;value-1&gt;...&lt;key-n&gt;&lt;value-n&gt;\n</code></pre>\n<ul>\n<li>A percent character (<code>%</code>) as the first byte.</li>\n<li>One or more decimal digits (<code>0</code>..<code>9</code>) as the number of entries, or key-value tuples, in the map as an unsigned, base-10 value.</li>\n<li>The CRLF terminator.</li>\n<li>Two additional RESP types for every key and value in the map.</li>\n</ul>\n<p>For example, the following JSON object:</p>\n<pre><code>{\n    &quot;first&quot;: 1,\n    &quot;second&quot;: 2\n}\n</code></pre>\n<p>Can be encoded in RESP like so:</p>\n<pre><code>%2\\r\\n\n+first\\r\\n\n:1\\r\\n\n+second\\r\\n\n:2\\r\\n\n</code></pre>\n<p>(The raw RESP encoding is split into multiple lines for readability).</p>\n<p>Both map keys and values can be any of RESP&#39;s types.</p>\n<p>Valkey clients should return the idiomatic dictionary type that their language provides.<br>However, low-level programming languages (such as C, for example) will likely return an array along with type information that indicates to the caller that it is a dictionary.</p>\n<p><strong>Note:</strong><br>RESP2 doesn&#39;t have a map type.<br>A map in RESP2 is represented by a flat array containing the keys and the values.<br>The first element is a key, followed by the corresponding value, then the next key and so on, like this:<br><code>key1, value1, key2, value2, ...</code>.</p>\n<h3>Sets</h3>\n<p>Sets are somewhat like <a href=\"#arrays\">Arrays</a> but are unordered and should only contain unique elements.</p>\n<p>RESP set&#39;s encoding is:</p>\n<pre><code>~&lt;number-of-elements&gt;\\r\\n&lt;element-1&gt;...&lt;element-n&gt;\n</code></pre>\n<ul>\n<li>A tilde (<code>~</code>) as the first byte.</li>\n<li>One or more decimal digits (<code>0</code>..<code>9</code>) as the number of elements in the set as an unsigned, base-10 value.</li>\n<li>The CRLF terminator.</li>\n<li>An additional RESP type for every element of the Set.</li>\n</ul>\n<p>Clients should return the native set type if it is available in their programming language.<br>Alternatively, in the absence of a native set type, an array coupled with type information can be used (in C, for example).</p>\n<p><a name=\"push-event\"></a></p>\n<h3>Pushes</h3>\n<p>RESP&#39;s pushes contain out-of-band data.<br>They are an exception to the protocol&#39;s request-response model and provide a generic <em>push mode</em> for connections.</p>\n<p>Push events are encoded similarly to <a href=\"#arrays\">arrays</a>, differing only in their first byte:</p>\n<pre><code>&gt;&lt;number-of-elements&gt;\\r\\n&lt;element-1&gt;...&lt;element-n&gt;\n</code></pre>\n<ul>\n<li>A greater-than sign (<code>&gt;</code>) as the first byte.</li>\n<li>One or more decimal digits (<code>0</code>..<code>9</code>) as the number of elements in the message as an unsigned, base-10 value.</li>\n<li>The CRLF terminator.</li>\n<li>An additional RESP type for every element of the push event.</li>\n</ul>\n<p>Pushed data may precede or follow any of RESP&#39;s data types but never inside them.<br>That means a client won&#39;t find push data in the middle of a map reply, for example.<br>It also means that pushed data may appear before or after a command&#39;s reply, as well as by itself (without calling any command).</p>\n<p>Clients should react to pushes by invoking a callback that implements their handling of the pushed data.</p>\n<h2>Client handshake</h2>\n<p>New RESP connections should begin the session by calling the <code>HELLO</code> command.<br>This practice accomplishes two things:</p>\n<ol>\n<li>It allows servers to be backward compatible with RESP2 versions.<br>  This is needed in Valkey to make the transition to version 3 of the protocol gentler.</li>\n<li>The <code>HELLO</code> command returns information about the server and the protocol that the client can use for different goals.</li>\n</ol>\n<p>The <code>HELLO</code> command has the following high-level syntax:</p>\n<pre><code>HELLO &lt;protocol-version&gt; [optional-arguments]\n</code></pre>\n<p>The first argument of the command is the protocol version we want the connection to be set.<br>By default, the connection starts in RESP2 mode.<br>If we specify a connection version that is too big and unsupported by the server, it should reply with a <code>-NOPROTO</code> error. Example:</p>\n<pre><code>Client: HELLO 4\nServer: -NOPROTO sorry, this protocol version is not supported.\n</code></pre>\n<p>At that point, the client may retry with a lower protocol version.</p>\n<p>Similarly, the client can easily detect a server that is only able to speak RESP2:</p>\n<pre><code>Client: HELLO 3\nServer: -ERR unknown command &#39;HELLO&#39;\n</code></pre>\n<p>The client can then proceed and use RESP2 to communicate with the server.</p>\n<p>Note that even if the protocol&#39;s version is supported, the <code>HELLO</code> command may return an error, perform no action and remain in RESP2 mode.<br>For example, when used with invalid authentication credentials in the command&#39;s optional <code>!AUTH</code> clause:</p>\n<pre><code>Client: HELLO 3 AUTH default mypassword\nServer: -ERR invalid password\n(the connection remains in RESP2 mode)\n</code></pre>\n<p>A successful reply to the <code>HELLO</code> command is a map reply.<br>The information in the reply is partly server-dependent, but certain fields are mandatory for all the RESP3 implementations:</p>\n<ul>\n<li><strong>server</strong>: &quot;redis&quot; (or other software name).</li>\n<li><strong>version</strong>: the server&#39;s version.</li>\n<li><strong>proto</strong>: the highest supported version of the RESP protocol.</li>\n</ul>\n<p>In Valkey&#39; RESP3 implementation, the following fields are also emitted:</p>\n<ul>\n<li><strong>id</strong>: the connection&#39;s identifier (ID).</li>\n<li><strong>mode</strong>: &quot;standalone&quot;, &quot;sentinel&quot; or &quot;cluster&quot;.</li>\n<li><strong>role</strong>: &quot;primary&quot; or &quot;replica&quot;.</li>\n<li><strong>modules</strong>: list of loaded modules as an Array of Bulk Strings.</li>\n</ul>\n<h2>Sending commands to a Valkey server</h2>\n<p>Now that you are familiar with the RESP serialization format, you can use it to help write a Valkey client library.<br>We can further specify how the interaction between the client and the server works:</p>\n<ul>\n<li>A client sends the Valkey server an <a href=\"#arrays\">array</a> consisting of only bulk strings.</li>\n<li>A Valkey server replies to clients, sending any valid RESP data type as a reply.</li>\n</ul>\n<p>So, for example, a typical interaction could be the following.</p>\n<p>The client sends the command <code>LLEN mylist</code> to get the length of the list stored at the key <em>mylist</em>.<br>Then the server replies with an <a href=\"#integers\">integer</a> reply as in the following example (<code>C:</code> is the client, <code>S:</code> the server).</p>\n<pre><code>C: *2\\r\\n\nC: $4\\r\\n\nC: LLEN\\r\\n\nC: $6\\r\\n\nC: mylist\\r\\n\n\nS: :48293\\r\\n\n</code></pre>\n<p>As usual, we separate different parts of the protocol with newlines for simplicity, but the actual interaction is the client sending <code>*2\\r\\n$4\\r\\nLLEN\\r\\n$6\\r\\nmylist\\r\\n</code> as a whole.</p>\n<h2>Multiple commands and pipelining</h2>\n<p>A client can use the same connection to issue multiple commands.<br>Pipelining is supported, so multiple commands can be sent with a single write operation by the client.<br>The client can skip reading replies and continue to send the commands one after the other.<br>All the replies can be read at the end.</p>\n<p>For more information, see <a href=\"pipelining\">Pipelining</a>.</p>\n<h2>Inline commands</h2>\n<p>Sometimes you may need to send a command to the Valkey server but only have <code>telnet</code> available.<br>While the Valkey protocol is simple to implement, it is not ideal for interactive sessions, and <code>valkey-cli</code> may not always be available.<br>For this reason, Valkey also accepts commands in the <em>inline command</em> format.</p>\n<p>The following example demonstrates a server/client exchange using an inline command (the server chat starts with <code>S:</code>, the client chat with <code>C:</code>):</p>\n<pre><code>C: PING\nS: +PONG\n</code></pre>\n<p>Here&#39;s another example of an inline command where the server returns an integer:</p>\n<pre><code>C: EXISTS somekey\nS: :0\n</code></pre>\n<p>Basically, to issue an inline command, you write space-separated arguments in a telnet session.<br>Since no command starts with <code>*</code> (the identifying byte of RESP Arrays), Valkey detects this condition and parses your command inline.</p>\n<h2>High-performance parser for the Valkey protocol</h2>\n<p>While the Valkey protocol is human-readable and easy to implement, its implementation can exhibit performance similar to that of a binary protocol.</p>\n<p>RESP uses prefixed lengths to transfer bulk data.<br>That makes scanning the payload for special characters unnecessary (unlike parsing JSON, for example).<br>For the same reason, quoting and escaping the payload isn&#39;t needed.</p>\n<p>Reading the length of aggregate types (for example, bulk strings or arrays) can be processed with code that performs a single operation per character while at the same time scanning for the CR character.</p>\n<p>Example (in C):</p>\n<pre><code class=\"language-c\">#include &lt;stdio.h&gt;\n\nint main(void) {\n    unsigned char *p = &quot;$123\\r\\n&quot;;\n    int len = 0;\n\n    p++;\n    while(*p != &#39;\\r&#39;) {\n        len = (len*10)+(*p - &#39;0&#39;);\n        p++;\n    }\n\n    /* Now p points at &#39;\\r&#39;, and the len is in bulk_len. */\n    printf(&quot;%d\\n&quot;, len);\n    return 0;\n}\n</code></pre>\n<p>After the first CR is identified, it can be skipped along with the following LF without further processing.<br>Then, the bulk data can be read with a single read operation that doesn&#39;t inspect the payload in any way.<br>Finally, the remaining CR and LF characters are discarded without additional processing.</p>\n<p>While comparable in performance to a binary protocol, the Valkey protocol is significantly more straightforward to implement in most high-level languages, reducing the number of bugs in client software.</p>\n<h2>Tips for Valkey client authors</h2>\n<ul>\n<li>For testing purposes, use <a href=\"lua-api#lua-to-resp3-type-conversion\">Lua&#39;s type conversions</a> to have Valkey reply with any RESP2/RESP3 needed.<br>As an example, a RESP3 double can be generated like so:<pre><code>EVAL &quot;return { double = tonumber(ARGV[1]) }&quot; 0 1e0\n</code></pre>\n</li>\n</ul>\n"
  },
  {
    "id": "pubsub",
    "topicName": "Pub/Sub",
    "description": "How to use pub/sub channels in Valkey",
    "htmlContent": "<p><code>SUBSCRIBE</code>, <code>UNSUBSCRIBE</code> and <code>PUBLISH</code> implement the <a href=\"https://en.wikipedia.org/wiki/Publish/subscribe\">Publish/Subscribe messaging paradigm</a> where publishers send their messages to channels, without knowledge of what receivers (subscribers) there may be.<br>Subscribers express interest in one or more channels and only receive messages that are of interest, without knowledge of what (if any) publishers there are.<br>This decoupling of publishers and subscribers allows for greater scalability and a more dynamic network topology.</p>\n<p>Pubsub channels are not persisted. If there are no subscribes to a channel when a message is published, the message is lost.<br>If you&#39;re looking for persisted messages queues, you may want to look into <a href=\"streams-intro\">Streams</a> instead.</p>\n<p>To subscribe to channels &quot;channel11&quot; and &quot;ch:00&quot; the client issues a <code>SUBSCRIBE</code> providing the names of the channels:</p>\n<pre><code class=\"language-bash\">SUBSCRIBE channel11 ch:00\n</code></pre>\n<p>Messages sent by other clients to these channels will be pushed by Valkey to all the subscribed clients.<br>Subscribers receive the messages in the order that the messages are published.</p>\n<p>A client subscribed to one or more channels shouldn&#39;t issue commands, although it can <code>SUBSCRIBE</code> and <code>UNSUBSCRIBE</code> to and from other channels.<br>The replies to subscription and unsubscribing operations are sent in the form of messages so that the client can just read a coherent stream of messages where the first element indicates the type of message.<br>The commands that are allowed in the context of a subscribed RESP2 client are:</p>\n<ul>\n<li><code>PING</code></li>\n<li><code>PSUBSCRIBE</code></li>\n<li><code>PUNSUBSCRIBE</code></li>\n<li><code>QUIT</code></li>\n<li><code>RESET</code></li>\n<li><code>SSUBSCRIBE</code></li>\n<li><code>SUBSCRIBE</code></li>\n<li><code>SUNSUBSCRIBE</code></li>\n<li><code>UNSUBSCRIBE</code></li>\n</ul>\n<p>However, if RESP3 is used (see <code>HELLO</code>), a client can issue any commands while in the subscribed state.</p>\n<p>Please note that when using <code>valkey-cli</code>, in subscribed mode commands such as <code>UNSUBSCRIBE</code> and <code>PUNSUBSCRIBE</code> cannot be used because <code>valkey-cli</code> will not accept any commands and can only quit the mode with <code>Ctrl-C</code>.</p>\n<h2>Delivery semantics</h2>\n<p>Valkey&#39; Pub/Sub exhibits <em>at-most-once</em> message delivery semantics.<br>As the name suggests, it means that a message will be delivered once if at all.<br>Once the message is sent by the Valkey server, there&#39;s no chance of it being sent again.<br>If the subscriber is unable to handle the message (for example, due to an error or a network disconnect) the message is forever lost.</p>\n<p>If your application requires stronger delivery guarantees, you may want to learn about <a href=\"streams-intro\">Streams</a>.<br>Messages in streams are persisted, and support both <em>at-most-once</em> as well as <em>at-least-once</em> delivery semantics.</p>\n<h2>Format of pushed messages</h2>\n<p>A message is an <a href=\"protocol#arrays\">array-reply</a> with three elements.</p>\n<p>The first element is the kind of message:</p>\n<ul>\n<li><p><code>subscribe</code>: means that we successfully subscribed to the channel given as the second element in the reply.<br>The third argument represents the number of channels we are currently subscribed to.</p>\n</li>\n<li><p><code>unsubscribe</code>: means that we successfully unsubscribed from the channel given as second element in the reply.<br>The third argument represents the number of channels we are currently subscribed to.<br>When the last argument is zero, we are no longer subscribed to any channel, and the client can issue any kind of Valkey command as we are outside the Pub/Sub state.</p>\n</li>\n<li><p><code>message</code>: it is a message received as a result of a <code>PUBLISH</code> command issued by another client.<br>The second element is the name of the originating channel, and the third argument is the actual message payload.</p>\n</li>\n</ul>\n<h2>Database &amp; Scoping</h2>\n<p>Pub/Sub has no relation to the key space.<br>It was made to not interfere with it on any level, including database numbers.</p>\n<p>Publishing on db 10, will be heard by a subscriber on db 1.</p>\n<p>If you need scoping of some kind, prefix the channels with the name of the environment (test, staging, production...).</p>\n<h2>Wire protocol example</h2>\n<pre><code>SUBSCRIBE first second\n*3\n$9\nsubscribe\n$5\nfirst\n:1\n*3\n$9\nsubscribe\n$6\nsecond\n:2\n</code></pre>\n<p>At this point, from another client we issue a <code>PUBLISH</code> operation against the channel named <code>second</code>:</p>\n<pre><code>&gt; PUBLISH second Hello\n</code></pre>\n<p>This is what the first client receives:</p>\n<pre><code>*3\n$7\nmessage\n$6\nsecond\n$5\nHello\n</code></pre>\n<p>Now the client unsubscribes itself from all the channels using the <code>UNSUBSCRIBE</code> command without additional arguments:</p>\n<pre><code>UNSUBSCRIBE\n*3\n$11\nunsubscribe\n$6\nsecond\n:1\n*3\n$11\nunsubscribe\n$5\nfirst\n:0\n</code></pre>\n<h2>Pattern-matching subscriptions</h2>\n<p>The Valkey Pub/Sub implementation supports pattern matching.<br>Clients may subscribe to glob-style patterns to receive all the messages sent to channel names matching a given pattern.</p>\n<p>For instance:</p>\n<pre><code>PSUBSCRIBE news.*\n</code></pre>\n<p>Will receive all the messages sent to the channel <code>news.art.figurative</code>, <code>news.music.jazz</code>, etc.<br>All the glob-style patterns are valid, so multiple wildcards are supported.</p>\n<pre><code>PUNSUBSCRIBE news.*\n</code></pre>\n<p>Will then unsubscribe the client from that pattern.<br>No other subscriptions will be affected by this call.</p>\n<p>Messages received as a result of pattern matching are sent in a different format:</p>\n<ul>\n<li>The type of the message is <code>pmessage</code>: it is a message received as a result from a <code>PUBLISH</code> command issued by another client, matching a pattern-matching subscription.<br>The second element is the original pattern matched, the third element is the name of the originating channel, and the last element is the actual message payload.</li>\n</ul>\n<p>Similarly to <code>SUBSCRIBE</code> and <code>UNSUBSCRIBE</code>, <code>PSUBSCRIBE</code> and <code>PUNSUBSCRIBE</code> commands are acknowledged by the system sending a message of type <code>psubscribe</code> and <code>punsubscribe</code> using the same format as the <code>subscribe</code> and <code>unsubscribe</code> message format.</p>\n<h2>Messages matching both a pattern and a channel subscription</h2>\n<p>A client may receive a single message multiple times if it&#39;s subscribed to multiple patterns matching a published message, or if it is subscribed to both patterns and channels matching the message.<br>This is shown by the following example:</p>\n<pre><code>SUBSCRIBE foo\nPSUBSCRIBE f*\n</code></pre>\n<p>In the above example, if a message is sent to channel <code>foo</code>, the client will receive two messages: one of type <code>message</code> and one of type <code>pmessage</code>.</p>\n<h2>The meaning of the subscription count with pattern matching</h2>\n<p>In <code>subscribe</code>, <code>unsubscribe</code>, <code>psubscribe</code> and <code>punsubscribe</code> message types, the last argument is the count of subscriptions still active.<br>This number is the total number of channels and patterns the client is still subscribed to.<br>So the client will exit the Pub/Sub state only when this count drops to zero as a result of unsubscribing from all the channels and patterns.</p>\n<h2>Sharded Pub/Sub</h2>\n<p>From Redis OSS 7.0, sharded Pub/Sub is introduced in which shard channels are assigned to slots by the same algorithm used to assign keys to slots.<br>A shard message must be sent to a node that owns the slot the shard channel is hashed to.<br>The cluster makes sure the published shard messages are forwarded to all nodes in the shard, so clients can subscribe to a shard channel by connecting to either the primary responsible for the slot, or to any of its replicas.<br><code>SSUBSCRIBE</code>, <code>SUNSUBSCRIBE</code> and <code>SPUBLISH</code> are used to implement sharded Pub/Sub.</p>\n<p>Sharded Pub/Sub helps to scale the usage of Pub/Sub in cluster mode.<br>It restricts the propagation of messages to be within the shard of a cluster.<br>Hence, the amount of data passing through the cluster bus is limited in comparison to global Pub/Sub where each message propagates to each node in the cluster.<br>This allows users to horizontally scale the Pub/Sub usage by adding more shards.</p>\n<h2>Client library implementation hints</h2>\n<p>Because all the messages received contain the original subscription causing the message delivery (the channel in the case of message type, and the original pattern in the case of pmessage type) client libraries may bind the original subscription to callbacks (that can be anonymous functions, blocks, function pointers), using a hash table.</p>\n<p>When a message is received an O(1) lookup can be done to deliver the message to the registered callback.</p>\n"
  },
  {
    "id": "quickstart",
    "topicName": "Quick start guide",
    "description": "Understand how to use basic Valkey data types",
    "htmlContent": "<p>This quick start guide shows you how to:</p>\n<ol>\n<li>Get started with Valkey </li>\n<li>Store data under a key in Valkey</li>\n<li>Retrieve data with a key from Valkey</li>\n<li>Scan the keyspace for keys that match a specific pattern</li>\n</ol>\n<p>The examples in this article refer to a simple bicycle inventory.</p>\n<h2>Setup</h2>\n<p>See the <a href=\"installation\">installation guides</a> to install Valkey on your local machine.</p>\n<h2>Connect</h2>\n<p>The first step is to connect to Valkey. There are client connectors for <a href=\"../clients/\">most programming languages</a>.<br>You can also connect using <a href=\"cli\">valkey-cli</a>, the command line interface.<br>The following example shows how to connect to a Valkey server that runs on localhost (<code>-h 127.0.0.1</code>) and listens on the default port (<code>-p 6379</code>):</p>\n<pre><code class=\"language-sh\">$ valkey-cli -h 127.0.0.1 -p 6379\n</code></pre>\n<h2>Store and retrieve data</h2>\n<p>Valkey is a remote dictionary server. You can use the same data types as in your local programming environment but on the server side within Valkey.</p>\n<p>Similar to byte arrays, Strings store sequences of bytes, including text, serialized objects, counter values, and binary arrays. The following example shows you how to set and get a string value:</p>\n<pre><code>127.0.0.1:6379&gt; SET bike:1 &quot;Process 134&quot;\nOK\n127.0.0.1:6379&gt; GET bike:1\n&quot;Process 134&quot;\n</code></pre>\n<p>Hashes are the equivalent of dictionaries (dicts or hash maps). Among other things, you can use hashes to represent plain objects and to store groupings of counters. The following example explains how to set and access field values of an object:</p>\n<pre><code>127.0.0.1:6379&gt; HSET bike:1 model Deimos brand Ergonom type &#39;Enduro bikes&#39; price 4972\n(integer) 4\n127.0.0.1:6379&gt; HGET bike:1 model\n&quot;Deimos&quot;\n127.0.0.1:6379&gt; HGET bike:1 price\n&quot;4972&quot;\n127.0.0.1:6379&gt; HGETALL bike:1\n1) &quot;model&quot;\n2) &quot;Deimos&quot;\n3) &quot;brand&quot;\n4) &quot;Ergonom&quot;\n5) &quot;type&quot;\n6) &quot;Enduro bikes&quot;\n7) &quot;price&quot;\n8) &quot;4972&quot;\n</code></pre>\n<p>You can get a complete overview of available data types in this documentation site&#39;s <a href=\"data-types\">data types section</a>. Each data type has commands allowing you to manipulate or retrieve data. The <a href=\"../commands/\">commands reference</a> provides a sophisticated explanation.</p>\n<h2>Scan the keyspace</h2>\n<p>Each item within Valkey has a unique key. All items live within the Valkey <a href=\"keyspace\">keyspace</a>. You can scan the Valkey keyspace via the <a href=\"../commands/scan\">SCAN command</a>. Here is an example that scans for the first 100 keys that have the prefix <code>bike:</code>:</p>\n<pre><code>127.0.0.1:6379&gt; SCAN 0 MATCH &quot;bike:*&quot; COUNT 100\n1) &quot;0&quot;\n2) 1) &quot;bike:4&quot;\n   2) &quot;bike:3&quot;\n   3) &quot;bike:5&quot;\n   4) &quot;bike:1&quot;\n   5) &quot;bike:2&quot;\n</code></pre>\n<p><a href=\"../commands/scan\">SCAN</a> returns a cursor position, allowing you to scan iteratively for the next batch of keys until you reach the cursor value 0.</p>\n"
  },
  {
    "id": "releases",
    "topicName": "Releases and versioning",
    "description": "How new versions of Valkey are released and supported",
    "htmlContent": "<p>Valkey is usually among the most critical pieces of a software stack.<br>For this reason, Valkey&#39;s release cycle prioritizes highly stable releases at the cost of slower release cycles.</p>\n<p>All Valkey releases are published in the <a href=\"https://github.com/valkey-io/valkey/releases\">Valkey GitHub repository</a>.</p>\n<h2>Versioning</h2>\n<p>Valkey stable releases will generally follow <code>major.minor.patch</code> <a href=\"https://semver.org/\">semantic versioning schema</a>.<br>We follow semantic versioning to provide explicit guarantees regarding backward compatibility.</p>\n<p>When discussing compatibility, we refer to the following API contracts:</p>\n<ol>\n<li>Valkey commands including their inputs, outputs, and defined behavior</li>\n<li>The functions and APIs that can be executed from a Lua script</li>\n<li>The RDB version</li>\n<li>The protocol used to establish and replicate data from primaries to replicas</li>\n<li>The protocol between nodes within a Valkey cluster</li>\n<li>The Valkey Module API interface</li>\n<li>The AOF on disk format</li>\n</ol>\n<h3>Patch versions</h3>\n<p><em>Patch</em> versions are released with backwards compatible bug fixes and should not introduce new features.</p>\n<p>Upgrading from a previous patch version should be safe and seamless.<br>It should be safe to run a primary-replica pair or a Valkey cluster with servers running on different patch versions.</p>\n<p><em>Patch</em> versions may also introduce small improvements such as performance or memory optimizations that are easy to verify as safe.</p>\n<h3>Minor versions</h3>\n<p><em>Minor</em> versions are released with new functionality that is added in a backward compatible manner.<br>Examples of new functionality include new commands, info fields, or configuration parameters.</p>\n<p>Upgrading from a previous minor version should be safe, and will not introduce incompatibilities between servers in the cluster when default server configurations are used.</p>\n<p><strong>NOTE:</strong> Minor releases may include new commands and data types that can introduce incompatibility between servers in the cluster, but users need to opt-in to these features to cause this type of incompatibility.<br>For this reason, it is not recommended to run a Valkey cluster with servers running on different minor versions.<br>Users should avoid new features until all servers in the cluster have been upgraded.</p>\n<p>Commands may also be marked as <strong>deprecated</strong> in minor versions.<br>Deprecated commands are not removed, instead a replacement command or an alternative to using the command will be defined in the same minor version.</p>\n<h3>Major versions</h3>\n<p><em>Major</em> versions are released with significant functionality that may break backwards compatibility or alter key performance characteristics.<br>Examples of significant functionality includes altering the behavior of an existing command, removing previously deprecated commands, changing the default value of configs, and significant refactoring for performance improvements.</p>\n<p>Upgrading from a previous major version is intended to be safe, but should be approached with caution.<br>You should carefully read the release notes before performing a major version upgrade.<br>Although Major versions can introduce breaking changes, data replicated from primaries to replicas will always be sent in a backward compatible format.<br>You should always upgrade replicas before upgrading primaries in order to ensure data consistency.</p>\n<p>The Valkey community strives to make as few backwards breaking changes as possible.<br>When breaking changes are required, we will also strive to provide a way to mitigate the impact without incurring downtime to your application.</p>\n<h2>Release schedule</h2>\n<p>The Valkey community typically releases a stable major version once each year.<br>Stable minor versions are introduced as needed between major releases,<br>with at least one minor version published annually.</p>\n<h3>Release candidate</h3>\n<p>New minor and major versions of Valkey begin by branching off the <code>unstable</code> branch as an initial release candidate branch with a name that takes the form of <em><code>major.minor</code></em>, example <code>7.2</code>.<br>The first release candidate, or rc1, is released once it can be used for development purposes and for testing the new version.<br>Release candidate versions will start with a patch version of &quot;0&quot; and will take the form <em><code>major.minor.patch-rcN</code></em>, example <code>7.2.0-rc1</code> followed by <code>7.2.0-rc2</code>.<br>At this stage, most of the new features and changes in the new version are ready for review, and the version is released for the purpose of collecting public feedback.<br>Subsequent release candidates are released every couple of weeks, primarily for fixing bugs and refining features based off of user input.</p>\n<h3>Stable release</h3>\n<p>Once development has ended and the feedback for release candidate slows down, it is ready for the final release.<br>At this point, the release is marked as stable and is released with &quot;0&quot; as its patch-level version.</p>\n<p>Patches are released as needed to fix high-urgency issues, or once a stable version accumulates enough fixes to justify it.</p>\n<h2>Support</h2>\n<p>The latest stable release is always fully supported and maintained.</p>\n<p>The Valkey community will provide maintenance support, providing patch releases for bug fixes and all security fixes, for 3 years from when a minor version was first released.</p>\n<p>The Valkey community will also provide extended security support for the latest minor version of each major version for 5 years from when a version was first released.<br>The minor version to be used for this extended security support will be decided once the next major version has been launched.<br>The Valkey community will only patch security issues we believe to be possible to exploit, which will be up to the discretion of the TSC.</p>\n<p>For contacting the TSC on sensitive matters and security issues, please see <a href=\"https://github.com/valkey-io/valkey/blob/unstable/SECURITY\">SECURITY.md</a>.</p>\n<h3>List of supported versions</h3>\n<table>\n<thead>\n<tr>\n<th>Version</th>\n<th>Initial release</th>\n<th>Maintenance support end</th>\n<th>Extended Security support end</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>8.0</td>\n<td>2024-09-15</td>\n<td>2027-09-15</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>7.2</td>\n<td>2024-04-16</td>\n<td>2027-04-16</td>\n<td>2029-04-16</td>\n</tr>\n</tbody></table>\n<h2>Unstable tree</h2>\n<p>The development tree of Valkey is located in the <code>unstable</code> branch in the <a href=\"https://github.com/valkey-io/valkey\">Valkey GitHub repository</a>.</p>\n<p>This branch is the source tree where most of the new features are under development.<br><code>unstable</code> is not considered production-ready: it may contain critical bugs, incomplete features, and is potentially unstable.</p>\n<p>However, we try hard to make sure that even the unstable branch is usable most of the time in a development environment without significant issues.</p>\n"
  },
  {
    "id": "replication",
    "topicName": "Replication",
    "description": "How Valkey supports high availability and failover with replication",
    "htmlContent": "<p>At the base of Valkey replication (excluding the high availability features provided as an additional layer by Valkey Cluster or Valkey Sentinel) there is a <em>leader follower</em> (primary-replica) replication that is simple to use and configure. It allows replica Valkey instances to be exact copies of primary instances. The replica will automatically reconnect to the primary every time the link breaks, and will attempt to be an exact copy of it <em>regardless</em> of what happens to the primary.</p>\n<p>This system works using three main mechanisms:</p>\n<ol>\n<li>When a primary and a replica instances are well-connected, the primary keeps the replica updated by sending a stream of commands to the replica to replicate the effects on the dataset happening in the primary side due to: client writes, keys expired or evicted, any other action changing the primary dataset.</li>\n<li>When the link between the primary and the replica breaks, for network issues or because a timeout is sensed in the primary or the replica, the replica reconnects and attempts to proceed with a partial resynchronization: it means that it will try to just obtain the part of the stream of commands it missed during the disconnection.</li>\n<li>When a partial resynchronization is not possible, the replica will ask for a full resynchronization. This will involve a more complex process in which the primary needs to create a snapshot of all its data, send it to the replica, and then continue sending the stream of commands as the dataset changes.</li>\n</ol>\n<p>Valkey uses by default asynchronous replication, which being low latency and<br>high performance, is the natural replication mode for the vast majority of Valkey<br>use cases. However, Valkey replicas asynchronously acknowledge the amount of data<br>they received periodically with the primary. So the primary does not wait every time<br>for a command to be processed by the replicas, however it knows, if needed, what<br>replica already processed what command. This allows having optional synchronous replication.</p>\n<p>Synchronous replication of certain data can be requested by the clients using<br>the <code>WAIT</code> command. However <code>WAIT</code> is only able to ensure there are the<br>specified number of acknowledged copies in the other Valkey instances, it does not<br>turn a set of Valkey instances into a CP system with strong consistency: acknowledged<br>writes can still be lost during a failover, depending on the exact configuration<br>of the Valkey persistence. However with <code>WAIT</code> the probability of losing a write<br>after a failure event is greatly reduced to certain hard to trigger failure<br>modes.</p>\n<p>You can check the Valkey Sentinel or Valkey Cluster documentation for more information<br>about high availability and failover. The rest of this document mainly describes the basic characteristics of Valkey basic replication.</p>\n<h3>Important facts about Valkey replication</h3>\n<ul>\n<li>Valkey uses asynchronous replication, with asynchronous replica-to-primary acknowledges of the amount of data processed.</li>\n<li>A primary can have multiple replicas.</li>\n<li>Replicas are able to accept connections from other replicas. Aside from connecting a number of replicas to the same primary, replicas can also be connected to other replicas in a cascading-like structure. All the sub-replicas will receive exactly the same replication stream from the primary.</li>\n<li>Valkey replication is non-blocking on the primary side. This means that the primary will continue to handle queries when one or more replicas perform the initial synchronization or a partial resynchronization.</li>\n<li>Replication is also largely non-blocking on the replica side. While the replica is performing the initial synchronization, it can handle queries using the old version of the dataset, assuming you configured Valkey to do so in valkey.conf.  Otherwise, you can configure Valkey replicas to return an error to clients if the replication stream is down. However, after the initial sync, the old dataset must be deleted and the new one must be loaded. The replica will block incoming connections during this brief window (that can be as long as many seconds for very large datasets). You can configure Valkey so that the deletion of the old data set happens in a different thread, however loading the new initial dataset will still happen in the main thread and block the replica.</li>\n<li>Replication can be used both for scalability, to have multiple replicas for read-only queries (for example, slow O(N) operations can be offloaded to replicas), or simply for improving data safety and high availability.</li>\n<li>You can use replication to avoid the cost of having the primary writing the full dataset to disk: a typical technique involves configuring your primary&#39;s <code>valkey.conf</code> to avoid persisting to disk at all, then connect a replica configured to save from time to time, or with AOF enabled. However, this setup must be handled with care, since a restarting primary will start with an empty dataset: if the replica tries to sync with it, the replica will be emptied as well.</li>\n</ul>\n<h2>Safety of replication when primary has persistence turned off</h2>\n<p>In setups where Valkey replication is used, it is strongly advised to have<br>persistence turned on in the primary and in the replicas. When this is not possible,<br>for example because of latency concerns due to very slow disks, instances should<br>be configured to <strong>avoid restarting automatically</strong> after a reboot.</p>\n<p>To better understand why primaries with persistence turned off configured to<br>auto restart are dangerous, check the following failure mode where data<br>is wiped from the primary and all its replicas:</p>\n<ol>\n<li>We have a setup with node A acting as primary, with persistence turned down, and nodes B and C replicating from node A.</li>\n<li>Node A crashes, however it has some auto-restart system, that restarts the process. However since persistence is turned off, the node restarts with an empty data set.</li>\n<li>Nodes B and C will replicate from node A, which is empty, so they&#39;ll effectively destroy their copy of the data.</li>\n</ol>\n<p>When Valkey Sentinel is used for high availability, also turning off persistence<br>on the primary, together with auto restart of the process, is dangerous. For example, the primary can restart fast enough for Sentinel to not detect a failure, so that the failure mode described above happens.</p>\n<p>Every time data safety is important, and replication is used with primary configured without persistence, auto restart of instances should be disabled.</p>\n<h2>How Valkey replication works</h2>\n<p>Every Valkey primary has a replication ID: it is a large pseudo random string<br>that marks a given story of the dataset. Each primary also takes an offset that<br>increments for every byte of replication stream that it is produced to be<br>sent to replicas, to update the state of the replicas with the new changes<br>modifying the dataset. The replication offset is incremented even if no replica<br>is actually connected, so basically every given pair of:</p>\n<pre><code>Replication ID, offset\n</code></pre>\n<p>Identifies an exact version of the dataset of a primary.</p>\n<p>When replicas connect to primaries, they use the <code>PSYNC</code> command to send<br>their old primary replication ID and the offsets they processed so far. This way<br>the primary can send just the incremental part needed. However if there is not<br>enough <em>backlog</em> in the primary buffers, or if the replica is referring to a<br>history (replication ID) which is no longer known, then a full resynchronization<br>happens: in this case the replica will get a full copy of the dataset, from scratch.</p>\n<p>This is how a full synchronization works in more details:</p>\n<p>The primary starts a background saving process to produce an RDB file. At the same time it starts to buffer all new write commands received from the clients. When the background saving is complete, the primary transfers the database file to the replica, which saves it on disk, and then loads it into memory. The primary will then send all buffered commands to the replica. This is done as a stream of commands and is in the same format of the Valkey protocol itself.</p>\n<p>You can try it yourself via telnet. Connect to the Valkey port while the<br>server is doing some work and issue the <code>SYNC</code> command. You&#39;ll see a bulk<br>transfer and then every command received by the primary will be re-issued<br>in the telnet session. Actually <code>SYNC</code> is an old protocol no longer used by<br>newer Valkey instances, but is still there for backward compatibility: it does<br>not allow partial resynchronizations, so now <code>PSYNC</code> is used instead.</p>\n<p>As already said, replicas are able to automatically reconnect when the primary-replica link goes down for some reason. If the primary receives multiple concurrent replica synchronization requests, it performs a single background save in to serve all of them.</p>\n<h2>Replication ID explained</h2>\n<p>In the previous section we said that if two instances have the same replication<br>ID and replication offset, they have exactly the same data. However it is useful<br>to understand what exactly is the replication ID, and why instances have actually<br>two replication IDs: the main ID and the secondary ID.</p>\n<p>A replication ID basically marks a given <em>history</em> of the data set. Every time<br>an instance restarts from scratch as a primary, or a replica is promoted to primary,<br>a new replication ID is generated for this instance. The replicas connected to<br>a primary will inherit its replication ID after the handshake. So two instances<br>with the same ID are related by the fact that they hold the same data, but<br>potentially at a different time. It is the offset that works as a logical time<br>to understand, for a given history (replication ID), who holds the most updated<br>data set.</p>\n<p>For instance, if two instances A and B have the same replication ID, but one<br>with offset 1000 and one with offset 1023, it means that the first lacks certain<br>commands applied to the data set. It also means that A, by applying just a few<br>commands, may reach exactly the same state of B.</p>\n<p>The reason why Valkey instances have two replication IDs is because of replicas<br>that are promoted to primaries. After a failover, the promoted replica requires<br>to still remember what was its past replication ID, because such replication ID<br>was the one of the former primary. In this way, when other replicas will sync<br>with the new primary, they will try to perform a partial resynchronization using the<br>old primary replication ID. This will work as expected, because when the replica<br>is promoted to primary, it sets its secondary ID to its main ID, remembering what<br>was the offset when this ID switch happened. Later it will select a new random<br>replication ID, because a new history begins. When handling the new replicas<br>connecting, the primary will match their IDs and offsets both with the current<br>ID and the secondary ID (up to a given offset, for safety). In short this means<br>that after a failover, replicas connecting to the newly promoted primary don&#39;t have<br>to perform a full sync.</p>\n<p>In case you wonder why a replica promoted to primary needs to change its<br>replication ID after a failover: it is possible that the old primary is still<br>working as a primary because of some network partition: retaining the same<br>replication ID would violate the fact that the same ID and same offset of any<br>two random instances mean they have the same data set.</p>\n<h2>Diskless replication</h2>\n<p>Normally a full resynchronization requires creating an RDB file on disk,<br>then reloading the same RDB from disk to feed the replicas with the data.</p>\n<p>With slow disks this can be a very stressing operation for the primary.<br>Valkey has support for diskless<br>replication. In this setup the child process directly sends the<br>RDB over the wire to replicas, without using the disk as intermediate storage.</p>\n<h2>Configuration</h2>\n<p>To configure basic Valkey replication is trivial: just add the following line to the replica configuration file:</p>\n<pre><code>replicaof 192.168.1.1 6379\n</code></pre>\n<p>Of course you need to replace 192.168.1.1 6379 with your primary IP address (or<br>hostname) and port. Alternatively, you can call the <code>REPLICAOF</code> command and the<br>primary host will start a sync with the replica.</p>\n<p>There are also a few parameters for tuning the replication backlog taken<br>in memory by the primary to perform the partial resynchronization. See the example<br><code>valkey.conf</code> shipped with the Valkey distribution for more information.</p>\n<p>Diskless replication can be enabled using the <code>repl-diskless-sync</code> configuration<br>parameter. The delay to start the transfer to wait for more replicas to<br>arrive after the first one is controlled by the <code>repl-diskless-sync-delay</code><br>parameter. Please refer to the example <code>valkey.conf</code> file in the Valkey distribution<br>for more details.</p>\n<h2>Read-only replica</h2>\n<p>Replicas are read-only by default.<br>This behavior is controlled by the <code>replica-read-only</code> option in the valkey.conf file, and can be enabled and disabled at runtime using <code>CONFIG SET</code>.</p>\n<p>Read-only replicas will reject all write commands, so that it is not possible to write to a replica because of a mistake. This does not mean that the feature is intended to expose a replica instance to the internet or more generally to a network where untrusted clients exist, because administrative commands like <code>DEBUG</code> or <code>CONFIG</code> are still enabled. The <a href=\"security\">Security</a> page describes how to secure a Valkey instance.</p>\n<p>You may wonder why it is possible to revert the read-only setting<br>and have replica instances that can be targeted by write operations.<br>The answer is that writable replicas exist only for historical reasons.<br>Using writable replicas can result in inconsistency between the primary and the replica, so it is not recommended to use writable replicas.<br>To understand in which situations this can be a problem, we need to understand how replication works.<br>Changes on the primary is replicated by propagating regular Valkey commands to the replica.<br>When a key expires on the primary, this is propagated as a DEL command.<br>If a key which exists on the primary but is deleted, expired or has a different type on the replica compared to the primary will react differently to commands like DEL, INCR or RPOP propagated from the primary than intended.<br>The propagated command may fail on the replica or result in a different outcome.<br>To minimize the risks (if you insist on using writable replicas) we suggest you follow these recommendations:</p>\n<ul>\n<li><p>Don&#39;t write to keys in a writable replica that are also used on the primary.<br>(This can be hard to guarantee if you don&#39;t have control over all the clients that write to the primary.)</p>\n</li>\n<li><p>Don&#39;t configure an instance as a writable replica as an intermediary step when upgrading a set of instances in a running system.<br>In general, don&#39;t configure an instance as a writable replica if it can ever be promoted to a primary if you want to guarantee data consistency.</p>\n</li>\n</ul>\n<p>Historically, there were some use cases that were considered legitimate for writable replicas.<br>As of version 7.0, these use cases are now all obsolete and the same can be achieved by other means.<br>For example:</p>\n<ul>\n<li><p>Computing slow Set or Sorted set operations and storing the result in temporary local keys using commands like <code>SUNIONSTORE</code> and <code>ZINTERSTORE</code>.<br>Instead, use commands that return the result without storing it, such as <code>SUNION</code> and <code>ZINTER</code>.</p>\n</li>\n<li><p>Using the <code>SORT</code> command (which is not considered a read-only command because of the optional STORE option and therefore cannot be used on a read-only replica).<br>Instead, use <code>SORT_RO</code>, which is a read-only command.</p>\n</li>\n<li><p>Using <code>EVAL</code> and <code>EVALSHA</code> are also not considered read-only commands, because the Lua script may call write commands.<br>Instead, use <code>EVAL_RO</code> and <code>EVALSHA_RO</code> where the Lua script can only call read-only commands.</p>\n</li>\n</ul>\n<p>While writes to a replica will be discarded if the replica and the primary resync or if the replica is restarted, there is no guarantee that they will sync automatically.</p>\n<p>Before version 4.0, writable replicas were incapable of expiring keys with a time to live set.<br>This means that if you use <code>EXPIRE</code> or other commands that set a maximum TTL for a key, the key will leak, and while you may no longer see it while accessing it with read commands, you will see it in the count of keys and it will still use memory.<br>Valkey is able to evict keys with TTL as primaries do, with the exceptions of keys written in DB numbers greater than 63 (but by default Valkey instances only have 16 databases).<br>Note though that even in versions greater than 4.0, using <code>EXPIRE</code> on a key that could ever exists on the primary can cause inconsistency between the replica and the primary.</p>\n<p>Also note that replica writes are only local, and are not propagated to sub-replicas attached to the instance. Sub-replicas instead will always receive the replication stream identical to the one sent by the top-level primary to the intermediate replicas. So for example in the following setup:</p>\n<pre><code>A ---&gt; B ---&gt; C\n</code></pre>\n<p>Even if <code>B</code> is writable, C will not see <code>B</code> writes and will instead have identical dataset as the primary instance <code>A</code>.</p>\n<h2>Setting a replica to authenticate to a primary</h2>\n<p>If your primary has a password via <code>requirepass</code>, it&#39;s trivial to configure the<br>replica to use that password in all sync operations.</p>\n<p>To do it on a running instance, use <code>valkey-cli</code> and type:</p>\n<pre><code>config set primaryauth &lt;password&gt;\n</code></pre>\n<p>To set it permanently, add this to your config file:</p>\n<pre><code>primaryauth &lt;password&gt;\n</code></pre>\n<h2>Allow writes only with N attached replicas</h2>\n<p>You can configure a Valkey primary to<br>accept write queries only if at least N replicas are currently connected to the<br>primary.</p>\n<p>However, because Valkey uses asynchronous replication it is not possible to ensure<br>the replica actually received a given write, so there is always a window for data<br>loss.</p>\n<p>This is how the feature works:</p>\n<ul>\n<li>Valkey replicas ping the primary every second, acknowledging the amount of replication stream processed.</li>\n<li>Valkey primaries will remember the last time it received a ping from every replica.</li>\n<li>The user can configure a minimum number of replicas that have a lag not greater than a maximum number of seconds.</li>\n</ul>\n<p>If there are at least N replicas, with a lag less than M seconds, then the write will be accepted.</p>\n<p>You may think of it as a best effort data safety mechanism, where consistency is not ensured for a given write, but at least the time window for data loss is restricted to a given number of seconds. In general bound data loss is better than unbound one.</p>\n<p>If the conditions are not met, the primary will instead reply with an error and the write will not be accepted.</p>\n<p>There are two configuration parameters for this feature:</p>\n<ul>\n<li>min-replicas-to-write <code>&lt;number of replicas&gt;</code></li>\n<li>min-replicas-max-lag <code>&lt;number of seconds&gt;</code></li>\n</ul>\n<p>For more information, please check the example <code>valkey.conf</code> file shipped with the<br>Valkey source distribution.</p>\n<h2>How Valkey replication deals with expires on keys</h2>\n<p>Valkey expires allow keys to have a limited time to live (TTL). Such a feature depends<br>on the ability of an instance to count the time, however Valkey replicas correctly<br>replicate keys with expires, even when such keys are altered using Lua<br>scripts.</p>\n<p>To implement such a feature Valkey cannot rely on the ability of the primary and<br>replica to have synced clocks, since this is a problem that cannot be solved<br>and would result in race conditions and diverging data sets, so Valkey<br>uses three main techniques to make the replication of expired keys<br>able to work:</p>\n<ol>\n<li>Replicas don&#39;t expire keys, instead they wait for primaries to expire the keys. When a primary expires a key (or evicts it because of LRU), it synthesizes a <code>DEL</code> command which is transmitted to all the replicas.</li>\n<li>However because of primary-driven expire, sometimes replicas may still have in memory keys that are already logically expired, since the primary was not able to provide the <code>DEL</code> command in time. To deal with that the replica uses its logical clock to report that a key does not exist <strong>only for read operations</strong> that don&#39;t violate the consistency of the data set (as new commands from the primary will arrive). In this way replicas avoid reporting logically expired keys that are still existing. In practical terms, an HTML fragments cache that uses replicas to scale will avoid returning items that are already older than the desired time to live.</li>\n<li>During Lua scripts executions no key expiries are performed. As a Lua script runs, conceptually the time in the primary is frozen, so that a given key will either exist or not for all the time the script runs. This prevents keys expiring in the middle of a script, and is needed to send the same script to the replica in a way that is guaranteed to have the same effects in the data set.</li>\n</ol>\n<p>Once a replica is promoted to a primary it will start to expire keys independently, and will not require any help from its old primary.</p>\n<h2>Configuring replication in Docker and NAT</h2>\n<p>When Docker, or other types of containers using port forwarding, or Network Address Translation is used, Valkey replication needs some extra care, especially when using Valkey Sentinel or other systems where the primary <code>INFO</code> or <code>ROLE</code> commands output is scanned to discover replicas&#39; addresses.</p>\n<p>The problem is that the <code>ROLE</code> command, and the replication section of<br>the <code>INFO</code> output, when issued into a primary instance, will show replicas<br>as having the IP address they use to connect to the primary, which, in<br>environments using NAT may be different compared to the logical address of the<br>replica instance (the one that clients should use to connect to replicas).</p>\n<p>Similarly the replicas will be listed with the listening port configured<br>into <code>valkey.conf</code>, that may be different from the forwarded port in case<br>the port is remapped.</p>\n<p>To fix both issues, it is possible to force<br>a replica to announce an arbitrary pair of IP and port to the primary.<br>The two configurations directives to use are:</p>\n<pre><code>replica-announce-ip 5.5.5.5\nreplica-announce-port 1234\n</code></pre>\n<p>And are documented in the example <code>valkey.conf</code> of recent Valkey distributions.</p>\n<h2>The INFO and ROLE command</h2>\n<p>There are two Valkey commands that provide a lot of information on the current<br>replication parameters of primary and replica instances. One is <code>INFO</code>. If the<br>command is called with the <code>replication</code> argument as <code>INFO replication</code> only<br>information relevant to the replication are displayed. Another more<br>computer-friendly command is <code>ROLE</code>, that provides the replication status of<br>primaries and replicas together with their replication offsets, list of connected<br>replicas and so forth.</p>\n<h2>Partial sync after restarts and failovers</h2>\n<p>When an instance is promoted to primary after a failover,<br>it will still be able to perform a partial resynchronization with the replicas<br>of the old primary. To do so, the replica remembers the old replication ID and<br>offset of its former primary, so can provide part of the backlog to the connecting<br>replicas even if they ask for the old replication ID.</p>\n<p>However the new replication ID of the promoted replica will be different, since it<br>constitutes a different history of the data set. For example, the primary can<br>return available and can continue accepting writes for some time, so using the<br>same replication ID in the promoted replica would violate the rule that a<br>replication ID and offset pair identifies only a single data set.</p>\n<p>Moreover, replicas - when powered off gently and restarted - are able to store<br>in the <code>RDB</code> file the information needed to resync with their<br>primary. This is useful in case of upgrades. When this is needed, it is better to<br>use the <code>SHUTDOWN</code> command in order to perform a <code>save &amp; quit</code> operation on the<br>replica.</p>\n<p>It is not possible to partially sync a replica that restarted via the<br>AOF file. However the instance may be turned to RDB persistence before shutting<br>down it, than can be restarted, and finally AOF can be enabled again.</p>\n<h2><code>Maxmemory</code> on replicas</h2>\n<p>By default, a replica will ignore <code>maxmemory</code> (unless it is promoted to a primary after a failover or manually).<br>It means that the eviction of keys will be handled by the primary, sending the DEL commands to the replica as keys evict in the primary side.</p>\n<p>This behavior ensures that primaries and replicas stay consistent, which is usually what you want.<br>However, if your replica is writable, or you want the replica to have a different memory setting, and you are sure all the writes performed to the replica are idempotent, then you may change this default (but be sure to understand what you are doing).</p>\n<p>Note that since the replica by default does not evict, it may end up using more memory than what is set via <code>maxmemory</code> (since there are certain buffers that may be larger on the replica, or data structures may sometimes take more memory and so forth).<br>Make sure you monitor your replicas, and make sure they have enough memory to never hit a real out-of-memory condition before the primary hits the configured <code>maxmemory</code> setting.</p>\n<p>To change this behavior, you can allow a replica to not ignore the <code>maxmemory</code>. The configuration directives to use is:</p>\n<pre><code>replica-ignore-maxmemory no\n</code></pre>\n"
  },
  {
    "id": "security",
    "topicName": "Security",
    "description": "Security model and features in Valkey",
    "htmlContent": "<p>This document provides an introduction to the topic of security from the point of<br>view of Valkey. It covers the access control provided by Valkey, code security concerns,<br>attacks that can be triggered from the outside by selecting malicious inputs, and<br>other similar topics. </p>\n<p>For security-related contacts, open an issue on GitHub, or when you feel it<br>is really important to preserve the security of the communication, use the<br>GPG key at the end of this document.</p>\n<h2>Security model</h2>\n<p>Valkey is designed to be accessed by trusted clients inside trusted environments.<br>This means that usually it is not a good idea to expose the Valkey instance<br>directly to the internet or, in general, to an environment where untrusted<br>clients can directly access the Valkey TCP port or UNIX socket.</p>\n<p>For instance, in the common context of a web application implemented using Valkey<br>as a database, cache, or messaging system, the clients inside the front-end<br>(web side) of the application will query Valkey to generate pages or<br>to perform operations requested or triggered by the web application user.</p>\n<p>In this case, the web application mediates access between Valkey and<br>untrusted clients (the user browsers accessing the web application).</p>\n<p>In general, untrusted access to Valkey should<br>always be mediated by a layer implementing ACLs, validating user input,<br>and deciding what operations to perform against the Valkey instance.</p>\n<h2>Network security</h2>\n<p>Access to the Valkey port should be denied to everybody but trusted clients<br>in the network, so the servers running Valkey should be directly accessible<br>only by the computers implementing the application using Valkey.</p>\n<p>In the common case of a single computer directly exposed to the internet, such<br>as a virtualized Linux instance (Linode, EC2, ...), the Valkey port should be<br>firewalled to prevent access from the outside. Clients will still be able to<br>access Valkey using the loopback interface.</p>\n<p>Note that it is possible to bind Valkey to a single interface by adding a line<br>like the following to the <strong>valkey.conf</strong> file:</p>\n<pre><code>bind 127.0.0.1\n</code></pre>\n<p>Failing to protect the Valkey port from the outside can have a big security<br>impact because of the nature of Valkey. For instance, a single <code>FLUSHALL</code> command can be used by an external attacker to delete the whole data set.</p>\n<h2>Protected mode</h2>\n<p>Unfortunately, many users fail to protect Valkey instances from being accessed<br>from external networks. Many instances are simply left exposed on the<br>internet with public IPs. Valkey enters a special mode called <strong>protected mode</strong> when it is<br>executed with the default configuration (binding all the interfaces) and<br>without any password in order to access it. In this mode, Valkey only replies to queries from the<br>loopback interfaces, and replies to clients connecting from other<br>addresses with an error that explains the problem and how to configure<br>Valkey properly.</p>\n<p>We expect protected mode to seriously decrease the security issues caused<br>by unprotected Valkey instances executed without proper administration. However,<br>the system administrator can still ignore the error given by Valkey and<br>disable protected mode or manually bind all the interfaces.</p>\n<h2>Authentication</h2>\n<p>Valkey provides two ways to authenticate clients.<br>The recommended authentication method is via Access Control Lists, allowing named users to be created and assigned fine-grained permissions.<br>Read more about Access Control Lists <a href=\"acl\">here</a>.</p>\n<p>The legacy authentication method is enabled by editing the <strong>valkey.conf</strong> file, and providing a database password using the <code>requirepass</code> setting.<br>This password is then used by all clients.</p>\n<p>When the <code>requirepass</code> setting is enabled, Valkey will refuse any query by<br>unauthenticated clients. A client can authenticate itself by sending the<br><strong>AUTH</strong> command followed by the password.</p>\n<p>The password is set by the system administrator in clear text inside the<br>valkey.conf file. It should be long enough to prevent brute force attacks<br>for two reasons:</p>\n<ul>\n<li>Valkey is very fast at serving queries. Many passwords per second can be tested by an external client.</li>\n<li>The Valkey password is stored in the <strong>valkey.conf</strong> file and inside the client configuration. Since the system administrator does not need to remember it, the password can be very long.</li>\n</ul>\n<p>The goal of the authentication layer is to optionally provide a layer of<br>redundancy. If firewalling or any other system implemented to protect Valkey<br>from external attackers fail, an external client will still not be able to<br>access the Valkey instance without knowledge of the authentication password.</p>\n<p>Since the <code>AUTH</code> command, like every other Valkey command, is sent unencrypted, it<br>does not protect against an attacker that has enough access to the network to<br>perform eavesdropping.</p>\n<h2>TLS support</h2>\n<p>Valkey has optional support for TLS on all communication channels, including<br>client connections, replication links, and the Valkey Cluster bus protocol.</p>\n<h2>Attacks triggered by malicious inputs from external clients</h2>\n<p>There is a class of attacks that an attacker can trigger from the outside even<br>without external access to the instance. For example, an attacker might insert data into Valkey that triggers pathological (worst case)<br>algorithm complexity on data structures implemented inside Valkey internals.</p>\n<p>An attacker could supply, via a web form, a set of strings that<br>are known to hash to the same bucket in a hash table in order to turn the<br>O(1) expected time (the average time) to the O(N) worst case. This can consume more<br>CPU than expected and ultimately cause a Denial of Service.</p>\n<p>To prevent this specific attack, Valkey uses a per-execution, pseudo-random<br>seed to the hash function.</p>\n<p>Valkey implements the SORT command using the qsort algorithm. Currently,<br>the algorithm is not randomized, so it is possible to trigger a quadratic<br>worst-case behavior by carefully selecting the right set of inputs.</p>\n<h2>String escaping and NoSQL injection</h2>\n<p>The Valkey protocol has no concept of string escaping, so injection<br>is impossible under normal circumstances using a normal client library.<br>The protocol uses prefixed-length strings and is completely binary safe.</p>\n<p>Since Lua scripts executed by the <code>EVAL</code> and <code>EVALSHA</code> commands follow the<br>same rules, those commands are also safe.</p>\n<p>While it would be a strange use case, the application should avoid composing the body of the Lua script from strings obtained from untrusted sources.</p>\n<h2>Code security</h2>\n<p>Internally, Valkey uses all the well-known practices for writing secure code to<br>prevent buffer overflows, format bugs, and other memory corruption issues.</p>\n<p>Valkey does not require root privileges to run. It is recommended to<br>run it as an unprivileged <em>valkey</em> user that is only used for this purpose.</p>\n"
  },
  {
    "id": "sentinel-clients",
    "topicName": "Sentinel client spec",
    "description": "How to build clients for Valkey Sentinel",
    "htmlContent": "<p>Valkey Sentinel is a monitoring solution for Valkey instances that handles<br>automatic failover of Valkey primaries and service discovery (who is the current<br>primary for a given group of instances?). Since Sentinel is both responsible<br>for reconfiguring instances during failovers, and providing configurations to<br>clients connecting to Valkey primaries or replicas, clients are required to have<br>explicit support for Valkey Sentinel.</p>\n<p>This document is targeted at Valkey clients developers that want to support Sentinel in their clients implementation with the following goals:</p>\n<ul>\n<li>Automatic configuration of clients via Sentinel.</li>\n<li>Improved safety of Valkey Sentinel automatic failover.</li>\n</ul>\n<p>For details about how Valkey Sentinel works, please check the <a href=\"sentinel\">Valkey Documentation</a>, as this document only contains information needed for Valkey client developers, and it is expected that readers are familiar with the way Valkey Sentinel works.</p>\n<h2>Valkey service discovery via Sentinel</h2>\n<p>Valkey Sentinel identifies every primary with a name like &quot;stats&quot; or &quot;cache&quot;.<br>Every name actually identifies a <em>group of instances</em>, composed of a primary<br>and a variable number of replicas.</p>\n<p>The address of the Valkey primary that is used for a specific purpose inside a network may change after events like an automatic failover, a manually triggered failover (for instance in order to upgrade a Valkey instance), and other reasons.</p>\n<p>Normally Valkey clients have some kind of hard-coded configuration that specifies the address of a Valkey primary instance within a network as IP address and port number. However if the primary address changes, manual intervention in every client is needed.</p>\n<p>A Valkey client supporting Sentinel can automatically discover the address of a Valkey primary from the primary name using Valkey Sentinel. So instead of a hard coded IP address and port, a client supporting Sentinel should optionally be able to take as input:</p>\n<ul>\n<li>A list of ip:port pairs pointing to known Sentinel instances.</li>\n<li>The name of the service, like &quot;cache&quot; or &quot;timelines&quot;.</li>\n</ul>\n<p>This is the procedure a client should follow in order to obtain the primary address starting from the list of Sentinels and the service name.</p>\n<h2>Step 1: connect to the first Sentinel</h2>\n<p>The client should iterate the list of Sentinel addresses. For every address it should try to connect to the Sentinel, using a short timeout (in the order of a few hundreds of milliseconds). On errors or timeouts the next Sentinel address should be tried.</p>\n<p>If all the Sentinel addresses were tried without success, an error should be returned to the client.</p>\n<p>The first Sentinel replying to the client request should be put at the start of the list, so that at the next reconnection, we&#39;ll try first the Sentinel that was reachable in the previous connection attempt, minimizing latency.</p>\n<h2>Step 2: ask for primary address</h2>\n<p>Once a connection with a Sentinel is established, the client should retry to execute the following command on the Sentinel:</p>\n<pre><code>SENTINEL get-master-addr-by-name master-name\n</code></pre>\n<p>Where <em>master-name</em> should be replaced with the actual service name specified by the user.</p>\n<p>The result from this call can be one of the following two replies:</p>\n<ul>\n<li>An ip:port pair.</li>\n<li>A null reply. This means Sentinel does not know this primary.</li>\n</ul>\n<p>If an ip:port pair is received, this address should be used to connect to the Valkey primary. Otherwise if a null reply is received, the client should try the next Sentinel in the list.</p>\n<h2>Step 3: call the ROLE command in the target instance</h2>\n<p>Once the client discovered the address of the primary instance, it should<br>attempt a connection with the primary, and call the <code>ROLE</code> command in order<br>to verify the role of the instance is actually a primary.</p>\n<p>If the instance is not a primary as expected, the client should wait a short amount of time (a few hundreds of milliseconds) and should try again starting from Step 1.</p>\n<h1>Handling reconnections</h1>\n<p>Once the service name is resolved into the primary address and a connection is established with the Valkey primary instance, every time a reconnection is needed, the client should resolve again the address using Sentinels restarting from Step 1. For instance Sentinel should contacted again the following cases:</p>\n<ul>\n<li>If the client reconnects after a timeout or socket error.</li>\n<li>If the client reconnects because it was explicitly closed or reconnected by the user.</li>\n</ul>\n<p>In the above cases and any other case where the client lost the connection with the Valkey server, the client should resolve the primary address again.</p>\n<h1>Sentinel failover disconnection</h1>\n<p>When Valkey Sentinel changes the configuration of<br>an instance, for example promoting a replica to a primary, demoting a primary to<br>replicate to the new primary after a failover, or simply changing the primary<br>address of a stale replica instance, it sends a <code>CLIENT KILL type normal</code><br>command to the instance in order to make sure all the clients are disconnected<br>from the reconfigured instance. This will force clients to resolve the primary<br>address again.</p>\n<p>If the client will contact a Sentinel with yet not updated information, the verification of the Valkey instance role via the <code>ROLE</code> command will fail, allowing the client to detect that the contacted Sentinel provided stale information, and will try again.</p>\n<p>Note: it is possible that a stale primary returns online at the same time a client contacts a stale Sentinel instance, so the client may connect with a stale primary, and yet the ROLE output will match. However when the primary is back again Sentinel will try to demote it to replica, triggering a new disconnection. The same reasoning applies to connecting to stale replicas that will get reconfigured to replicate with a different primary.</p>\n<h1>Connecting to replicas</h1>\n<p>Sometimes clients are interested to connect to replicas, for example in order to scale read requests. This protocol supports connecting to replicas by modifying step 2 slightly. Instead of calling the following command:</p>\n<pre><code>SENTINEL get-master-addr-by-name master-name\n</code></pre>\n<p>The clients should call instead:</p>\n<pre><code>SENTINEL replicas primary-name\n</code></pre>\n<p>In order to retrieve a list of replica instances.</p>\n<p>Symmetrically the client should verify with the <code>ROLE</code> command that the<br>instance is actually a replica, in order to avoid scaling read queries with<br>the primary.</p>\n<h1>Connection pools</h1>\n<p>For clients implementing connection pools, on reconnection of a single connection, the Sentinel should be contacted again, and in case of a primary address change all the existing connections should be closed and connected to the new address.</p>\n<h1>Error reporting</h1>\n<p>The client should correctly return the information to the user in case of errors. Specifically:</p>\n<ul>\n<li>If no Sentinel can be contacted (so that the client was never able to get the reply to <code>SENTINEL get-master-addr-by-name</code>), an error that clearly states that Valkey Sentinel is unreachable should be returned.</li>\n<li>If all the Sentinels in the pool replied with a null reply, the user should be informed with an error that Sentinels don&#39;t know this primary name.</li>\n</ul>\n<h1>Sentinels list automatic refresh</h1>\n<p>Optionally once a successful reply to <code>get-master-addr-by-name</code> is received, a client may update its internal list of Sentinel nodes following this procedure:</p>\n<ul>\n<li>Obtain a list of other Sentinels for this primary using the command <code>SENTINEL sentinels &lt;master-name&gt;</code>.</li>\n<li>Add every ip:port pair not already existing in our list at the end of the list.</li>\n</ul>\n<p>It is not needed for a client to be able to make the list persistent updating its own configuration. The ability to upgrade the in-memory representation of the list of Sentinels can be already useful to improve reliability.</p>\n<h1>Subscribe to Sentinel events to improve responsiveness</h1>\n<p>The <a href=\"sentinel\">Sentinel documentation</a> shows how clients can connect to<br>Sentinel instances using Pub/Sub in order to subscribe to changes in the<br>Valkey instances configurations.</p>\n<p>This mechanism can be used in order to speedup the reconfiguration of clients,<br>that is, clients may listen to Pub/Sub in order to know when a configuration<br>change happened in order to run the three steps protocol explained in this<br>document in order to resolve the new Valkey primary (or replica) address.</p>\n<p>However update messages received via Pub/Sub should not substitute the<br>above procedure, since there is no guarantee that a client is able to<br>receive all the update messages.</p>\n<blockquote>\n<p>NOTE: If not for backward compatibility, the Valkey project no longer uses the words &quot;master&quot; and &quot;slave&quot;. Unfortunately in the given commands these words are part of the protocol, so we’ll be able to remove such occurrences only when this API will be naturally deprecated.</p>\n</blockquote>\n"
  },
  {
    "id": "sentinel",
    "topicName": "High availability with Valkey Sentinel",
    "description": "High availability for non-clustered Valkey",
    "htmlContent": "<h2>Usage</h2>\n<p><strong><code>valkey-sentinel</code></strong> <em>/path/to/sentinel.conf</em></p>\n<p><strong><code>valkey-server</code></strong> <em>/path/to/sentinel.conf</em> <strong><code>--sentinel</code></strong></p>\n<h2>Description</h2>\n<p>Valkey Sentinel provides high availability for Valkey when not using <a href=\"cluster-tutorial\">Valkey Cluster</a>. </p>\n<p>Valkey Sentinel also provides other collateral tasks such as monitoring,<br>notifications and acts as a configuration provider for clients.</p>\n<p>This is the full list of Sentinel capabilities at a macroscopic level (i.e. the <em>big picture</em>):</p>\n<ul>\n<li><strong>Monitoring</strong>. Sentinel constantly checks if your primary and replica instances are working as expected.</li>\n<li><strong>Notification</strong>. Sentinel can notify the system administrator, or other computer programs, via the API, that something is wrong with one of the monitored Valkey instances.</li>\n<li><strong>Automatic failover</strong>. If a primary is not working as expected, Sentinel can start a failover process where a replica is promoted to primary, the other additional replicas are reconfigured to use the new primary, and the applications using the Valkey server are informed about the new address to use when connecting.</li>\n<li><strong>Configuration provider</strong>. Sentinel acts as a source of authority for clients service discovery: clients connect to Sentinels in order to ask for the address of the current Valkey primary responsible for a given service. If a failover occurs, Sentinels will report the new address.</li>\n</ul>\n<h2>Sentinel as a distributed system</h2>\n<p>Valkey Sentinel is a distributed system:</p>\n<p>Sentinel itself is designed to run in a configuration where there are multiple Sentinel processes cooperating together. The advantage of having multiple Sentinel processes cooperating are the following:</p>\n<ol>\n<li>Failure detection is performed when multiple Sentinels agree about the fact a given primary is no longer available. This lowers the probability of false positives.</li>\n<li>Sentinel works even if not all the Sentinel processes are working, making the system robust against failures. There is no fun in having a failover system which is itself a single point of failure, after all.</li>\n</ol>\n<p>The sum of Sentinels, Valkey instances (primaries and replicas) and clients<br>connecting to Sentinel and Valkey, are also a larger distributed system with<br>specific properties. In this document concepts will be introduced gradually<br>starting from basic information needed in order to understand the basic<br>properties of Sentinel, to more complex information (that are optional) in<br>order to understand how exactly Sentinel works.</p>\n<h2>Sentinel quick start</h2>\n<p>Valkey Sentinel is included in Valkey.</p>\n<h3>Running Sentinel</h3>\n<p>If you are using the <code>valkey-sentinel</code> executable (or if you have a symbolic<br>link with that name to the <code>valkey-server</code> executable) you can run Sentinel<br>with the following command line:</p>\n<pre><code>valkey-sentinel /path/to/sentinel.conf\n</code></pre>\n<p>Otherwise you can use directly the <code>valkey-server</code> executable starting it in<br>Sentinel mode:</p>\n<pre><code>valkey-server /path/to/sentinel.conf --sentinel\n</code></pre>\n<p>Both ways work the same.</p>\n<p>However <strong>it is mandatory</strong> to use a configuration file when running Sentinel, as this file will be used by the system in order to save the current state that will be reloaded in case of restarts. Sentinel will simply refuse to start if no configuration file is given or if the configuration file path is not writable.</p>\n<p>Sentinels by default run <strong>listening for connections to TCP port 26379</strong>, so<br>for Sentinels to work, port 26379 of your servers <strong>must be open</strong> to receive<br>connections from the IP addresses of the other Sentinel instances.<br>Otherwise Sentinels can&#39;t talk and can&#39;t agree about what to do, so failover<br>will never be performed.</p>\n<h3>Fundamental things to know about Sentinel before deploying</h3>\n<ol>\n<li>You need at least three Sentinel instances for a robust deployment.</li>\n<li>The three Sentinel instances should be placed into computers or virtual machines that are believed to fail in an independent way. So for example different physical servers or Virtual Machines executed on different availability zones.</li>\n<li>Sentinel + Valkey distributed system does not guarantee that acknowledged writes are retained during failures, since Valkey uses asynchronous replication. However there are ways to deploy Sentinel that make the window to lose writes limited to certain moments, while there are other less secure ways to deploy it.</li>\n<li>You need Sentinel support in your clients. Popular client libraries have Sentinel support, but not all.</li>\n<li>There is no HA setup which is safe if you don&#39;t test from time to time in development environments, or even better, if you can in production environments, if they work. You may have a misconfiguration that will become apparent only when it&#39;s too late (at 3am when your primary stops working).</li>\n<li><strong>Sentinel, Docker, or other forms of Network Address Translation or Port Mapping should be mixed with care</strong>: Docker performs port remapping, breaking Sentinel auto discovery of other Sentinel processes and the list of replicas for a primary. Check the <a href=\"#sentinel-docker-nat-and-possible-issues\">section about <em>Sentinel and Docker</em></a> later in this document for more information.</li>\n</ol>\n<h3>Configuring Sentinel</h3>\n<p>The Valkey source distribution contains a file called <code>sentinel.conf</code><br>that is a self-documented example configuration file you can use to<br>configure Sentinel, however a typical minimal configuration file looks like the<br>following:</p>\n<pre><code>sentinel monitor mymaster 127.0.0.1 6379 2\nsentinel down-after-milliseconds mymaster 60000\nsentinel failover-timeout mymaster 180000\nsentinel parallel-syncs mymaster 1\n\nsentinel monitor resque 192.168.1.3 6380 4\nsentinel down-after-milliseconds resque 10000\nsentinel failover-timeout resque 180000\nsentinel parallel-syncs resque 5\n</code></pre>\n<p>You only need to specify the primaries to monitor, giving to each separated<br>primary (that may have any number of replicas) a different name. There is no<br>need to specify replicas, which are auto-discovered. Sentinel will update the<br>configuration automatically with additional information about replicas (in<br>order to retain the information in case of restart). The configuration is<br>also rewritten every time a replica is promoted to primary during a failover<br>and every time a new Sentinel is discovered.</p>\n<p>The example configuration above basically monitors two sets of Valkey<br>instances, each composed of a primary and an undefined number of replicas.<br>One set of instances is called <code>mymaster</code>, and the other <code>resque</code>.</p>\n<p>The meaning of the arguments of <code>sentinel monitor</code> statements is the following:</p>\n<pre><code>sentinel monitor &lt;primary-name&gt; &lt;ip&gt; &lt;port&gt; &lt;quorum&gt;\n</code></pre>\n<p>For the sake of clarity, let&#39;s check line by line what the configuration<br>options mean:</p>\n<p>The first line is used to tell Valkey to monitor a primary called <em>mymaster</em>,<br>that is at address 127.0.0.1 and port 6379, with a quorum of 2. Everything<br>is pretty obvious but the <strong>quorum</strong> argument:</p>\n<ul>\n<li>The <strong>quorum</strong> is the number of Sentinels that need to agree about the fact the primary is not reachable, in order to really mark the primary as failing, and eventually start a failover procedure if possible.</li>\n<li>However <strong>the quorum is only used to detect the failure</strong>. In order to actually perform a failover, one of the Sentinels need to be elected leader for the failover and be authorized to proceed. This only happens with the vote of the <strong>majority of the Sentinel processes</strong>.</li>\n</ul>\n<p>So for example if you have 5 Sentinel processes, and the quorum for a given<br>primary is set to the value of 2, this is what happens:</p>\n<ul>\n<li>If two Sentinels agree at the same time about the primary being unreachable, one of the two will try to start a failover.</li>\n<li>If there are at least a total of three Sentinels reachable, the failover will be authorized and will actually start.</li>\n</ul>\n<p>In practical terms this means during failures <strong>Sentinel never starts a failover if the majority of Sentinel processes are unable to talk</strong> (aka no failover in the minority partition).</p>\n<h3>Other Sentinel options</h3>\n<p>The other options are almost always in the form:</p>\n<pre><code>sentinel &lt;option_name&gt; &lt;primary_name&gt; &lt;option_value&gt;\n</code></pre>\n<p>And are used for the following purposes:</p>\n<ul>\n<li><code>down-after-milliseconds</code> is the time in milliseconds an instance should not<br>be reachable (either does not reply to our PINGs or it is replying with an<br>error) for a Sentinel starting to think it is down.</li>\n<li><code>parallel-syncs</code> sets the number of replicas that can be reconfigured to use<br>the new primary after a failover at the same time. The lower the number, the<br>more time it will take for the failover process to complete, however if the<br>replicas are configured to serve old data, you may not want all the replicas to<br>re-synchronize with the primary at the same time. While the replication<br>process is mostly non blocking for a replica, there is a moment when it stops to<br>load the bulk data from the primary. You may want to make sure only one replica<br>at a time is not reachable by setting this option to the value of 1.</li>\n</ul>\n<p>Additional options are described in the rest of this document and<br>documented in the example <code>sentinel.conf</code> file shipped with the Valkey<br>distribution.</p>\n<p>Configuration parameters can be modified at runtime:</p>\n<ul>\n<li>Master-specific configuration parameters are modified using <code>SENTINEL SET</code>.</li>\n<li>Global configuration parameters are modified using <code>SENTINEL CONFIG SET</code>.</li>\n</ul>\n<p>See the <a href=\"#reconfiguring-sentinel-at-runtime\"><em>Reconfiguring Sentinel at runtime</em> section</a> for more information.</p>\n<h3>Example Sentinel deployments</h3>\n<p>Now that you know the basic information about Sentinel, you may wonder where<br>you should place your Sentinel processes, how many Sentinel processes you need<br>and so forth. This section shows a few example deployments.</p>\n<p>We use ASCII art in order to show you configuration examples in a <em>graphical</em><br>format, this is what the different symbols means:</p>\n<pre><code>+--------------------+\n| This is a computer |\n| or VM that fails   |\n| independently. We  |\n| call it a &quot;box&quot;    |\n+--------------------+\n</code></pre>\n<p>We write inside the boxes what they are running:</p>\n<pre><code>+--------------------+\n| Valkey primary M1   |\n| Valkey Sentinel S1 |\n+--------------------+\n</code></pre>\n<p>Different boxes are connected by lines, to show that they are able to talk:</p>\n<pre><code>+-------------+               +-------------+\n| Sentinel S1 |---------------| Sentinel S2 |\n+-------------+               +-------------+\n</code></pre>\n<p>Network partitions are shown as interrupted lines using slashes:</p>\n<pre><code>+-------------+                +-------------+\n| Sentinel S1 |------ // ------| Sentinel S2 |\n+-------------+                +-------------+\n</code></pre>\n<p>Also note that:</p>\n<ul>\n<li>Primaries are called M1, M2, M3, ..., Mn.</li>\n<li>Replicas are called R1, R2, R3, ..., Rn (R stands for <em>replica</em>).</li>\n<li>Sentinels are called S1, S2, S3, ..., Sn.</li>\n<li>Clients are called C1, C2, C3, ..., Cn.</li>\n<li>When an instance changes role because of Sentinel actions, we put it inside square brackets, so [M1] means an instance that is now a primary because of Sentinel intervention.</li>\n</ul>\n<p>Note that we will never show <strong>setups where just two Sentinels are used</strong>, since<br>Sentinels always need <strong>to talk with the majority</strong> in order to start a<br>failover.</p>\n<h4>Example 1: just two Sentinels, DON&#39;T DO THIS</h4>\n<pre><code>+----+         +----+\n| M1 |---------| R1 |\n| S1 |         | S2 |\n+----+         +----+\n\nConfiguration: quorum = 1\n</code></pre>\n<ul>\n<li>In this setup, if the primary M1 fails, R1 will be promoted since the two Sentinels can reach agreement about the failure (obviously with quorum set to 1) and can also authorize a failover because the majority is two. So apparently it could superficially work, however check the next points to see why this setup is broken.</li>\n<li>If the box where M1 is running stops working, also S1 stops working. The Sentinel running in the other box S2 will not be able to authorize a failover, so the system will become not available.</li>\n</ul>\n<p>Note that a majority is needed in order to order different failovers, and later propagate the latest configuration to all the Sentinels. Also note that the ability to failover in a single side of the above setup, without any agreement, would be very dangerous:</p>\n<pre><code>+----+           +------+\n| M1 |----//-----| [M1] |\n| S1 |           | S2   |\n+----+           +------+\n</code></pre>\n<p>In the above configuration we created two primaries (assuming S2 could failover<br>without authorization) in a perfectly symmetrical way. Clients may write<br>indefinitely to both sides, and there is no way to understand when the<br>partition heals what configuration is the right one, in order to prevent<br>a <em>permanent split brain condition</em>.</p>\n<p>So please <strong>deploy at least three Sentinels in three different boxes</strong> always.</p>\n<h4>Example 2: basic setup with three boxes</h4>\n<p>This is a very simple setup, that has the advantage to be simple to tune<br>for additional safety. It is based on three boxes, each box running both<br>a Valkey process and a Sentinel process.</p>\n<pre><code>       +----+\n       | M1 |\n       | S1 |\n       +----+\n          |\n+----+    |    +----+\n| R2 |----+----| R3 |\n| S2 |         | S3 |\n+----+         +----+\n\nConfiguration: quorum = 2\n</code></pre>\n<p>If the primary M1 fails, S2 and S3 will agree about the failure and will<br>be able to authorize a failover, making clients able to continue.</p>\n<p>In every Sentinel setup, as Valkey uses asynchronous replication, there is<br>always the risk of losing some writes because a given acknowledged write<br>may not be able to reach the replica which is promoted to primary. However in<br>the above setup there is a higher risk due to clients being partitioned away<br>with an old primary, like in the following picture:</p>\n<pre><code>         +----+\n         | M1 |\n         | S1 | &lt;- C1 (writes will be lost)\n         +----+\n            |\n            /\n            /\n+------+    |    +----+\n| [M2] |----+----| R3 |\n| S2   |         | S3 |\n+------+         +----+\n</code></pre>\n<p>In this case a network partition isolated the old primary M1, so the<br>replica R2 is promoted to primary. However clients, like C1, that are<br>in the same partition as the old primary, may continue to write data<br>to the old primary. This data will be lost forever since when the partition<br>will heal, the primary will be reconfigured as a replica of the new primary,<br>discarding its data set.</p>\n<p>This problem can be mitigated using the following Valkey replication<br>feature, that allows to stop accepting writes if a primary detects that<br>it is no longer able to transfer its writes to the specified number of replicas.</p>\n<pre><code>min-replicas-to-write 1\nmin-replicas-max-lag 10\n</code></pre>\n<p>With the above configuration (please see the self-commented <code>valkey.conf</code> example in the Valkey distribution for more information) a Valkey instance, when acting as a primary, will stop accepting writes if it can&#39;t write to at least 1 replica. Since replication is asynchronous <em>not being able to write</em> actually means that the replica is either disconnected, or is not sending us asynchronous acknowledges for more than the specified <code>max-lag</code> number of seconds.</p>\n<p>Using this configuration, the old Valkey primary M1 in the above example, will become unavailable after 10 seconds. When the partition heals, the Sentinel configuration will converge to the new one, the client C1 will be able to fetch a valid configuration and will continue with the new primary.</p>\n<p>However there is no free lunch. With this refinement, if the two replicas are<br>down, the primary will stop accepting writes. It&#39;s a trade off.</p>\n<h4>Example 3: Sentinel in the client boxes</h4>\n<p>Sometimes we have only two Valkey boxes available, one for the primary and<br>one for the replica. The configuration in the example 2 is not viable in<br>that case, so we can resort to the following, where Sentinels are placed<br>where clients are:</p>\n<pre><code>            +----+         +----+\n            | M1 |----+----| R1 |\n            |    |    |    |    |\n            +----+    |    +----+\n                      |\n         +------------+------------+\n         |            |            |\n         |            |            |\n      +----+        +----+      +----+\n      | C1 |        | C2 |      | C3 |\n      | S1 |        | S2 |      | S3 |\n      +----+        +----+      +----+\n\n      Configuration: quorum = 2\n</code></pre>\n<p>In this setup, the point of view Sentinels is the same as the clients: if<br>a primary is reachable by the majority of the clients, it is fine.<br>C1, C2, C3 here are generic clients, it does not mean that C1 identifies<br>a single client connected to Valkey. It is more likely something like<br>an application server, a Rails app, or something like that.</p>\n<p>If the box where M1 and S1 are running fails, the failover will happen<br>without issues, however it is easy to see that different network partitions<br>will result in different behaviors. For example Sentinel will not be able<br>to setup if the network between the clients and the Valkey servers is<br>disconnected, since the Valkey primary and replica will both be unavailable.</p>\n<p>Note that if C3 gets partitioned with M1 (hardly possible with<br>the network described above, but more likely possible with different<br>layouts, or because of failures at the software layer), we have a similar<br>issue as described in Example 2, with the difference that here we have<br>no way to break the symmetry, since there is just a replica and a primary, so<br>the primary can&#39;t stop accepting queries when it is disconnected from its replica,<br>otherwise the primary would never be available during replica failures.</p>\n<p>So this is a valid setup but the setup in the Example 2 has advantages<br>such as the HA system of Valkey running in the same boxes as Valkey itself<br>which may be simpler to manage, and the ability to put a bound on the amount<br>of time a primary in the minority partition can receive writes.</p>\n<h4>Example 4: Sentinel client side with less than three clients</h4>\n<p>The setup described in the Example 3 cannot be used if there are less than<br>three boxes in the client side (for example three web servers). In this<br>case we need to resort to a mixed setup like the following:</p>\n<pre><code>            +----+         +----+\n            | M1 |----+----| R1 |\n            | S1 |    |    | S2 |\n            +----+    |    +----+\n                      |\n               +------+-----+\n               |            |\n               |            |\n            +----+        +----+\n            | C1 |        | C2 |\n            | S3 |        | S4 |\n            +----+        +----+\n\n      Configuration: quorum = 3\n</code></pre>\n<p>This is similar to the setup in Example 3, but here we run four Sentinels<br>in the four boxes we have available. If the primary M1 becomes unavailable<br>the other three Sentinels will perform the failover.</p>\n<p>In theory this setup works removing the box where C2 and S4 are running, and<br>setting the quorum to 2. However it is unlikely that we want HA in the<br>Valkey side without having high availability in our application layer.</p>\n<h3>Sentinel, Docker, NAT, and possible issues</h3>\n<p>Docker uses a technique called port mapping: programs running inside Docker<br>containers may be exposed with a different port compared to the one the<br>program believes to be using. This is useful in order to run multiple<br>containers using the same ports, at the same time, in the same server.</p>\n<p>Docker is not the only software system where this happens, there are other<br>Network Address Translation setups where ports may be remapped, and sometimes<br>not ports but also IP addresses.</p>\n<p>Remapping ports and addresses creates issues with Sentinel in two ways:</p>\n<ol>\n<li>Sentinel auto-discovery of other Sentinels no longer works, since it is based on <em>hello</em> messages where each Sentinel announce at which port and IP address they are listening for connection. However Sentinels have no way to understand that an address or port is remapped, so it is announcing an information that is not correct for other Sentinels to connect.</li>\n<li>Replicas are listed in the <code>INFO</code> output of a Valkey primary in a similar way: the address is detected by the primary checking the remote peer of the TCP connection, while the port is advertised by the replica itself during the handshake, however the port may be wrong for the same reason as exposed in point 1.</li>\n</ol>\n<p>Since Sentinels auto detect replicas using primaries <code>INFO</code> output information,<br>the detected replicas will not be reachable, and Sentinel will never be able to<br>failover the primary, since there are no good replicas from the point of view of<br>the system, so there is currently no way to monitor with Sentinel a set of<br>primary and replica instances deployed with Docker, <strong>unless you instruct Docker<br>to map the port 1:1</strong>.</p>\n<p>For the first problem, in case you want to run a set of Sentinel<br>instances using Docker with forwarded ports (or any other NAT setup where ports<br>are remapped), you can use the following two Sentinel configuration directives<br>in order to force Sentinel to announce a specific set of IP and port:</p>\n<pre><code>sentinel announce-ip &lt;ip&gt;\nsentinel announce-port &lt;port&gt;\n</code></pre>\n<p>Note that Docker has the ability to run in <em>host networking mode</em> (check the <code>--net=host</code> option for more information). This should create no issues since ports are not remapped in this setup.</p>\n<h3>IP Addresses and DNS names</h3>\n<p>Older versions of Sentinel did not support host names and required IP addresses to be specified everywhere.<br>Starting with version 6.2, Sentinel has <em>optional</em> support for host names.</p>\n<p><strong>This capability is disabled by default. If you&#39;re going to enable DNS/hostnames support, please note:</strong></p>\n<ol>\n<li>The name resolution configuration on your Valkey and Sentinel nodes must be reliable and be able to resolve addresses quickly. Unexpected delays in address resolution may have a negative impact on Sentinel.</li>\n<li>You should use hostnames everywhere and avoid mixing hostnames and IP addresses. To do that, use <code>replica-announce-ip &lt;hostname&gt;</code> and <code>sentinel announce-ip &lt;hostname&gt;</code> for all Valkey and Sentinel instances, respectively.</li>\n</ol>\n<p>Enabling the <code>resolve-hostnames</code> global configuration allows Sentinel to accept host names:</p>\n<ul>\n<li>As part of a <code>sentinel monitor</code> command</li>\n<li>As a replica address, if the replica uses a host name value for <code>replica-announce-ip</code></li>\n</ul>\n<p>Sentinel will accept host names as valid inputs and resolve them, but will still refer to IP addresses when announcing an instance, updating configuration files, etc.</p>\n<p>Enabling the <code>announce-hostnames</code> global configuration makes Sentinel use host names instead. This affects replies to clients, values written in configuration files, the <code>REPLICAOF</code> command issued to replicas, etc.</p>\n<p>This behavior may not be compatible with all Sentinel clients, that may explicitly expect an IP address.</p>\n<p>Using host names may be useful when clients use TLS to connect to instances and require a name rather than an IP address in order to perform certificate ASN matching.</p>\n<h2>A quick tutorial</h2>\n<p>In the next sections of this document, all the details about <a href=\"#sentinel-api\"><em>Sentinel API</em></a>,<br>configuration and semantics will be covered incrementally. However for people<br>that want to play with the system ASAP, this section is a tutorial that shows<br>how to configure and interact with 3 Sentinel instances.</p>\n<p>Here we assume that the instances are executed at port 5000, 5001, 5002.<br>We also assume that you have a running Valkey primary at port 6379 with a<br>replica running at port 6380. We will use the IPv4 loopback address 127.0.0.1<br>everywhere during the tutorial, assuming you are running the simulation<br>on your personal computer.</p>\n<p>The three Sentinel configuration files should look like the following:</p>\n<pre><code>port 5000\nsentinel monitor mymaster 127.0.0.1 6379 2\nsentinel down-after-milliseconds mymaster 5000\nsentinel failover-timeout mymaster 60000\nsentinel parallel-syncs mymaster 1\n</code></pre>\n<p>The other two configuration files will be identical but using 5001 and 5002<br>as port numbers.</p>\n<p>A few things to note about the above configuration:</p>\n<ul>\n<li>The primary set is called <code>mymaster</code>. It identifies the primary and its replicas. Since each <em>primary set</em> has a different name, Sentinel can monitor different sets of primaries and replicas at the same time.</li>\n<li>The quorum was set to the value of 2 (last argument of <code>sentinel monitor</code> configuration directive).</li>\n<li>The <code>down-after-milliseconds</code> value is 5000 milliseconds, that is 5 seconds, so primaries will be detected as failing as soon as we don&#39;t receive any reply from our pings within this amount of time.</li>\n</ul>\n<p>Once you start the three Sentinels, you&#39;ll see a few messages they log, like:</p>\n<pre><code>+monitor master mymaster 127.0.0.1 6379 quorum 2\n</code></pre>\n<p>This is a Sentinel event, and you can receive this kind of events via Pub/Sub<br>if you <code>SUBSCRIBE</code> to the event name as specified later in <a href=\"#pubsub-messages\"><em>Pubsub Messages</em> section</a>.</p>\n<p>Sentinel generates and logs different events during failure detection and<br>failover.</p>\n<h2>Asking Sentinel about the state of a primary</h2>\n<p>The most obvious thing to do with Sentinel to get started, is check if the<br>primary it is monitoring is doing well:</p>\n<pre><code>$ valkey-cli -p 5000\n127.0.0.1:5000&gt; sentinel master mymaster\n 1) &quot;name&quot;\n 2) &quot;mymaster&quot;\n 3) &quot;ip&quot;\n 4) &quot;127.0.0.1&quot;\n 5) &quot;port&quot;\n 6) &quot;6379&quot;\n 7) &quot;runid&quot;\n 8) &quot;953ae6a589449c13ddefaee3538d356d287f509b&quot;\n 9) &quot;flags&quot;\n10) &quot;master&quot;\n11) &quot;link-pending-commands&quot;\n12) &quot;0&quot;\n13) &quot;link-refcount&quot;\n14) &quot;1&quot;\n15) &quot;last-ping-sent&quot;\n16) &quot;0&quot;\n17) &quot;last-ok-ping-reply&quot;\n18) &quot;735&quot;\n19) &quot;last-ping-reply&quot;\n20) &quot;735&quot;\n21) &quot;down-after-milliseconds&quot;\n22) &quot;5000&quot;\n23) &quot;info-refresh&quot;\n24) &quot;126&quot;\n25) &quot;role-reported&quot;\n26) &quot;master&quot;\n27) &quot;role-reported-time&quot;\n28) &quot;532439&quot;\n29) &quot;config-epoch&quot;\n30) &quot;1&quot;\n31) &quot;num-slaves&quot;\n32) &quot;1&quot;\n33) &quot;num-other-sentinels&quot;\n34) &quot;2&quot;\n35) &quot;quorum&quot;\n36) &quot;2&quot;\n37) &quot;failover-timeout&quot;\n38) &quot;60000&quot;\n39) &quot;parallel-syncs&quot;\n40) &quot;1&quot;\n</code></pre>\n<p>As you can see, it prints a number of information about the primary. There are<br>a few that are of particular interest for us:</p>\n<ol>\n<li><code>num-other-sentinels</code> is 2, so we know the Sentinel already detected two more Sentinels for this primary. If you check the logs you&#39;ll see the <code>+sentinel</code> events generated.</li>\n<li><code>flags</code> is just <code>master</code>. If the primary was down we could expect to see <code>s_down</code> or <code>o_down</code> flag as well here.</li>\n<li><code>num-slaves</code> is correctly set to 1, so Sentinel also detected that there is an attached replica to our primary.</li>\n</ol>\n<p>In order to explore more about this instance, you may want to try the following<br>two commands:</p>\n<pre><code>SENTINEL replicas mymaster\nSENTINEL sentinels mymaster\n</code></pre>\n<p>The first will provide similar information about the replicas connected to the<br>primary, and the second about the other Sentinels.</p>\n<h2>Obtaining the address of the current primary</h2>\n<p>As we already specified, Sentinel also acts as a configuration provider for<br>clients that want to connect to a set of primary and replicas. Because of<br>possible failovers or reconfigurations, clients have no idea about who is<br>the currently active primary for a given set of instances, so Sentinel exports<br>an API to ask this question:</p>\n<pre><code>127.0.0.1:5000&gt; SENTINEL get-master-addr-by-name mymaster\n1) &quot;127.0.0.1&quot;\n2) &quot;6379&quot;\n</code></pre>\n<h3>Testing the failover</h3>\n<p>At this point our toy Sentinel deployment is ready to be tested. We can<br>just kill our primary and check if the configuration changes. To do so<br>we can just do:</p>\n<pre><code>valkey-cli -p 6379 DEBUG sleep 30\n</code></pre>\n<p>This command will make our primary no longer reachable, sleeping for 30 seconds.<br>It basically simulates a primary hanging for some reason.</p>\n<p>If you check the Sentinel logs, you should be able to see a lot of action:</p>\n<ol>\n<li>Each Sentinel detects the primary is down with an <code>+sdown</code> event.</li>\n<li>This event is later escalated to <code>+odown</code>, which means that multiple Sentinels agree about the fact the primary is not reachable.</li>\n<li>Sentinels vote a Sentinel that will start the first failover attempt.</li>\n<li>The failover happens.</li>\n</ol>\n<p>If you ask again what is the current primary address for <code>mymaster</code>, eventually<br>we should get a different reply this time:</p>\n<pre><code>127.0.0.1:5000&gt; SENTINEL get-master-addr-by-name mymaster\n1) &quot;127.0.0.1&quot;\n2) &quot;6380&quot;\n</code></pre>\n<p>So far so good... At this point you may jump to create your Sentinel deployment<br>or can read more to understand all the Sentinel commands and internals.</p>\n<h2>Sentinel API</h2>\n<p>Sentinel provides an API in order to inspect its state, check the health<br>of monitored primaries and replicas, subscribe in order to receive specific<br>notifications, and change the Sentinel configuration at run time.</p>\n<p>By default Sentinel runs using TCP port 26379 (note that 6379 is the normal<br>Valkey port). Sentinels accept commands using the Valkey protocol, so you can<br>use <code>valkey-cli</code> or any other unmodified Valkey client in order to talk with<br>Sentinel.</p>\n<p>It is possible to directly query a Sentinel to check what is the state of<br>the monitored Valkey instances from its point of view, to see what other<br>Sentinels it knows, and so forth. Alternatively, using Pub/Sub, it is possible<br>to receive <em>push style</em> notifications from Sentinels, every time some event<br>happens, like a failover, or an instance entering an error condition, and<br>so forth.</p>\n<h3>Sentinel commands</h3>\n<p>The <code>SENTINEL</code> command is the main API for Sentinel. The following is the list of its subcommands (minimal version is noted for where applicable):</p>\n<ul>\n<li><strong>SENTINEL CONFIG GET <code>&lt;name&gt;</code></strong> (<code>&gt;= 6.2</code>) Get the current value of a global Sentinel configuration parameter. The specified name may be a wildcard, similar to the Valkey <code>CONFIG GET</code> command.</li>\n<li><strong>SENTINEL CONFIG SET <code>&lt;name&gt;</code> <code>&lt;value&gt;</code></strong> (<code>&gt;= 6.2</code>) Set the value of a global Sentinel configuration parameter.</li>\n<li><strong>SENTINEL CKQUORUM <code>&lt;primary name&gt;</code></strong> Check if the current Sentinel configuration is able to reach the quorum needed to failover a primary, and the majority needed to authorize the failover. This command should be used in monitoring systems to check if a Sentinel deployment is ok.</li>\n<li><strong>SENTINEL FLUSHCONFIG</strong> Force Sentinel to rewrite its configuration on disk, including the current Sentinel state. Normally Sentinel rewrites the configuration every time something changes in its state (in the context of the subset of the state which is persisted on disk across restart). However sometimes it is possible that the configuration file is lost because of operation errors, disk failures, package upgrade scripts or configuration managers. In those cases a way to force Sentinel to rewrite the configuration file is handy. This command works even if the previous configuration file is completely missing.</li>\n<li><strong>SENTINEL FAILOVER <code>&lt;primary name&gt;</code></strong> Force a failover as if the primary was not reachable, and without asking for agreement to other Sentinels (however a new version of the configuration will be published so that the other Sentinels will update their configurations).</li>\n<li><strong>SENTINEL GET-MASTER-ADDR-BY-NAME <code>&lt;primary name&gt;</code></strong> Return the ip and port number of the primary with that name. If a failover is in progress or terminated successfully for this primary it returns the address and port of the promoted replica.</li>\n<li><strong>SENTINEL INFO-CACHE</strong> Return cached <code>INFO</code> output from primaries and replicas.</li>\n<li><strong>SENTINEL IS-MASTER-DOWN-BY-ADDR <ip> <port> <current-epoch> <runid></strong> Check if the primary specified by ip:port is down from current Sentinel&#39;s point of view. This command is mostly for internal use.</li>\n<li><strong>SENTINEL MASTER <code>&lt;primary name&gt;</code></strong> Show the state and info of the specified primary.</li>\n<li><strong>SENTINEL MASTERS</strong> Show a list of monitored primaries and their state.</li>\n<li><strong>SENTINEL MONITOR</strong> Start Sentinel&#39;s monitoring. Refer to the <a href=\"#reconfiguring-sentinel-at-runtime\"><em>Reconfiguring Sentinel at Runtime</em> section</a> for more information.</li>\n<li><strong>SENTINEL MYID</strong> (<code>&gt;= 6.2</code>) Return the ID of the Sentinel instance.</li>\n<li><strong>SENTINEL PENDING-SCRIPTS</strong> This command returns information about pending scripts.</li>\n<li><strong>SENTINEL REMOVE</strong> Stop Sentinel&#39;s monitoring. Refer to the <a href=\"#reconfiguring-sentinel-at-runtime\"><em>Reconfiguring Sentinel at Runtime</em> section</a> for more information.</li>\n<li><strong>SENTINEL REPLICAS <code>&lt;primary name&gt;</code></strong> Show a list of replicas for this primary, and their state.</li>\n<li><strong>SENTINEL SENTINELS <code>&lt;primary name&gt;</code></strong> Show a list of sentinel instances for this primary, and their state.</li>\n<li><strong>SENTINEL SET</strong> Set Sentinel&#39;s monitoring configuration. Refer to the <a href=\"#reconfiguring-sentinel-at-runtime\"><em>Reconfiguring Sentinel at Runtime</em> section</a> for more information.</li>\n<li><strong>SENTINEL SIMULATE-FAILURE (crash-after-election|crash-after-promotion|help)</strong> This command simulates different Sentinel crash scenarios.</li>\n<li><strong>SENTINEL RESET <code>&lt;pattern&gt;</code></strong> This command will reset all the primaries with matching name. The pattern argument is a glob-style pattern. The reset process clears any previous state in a primary (including a failover in progress), and removes every replica and sentinel already discovered and associated with the primary.</li>\n</ul>\n<p>For connection management and administration purposes, Sentinel supports the following subset of Valkey&#39;s commands:</p>\n<ul>\n<li><strong>ACL</strong> (<code>&gt;= 6.2</code>) This command manages the Sentinel Access Control List. For more information refer to the <a href=\"acl\">ACL</a> documentation page and the <a href=\"#sentinel-access-control-list-authentication\"><em>Sentinel Access Control List authentication</em></a>.</li>\n<li><strong>AUTH</strong> Authenticate a client connection. For more information refer to the <code>AUTH</code> command and the <a href=\"#configuring-sentinel-instances-with-authentication\"><em>Configuring Sentinel instances with authentication</em> section</a>.</li>\n<li><strong>CLIENT</strong> This command manages client connections. For more information refer to its subcommands&#39; pages.</li>\n<li><strong>COMMAND</strong> (<code>&gt;= 6.2</code>) This command returns information about commands. For more information refer to the <code>COMMAND</code> command and its various subcommands.</li>\n<li><strong>HELLO</strong> (<code>&gt;= 6.0</code>) Switch the connection&#39;s protocol. For more information refer to the <code>HELLO</code> command.</li>\n<li><strong>INFO</strong> Return information and statistics about the Sentinel server. For more information see the <code>INFO</code> command.</li>\n<li><strong>PING</strong> This command simply returns PONG.</li>\n<li><strong>ROLE</strong> This command returns the string &quot;sentinel&quot; and a list of monitored primaries. For more information refer to the <code>ROLE</code> command.</li>\n<li><strong>SHUTDOWN</strong> Shut down the Sentinel instance.</li>\n</ul>\n<p>Lastly, Sentinel also supports the <code>SUBSCRIBE</code>, <code>UNSUBSCRIBE</code>, <code>PSUBSCRIBE</code> and <code>PUNSUBSCRIBE</code> commands. Refer to the <a href=\"#pubsub-messages\"><em>Pub/Sub Messages</em> section</a> for more details.</p>\n<h3>Reconfiguring Sentinel at Runtime</h3>\n<p>Sentinel provides an API in order to add, remove, or change the configuration of a given primary. Note that if you have multiple sentinels you should apply the changes to all to your instances for Valkey Sentinel to work properly. This means that changing the configuration of a single Sentinel does not automatically propagate the changes to the other Sentinels in the network.</p>\n<p>The following is a list of <code>SENTINEL</code> subcommands used in order to update the configuration of a Sentinel instance.</p>\n<ul>\n<li><strong>SENTINEL MONITOR <code>&lt;name&gt;</code> <code>&lt;ip&gt;</code> <code>&lt;port&gt;</code> <code>&lt;quorum&gt;</code></strong> This command tells the Sentinel to start monitoring a new primary with the specified name, ip, port, and quorum. It is identical to the <code>sentinel monitor</code> configuration directive in <code>sentinel.conf</code> configuration file, with the difference that you can&#39;t use a hostname in as <code>ip</code>, but you need to provide an IPv4 or IPv6 address.</li>\n<li><strong>SENTINEL REMOVE <code>&lt;name&gt;</code></strong> is used in order to remove the specified primary: the primary will no longer be monitored, and will totally be removed from the internal state of the Sentinel, so it will no longer listed by <code>SENTINEL masters</code> and so forth.</li>\n<li><strong>SENTINEL SET <code>&lt;name&gt;</code> [<code>&lt;option&gt;</code> <code>&lt;value&gt;</code> ...]</strong> The SET command is very similar to the <code>CONFIG SET</code> command of Valkey, and is used in order to change configuration parameters of a specific primary. Multiple option / value pairs can be specified (or none at all). All the configuration parameters that can be configured via <code>sentinel.conf</code> are also configurable using the SET command.</li>\n</ul>\n<p>The following is an example of <code>SENTINEL SET</code> command in order to modify the <code>down-after-milliseconds</code> configuration of a primary called <code>objects-cache</code>:</p>\n<pre><code>SENTINEL SET objects-cache-master down-after-milliseconds 1000\n</code></pre>\n<p>As already stated, <code>SENTINEL SET</code> can be used to set all the configuration parameters that are settable in the startup configuration file. Moreover it is possible to change just the primary quorum configuration without removing and re-adding the primary with <code>SENTINEL REMOVE</code> followed by <code>SENTINEL MONITOR</code>, but simply using:</p>\n<pre><code>SENTINEL SET objects-cache-master quorum 5\n</code></pre>\n<p>Note that there is no equivalent GET command since <code>SENTINEL MASTER</code> provides all the configuration parameters in a simple to parse format (as a field/value pairs array).</p>\n<p>Sentinel also allows getting and setting global configuration parameters which were only supported in the configuration file prior to that.</p>\n<ul>\n<li><strong>SENTINEL CONFIG GET <code>&lt;name&gt;</code></strong> Get the current value of a global Sentinel configuration parameter. The specified name may be a wildcard, similar to the Valkey <code>CONFIG GET</code> command.</li>\n<li><strong>SENTINEL CONFIG SET <code>&lt;name&gt;</code> <code>&lt;value&gt;</code></strong> Set the value of a global Sentinel configuration parameter.</li>\n</ul>\n<p>Global parameters that can be manipulated include:</p>\n<ul>\n<li><code>resolve-hostnames</code>, <code>announce-hostnames</code>. See <a href=\"#ip-addresses-and-dns-names\"><em>IP addresses and DNS names</em></a>.</li>\n<li><code>announce-ip</code>, <code>announce-port</code>. See <a href=\"#sentinel-docker-nat-and-possible-issues\"><em>Sentinel, Docker, NAT, and possible issues</em></a>.</li>\n<li><code>sentinel-user</code>, <code>sentinel-pass</code>. See <a href=\"#configuring-sentinel-instances-with-authentication\"><em>Configuring Sentinel instances with authentication</em></a>.</li>\n</ul>\n<h3>Adding or removing Sentinels</h3>\n<p>Adding a new Sentinel to your deployment is a simple process because of the<br>auto-discover mechanism implemented by Sentinel. All you need to do is to<br>start the new Sentinel configured to monitor the currently active primary.<br>Within 10 seconds the Sentinel will acquire the list of other Sentinels and<br>the set of replicas attached to the primary.</p>\n<p>If you need to add multiple Sentinels at once, it is suggested to add it<br>one after the other, waiting for all the other Sentinels to already know<br>about the first one before adding the next. This is useful in order to still<br>guarantee that majority can be achieved only in one side of a partition,<br>in the chance failures should happen in the process of adding new Sentinels.</p>\n<p>This can be easily achieved by adding every new Sentinel with a 30 seconds delay, and during absence of network partitions.</p>\n<p>At the end of the process it is possible to use the command<br><code>SENTINEL MASTER &lt;primary name&gt;</code> in order to check if all the Sentinels agree about<br>the total number of Sentinels monitoring the primary.</p>\n<p>Removing a Sentinel is a bit more complex: <strong>Sentinels never forget already seen<br>Sentinels</strong>, even if they are not reachable for a long time, since we don&#39;t<br>want to dynamically change the majority needed to authorize a failover and<br>the creation of a new configuration number. So in order to remove a Sentinel<br>the following steps should be performed in absence of network partitions:</p>\n<ol>\n<li>Stop the Sentinel process of the Sentinel you want to remove.</li>\n<li>Send a <code>SENTINEL RESET *</code> command to all the other Sentinel instances (instead of <code>*</code> you can use the exact primary name if you want to reset just a single primary). One after the other, waiting at least 30 seconds between instances.</li>\n<li>Check that all the Sentinels agree about the number of Sentinels currently active, by inspecting the output of <code>SENTINEL MASTER &lt;primary name&gt;</code> of every Sentinel.</li>\n</ol>\n<h3>Removing the old primary or unreachable replicas</h3>\n<p>Sentinels never forget about replicas of a given primary, even when they are<br>unreachable for a long time. This is useful, because Sentinels should be able<br>to correctly reconfigure a returning replica after a network partition or a<br>failure event.</p>\n<p>Moreover, after a failover, the failed over primary is virtually added as a<br>replica of the new primary, this way it will be reconfigured to replicate with<br>the new primary as soon as it will be available again.</p>\n<p>However sometimes you want to remove a replica (that may be the old primary)<br>forever from the list of replicas monitored by Sentinels.</p>\n<p>In order to do this, you need to send a <code>SENTINEL RESET &lt;primary name&gt;</code> command<br>to all the Sentinels: they&#39;ll refresh the list of replicas within the next<br>10 seconds, only adding the ones listed as correctly replicating from the<br>current primary <code>INFO</code> output.</p>\n<h3>Pubsub messages</h3>\n<p>A client can use a Sentinel as a Valkey-compatible Pub/Sub server<br>(but you can&#39;t use <code>PUBLISH</code>) in order to <code>SUBSCRIBE</code> or <code>PSUBSCRIBE</code> to<br>channels and get notified about specific events.</p>\n<p>The channel name is the same as the name of the event. For instance the<br>channel named <code>+sdown</code> will receive all the notifications related to instances<br>entering an <code>SDOWN</code> (SDOWN means the instance is no longer reachable from<br>the point of view of the Sentinel you are querying) condition.</p>\n<p>To get all the messages simply subscribe using <code>PSUBSCRIBE *</code>.</p>\n<p>The following is a list of channels and message formats you can receive using<br>this API. The first word is the channel / event name, the rest is the format of the data.</p>\n<p>Note: where <em>instance details</em> is specified it means that the following arguments are provided to identify the target instance:</p>\n<pre><code>&lt;instance-type&gt; &lt;name&gt; &lt;ip&gt; &lt;port&gt; @ &lt;primary-name&gt; &lt;primary-ip&gt; &lt;primary-port&gt;\n</code></pre>\n<p>The part identifying the primary (from the @ argument to the end) is optional<br>and is only specified if the instance is not a primary itself.</p>\n<ul>\n<li><strong>+reset-master</strong> <code>&lt;instance details&gt;</code> -- The primary was reset.</li>\n<li><strong>+slave</strong> <code>&lt;instance details&gt;</code> -- A new replica was detected and attached.</li>\n<li><strong>+failover-state-reconf-slaves</strong> <code>&lt;instance details&gt;</code> -- Failover state changed to <code>reconf-slaves</code> state.</li>\n<li><strong>+failover-detected</strong> <code>&lt;instance details&gt;</code> -- A failover started by another Sentinel or any other external entity was detected (An attached replica turned into a primary).</li>\n<li><strong>+slave-reconf-sent</strong> <code>&lt;instance details&gt;</code> -- The leader sentinel sent the <code>REPLICAOF</code> command to this instance in order to reconfigure it for the new replica.</li>\n<li><strong>+slave-reconf-inprog</strong> <code>&lt;instance details&gt;</code> -- The replica being reconfigured showed to be a replica of the new primary ip:port pair, but the synchronization process is not yet complete.</li>\n<li><strong>+slave-reconf-done</strong> <code>&lt;instance details&gt;</code> -- The replica is now synchronized with the new primary.</li>\n<li><strong>-dup-sentinel</strong> <code>&lt;instance details&gt;</code> -- One or more sentinels for the specified primary were removed as duplicated (this happens for instance when a Sentinel instance is restarted).</li>\n<li><strong>+sentinel</strong> <code>&lt;instance details&gt;</code> -- A new sentinel for this primary was detected and attached.</li>\n<li><strong>+sdown</strong> <code>&lt;instance details&gt;</code> -- The specified instance is now in Subjectively Down state.</li>\n<li><strong>-sdown</strong> <code>&lt;instance details&gt;</code> -- The specified instance is no longer in Subjectively Down state.</li>\n<li><strong>+odown</strong> <code>&lt;instance details&gt;</code> -- The specified instance is now in Objectively Down state.</li>\n<li><strong>-odown</strong> <code>&lt;instance details&gt;</code> -- The specified instance is no longer in Objectively Down state.</li>\n<li><strong>+new-epoch</strong> <code>&lt;instance details&gt;</code> -- The current epoch was updated.</li>\n<li><strong>+try-failover</strong> <code>&lt;instance details&gt;</code> -- New failover in progress, waiting to be elected by the majority.</li>\n<li><strong>+elected-leader</strong> <code>&lt;instance details&gt;</code> -- Won the election for the specified epoch, can do the failover.</li>\n<li><strong>+failover-state-select-slave</strong> <code>&lt;instance details&gt;</code> -- New failover state is <code>select-slave</code>: we are trying to find a suitable replica for promotion.</li>\n<li><strong>no-good-slave</strong> <code>&lt;instance details&gt;</code> -- There is no good replica to promote. Currently we&#39;ll try after some time, but probably this will change and the state machine will abort the failover at all in this case.</li>\n<li><strong>selected-slave</strong> <code>&lt;instance details&gt;</code> -- We found the specified good replica to promote.</li>\n<li><strong>failover-state-send-slaveof-noone</strong> <code>&lt;instance details&gt;</code> -- We are trying to reconfigure the promoted replica as primary, waiting for it to switch.</li>\n<li><strong>failover-end-for-timeout</strong> <code>&lt;instance details&gt;</code> -- The failover terminated for timeout, replicas will eventually be configured to replicate with the new primary anyway.</li>\n<li><strong>failover-end</strong> <code>&lt;instance details&gt;</code> -- The failover terminated with success. All the replicas appear to be reconfigured to replicate with the new primary.</li>\n<li><strong>switch-master</strong> <code>&lt;primary name&gt; &lt;oldip&gt; &lt;oldport&gt; &lt;newip&gt; &lt;newport&gt;</code> -- The primary new IP and address is the specified one after a configuration change. This is <strong>the message most external users are interested in</strong>.</li>\n<li><strong>+tilt</strong> -- Tilt mode entered.</li>\n<li><strong>-tilt</strong> -- Tilt mode exited.</li>\n</ul>\n<h3>Handling of -BUSY state</h3>\n<p>The -BUSY error is returned by a Valkey instance when a Lua script is running for<br>more time than the configured Lua script time limit. When this happens before<br>triggering a fail over Valkey Sentinel will try to send a <code>SCRIPT KILL</code><br>command, that will only succeed if the script was read-only.</p>\n<p>If the instance is still in an error condition after this try, it will<br>eventually be failed over.</p>\n<h2>Replicas priority</h2>\n<p>Valkey instances have a configuration parameter called <code>replica-priority</code>.<br>This information is exposed by Valkey replica instances in their <code>INFO</code> output,<br>and Sentinel uses it in order to pick a replica among the ones that can be<br>used in order to failover a primary:</p>\n<ol>\n<li>If the replica priority is set to 0, the replica is never promoted to primary.</li>\n<li>Replicas with a <em>lower</em> priority number are preferred by Sentinel.</li>\n</ol>\n<p>For example if there is a replica S1 in the same data center of the current<br>primary, and another replica S2 in another data center, it is possible to set<br>S1 with a priority of 10 and S2 with a priority of 100, so that if the primary<br>fails and both S1 and S2 are available, S1 will be preferred.</p>\n<p>For more information about the way replicas are selected, please check the <a href=\"#replica-selection-and-priority\"><em>Replica selection and priority</em> section</a> of this documentation.</p>\n<h3>Sentinel and Valkey authentication</h3>\n<p>When the primary is configured to require authentication from clients,<br>as a security measure, replicas need to also be aware of the credentials in<br>order to authenticate with the primary and create the primary-replica connection<br>used for the asynchronous replication protocol.</p>\n<h2>Valkey Access Control List authentication</h2>\n<p>User authentication and permission is managed with the <a href=\"acl\">Access Control List (ACL)</a>.</p>\n<p>In order for Sentinels to connect to Valkey server instances when they are<br>configured with ACL, the Sentinel configuration must include the<br>following directives:</p>\n<pre><code>sentinel auth-user &lt;primary-name&gt; &lt;username&gt;\nsentinel auth-pass &lt;primary-name&gt; &lt;password&gt;\n</code></pre>\n<p>Where <code>&lt;username&gt;</code> and <code>&lt;password&gt;</code> are the username and password for accessing the group&#39;s instances. These credentials should be provisioned on all of the group&#39;s Valkey instances with the minimal control permissions. For example:</p>\n<pre><code>127.0.0.1:6379&gt; ACL SETUSER sentinel-user ON &gt;somepassword allchannels +multi +slaveaof +ping +exec +subscribe +config|rewrite +role +publish +info +client|setname +client|kill +script|kill\n</code></pre>\n<h3>Valkey password-only authentication</h3>\n<p>Before ACL was introduced, authentication could be achieved using the following configuration directives:</p>\n<ul>\n<li><code>requirepass</code> in the primary, in order to set the authentication password, and to make sure the instance will not process requests for non authenticated clients.</li>\n<li><code>masterauth</code> in the replicas in order for the replicas to authenticate with the primary in order to correctly replicate data from it.</li>\n</ul>\n<p>When Sentinel is used, there is not a single primary, since after a failover<br>replicas may play the role of primaries, and old primaries can be reconfigured in<br>order to act as replicas, so what you want to do is to set the above directives<br>in all your instances, both primaries and replicas.</p>\n<p>This is also usually a sane setup since you don&#39;t want to protect<br>data only in the primary, having the same data accessible in the replicas.</p>\n<p>However, in the uncommon case where you need a replica that is accessible<br>without authentication, you can still do it by setting up <strong>a replica priority<br>of zero</strong>, to prevent this replica from being promoted to primary, and<br>configuring in this replica only the <code>masterauth</code> directive, without<br>using the <code>requirepass</code> directive, so that data will be readable by<br>unauthenticated clients.</p>\n<p>In order for Sentinels to connect to Valkey server instances when they are<br>configured with <code>requirepass</code>, the Sentinel configuration must include the<br><code>sentinel auth-pass</code> directive, in the format:</p>\n<pre><code>sentinel auth-pass &lt;primary-name&gt; &lt;password&gt;\n</code></pre>\n<h2>Configuring Sentinel instances with authentication</h2>\n<p>Sentinel instances themselves can be secured by requiring clients to authenticate via the <code>AUTH</code> command. Starting with Redis OSS 6.2, the <a href=\"acl\">Access Control List (ACL)</a> is available, whereas older versions support password-only authentication.</p>\n<p>Note that Sentinel&#39;s authentication configuration should be <strong>applied to each of the instances</strong> in your deployment, and <strong>all instances should use the same configuration</strong>. Furthermore, ACL and password-only authentication should not be used together.</p>\n<h3>Sentinel Access Control List authentication</h3>\n<p>The first step in securing a Sentinel instance with ACL is preventing any unauthorized access to it. To do that, you&#39;ll need to disable the default superuser (or at the very least set it up with a strong password) and create a new one and allow it access to Pub/Sub channels:</p>\n<pre><code>127.0.0.1:5000&gt; ACL SETUSER admin ON &gt;admin-password allchannels +@all\nOK\n127.0.0.1:5000&gt; ACL SETUSER default off\nOK\n</code></pre>\n<p>The default user is used by Sentinel to connect to other instances. You can provide the credentials of another superuser with the following configuration directives:</p>\n<pre><code>sentinel sentinel-user &lt;username&gt;\nsentinel sentinel-pass &lt;password&gt;\n</code></pre>\n<p>Where <code>&lt;username&gt;</code> and <code>&lt;password&gt;</code> are the Sentinel&#39;s superuser and password, respectively (e.g. <code>admin</code> and <code>admin-password</code> in the example above).</p>\n<p>Lastly, for authenticating incoming client connections, you can create a Sentinel restricted user profile such as the following:</p>\n<pre><code>127.0.0.1:5000&gt; ACL SETUSER sentinel-user ON &gt;user-password -@all +auth +client|getname +client|id +client|setname +command +hello +ping +role +sentinel|get-master-addr-by-name +sentinel|master +sentinel|myid +sentinel|replicas +sentinel|sentinels\n</code></pre>\n<p>Refer to the documentation of your Sentinel client of choice for further information.</p>\n<h3>Sentinel password-only authentication</h3>\n<p>To use Sentinel with password-only authentication, add the <code>requirepass</code> configuration directive to <strong>all</strong> your Sentinel instances as follows:</p>\n<pre><code>requirepass &quot;your_password_here&quot;\n</code></pre>\n<p>When configured this way, Sentinels will do two things:</p>\n<ol>\n<li>A password will be required from clients in order to send commands to Sentinels. This is obvious since this is how such configuration directive works in Valkey in general.</li>\n<li>Moreover the same password configured to access the local Sentinel, will be used by this Sentinel instance in order to authenticate to all the other Sentinel instances it connects to.</li>\n</ol>\n<p>This means that <strong>you will have to configure the same <code>requirepass</code> password in all the Sentinel instances</strong>. This way every Sentinel can talk with every other Sentinel without any need to configure for each Sentinel the password to access all the other Sentinels, that would be very impractical.</p>\n<p>Before using this configuration, make sure your client library can send the <code>AUTH</code> command to Sentinel instances.</p>\n<h3>Sentinel clients implementation</h3>\n<hr>\n<p>Sentinel requires explicit client support, unless the system is configured to execute a script that performs a transparent redirection of all the requests to the new primary instance (virtual IP or other similar systems). The topic of client libraries implementation is covered in the document <a href=\"sentinel-clients\">Sentinel clients guidelines</a>.</p>\n<h2>More advanced concepts</h2>\n<p>In the following sections we&#39;ll cover a few details about how Sentinel works,<br>without resorting to implementation details and algorithms that will be<br>covered in the final part of this document.</p>\n<h3>SDOWN and ODOWN failure state</h3>\n<p>Valkey Sentinel has two different concepts of <em>being down</em>, one is called<br>a <em>Subjectively Down</em> condition (SDOWN) and is a down condition that is<br>local to a given Sentinel instance. Another is called <em>Objectively Down</em><br>condition (ODOWN) and is reached when enough Sentinels (at least the<br>number configured as the <code>quorum</code> parameter of the monitored primary) have<br>an SDOWN condition, and get feedback from other Sentinels using<br>the <code>SENTINEL is-master-down-by-addr</code> command.</p>\n<p>From the point of view of a Sentinel an SDOWN condition is reached when it<br>does not receive a valid reply to PING requests for the number of seconds<br>specified in the configuration as <code>is-master-down-after-milliseconds</code><br>parameter.</p>\n<p>An acceptable reply to PING is one of the following:</p>\n<ul>\n<li>PING replied with +PONG.</li>\n<li>PING replied with -LOADING error.</li>\n<li>PING replied with -MASTERDOWN error.</li>\n</ul>\n<p>Any other reply (or no reply at all) is considered non valid.<br>However note that <strong>a logical primary that advertises itself as a replica in<br>the INFO output is considered to be down</strong>.</p>\n<p>Note that SDOWN requires that no acceptable reply is received for the whole<br>interval configured, so for instance if the interval is 30000 milliseconds<br>(30 seconds) and we receive an acceptable ping reply every 29 seconds, the<br>instance is considered to be working.</p>\n<p>SDOWN is not enough to trigger a failover: it only means a single Sentinel<br>believes a Valkey instance is not available. To trigger a failover, the<br>ODOWN state must be reached.</p>\n<p>To switch from SDOWN to ODOWN no strong consensus algorithm is used, but<br>just a form of gossip: if a given Sentinel gets reports that a primary<br>is not working from enough Sentinels <strong>in a given time range</strong>, the SDOWN is<br>promoted to ODOWN. If this acknowledge is later missing, the flag is cleared.</p>\n<p>A more strict authorization that uses an actual majority is required in<br>order to really start the failover, but no failover can be triggered without<br>reaching the ODOWN state.</p>\n<p>The ODOWN condition <strong>only applies to primaries</strong>. For other kind of instances<br>Sentinel doesn&#39;t require to act, so the ODOWN state is never reached for replicas<br>and other sentinels, but only SDOWN is.</p>\n<p>However SDOWN has also semantic implications. For example a replica in SDOWN<br>state is not selected to be promoted by a Sentinel performing a failover.</p>\n<h2>Sentinels and replicas auto discovery</h2>\n<p>Sentinels stay connected with other Sentinels in order to reciprocally<br>check the availability of each other, and to exchange messages. However you<br>don&#39;t need to configure a list of other Sentinel addresses in every Sentinel<br>instance you run, as Sentinel uses the Valkey instances Pub/Sub capabilities<br>in order to discover the other Sentinels that are monitoring the same primaries<br>and replicas.</p>\n<p>This feature is implemented by sending <em>hello messages</em> into the channel named<br><code>__sentinel__:hello</code>.</p>\n<p>Similarly you don&#39;t need to configure what is the list of the replicas attached<br>to a primary, as Sentinel will auto discover this list querying Valkey.</p>\n<ul>\n<li>Every Sentinel publishes a message to every monitored primary and replica Pub/Sub channel <code>__sentinel__:hello</code>, every two seconds, announcing its presence with ip, port, runid.</li>\n<li>Every Sentinel is subscribed to the Pub/Sub channel <code>__sentinel__:hello</code> of every primary and replica, looking for unknown sentinels. When new sentinels are detected, they are added as sentinels of this primary.</li>\n<li>Hello messages also include the full current configuration of the primary. If the receiving Sentinel has a configuration for a given primary which is older than the one received, it updates to the new configuration immediately.</li>\n<li>Before adding a new sentinel to a primary a Sentinel always checks if there is already a sentinel with the same runid or the same address (ip and port pair). In that case all the matching sentinels are removed, and the new added.</li>\n</ul>\n<h2>Sentinel reconfiguration of instances outside the failover procedure</h2>\n<p>Even when no failover is in progress, Sentinels will always try to set the<br>current configuration on monitored instances. Specifically:</p>\n<ul>\n<li>Replicas (according to the current configuration) that claim to be primaries, will be configured as replicas to replicate with the current primary.</li>\n<li>Replicas connected to a wrong primary, will be reconfigured to replicate with the right primary.</li>\n</ul>\n<p>For Sentinels to reconfigure replicas, the wrong configuration must be observed for some time, that is greater than the period used to broadcast new configurations.</p>\n<p>This prevents Sentinels with a stale configuration (for example because they just rejoined from a partition) will try to change the replicas configuration before receiving an update.</p>\n<p>Also note how the semantics of always trying to impose the current configuration makes the failover more resistant to partitions:</p>\n<ul>\n<li>Masters failed over are reconfigured as replicas when they return available.</li>\n<li>Replicas partitioned away during a partition are reconfigured once reachable.</li>\n</ul>\n<p>The important lesson to remember about this section is: <strong>Sentinel is a system where each process will always try to impose the last logical configuration to the set of monitored instances</strong>.</p>\n<h3>Replica selection and priority</h3>\n<p>When a Sentinel instance is ready to perform a failover, since the primary<br>is in <code>ODOWN</code> state and the Sentinel received the authorization to failover<br>from the majority of the Sentinel instances known, a suitable replica needs<br>to be selected.</p>\n<p>The replica selection process evaluates the following information about replicas:</p>\n<ol>\n<li>Disconnection time from the primary.</li>\n<li>Replica priority.</li>\n<li>Replication offset processed.</li>\n<li>Run ID.</li>\n</ol>\n<p>A replica that is found to be disconnected from the primary for more than ten<br>times the configured primary timeout (down-after-milliseconds option), plus<br>the time the primary is also not available from the point of view of the<br>Sentinel doing the failover, is considered to be not suitable for the failover<br>and is skipped.</p>\n<p>In more rigorous terms, a replica whose the <code>INFO</code> output suggests it has been<br>disconnected from the primary for more than:</p>\n<pre><code>(down-after-milliseconds * 10) + milliseconds_since_master_is_in_SDOWN_state\n</code></pre>\n<p>Is considered to be unreliable and is disregarded entirely.</p>\n<p>The replica selection only considers the replicas that passed the above test,<br>and sorts it based on the above criteria, in the following order.</p>\n<ol>\n<li>The replicas are sorted by <code>replica-priority</code> as configured in the <code>valkey.conf</code> file of the Valkey instance. A lower priority will be preferred.</li>\n<li>If the priority is the same, the replication offset processed by the replica is checked, and the replica that received more data from the primary is selected.</li>\n<li>If multiple replicas have the same priority and processed the same data from the primary, a further check is performed, selecting the replica with the lexicographically smaller run ID. Having a lower run ID is not a real advantage for a replica, but is useful in order to make the process of replica selection more deterministic, instead of resorting to select a random replica.</li>\n</ol>\n<p>In most cases, <code>replica-priority</code> does not need to be set explicitly so all<br>instances will use the same default value. If there is a particular fail-over<br>preference, <code>replica-priority</code> must be set on all instances, including primaries,<br>as a primary may become a replica at some future point in time - and it will then<br>need the proper <code>replica-priority</code> settings.</p>\n<p>A Valkey instance can be configured with a special <code>replica-priority</code> of zero<br>in order to be <strong>never selected</strong> by Sentinels as the new primary.<br>However a replica configured in this way will still be reconfigured by<br>Sentinels in order to replicate with the new primary after a failover, the<br>only difference is that it will never become a primary itself.</p>\n<h2>Algorithms and internals</h2>\n<p>In the following sections we will explore the details of Sentinel behavior.<br>It is not strictly needed for users to be aware of all the details, but a<br>deep understanding of Sentinel may help to deploy and operate Sentinel in<br>a more effective way.</p>\n<h3>Quorum</h3>\n<p>The previous sections showed that every primary monitored by Sentinel is associated to a configured <strong>quorum</strong>. It specifies the number of Sentinel processes<br>that need to agree about the unreachability or error condition of the primary in<br>order to trigger a failover.</p>\n<p>However, after the failover is triggered, in order for the failover to actually be performed, <strong>at least a majority of Sentinels must authorize the Sentinel to<br>failover</strong>. Sentinel never performs a failover in the partition where a<br>minority of Sentinels exist.</p>\n<p>Let&#39;s try to make things a bit more clear:</p>\n<ul>\n<li>Quorum: the number of Sentinel processes that need to detect an error condition in order for a primary to be flagged as <strong>ODOWN</strong>.</li>\n<li>The failover is triggered by the <strong>ODOWN</strong> state.</li>\n<li>Once the failover is triggered, the Sentinel trying to failover is required to ask for authorization to a majority of Sentinels (or more than the majority if the quorum is set to a number greater than the majority).</li>\n</ul>\n<p>The difference may seem subtle but is actually quite simple to understand and use.  For example if you have 5 Sentinel instances, and the quorum is set to 2, a failover will be triggered as soon as 2 Sentinels believe that the primary is not reachable, however one of the two Sentinels will be able to failover only if it gets authorization at least from 3 Sentinels.</p>\n<p>If instead the quorum is configured to 5, all the Sentinels must agree about the primary error condition, and the authorization from all Sentinels is required in order to failover.</p>\n<p>This means that the quorum can be used to tune Sentinel in two ways:</p>\n<ol>\n<li>If a quorum is set to a value smaller than the majority of Sentinels we deploy, we are basically making Sentinel more sensitive to primary failures, triggering a failover as soon as even just a minority of Sentinels is no longer able to talk with the primary.</li>\n<li>If a quorum is set to a value greater than the majority of Sentinels, we are making Sentinel able to failover only when there are a very large number (larger than majority) of well connected Sentinels which agree about the primary being down.</li>\n</ol>\n<h3>Configuration epochs</h3>\n<p>Sentinels require to get authorizations from a majority in order to start a<br>failover for a few important reasons:</p>\n<p>When a Sentinel is authorized, it gets a unique <strong>configuration epoch</strong> for the primary it is failing over. This is a number that will be used to version the new configuration after the failover is completed. Because a majority agreed that a given version was assigned to a given Sentinel, no other Sentinel will be able to use it. This means that every configuration of every failover is versioned with a unique version. We&#39;ll see why this is so important.</p>\n<p>Moreover Sentinels have a rule: if a Sentinel voted another Sentinel for the failover of a given primary, it will wait some time to try to failover the same primary again. This delay is the <code>2 * failover-timeout</code> you can configure in <code>sentinel.conf</code>. This means that Sentinels will not try to failover the same primary at the same time, the first to ask to be authorized will try, if it fails another will try after some time, and so forth.</p>\n<p>Valkey Sentinel guarantees the <em>liveness</em> property that if a majority of Sentinels are able to talk, eventually one will be authorized to failover if the primary is down.</p>\n<p>Valkey Sentinel also guarantees the <em>safety</em> property that every Sentinel will failover the same primary using a different <em>configuration epoch</em>.</p>\n<h3>Configuration propagation</h3>\n<p>Once a Sentinel is able to failover a primary successfully, it will start to broadcast the new configuration so that the other Sentinels will update their information about a given primary.</p>\n<p>For a failover to be considered successful, it requires that the Sentinel was able to send the <code>REPLICAOF NO ONE</code> command to the selected replica, and that the switch to primary was later observed in the <code>INFO</code> output of the primary.</p>\n<p>At this point, even if the reconfiguration of the replicas is in progress, the failover is considered to be successful, and all the Sentinels are required to start reporting the new configuration.</p>\n<p>The way a new configuration is propagated is the reason why we need that every<br>Sentinel failover is authorized with a different version number (configuration epoch).</p>\n<p>Every Sentinel continuously broadcast its version of the configuration of a primary using Valkey Pub/Sub messages, both in the primary and all the replicas.  At the same time all the Sentinels wait for messages to see what is the configuration<br>advertised by the other Sentinels.</p>\n<p>Configurations are broadcast in the <code>__sentinel__:hello</code> Pub/Sub channel.</p>\n<p>Because every configuration has a different version number, the greater version<br>always wins over smaller versions.</p>\n<p>So for example the configuration for the primary <code>mymaster</code> start with all the<br>Sentinels believing the primary is at 192.168.1.50:6379. This configuration<br>has version 1. After some time a Sentinel is authorized to failover with version 2. If the failover is successful, it will start to broadcast a new configuration, let&#39;s say 192.168.1.50:9000, with version 2. All the other instances will see this configuration and will update their configuration accordingly, since the new configuration has a greater version.</p>\n<p>This means that Sentinel guarantees a second liveness property: a set of<br>Sentinels that are able to communicate will all converge to the same configuration with the higher version number.</p>\n<p>Basically if the net is partitioned, every partition will converge to the higher<br>local configuration. In the special case of no partitions, there is a single<br>partition and every Sentinel will agree about the configuration.</p>\n<h3>Consistency under partitions</h3>\n<p>Valkey Sentinel configurations are eventually consistent, so every partition will<br>converge to the higher configuration available.<br>However in a real-world system using Sentinel there are three different players:</p>\n<ul>\n<li>Valkey instances.</li>\n<li>Sentinel instances.</li>\n<li>Clients.</li>\n</ul>\n<p>In order to define the behavior of the system we have to consider all three.</p>\n<p>The following is a simple network where there are 3 nodes, each running<br>a Valkey instance, and a Sentinel instance:</p>\n<pre><code>            +--------------+\n            | Sentinel 1   |----- Client A\n            | Valkey 1 (M) |\n            +--------------+\n                    |\n                    |\n+--------------+    |          +-------------+\n| Sentinel 2   |----+-- // ----| Sentinel 3  |----- Client B\n| Valkey 2 (S) |               | Valkey 3 (M)|\n+--------------+               +-------------+\n</code></pre>\n<p>In this system the original state was that Valkey 3 was the primary, while<br>Valkey 1 and 2 were replicas. A partition occurred isolating the old primary.<br>Sentinels 1 and 2 started a failover promoting Sentinel 1 as the new primary.</p>\n<p>The Sentinel properties guarantee that Sentinel 1 and 2 now have the new<br>configuration for the primary. However Sentinel 3 has still the old configuration<br>since it lives in a different partition.</p>\n<p>We know that Sentinel 3 will get its configuration updated when the network<br>partition will heal, however what happens during the partition if there<br>are clients partitioned with the old primary?</p>\n<p>Clients will be still able to write to Valkey 3, the old primary. When the<br>partition will rejoin, Valkey 3 will be turned into a replica of Valkey 1, and<br>all the data written during the partition will be lost.</p>\n<p>Depending on your configuration you may want or not that this scenario happens:</p>\n<ul>\n<li>If you are using Valkey as a cache, it could be handy that Client B is still able to write to the old primary, even if its data will be lost.</li>\n<li>If you are using Valkey as a store, this is not good and you need to configure the system in order to partially prevent this problem.</li>\n</ul>\n<p>Since Valkey is asynchronously replicated, there is no way to totally prevent data loss in this scenario, however you can bound the divergence between Valkey 3 and Valkey 1<br>using the following Valkey configuration option:</p>\n<pre><code>min-replicas-to-write 1\nmin-replicas-max-lag 10\n</code></pre>\n<p>With the above configuration (please see the self-commented <code>valkey.conf</code> example in the Valkey distribution for more information) a Valkey instance, when acting as a primary, will stop accepting writes if it can&#39;t write to at least 1 replica. Since replication is asynchronous <em>not being able to write</em> actually means that the replica is either disconnected, or is not sending us asynchronous acknowledges for more than the specified <code>max-lag</code> number of seconds.</p>\n<p>Using this configuration the Valkey 3 in the above example will become unavailable after 10 seconds. When the partition heals, the Sentinel 3 configuration will converge to<br>the new one, and Client B will be able to fetch a valid configuration and continue.</p>\n<p>In general Valkey + Sentinel as a whole are an <strong>eventually consistent system</strong> where the merge function is <strong>last failover wins</strong>, and the data from old primaries are discarded to replicate the data of the current primary, so there is always a window for losing acknowledged writes. This is due to Valkey asynchronous<br>replication and the discarding nature of the &quot;virtual&quot; merge function of the system. Note that this is not a limitation of Sentinel itself, and if you orchestrate the failover with a strongly consistent replicated state machine, the same properties will still apply. There are only two ways to avoid losing acknowledged writes:</p>\n<ol>\n<li>Use synchronous replication (and a proper consensus algorithm to run a replicated state machine).</li>\n<li>Use an eventually consistent system where different versions of the same object can be merged.</li>\n</ol>\n<p>Valkey (like it&#39;s predecessor Redis OSS) is currently not able to use any of the above systems, and using them is currently outside the development goals. However, there are proxies implementing solution &quot;2&quot; on top of Redis OSS stores such as SoundCloud <a href=\"https://github.com/soundcloud/roshi\">Roshi</a>, or Netflix <a href=\"https://github.com/Netflix/dynomite\">Dynomite</a>.</p>\n<h2>Sentinel persistent state</h2>\n<p>Sentinel state is persisted in the sentinel configuration file. For example<br>every time a new configuration is received, or created (leader Sentinels), for<br>a primary, the configuration is persisted on disk together with the configuration<br>epoch. This means that it is safe to stop and restart Sentinel processes.</p>\n<h3>TILT mode</h3>\n<p>Valkey Sentinel is heavily dependent on the computer time: for instance in<br>order to understand if an instance is available it remembers the time of the<br>latest successful reply to the PING command, and compares it with the current<br>time to understand how old it is.</p>\n<p>However if the computer time changes in an unexpected way, or if the computer<br>is very busy, or the process blocked for some reason, Sentinel may start to<br>behave in an unexpected way.</p>\n<p>The TILT mode is a special &quot;protection&quot; mode that a Sentinel can enter when<br>something odd is detected that can lower the reliability of the system.<br>The Sentinel timer interrupt is normally called 10 times per second, so we<br>expect that more or less 100 milliseconds will elapse between two calls<br>to the timer interrupt.</p>\n<p>What a Sentinel does is to register the previous time the timer interrupt<br>was called, and compare it with the current call: if the time difference<br>is negative or unexpectedly big (2 seconds or more) the TILT mode is entered<br>(or if it was already entered the exit from the TILT mode postponed).</p>\n<p>When in TILT mode the Sentinel will continue to monitor everything, but:</p>\n<ul>\n<li>It stops acting at all.</li>\n<li>It starts to reply negatively to <code>SENTINEL is-master-down-by-addr</code> requests as the ability to detect a failure is no longer trusted.</li>\n</ul>\n<p>If everything appears to be normal for 30 seconds, the TILT mode is exited.</p>\n<p>In the Sentinel TILT mode, if we send the INFO command, we could get the following response:</p>\n<pre><code>$ valkey-cli -p 26379\n127.0.0.1:26379&gt; info\n(Other information from Sentinel server skipped.)\n\n# Sentinel\nsentinel_masters:1\nsentinel_tilt:0\nsentinel_tilt_since_seconds:-1\nsentinel_running_scripts:0\nsentinel_scripts_queue_length:0\nsentinel_simulate_failure_flags:0\nmaster0:name=mymaster,status=ok,address=127.0.0.1:6379,slaves=0,sentinels=1\n</code></pre>\n<p>The field &quot;sentinel_tilt_since_seconds&quot; indicates how many seconds the Sentinel already is in the TILT mode.<br>If it is not in TILT mode, the value will be -1.</p>\n<p>Note that in some ways TILT mode could be replaced using the monotonic clock<br>API that many kernels offer. However it is not still clear if this is a good<br>solution since the current system avoids issues in case the process is just<br>suspended or not executed by the scheduler for a long time.</p>\n<p><strong>A note about the words &quot;master&quot; and &quot;slave&quot; used in this man page</strong>: If not for backward compatibility, the Valkey project no longer uses the words &quot;master&quot; and &quot;slave&quot;. Unfortunately in this command these words are part of the protocol, so we&#39;ll be able to remove such occurrences only when this API will be naturally deprecated.</p>\n"
  },
  {
    "id": "server",
    "topicName": "The Valkey server",
    "description": "Manual for valkey-server, the Valkey server program\n",
    "htmlContent": "<h2>Usage</h2>\n<p><strong><code>valkey-server</code></strong> [ <em>/path/to/valkey.conf</em> ] [ <em>OPTIONS</em> ] [<strong><code>-</code></strong>]<br><strong><code>valkey-server</code></strong> <strong><code>-v</code></strong> | <strong><code>--version</code></strong><br><strong><code>valkey-server</code></strong> <strong><code>-h</code></strong> | <strong><code>--help</code></strong><br><strong><code>valkey-server</code></strong> <strong><code>--test-memory</code></strong> <em>megabytes</em><br><strong><code>valkey-server</code></strong> <strong><code>--check-system</code></strong></p>\n<h2>Description</h2>\n<p><code>valkey-server</code> is the Valkey database program.</p>\n<p>What is Valkey? See <a href=\"introduction\">Introduction</a>.</p>\n<h2>Options</h2>\n<p>The configuration file and the configuration directives are documented in<br><a href=\"valkey.conf\">Configuration</a>. Use <code>-</code> to read configuration from stdin.</p>\n<p>Each of the configuration directives can be provided on the command line<br>with its name prefixed by two dashes. For example, <code>--port 6380</code> on the command<br>line is equivalent to <code>port 6380</code> in the config file.</p>\n<p>Additional options:</p>\n<p><strong><code>-v</code></strong>, <strong><code>--version</code></strong><br>: Output version and exit.</p>\n<p><strong><code>-h</code></strong>, <strong><code>--help</code></strong><br>: Output help and exit.</p>\n<p><strong><code>--test-memory</code></strong> <em>megabytes</em><br>: Run a memory test and exit.</p>\n<p><strong><code>--check-sytem</code></strong><br>: Output some operating system properties relevant for running Valkey and exit.</p>\n<p><strong><code>--sentinel</code></strong><br>: Start in <a href=\"sentinel\">sentinel</a> mode</p>\n<h2>Examples</h2>\n<p>Run the server with default config:</p>\n<pre><code>valkey-server\n</code></pre>\n<p>Read configuration from stdin:</p>\n<pre><code>echo &#39;maxmemory 128mb&#39; | valkey-server -\n</code></pre>\n<p>Start with a configuration file:</p>\n<pre><code>valkey-server /etc/valkey/6379.conf\n</code></pre>\n<p>Start with configuration as command line options:</p>\n<pre><code>valkey-server --port 7777\n</code></pre>\n<p>Start as a replica of another Valkey server that can accessed at 127.0.0.1:8888:</p>\n<pre><code>valkey-server --port 7777 --replicaof 127.0.0.1 8888\n</code></pre>\n<p>Start with a config file, then some additional options overriding the ones in<br>the config file, and finally some more options from stdin:</p>\n<pre><code>valkey-server /etc/myvalkey.conf --loglevel verbose -\n</code></pre>\n<p>Start with a config file and some additional options overriding the ones in<br>the config file:</p>\n<pre><code>valkey-server /etc/myvalkey.conf --loglevel verbose\n</code></pre>\n<h2>See also</h2>\n<p><a href=\"./\">Valkey documentation</a>, <a href=\"introduction\">Introduction</a>, <a href=\"valkey.conf\">Configuration</a>, <a href=\"installation\">Installation</a>, <a href=\"cli\">valkey-cli</a></p>\n"
  },
  {
    "id": "sets",
    "topicName": "Sets",
    "description": "Introduction to Sets\n",
    "htmlContent": "<p>A Set is an unordered collection of unique strings (members).<br>You can use Sets to efficiently:</p>\n<ul>\n<li>Track unique items (e.g., track all unique IP addresses accessing a given blog post).</li>\n<li>Represent relations (e.g., the set of all users with a given role).</li>\n<li>Perform common set operations such as intersection, unions, and differences.</li>\n</ul>\n<h2>Basic commands</h2>\n<ul>\n<li><code>SADD</code> adds a new member to a set.</li>\n<li><code>SREM</code> removes the specified member from the set.</li>\n<li><code>SISMEMBER</code> tests a string for set membership.</li>\n<li><code>SINTER</code> returns the set of members that two or more sets have in common (i.e., the intersection).</li>\n<li><code>SCARD</code> returns the size (a.k.a. cardinality) of a set.</li>\n</ul>\n<p>See the <a href=\"../commands/#set\">complete list of set commands</a>.</p>\n<h2>Examples</h2>\n<ul>\n<li>Store the sets of bikes racing in France and the USA. Note that<br>if you add a member that already exists, it will be ignored.</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; SADD bikes:racing:france bike:1\n(integer) 1\n127.0.0.1:6379&gt; SADD bikes:racing:france bike:1\n(integer) 0\n127.0.0.1:6379&gt; SADD bikes:racing:france bike:2 bike:3\n(integer) 2\n127.0.0.1:6379&gt; SADD bikes:racing:usa bike:1 bike:4\n(integer) 2\n</code></pre>\n<ul>\n<li>Check whether bike:1 or bike:2 are racing in the US.</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; SISMEMBER bikes:racing:usa bike:1\n(integer) 1\n127.0.0.1:6379&gt; SISMEMBER bikes:racing:usa bike:2\n(integer) 0\n</code></pre>\n<ul>\n<li>Which bikes are competing in both races?</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; SINTER bikes:racing:france bikes:racing:usa\n1) &quot;bike:1&quot;\n</code></pre>\n<ul>\n<li>How many bikes are racing in France?</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; SCARD bikes:racing:france\n(integer) 3\n</code></pre>\n<h2>Tutorial</h2>\n<p>The <code>SADD</code> command adds new elements to a set. It&#39;s also possible<br>to do a number of other operations against sets like testing if a given element<br>already exists, performing the intersection, union or difference between<br>multiple sets, and so forth.</p>\n<pre><code>127.0.0.1:6379&gt; SADD bikes:racing:france bike:1 bike:2 bike:3\n(integer) 3\n127.0.0.1:6379&gt; SMEMBERS bikes:racing:france\n1) bike:3\n2) bike:1\n3) bike:2\n</code></pre>\n<p>Here I&#39;ve added three elements to my set and told Valkey to return all the<br>elements. There is no order guarantee with a set. Valkey is free to return the<br>elements in any order at every call.</p>\n<p>Valkey has commands to test for set membership. These commands can be used on single as well as multiple items:</p>\n<pre><code>127.0.0.1:6379&gt; SISMEMBER bikes:racing:france bike:1\n(integer) 1\n127.0.0.1:6379&gt; SMISMEMBER bikes:racing:france bike:2 bike:3 bike:4\n1) (integer) 1\n2) (integer) 1\n3) (integer) 0\n</code></pre>\n<p>We can also find the difference between two sets. For instance, we may want<br>to know which bikes are racing in France but not in the USA:</p>\n<pre><code>127.0.0.1:6379&gt; SADD bikes:racing:usa bike:1 bike:4\n(integer) 2\n127.0.0.1:6379&gt; SDIFF bikes:racing:france bikes:racing:usa\n1) &quot;bike:3&quot;\n2) &quot;bike:2&quot;\n</code></pre>\n<p>There are other non trivial operations that are still easy to implement<br>using the right Valkey commands. For instance we may want a list of all the<br>bikes racing in France, the USA, and some other races. We can do this using<br>the <code>SINTER</code> command, which performs the intersection between different<br>sets. In addition to intersection you can also perform<br>unions, difference, and more. For example<br>if we add a third race we can see some of these commands in action:</p>\n<pre><code>127.0.0.1:6379&gt; SADD bikes:racing:france bike:1 bike:2 bike:3\n(integer) 3\n127.0.0.1:6379&gt; SADD bikes:racing:usa bike:1 bike:4\n(integer) 2\n127.0.0.1:6379&gt; SADD bikes:racing:italy bike:1 bike:2 bike:3 bike:4\n(integer) 4\n127.0.0.1:6379&gt; SINTER bikes:racing:france bikes:racing:usa bikes:racing:italy\n1) &quot;bike:1&quot;\n127.0.0.1:6379&gt; SUNION bikes:racing:france bikes:racing:usa bikes:racing:italy\n1) &quot;bike:2&quot;\n2) &quot;bike:1&quot;\n3) &quot;bike:4&quot;\n4) &quot;bike:3&quot;\n127.0.0.1:6379&gt; SDIFF bikes:racing:france bikes:racing:usa bikes:racing:italy\n(empty array)\n127.0.0.1:6379&gt; SDIFF bikes:racing:france bikes:racing:usa\n1) &quot;bike:3&quot;\n2) &quot;bike:2&quot;\n127.0.0.1:6379&gt; SDIFF bikes:racing:usa bikes:racing:france\n1) &quot;bike:4&quot;\n</code></pre>\n<p>You&#39;ll note that the <code>SDIFF</code> command returns an empty array when the<br>difference between all sets is empty. You&#39;ll also note that the order of sets<br>passed to <code>SDIFF</code> matters, since the difference is not commutative.</p>\n<p>When you want to remove items from a set, you can use the <code>SREM</code> command to<br>remove one or more items from a set, or you can use the <code>SPOP</code> command to<br>remove a random item from a set. You can also <em>return</em> a random item from a<br>set without removing it using the <code>SRANDMEMBER</code> command:</p>\n<pre><code>127.0.0.1:6379&gt; SADD bikes:racing:france bike:1 bike:2 bike:3 bike:4 bike:5\n(integer) 5\n127.0.0.1:6379&gt; SREM bikes:racing:france bike:1\n(integer) 1\n127.0.0.1:6379&gt; SPOP bikes:racing:france\n&quot;bike:3&quot;\n127.0.0.1:6379&gt; SMEMBERS bikes:racing:france\n1) &quot;bike:2&quot;\n2) &quot;bike:4&quot;\n3) &quot;bike:5&quot;\n127.0.0.1:6379&gt; SRANDMEMBER bikes:racing:france\n&quot;bike:2&quot;\n</code></pre>\n<h2>Limits</h2>\n<p>The max size of a Set is 2^32 - 1 (4,294,967,295) members.</p>\n<h2>Performance</h2>\n<p>Most set operations, including adding, removing, and checking whether an item is a set member, are O(1).<br>This means that they&#39;re highly efficient.<br>However, for large sets with hundreds of thousands of members or more, you should exercise caution when running the <code>SMEMBERS</code> command.<br>This command is O(n) and returns the entire set in a single response.<br>As an alternative, consider the <code>SSCAN</code>, which lets you retrieve all members of a set iteratively.</p>\n"
  },
  {
    "id": "signals",
    "topicName": "Signal handling",
    "description": "How Valkey handles common Unix signals",
    "htmlContent": "<p>This document provides information about how Valkey reacts to different POSIX signals such as <code>SIGTERM</code> and <code>SIGSEGV</code>.</p>\n<h2>SIGTERM and SIGINT</h2>\n<p>The <code>SIGTERM</code> and <code>SIGINT</code> signals tell Valkey to shut down gracefully. When the server receives this signal,<br>it does not immediately exit. Instead, it schedules<br>a shutdown similar to the one performed by the <code>SHUTDOWN</code> command. The scheduled shutdown starts as soon as possible, specifically as long as the<br>current command in execution terminates (if any), with a possible additional<br>delay of 0.1 seconds or less.</p>\n<p>If the server is blocked by a long-running Lua script,<br>kill the script with <code>SCRIPT KILL</code> if possible. The scheduled shutdown will<br>run just after the script is killed or terminates spontaneously.</p>\n<p>This shutdown process includes the following actions:</p>\n<ul>\n<li>If there are any replicas lagging behind in replication:<ul>\n<li>Pause clients attempting to write with <code>CLIENT PAUSE</code> and the <code>WRITE</code> option.</li>\n<li>Wait up to the configured <code>shutdown-timeout</code> (default 10 seconds) for replicas to catch up with the primary&#39;s replication offset.</li>\n</ul>\n</li>\n<li>If a background child is saving the RDB file or performing an AOF rewrite, the child process is killed.</li>\n<li>If the AOF is active, Valkey calls the <code>fsync</code> system call on the AOF file descriptor to flush the buffers on disk.</li>\n<li>If Valkey is configured to persist on disk using RDB files, a synchronous (blocking) save is performed. Since the save is synchronous, it doesn&#39;t use any additional memory.</li>\n<li>If the server is daemonized, the PID file is removed.</li>\n<li>If the Unix domain socket is enabled, it gets removed.</li>\n<li>The server exits with an exit code of zero.</li>\n</ul>\n<p>IF the RDB file can&#39;t be saved, the shutdown fails, and the server continues to run in order to ensure no data loss.<br>Likewise, if the user just turned on AOF, and the server triggered the first AOF rewrite in order to create the initial AOF file but this file can&#39;t be saved, the shutdown fails and the server continues to run.<br>No further attempt to shut down will be made unless a new <code>SIGTERM</code> is received or the <code>SHUTDOWN</code> command is issued.</p>\n<p>Since Redis OSS 7.0, the server waits for lagging replicas up to a configurable <code>shutdown-timeout</code>, 10 seconds by default, before shutting down.<br>This provides a best effort to minimize the risk of data loss in a situation where no save points are configured and AOF is deactivated.<br>Before version 7.0, shutting down a heavily loaded primary node in a diskless setup was more likely to result in data loss.<br>To minimize the risk of data loss in such setups, trigger a manual <code>FAILOVER</code> (or <code>CLUSTER FAILOVER</code>) to demote the primary to a replica and promote one of the replicas to a new primary before shutting down a primary node.</p>\n<h2>SIGSEGV, SIGBUS, SIGFPE and SIGILL</h2>\n<p>The following signals are handled as a Valkey crash:</p>\n<ul>\n<li>SIGSEGV</li>\n<li>SIGBUS</li>\n<li>SIGFPE</li>\n<li>SIGILL</li>\n</ul>\n<p>Once one of these signals is trapped, Valkey stops any current operation and performs the following actions:</p>\n<ul>\n<li>Adds a bug report to the log file. This includes a stack trace, dump of registers, and information about the state of clients.</li>\n<li>A fast memory test is performed as a first check of the reliability of the crashing system.</li>\n<li>If the server was daemonized, the PID file is removed.</li>\n<li>Finally the server unregisters its own signal handler for the received signal and resends the same signal to itself to make sure that the default action is performed, such as dumping the core on the file system.</li>\n</ul>\n<h2>What happens when a child process gets killed</h2>\n<p>When the child performing the Append Only File rewrite gets killed by a signal,<br>Valkey handles this as an error and discards the (probably partial or corrupted)<br>AOF file. It will attempt the rewrite again later.</p>\n<p>When the child performing an RDB save is killed, Valkey handles the<br>condition as a more severe error. While the failure of an<br>AOF file rewrite can cause AOF file enlargement, failed RDB file<br>creation reduces durability.</p>\n<p>As a result of the child producing the RDB file being killed by a signal,<br>or when the child exits with an error (non zero exit code), Valkey enters<br>a special error condition where no further write command is accepted.</p>\n<ul>\n<li>Valkey will continue to reply to read commands.</li>\n<li>Valkey will reply to all write commands with a <code>MISCONFIG</code> error.</li>\n</ul>\n<p>This error condition will persist until it becomes possible to create an RDB file successfully.</p>\n<h2>Kill the RDB file without errors</h2>\n<p>Sometimes the user may want to kill the RDB-saving child process without<br>generating an error. This can be done using the signal <code>SIGUSR1</code>. This signal is handled in a special way:<br>it kills the child process like any other signal, but the parent process will<br>not detect this as a critical error and will continue to serve write<br>requests.</p>\n"
  },
  {
    "id": "sorted-sets",
    "topicName": "Sorted Sets",
    "description": "Introduction to Sorted Sets\n",
    "htmlContent": "<p>A Sorted Set is a collection of unique strings (members) ordered by an associated score.<br>When more than one string has the same score, the strings are ordered lexicographically.<br>Some use cases for sorted sets include:</p>\n<ul>\n<li>Leaderboards. For example, you can use sorted sets to easily maintain  ordered lists of the highest scores in a massive online game.</li>\n<li>Rate limiters. In particular, you can use a sorted set to build a sliding-window rate limiter to prevent excessive API requests.</li>\n</ul>\n<p>You can think of sorted sets as a mix between a Set and<br>a Hash. Like sets, sorted sets are composed of unique, non-repeating<br>string elements, so in some sense a sorted set is a set as well.</p>\n<p>However while elements inside sets are not ordered, every element in<br>a sorted set is associated with a floating point value, called <em>the score</em><br>(this is why the type is also similar to a hash, since every element<br>is mapped to a value).</p>\n<p>Moreover, elements in a sorted set are <em>taken in order</em> (so they are not<br>ordered on request, order is a peculiarity of the data structure used to<br>represent sorted sets). They are ordered according to the following rule:</p>\n<ul>\n<li>If B and A are two elements with a different score, then A &gt; B if A.score is &gt; B.score.</li>\n<li>If B and A have exactly the same score, then A &gt; B if the A string is lexicographically greater than the B string. B and A strings can&#39;t be equal since sorted sets only have unique elements.</li>\n</ul>\n<p>Let&#39;s start with a simple example, we&#39;ll add all our racers and the score they got in the first race:</p>\n<pre><code>127.0.0.1:6379&gt; ZADD racer_scores 10 &quot;Norem&quot;\n(integer) 1\n127.0.0.1:6379&gt; ZADD racer_scores 12 &quot;Castilla&quot;\n(integer) 1\n127.0.0.1:6379&gt; ZADD racer_scores 8 &quot;Sam-Bodden&quot; 10 &quot;Royce&quot; 6 &quot;Ford&quot; 14 &quot;Prickett&quot;\n(integer) 4\n</code></pre>\n<p>As you can see <code>ZADD</code> is similar to <code>SADD</code>, but takes one additional argument<br>(placed before the element to be added) which is the score.<br><code>ZADD</code> is also variadic, so you are free to specify multiple score-value<br>pairs, even if this is not used in the example above.</p>\n<p>With sorted sets it is trivial to return a list of hackers sorted by their<br>birth year because actually <em>they are already sorted</em>.</p>\n<p>Implementation note: Sorted sets are implemented via a<br>dual-ported data structure containing both a skip list and a hash table, so<br>every time we add an element Valkey performs an O(log(N)) operation. That&#39;s<br>good, but when we ask for sorted elements Valkey does not have to do any work at<br>all, it&#39;s already sorted. Note that the <code>ZRANGE</code> order is low to high, while the <code>ZREVRANGE</code> order is high to low:</p>\n<pre><code>127.0.0.1:6379&gt; ZRANGE racer_scores 0 -1\n1) &quot;Ford&quot;\n2) &quot;Sam-Bodden&quot;\n3) &quot;Norem&quot;\n4) &quot;Royce&quot;\n5) &quot;Castilla&quot;\n6) &quot;Prickett&quot;\n127.0.0.1:6379&gt; ZREVRANGE racer_scores 0 -1\n1) &quot;Prickett&quot;\n2) &quot;Castilla&quot;\n3) &quot;Royce&quot;\n4) &quot;Norem&quot;\n5) &quot;Sam-Bodden&quot;\n6) &quot;Ford&quot;\n</code></pre>\n<p>Note: 0 and -1 means from element index 0 to the last element (-1 works<br>here just as it does in the case of the <code>LRANGE</code> command).</p>\n<p>It is possible to return scores as well, using the <code>WITHSCORES</code> argument:</p>\n<pre><code>127.0.0.1:6379&gt; ZRANGE racer_scores 0 -1 withscores\n 1) &quot;Ford&quot;\n 2) &quot;6&quot;\n 3) &quot;Sam-Bodden&quot;\n 4) &quot;8&quot;\n 5) &quot;Norem&quot;\n 6) &quot;10&quot;\n 7) &quot;Royce&quot;\n 8) &quot;10&quot;\n 9) &quot;Castilla&quot;\n10) &quot;12&quot;\n11) &quot;Prickett&quot;\n12) &quot;14&quot;\n</code></pre>\n<h3>Operating on ranges</h3>\n<p>Sorted sets are more powerful than this. They can operate on ranges.<br>Let&#39;s get all the racers with 10 or fewer points. We<br>use the <code>ZRANGEBYSCORE</code> command to do it:</p>\n<pre><code>127.0.0.1:6379&gt; ZRANGEBYSCORE racer_scores -inf 10\n1) &quot;Ford&quot;\n2) &quot;Sam-Bodden&quot;\n3) &quot;Norem&quot;\n4) &quot;Royce&quot;\n</code></pre>\n<p>We asked Valkey to return all the elements with a score between negative<br>infinity and 10 (both extremes are included).</p>\n<p>To remove an element we&#39;d simply call <code>ZREM</code> with the racer&#39;s name.<br>It&#39;s also possible to remove ranges of elements. Let&#39;s remove racer Castilla along with all<br>the racers with strictly fewer than 10 points:</p>\n<pre><code>127.0.0.1:6379&gt; ZREM racer_scores &quot;Castilla&quot;\n(integer) 1\n127.0.0.1:6379&gt; ZREMRANGEBYSCORE racer_scores -inf 9\n(integer) 2\n127.0.0.1:6379&gt; ZRANGE racer_scores 0 -1\n1) &quot;Norem&quot;\n2) &quot;Royce&quot;\n3) &quot;Prickett&quot;\n</code></pre>\n<p><code>ZREMRANGEBYSCORE</code> is perhaps not the best command name,<br>but it can be very useful, and returns the number of removed elements.</p>\n<p>Another extremely useful operation defined for sorted set elements<br>is the get-rank operation. It is possible to ask what is the<br>position of an element in the set of ordered elements.<br>The <code>ZREVRANK</code> command is also available in order to get the rank, considering<br>the elements sorted in a descending way.</p>\n<pre><code>127.0.0.1:6379&gt; ZRANK racer_scores &quot;Norem&quot;\n(integer) 0\n127.0.0.1:6379&gt; ZREVRANK racer_scores &quot;Norem&quot;\n(integer) 3\n</code></pre>\n<h3>Lexicographical scores</h3>\n<p>A family of commands allow<br>getting ranges lexicographically, assuming elements in a sorted set are all<br>inserted with the same identical score. Elements are compared with the C<br><code>memcmp</code> function, so it is guaranteed that there is no collation, and every<br>Valkey instance will reply with the same output.</p>\n<p>The main commands to operate with lexicographical ranges are <code>ZRANGEBYLEX</code>,<br><code>ZREVRANGEBYLEX</code>, <code>ZREMRANGEBYLEX</code> and <code>ZLEXCOUNT</code>.</p>\n<p>For example, let&#39;s add again our list of famous hackers, but this time<br>using a score of zero for all the elements. We&#39;ll see that because of the sorted sets ordering rules, they are already sorted lexicographically. Using <code>ZRANGEBYLEX</code> we can ask for lexicographical ranges:</p>\n<pre><code>127.0.0.1:6379&gt; ZADD racer_scores 0 &quot;Norem&quot; 0 &quot;Sam-Bodden&quot; 0 &quot;Royce&quot; 0 &quot;Castilla&quot; 0 &quot;Prickett&quot; 0 &quot;Ford&quot;\n(integer) 3\n127.0.0.1:6379&gt; ZRANGE racer_scores 0 -1\n1) &quot;Castilla&quot;\n2) &quot;Ford&quot;\n3) &quot;Norem&quot;\n4) &quot;Prickett&quot;\n5) &quot;Royce&quot;\n6) &quot;Sam-Bodden&quot;\n127.0.0.1:6379&gt; ZRANGEBYLEX racer_scores [A [L\n1) &quot;Castilla&quot;\n2) &quot;Ford&quot;\n</code></pre>\n<p>Ranges can be inclusive or exclusive (depending on the first character),<br>also string infinite and minus infinite are specified respectively with<br>the <code>+</code> and <code>-</code> strings. See the documentation for more information.</p>\n<p>This feature is important because it allows us to use sorted sets as a generic<br>index. For example, if you want to index elements by a 128-bit unsigned<br>integer argument, all you need to do is to add elements into a sorted<br>set with the same score (for example 0) but with a 16 byte prefix<br>consisting of <strong>the 128 bit number in big endian</strong>. Since numbers in big<br>endian, when ordered lexicographically (in raw bytes order) are actually<br>ordered numerically as well, you can ask for ranges in the 128 bit space,<br>and get the element&#39;s value discarding the prefix.</p>\n<h2>Updating the score: leaderboards</h2>\n<p>Just a final note about sorted sets before switching to the next topic.<br>Sorted sets&#39; scores can be updated at any time. Just calling <code>ZADD</code> against<br>an element already included in the sorted set will update its score<br>(and position) with O(log(N)) time complexity.  As such, sorted sets are suitable<br>when there are tons of updates.</p>\n<p>Because of this characteristic a common use case is leaderboards.<br>The typical application is a Facebook game where you combine the ability to<br>take users sorted by their high score, plus the get-rank operation, in order<br>to show the top-N users, and the user rank in the leader board (e.g., &quot;you are<br>the #4932 best score here&quot;).</p>\n<h2>Examples</h2>\n<ul>\n<li>There are two ways we can use a sorted set to represent a leaderboard. If we know a racer&#39;s new score, we can update it directly via the <code>ZADD</code> command. However, if we want to add points to an existing score, we can use the <code>ZINCRBY</code> command.</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; ZADD racer_scores 100 &quot;Wood&quot;\n(integer) 1\n127.0.0.1:6379&gt; ZADD racer_scores 100 &quot;Henshaw&quot;\n(integer) 1\n127.0.0.1:6379&gt; ZADD racer_scores 150 &quot;Henshaw&quot;\n(integer) 0\n127.0.0.1:6379&gt; ZINCRBY racer_scores 50 &quot;Wood&quot;\n&quot;150&quot;\n127.0.0.1:6379&gt; ZINCRBY racer_scores 50 &quot;Henshaw&quot;\n&quot;200&quot;\n</code></pre>\n<p>You&#39;ll see that <code>ZADD</code> returns 0 when the member already exists (the score is updated), while <code>ZINCRBY</code> returns the new score. The score for racer Henshaw went from 100, was changed to 150 with no regard for what score was there before, and then was incremented by 50 to 200.</p>\n<h2>Basic commands</h2>\n<ul>\n<li><code>ZADD</code> adds a new member and associated score to a sorted set. If the member already exists, the score is updated.</li>\n<li><code>ZRANGE</code> returns members of a sorted set, sorted within a given range.</li>\n<li><code>ZRANK</code> returns the rank of the provided member, assuming the sorted is in ascending order.</li>\n<li><code>ZREVRANK</code> returns the rank of the provided member, assuming the sorted set is in descending order.</li>\n</ul>\n<p>See the <a href=\"../commands/#sorted-set\">complete list of sorted set commands</a>.</p>\n<h2>Performance</h2>\n<p>Most sorted set operations are O(log(n)), where <em>n</em> is the number of members.</p>\n<p>Exercise some caution when running the <code>ZRANGE</code> command with large returns values (e.g., in the tens of thousands or more).<br>This command&#39;s time complexity is O(log(n) + m), where <em>m</em> is the number of results returned. </p>\n"
  },
  {
    "id": "streams-intro",
    "topicName": "Streams",
    "description": "Introduction to Streams\n",
    "htmlContent": "<p>A Stream is a data structure that acts like an append-only log but also implements several operations to overcome some of the limits of a typical append-only log. These include random access in O(1) time and complex consumption strategies, such as consumer groups.<br>You can use streams to record and simultaneously syndicate events in real time.<br>Examples of Stream use cases include:</p>\n<ul>\n<li>Event sourcing (e.g., tracking user actions, clicks, etc.)</li>\n<li>Sensor monitoring (e.g., readings from devices in the field) </li>\n<li>Notifications (e.g., storing a record of each user&#39;s notifications in a separate stream)</li>\n</ul>\n<p>Valkey generates a unique ID for each stream entry.<br>You can use these IDs to retrieve their associated entries later or to read and process all subsequent entries in the stream. Note that because these IDs are related to time, the ones shown here may vary and will be different from the IDs you see in your own Valkey instance.</p>\n<p>Streams support several trimming strategies (to prevent streams from growing unbounded) and more than one consumption strategy (see <code>XREAD</code>, <code>XREADGROUP</code>, and <code>XRANGE</code>).</p>\n<h2>Basic commands</h2>\n<ul>\n<li><code>XADD</code> adds a new entry to a stream.</li>\n<li><code>XREAD</code> reads one or more entries, starting at a given position and moving forward in time.</li>\n<li><code>XRANGE</code> returns a range of entries between two supplied entry IDs.</li>\n<li><code>XLEN</code> returns the length of a stream.</li>\n</ul>\n<p>See the <a href=\"../commands/#stream\">complete list of stream commands</a>.</p>\n<h2>Examples</h2>\n<ul>\n<li>When our racers pass a checkpoint, we add a stream entry for each racer that includes the racer&#39;s name, speed, position, and location ID:</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; XADD race:france * rider Castilla speed 30.2 position 1 location_id 1\n&quot;1692632086370-0&quot;\n127.0.0.1:6379&gt; XADD race:france * rider Norem speed 28.8 position 3 location_id 1\n&quot;1692632094485-0&quot;\n127.0.0.1:6379&gt; XADD race:france * rider Prickett speed 29.7 position 2 location_id 1\n&quot;1692632102976-0&quot;\n</code></pre>\n<ul>\n<li>Read two stream entries starting at ID <code>1692632086370-0</code>:</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; XRANGE race:france 1692632086370-0 + COUNT 2\n1) 1) &quot;1692632086370-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Castilla&quot;\n      3) &quot;speed&quot;\n      4) &quot;30.2&quot;\n      5) &quot;position&quot;\n      6) &quot;1&quot;\n      7) &quot;location_id&quot;\n      8) &quot;1&quot;\n2) 1) &quot;1692632094485-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Norem&quot;\n      3) &quot;speed&quot;\n      4) &quot;28.8&quot;\n      5) &quot;position&quot;\n      6) &quot;3&quot;\n      7) &quot;location_id&quot;\n      8) &quot;1&quot;\n</code></pre>\n<ul>\n<li>Read up to 100 new stream entries, starting at the end of the stream, and block for up to 300 ms if no entries are being written:</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; XREAD COUNT 100 BLOCK 300 STREAMS race:france $\n(nil)\n</code></pre>\n<h2>Performance</h2>\n<p>Adding an entry to a stream is O(1).<br>Accessing any single entry is O(n), where <em>n</em> is the length of the ID.<br>Since stream IDs are typically short and of a fixed length, this effectively reduces to a constant time lookup.<br>For details on why, note that streams are implemented as <a href=\"https://en.wikipedia.org/wiki/Radix_tree\">radix trees</a>.</p>\n<p>Simply put, Streams provide highly efficient inserts and reads.<br>See each command&#39;s time complexity for the details.</p>\n<h2>Streams basics</h2>\n<p>Streams are an append-only data structure. The fundamental write command, called <code>XADD</code>, appends a new entry to the specified stream.</p>\n<p>Each stream entry consists of one or more field-value pairs, somewhat like a dictionary or a Hash:</p>\n<pre><code>127.0.0.1:6379&gt; XADD race:france * rider Castilla speed 29.9 position 1 location_id 2\n&quot;1692632147973-0&quot;\n</code></pre>\n<p>The above call to the <code>XADD</code> command adds an entry <code>rider: Castilla, speed: 29.9, position: 1, location_id: 2</code> to the stream at key <code>race:france</code>, using an auto-generated entry ID, which is the one returned by the command, specifically <code>1692632147973-0</code>. It gets as its first argument the key name <code>race:france</code>, the second argument is the entry ID that identifies every entry inside a stream. However, in this case, we passed <code>*</code> because we want the server to generate a new ID for us. Every new ID will be monotonically increasing, so in more simple terms, every new entry added will have a higher ID compared to all the past entries. Auto-generation of IDs by the server is almost always what you want, and the reasons for specifying an ID explicitly are very rare. We&#39;ll talk more about this later. The fact that each Stream entry has an ID is another similarity with log files, where line numbers, or the byte offset inside the file, can be used in order to identify a given entry. Returning back at our <code>XADD</code> example, after the key name and ID, the next arguments are the field-value pairs composing our stream entry.</p>\n<p>It is possible to get the number of items inside a Stream just using the <code>XLEN</code> command:</p>\n<pre><code>127.0.0.1:6379&gt; XLEN race:france\n(integer) 4\n</code></pre>\n<h3>Entry IDs</h3>\n<p>The entry ID returned by the <code>XADD</code> command, and identifying univocally each entry inside a given stream, is composed of two parts:</p>\n<pre><code>&lt;millisecondsTime&gt;-&lt;sequenceNumber&gt;\n</code></pre>\n<p>The milliseconds time part is actually the local time in the local Valkey node generating the stream ID, however if the current milliseconds time happens to be smaller than the previous entry time, then the previous entry time is used instead, so if a clock jumps backward the monotonically incrementing ID property still holds. The sequence number is used for entries created in the same millisecond. Since the sequence number is 64 bit wide, in practical terms there is no limit to the number of entries that can be generated within the same millisecond.</p>\n<p>The format of such IDs may look strange at first, and the gentle reader may wonder why the time is part of the ID. The reason is that Streams support range queries by ID. Because the ID is related to the time the entry is generated, this gives the ability to query for time ranges basically for free. We will see this soon while covering the <code>XRANGE</code> command.</p>\n<p>If for some reason the user needs incremental IDs that are not related to time but are actually associated to another external system ID, as previously mentioned, the <code>XADD</code> command can take an explicit ID instead of the <code>*</code> wildcard ID that triggers auto-generation, like in the following examples:</p>\n<pre><code>127.0.0.1:6379&gt; XADD race:usa 0-1 racer Castilla\n0-1\n127.0.0.1:6379&gt; XADD race:usa 0-2 racer Norem\n0-2\n</code></pre>\n<p>Note that in this case, the minimum ID is 0-1 and that the command will not accept an ID equal or smaller than a previous one:</p>\n<pre><code>127.0.0.1:6379&gt; XADD race:usa 0-1 racer Prickett\n(error) ERR The ID specified in XADD is equal or smaller than the target stream top item\n</code></pre>\n<p>If you&#39;re running Redis OSS 7 or later, you can also provide an explicit ID consisting of the milliseconds part only. In this case, the sequence portion of the ID will be automatically generated. To do this, use the syntax below:</p>\n<pre><code>127.0.0.1:6379&gt; XADD race:usa 0-* racer Prickett\n0-3\n</code></pre>\n<h2>Getting data from Streams</h2>\n<p>Now we are finally able to append entries in our stream via <code>XADD</code>. However, while appending data to a stream is quite obvious, the way streams can be queried in order to extract data is not so obvious. If we continue with the analogy of the log file, one obvious way is to mimic what we normally do with the Unix command <code>tail -f</code>, that is, we may start to listen in order to get the new messages that are appended to the stream. Note that unlike the blocking list operations of Valkey, where a given element will reach a single client which is blocking in a <em>pop style</em> operation like <code>BLPOP</code>, with streams we want multiple consumers to see the new messages appended to the stream (the same way many <code>tail -f</code> processes can see what is added to a log). Using the traditional terminology we want the streams to be able to <em>fan out</em> messages to multiple clients.</p>\n<p>However, this is just one potential access mode. We could also see a stream in quite a different way: not as a messaging system, but as a <em>time series store</em>. In this case, maybe it&#39;s also useful to get the new messages appended, but another natural query mode is to get messages by ranges of time, or alternatively to iterate the messages using a cursor to incrementally check all the history. This is definitely another useful access mode.</p>\n<p>Finally, if we see a stream from the point of view of consumers, we may want to access the stream in yet another way, that is, as a stream of messages that can be partitioned to multiple consumers that are processing such messages, so that groups of consumers can only see a subset of the messages arriving in a single stream. In this way, it is possible to scale the message processing across different consumers, without single consumers having to process all the messages: each consumer will just get different messages to process. This is basically what Kafka (TM) does with consumer groups. Reading messages via consumer groups is yet another interesting mode of reading from a Stream.</p>\n<p>Streams support all three of the query modes described above via different commands. The next sections will show them all, starting from the simplest and most direct to use: range queries.</p>\n<h3>Querying by range: XRANGE and XREVRANGE</h3>\n<p>To query the stream by range we are only required to specify two IDs, <em>start</em> and <em>end</em>. The range returned will include the elements having start or end as ID, so the range is inclusive. The two special IDs <code>-</code> and <code>+</code> respectively mean the smallest and the greatest ID possible.</p>\n<pre><code>127.0.0.1:6379&gt; XRANGE race:france - +\n1) 1) &quot;1692632086370-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Castilla&quot;\n      3) &quot;speed&quot;\n      4) &quot;30.2&quot;\n      5) &quot;position&quot;\n      6) &quot;1&quot;\n      7) &quot;location_id&quot;\n      8) &quot;1&quot;\n2) 1) &quot;1692632094485-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Norem&quot;\n      3) &quot;speed&quot;\n      4) &quot;28.8&quot;\n      5) &quot;position&quot;\n      6) &quot;3&quot;\n      7) &quot;location_id&quot;\n      8) &quot;1&quot;\n3) 1) &quot;1692632102976-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Prickett&quot;\n      3) &quot;speed&quot;\n      4) &quot;29.7&quot;\n      5) &quot;position&quot;\n      6) &quot;2&quot;\n      7) &quot;location_id&quot;\n      8) &quot;1&quot;\n4) 1) &quot;1692632147973-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Castilla&quot;\n      3) &quot;speed&quot;\n      4) &quot;29.9&quot;\n      5) &quot;position&quot;\n      6) &quot;1&quot;\n      7) &quot;location_id&quot;\n      8) &quot;2&quot;\n</code></pre>\n<p>Each entry returned is an array of two items: the ID and the list of field-value pairs. We already said that the entry IDs have a relation with the time, because the part at the left of the <code>-</code> character is the Unix time in milliseconds of the local node that created the stream entry, at the moment the entry was created (however note that streams are replicated with fully specified <code>XADD</code> commands, so the replicas will have identical IDs to the primary). This means that I could query a range of time using <code>XRANGE</code>. In order to do so, however, I may want to omit the sequence part of the ID: if omitted, in the start of the range it will be assumed to be 0, while in the end part it will be assumed to be the maximum sequence number available. This way, querying using just two milliseconds Unix times, we get all the entries that were generated in that range of time, in an inclusive way. For instance, if I want to query a two milliseconds period I could use:</p>\n<pre><code>127.0.0.1:6379&gt; XRANGE race:france 1692632086369 1692632086371\n1) 1) &quot;1692632086370-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Castilla&quot;\n      3) &quot;speed&quot;\n      4) &quot;30.2&quot;\n      5) &quot;position&quot;\n      6) &quot;1&quot;\n      7) &quot;location_id&quot;\n      8) &quot;1&quot;\n</code></pre>\n<p>I have only a single entry in this range. However in real data sets, I could query for ranges of hours, or there could be many items in just two milliseconds, and the result returned could be huge. For this reason, <code>XRANGE</code> supports an optional <strong>COUNT</strong> option at the end. By specifying a count, I can just get the first <em>N</em> items. If I want more, I can get the last ID returned, increment the sequence part by one, and query again. Let&#39;s see this in the following example. Let&#39;s assume that the stream <code>race:france</code> was populated with 4 items. To start my iteration, getting 2 items per command, I start with the full range, but with a count of 2.</p>\n<pre><code>127.0.0.1:6379&gt; XRANGE race:france - + COUNT 2\n1) 1) &quot;1692632086370-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Castilla&quot;\n      3) &quot;speed&quot;\n      4) &quot;30.2&quot;\n      5) &quot;position&quot;\n      6) &quot;1&quot;\n      7) &quot;location_id&quot;\n      8) &quot;1&quot;\n2) 1) &quot;1692632094485-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Norem&quot;\n      3) &quot;speed&quot;\n      4) &quot;28.8&quot;\n      5) &quot;position&quot;\n      6) &quot;3&quot;\n      7) &quot;location_id&quot;\n      8) &quot;1&quot;\n</code></pre>\n<p>To continue the iteration with the next two items, I have to pick the last ID returned, that is <code>1692632094485-0</code>, and add the prefix <code>(</code> to it. The resulting exclusive range interval, that is <code>(1692632094485-0</code> in this case, can now be used as the new <em>start</em> argument for the next <code>XRANGE</code> call:</p>\n<pre><code>127.0.0.1:6379&gt; XRANGE race:france (1692632094485-0 + COUNT 2\n1) 1) &quot;1692632102976-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Prickett&quot;\n      3) &quot;speed&quot;\n      4) &quot;29.7&quot;\n      5) &quot;position&quot;\n      6) &quot;2&quot;\n      7) &quot;location_id&quot;\n      8) &quot;1&quot;\n2) 1) &quot;1692632147973-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Castilla&quot;\n      3) &quot;speed&quot;\n      4) &quot;29.9&quot;\n      5) &quot;position&quot;\n      6) &quot;1&quot;\n      7) &quot;location_id&quot;\n      8) &quot;2&quot;\n</code></pre>\n<p>Now that we&#39;ve retrieved 4 items out of a stream that only had 4 entries in it, if we try to retrieve more items, we&#39;ll get an empty array:</p>\n<pre><code>127.0.0.1:6379&gt; XRANGE race:france (1692632147973-0 + COUNT 2\n(empty array)\n</code></pre>\n<p>Since <code>XRANGE</code> complexity is <em>O(log(N))</em> to seek, and then <em>O(M)</em> to return M elements, with a small count the command has a logarithmic time complexity, which means that each step of the iteration is fast. So <code>XRANGE</code> is also the de facto <em>streams iterator</em> and does not require an <strong>XSCAN</strong> command.</p>\n<p>The command <code>XREVRANGE</code> is the equivalent of <code>XRANGE</code> but returning the elements in inverted order, so a practical use for <code>XREVRANGE</code> is to check what is the last item in a Stream:</p>\n<pre><code>127.0.0.1:6379&gt; XREVRANGE race:france + - COUNT 1\n1) 1) &quot;1692632147973-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Castilla&quot;\n      3) &quot;speed&quot;\n      4) &quot;29.9&quot;\n      5) &quot;position&quot;\n      6) &quot;1&quot;\n      7) &quot;location_id&quot;\n      8) &quot;2&quot;\n</code></pre>\n<p>Note that the <code>XREVRANGE</code> command takes the <em>start</em> and <em>stop</em> arguments in reverse order.</p>\n<h2>Listening for new items with XREAD</h2>\n<p>When we do not want to access items by a range in a stream, usually what we want instead is to <em>subscribe</em> to new items arriving to the stream. This concept may appear related to Valkey Pub/Sub, where you subscribe to a channel, or to Valkey blocking lists, where you wait for a key to get new elements to fetch, but there are fundamental differences in the way you consume a stream:</p>\n<ol>\n<li>A stream can have multiple clients (consumers) waiting for data. Every new item, by default, will be delivered to <em>every consumer</em> that is waiting for data in a given stream. This behavior is different than blocking lists, where each consumer will get a different element. However, the ability to <em>fan out</em> to multiple consumers is similar to Pub/Sub.</li>\n<li>While in Pub/Sub messages are <em>fire and forget</em> and are never stored anyway, and while when using blocking lists, when a message is received by the client it is <em>popped</em> (effectively removed) from the list, streams work in a fundamentally different way. All the messages are appended in the stream indefinitely (unless the user explicitly asks to delete entries): different consumers will know what is a new message from its point of view by remembering the ID of the last message received.</li>\n<li>Streams Consumer Groups provide a level of control that Pub/Sub or blocking lists cannot achieve, with different groups for the same stream, explicit acknowledgment of processed items, ability to inspect the pending items, claiming of unprocessed messages, and coherent history visibility for each single client, that is only able to see its private past history of messages.</li>\n</ol>\n<p>The command that provides the ability to listen for new messages arriving into a stream is called <code>XREAD</code>. It&#39;s a bit more complex than <code>XRANGE</code>, so we&#39;ll start showing simple forms, and later the whole command layout will be provided.</p>\n<pre><code>127.0.0.1:6379&gt; XREAD COUNT 2 STREAMS race:france 0\n1) 1) &quot;race:france&quot;\n   2) 1) 1) &quot;1692632086370-0&quot;\n         2) 1) &quot;rider&quot;\n            2) &quot;Castilla&quot;\n            3) &quot;speed&quot;\n            4) &quot;30.2&quot;\n            5) &quot;position&quot;\n            6) &quot;1&quot;\n            7) &quot;location_id&quot;\n            8) &quot;1&quot;\n      2) 1) &quot;1692632094485-0&quot;\n         2) 1) &quot;rider&quot;\n            2) &quot;Norem&quot;\n            3) &quot;speed&quot;\n            4) &quot;28.8&quot;\n            5) &quot;position&quot;\n            6) &quot;3&quot;\n            7) &quot;location_id&quot;\n            8) &quot;1&quot;\n</code></pre>\n<p>The above is the non-blocking form of <code>XREAD</code>. Note that the <strong>COUNT</strong> option is not mandatory, in fact the only mandatory option of the command is the <strong>STREAMS</strong> option, that specifies a list of keys together with the corresponding maximum ID already seen for each stream by the calling consumer, so that the command will provide the client only with messages with an ID greater than the one we specified.</p>\n<p>In the above command we wrote <code>STREAMS race:france 0</code> so we want all the messages in the Stream <code>race:france</code> having an ID greater than <code>0-0</code>. As you can see in the example above, the command returns the key name, because actually it is possible to call this command with more than one key to read from different streams at the same time. I could write, for instance: <code>STREAMS race:france race:italy 0 0</code>. Note how after the <strong>STREAMS</strong> option we need to provide the key names, and later the IDs. For this reason, the <strong>STREAMS</strong> option must always be the last option.<br>Any other options must come before the <strong>STREAMS</strong> option.</p>\n<p>Apart from the fact that <code>XREAD</code> can access multiple streams at once, and that we are able to specify the last ID we own to just get newer messages, in this simple form the command is not doing something so different compared to <code>XRANGE</code>. However, the interesting part is that we can turn <code>XREAD</code> into a <em>blocking command</em> easily, by specifying the <strong>BLOCK</strong> argument:</p>\n<pre><code>&gt; XREAD BLOCK 0 STREAMS race:france $\n</code></pre>\n<p>Note that in the example above, other than removing <strong>COUNT</strong>, I specified the new <strong>BLOCK</strong> option with a timeout of 0 milliseconds (that means to never timeout). Moreover, instead of passing a normal ID for the stream <code>race:france</code> I passed the special ID <code>$</code>. This special ID means that <code>XREAD</code> should use as last ID the maximum ID already stored in the stream <code>race:france</code>, so that we will receive only <em>new</em> messages, starting from the time we started listening. This is similar to the <code>tail -f</code> Unix command in some way.</p>\n<p>Note that when the <strong>BLOCK</strong> option is used, we do not have to use the special ID <code>$</code>. We can use any valid ID. If the command is able to serve our request immediately without blocking, it will do so, otherwise it will block. Normally if we want to consume the stream starting from new entries, we start with the ID <code>$</code>, and after that we continue using the ID of the last message received to make the next call, and so forth.</p>\n<p>The blocking form of <code>XREAD</code> is also able to listen to multiple Streams, just by specifying multiple key names. If the request can be served synchronously because there is at least one stream with elements greater than the corresponding ID we specified, it returns with the results. Otherwise, the command will block and will return the items of the first stream which gets new data (according to the specified ID).</p>\n<p>Similarly to blocking list operations, blocking stream reads are <em>fair</em> from the point of view of clients waiting for data, since the semantics is FIFO style. The first client that blocked for a given stream will be the first to be unblocked when new items are available.</p>\n<p><code>XREAD</code> has no other options than <strong>COUNT</strong> and <strong>BLOCK</strong>, so it&#39;s a pretty basic command with a specific purpose to attach consumers to one or multiple streams. More powerful features to consume streams are available using the consumer groups API, however reading via consumer groups is implemented by a different command called <code>XREADGROUP</code>, covered in the next section of this guide.</p>\n<h2>Consumer groups</h2>\n<p>When the task at hand is to consume the same stream from different clients, then <code>XREAD</code> already offers a way to <em>fan-out</em> to N clients, potentially also using replicas in order to provide more read scalability. However in certain problems what we want to do is not to provide the same stream of messages to many clients, but to provide a <em>different subset</em> of messages from the same stream to many clients. An obvious case where this is useful is that of messages which are slow to process: the ability to have N different workers that will receive different parts of the stream allows us to scale message processing, by routing different messages to different workers that are ready to do more work.</p>\n<p>In practical terms, if we imagine having three consumers C1, C2, C3, and a stream that contains the messages 1, 2, 3, 4, 5, 6, 7 then what we want is to serve the messages according to the following diagram:</p>\n<pre><code>1 -&gt; C1\n2 -&gt; C2\n3 -&gt; C3\n4 -&gt; C1\n5 -&gt; C2\n6 -&gt; C3\n7 -&gt; C1\n</code></pre>\n<p>In order to achieve this, Valkey uses a concept called <em>consumer groups</em>. It is very important to understand that Valkey consumer groups have nothing to do, from an implementation standpoint, with Kafka (TM) consumer groups. Yet they are similar in functionality, so I decided to keep Kafka&#39;s (TM) terminology, as it originally popularized this idea.</p>\n<p>A consumer group is like a <em>pseudo consumer</em> that gets data from a stream, and actually serves multiple consumers, providing certain guarantees:</p>\n<ol>\n<li>Each message is served to a different consumer so that it is not possible that the same message will be delivered to multiple consumers.</li>\n<li>Consumers are identified, within a consumer group, by a name, which is a case-sensitive string that the clients implementing consumers must choose. This means that even after a disconnect, the stream consumer group retains all the state, since the client will claim again to be the same consumer. However, this also means that it is up to the client to provide a unique identifier.</li>\n<li>Each consumer group has the concept of the <em>first ID never consumed</em> so that, when a consumer asks for new messages, it can provide just messages that were not previously delivered.</li>\n<li>Consuming a message, however, requires an explicit acknowledgment using a specific command. Valkey interprets the acknowledgment as: this message was correctly processed so it can be evicted from the consumer group.</li>\n<li>A consumer group tracks all the messages that are currently pending, that is, messages that were delivered to some consumer of the consumer group, but are yet to be acknowledged as processed. Thanks to this feature, when accessing the message history of a stream, each consumer <em>will only see messages that were delivered to it</em>.</li>\n</ol>\n<p>In a way, a consumer group can be imagined as some <em>amount of state</em> about a stream:</p>\n<pre><code>+----------------------------------------+\n| consumer_group_name: mygroup           |\n| consumer_group_stream: somekey         |\n| last_delivered_id: 1292309234234-92    |\n|                                        |\n| consumers:                             |\n|    &quot;consumer-1&quot; with pending messages  |\n|       1292309234234-4                  |\n|       1292309234232-8                  |\n|    &quot;consumer-42&quot; with pending messages |\n|       ... (and so forth)               |\n+----------------------------------------+\n</code></pre>\n<p>If you see this from this point of view, it is very simple to understand what a consumer group can do, how it is able to just provide consumers with their history of pending messages, and how consumers asking for new messages will just be served with message IDs greater than <code>last_delivered_id</code>. At the same time, if you look at the consumer group as an auxiliary data structure for Streams, it is obvious that a single stream can have multiple consumer groups, that have a different set of consumers. Actually, it is even possible for the same stream to have clients reading without consumer groups via <code>XREAD</code>, and clients reading via <code>XREADGROUP</code> in different consumer groups.</p>\n<p>Now it&#39;s time to zoom in to see the fundamental consumer group commands. They are the following:</p>\n<ul>\n<li><code>XGROUP</code> is used in order to create, destroy and manage consumer groups.</li>\n<li><code>XREADGROUP</code> is used to read from a stream via a consumer group.</li>\n<li><code>XACK</code> is the command that allows a consumer to mark a pending message as correctly processed.</li>\n</ul>\n<h2>Creating a consumer group</h2>\n<p>Assuming I have a key <code>race:france</code> of type stream already existing, in order to create a consumer group I just need to do the following:</p>\n<pre><code>127.0.0.1:6379&gt; XGROUP CREATE race:france france_riders $\nOK\n</code></pre>\n<p>As you can see in the command above when creating the consumer group we have to specify an ID, which in the example is just <code>$</code>. This is needed because the consumer group, among the other states, must have an idea about what message to serve next at the first consumer connecting, that is, what was the <em>last message ID</em> when the group was just created. If we provide <code>$</code> as we did, then only new messages arriving in the stream from now on will be provided to the consumers in the group. If we specify <code>0</code> instead the consumer group will consume <em>all</em> the messages in the stream history to start with. Of course, you can specify any other valid ID. What you know is that the consumer group will start delivering messages that are greater than the ID you specify. Because <code>$</code> means the current greatest ID in the stream, specifying <code>$</code> will have the effect of consuming only new messages.</p>\n<p><code>XGROUP CREATE</code> also supports creating the stream automatically, if it doesn&#39;t exist, using the optional <code>MKSTREAM</code> subcommand as the last argument:</p>\n<pre><code>127.0.0.1:6379&gt; XGROUP CREATE race:italy italy_riders $ MKSTREAM\nOK\n</code></pre>\n<p>Now that the consumer group is created we can immediately try to read messages via the consumer group using the <code>XREADGROUP</code> command. We&#39;ll read from consumers, that we will call Alice and Bob, to see how the system will return different messages to Alice or Bob.</p>\n<p><code>XREADGROUP</code> is very similar to <code>XREAD</code> and provides the same <strong>BLOCK</strong> option, otherwise it is a synchronous command. However there is a <em>mandatory</em> option that must be always specified, which is <strong>GROUP</strong> and has two arguments: the name of the consumer group, and the name of the consumer that is attempting to read. The option <strong>COUNT</strong> is also supported and is identical to the one in <code>XREAD</code>.</p>\n<p>We&#39;ll add riders to the race:italy stream and try reading something using the consumer group:<br>Note: <em>here rider is the field name, and the name is the associated value. Remember that stream items are small dictionaries.</em></p>\n<pre><code>127.0.0.1:6379&gt; XADD race:italy * rider Castilla\n&quot;1692632639151-0&quot;\n127.0.0.1:6379&gt; XADD race:italy * rider Royce\n&quot;1692632647899-0&quot;\n127.0.0.1:6379&gt; XADD race:italy * rider Sam-Bodden\n&quot;1692632662819-0&quot;\n127.0.0.1:6379&gt; XADD race:italy * rider Prickett\n&quot;1692632670501-0&quot;\n127.0.0.1:6379&gt; XADD race:italy * rider Norem\n&quot;1692632678249-0&quot;\n127.0.0.1:6379&gt; XREADGROUP GROUP italy_riders Alice COUNT 1 STREAMS race:italy &gt;\n1) 1) &quot;race:italy&quot;\n   2) 1) 1) &quot;1692632639151-0&quot;\n         2) 1) &quot;rider&quot;\n            2) &quot;Castilla&quot;\n</code></pre>\n<p><code>XREADGROUP</code> replies are just like <code>XREAD</code> replies. Note however the <code>GROUP &lt;group-name&gt; &lt;consumer-name&gt;</code> provided above. It states that I want to read from the stream using the consumer group <code>mygroup</code> and I&#39;m the consumer <code>Alice</code>. Every time a consumer performs an operation with a consumer group, it must specify its name, uniquely identifying this consumer inside the group.</p>\n<p>There is another very important detail in the command line above, after the mandatory <strong>STREAMS</strong> option the ID requested for the key <code>race:italy</code> is the special ID <code>&gt;</code>. This special ID is only valid in the context of consumer groups, and it means: <strong>messages never delivered to other consumers so far</strong>.</p>\n<p>This is almost always what you want, however it is also possible to specify a real ID, such as <code>0</code> or any other valid ID, in this case, however, what happens is that we request from <code>XREADGROUP</code> to just provide us with the <strong>history of pending messages</strong>, and in such case, will never see new messages in the group. So basically <code>XREADGROUP</code> has the following behavior based on the ID we specify:</p>\n<ul>\n<li>If the ID is the special ID <code>&gt;</code> then the command will return only new messages never delivered to other consumers so far, and as a side effect, will update the consumer group&#39;s <em>last ID</em>.</li>\n<li>If the ID is any other valid numerical ID, then the command will let us access our <em>history of pending messages</em>. That is, the set of messages that were delivered to this specified consumer (identified by the provided name), and never acknowledged so far with <code>XACK</code>.</li>\n</ul>\n<p>We can test this behavior immediately specifying an ID of 0, without any <strong>COUNT</strong> option: we&#39;ll just see the only pending message, that is, the one about Castilla:</p>\n<pre><code>127.0.0.1:6379&gt; XREADGROUP GROUP italy_riders Alice STREAMS race:italy 0\n1) 1) &quot;race:italy&quot;\n   2) 1) 1) &quot;1692632639151-0&quot;\n         2) 1) &quot;rider&quot;\n            2) &quot;Castilla&quot;\n</code></pre>\n<p>However, if we acknowledge the message as processed, it will no longer be part of the pending messages history, so the system will no longer report anything:</p>\n<pre><code>127.0.0.1:6379&gt; XACK race:italy italy_riders 1692632639151-0\n(integer) 1\n127.0.0.1:6379&gt; XREADGROUP GROUP italy_riders Alice STREAMS race:italy 0\n1) 1) &quot;race:italy&quot;\n   2) (empty array)\n</code></pre>\n<p>Don&#39;t worry if you yet don&#39;t know how <code>XACK</code> works, the idea is just that processed messages are no longer part of the history that we can access.</p>\n<p>Now it&#39;s Bob&#39;s turn to read something:</p>\n<pre><code>127.0.0.1:6379&gt; XREADGROUP GROUP italy_riders Bob COUNT 2 STREAMS race:italy &gt;\n1) 1) &quot;race:italy&quot;\n   2) 1) 1) &quot;1692632647899-0&quot;\n         2) 1) &quot;rider&quot;\n            2) &quot;Royce&quot;\n      2) 1) &quot;1692632662819-0&quot;\n         2) 1) &quot;rider&quot;\n            2) &quot;Sam-Bodden&quot;\n</code></pre>\n<p>Bob asked for a maximum of two messages and is reading via the same group <code>mygroup</code>. So what happens is that Valkey reports just <em>new</em> messages. As you can see the &quot;Castilla&quot; message is not delivered, since it was already delivered to Alice, so Bob gets Royce and Sam-Bodden and so forth.</p>\n<p>This way Alice, Bob, and any other consumer in the group, are able to read different messages from the same stream, to read their history of yet to process messages, or to mark messages as processed. This allows creating different topologies and semantics for consuming messages from a stream.</p>\n<p>There are a few things to keep in mind:</p>\n<ul>\n<li>Consumers are auto-created the first time they are mentioned, no need for explicit creation.</li>\n<li>Even with <code>XREADGROUP</code> you can read from multiple keys at the same time, however for this to work, you need to create a consumer group with the same name in every stream. This is not a common need, but it is worth mentioning that the feature is technically available.</li>\n<li><code>XREADGROUP</code> is a <em>write command</em> because even if it reads from the stream, the consumer group is modified as a side effect of reading, so it can only be called on primary instances.</li>\n</ul>\n<p>An example of a consumer implementation, using consumer groups, written in the Ruby language could be the following. The Ruby code is aimed to be readable by virtually any experienced programmer, even if they do not know Ruby:</p>\n<pre><code class=\"language-ruby\">require &#39;redis&#39;\n\nif ARGV.length == 0\n    puts &quot;Please specify a consumer name&quot;\n    exit 1\nend\n\nConsumerName = ARGV[0]\nGroupName = &quot;mygroup&quot;\nr = Redis.new\n\ndef process_message(id,msg)\n    puts &quot;[#{ConsumerName}] #{id} = #{msg.inspect}&quot;\nend\n\n$lastid = &#39;0-0&#39;\n\nputs &quot;Consumer #{ConsumerName} starting...&quot;\ncheck_backlog = true\nwhile true\n    # Pick the ID based on the iteration: the first time we want to\n    # read our pending messages, in case we crashed and are recovering.\n    # Once we consumed our history, we can start getting new messages.\n    if check_backlog\n        myid = $lastid\n    else\n        myid = &#39;&gt;&#39;\n    end\n\n    items = r.xreadgroup(&#39;GROUP&#39;,GroupName,ConsumerName,&#39;BLOCK&#39;,&#39;2000&#39;,&#39;COUNT&#39;,&#39;10&#39;,&#39;STREAMS&#39;,:my_stream_key,myid)\n\n    if items == nil\n        puts &quot;Timeout!&quot;\n        next\n    end\n\n    # If we receive an empty reply, it means we were consuming our history\n    # and that the history is now empty. Let&#39;s start to consume new messages.\n    check_backlog = false if items[0][1].length == 0\n\n    items[0][1].each{|i|\n        id,fields = i\n\n        # Process the message\n        process_message(id,fields)\n\n        # Acknowledge the message as processed\n        r.xack(:my_stream_key,GroupName,id)\n\n        $lastid = id\n    }\nend\n</code></pre>\n<p>As you can see the idea here is to start by consuming the history, that is, our list of pending messages. This is useful because the consumer may have crashed before, so in the event of a restart we want to re-read messages that were delivered to us without getting acknowledged. Note that we might process a message multiple times or one time (at least in the case of consumer failures, but there are also the limits of Valkey persistence and replication involved, see the specific section about this topic).</p>\n<p>Once the history was consumed, and we get an empty list of messages, we can switch to using the <code>&gt;</code> special ID in order to consume new messages.</p>\n<h2>Recovering from permanent failures</h2>\n<p>The example above allows us to write consumers that participate in the same consumer group, each taking a subset of messages to process, and when recovering from failures re-reading the pending messages that were delivered just to them. However in the real world consumers may permanently fail and never recover. What happens to the pending messages of the consumer that never recovers after stopping for any reason?</p>\n<p>Valkey consumer groups offer a feature that is used in these situations in order to <em>claim</em> the pending messages of a given consumer so that such messages will change ownership and will be re-assigned to a different consumer. The feature is very explicit. A consumer has to inspect the list of pending messages, and will have to claim specific messages using a special command, otherwise the server will leave the messages pending forever and assigned to the old consumer. In this way different applications can choose if to use such a feature or not, and exactly how to use it.</p>\n<p>The first step of this process is just a command that provides observability of pending entries in the consumer group and is called <code>XPENDING</code>.<br>This is a read-only command which is always safe to call and will not change ownership of any message.<br>In its simplest form, the command is called with two arguments, which are the name of the stream and the name of the consumer group.</p>\n<pre><code>127.0.0.1:6379&gt; XPENDING race:italy italy_riders\n1) (integer) 2\n2) &quot;1692632647899-0&quot;\n3) &quot;1692632662819-0&quot;\n4) 1) 1) &quot;Bob&quot;\n      2) &quot;2&quot;\n</code></pre>\n<p>When called in this way, the command outputs the total number of pending messages in the consumer group (two in this case), the lower and higher message ID among the pending messages, and finally a list of consumers and the number of pending messages they have.<br>We have only Bob with two pending messages because the single message that Alice requested was acknowledged using <code>XACK</code>.</p>\n<p>We can ask for more information by giving more arguments to <code>XPENDING</code>, because the full command signature is the following:</p>\n<pre><code>XPENDING &lt;key&gt; &lt;groupname&gt; [[IDLE &lt;min-idle-time&gt;] &lt;start-id&gt; &lt;end-id&gt; &lt;count&gt; [&lt;consumer-name&gt;]]\n</code></pre>\n<p>By providing a start and end ID (that can be just <code>-</code> and <code>+</code> as in <code>XRANGE</code>) and a count to control the amount of information returned by the command, we are able to know more about the pending messages. The optional final argument, the consumer name, is used if we want to limit the output to just messages pending for a given consumer, but won&#39;t use this feature in the following example.</p>\n<pre><code>127.0.0.1:6379&gt; XPENDING race:italy italy_riders - + 10\n1) 1) &quot;1692632647899-0&quot;\n   2) &quot;Bob&quot;\n   3) (integer) 74642\n   4) (integer) 1\n2) 1) &quot;1692632662819-0&quot;\n   2) &quot;Bob&quot;\n   3) (integer) 74642\n   4) (integer) 1\n</code></pre>\n<p>Now we have the details for each message: the ID, the consumer name, the <em>idle time</em> in milliseconds, which is how many milliseconds have passed since the last time the message was delivered to some consumer, and finally the number of times that a given message was delivered.<br>We have two messages from Bob, and they are idle for 60000+ milliseconds, about a minute.</p>\n<p>Note that nobody prevents us from checking what the first message content was by just using <code>XRANGE</code>.</p>\n<pre><code>127.0.0.1:6379&gt; XRANGE race:italy 1692632647899-0 1692632647899-0\n1) 1) &quot;1692632647899-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Royce&quot;\n</code></pre>\n<p>We have just to repeat the same ID twice in the arguments. Now that we have some ideas, Alice may decide that after 1 minute of not processing messages, Bob will probably not recover quickly, and it&#39;s time to <em>claim</em> such messages and resume the processing in place of Bob. To do so, we use the <code>XCLAIM</code> command.</p>\n<p>This command is very complex and full of options in its full form, since it is used for replication of consumer groups changes, but we&#39;ll use just the arguments that we need normally. In this case it is as simple as:</p>\n<pre><code>XCLAIM &lt;key&gt; &lt;group&gt; &lt;consumer&gt; &lt;min-idle-time&gt; &lt;ID-1&gt; &lt;ID-2&gt; ... &lt;ID-N&gt;\n</code></pre>\n<p>Basically we say, for this specific key and group, I want that the message IDs specified will change ownership, and will be assigned to the specified consumer name <code>&lt;consumer&gt;</code>. However, we also provide a minimum idle time, so that the operation will only work if the idle time of the mentioned messages is greater than the specified idle time. This is useful because maybe two clients are retrying to claim a message at the same time:</p>\n<pre><code>Client 1: XCLAIM race:italy italy_riders Alice 60000 1692632647899-0\nClient 2: XCLAIM race:italy italy_riders Lora 60000 1692632647899-0\n</code></pre>\n<p>However, as a side effect, claiming a message will reset its idle time and will increment its number of deliveries counter, so the second client will fail claiming it. In this way we avoid trivial re-processing of messages (even if in the general case you cannot obtain exactly once processing).</p>\n<p>This is the result of the command execution:</p>\n<pre><code>127.0.0.1:6379&gt; XCLAIM race:italy italy_riders Alice 60000 1692632647899-0\n1) 1) &quot;1692632647899-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Royce&quot;\n</code></pre>\n<p>The message was successfully claimed by Alice, who can now process the message and acknowledge it, and move things forward even if the original consumer is not recovering.</p>\n<p>It is clear from the example above that as a side effect of successfully claiming a given message, the <code>XCLAIM</code> command also returns it. However this is not mandatory. The <strong>JUSTID</strong> option can be used in order to return just the IDs of the message successfully claimed. This is useful if you want to reduce the bandwidth used between the client and the server (and also the performance of the command) and you are not interested in the message because your consumer is implemented in a way that it will rescan the history of pending messages from time to time.</p>\n<p>Claiming may also be implemented by a separate process: one that just checks the list of pending messages, and assigns idle messages to consumers that appear to be active. Active consumers can be obtained using one of the observability features of Streams. This is the topic of the next section.</p>\n<h2>Automatic claiming</h2>\n<p>The <code>XAUTOCLAIM</code> command, added in Redis OSS 6.2, implements the claiming process that we&#39;ve described above.<br><code>XPENDING</code> and <code>XCLAIM</code> provide the basic building blocks for different types of recovery mechanisms.<br>This command optimizes the generic process by having Valkey manage it and offers a simple solution for most recovery needs.</p>\n<p><code>XAUTOCLAIM</code> identifies idle pending messages and transfers ownership of them to a consumer.<br>The command&#39;s signature looks like this:</p>\n<pre><code>XAUTOCLAIM &lt;key&gt; &lt;group&gt; &lt;consumer&gt; &lt;min-idle-time&gt; &lt;start&gt; [COUNT count] [JUSTID]\n</code></pre>\n<p>So, in the example above, I could have used automatic claiming to claim a single message like this:</p>\n<pre><code>127.0.0.1:6379&gt; XAUTOCLAIM race:italy italy_riders Alice 60000 0-0 COUNT 1\n1) &quot;0-0&quot;\n2) 1) 1) &quot;1692632662819-0&quot;\n      2) 1) &quot;rider&quot;\n         2) &quot;Sam-Bodden&quot;\n</code></pre>\n<p>Like <code>XCLAIM</code>, the command replies with an array of the claimed messages, but it also returns a stream ID that allows iterating the pending entries.<br>The stream ID is a cursor, and I can use it in my next call to continue in claiming idle pending messages:</p>\n<pre><code>127.0.0.1:6379&gt; XAUTOCLAIM race:italy italy_riders Lora 60000 (1692632662819-0 COUNT 1\n1) &quot;1692632662819-0&quot;\n2) 1) 1) &quot;1692632647899-0&quot;\n      2) 1) &quot;rider&quot;\n         2) &quot;Royce&quot;\n</code></pre>\n<p>When <code>XAUTOCLAIM</code> returns the &quot;0-0&quot; stream ID as a cursor, that means that it reached the end of the consumer group pending entries list.<br>That doesn&#39;t mean that there are no new idle pending messages, so the process continues by calling <code>XAUTOCLAIM</code> from the beginning of the stream.</p>\n<h2>Claiming and the delivery counter</h2>\n<p>The counter that you observe in the <code>XPENDING</code> output is the number of deliveries of each message. The counter is incremented in two ways: when a message is successfully claimed via <code>XCLAIM</code> or when an <code>XREADGROUP</code> call is used in order to access the history of pending messages.</p>\n<p>When there are failures, it is normal that messages will be delivered multiple times, but eventually they usually get processed and acknowledged. However there might be a problem processing some specific message, because it is corrupted or crafted in a way that triggers a bug in the processing code. In such a case what happens is that consumers will continuously fail to process this particular message. Because we have the counter of the delivery attempts, we can use that counter to detect messages that for some reason are not processable. So once the deliveries counter reaches a given large number that you chose, it is probably wiser to put such messages in another stream and send a notification to the system administrator. This is basically the way that Streams implements the <em>dead letter</em> concept.</p>\n<h2>Streams observability</h2>\n<p>Messaging systems that lack observability are very hard to work with. Not knowing who is consuming messages, what messages are pending, the set of consumer groups active in a given stream, makes everything opaque. For this reason, Streams and consumer groups have different ways to observe what is happening. We already covered <code>XPENDING</code>, which allows us to inspect the list of messages that are under processing at a given moment, together with their idle time and number of deliveries.</p>\n<p>However we may want to do more than that, and the <code>XINFO</code> command is an observability interface that can be used with sub-commands in order to get information about streams or consumer groups.</p>\n<p>This command uses subcommands in order to show different information about the status of the stream and its consumer groups. For instance <strong>XINFO STREAM <key></strong> reports information about the stream itself.</p>\n<pre><code>127.0.0.1:6379&gt; XINFO STREAM race:italy\n 1) &quot;length&quot;\n 2) (integer) 5\n 3) &quot;radix-tree-keys&quot;\n 4) (integer) 1\n 5) &quot;radix-tree-nodes&quot;\n 6) (integer) 2\n 7) &quot;last-generated-id&quot;\n 8) &quot;1692632678249-0&quot;\n 9) &quot;groups&quot;\n10) (integer) 1\n11) &quot;first-entry&quot;\n12) 1) &quot;1692632639151-0&quot;\n    2) 1) &quot;rider&quot;\n       2) &quot;Castilla&quot;\n13) &quot;last-entry&quot;\n14) 1) &quot;1692632678249-0&quot;\n    2) 1) &quot;rider&quot;\n       2) &quot;Norem&quot;\n</code></pre>\n<p>The output shows information about how the stream is encoded internally, and also shows the first and last message in the stream. Another piece of information available is the number of consumer groups associated with this stream. We can dig further asking for more information about the consumer groups.</p>\n<pre><code>127.0.0.1:6379&gt; XINFO GROUPS race:italy\n1) 1) &quot;name&quot;\n   2) &quot;italy_riders&quot;\n   3) &quot;consumers&quot;\n   4) (integer) 3\n   5) &quot;pending&quot;\n   6) (integer) 2\n   7) &quot;last-delivered-id&quot;\n   8) &quot;1692632662819-0&quot;\n</code></pre>\n<p>As you can see in this and in the previous output, the <code>XINFO</code> command outputs a sequence of field-value items. Because it is an observability command this allows the human user to immediately understand what information is reported, and allows the command to report more information in the future by adding more fields without breaking compatibility with older clients. Other commands that must be more bandwidth efficient, like <code>XPENDING</code>, just report the information without the field names.</p>\n<p>The output of the example above, where the <strong>GROUPS</strong> subcommand is used, should be clear observing the field names. We can check in more detail the state of a specific consumer group by checking the consumers that are registered in the group.</p>\n<pre><code>127.0.0.1:6379&gt; XINFO CONSUMERS race:italy italy_riders\n1) 1) &quot;name&quot;\n   2) &quot;Alice&quot;\n   3) &quot;pending&quot;\n   4) (integer) 1\n   5) &quot;idle&quot;\n   6) (integer) 177546\n2) 1) &quot;name&quot;\n   2) &quot;Bob&quot;\n   3) &quot;pending&quot;\n   4) (integer) 0\n   5) &quot;idle&quot;\n   6) (integer) 424686\n3) 1) &quot;name&quot;\n   2) &quot;Lora&quot;\n   3) &quot;pending&quot;\n   4) (integer) 1\n   5) &quot;idle&quot;\n   6) (integer) 72241\n</code></pre>\n<p>In case you do not remember the syntax of the command, just ask the command itself for help:</p>\n<pre><code>&gt; XINFO HELP\n1) XINFO &lt;subcommand&gt; [&lt;arg&gt; [value] [opt] ...]. Subcommands are:\n2) CONSUMERS &lt;key&gt; &lt;groupname&gt;\n3)     Show consumers of &lt;groupname&gt;.\n4) GROUPS &lt;key&gt;\n5)     Show the stream consumer groups.\n6) STREAM &lt;key&gt; [FULL [COUNT &lt;count&gt;]\n7)     Show information about the stream.\n8) HELP\n9)     Prints this help.\n</code></pre>\n<h2>Differences with Kafka (TM) partitions</h2>\n<p>Consumer groups in Streams may resemble in some way Kafka (TM) partitioning-based consumer groups, however note that Streams are, in practical terms, very different. The partitions are only <em>logical</em> and the messages are just put into a single Valkey key, so the way the different clients are served is based on who is ready to process new messages, and not from which partition clients are reading. For instance, if the consumer C3 at some point fails permanently, Valkey will continue to serve C1 and C2 all the new messages arriving, as if now there are only two <em>logical</em> partitions.</p>\n<p>Similarly, if a given consumer is much faster at processing messages than the other consumers, this consumer will receive proportionally more messages in the same unit of time. This is possible since Valkey tracks all the unacknowledged messages explicitly, and remembers who received which message and the ID of the first message never delivered to any consumer.</p>\n<p>However, this also means that in Valkey if you really want to partition messages in the same stream into multiple Valkey instances, you have to use multiple keys and some sharding system such as Valkey Cluster or some other application-specific sharding system. A single Stream is not automatically partitioned to multiple instances.</p>\n<p>We could say that schematically the following is true:</p>\n<ul>\n<li>If you use 1 stream -&gt; 1 consumer, you are processing messages in order.</li>\n<li>If you use N streams with N consumers, so that only a given consumer hits a subset of the N streams, you can scale the above model of 1 stream -&gt; 1 consumer.</li>\n<li>If you use 1 stream -&gt; N consumers, you are load balancing to N consumers, however in that case, messages about the same logical item may be consumed out of order, because a given consumer may process message 3 faster than another consumer is processing message 4.</li>\n</ul>\n<p>So basically Kafka partitions are more similar to using N different Valkey keys, while Valkey consumer groups are a server-side load balancing system of messages from a given stream to N different consumers.</p>\n<h2>Capped Streams</h2>\n<p>Many applications do not want to collect data into a stream forever. Sometimes it is useful to have at maximum a given number of items inside a stream, other times once a given size is reached, it is useful to move data from Valkey to a storage which is not in memory and not as fast but suited to store the history for, potentially, decades to come. Streams have some support for this. One is the <strong>MAXLEN</strong> option of the <code>XADD</code> command. This option is very simple to use:</p>\n<pre><code>127.0.0.1:6379&gt; XADD race:italy MAXLEN 2 * rider Jones\n&quot;1692633189161-0&quot;\n127.0.0.1:6379&gt; XADD race:italy MAXLEN 2 * rider Wood\n&quot;1692633198206-0&quot;\n127.0.0.1:6379&gt; XADD race:italy MAXLEN 2 * rider Henshaw\n&quot;1692633208557-0&quot;\n127.0.0.1:6379&gt; XLEN race:italy\n(integer) 2\n127.0.0.1:6379&gt; XRANGE race:italy - +\n1) 1) &quot;1692633198206-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Wood&quot;\n2) 1) &quot;1692633208557-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Henshaw&quot;\n</code></pre>\n<p>Using <strong>MAXLEN</strong> the old entries are automatically evicted when the specified length is reached, so that the stream is left at a constant size. There is currently no option to tell the stream to just retain items that are not older than a given period, because such command, in order to run consistently, would potentially block for a long time in order to evict items. Imagine for example what happens if there is an insertion spike, then a long pause, and another insertion, all with the same maximum time. The stream would block to evict the data that became too old during the pause. So it is up to the user to do some planning and understand what is the maximum stream length desired. Moreover, while the length of the stream is proportional to the memory used, trimming by time is less simple to control and anticipate: it depends on the insertion rate which often changes over time (and when it does not change, then to just trim by size is trivial).</p>\n<p>However trimming with <strong>MAXLEN</strong> can be expensive: streams are represented by macro nodes into a radix tree, in order to be very memory efficient. Altering the single macro node, consisting of a few tens of elements, is not optimal. So it&#39;s possible to use the command in the following special form:</p>\n<pre><code>XADD race:italy MAXLEN ~ 1000 * ... entry fields here ...\n</code></pre>\n<p>The <code>~</code> argument between the <strong>MAXLEN</strong> option and the actual count means, I don&#39;t really need this to be exactly 1000 items. It can be 1000 or 1010 or 1030, just make sure to save at least 1000 items. With this argument, the trimming is performed only when we can remove a whole node. This makes it much more efficient, and it is usually what you want. You&#39;ll note here that the client libraries have various implementations of this. For example, the Python client defaults to approximate and has to be explicitly set to a true length.</p>\n<p>There is also the <code>XTRIM</code> command, which performs something very similar to what the <strong>MAXLEN</strong> option does above, except that it can be run by itself:</p>\n<pre><code>127.0.0.1:6379&gt; XTRIM race:italy MAXLEN 10\n(integer) 0\n</code></pre>\n<p>Or, as for the <code>XADD</code> option:</p>\n<pre><code>127.0.0.1:6379&gt; XTRIM race:italy MAXLEN ~ 10\n(integer) 0\n</code></pre>\n<p>However, <code>XTRIM</code> is designed to accept different trimming strategies. Another trimming strategy is <strong>MINID</strong>, that evicts entries with IDs lower than the one specified.</p>\n<p>As <code>XTRIM</code> is an explicit command, the user is expected to know about the possible shortcomings of different trimming strategies.</p>\n<p>Another useful eviction strategy that may be added to <code>XTRIM</code> in the future, is to remove by a range of IDs to ease use of <code>XRANGE</code> and <code>XTRIM</code> to move data from Valkey to other storage systems if needed.</p>\n<h2>Special IDs in the streams API</h2>\n<p>You may have noticed that there are several special IDs that can be used in the Valkey API. Here is a short recap, so that they can make more sense in the future.</p>\n<p>The first two special IDs are <code>-</code> and <code>+</code>, and are used in range queries with the <code>XRANGE</code> command. Those two IDs respectively mean the smallest ID possible (that is basically <code>0-1</code>) and the greatest ID possible (that is <code>18446744073709551615-18446744073709551615</code>). As you can see it is a lot cleaner to write <code>-</code> and <code>+</code> instead of those numbers.</p>\n<p>Then there are APIs where we want to say, the ID of the item with the greatest ID inside the stream. This is what <code>$</code> means. So for instance if I want only new entries with <code>XREADGROUP</code> I use this ID to signify I already have all the existing entries, but not the new ones that will be inserted in the future. Similarly when I create or set the ID of a consumer group, I can set the last delivered item to <code>$</code> in order to just deliver new entries to the consumers in the group.</p>\n<p>As you can see <code>$</code> does not mean <code>+</code>, they are two different things, as <code>+</code> is the greatest ID possible in every possible stream, while <code>$</code> is the greatest ID in a given stream containing given entries. Moreover APIs will usually only understand <code>+</code> or <code>$</code>, yet it was useful to avoid loading a given symbol with multiple meanings.</p>\n<p>Another special ID is <code>&gt;</code>, that is a special meaning only related to consumer groups and only when the <code>XREADGROUP</code> command is used. This special ID means that we want only entries that were never delivered to other consumers so far. So basically the <code>&gt;</code> ID is the <em>last delivered ID</em> of a consumer group.</p>\n<p>Finally the special ID <code>*</code>, that can be used only with the <code>XADD</code> command, means to auto select an ID for us for the new entry.</p>\n<p>So we have <code>-</code>, <code>+</code>, <code>$</code>, <code>&gt;</code> and <code>*</code>, and all have a different meaning, and most of the time, can be used in different contexts.</p>\n<h2>Persistence, replication and message safety</h2>\n<p>A Stream, like any other Valkey data structure, is asynchronously replicated to replicas and persisted into AOF and RDB files. However what may not be so obvious is that also the consumer groups full state is propagated to AOF, RDB and replicas, so if a message is pending in the primary, also the replica will have the same information. Similarly, after a restart, the AOF will restore the consumer groups&#39; state.</p>\n<p>However note that Streams and consumer groups are persisted and replicated using the Valkey default replication, so:</p>\n<ul>\n<li>AOF must be used with a strong fsync policy if persistence of messages is important in your application.</li>\n<li>By default the asynchronous replication will not guarantee that <code>XADD</code> commands or consumer groups state changes are replicated: after a failover something can be missing depending on the ability of replicas to receive the data from the primary.</li>\n<li>The <code>WAIT</code> command may be used in order to force the propagation of the changes to a set of replicas. However note that while this makes it very unlikely that data is lost, the Valkey failover process as operated by Sentinel or Valkey Cluster performs only a <em>best effort</em> check to failover to the replica which is the most updated, and under certain specific failure conditions may promote a replica that lacks some data.</li>\n</ul>\n<p>So when designing an application using Streams and consumer groups, make sure to understand the semantical properties your application should have during failures, and configure things accordingly, evaluating whether it is safe enough for your use case.</p>\n<h2>Removing single items from a stream</h2>\n<p>Streams also have a special command for removing items from the middle of a stream, just by ID. Normally for an append only data structure this may look like an odd feature, but it is actually useful for applications involving, for instance, privacy regulations. The command is called <code>XDEL</code> and receives the name of the stream followed by the IDs to delete:</p>\n<pre><code>127.0.0.1:6379&gt; XRANGE race:italy - + COUNT 2\n1) 1) &quot;1692633198206-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Wood&quot;\n2) 1) &quot;1692633208557-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Henshaw&quot;\n127.0.0.1:6379&gt; XDEL race:italy 1692633208557-0\n(integer) 1\n127.0.0.1:6379&gt; XRANGE race:italy - + COUNT 2\n1) 1) &quot;1692633198206-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Wood&quot;\n</code></pre>\n<p>However in the current implementation, memory is not really reclaimed until a macro node is completely empty, so you should not abuse this feature.</p>\n<h2>Zero length streams</h2>\n<p>A difference between streams and other Valkey data structures is that when the other data structures no longer have any elements, as a side effect of calling commands that remove elements, the key itself will be removed. So for instance, a sorted set will be completely removed when a call to <code>ZREM</code> will remove the last element in the sorted set. Streams, on the other hand, are allowed to stay at zero elements, both as a result of using a <strong>MAXLEN</strong> option with a count of zero (<code>XADD</code> and <code>XTRIM</code> commands), or because <code>XDEL</code> was called.</p>\n<p>The reason why such an asymmetry exists is because Streams may have associated consumer groups, and we do not want to lose the state that the consumer groups defined just because there are no longer any items in the stream. Currently the stream is not deleted even when it has no associated consumer groups.</p>\n<h2>Total latency of consuming a message</h2>\n<p>Non blocking stream commands like <code>XRANGE</code> and <code>XREAD</code> or <code>XREADGROUP</code> without the BLOCK option are served synchronously like any other Valkey command, so to discuss latency of such commands is meaningless: it is more interesting to check the time complexity of the commands in the Valkey documentation. It should be enough to say that stream commands are at least as fast as sorted set commands when extracting ranges, and that <code>XADD</code> is very fast and can easily insert from half a million to one million items per second in an average machine if pipelining is used.</p>\n<p>However latency becomes an interesting parameter if we want to understand the delay of processing a message, in the context of blocking consumers in a consumer group, from the moment the message is produced via <code>XADD</code>, to the moment the message is obtained by the consumer because <code>XREADGROUP</code> returned with the message.</p>\n<h2>How serving blocked consumers works</h2>\n<p>Before providing the results of performed tests, it is interesting to understand what model Valkey uses in order to route stream messages (and in general actually how any blocking operation waiting for data is managed).</p>\n<ul>\n<li>The blocked client is referenced in a hash table that maps keys for which there is at least one blocking consumer, to a list of consumers that are waiting for such key. This way, given a key that received data, we can resolve all the clients that are waiting for such data.</li>\n<li>When a write happens, in this case when the <code>XADD</code> command is called, it calls the <code>signalKeyAsReady()</code> function. This function will put the key into a list of keys that need to be processed, because such keys may have new data for blocked consumers. Note that such <em>ready keys</em> will be processed later, so in the course of the same event loop cycle, it is possible that the key will receive other writes.</li>\n<li>Finally, before returning into the event loop, the <em>ready keys</em> are finally processed. For each key the list of clients waiting for data is scanned, and if applicable, such clients will receive the new data that arrived. In the case of streams the data is the messages in the applicable range requested by the consumer.</li>\n</ul>\n<p>As you can see, basically, before returning to the event loop both the client calling <code>XADD</code> and the clients blocked to consume messages, will have their reply in the output buffers, so the caller of <code>XADD</code> should receive the reply from Valkey at about the same time the consumers will receive the new messages.</p>\n<p>This model is <em>push-based</em>, since adding data to the consumers buffers will be performed directly by the action of calling <code>XADD</code>, so the latency tends to be quite predictable.</p>\n<h2>Latency tests results</h2>\n<p>In order to check these latency characteristics a test was performed using multiple instances of Ruby programs pushing messages having as an additional field the computer millisecond time, and Ruby programs reading the messages from the consumer group and processing them. The message processing step consisted of comparing the current computer time with the message timestamp, in order to understand the total latency.</p>\n<p>Results obtained:</p>\n<pre><code>Processed between 0 and 1 ms -&gt; 74.11%\nProcessed between 1 and 2 ms -&gt; 25.80%\nProcessed between 2 and 3 ms -&gt; 0.06%\nProcessed between 3 and 4 ms -&gt; 0.01%\nProcessed between 4 and 5 ms -&gt; 0.02%\n</code></pre>\n<p>So 99.9% of requests have a latency &lt;= 2 milliseconds, with the outliers that remain still very close to the average.</p>\n<p>Adding a few million unacknowledged messages to the stream does not change the gist of the benchmark, with most queries still processed with very short latency.</p>\n<p>A few remarks:</p>\n<ul>\n<li>Here we processed up to 10k messages per iteration, this means that the <code>COUNT</code> parameter of <code>XREADGROUP</code> was set to 10000. This adds a lot of latency but is needed in order to allow the slow consumers to be able to keep with the message flow. So you can expect a real world latency that is a lot smaller.</li>\n<li>The system used for this benchmark is very slow compared to today&#39;s standards.</li>\n</ul>\n"
  },
  {
    "id": "strings",
    "topicName": "Strings",
    "description": "Introduction to Strings\n",
    "htmlContent": "<p>Strings store sequences of bytes, including text, serialized objects, and binary arrays.<br>As such, strings are the simplest type of value you can associate with<br>a Valkey key.<br>They&#39;re often used for caching, but they support additional functionality that lets you implement counters and perform bitwise operations, too.</p>\n<p>Since Valkey keys are strings, when we use the string type as a value too,<br>we are mapping a string to another string. The string data type is useful<br>for a number of use cases, like caching HTML fragments or pages.</p>\n<pre><code>127.0.0.1:6379&gt; SET bike:1 Deimos\nOK\n127.0.0.1:6379&gt; GET bike:1\n&quot;Deimos&quot;\n</code></pre>\n<p>As you can see using the <code>SET</code> and the <code>GET</code> commands are the way we set<br>and retrieve a string value. Note that <code>SET</code> will replace any existing value<br>already stored into the key, in the case that the key already exists, even if<br>the key is associated with a non-string value. So <code>SET</code> performs an assignment.</p>\n<p>Values can be strings (including binary data) of every kind, for instance you<br>can store a jpeg image inside a value. A value can&#39;t be bigger than 512 MB.</p>\n<p>The <code>SET</code> command has interesting options, that are provided as additional<br>arguments. For example, I may ask <code>SET</code> to fail if the key already exists,<br>or the opposite, that it only succeed if the key already exists:</p>\n<pre><code>127.0.0.1:6379&gt; set bike:1 bike nx\n(nil)\n127.0.0.1:6379&gt; set bike:1 bike xx\nOK\n</code></pre>\n<p>There are a number of other commands for operating on strings. For example<br>the <code>GETSET</code> command sets a key to a new value, returning the old value as the<br>result. You can use this command, for example, if you have a<br>system that increments a Valkey key using <code>INCR</code><br>every time your web site receives a new visitor. You may want to collect this<br>information once every hour, without losing a single increment.<br>You can <code>GETSET</code> the key, assigning it the new value of &quot;0&quot; and reading the<br>old value back.</p>\n<p>The ability to set or retrieve the value of multiple keys in a single<br>command is also useful for reduced latency. For this reason there are<br>the <code>MSET</code> and <code>MGET</code> commands:</p>\n<pre><code>127.0.0.1:6379&gt; mset bike:1 &quot;Deimos&quot; bike:2 &quot;Ares&quot; bike:3 &quot;Vanth&quot;\nOK\n127.0.0.1:6379&gt; mget bike:1 bike:2 bike:3\n1) &quot;Deimos&quot;\n2) &quot;Ares&quot;\n3) &quot;Vanth&quot;\n</code></pre>\n<p>When <code>MGET</code> is used, Valkey returns an array of values.</p>\n<h3>Strings as counters</h3>\n<p>Even if strings are the basic values of Valkey, there are interesting operations<br>you can perform with them. For instance, one is atomic increment:</p>\n<pre><code>127.0.0.1:6379&gt; set total_crashes 0\nOK\n127.0.0.1:6379&gt; incr total_crashes\n(integer) 1\n127.0.0.1:6379&gt; incrby total_crashes 10\n(integer) 11\n</code></pre>\n<p>The <code>INCR</code> command parses the string value as an integer,<br>increments it by one, and finally sets the obtained value as the new value.<br>There are other similar commands like <code>INCRBY</code>,<br><code>DECR</code> and <code>DECRBY</code>. Internally it&#39;s<br>always the same command, acting in a slightly different way.</p>\n<p>What does it mean that INCR is atomic?<br>That even multiple clients issuing INCR against<br>the same key will never enter into a race condition. For instance, it will never<br>happen that client 1 reads &quot;10&quot;, client 2 reads &quot;10&quot; at the same time, both<br>increment to 11, and set the new value to 11. The final value will always be<br>12 and the read-increment-set operation is performed while all the other<br>clients are not executing a command at the same time.</p>\n<h2>Limits</h2>\n<p>By default, a single String can be a maximum of 512 MB.</p>\n<h2>Basic commands</h2>\n<h3>Getting and setting Strings</h3>\n<ul>\n<li><code>SET</code> stores a string value.</li>\n<li><code>SETNX</code> stores a string value only if the key doesn&#39;t already exist. Useful for implementing locks.</li>\n<li><code>GET</code> retrieves a string value.</li>\n<li><code>MGET</code> retrieves multiple string values in a single operation.</li>\n</ul>\n<h3>Managing counters</h3>\n<ul>\n<li><code>INCRBY</code> atomically increments (and decrements when passing a negative number) counters stored at a given key.</li>\n<li>Another command exists for floating point counters: <code>INCRBYFLOAT</code>.</li>\n</ul>\n<h3>Bitwise operations</h3>\n<p>To perform bitwise operations on a string, see the <a href=\"bitmaps\">bitmaps data type</a> docs.</p>\n<p>See the <a href=\"../commands/#string\">complete list of string commands</a>.</p>\n<h2>Performance</h2>\n<p>Most string operations are O(1), which means they&#39;re highly efficient.<br>However, be careful with the <code>SUBSTR</code>, <code>GETRANGE</code>, and <code>SETRANGE</code> commands, which can be O(n).<br>These random-access string commands may cause performance issues when dealing with large strings.</p>\n<h2>Alternatives</h2>\n<p>If you&#39;re storing structured data as a serialized string, you may also want to consider Valkey <a href=\"hashes\">hashes</a>.</p>\n"
  },
  {
    "id": "transactions",
    "topicName": "Transactions",
    "description": "How transactions work in Valkey",
    "htmlContent": "<p>Valkey Transactions allow the execution of a group of commands<br>in a single step, they are centered around the commands<br><code>MULTI</code>, <code>EXEC</code>, <code>DISCARD</code> and <code>WATCH</code>.<br>Valkey Transactions make two important guarantees:</p>\n<ul>\n<li><p>All the commands in a transaction are serialized and executed<br>sequentially. A request sent by another client will never be<br>served <strong>in the middle</strong> of the execution of a Valkey Transaction.<br>This guarantees that the commands are executed as a single<br>isolated operation.</p>\n</li>\n<li><p>The <code>EXEC</code> command<br>triggers the execution of all the commands in the transaction, so<br>if a client loses the connection to the server in the context of a<br>transaction before calling the <code>EXEC</code> command none of the operations<br>are performed, instead if the <code>EXEC</code> command is called, all the<br>operations are performed. When using the<br><a href=\"persistence#append-only-file\">append-only file</a> Valkey makes sure<br>to use a single write(2) syscall to write the transaction on disk.<br>However if the Valkey server crashes or is killed by the system administrator<br>in some hard way it is possible that only a partial number of operations<br>are registered. Valkey will detect this condition at restart, and will exit with an error.<br>Using the <code>valkey-check-aof</code> tool it is possible to fix the<br>append only file that will remove the partial transaction so that the<br>server can start again.</p>\n</li>\n</ul>\n<p>Valkey allows for an extra guarantee to the<br>above two, in the form of optimistic locking in a way very similar to a<br>check-and-set (CAS) operation.<br>This is documented <a href=\"#cas\">later</a> on this page.</p>\n<h2>Usage</h2>\n<p>A Valkey Transaction is entered using the <code>MULTI</code> command. The command<br>always replies with <code>OK</code>. At this point the user can issue multiple<br>commands. Instead of executing these commands, Valkey will queue<br>them. All the commands are executed once <code>EXEC</code> is called.</p>\n<p>Calling <code>DISCARD</code> instead will flush the transaction queue and will exit<br>the transaction.</p>\n<p>The following example increments keys <code>foo</code> and <code>bar</code> atomically.</p>\n<pre><code>&gt; MULTI\nOK\n&gt; INCR foo\nQUEUED\n&gt; INCR bar\nQUEUED\n&gt; EXEC\n1) (integer) 1\n2) (integer) 1\n</code></pre>\n<p>As is clear from the session above, <code>EXEC</code> returns an<br>array of replies, where every element is the reply of a single command<br>in the transaction, in the same order the commands were issued.</p>\n<p>When a Valkey connection is in the context of a <code>MULTI</code> request,<br>all commands will reply with the string <code>QUEUED</code> (sent as a Status Reply<br>from the point of view of the Valkey protocol). A queued command is<br>simply scheduled for execution when <code>EXEC</code> is called.</p>\n<h2>Errors inside a transaction</h2>\n<p>During a transaction it is possible to encounter two kinds of command errors:</p>\n<ul>\n<li>A command may fail to be queued, so there may be an error before <code>EXEC</code> is called.<br>For instance the command may be syntactically wrong (wrong number of arguments,<br>wrong command name, ...), or there may be some critical condition like an out of<br>memory condition (if the server is configured to have a memory limit using the <code>maxmemory</code> directive).</li>\n<li>A command may fail <em>after</em> <code>EXEC</code> is called, for instance since we performed<br>an operation against a key with the wrong value (like calling a list operation against a string value).</li>\n</ul>\n<p>The server will detect an error during the accumulation of commands.<br>It will then refuse to execute the transaction returning an error during <code>EXEC</code>, discarding the transaction.</p>\n<p>Errors happening <em>after</em> <code>EXEC</code> instead are not handled in a special way:<br>all the other commands will be executed even if some command fails during the transaction.</p>\n<p>This is more clear on the protocol level. In the following example one<br>command will fail when executed even if the syntax is right:</p>\n<pre><code>Trying 127.0.0.1...\nConnected to localhost.\nEscape character is &#39;^]&#39;.\nMULTI\n+OK\nSET a abc\n+QUEUED\nLPOP a\n+QUEUED\nEXEC\n*2\n+OK\n-WRONGTYPE Operation against a key holding the wrong kind of value\n</code></pre>\n<p><code>EXEC</code> returned two-element <a href=\"protocol#bulk-strings\">bulk string reply</a> where one is an <code>OK</code> code and<br>the other an error reply. It&#39;s up to the client library to find a<br>sensible way to provide the error to the user.</p>\n<p>It&#39;s important to note that<br><strong>even when a command fails, all the other commands in the queue are processed</strong> – Valkey will <em>not</em> stop the<br>processing of commands.</p>\n<p>Another example, again using the wire protocol with <code>telnet</code>, shows how<br>syntax errors are reported ASAP instead:</p>\n<pre><code>MULTI\n+OK\nINCR a b c\n-ERR wrong number of arguments for &#39;incr&#39; command\nEXEC\n-EXECABORT Transaction discarded because of previous errors.\n</code></pre>\n<p>This time due to the syntax error the bad <code>INCR</code> command is not queued<br>at all. And the <code>EXEC</code> command will receive an <code>EXECABORT</code> error.</p>\n<p>When the <code>EXEC</code> command is processed, the server will check if a failover or slot migration has occurred since queuing the commands.<br>If either event has occurred, a <code>-MOVED</code> or <code>-REDIRECT</code> error will be returned if needed without processing the transaction.</p>\n<p>For cluster mode:</p>\n<pre><code>MULTI    ==&gt;  +OK\nSET x y  ==&gt;  +QUEUED\nslot {x} is migrated to other node\nEXEC     ==&gt;  -MOVED\n</code></pre>\n<p>For standalone mode:</p>\n<pre><code>MULTI    ==&gt;  +OK\nSET x y  ==&gt;  +QUEUED\nfailover\nEXEC     ==&gt;  -REDIRECT\n</code></pre>\n<p>Before the <code>EXEC</code> command is processed, if a command accesses data that does not belong to the current node,<br>a <code>-MOVED</code> or <code>-REDIRECT</code> error will be returned immediately, and the <code>EXEC</code> command will receive an <code>EXECABORT</code> error.</p>\n<p>For cluster mode:</p>\n<pre><code>MULTI    ==&gt;  +OK\nSET x y  ==&gt;  -MOVED\nEXEC     ==&gt;  -EXECABORT\n</code></pre>\n<p>For standalone mode:</p>\n<pre><code>MULTI    ==&gt;  +OK\nSET x y  ==&gt;  -REDIRECT\nEXEC     ==&gt;  -EXECABORT\n</code></pre>\n<h2>What about rollbacks?</h2>\n<p>Valkey does not support rollbacks of transactions since supporting rollbacks<br>would have a significant impact on the simplicity and performance of Valkey.</p>\n<h2>Discarding the command queue</h2>\n<p><code>DISCARD</code> can be used in order to abort a transaction. In this case, no<br>commands are executed and the state of the connection is restored to<br>normal.</p>\n<pre><code>&gt; SET foo 1\nOK\n&gt; MULTI\nOK\n&gt; INCR foo\nQUEUED\n&gt; DISCARD\nOK\n&gt; GET foo\n&quot;1&quot;\n</code></pre>\n<p><a name=\"cas\"></a></p>\n<h2>Optimistic locking using check-and-set</h2>\n<p><code>WATCH</code> is used to provide a check-and-set (CAS) behavior to Valkey<br>transactions.</p>\n<p><code>WATCH</code>ed keys are monitored in order to detect changes against them. If<br>at least one watched key is modified before the <code>EXEC</code> command, the<br>whole transaction aborts, and <code>EXEC</code> returns a <a href=\"protocol#nil-reply\">Null reply</a> to notify that<br>the transaction failed.</p>\n<p>For example, imagine we have the need to atomically increment the value<br>of a key by 1 (let&#39;s suppose Valkey doesn&#39;t have <code>INCR</code>).</p>\n<p>The first try may be the following:</p>\n<pre><code>val = GET mykey\nval = val + 1\nSET mykey $val\n</code></pre>\n<p>This will work reliably only if we have a single client performing the<br>operation in a given time. If multiple clients try to increment the key<br>at about the same time there will be a race condition. For instance,<br>client A and B will read the old value, for instance, 10. The value will<br>be incremented to 11 by both the clients, and finally <code>SET</code> as the value<br>of the key. So the final value will be 11 instead of 12.</p>\n<p>Thanks to <code>WATCH</code> we are able to model the problem very well:</p>\n<pre><code>WATCH mykey\nval = GET mykey\nval = val + 1\nMULTI\nSET mykey $val\nEXEC\n</code></pre>\n<p>Using the above code, if there are race conditions and another client<br>modifies the result of <code>val</code> in the time between our call to <code>WATCH</code> and<br>our call to <code>EXEC</code>, the transaction will fail.</p>\n<p>We just have to repeat the operation hoping this time we&#39;ll not get a<br>new race. This form of locking is called <em>optimistic locking</em>.<br>In many use cases, multiple clients will be accessing different keys,<br>so collisions are unlikely – usually there&#39;s no need to repeat the operation.</p>\n<h2>WATCH explained</h2>\n<p>So what is <code>WATCH</code> really about? It is a command that will<br>make the <code>EXEC</code> conditional: we are asking Valkey to perform<br>the transaction only if none of the <code>WATCH</code>ed keys were modified. This includes<br>modifications made by the client, like write commands, and by Valkey itself,<br>like expiration or eviction. If keys were modified between when they were<br><code>WATCH</code>ed and when the <code>EXEC</code> was received, the entire transaction will be aborted<br>instead.</p>\n<p><strong>NOTE:</strong><br>Commands within a transaction won&#39;t trigger the <code>WATCH</code> condition since they<br>are only queued until the <code>EXEC</code> is sent.</p>\n<p><code>WATCH</code> can be called multiple times. Simply all the <code>WATCH</code> calls will<br>have the effects to watch for changes starting from the call, up to<br>the moment <code>EXEC</code> is called. You can also send any number of keys to a<br>single <code>WATCH</code> call.</p>\n<p>When <code>EXEC</code> is called, all keys are <code>UNWATCH</code>ed, regardless of whether<br>the transaction was aborted or not.  Also when a client connection is<br>closed, everything gets <code>UNWATCH</code>ed.</p>\n<p>It is also possible to use the <code>UNWATCH</code> command (without arguments)<br>in order to flush all the watched keys. Sometimes this is useful as we<br>optimistically lock a few keys, since possibly we need to perform a<br>transaction to alter those keys, but after reading the current content<br>of the keys we don&#39;t want to proceed.  When this happens we just call<br><code>UNWATCH</code> so that the connection can already be used freely for new<br>transactions.</p>\n<h3>Using WATCH to implement ZPOPMIN</h3>\n<p>An example to illustrate how <code>WATCH</code> can be used to create<br>atomic operations is to implement <code>ZPOPMIN</code>,<br>that is a command that pops the element with the lower<br>score from a sorted set in an atomic way. This is a possible implementation:</p>\n<pre><code>WATCH zset\nelement = ZRANGE zset 0 0\nMULTI\nZREM zset element\nEXEC\n</code></pre>\n<p>If <code>EXEC</code> fails (i.e. returns a <a href=\"protocol#nil-reply\">Null reply</a>) we just repeat the operation.</p>\n<h2>Valkey scripting and transactions</h2>\n<p>Something else to consider for transaction-like operations are<br><a href=\"../commands/eval\">scripts</a> which are transactional. Everything<br>you can do with a Valkey Transaction, you can also do with a script.</p>\n"
  },
  {
    "id": "twitter-clone",
    "topicName": "Patterns example",
    "description": "Learn several Valkey patterns by building a Twitter clone",
    "htmlContent": "<p>This article describes the design and implementation of a <a href=\"https://github.com/antirez/retwis\">very simple Twitter clone</a> written using PHP with Valkey as the only database. The programming community has traditionally considered key-value stores as a special purpose database that couldn&#39;t be used as a drop-in replacement for a relational database for the development of web applications. This article will try to show that Valkey data structures on top of a key-value layer are an effective data model to implement many kinds of applications.</p>\n<p>Note: the original version of this article was written in 2009 when Redis OSS was<br>released. It was not exactly clear at that time that the data model was<br>suitable to write entire applications. There were many cases of<br>applications using Valkeyt as their main store, so the goal of the article today<br>is to be a tutorial for newcomers. You&#39;ll learn how to design a simple<br>data layout using Valkey, and how to apply different data structures.</p>\n<p>Our Twitter clone, called <a href=\"https://github.com/antirez/retwis\">Retwis</a>, is structurally simple, has very good performance, and can be distributed among any number of web and Valkey servers with little efforts. <a href=\"https://github.com/antirez/retwis\">View the Retwis source code</a>.</p>\n<p>I used PHP for the example because of its universal readability. The same (or better) results can be obtained using Ruby, Python, Erlang, and so on.<br>A few clones exist (however not all the clones use the same data layout as the<br>current version of this tutorial, so please, stick with the official PHP<br>implementation for the sake of following the article better).</p>\n<ul>\n<li><a href=\"https://github.com/danlucraft/retwis-rb\">Retwis-RB</a> is a port of Retwis to Ruby and Sinatra written by Daniel Lucraft.</li>\n<li><a href=\"https://docs.spring.io/spring-data/data-keyvalue/examples/retwisj/current/\">Retwis-J</a> is a port of Retwis to Java, using the Spring Data Framework, written by <a href=\"https://twitter.com/costinl\">Costin Leau</a>. Its source code can be found on <a href=\"https://github.com/SpringSource/spring-data-keyvalue-examples\">GitHub</a>, and there is comprehensive documentation available at <a href=\"https://j.mp/eo6z6I\">springsource.org</a>.</li>\n</ul>\n<h2>What is a key-value store?</h2>\n<p>The essence of a key-value store is the ability to store some data, called a <em>value</em>, inside a key. The value can be retrieved later only if we know the specific key it was stored in. There is no direct way to search for a key by value. In some sense, it is like a very large hash/dictionary, but it is persistent, i.e. when your application ends, the data doesn&#39;t go away. So, for example, I can use the command <code>SET</code> to store the value <em>bar</em> in the key <em>foo</em>:</p>\n<pre><code>SET foo bar\n</code></pre>\n<p>Valkey stores data permanently, so if I later ask &quot;<em>What is the value stored in key foo?</em>&quot; Valkey will reply with <em>bar</em>:</p>\n<pre><code>GET foo =&gt; bar\n</code></pre>\n<p>Other common operations provided by key-value stores are <code>DEL</code>, to delete a given key and its associated value, SET-if-not-exists (called <code>SETNX</code> on Valkey), to assign a value to a key only if the key does not already exist, and <code>INCR</code>, to atomically increment a number stored in a given key:</p>\n<pre><code>SET foo 10\nINCR foo =&gt; 11\nINCR foo =&gt; 12\nINCR foo =&gt; 13\n</code></pre>\n<h2>Atomic operations</h2>\n<p>There is something special about <code>INCR</code>. You may wonder why Valkey provides such an operation if we can do it ourselves with a bit of code? After all, it is as simple as:</p>\n<pre><code>x = GET foo\nx = x + 1\nSET foo x\n</code></pre>\n<p>The problem is that incrementing this way will work as long as there is only one client working with the key <em>foo</em> at one time. See what happens if two clients are accessing this key at the same time:</p>\n<pre><code>x = GET foo (yields 10)\ny = GET foo (yields 10)\nx = x + 1 (x is now 11)\ny = y + 1 (y is now 11)\nSET foo x (foo is now 11)\nSET foo y (foo is now 11)\n</code></pre>\n<p>Something is wrong! We incremented the value two times, but instead of going from 10 to 12, our key holds 11. This is because the increment done with <code>GET / increment / SET</code> <em>is not an atomic operation</em>. Instead the INCR provided by Valkey, Memcached, ..., are atomic implementations, and the server will take care of protecting the key during the time needed to complete the increment in order to prevent simultaneous accesses.</p>\n<p>What makes Valkey different from other key-value stores is that it provides other operations similar to INCR that can be used to model complex problems. This is why you can use Valkey to write whole web applications without using another database like an SQL database, and without going crazy.</p>\n<h2>Beyond key-value stores: lists</h2>\n<p>In this section we will see which Valkey features we need to build our Twitter clone. The first thing to know is that Valkey values can be more than strings. Valkey supports Lists, Sets, Hashes, Sorted Sets, Bitmaps, and HyperLogLog types as values, and there are atomic operations to operate on them so we are safe even with multiple accesses to the same key. Let&#39;s start with Lists:</p>\n<pre><code>LPUSH mylist a (now mylist holds &#39;a&#39;)\nLPUSH mylist b (now mylist holds &#39;b&#39;,&#39;a&#39;)\nLPUSH mylist c (now mylist holds &#39;c&#39;,&#39;b&#39;,&#39;a&#39;)\n</code></pre>\n<p><code>LPUSH</code> means <em>Left Push</em>, that is, add an element to the left (or to the head) of the list stored in <em>mylist</em>. If the key <em>mylist</em> does not exist it is automatically created as an empty list before the PUSH operation. As you can imagine, there is also an <code>RPUSH</code> operation that adds the element to the right of the list (on the tail). This is very useful for our Twitter clone. User updates can be added to a list stored in <code>username:updates</code>, for instance.</p>\n<p>There are operations to get data from Lists, of course. For instance, LRANGE returns a range from the list, or the whole list.</p>\n<pre><code>LRANGE mylist 0 1 =&gt; c,b\n</code></pre>\n<p>LRANGE uses zero-based indexes - that is the first element is 0, the second 1, and so on. The command arguments are <code>LRANGE key first-index last-index</code>. The <em>last-index</em> argument can be negative, with a special meaning: -1 is the last element of the list, -2 the penultimate, and so on. So, to get the whole list use:</p>\n<pre><code>LRANGE mylist 0 -1 =&gt; c,b,a\n</code></pre>\n<p>Other important operations are LLEN that returns the number of elements in the list, and LTRIM that is like LRANGE but instead of returning the specified range <em>trims</em> the list, so it is like <em>Get range from mylist, Set this range as new value</em> but does so atomically.</p>\n<h2>The Set data type</h2>\n<p>Currently we don&#39;t use the Set type in this tutorial, but since we use<br>Sorted Sets, which are kind of a more capable version of Sets, it is better<br>to start introducing Sets first (which are a very useful data structure<br>per se), and later Sorted Sets.</p>\n<p>There are more data types than just Lists. Valkey also supports Sets, which are unsorted collections of elements. It is possible to add, remove, and test for existence of members, and perform the intersection between different Sets. Of course it is possible to get the elements of a Set. Some examples will make it more clear. Keep in mind that <code>SADD</code> is the <em>add to set</em> operation, <code>SREM</code> is the <em>remove from set</em> operation, <code>SISMEMBER</code> is the <em>test if member</em> operation, and <code>SINTER</code> is the <em>perform intersection</em> operation. Other operations are <code>SCARD</code> to get the cardinality (the number of elements) of a Set, and <code>SMEMBERS</code> to return all the members of a Set.</p>\n<pre><code>SADD myset a\nSADD myset b\nSADD myset foo\nSADD myset bar\nSCARD myset =&gt; 4\nSMEMBERS myset =&gt; bar,a,foo,b\n</code></pre>\n<p>Note that <code>SMEMBERS</code> does not return the elements in the same order we added them since Sets are <em>unsorted</em> collections of elements. When you want to store in order it is better to use Lists instead. Some more operations against Sets:</p>\n<pre><code>SADD mynewset b\nSADD mynewset foo\nSADD mynewset hello\nSINTER myset mynewset =&gt; foo,b\n</code></pre>\n<p><code>SINTER</code> can return the intersection between Sets but it is not limited to two Sets. You may ask for the intersection of 4,5, or 10000 Sets. Finally let&#39;s check how <code>SISMEMBER</code> works:</p>\n<pre><code>SISMEMBER myset foo =&gt; 1\nSISMEMBER myset notamember =&gt; 0\n</code></pre>\n<h2>The Sorted Set data type</h2>\n<p>Sorted Sets are similar to Sets: collection of elements. However in Sorted<br>Sets each element is associated with a floating point value, called the<br><em>element score</em>. Because of the score, elements inside a Sorted Set are<br>ordered, since we can always compare two elements by score (and if the score<br>happens to be the same, we compare the two elements as strings).</p>\n<p>Like Sets in Sorted Sets it is not possible to add repeated elements, every<br>element is unique. However it is possible to update an element&#39;s score.</p>\n<p>Sorted Set commands are prefixed with <code>Z</code>. The following is an example<br>of Sorted Sets usage:</p>\n<pre><code>ZADD zset 10 a\nZADD zset 5 b\nZADD zset 12.55 c\nZRANGE zset 0 -1 =&gt; b,a,c\n</code></pre>\n<p>In the above example we added a few elements with <code>ZADD</code>, and later retrieved<br>the elements with <code>ZRANGE</code>. As you can see the elements are returned in order<br>according to their score. In order to check if a given element exists, and<br>also to retrieve its score if it exists, we use the <code>ZSCORE</code> command:</p>\n<pre><code>ZSCORE zset a =&gt; 10\nZSCORE zset non_existing_element =&gt; NULL\n</code></pre>\n<p>Sorted Sets are a very powerful data structure, you can query elements by<br>score range, lexicographically, in reverse order, and so forth.<br>To know more <a href=\"https://redis.io/commands/#sorted_set\">please check the Sorted Set sections in the official Valkey commands documentation</a>.</p>\n<h2>The Hash data type</h2>\n<p>This is the last data structure we use in our program, and is extremely easy<br>to grasp since there is an equivalent in almost every programming language out<br>there: Hashes. Hashes are basically like Ruby or Python hashes, a<br>collection of fields associated with values:</p>\n<pre><code>HMSET myuser name Salvatore surname Sanfilippo country Italy\nHGET myuser surname =&gt; Sanfilippo\n</code></pre>\n<p><code>HMSET</code> can be used to set fields in the hash, that can be retrieved with<br><code>HGET</code> later. It is possible to check if a field exists with <code>HEXISTS</code>, or<br>to increment a hash field with <code>HINCRBY</code> and so forth.</p>\n<p>Hashes are the ideal data structure to represent <em>objects</em>. For example we<br>use Hashes in order to represent Users and Updates in our Twitter clone.</p>\n<p>Okay, we just exposed the basics of the Valkey main data structures,<br>we are ready to start coding!</p>\n<h2>Prerequisites</h2>\n<p>If you haven&#39;t downloaded the <a href=\"https://github.com/antirez/retwis\">Retwis source code</a> already please grab it now. It contains a few PHP files, and also a copy of <a href=\"https://github.com/nrk/predis\">Predis</a>, the PHP client library we use in this example.</p>\n<p>Another thing you probably want is a working Valkey server. Just get the source, build with <code>make</code>, run with <code>./valkey-server</code>, and you&#39;re ready to go. No configuration is required at all in order to play with or run Retwis on your computer.</p>\n<h2>Data layout</h2>\n<p>When working with a relational database, a database schema must be designed so that we&#39;d know the tables, indexes, and so on that the database will contain. We don&#39;t have tables in Valkey, so what do we need to design? We need to identify what keys are needed to represent our objects and what kind of values these keys need to hold.</p>\n<p>Let&#39;s start with Users. We need to represent users, of course, with their username, userid, password, the set of users following a given user, the set of users a given user follows, and so on. The first question is, how should we identify a user? Like in a relational DB, a good solution is to identify different users with different numbers, so we can associate a unique ID with every user. Every other reference to this user will be done by id. Creating unique IDs is very simple to do by using our atomic <code>INCR</code> operation. When we create a new user we can do something like this, assuming the user is called &quot;antirez&quot;:</p>\n<pre><code>INCR next_user_id =&gt; 1000\nHMSET user:1000 username antirez password p1pp0\n</code></pre>\n<p><em>Note: you should use a hashed password in a real application, for simplicity<br>we store the password in clear text.</em></p>\n<p>We use the <code>next_user_id</code> key in order to always get a unique ID for every new user. Then we use this unique ID to name the key holding a Hash with user&#39;s data. <em>This is a common design pattern</em> with key-values stores! Keep it in mind.<br>Besides the fields already defined, we need some more stuff in order to fully define a User. For example, sometimes it can be useful to be able to get the user ID from the username, so every time we add a user, we also populate the <code>users</code> key, which is a Hash, with the username as field, and its ID as value.</p>\n<pre><code>HSET users antirez 1000\n</code></pre>\n<p>This may appear strange at first, but remember that we are only able to access data in a direct way, without secondary indexes. It&#39;s not possible to tell Valkey to return the key that holds a specific value. This is also <em>our strength</em>. This new paradigm is forcing us to organize data so that everything is accessible by <em>primary key</em>, speaking in relational DB terms.</p>\n<h2>Followers, following, and updates</h2>\n<p>There is another central need in our system. A user might have users who follow them, which we&#39;ll call their followers. A user might follow other users, which we&#39;ll call a following. We have a perfect data structure for this. That is... Sets.<br>The uniqueness of Sets elements, and the fact we can test in constant time for<br>existence, are two interesting features. However what about also remembering<br>the time at which a given user started following another one? In an enhanced<br>version of our simple Twitter clone this may be useful, so instead of using<br>a simple Set, we use a Sorted Set, using the user ID of the following or follower<br>user as element, and the unix time at which the relation between the users<br>was created, as our score.</p>\n<p>So let&#39;s define our keys:</p>\n<pre><code>followers:1000 =&gt; Sorted Set of uids of all the followers users\nfollowing:1000 =&gt; Sorted Set of uids of all the following users\n</code></pre>\n<p>We can add new followers with:</p>\n<pre><code>ZADD followers:1000 1401267618 1234 =&gt; Add user 1234 with time 1401267618\n</code></pre>\n<p>Another important thing we need is a place where we can add the updates to display in the user&#39;s home page. We&#39;ll need to access this data in chronological order later, from the most recent update to the oldest, so the perfect kind of data structure for this is a List. Basically every new update will be <code>LPUSH</code>ed in the user updates key, and thanks to <code>LRANGE</code>, we can implement pagination and so on. Note that we use the words <em>updates</em> and <em>posts</em> interchangeably, since updates are actually &quot;little posts&quot; in some way.</p>\n<pre><code>posts:1000 =&gt; a List of post ids - every new post is LPUSHed here.\n</code></pre>\n<p>This list is basically the User timeline. We&#39;ll push the IDs of her/his own<br>posts, and, the IDs of all the posts of created by the following users.<br>Basically, we&#39;ll implement a write fanout.</p>\n<h2>Authentication</h2>\n<p>OK, we have more or less everything about the user except for authentication. We&#39;ll handle authentication in a simple but robust way: we don&#39;t want to use PHP sessions, as our system must be ready to be distributed among different web servers easily, so we&#39;ll keep the whole state in our Valkey database. All we need is a random <strong>unguessable</strong> string to set as the cookie of an authenticated user, and a key that will contain the user ID of the client holding the string.</p>\n<p>We need two things in order to make this thing work in a robust way.<br>First: the current authentication <em>secret</em> (the random unguessable string)<br>should be part of the User object, so when the user is created we also set<br>an <code>auth</code> field in its Hash:</p>\n<pre><code>HSET user:1000 auth fea5e81ac8ca77622bed1c2132a021f9\n</code></pre>\n<p>Moreover, we need a way to map authentication secrets to user IDs, so<br>we also take an <code>auths</code> key, which has as value a Hash type mapping<br>authentication secrets to user IDs.</p>\n<pre><code>HSET auths fea5e81ac8ca77622bed1c2132a021f9 1000\n</code></pre>\n<p>In order to authenticate a user we&#39;ll do these simple steps (see the <code>login.php</code> file in the Retwis source code):</p>\n<ul>\n<li>Get the username and password via the login form.</li>\n<li>Check if the <code>username</code> field actually exists in the <code>users</code> Hash.</li>\n<li>If it exists we have the user id, (i.e. 1000).</li>\n<li>Check if user:1000 password matches, if not, return an error message.</li>\n<li>Ok authenticated! Set &quot;fea5e81ac8ca77622bed1c2132a021f9&quot; (the value of user:1000 <code>auth</code> field) as the &quot;auth&quot; cookie.</li>\n</ul>\n<p>This is the actual code:</p>\n<pre><code class=\"language-php\">include(&quot;retwis.php&quot;);\n\n# Form sanity checks\nif (!gt(&quot;username&quot;) || !gt(&quot;password&quot;))\n    goback(&quot;You need to enter both username and password to login.&quot;);\n\n# The form is ok, check if the username is available\n$username = gt(&quot;username&quot;);\n$password = gt(&quot;password&quot;);\n$r = redisLink();\n$userid = $r-&gt;hget(&quot;users&quot;,$username);\nif (!$userid)\n    goback(&quot;Wrong username or password&quot;);\n$realpassword = $r-&gt;hget(&quot;user:$userid&quot;,&quot;password&quot;);\nif ($realpassword != $password)\n    goback(&quot;Wrong username or password&quot;);\n\n# Username / password OK, set the cookie and redirect to index.php\n$authsecret = $r-&gt;hget(&quot;user:$userid&quot;,&quot;auth&quot;);\nsetcookie(&quot;auth&quot;,$authsecret,time()+3600*24*365);\nheader(&quot;Location: index.php&quot;);\n</code></pre>\n<p>This happens every time a user logs in, but we also need a function <code>isLoggedIn</code> in order to check if a given user is already authenticated or not. These are the logical steps preformed by the <code>isLoggedIn</code> function:</p>\n<ul>\n<li>Get the &quot;auth&quot; cookie from the user. If there is no cookie, the user is not logged in, of course. Let&#39;s call the value of the cookie <code>&lt;authcookie&gt;</code>.</li>\n<li>Check if <code>&lt;authcookie&gt;</code> field in the <code>auths</code> Hash exists, and what the value (the user ID) is (1000 in the example).</li>\n<li>In order for the system to be more robust, also verify that user:1000 auth field also matches.</li>\n<li>OK the user is authenticated, and we loaded a bit of information in the <code>$User</code> global variable.</li>\n</ul>\n<p>The code is simpler than the description, possibly:</p>\n<pre><code class=\"language-php\">function isLoggedIn() {\n    global $User, $_COOKIE;\n\n    if (isset($User)) return true;\n\n    if (isset($_COOKIE[&#39;auth&#39;])) {\n        $r = redisLink();\n        $authcookie = $_COOKIE[&#39;auth&#39;];\n        if ($userid = $r-&gt;hget(&quot;auths&quot;,$authcookie)) {\n            if ($r-&gt;hget(&quot;user:$userid&quot;,&quot;auth&quot;) != $authcookie) return false;\n            loadUserInfo($userid);\n            return true;\n        }\n    }\n    return false;\n}\n\nfunction loadUserInfo($userid) {\n    global $User;\n\n    $r = redisLink();\n    $User[&#39;id&#39;] = $userid;\n    $User[&#39;username&#39;] = $r-&gt;hget(&quot;user:$userid&quot;,&quot;username&quot;);\n    return true;\n}\n</code></pre>\n<p>Having <code>loadUserInfo</code> as a separate function is overkill for our application, but it&#39;s a good approach in a complex application. The only thing that&#39;s missing from all the authentication is the logout. What do we do on logout? That&#39;s simple, we&#39;ll just change the random string in user:1000 <code>auth</code> field, remove the old authentication secret from the <code>auths</code> Hash, and add the new one.</p>\n<p><em>Important:</em> the logout procedure explains why we don&#39;t just authenticate the user after looking up the authentication secret in the <code>auths</code> Hash, but double check it against user:1000 <code>auth</code> field. The true authentication string is the latter, while the <code>auths</code> Hash is just an authentication field that may even be volatile, or, if there are bugs in the program or a script gets interrupted, we may even end with multiple entries in the <code>auths</code> key pointing to the same user ID. The logout code is the following (<code>logout.php</code>):</p>\n<pre><code class=\"language-php\">include(&quot;retwis.php&quot;);\n\nif (!isLoggedIn()) {\n    header(&quot;Location: index.php&quot;);\n    exit;\n}\n\n$r = redisLink();\n$newauthsecret = getrand();\n$userid = $User[&#39;id&#39;];\n$oldauthsecret = $r-&gt;hget(&quot;user:$userid&quot;,&quot;auth&quot;);\n\n$r-&gt;hset(&quot;user:$userid&quot;,&quot;auth&quot;,$newauthsecret);\n$r-&gt;hset(&quot;auths&quot;,$newauthsecret,$userid);\n$r-&gt;hdel(&quot;auths&quot;,$oldauthsecret);\n\nheader(&quot;Location: index.php&quot;);\n</code></pre>\n<p>That is just what we described and should be simple to understand.</p>\n<h2>Updates</h2>\n<p>Updates, also known as posts, are even simpler. In order to create a new post in the database we do something like this:</p>\n<pre><code>INCR next_post_id =&gt; 10343\nHMSET post:10343 user_id $owner_id time $time body &quot;I&#39;m having fun with Retwis&quot;\n</code></pre>\n<p>As you can see each post is just represented by a Hash with three fields. The ID of the user owning the post, the time at which the post was published, and finally, the body of the post, which is, the actual status message.</p>\n<p>After we create a post and we obtain the post ID, we need to LPUSH the ID in the timeline of every user that is following the author of the post, and of course in the list of posts of the author itself (everybody is virtually following herself/himself). This is the file <code>post.php</code> that shows how this is performed:</p>\n<pre><code class=\"language-php\">include(&quot;retwis.php&quot;);\n\nif (!isLoggedIn() || !gt(&quot;status&quot;)) {\n    header(&quot;Location:index.php&quot;);\n    exit;\n}\n\n$r = redisLink();\n$postid = $r-&gt;incr(&quot;next_post_id&quot;);\n$status = str_replace(&quot;\\n&quot;,&quot; &quot;,gt(&quot;status&quot;));\n$r-&gt;hmset(&quot;post:$postid&quot;,&quot;user_id&quot;,$User[&#39;id&#39;],&quot;time&quot;,time(),&quot;body&quot;,$status);\n$followers = $r-&gt;zrange(&quot;followers:&quot;.$User[&#39;id&#39;],0,-1);\n$followers[] = $User[&#39;id&#39;]; /* Add the post to our own posts too */\n\nforeach($followers as $fid) {\n    $r-&gt;lpush(&quot;posts:$fid&quot;,$postid);\n}\n# Push the post on the timeline, and trim the timeline to the\n# newest 1000 elements.\n$r-&gt;lpush(&quot;timeline&quot;,$postid);\n$r-&gt;ltrim(&quot;timeline&quot;,0,1000);\n\nheader(&quot;Location: index.php&quot;);\n</code></pre>\n<p>The core of the function is the <code>foreach</code> loop. We use <code>ZRANGE</code> to get all the followers of the current user, then the loop will <code>LPUSH</code> the push the post in every follower timeline List.</p>\n<p>Note that we also maintain a global timeline for all the posts, so that in the Retwis home page we can show everybody&#39;s updates easily. This requires just doing an <code>LPUSH</code> to the <code>timeline</code> List. Let&#39;s face it, aren&#39;t you starting to think it was a bit strange to have to sort things added in chronological order using <code>ORDER BY</code> with SQL? I think so.</p>\n<p>There is an interesting thing to notice in the code above: we used a new<br>command called <code>LTRIM</code> after we perform the <code>LPUSH</code> operation in the global<br>timeline. This is used in order to trim the list to just 1000 elements. The<br>global timeline is actually only used in order to show a few posts in the<br>home page, there is no need to have the full history of all the posts.</p>\n<p>Basically <code>LTRIM</code> + <code>LPUSH</code> is a way to create a <em>capped collection</em> in Valkey.</p>\n<h2>Paginating updates</h2>\n<p>Now it should be pretty clear how we can use <code>LRANGE</code> in order to get ranges of posts, and render these posts on the screen. The code is simple:</p>\n<pre><code class=\"language-php\">function showPost($id) {\n    $r = redisLink();\n    $post = $r-&gt;hgetall(&quot;post:$id&quot;);\n    if (empty($post)) return false;\n\n    $userid = $post[&#39;user_id&#39;];\n    $username = $r-&gt;hget(&quot;user:$userid&quot;,&quot;username&quot;);\n    $elapsed = strElapsed($post[&#39;time&#39;]);\n    $userlink = &quot;&lt;a class=\\&quot;username\\&quot; href=\\&quot;profile.php?u=&quot;.urlencode($username).&quot;\\&quot;&gt;&quot;.utf8entities($username).&quot;&lt;/a&gt;&quot;;\n\n    echo(&#39;&lt;div class=&quot;post&quot;&gt;&#39;.$userlink.&#39; &#39;.utf8entities($post[&#39;body&#39;]).&quot;&lt;br&gt;&quot;);\n    echo(&#39;&lt;i&gt;posted &#39;.$elapsed.&#39; ago via web&lt;/i&gt;&lt;/div&gt;&#39;);\n    return true;\n}\n\nfunction showUserPosts($userid,$start,$count) {\n    $r = redisLink();\n    $key = ($userid == -1) ? &quot;timeline&quot; : &quot;posts:$userid&quot;;\n    $posts = $r-&gt;lrange($key,$start,$start+$count);\n    $c = 0;\n    foreach($posts as $p) {\n        if (showPost($p)) $c++;\n        if ($c == $count) break;\n    }\n    return count($posts) == $count+1;\n}\n</code></pre>\n<p><code>showPost</code> will simply convert and print a Post in HTML while <code>showUserPosts</code> gets a range of posts and then passes them to <code>showPosts</code>.</p>\n<p><strong>Note:</strong> <code>LRANGE</code> is not very efficient if the list of posts start to be very<br>big, and we want to access elements which are in the middle of the list, since Lists are backed by linked lists. If a system is designed for<br>deep pagination of million of items, it is better to resort to Sorted Sets<br>instead.*</p>\n<h2>Following users</h2>\n<p>It is not hard, but we did not yet check how we create following / follower relationships. If user ID 1000 (antirez) wants to follow user ID 5000 (pippo), we need to create both a following and a follower relationship. We just need to <code>ZADD</code> calls:</p>\n<pre><code>ZADD following:1000 5000\nZADD followers:5000 1000\n</code></pre>\n<p>Note the same pattern again and again. In theory with a relational database, the list of following and followers would be contained in a single table with fields like <code>following_id</code> and <code>follower_id</code>. You can extract the followers or following of every user using an SQL query. With a key-value DB things are a bit different since we need to set both the <code>1000 is following 5000</code> and <code>5000 is followed by 1000</code> relations. This is the price to pay, but on the other hand accessing the data is simpler and extremely fast. Having these things as separate sets allows us to do interesting stuff. For example, using <code>ZINTERSTORE</code> we can have the intersection of <code>following</code> of two different users, so we may add a feature to our Twitter clone so that it is able to tell you very quickly when you visit somebody else&#39;s profile, &quot;you and Alice have 34 followers in common&quot;, and things like that.</p>\n<p>You can find the code that sets or removes a following / follower relation in the <code>follow.php</code> file.</p>\n<h2>Making it horizontally scalable</h2>\n<p>Gentle reader, if you read till this point you are already a hero. Thank you. Before talking about scaling horizontally it is worth checking performance on a single server. Retwis is <em>extremely fast</em>, without any kind of cache. On a very slow and loaded server, an Apache benchmark with 100 parallel clients issuing 100000 requests measured the average pageview to take 5 milliseconds. This means you can serve millions of users every day with just a single Linux box, and this one was monkey ass slow... Imagine the results with more recent hardware.</p>\n<p>However you can&#39;t go with a single server forever, how do you scale a key-value<br>store?</p>\n<p>Retwis does not perform any multi-keys operation, so making it scalable is<br>simple: you may use client-side sharding, or something like a sharding proxy<br>like Twemproxy, or the upcoming Valkey Cluster.</p>\n<p>To know more about those topics please read<br><a href=\"cluster-tutorial\">our documentation about sharding</a>. However, the point here<br>to stress is that in a key-value store, if you design with care, the data set<br>is split among <strong>many independent small keys</strong>. To distribute those keys<br>to multiple nodes is more straightforward and predictable compared to using<br>a semantically more complex database system.</p>\n"
  },
  {
    "id": "valkey.conf",
    "topicName": "Configuration",
    "description": "Overview of valkey.conf, the Valkey configuration file\n",
    "htmlContent": "<p>Valkey is able to start without a configuration file using a built-in default<br>configuration, however this setup is only recommended for testing and<br>development purposes.</p>\n<p>The proper way to configure Valkey is by providing a Valkey configuration file,<br>usually called <code>valkey.conf</code>.</p>\n<p>The <code>valkey.conf</code> file contains a number of directives that have a very simple<br>format:</p>\n<pre><code>keyword argument1 argument2 ... argumentN\n</code></pre>\n<p>This is an example of a configuration directive:</p>\n<pre><code>replicaof 127.0.0.1 6380\n</code></pre>\n<p>It is possible to provide strings containing spaces as arguments using<br>(double or single) quotes, as in the following example:</p>\n<pre><code>requirepass &quot;hello world&quot;\n</code></pre>\n<p>Single-quoted string can contain characters escaped by backslashes, and<br>double-quoted strings can additionally include any ASCII symbols encoded using<br>backslashed hexadecimal notation &quot;\\xff&quot;.</p>\n<p>The list of configuration directives, and their meaning and intended usage<br>is available in the self documented example valkey.conf shipped into the<br>Valkey distribution.</p>\n<ul>\n<li>The self documented <a href=\"https://raw.githubusercontent.com/valkey-io/valkey/7.2/valkey.conf\">valkey.conf for Valkey OSS 7.2</a>.</li>\n<li>The self documented <a href=\"https://raw.githubusercontent.com/redis/redis/7.2/redis.conf\">redis.conf for Redis OSS 7.2</a>.</li>\n<li>The self documented <a href=\"https://raw.githubusercontent.com/redis/redis/7.0/redis.conf\">redis.conf for Redis OSS 7.0</a>.</li>\n<li>The self documented <a href=\"https://raw.githubusercontent.com/redis/redis/6.2/redis.conf\">redis.conf for Redis OSS 6.2</a>.</li>\n</ul>\n<h2>Passing arguments via the command line</h2>\n<p>You can also pass Valkey configuration parameters<br>using the command line directly. This is very useful for testing purposes.<br>The following is an example that starts a new Valkey instance using port 6380<br>as a replica of the instance running at 127.0.0.1 port 6379.</p>\n<pre><code>./valkey-server --port 6380 --replicaof 127.0.0.1 6379\n</code></pre>\n<p>The format of the arguments passed via the command line is exactly the same<br>as the one used in the valkey.conf file, with the exception that the keyword<br>is prefixed with <code>--</code>.</p>\n<p>Note that internally this generates an in-memory temporary config file<br>(possibly concatenating the config file passed by the user, if any) where<br>arguments are translated into the format of valkey.conf.</p>\n<h2>Changing Valkey configuration while the server is running</h2>\n<p>It is possible to reconfigure Valkey on the fly without stopping and restarting<br>the service, or querying the current configuration programmatically using the<br>special commands <code>CONFIG SET</code> and <code>CONFIG GET</code>.</p>\n<p>Not all of the configuration directives are supported in this way, but most<br>are supported as expected.<br>Please refer to the <code>CONFIG SET</code> and <code>CONFIG GET</code> pages for more information.</p>\n<p>Note that modifying the configuration on the fly <strong>has no effects on the<br>valkey.conf file</strong> so at the next restart of Valkey the old configuration will<br>be used instead.</p>\n<p>Make sure to also modify the <code>valkey.conf</code> file accordingly to the configuration<br>you set using <code>CONFIG SET</code>.<br>You can do it manually, or you can use <code>CONFIG REWRITE</code>, which will automatically scan your <code>valkey.conf</code> file and update the fields which don&#39;t match the current configuration value.<br>Fields non existing but set to the default value are not added.<br>Comments inside your configuration file are retained.</p>\n<h2>Configuring Valkey as a cache</h2>\n<p>If you plan to use Valkey as a cache where every key will have an<br>expire set, you may consider using the following configuration instead<br>(assuming a max memory limit of 2 megabytes as an example):</p>\n<pre><code>maxmemory 2mb\nmaxmemory-policy allkeys-lru\n</code></pre>\n<p>In this configuration there is no need for the application to set a<br>time to live for keys using the <code>EXPIRE</code> command (or equivalent) since<br>all the keys will be evicted using an approximated LRU algorithm as long<br>as we hit the 2 megabyte memory limit.</p>\n<p>Basically, in this configuration Valkey acts in a similar way to memcached.<br>We have more extensive documentation about using Valkey as an LRU cache <a href=\"lru-cache\">here</a>.</p>\n"
  }
];

export const categories: TopicCategory[] = [
  {
    "title": "GETTING STARTED",
    "items": [
      {
        "id": "faq",
        "topicName": "FAQ",
        "description": "Commonly asked questions when getting started with Valkey\n",
        "htmlContent": "<h2>How is Valkey different from other key-value stores?</h2>\n<ul>\n<li>Valkey has a different evolution path in the key-value DBs where values can contain more complex data types, with atomic operations defined on those data types. Valkey data types are closely related to fundamental data structures and are exposed to the programmer as such, without additional abstraction layers.</li>\n<li>Valkey is an in-memory but persistent on disk database, so it represents a different trade off where very high write and read speed is achieved with the limitation of data sets that can&#39;t be larger than memory. Another advantage of<br>in-memory databases is that the memory representation of complex data structures<br>is much simpler to manipulate compared to the same data structures on disk, so<br>Valkey can do a lot with little internal complexity. At the same time the<br>two on-disk storage formats (RDB and AOF) don&#39;t need to be suitable for random<br>access, so they are compact and always generated in an append-only fashion<br>(Even the AOF log rotation is an append-only operation, since the new version<br>is generated from the copy of data in memory). However this design also involves<br>different challenges compared to traditional on-disk stores. Being the main data<br>representation on memory, Valkey operations must be carefully handled to make sure<br>there is always an updated version of the data set on disk.</li>\n</ul>\n<h2>What&#39;s the Valkey memory footprint?</h2>\n<p>To give you a few examples:</p>\n<ul>\n<li>An empty instance uses ~ 3MB of memory.</li>\n<li>1 Million small Keys -&gt; String Value pairs use ~ 85MB of memory.</li>\n<li>1 Million Keys -&gt; Hash value, representing an object with 5 fields, use ~ 160 MB of memory.</li>\n</ul>\n<p>Testing your use case is trivial. Use the <code>valkey-benchmark</code> utility to generate random data sets then check the space used with the <code>INFO memory</code> command.</p>\n<h2>Why does Valkey keep its entire dataset in memory?</h2>\n<p>In the past, developers experimented with Virtual Memory and other systems in order to allow larger than RAM datasets, but after all we are very happy if we can do one thing well: data served from memory, disk used for storage. So for now there are no plans to create an on disk backend for Valkey. Most of what<br>Valkey is, after all, a direct result of its current design.</p>\n<p>If your real problem is not the total RAM needed, but the fact that you need<br>to split your data set into multiple Valkey instances, please read the<br><a href=\"cluster-tutorial\">partitioning page</a> in this documentation for more info.</p>\n<h2>Can you use Valkey with a disk-based database?</h2>\n<p>Yes, a common design pattern involves taking very write-heavy small data<br>in Valkey (and data you need the Valkey data structures to model your problem<br>in an efficient way), and big <em>blobs</em> of data into an SQL or eventually<br>consistent on-disk database. Similarly sometimes Valkey is used in order to<br>take in memory another copy of a subset of the same data stored in the on-disk<br>database. This may look similar to caching, but actually is a more advanced model<br>since normally the Valkey dataset is updated together with the on-disk DB dataset,<br>and not refreshed on cache misses.</p>\n<h2>How can I reduce Valkey&#39; overall memory usage?</h2>\n<p>A good practice is to consider memory consumption when mapping your logical data model to the physical data model within Valkey. These considerations include using specific data types, key patterns, and normalization.</p>\n<p>Beyond data modeling, there is more info in the <a href=\"memory-optimization\">Memory Optimization page</a>.</p>\n<h2>What happens if Valkey runs out of memory?</h2>\n<p>Valkey has built-in protections allowing the users to set a max limit on memory<br>usage, using the <code>maxmemory</code> option in the configuration file to put a limit<br>to the memory Valkey can use. If this limit is reached, Valkey will start to reply<br>with an error to write commands (but will continue to accept read-only<br>commands).</p>\n<p>You can also configure Valkey to evict keys when the max memory limit<br>is reached. See the <a href=\"lru-cache\">eviction policy docs</a> for more information on this.</p>\n<h2>Background saving fails with a fork() error on Linux?</h2>\n<p>Short answer: <code>echo 1 &gt; /proc/sys/vm/overcommit_memory</code> :)</p>\n<p>And now the long one:</p>\n<p>The Valkey background saving schema relies on the copy-on-write semantic of the <code>fork</code> system call in<br>modern operating systems: Valkey forks (creates a child process) that is an<br>exact copy of the parent. The child process dumps the DB on disk and finally<br>exits. In theory the child should use as much memory as the parent being a<br>copy, but actually thanks to the copy-on-write semantic implemented by most<br>modern operating systems the parent and child process will <em>share</em> the common<br>memory pages. A page will be duplicated only when it changes in the child or in<br>the parent. Since in theory all the pages may change while the child process is<br>saving, Linux can&#39;t tell in advance how much memory the child will take, so if<br>the <code>overcommit_memory</code> setting is set to zero the fork will fail unless there is<br>as much free RAM as required to really duplicate all the parent memory pages.<br>If you have a Valkey dataset of 3 GB and just 2 GB of free<br>memory it will fail.</p>\n<p>Setting <code>overcommit_memory</code> to 1 tells Linux to relax and perform the fork in a<br>more optimistic allocation fashion, and this is indeed what you want for Valkey.</p>\n<p>You can refer to the <a href=\"https://man7.org/linux/man-pages/man5/proc.5.html\">proc(5)</a> man page for explanations of the<br>available values.</p>\n<h2>Are Valkey on-disk snapshots atomic?</h2>\n<p>Yes, the Valkey background saving process is always forked when the server is<br>outside of the execution of a command, so every command reported to be atomic<br>in RAM is also atomic from the point of view of the disk snapshot.</p>\n<h2>How can Valkey use multiple CPUs or cores?</h2>\n<p>Enable I/O threading to offload client communication to threads.<br>In Valkey 8, the I/O threading implementation has been rewritten and greatly improved.<br>Reading commands from clients and writing replies back uses considerable CPU time.<br>By offloading this work to separate threads, the main thread can focus on executing commands.</p>\n<p>You can also start multiple instances of Valkey in the same box and combine them into a <a href=\"cluster-tutorial\">cluster</a>.</p>\n<h2>What is the maximum number of keys a single Valkey instance can hold? What is the maximum number of elements in a Hash, List, Set, and Sorted Set?</h2>\n<p>Valkey can handle up to 2<sup>32</sup> keys, and was tested in practice to<br>handle at least 250 million keys per instance.</p>\n<p>Every hash, list, set, and sorted set, can hold 2<sup>32</sup> elements.</p>\n<p>In other words your limit is likely the available memory in your system.</p>\n<h2>Why does my replica have a different number of keys than its primary instance?</h2>\n<p>If you use keys with limited time to live (Valkey expires) this is normal behavior. This is what happens:</p>\n<ul>\n<li>The primary generates an RDB file on the first synchronization with the replica.</li>\n<li>The RDB file will not include keys already expired in the primary but which are still in memory.</li>\n<li>These keys are still in the memory of the Valkey primary, even if logically expired. They&#39;ll be considered non-existent, and their memory will be reclaimed later, either incrementally or explicitly on access. While these keys are not logically part of the dataset, they are accounted for in the <code>INFO</code> output and in the <code>DBSIZE</code> command.</li>\n<li>When the replica reads the RDB file generated by the primary, this set of keys will not be loaded.</li>\n</ul>\n<p>Because of this, it&#39;s common for users with many expired keys to see fewer keys in the replicas. However, logically, the primary and replica will have the same content.</p>\n<h2>Why did Linux Foundation start the Valkey project?</h2>\n<p>Read about <a href=\"history\">the history of Valkey</a>.</p>\n"
      },
      {
        "id": "history",
        "topicName": "History",
        "description": "How the Valkey project started",
        "htmlContent": "<p>Valkey is a fork of the open-source Redis (REmote DIctionary Server) database<br>created in 2009 by the Italian hacker Salvatore “antirez” Sanfilippo. He<br>announced it on <a href=\"https://news.ycombinator.com/item?id=494649\">Hacker News</a> on Feb 25, 2009. <a href=\"https://github.blog/2009-11-03-introducing-resque/\">GitHub</a> and<br><a href=\"https://instagram-engineering.com/storing-hundreds-of-millions-of-simple-key-value-pairs-in-redis-1091ae80f74c\">Instagram</a> were among the early adopters.</p>\n<h2>Early works of Salvatore Sanfilippo</h2>\n<p>At the time, Salvatore “antirez” was already known for inventing the <a href=\"https://en.wikipedia.org/wiki/Idle_scan\">Idle<br>scan</a> port scanning technique, the <a href=\"https://en.wikipedia.org/wiki/Hping\">Hping</a> TCP/IP packet<br>generator and analyzer, the <a href=\"https://jim.tcl-lang.org/index.html/doc/www/www/about/\">Jim</a> TCL interpreter and the <a href=\"https://github.com/antirez/lloogg/blob/master/README\">LLOOGG</a><br>real-time log analyzer. To improve it, he created an in-memory database called<br>called <a href=\"https://gist.github.com/antirez/6ca04dd191bdb82aad9fb241013e88a8\">LLOOGG Memory DB</a>, which was a proof-of-concept of what later<br>became Redis and Valkey.</p>\n<h2>Early contributions and sponsorships</h2>\n<p>During 2009, Engine Yard contributed blocking POP (BLPOP) and part of the<br>Virtual Memory implementation (later deleted), Hitmeister contributed part of<br>the Cluster implementation and Citrusbyte contributed part of Virtual Memory<br>implementation. In 2010, Slicehost (acquired by Rackspace) provided Virtual<br>Machines for testing in a virtualized environment and Linode provided virtual<br>machines for testing in a virtualized environment. Also thanks to the following<br>people or organizations that donated to the Project: Emil Vladev, <a href=\"https://bradjasper.com/\">Brad<br>Jasper</a> and <a href=\"http://mrkris.com/\">Mrkris</a>. The<br><a href=\"https://en.wikipedia.org/wiki/Shuttleworth_Foundation\">Shuttleworth Foundation</a><br>donated 5000 USD to the project in form of a flash grant.</p>\n<p>Pieter Noordhuis and Matt Stancliff provided a significant amount of code and<br>ideas to the core and client libraries.</p>\n<h2>The time with VMware</h2>\n<p>In March, 2010, Sanfilippo was hired by <a href=\"https://vmware.com\">VMware</a> to work on<br>Redis and Redis Tools. In his blog post <a href=\"https://web.archive.org/web/20241017012850/http://oldblog.antirez.com/post/vmware-the-new-redis-home.html\">VMware: the new Redis<br>home</a>, he writes:</p>\n<blockquote>\n<p>Not only Redis will remain a totally open source project, but Redis Tools will<br>be open sourced also (and this was an idea I got from VMware itself!).</p>\n<p>This is why I&#39;m truly excited about joining VMware: together we&#39;ll build a<br>better, free Redis, bringing Redis development to another level.</p>\n</blockquote>\n<p>VMware, and later Pivotal (a VMware spin-off), provided a 24 GB RAM workstation<br>for Salvatore to run the Redis CI test and other long running tests. Later,<br>Salvatore equipped the server with an SSD drive in order to test in the same<br>hardware with rotating and flash drives. VMware sponsored the project until May<br>2013, with the work of Salvatore Sanfilippo and Pieter Noordhuis. From May 2013<br>to June 2015, Salvatore&#39;s work was sponsored by Pivotal.</p>\n<h2>The Redis Labs era</h2>\n<p>In 2011, a company called Garantia Data was founded and started providing<br>database services based on Redis. In 2013, Garantia Data was changing its name<br>to RedisDB, but <a href=\"https://www.forbes.com/sites/benkepes/2013/11/04/was-garantia-is-now-redisdb-either-way-nosql-is-hot/\">decided to withdraw the change</a> after complaints by<br>Sanfilippo:</p>\n<blockquote>\n<p>If this is true, it is not a good thing as the current informal rule was: use<br>&quot;Redis&quot; in company names that are selling Redis services, but in a way that<br>makes it distinguishable from Redis as a project. There are many examples like<br>OpenRedis, RedisToGo, and so forth. However &quot;RedisDB&quot; is different as it is<br>more like &quot;We are Redis&quot;, (I even own the &quot;redis-db.com&quot; domain name since<br>2009! you can WHOIS it to check). So in my opinion calling the company<br>&quot;RedisDB&quot; is wrong, especially since I and Garantia Data from time to time<br>have friendly conversations as we are both part of the &quot;Redis ecosystem&quot;, but<br>I did not received any prior question about this issue.</p>\n</blockquote>\n<p>The following year, 2014, Garantia Data <a href=\"https://techcrunch.com/2014/01/29/database-provider-garantia-data-makes-another-name-change-this-time-to-redis-labs/\">changed its name to Redis Labs</a>.</p>\n<p>In 2015, Salvatore left Pivotal for Redis Labs. He writes in his blog post<br><a href=\"https://web.archive.org/web/20241123010805/http://antirez.com/news/91\">Thanks Pivotal, Hello Redis Labs</a>:</p>\n<blockquote>\n<p>Redis Labs was willing to continue what VMware and Pivotal started. I&#39;ll be<br>able to work as I do currently, spending all my time in the open source side<br>of the project, while Redis Labs continues to provide Redis users with an<br>hassles-free Redis experience of managed instances and products.</p>\n</blockquote>\n<p>In 2018, Redis Labs changed the license of some of its modules from AGPL to a<br>source-available license. The license prevents competing cloud providers from<br>offering these modules to customers and does therefore not fulfill the criteria<br>for an open source license.</p>\n<p>This was interpreted by some as if Redis is no longer open source. Sanfilippo<br>clarified on his blog <a href=\"https://web.archive.org/web/20241111062719/http://antirez.com/news/120\">Redis will remain BSD licensed</a>.</p>\n<p>Yiftach Shoolman, CTO and co-founder of Redis Labs, also clarified in in the<br>company&#39;s blog that <a href=\"https://redis.io/blog/redis-license-bsd-will-remain-bsd/\">Redis&#39; License is BSD and will remain<br>BSD</a>. He repeated this promise in <a href=\"https://news.ycombinator.com/item?id=17819392\">a comment on Hacker<br>News</a>, writing “let me assure you that Redis remains and always<br>will remain, open source, BSD license”.</p>\n<p>In 2020, Salvatore Sanfilippo announced in his blog post <a href=\"https://web.archive.org/web/20241123005834/http://antirez.com/news/133\">The end of the Redis<br>adventure</a> that he was stepping back as the Redis<br>maintainer, handing over the maintenance to Yossi Gottlieb and Oran Agra at<br>Redis Labs. The two created a “core team” to maintain the project and invited<br>Itamar Haber from Redis Labs, Zhao Zhao from Alibaba and Madelyn Olson from<br>Amazon. The members were selected “based on demonstrated, long-term personal<br>involvement and contributions”. This was described in the projects<br><a href=\"https://web.archive.org/web/20200709170526/https://redis.io/topics/governance\">Governance</a> page which was the inspiration for the current<br><a href=\"https://github.com/valkey-io/valkey/blob/unstable/GOVERNANCE\">Valkey governance</a>.</p>\n<p>In 2021, the Redis Labs changed its name to Redis Ltd. or just Redis. In this<br>article, we&#39;re using the name Redis Ltd. when referring to the company to avoid<br>confusion. By this time, Redis Ltd. had acquired the trademark rights to the<br>name Redis and the logo from Sanfilippo.</p>\n<h2>The end of open source Redis</h2>\n<p>In 2024, Redis Ltd. changed the license of Redis from the open source BSD<br>license to dual source-available licenses. This was announced in a blog post<br><a href=\"https://redis.io/blog/redis-adopts-dual-source-available-licensing/\">Redis Adopts Dual Source-Available Licensing</a> and the<br>license change was <a href=\"https://github.com/redis/redis/pull/13157\">committed to the repository</a> the same day.</p>\n<p>Neither of the licenses, Redis Source Available License (RSALv2) nor the Server<br>Side Public License (SSPLv1), are open source licenses, as neither meet the<br>criteria of an open source license.</p>\n<p>RSALv2 forbids the use of the software in database products, to prevent their<br>competitors from providing database products and services. Such a restriction is<br>not in line with <a href=\"https://opensource.org/osd\">The Open Source Definition</a>, criterion #6 “The license<br>must not restrict anyone from making use of the program in a specific field of<br>endeavor” by the Open Source Initiative, nor “the freedom to run the program as<br>you wish, for any purpose (freedom 0)” in the Free Software Foundation&#39;s<br>definition of Free Software. The SSPL has similar restrictions, explained in the<br><a href=\"https://en.wikipedia.org/wiki/Server_Side_Public_License\">SSPL article on Wikipedia</a>.</p>\n<h2>The birth of Valkey</h2>\n<p>Many contributors, including companies providing hosted Redis-derived or<br>Redis-compatible database services, just like Redis Ltd. does, have been using<br>and contributing to Redis just as long as Redis Ltd. has existed. It was<br>therefore and easy decision for many of them to continue the open source<br>development as usual under the BSD license.</p>\n<p>As Redis Ltd. owns the trademark rights to the name Redis, the open source<br>project needed to continue under a different name. A group of six active<br>contributors (one from each of Alibaba, Amazon, Ericsson, Google, Huawei and<br>Tencent) with the support from several other companies launched Valkey as a<br>Linux Foundation project. It was announced in a <a href=\"https://www.linuxfoundation.org/press/linux-foundation-launches-open-source-valkey-community\">press release</a> only<br>eight days after Redis&#39; license change. Three weeks later, a <a href=\"https://www.linuxfoundation.org/press/valkey-community-announces-release-candidate-amid-growing-support-for-open-source-data-store\">second press<br>release</a> announced seven more companies joining and the first<br>release, Valkey 7.2.5.</p>\n"
      },
      {
        "id": "installation",
        "topicName": "Installation",
        "description": "Install Valkey on Linux, macOS, and Windows\n",
        "htmlContent": "<p>This is a an installation guide. You&#39;ll learn how to install, run, and experiment with the Valkey server process.</p>\n<p>The download page <a href=\"https://valkey.io/download\">valkey.io/download</a> lists the latest releases.</p>\n<h2>Install Valkey</h2>\n<p>These are some ways to install Valkey.<br>Refer to <a href=\"admin\">Valkey Administration</a> for detailed setup tips.</p>\n<h3>From source</h3>\n<p>Source releases are available from the GitHub <a href=\"https://github.com/valkey-io/valkey/releases\">Releases</a> page.</p>\n<p>Unpack the tarball (e.g. <code>tar -xzvf valkey-8.0.1.tar.gz</code>) and follow the instructions in the included README.md.</p>\n<h3>Containers</h3>\n<p>Containers on <a href=\"https://hub.docker.com/r/valkey/valkey/\">Docker Hub</a>.</p>\n<h3>MacOS</h3>\n<h4>Using <a href=\"https://brew.sh/\">Homebrew</a> to install and run Valkey:</h4>\n<pre><code class=\"language-bash\">brew install valkey\n# To run Valkey as a service, use\nbrew services start valkey\n# Check that it&#39;s running using\nbrew services info valkey\n# and stop it using\nbrew services stop valkey\n</code></pre>\n<h4>Using <a href=\"https://www.macports.org/\">MacPorts</a>:</h4>\n<pre><code class=\"language-bash\">sudo port install valkey\n</code></pre>\n<h3>Linux/BSD package managers</h3>\n<p>The following package managers are known to be supported, but the list is not exhaustive and may not be up to date.<br>If you see an issue, feel free to submit a PR to update this list.<br>You can use the <a href=\"https://pkgs.org/download/valkey\">pkgs.org</a> website (linux/unix only) or <a href=\"https://repology.org/project/valkey/versions\">repology.org</a> to check which versions of Valkey are available for your distributions.</p>\n<h4>apt (Debian based)</h4>\n<p>Currently available on:<br>Debian/Ubuntu/Mint/Devuan/Raspbian/PureOS</p>\n<pre><code class=\"language-bash\">sudo apt update\nsudo apt install valkey\n# For symlinked binaries to redis-cli and redis-server\nsudo apt install valkey-compat\n</code></pre>\n<h4>apk (Alpine Linux/Kali Linux/Wolfi)</h4>\n<pre><code class=\"language-bash\">sudo apk update\nsudo apk add valkey\n# Below relevant for Alpine.\n# For valkey-cli\nsudo apk add valkey-cli\n# For symlinked binaries to redis-cli and redis-server\nsudo apk add valkey-compat\n</code></pre>\n<h4>yum (CentOS/RHEL/Fedora)</h4>\n<pre><code class=\"language-bash\">sudo yum install valkey\n# For symlinked binaries to redis-cli and redis-server\nsudo yum install valkey-compat\n# For valkey-doc (can be used with man, e.g. `man hgetall`, `man valkey.conf`, etc.)\nsudo yum install valkey-doc\n</code></pre>\n<p>Some versions of CentOS and RHEL may not have Valkey in their default repositories.<br>You can use the EPEL repository - <a href=\"https://fedoraproject.org/wiki/EPEL\">https://fedoraproject.org/wiki/EPEL</a> to install Valkey.</p>\n<h4>dnf (Fedora)</h4>\n<pre><code class=\"language-bash\">sudo dnf install valkey\n# For symlinked binaries to redis-cli and redis-server\nsudo dnf install valkey-compat\n# For valkey-doc (can be used with man, e.g. `man hgetall`, `man valkey.conf`, etc.)\nsudo dnf install valkey-doc\n</code></pre>\n<h4>Other distributions</h4>\n<pre><code class=\"language-bash\"># ALT Linux\nsudo apt-get install valkey\n# Arch Linux/Manjaro\nsudo pacman -Sy valkey\n# FreeBSD\nsudo pkg install valkey\n# NixOS\nnix-env -i valkey\n# openSUSE\nsudo zypper install valkey\n# Solus\nsudo eopkg install valkey\n# Void Linux\nsudo xbps-install -Su valkey\n# Exherbo\ncave resolve -x dev-db/valkey\n</code></pre>\n<h4>Miscellaneous</h4>\n<p>Available on <a href=\"https://slackbuilds.org/repository/15.0/system/valkey/\">SlackBuilds</a><br>and openpkg on <a href=\"https://openpkg.com/\">OpenPKG</a>.</p>\n<h3>Windows</h3>\n<p>Valkey is not officially supported on Windows. However, you can install Valkey<br>on Windows for development using WSL (Windows Subsystem for Linux).</p>\n<h2>Test if you can connect using the CLI</h2>\n<p>If you&#39;re not yet running Valkey as a system service,<br>you can run Valkey in the foreground using <code>valkey-server</code> and stop it using Ctrl-C.</p>\n<p>When you have Valkey up and running, you can connect using <code>valkey-cli</code>.</p>\n<p>External programs talk to Valkey using a TCP socket and a Valkey specific protocol. This protocol is implemented in the Valkey client libraries for the different programming languages. However, to make hacking with Valkey simpler, Valkey provides a command line utility that can be used to send commands to Valkey. This program is called <strong>valkey-cli</strong>.</p>\n<p>The first thing to do to check if Valkey is working properly is sending a <strong>PING</strong> command using <code>valkey-cli</code>:</p>\n<pre><code>$ valkey-cli ping\nPONG\n</code></pre>\n<p>Running <strong>valkey-cli</strong> followed by a command name and its arguments will send this command to the Valkey instance running on localhost at port 6379. You can change the host and port used by <code>valkey-cli</code> - just try the <code>--help</code> option to check the usage information.</p>\n<p>Another interesting way to run <code>valkey-cli</code> is without arguments: the program will start in interactive mode. You can type different commands and see their replies.</p>\n<pre><code>$ valkey-cli\n127.0.0.1:6379&gt; ping\nPONG\n</code></pre>\n<h2>Securing Valkey</h2>\n<p>By default Valkey binds to <strong>all the interfaces</strong> and has no authentication at all. If you use Valkey in a very controlled environment, separated from the external internet and in general from attackers, that&#39;s fine. However, if an unhardened Valkey is exposed to the internet, it is a big security concern. If you are not 100% sure your environment is secured properly, please check the following steps in order to make Valkey more secure:</p>\n<ol>\n<li>Make sure the port Valkey uses to listen for connections (by default 6379 and additionally 16379 if you run Valkey in cluster mode, plus 26379 for Sentinel) is firewalled, so that it is not possible to contact Valkey from the outside world.</li>\n<li>Use a configuration file where the <code>bind</code> directive is set in order to guarantee that Valkey listens on only the network interfaces you are using. For example, only the loopback interface (127.0.0.1) if you are accessing Valkey locally from the same computer.</li>\n<li>Set up authentication using <a href=\"acl\">Access Control List (ACL)</a> or use the <code>requirepass</code> option to add an additional layer of security so that clients will be required to authenticate using the <code>AUTH</code> command.</li>\n<li>Use <a href=\"encryption\">TLS</a> to encrypt traffic between Valkey servers and Valkey clients if your environment requires encryption.</li>\n</ol>\n<p>Make sure you understand the above and apply <strong>at least</strong> a firewall layer. After the firewall is in place, try to connect with <code>valkey-cli</code> from an external host to confirm that the instance is not reachable.</p>\n<h2>Use Valkey from your application</h2>\n<p>Of course using Valkey just from the command line interface is not enough as the goal is to use it from your application. To do so, you need to download and install a Valkey client library for your programming language.</p>\n<p>You&#39;ll find a <a href=\"../clients/\">full list of clients for different languages in this page</a>.</p>\n<h2>Valkey persistence</h2>\n<p>You can learn <a href=\"persistence\">how Valkey persistence works on this page</a>.<br>It is important to understand that, if you start Valkey with the default configuration, Valkey will spontaneously save the dataset only from time to time.<br>For example, after at least five minutes if you have at least 100 changes in your data.<br>If you want your database to persist and be reloaded after a restart, make sure to call the <a href=\"../commands/save\">SAVE</a> command manually every time you want to force a data set snapshot.<br>Alternatively, you can save the data on disk before quitting by using the <a href=\"../commands/shutdown\">SHUTDOWN</a> command:</p>\n<pre><code>$ valkey-cli shutdown\n</code></pre>\n<p>This way, Valkey will save the data on disk before quitting. Reading the <a href=\"persistence\">persistence page</a> is strongly suggested to better understand how Valkey persistence works.</p>\n<h2>Install Valkey as a system service</h2>\n<p>Running Valkey from the command line is fine just to hack a bit or for development. However, at some point you&#39;ll have some actual application to run on a real server.<br>For this kind of usage, it&#39;s highly recommended to install Valkey as a system service so that everything will start properly after a system restart.<br>The available packages for supported Linux distributions already include the capability of starting the Valkey server as a service.</p>\n<p>Valkey supports systemd, but this document was written for init scripts, before systemd was widely adapted.<br>There are many guides online for how to set up a systemd service.</p>\n<p>The remainder of this section explains how to set up Valkey using an init script, for distros like Alpine Linux that don&#39;t use systemd.</p>\n<p>If you have not yet run <code>make install</code> after building the Valkey source, you will need to do so before continuing. By default, <code>make install</code> will copy the <code>valkey-server</code> and <code>valkey-cli</code> binaries to <code>/usr/local/bin</code>.</p>\n<ul>\n<li><p>Create a directory in which to store your Valkey config files and your data:</p>\n<pre><code>sudo mkdir /etc/valkey\nsudo mkdir /var/valkey\n</code></pre>\n</li>\n<li><p>Copy the init script that you&#39;ll find in the Valkey distribution under the <strong>utils</strong> directory into <code>/etc/init.d</code>. We suggest calling it with the name of the port where you are running this instance of Valkey. Make sure the resulting file has <code>0755</code> permissions.</p>\n<pre><code>sudo cp utils/valkey_init_script /etc/init.d/valkey_6379\n</code></pre>\n</li>\n<li><p>Edit the init script.</p>\n<pre><code>sudo vi /etc/init.d/valkey_6379\n</code></pre>\n</li>\n</ul>\n<p>Make sure to set the <code>VALKEYPORT</code> variable to the port you are using.<br>Both the pid file path and the configuration file name depend on the port number.</p>\n<ul>\n<li><p>Copy the template configuration file you&#39;ll find in the root directory of the Valkey distribution into <code>/etc/valkey/</code> using the port number as the name, for instance:</p>\n<pre><code>sudo cp valkey.conf /etc/valkey/6379.conf\n</code></pre>\n</li>\n<li><p>Create a directory inside <code>/var/valkey</code> that will work as both data and working directory for this Valkey instance:</p>\n<pre><code>sudo mkdir /var/valkey/6379\n</code></pre>\n</li>\n<li><p>Edit the configuration file, making sure to perform the following changes:</p>\n<ul>\n<li>Set <strong>daemonize</strong> to yes (by default it is set to no).</li>\n<li>Set the <strong>pidfile</strong> to <code>/var/run/valkey_6379.pid</code>, modifying the port as necessary.</li>\n<li>Change the <strong>port</strong> accordingly. In our example it is not needed as the default port is already <code>6379</code>.</li>\n<li>Set your preferred <strong>loglevel</strong>.</li>\n<li>Set the <strong>logfile</strong> to <code>/var/log/valkey_6379.log</code>.</li>\n<li>Set the <strong>dir</strong> to <code>/var/valkey/6379</code> (very important step!).</li>\n</ul>\n</li>\n<li><p>Finally, add the new Valkey init script to all the default runlevels using the following command:</p>\n<pre><code>sudo update-rc.d valkey_6379 defaults\n</code></pre>\n</li>\n</ul>\n<p>You are done! Now you can try running your instance with:</p>\n<pre><code>sudo /etc/init.d/valkey_6379 start\n</code></pre>\n<p>Make sure that everything is working as expected:</p>\n<ol>\n<li>Try pinging your instance within a <code>valkey-cli</code> session using the <code>PING</code> command.</li>\n<li>Do a test save with <code>valkey-cli save</code> and check that a dump file is correctly saved to <code>/var/valkey/6379/dump.rdb</code>.</li>\n<li>Check that your Valkey instance is logging to the <code>/var/log/valkey_6379.log</code> file.</li>\n<li>If it&#39;s a new machine where you can try it without problems, make sure that after a reboot everything is still working.</li>\n</ol>\n<h2>Configuring Valkey</h2>\n<p>The above instructions don&#39;t include all of the Valkey configuration parameters that you could change. For example, to use AOF persistence instead of RDB persistence, or to set up replication, and so forth.</p>\n<p>You should also read the example <a href=\"https://github.com/valkey-io/valkey/blob/unstable/valkey.conf\">valkey.conf</a> file, which is heavily annotated to help guide you on making changes. Further details can also be found in the <a href=\"valkey.conf\">configuration article on this site</a>.</p>\n"
      },
      {
        "id": "introduction",
        "topicName": "Introduction",
        "description": "Learn about the Valkey open source project",
        "htmlContent": "<p>Valkey is an open source (BSD licensed), in-memory <strong>data structure store</strong> used as a database, cache, message broker, and streaming engine. Valkey provides <a href=\"data-types\">data structures</a> such as<br><a href=\"strings\">strings</a>, <a href=\"hashes\">hashes</a>, <a href=\"lists\">lists</a>, <a href=\"sets\">sets</a>, <a href=\"sorted-sets\">sorted sets</a> with range queries, <a href=\"bitmaps\">bitmaps</a>, <a href=\"hyperloglogs\">hyperloglogs</a>, <a href=\"geospatial\">geospatial indexes</a>, and <a href=\"streams-intro\">streams</a>. Valkey has built-in <a href=\"replication\">replication</a>, <a href=\"eval-intro\">Lua scripting</a>, <a href=\"lru-cache\">LRU eviction</a>, <a href=\"transactions\">transactions</a>, and different levels of <a href=\"persistence\">on-disk persistence</a>, and provides high availability via <a href=\"sentinel\">Valkey Sentinel</a> and automatic partitioning with <a href=\"cluster-tutorial\">Valkey Cluster</a>.</p>\n<p>You can run <strong>atomic operations</strong><br>on these types, like <a href=\"../commands/append\">appending to a string</a>;<br><a href=\"../commands/hincrby\">incrementing the value in a hash</a>; <a href=\"../commands/lpush\">pushing an element to a<br>list</a>; <a href=\"../commands/sinter\">computing set intersection</a>,<br><a href=\"../commands/sunion\">union</a> and <a href=\"../commands/sdiff\">difference</a>;<br>or <a href=\"../commands/zrange\">getting the member with highest ranking in a sorted set</a>.</p>\n<p>To achieve top performance, Valkey works with an<br><strong>in-memory dataset</strong>. Depending on your use case, Valkey can persist your data either<br>by periodically <a href=\"persistence#snapshotting\">dumping the dataset to disk</a><br>or by <a href=\"persistence#append-only-file\">appending each command to a disk-based log</a>. You can also disable persistence if you just need a feature-rich, networked, in-memory cache.</p>\n<p>Valkey supports <a href=\"replication\">asynchronous replication</a>, with fast non-blocking synchronization and auto-reconnection with partial resynchronization on net split.</p>\n<p>Valkey also includes:</p>\n<ul>\n<li><a href=\"transactions\">Transactions</a></li>\n<li><a href=\"pubsub\">Pub/Sub</a></li>\n<li><a href=\"../commands/eval\">Lua scripting</a></li>\n<li><a href=\"../commands/expire\">Keys with a limited time-to-live</a></li>\n<li><a href=\"lru-cache\">LRU eviction of keys</a></li>\n<li><a href=\"sentinel\">Automatic failover</a></li>\n</ul>\n<p>You can use Valkey from most programming languages. See <a href=\"../clients/\">clients</a>.</p>\n<p>Valkey is written in <strong>ANSI C 11</strong> with Atomics and a few GCC/Clang built-ins like <code>__builtin_clz()</code>.<br>It works on most POSIX systems like Linux, *BSD and MacOS, without external dependencies.<br>Linux and MacOS are the two operating systems where Valkey is developed and tested the most, and we <strong>recommend using Linux for deployment</strong>.<br>Valkey may work on Solaris-derived systems like Illumos, but support is <em>best effort</em>.<br>Supported hardware includes x86-64 (AKA amd64), x86 (32-bit) and AArch64 (64-bit ARM).<br>It is also known to work on IBM z/Architecture like s390x and builds for this system are available from the Fedora distro.<br>There is no official support for Windows builds.</p>\n"
      },
      {
        "id": "license",
        "topicName": "License",
        "description": "License and trademark information\n",
        "htmlContent": "<ul>\n<li><p>Valkey is <strong>open source software</strong> released under the terms of the <strong>three clause BSD license</strong>. Most of the Valkey source code was written by Salvatore Sanfilippo and Pieter Noordhuis. A list of other contributors can be found in the git history.</p>\n</li>\n<li><p>Valkey is based on the formerly open source Redis, as it was before the<br>license of Redis was changed to one that is not open source.<br>Read more about this in the <a href=\"history\">History of Valkey</a>.<br>Redis is a trademark of Redis Ltd. Whenever we use the name Redis in the<br>Valkey documentation, we&#39;re trying our best to use it in accordance with the<br><a href=\"https://redis.com/legal/trademark-guidelines/\">Redis Trademark Guidelines</a>.</p>\n</li>\n</ul>\n<h2>Licences:</h2>\n<h3>Three clause BSD license</h3>\n<p>Every file in the Valkey distribution, with the exception of third party files<br>specified in the list below, is provided under the following license:</p>\n<pre><code>Redistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice,\n  this list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright\n  notice, this list of conditions and the following disclaimer in the\n  documentation and/or other materials provided with the distribution.\n\n* Neither the name of the copyright holder nor the names of its contributors\n  may be used to endorse or promote products derived from this software\n  without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\nARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\nLIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\nCONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\nSUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\nINTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\nCONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\nARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\nPOSSIBILITY OF SUCH DAMAGE.\n</code></pre>\n<p>Files in the Valkey distribution that were originally created for Redis when<br>Redis was still under the three-clause BSD license contain the following license<br>(which differs from the above text only in one occurrence of &quot;Redis&quot; in the 3rd<br>clause):</p>\n<pre><code>Redistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice,\n  this list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright\n  notice, this list of conditions and the following disclaimer in the\n  documentation and/or other materials provided with the distribution.\n\n* Neither the name of Redis nor the names of its contributors may be used\n  to endorse or promote products derived from this software without\n  specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\nARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\nLIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\nCONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\nSUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\nINTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\nCONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\nARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\nPOSSIBILITY OF SUCH DAMAGE.\n</code></pre>\n<h3>Third-party files and licenses</h3>\n<p>Valkey uses source code from third parties. All this code contains a BSD or BSD-compatible license. The following is a list of third-party files and information about their copyright.</p>\n<ul>\n<li><p>Valkey uses the <a href=\"http://oldhome.schmorp.de/marc/liblzf.html\">LHF compression library</a>. LibLZF is copyright Marc Alexander Lehmann and is released under the terms of the <strong>two-clause BSD license</strong>.</p>\n</li>\n<li><p>Valkey uses the <code>sha1.c</code> file that is copyright by Steve Reid and released under the <strong>public domain</strong>. This file is extremely popular and used among open source and proprietary code.</p>\n</li>\n<li><p>When compiled on Linux, Valkey uses the <a href=\"https://github.com/jemalloc/jemalloc\">Jemalloc allocator</a>, which is copyrighted by Jason Evans, Mozilla Foundation, and Facebook, Inc and released under the <strong>two-clause BSD license</strong>.</p>\n</li>\n<li><p>Inside Jemalloc, the file <code>pprof</code> is copyrighted by Google Inc. and released under the <strong>three-clause BSD license</strong>.</p>\n</li>\n<li><p>Inside Jemalloc the files <code>inttypes.h</code>, <code>stdbool.h</code>, <code>stdint.h</code>, <code>strings.h</code> under the <code>msvc_compat</code> directory are copyright Alexander Chemeris and released under the <strong>three-clause BSD license</strong>.</p>\n</li>\n<li><p>The libraries <strong>hiredis</strong> and <strong>linenoise</strong> also included inside the Valkey distribution are copyright Salvatore Sanfilippo and Pieter Noordhuis and released under the terms respectively of the <strong>three-clause BSD license</strong> and <strong>two-clause BSD license</strong>.</p>\n</li>\n</ul>\n"
      },
      {
        "id": "quickstart",
        "topicName": "Quick start guide",
        "description": "Understand how to use basic Valkey data types",
        "htmlContent": "<p>This quick start guide shows you how to:</p>\n<ol>\n<li>Get started with Valkey </li>\n<li>Store data under a key in Valkey</li>\n<li>Retrieve data with a key from Valkey</li>\n<li>Scan the keyspace for keys that match a specific pattern</li>\n</ol>\n<p>The examples in this article refer to a simple bicycle inventory.</p>\n<h2>Setup</h2>\n<p>See the <a href=\"installation\">installation guides</a> to install Valkey on your local machine.</p>\n<h2>Connect</h2>\n<p>The first step is to connect to Valkey. There are client connectors for <a href=\"../clients/\">most programming languages</a>.<br>You can also connect using <a href=\"cli\">valkey-cli</a>, the command line interface.<br>The following example shows how to connect to a Valkey server that runs on localhost (<code>-h 127.0.0.1</code>) and listens on the default port (<code>-p 6379</code>):</p>\n<pre><code class=\"language-sh\">$ valkey-cli -h 127.0.0.1 -p 6379\n</code></pre>\n<h2>Store and retrieve data</h2>\n<p>Valkey is a remote dictionary server. You can use the same data types as in your local programming environment but on the server side within Valkey.</p>\n<p>Similar to byte arrays, Strings store sequences of bytes, including text, serialized objects, counter values, and binary arrays. The following example shows you how to set and get a string value:</p>\n<pre><code>127.0.0.1:6379&gt; SET bike:1 &quot;Process 134&quot;\nOK\n127.0.0.1:6379&gt; GET bike:1\n&quot;Process 134&quot;\n</code></pre>\n<p>Hashes are the equivalent of dictionaries (dicts or hash maps). Among other things, you can use hashes to represent plain objects and to store groupings of counters. The following example explains how to set and access field values of an object:</p>\n<pre><code>127.0.0.1:6379&gt; HSET bike:1 model Deimos brand Ergonom type &#39;Enduro bikes&#39; price 4972\n(integer) 4\n127.0.0.1:6379&gt; HGET bike:1 model\n&quot;Deimos&quot;\n127.0.0.1:6379&gt; HGET bike:1 price\n&quot;4972&quot;\n127.0.0.1:6379&gt; HGETALL bike:1\n1) &quot;model&quot;\n2) &quot;Deimos&quot;\n3) &quot;brand&quot;\n4) &quot;Ergonom&quot;\n5) &quot;type&quot;\n6) &quot;Enduro bikes&quot;\n7) &quot;price&quot;\n8) &quot;4972&quot;\n</code></pre>\n<p>You can get a complete overview of available data types in this documentation site&#39;s <a href=\"data-types\">data types section</a>. Each data type has commands allowing you to manipulate or retrieve data. The <a href=\"../commands/\">commands reference</a> provides a sophisticated explanation.</p>\n<h2>Scan the keyspace</h2>\n<p>Each item within Valkey has a unique key. All items live within the Valkey <a href=\"keyspace\">keyspace</a>. You can scan the Valkey keyspace via the <a href=\"../commands/scan\">SCAN command</a>. Here is an example that scans for the first 100 keys that have the prefix <code>bike:</code>:</p>\n<pre><code>127.0.0.1:6379&gt; SCAN 0 MATCH &quot;bike:*&quot; COUNT 100\n1) &quot;0&quot;\n2) 1) &quot;bike:4&quot;\n   2) &quot;bike:3&quot;\n   3) &quot;bike:5&quot;\n   4) &quot;bike:1&quot;\n   5) &quot;bike:2&quot;\n</code></pre>\n<p><a href=\"../commands/scan\">SCAN</a> returns a cursor position, allowing you to scan iteratively for the next batch of keys until you reach the cursor value 0.</p>\n"
      }
    ]
  },
  {
    "title": "CONFIGURATION & SETUP",
    "items": [
      {
        "id": "acl",
        "topicName": "ACL",
        "description": "Valkey Access Control List",
        "htmlContent": "<p>The Valkey ACL, short for Access Control List, is a feature that allows certain connections to be limited in terms of the commands that can be executed and the keys that can be accessed.<br>The way it works is that, after connecting, a client is required to provide a username and a valid password to authenticate.<br>If authentication succeeded, the connection is associated with a given user and the limits the user has.<br>Valkey can be configured so that new connections are already authenticated with a &quot;default&quot; user (this is the default configuration).<br>Configuring the default user has, as a side effect, the ability to provide only a specific subset of functionalities to connections that are not explicitly authenticated.</p>\n<p>The standard way to authenticate is the two-argument form of the <code>AUTH</code> command:</p>\n<pre><code>AUTH &lt;username&gt; &lt;password&gt;\n</code></pre>\n<p>If the password is valid matches, the connection will be authenticated to the user with the name <code>&lt;username&gt;</code>.</p>\n<p>When the single argument form of the command is used, where only the password is specified, it is assumed that the implicit username is &quot;default&quot;.</p>\n<pre><code>AUTH &lt;password&gt;\n</code></pre>\n<p>This form authenticates against the &quot;default&quot; user&#39;s password, either set by ACLs or by setting <code>requirepass</code>.</p>\n<h2>When ACLs are useful</h2>\n<p>Before using ACLs, you may want to ask yourself what&#39;s the goal you want to<br>accomplish by implementing this layer of protection. Normally there are<br>two main goals that are well served by ACLs:</p>\n<ol>\n<li>You want to improve security by restricting the access to commands and keys, so that untrusted clients have no access and trusted clients have just the minimum access level to the database in order to perform the work needed. For instance, certain clients may just be able to execute read only commands.</li>\n<li>You want to improve operational safety, so that processes or humans accessing Valkey are not allowed to damage the data or the configuration due to software errors or manual mistakes. For instance, there is no reason for a worker that fetches delayed jobs from Valkey to be able to call the <code>FLUSHALL</code> command.</li>\n</ol>\n<p>Another typical usage of ACLs is related to managed Valkey instances. Valkey is<br>often provided as a managed service both by internal company teams that handle<br>the Valkey infrastructure for the other internal customers they have, or is<br>provided in a software-as-a-service setup by cloud providers. In both<br>setups, we want to be sure that configuration commands are excluded for the<br>customers.</p>\n<h2>Configure ACLs with the ACL command</h2>\n<p>ACLs are defined using a DSL (domain specific language) that describes what<br>a given user is allowed to do. Such rules are always implemented from the<br>first to the last, left-to-right, because sometimes the order of the rules is<br>important to understand what the user is really able to do.</p>\n<p>By default there is a single user defined, called <em>default</em>. We<br>can use the <code>ACL LIST</code> command in order to check the currently active ACLs<br>and verify what the configuration of a freshly started, defaults-configured<br>Valkey instance is:</p>\n<pre><code>&gt; ACL LIST\n1) &quot;user default on nopass ~* &amp;* +@all&quot;\n</code></pre>\n<p>The command above reports the list of users in the same format that is<br>used in the Valkey configuration files, by translating the current ACLs set<br>for the users back into their description.</p>\n<p>The first two words in each line are &quot;user&quot; followed by the username. The<br>next words are ACL rules that describe different things. We&#39;ll show how the rules work in detail, but for now it is enough to say that the default<br>user is configured to be active (on), to require no password (nopass), to<br>access every possible key (<code>~*</code>) and Pub/Sub channel (<code>&amp;*</code>), and be able to<br>call every possible command (<code>+@all</code>).</p>\n<p>Also, in the special case of the default user, having the <em>nopass</em> rule means<br>that new connections are automatically authenticated with the default user<br>without any explicit <code>AUTH</code> call needed.</p>\n<h2>ACL rules</h2>\n<p>The following is the list of valid ACL rules. Certain rules are just<br>single words that are used in order to activate or remove a flag, or to<br>perform a given change to the user ACL. Other rules are char prefixes that<br>are concatenated with command or category names, key patterns, and<br>so forth.</p>\n<p>Enable and disallow users:</p>\n<ul>\n<li><code>on</code>: Enable the user: it is possible to authenticate as this user.</li>\n<li><code>off</code>: Disallow the user: it&#39;s no longer possible to authenticate with this user; however, previously authenticated connections will still work. Note that if the default user is flagged as <em>off</em>, new connections will start as not authenticated and will require the user to send <code>AUTH</code> or <code>HELLO</code> with the AUTH option in order to authenticate in some way, regardless of the default user configuration.</li>\n</ul>\n<p>Allow and disallow commands:</p>\n<ul>\n<li><code>+&lt;command&gt;</code>: Add the command to the list of commands the user can call. Can be used with <code>|</code> for allowing subcommands (e.g &quot;+config|get&quot;).</li>\n<li><code>-&lt;command&gt;</code>: Remove the command to the list of commands the user can call. Starting Valkey 7.0, it can be used with <code>|</code> for blocking subcommands (e.g &quot;-config|set&quot;).</li>\n<li><code>+@&lt;category&gt;</code>: Add all the commands in such category to be called by the user, with valid categories being like @admin, @set, @sortedset, ... and so forth, see the full list by calling the <code>ACL CAT</code> command. The special category @all means all the commands, both the ones currently present in the server, and the ones that will be loaded in the future via modules.</li>\n<li><code>-@&lt;category&gt;</code>: Like <code>+@&lt;category&gt;</code> but removes the commands from the list of commands the client can call.</li>\n<li><code>+&lt;command&gt;|first-arg</code>: Allow a specific first argument of an otherwise disabled command. It is only supported on commands with no sub-commands, and is not allowed as negative form like -SELECT|1, only additive starting with &quot;+&quot;. This feature is deprecated and may be removed in the future.</li>\n<li><code>allcommands</code>: Alias for +@all. Note that it implies the ability to execute all the future commands loaded via the modules system.</li>\n<li><code>nocommands</code>: Alias for -@all.</li>\n</ul>\n<p>Allow and disallow certain keys and key permissions:</p>\n<ul>\n<li><code>~&lt;pattern&gt;</code>: Add a pattern of keys that can be mentioned as part of commands. For instance <code>~*</code> allows all the keys. The pattern is a glob-style pattern like the one of <code>KEYS</code>. It is possible to specify multiple patterns.</li>\n<li><code>%R~&lt;pattern&gt;</code>: Add the specified read key pattern. This behaves similar to the regular key pattern but only grants permission to read from keys that match the given pattern. See <a href=\"#key-permissions\">key permissions</a> for more information.</li>\n<li><code>%W~&lt;pattern&gt;</code>: Add the specified write key pattern. This behaves similar to the regular key pattern but only grants permission to write to keys that match the given pattern. See <a href=\"#key-permissions\">key permissions</a> for more information.</li>\n<li><code>%RW~&lt;pattern&gt;</code>: Alias for <code>~&lt;pattern&gt;</code>. </li>\n<li><code>allkeys</code>: Alias for <code>~*</code>.</li>\n<li><code>resetkeys</code>: Flush the list of allowed keys patterns. For instance the ACL <code>~foo:* ~bar:* resetkeys ~objects:*</code>, will only allow the client to access keys that match the pattern <code>objects:*</code>.</li>\n</ul>\n<p>Allow and disallow Pub/Sub channels:</p>\n<ul>\n<li><code>&amp;&lt;pattern&gt;</code>: Add a glob style pattern of Pub/Sub channels that can be accessed by the user. It is possible to specify multiple channel patterns. Note that pattern matching is done only for channels mentioned by <code>PUBLISH</code> and <code>SUBSCRIBE</code>, whereas <code>PSUBSCRIBE</code> requires a literal match between its channel patterns and those allowed for user.</li>\n<li><code>allchannels</code>: Alias for <code>&amp;*</code> that allows the user to access all Pub/Sub channels.</li>\n<li><code>resetchannels</code>: Flush the list of allowed channel patterns and disconnect the user&#39;s Pub/Sub clients if these are no longer able to access their respective channels and/or channel patterns.</li>\n</ul>\n<p>Configure valid passwords for the user:</p>\n<ul>\n<li><code>&gt;&lt;password&gt;</code>: Add this password to the list of valid passwords for the user. For example <code>&gt;mypass</code> will add &quot;mypass&quot; to the list of valid passwords.  This directive clears the <em>nopass</em> flag (see later). Every user can have any number of passwords.</li>\n<li><code>&lt;&lt;password&gt;</code>: Remove this password from the list of valid passwords. Emits an error in case the password you are trying to remove is actually not set.</li>\n<li><code>#&lt;hash&gt;</code>: Add this SHA-256 hash value to the list of valid passwords for the user. This hash value will be compared to the hash of a password entered for an ACL user. This allows users to store hashes in the <code>acl.conf</code> file rather than storing cleartext passwords. Only SHA-256 hash values are accepted as the password hash must be 64 characters and only contain lowercase hexadecimal characters.</li>\n<li><code>!&lt;hash&gt;</code>: Remove this hash value from the list of valid passwords. This is useful when you do not know the password specified by the hash value but would like to remove the password from the user.</li>\n<li><code>nopass</code>: All the set passwords of the user are removed, and the user is flagged as requiring no password: it means that every password will work against this user. If this directive is used for the default user, every new connection will be immediately authenticated with the default user without any explicit AUTH command required. Note that the <em>resetpass</em> directive will clear this condition.</li>\n<li><code>resetpass</code>: Flushes the list of allowed passwords and removes the <em>nopass</em> status. After <em>resetpass</em>, the user has no associated passwords and there is no way to authenticate without adding some password (or setting it as <em>nopass</em> later).</li>\n</ul>\n<p><em>Note: if a user is not flagged with nopass and has no list of valid passwords, that user is effectively impossible to use because there will be no way to log in as that user.</em></p>\n<p>Configure selectors for the user:</p>\n<ul>\n<li><code>(&lt;rule list&gt;)</code>: Create a new selector to match rules against. Selectors are evaluated after the user permissions, and are evaluated according to the order they are defined. If a command matches either the user permissions or any selector, it is allowed. See <a href=\"#selectors\">selectors</a> for more information.</li>\n<li><code>clearselectors</code>: Delete all of the selectors attached to the user.</li>\n</ul>\n<p>Reset the user:</p>\n<ul>\n<li><code>reset</code> Performs the following actions: resetpass, resetkeys, resetchannels, allchannels (if acl-pubsub-default is set), off, clearselectors, -@all. The user returns to the same state it had immediately after its creation.</li>\n</ul>\n<h2>Create and edit user ACLs with the ACL SETUSER command</h2>\n<p>Users can be created and modified in two main ways:</p>\n<ol>\n<li>Using the ACL command and its <code>ACL SETUSER</code> subcommand.</li>\n<li>Modifying the server configuration, where users can be defined, and restarting the server. With an <em>external ACL file</em>, just call <code>ACL LOAD</code>.</li>\n</ol>\n<p>In this section we&#39;ll learn how to define users using the <code>ACL</code> command.<br>With such knowledge, it will be trivial to do the same things via the<br>configuration files. Defining users in the configuration deserves its own<br>section and will be discussed later separately.</p>\n<p>To start, try the simplest <code>ACL SETUSER</code> command call:</p>\n<pre><code>&gt; ACL SETUSER alice\nOK\n</code></pre>\n<p>The <code>ACL SETUSER</code> command takes the username and a list of ACL rules to apply<br>to the user. However the above example did not specify any rule at all.<br>This will just create the user if it did not exist, using the defaults for new<br>users. If the user already exists, the command above will do nothing at all.</p>\n<p>Check the default user status:</p>\n<pre><code>&gt; ACL LIST\n1) &quot;user alice off resetchannels -@all&quot;\n2) &quot;user default on nopass ~* &amp;* +@all&quot;\n</code></pre>\n<p>The new user &quot;alice&quot; is:</p>\n<ul>\n<li>In the off status, so <code>AUTH</code> will not work for the user &quot;alice&quot;.</li>\n<li>The user also has no passwords set.</li>\n<li>Cannot access any command. Note that the user is created by default without the ability to access any command, so the <code>-@all</code> in the output above could be omitted; however, <code>ACL LIST</code> attempts to be explicit rather than implicit.</li>\n<li>There are no key patterns that the user can access.</li>\n<li>There are no Pub/Sub channels that the user can access.</li>\n</ul>\n<p>Such user is completely useless. Let&#39;s try to define the user so that<br>it is active, has a password, and can access with only the <code>GET</code> command<br>to key names starting with the string &quot;cached:&quot;.</p>\n<pre><code>&gt; ACL SETUSER alice on &gt;p1pp0 ~cached:* +get\nOK\n</code></pre>\n<p>Now the user can do something, but will refuse to do other things:</p>\n<pre><code>&gt; AUTH alice p1pp0\nOK\n&gt; GET foo\n(error) NOPERM this user has no permissions to access one of the keys used as arguments\n&gt; GET cached:1234\n(nil)\n&gt; SET cached:1234 zap\n(error) NOPERM this user has no permissions to run the &#39;set&#39; command\n</code></pre>\n<p>Things are working as expected. In order to inspect the configuration of the<br>user alice (remember that user names are case sensitive), it is possible to<br>use an alternative to <code>ACL LIST</code> which is designed to be more suitable for<br>computers to read, while <code>ACL GETUSER</code> is more human readable.</p>\n<pre><code>&gt; ACL GETUSER alice\n1) &quot;flags&quot;\n2) 1) &quot;on&quot;\n3) &quot;passwords&quot;\n4) 1) &quot;2d9c75...&quot;\n5) &quot;commands&quot;\n6) &quot;-@all +get&quot;\n7) &quot;keys&quot;\n8) &quot;~cached:*&quot;\n9) &quot;channels&quot;\n10) &quot;&quot;\n11) &quot;selectors&quot;\n12) (empty array)\n</code></pre>\n<p>The <code>ACL GETUSER</code> returns a field-value array that describes the user in more parsable terms. The output includes the set of flags, a list of key patterns, passwords, and so forth. The output is probably more readable if we use RESP3, so that it is returned as a map reply:</p>\n<pre><code>&gt; ACL GETUSER alice\n1# &quot;flags&quot; =&gt; 1~ &quot;on&quot;\n2# &quot;passwords&quot; =&gt; 1) &quot;2d9c75273d72b32df726fb545c8a4edc719f0a95a6fd993950b10c474ad9c927&quot;\n3# &quot;commands&quot; =&gt; &quot;-@all +get&quot;\n4# &quot;keys&quot; =&gt; &quot;~cached:*&quot;\n5# &quot;channels&quot; =&gt; &quot;&quot;\n6# &quot;selectors&quot; =&gt; (empty array)\n</code></pre>\n<p><em>Note: from now on, we&#39;ll continue using the Valkey default protocol, version 2</em></p>\n<p>Using another <code>ACL SETUSER</code> command (from a different user, because alice cannot run the <code>ACL</code> command), we can add multiple patterns to the user:</p>\n<pre><code>&gt; ACL SETUSER alice ~objects:* ~items:* ~public:*\nOK\n&gt; ACL LIST\n1) &quot;user alice on #2d9c75... ~cached:* ~objects:* ~items:* ~public:* resetchannels -@all +get&quot;\n2) &quot;user default on nopass ~* &amp;* +@all&quot;\n</code></pre>\n<p>The user representation in memory is now as we expect it to be.</p>\n<h2>Multiple calls to ACL SETUSER</h2>\n<p>It is very important to understand what happens when <code>ACL SETUSER</code> is called<br>multiple times. What is critical to know is that every <code>ACL SETUSER</code> call will<br>NOT reset the user, but will just apply the ACL rules to the existing user.<br>The user is reset only if it was not known before. In that case, a brand new<br>user is created with zeroed-ACLs. The user cannot do anything, is<br>disallowed, has no passwords, and so forth. This is the best default for safety.</p>\n<p>However later calls will just modify the user incrementally. For instance,<br>the following sequence:</p>\n<pre><code>&gt; ACL SETUSER myuser +set\nOK\n&gt; ACL SETUSER myuser +get\nOK\n</code></pre>\n<p>Will result in myuser being able to call both <code>GET</code> and <code>SET</code>:</p>\n<pre><code>&gt; ACL LIST\n1) &quot;user default on nopass ~* &amp;* +@all&quot;\n2) &quot;user myuser off resetchannels -@all +get +set&quot;\n</code></pre>\n<h2>Command categories</h2>\n<p>Setting user ACLs by specifying all the commands one after the other is<br>really annoying, so instead we do things like this:</p>\n<pre><code>&gt; ACL SETUSER antirez on +@all -@dangerous &gt;42a979... ~*\n</code></pre>\n<p>By saying +@all and -@dangerous, we included all the commands and later removed<br>all the commands that are tagged as dangerous inside the Valkey command table.<br>Note that command categories <strong>never include modules commands</strong> with<br>the exception of +@all. If you say +@all, all the commands can be executed by<br>the user, even future commands loaded via the modules system. However if you<br>use the ACL rule +@read or any other, the modules commands are always<br>excluded. This is very important because you should just trust the Valkey<br>internal command table. Modules may expose dangerous things and in<br>the case of an ACL that is just additive, that is, in the form of <code>+@all -...</code><br>You should be absolutely sure that you&#39;ll never include what you did not mean<br>to.</p>\n<p>The following is a list of command categories and their meanings:</p>\n<ul>\n<li><strong>admin</strong> - Administrative commands. Normal applications will never need to use<br>these. Includes <code>REPLICAOF</code>, <code>CONFIG</code>, <code>DEBUG</code>, <code>SAVE</code>, <code>MONITOR</code>, <code>ACL</code>, <code>SHUTDOWN</code>, etc.</li>\n<li><strong>bitmap</strong> - Data type: bitmaps related.</li>\n<li><strong>blocking</strong> - Potentially blocking the connection until released by another<br>command.</li>\n<li><strong>connection</strong> - Commands affecting the connection or other connections.<br>This includes <code>AUTH</code>, <code>SELECT</code>, <code>COMMAND</code>, <code>CLIENT</code>, <code>ECHO</code>, <code>PING</code>, etc.</li>\n<li><strong>dangerous</strong> - Potentially dangerous commands (each should be considered with care for<br>various reasons). This includes <code>FLUSHALL</code>, <code>MIGRATE</code>, <code>RESTORE</code>, <code>SORT</code>, <code>KEYS</code>,<br><code>CLIENT</code>, <code>DEBUG</code>, <code>INFO</code>, <code>CONFIG</code>, <code>SAVE</code>, <code>REPLICAOF</code>, etc.</li>\n<li><strong>geo</strong> - Data type: geospatial indexes related.</li>\n<li><strong>hash</strong> - Data type: hashes related.</li>\n<li><strong>hyperloglog</strong> - Data type: hyperloglog related.</li>\n<li><strong>fast</strong> - Fast O(1) commands. May loop on the number of arguments, but not the<br>number of elements in the key.</li>\n<li><strong>keyspace</strong> - Writing or reading from keys, databases, or their metadata<br>in a type agnostic way. Includes <code>DEL</code>, <code>RESTORE</code>, <code>DUMP</code>, <code>RENAME</code>, <code>EXISTS</code>, <code>DBSIZE</code>,<br><code>KEYS</code>, <code>EXPIRE</code>, <code>TTL</code>, <code>FLUSHALL</code>, etc. Commands that may modify the keyspace,<br>key, or metadata will also have the <code>write</code> category. Commands that only read<br>the keyspace, key, or metadata will have the <code>read</code> category.</li>\n<li><strong>list</strong> - Data type: lists related.</li>\n<li><strong>pubsub</strong> - PubSub-related commands.</li>\n<li><strong>read</strong> - Reading from keys (values or metadata). Note that commands that don&#39;t<br>interact with keys, will not have either <code>read</code> or <code>write</code>.</li>\n<li><strong>scripting</strong> - Scripting related.</li>\n<li><strong>set</strong> - Data type: sets related.</li>\n<li><strong>sortedset</strong> - Data type: sorted sets related.</li>\n<li><strong>slow</strong> - All commands that are not <code>fast</code>.</li>\n<li><strong>stream</strong> - Data type: streams related.</li>\n<li><strong>string</strong> - Data type: strings related.</li>\n<li><strong>transaction</strong> - <code>WATCH</code> / <code>MULTI</code> / <code>EXEC</code> related commands.</li>\n<li><strong>write</strong> - Writing to keys (values or metadata).</li>\n</ul>\n<p>Valkey can also show you a list of all categories and the exact commands each category includes using the Valkey <code>ACL CAT</code> command. It can be used in two forms:</p>\n<pre><code>ACL CAT -- Will just list all the categories available\nACL CAT &lt;category-name&gt; -- Will list all the commands inside the category\n</code></pre>\n<p>Examples:</p>\n<pre><code> &gt; ACL CAT\n 1) &quot;keyspace&quot;\n 2) &quot;read&quot;\n 3) &quot;write&quot;\n 4) &quot;set&quot;\n 5) &quot;sortedset&quot;\n 6) &quot;list&quot;\n 7) &quot;hash&quot;\n 8) &quot;string&quot;\n 9) &quot;bitmap&quot;\n10) &quot;hyperloglog&quot;\n11) &quot;geo&quot;\n12) &quot;stream&quot;\n13) &quot;pubsub&quot;\n14) &quot;admin&quot;\n15) &quot;fast&quot;\n16) &quot;slow&quot;\n17) &quot;blocking&quot;\n18) &quot;dangerous&quot;\n19) &quot;connection&quot;\n20) &quot;transaction&quot;\n21) &quot;scripting&quot;\n</code></pre>\n<p>As you can see, so far there are 21 distinct categories. Now let&#39;s check what<br>command is part of the <em>geo</em> category:</p>\n<pre><code> &gt; ACL CAT geo\n 1) &quot;geohash&quot;\n 2) &quot;georadius_ro&quot;\n 3) &quot;georadiusbymember&quot;\n 4) &quot;geopos&quot;\n 5) &quot;geoadd&quot;\n 6) &quot;georadiusbymember_ro&quot;\n 7) &quot;geodist&quot;\n 8) &quot;georadius&quot;\n 9) &quot;geosearch&quot;\n10) &quot;geosearchstore&quot;\n</code></pre>\n<p>Note that commands may be part of multiple categories. For example, an<br>ACL rule like <code>+@geo -@read</code> will result in certain geo commands to be<br>excluded because they are read-only commands.</p>\n<h2>Allow/block subcommands</h2>\n<p>Subcommands can be allowed/blocked just like other<br>commands (by using the separator <code>|</code> between the command and subcommand, for<br>example: <code>+config|get</code> or <code>-config|set</code>)</p>\n<p>That is true for all commands except DEBUG. In order to allow/block specific DEBUG subcommands, see the next section.</p>\n<h2>Allow the first-arg of a blocked command</h2>\n<p><strong>Note: This feature is deprecated and may be removed in the future.</strong></p>\n<p>Sometimes the ability to exclude or include a command or a subcommand as a whole is not enough.<br>Many deployments may not be happy providing the ability to execute a <code>SELECT</code> for any DB, but may<br>still want to be able to run <code>SELECT 0</code>.</p>\n<p>In such case we could alter the ACL of a user in the following way:</p>\n<pre><code>ACL SETUSER myuser -select +select|0\n</code></pre>\n<p>First, remove the <code>SELECT</code> command and then add the allowed<br>first-arg. Note that <strong>it is not possible to do the reverse</strong> since first-args<br>can be only added, not excluded. It is safer to specify all the first-args<br>that are valid for some user since it is possible that<br>new first-args may be added in the future.</p>\n<p>Another example:</p>\n<pre><code>ACL SETUSER myuser -debug +debug|digest\n</code></pre>\n<p>Note that first-arg matching may add some performance penalty; however, it is hard to measure even with synthetic benchmarks. The<br>additional CPU cost is only paid when such commands are called, and not when<br>other commands are called.</p>\n<p>It is possible to use this mechanism in order to allow subcommands in Valkey<br>versions prior to 7.0 (see above section).</p>\n<h2>+@all VS -@all</h2>\n<p>In the previous section, it was observed how it is possible to define command<br>ACLs based on adding/removing single commands.</p>\n<h2>Selectors</h2>\n<p>Valkey supports adding multiple sets of rules that are evaluated independently of each other.<br>These secondary sets of permissions are called selectors and added by wrapping a set of rules within parentheses.<br>In order to execute a command, either the root permissions (rules defined outside of parenthesis) or any of the selectors (rules defined inside parenthesis) must match the given command.<br>Internally, the root permissions are checked first followed by selectors in the order they were added.</p>\n<p>For example, consider a user with the ACL rules <code>+GET ~key1 (+SET ~key2)</code>.<br>This user is able to execute <code>GET key1</code> and <code>SET key2 hello</code>, but not <code>GET key2</code> or <code>SET key1 world</code>.</p>\n<p>Unlike the user&#39;s root permissions, selectors cannot be modified after they are added.<br>Instead, selectors can be removed with the <code>clearselectors</code> keyword, which removes all of the added selectors.<br>Note that <code>clearselectors</code> does not remove the root permissions.</p>\n<h2>Key permissions</h2>\n<p>key patterns can also be used to define how a command is able to touch a key.<br>This is achieved through rules that define key permissions.<br>The key permission rules take the form of <code>%(&lt;permission&gt;)~&lt;pattern&gt;</code>.<br>Permissions are defined as individual characters that map to the following key permissions:</p>\n<ul>\n<li>W (Write): The data stored within the key may be updated or deleted. </li>\n<li>R (Read): User supplied data from the key is processed, copied or returned. Note that this does not include metadata such as size information (example <code>STRLEN</code>), type information (example <code>TYPE</code>) or information about whether a value exists within a collection (example <code>SISMEMBER</code>).</li>\n</ul>\n<p>Permissions can be composed together by specifying multiple characters.<br>Specifying the permission as &#39;RW&#39; is considered full access and is analogous to just passing in <code>~&lt;pattern&gt;</code>.</p>\n<p>For a concrete example, consider a user with ACL rules <code>+@all ~app1:* (+@read ~app2:*)</code>.<br>This user has full access on <code>app1:*</code> and readonly access on <code>app2:*</code>.<br>However, some commands support reading data from one key, doing some transformation, and storing it into another key.<br>One such command is the <code>COPY</code> command, which copies the data from the source key into the destination key.<br>The example set of ACL rules is unable to handle a request copying data from <code>app2:user</code> into <code>app1:user</code>, since neither the root permission nor the selector fully matches the command.<br>However, using key selectors you can define a set of ACL rules that can handle this request <code>+@all ~app1:* %R~app2:*</code>.<br>The first pattern is able to match <code>app1:user</code> and the second pattern is able to match <code>app2:user</code>.</p>\n<p>Which type of permission is required for a command is documented through <a href=\"key-specs#logical-operation-flags\">key specifications</a>.<br>The type of permission is based off the keys logical operation flags.<br>The insert, update, and delete flags map to the write key permission.<br>The access flag maps to the read key permission.<br>If the key has no logical operation flags, such as <code>EXISTS</code>, the user still needs either key read or key write permissions to execute the command. </p>\n<p>Note: Side channels to accessing user data are ignored when it comes to evaluating whether read permissions are required to execute a command.<br>This means that some write commands that return metadata about the modified key only require write permission on the key to execute.<br>For example, consider the following two commands:</p>\n<ul>\n<li><code>LPUSH key1 data</code>: modifies &quot;key1&quot; but only returns metadata about it, the size of the list after the push, so the command only requires write permission on &quot;key1&quot; to execute.</li>\n<li><code>LPOP key2</code>: modifies &quot;key2&quot; but also returns data from it, the left most item in the list, so the command requires both read and write permission on &quot;key2&quot; to execute.</li>\n</ul>\n<p>If an application needs to make sure no data is accessed from a key, including side channels, it&#39;s recommended to not provide any access to the key.</p>\n<h2>How passwords are stored internally</h2>\n<p>Valkey internally stores passwords hashed with SHA256. If you set a password<br>and check the output of <code>ACL LIST</code> or <code>ACL GETUSER</code>, you&#39;ll see a long hex<br>string that looks pseudo random. Here is an example, because in the previous<br>examples, for the sake of brevity, the long hex string was trimmed:</p>\n<pre><code>&gt; ACL GETUSER default\n1) &quot;flags&quot;\n2) 1) &quot;on&quot;\n3) &quot;passwords&quot;\n4) 1) &quot;2d9c75273d72b32df726fb545c8a4edc719f0a95a6fd993950b10c474ad9c927&quot;\n5) &quot;commands&quot;\n6) &quot;+@all&quot;\n7) &quot;keys&quot;\n8) &quot;~*&quot;\n9) &quot;channels&quot;\n10) &quot;&amp;*&quot;\n11) &quot;selectors&quot;\n12) (empty array)\n</code></pre>\n<p>Using SHA256 provides the ability to avoid storing the password in clear text<br>while still allowing for a very fast <code>AUTH</code> command, which is a very important<br>feature of Valkey and is coherent with what clients expect from Valkey.</p>\n<p>However ACL <em>passwords</em> are not really passwords. They are shared secrets<br>between the server and the client, because the password is<br>not an authentication token used by a human being. For instance:</p>\n<ul>\n<li>There are no length limits, the password will just be memorized in some client software. There is no human that needs to recall a password in this context.</li>\n<li>The ACL password does not protect any other thing. For example, it will never be the password for some email account.</li>\n<li>Often when you are able to access the hashed password itself, by having full access to the Valkey commands of a given server, or corrupting the system itself, you already have access to what the password is protecting: the Valkey instance stability and the data it contains.</li>\n</ul>\n<p>For this reason, slowing down the password authentication, in order to use an<br>algorithm that uses time and space to make password cracking hard,<br>is a very poor choice. What we suggest instead is to generate strong<br>passwords, so that nobody will be able to crack it using a<br>dictionary or a brute force attack even if they have the hash. To do so, there is a special ACL<br>command <code>ACL GENPASS</code> that generates passwords using the system cryptographic pseudorandom<br>generator:</p>\n<pre><code>&gt; ACL GENPASS\n&quot;dd721260bfe1b3d9601e7fbab36de6d04e2e67b0ef1c53de59d45950db0dd3cc&quot;\n</code></pre>\n<p>The command outputs a 32-byte (256-bit) pseudorandom string converted to a<br>64-byte alphanumerical string. This is long enough to avoid attacks and short<br>enough to be easy to manage, cut &amp; paste, store, and so forth. This is what<br>you should use in order to generate Valkey passwords.</p>\n<h2>Use an external ACL file</h2>\n<p>There are two ways to store users inside the Valkey configuration:</p>\n<ol>\n<li>Users can be specified directly inside the <code>valkey.conf</code> file.</li>\n<li>It is possible to specify an external ACL file.</li>\n</ol>\n<p>The two methods are <em>mutually incompatible</em>, so Valkey will ask you to use one<br>or the other. Specifying users inside <code>valkey.conf</code> is<br>good for simple use cases. When there are multiple users to define, in a<br>complex environment, we recommend you use the ACL file instead.</p>\n<p>The format used inside <code>valkey.conf</code> and in the external ACL file is exactly<br>the same, so it is trivial to switch from one to the other, and is<br>the following:</p>\n<pre><code>user &lt;username&gt; ... acl rules ...\n</code></pre>\n<p>For instance:</p>\n<pre><code>user worker +@list +@connection ~jobs:* on &gt;ffa9203c493aa99\n</code></pre>\n<p>When you want to use an external ACL file, you are required to specify<br>the configuration directive called <code>aclfile</code>, like this:</p>\n<pre><code>aclfile /etc/valkey/users.acl\n</code></pre>\n<p>When you are just specifying a few users directly inside the <code>valkey.conf</code><br>file, you can use <code>CONFIG REWRITE</code> in order to store the new user configuration<br>inside the file by rewriting it.</p>\n<p>The external ACL file however is more powerful. You can do the following:</p>\n<ul>\n<li>Use <code>ACL LOAD</code> if you modified the ACL file manually and you want Valkey to reload the new configuration. Note that this command is able to load the file <em>only if all the users are correctly specified</em>. Otherwise, an error is reported to the user, and the old configuration will remain valid.</li>\n<li>Use <code>ACL SAVE</code> to save the current ACL configuration to the ACL file.</li>\n</ul>\n<p>Note that <code>CONFIG REWRITE</code> does not also trigger <code>ACL SAVE</code>. When you use<br>an ACL file, the configuration and the ACLs are handled separately.</p>\n<h2>ACL rules for Sentinel and Replicas</h2>\n<p>In case you don&#39;t want to provide Valkey replicas and Valkey Sentinel instances<br>full access to your Valkey instances, the following is the set of commands<br>that must be allowed in order for everything to work correctly.</p>\n<p>For Sentinel, allow the user to access the following commands both in the primary and replica instances:</p>\n<ul>\n<li>AUTH, CLIENT, SUBSCRIBE, SCRIPT, PUBLISH, PING, INFO, MULTI, SLAVEOF, CONFIG, CLIENT, EXEC.</li>\n</ul>\n<p>Sentinel does not need to access any key in the database but does use Pub/Sub, so the ACL rule would be the following (note: <code>AUTH</code> is not needed since it is always allowed):</p>\n<pre><code>ACL SETUSER sentinel-user on &gt;somepassword allchannels +multi +slaveof +ping +exec +subscribe +config|rewrite +role +publish +info +client|setname +client|kill +script|kill\n</code></pre>\n<p>Valkey replicas require the following commands to be allowed on the primary instance:</p>\n<ul>\n<li>PSYNC, REPLCONF, PING</li>\n</ul>\n<p>No keys need to be accessed, so this translates to the following rules:</p>\n<pre><code>ACL setuser replica-user on &gt;somepassword +psync +replconf +ping\n</code></pre>\n<p>Note that you don&#39;t need to configure the replicas to allow the primary to be able to execute any set of commands. The primary is always authenticated as the root user from the point of view of replicas.</p>\n"
      },
      {
        "id": "cli",
        "topicName": "CLI",
        "description": "Valkey command line interface\n",
        "htmlContent": "<h2>Usage</h2>\n<p><strong><code>valkey-cli</code></strong> [<em>OPTIONS</em>] [<em>cmd</em> [<em>arg</em>...]]</p>\n<h2>Description</h2>\n<p>The Valkey command line interface is used for administration, troubleshooting and experimenting with Valkey.</p>\n<p>In interactive mode, <code>valkey-cli</code> has basic line editing capabilities to provide a familiar typing experience.</p>\n<p>To launch the program in special modes, you can use several options, including:</p>\n<ul>\n<li>Simulate a replica and print the replication stream it receives from the primary.</li>\n<li>Check the latency of a Valkey server and display statistics. </li>\n<li>Request ASCII-art spectrogram of latency samples and frequencies.</li>\n</ul>\n<p>This topic covers the different aspects of <code>valkey-cli</code>, starting from the simplest and ending with the more advanced features.</p>\n<h2>Options</h2>\n<p><strong><code>-h</code></strong> <em>hostname</em><br>: Server hostname (default: 127.0.0.1).</p>\n<p><strong><code>-p</code></strong> <em>port</em><br>: Server port (default: 6379).</p>\n<p><strong><code>-t</code></strong> <em>timeout</em><br>: Server connection timeout in seconds (decimals allowed).<br>  Default timeout is 0, meaning no limit, depending on the OS.</p>\n<p><strong><code>-s</code></strong> <em>socket</em><br>: Server socket (overrides hostname and port).</p>\n<p><strong><code>-a</code></strong> <em>password</em><br>: Password to use when connecting to the server.<br>  You can also use the <code>REDISCLI_AUTH</code> environment<br>  variable to pass this password more safely.<br>  (If both are used, this argument takes precedence.)</p>\n<p><strong><code>--user</code></strong> <em>username</em><br>: Used to send ACL style &#39;AUTH username pass&#39;. Needs <code>-a</code>.</p>\n<p><strong><code>--pass</code></strong> <em>password</em><br>: Alias of -a for consistency with the new --user option.</p>\n<p><strong><code>--askpass</code></strong><br>: Force user to input password with mask from STDIN.<br>  If this argument is used, <code>-a</code> and the <code>REDISCLI_AUTH</code><br>  environment variable will be ignored.</p>\n<p><strong><code>-u</code></strong> <em>uri</em><br>: Server URI on format <code>valkey://user:password@host:port/dbnum</code>.<br>  User, password and dbnum are optional. For authentication<br>  without a username, use username &#39;default&#39;. For TLS, use<br>  the scheme &#39;valkeys&#39;.</p>\n<p><strong><code>-r</code></strong> <em>repeat</em><br>: Execute specified command N times.</p>\n<p><strong><code>-i</code></strong> <em>interval</em><br>: When <code>-r</code> is used, waits <em>interval</em> seconds per command.<br>  It is possible to specify sub-second times like <code>-i 0.1</code>.<br>  This interval is also used in <code>--scan</code> and <code>--stat</code> per cycle.<br>  and in <code>--bigkeys</code>, <code>--memkeys</code>, and <code>--hotkeys</code> per 100 cycles.</p>\n<p><strong><code>-n</code></strong> <em>db</em><br>: Database number.</p>\n<p><strong><code>-2</code></strong><br>: Start session in RESP2 protocol mode.</p>\n<p><strong><code>-3</code></strong><br>: Start session in RESP3 protocol mode.</p>\n<p><strong><code>-x</code></strong><br>: Read last argument from STDIN (see example below).</p>\n<p><strong><code>-X</code></strong><br>: Read <tag> argument from STDIN (see example below).</p>\n<p><strong><code>-d</code></strong> <em>delimiter</em><br>: Delimiter between response bulks for raw formatting (default: <code>\\n</code>).</p>\n<p><strong><code>-D</code></strong> <em>delimiter</em><br>: Delimiter between responses for raw formatting (default: <code>\\n</code>).</p>\n<p><strong><code>-c</code></strong><br>: Enable cluster mode (follow -ASK and -MOVED redirections).</p>\n<p><strong><code>-e</code></strong><br>: Return exit error code when command execution fails.</p>\n<p><strong><code>-4</code></strong><br>: Prefer IPv4 over IPv6 on DNS lookup.</p>\n<p><strong><code>-6</code></strong><br>: Prefer IPv6 over IPv4 on DNS lookup.&#39;</p>\n<p><strong><code>--tls</code></strong><br>: Establish a secure TLS connection.</p>\n<p><strong><code>--sni</code></strong> <em>host</em><br>: Server name indication for TLS.</p>\n<p><strong><code>--cacert</code></strong> <em>file</em><br>: CA Certificate file to verify with.</p>\n<p><strong><code>--cacertdir</code></strong> <em>dir</em><br>: Directory where trusted CA certificates are stored.<br>  If neither cacert nor cacertdir are specified, the default<br>  system-wide trusted root certs configuration will apply.</p>\n<p><strong><code>--insecure</code></strong><br>: Allow insecure TLS connection by skipping cert validation.</p>\n<p><strong><code>--cert</code></strong> <em>file</em><br>: Client certificate to authenticate with.</p>\n<p><strong><code>--key</code></strong> <em>file</em><br>: Private key file to authenticate with.</p>\n<p><strong><code>--tls-ciphers</code></strong> <em>list</em><br>: Sets the list of preferred ciphers (TLSv1.2 and below)<br>  in order of preference from highest to lowest separated by colon (&quot;:&quot;).<br>  See the <strong>ciphers</strong>(1ssl) manpage for more information about the syntax of this string.</p>\n<p><strong><code>--tls-ciphersuites</code></strong> <em>list</em><br>: Sets the list of preferred ciphersuites (TLSv1.3)<br>  in order of preference from highest to lowest separated by colon (&quot;:&quot;).<br>  See the <strong>ciphers</strong>(1ssl) manpage for more information about the syntax of this string,<br>  and specifically for TLSv1.3 ciphersuites.</p>\n<p><strong><code>--raw</code></strong><br>: Use raw formatting for replies (default when STDOUT is<br>  not a tty).</p>\n<p><strong><code>--no-raw</code></strong><br>: Force formatted output even when STDOUT is not a tty.</p>\n<p><strong><code>--quoted-input</code></strong><br>: Force input to be handled as quoted strings.</p>\n<p><strong><code>--csv</code></strong><br>: Output in CSV format.</p>\n<p><strong><code>--json</code></strong><br>: Output in JSON format (default RESP3, use -2 if you want to use with RESP2).</p>\n<p><strong><code>--quoted-json</code></strong><br>: Same as --json, but produce ASCII-safe quoted strings, not Unicode.</p>\n<p><strong><code>--show-pushes</code></strong> <strong><code>yes</code></strong>|<strong><code>no</code></strong><br>: Whether to print RESP3 PUSH messages.  Enabled by default when<br>  STDOUT is a tty but can be overridden with --show-pushes no.</p>\n<p><strong><code>--stat</code></strong><br>: Print rolling stats about server: mem, clients, ...</p>\n<p><strong><code>--latency</code></strong><br>: Enter a special mode continuously sampling latency.<br>  If you use this mode in an interactive session it runs<br>  forever displaying real-time stats. Otherwise if <code>--raw</code> or<br>  <code>--csv</code> is specified, or if you redirect the output to a non<br>  TTY, it samples the latency for 1 second (you can use<br>  <code>-i</code> to change the interval), then produces a single output<br>  and exits.</p>\n<p><strong><code>--latency-history</code></strong><br>: Like <code>--latency</code> but tracking latency changes over time.<br>  Default time interval is 15 sec. Change it using <code>-i</code>.</p>\n<p><strong><code>--latency-dist</code></strong><br>: Shows latency as a spectrum, requires xterm 256 colors.<br>  Default time interval is 1 sec. Change it using <code>-i</code>.</p>\n<p><strong><code>--lru-test</code></strong> <em>keys</em><br>: Simulate a cache workload with an 80-20 distribution.</p>\n<p><strong><code>--replica</code></strong><br>: Simulate a replica showing commands received from the primary.</p>\n<p><strong><code>--rdb</code></strong> <em>filename</em><br>: Transfer an RDB dump from remote server to local file.<br>  Use filename of &quot;-&quot; to write to stdout.</p>\n<p><strong><code>--functions-rdb</code></strong> <em>filename</em><br>: Like <code>--rdb</code> but only get the functions (not the keys)<br>  when getting the RDB dump file.</p>\n<p><strong><code>--pipe</code></strong><br>: Transfer raw RESP protocol from stdin to server.</p>\n<p><strong><code>--pipe-timeout</code></strong> <em>n</em><br>: In <code>--pipe</code> mode, abort with error if after sending all data.<br>  no reply is received within <em>n</em> seconds.<br>  Default timeout: 30. Use 0 to wait forever.</p>\n<p><strong><code>--bigkeys</code></strong><br>: Sample keys looking for keys with many elements (complexity).</p>\n<p><strong><code>--memkeys</code></strong><br>: Sample keys looking for keys consuming a lot of memory.</p>\n<p><strong><code>--memkeys-samples</code></strong> <em>n</em><br>: Sample keys looking for keys consuming a lot of memory.<br>  And define number of key elements to sample</p>\n<p><strong><code>--hotkeys</code></strong><br>: Sample keys looking for hot keys.<br>  only works when maxmemory-policy is <code>*lfu</code>.</p>\n<p><strong><code>--scan</code></strong><br>: List all keys using the SCAN command.</p>\n<p><strong><code>--pattern</code></strong> <em>pat</em><br>: Keys pattern when using the <code>--scan</code>, <code>--bigkeys</code> or <code>--hotkeys</code><br>  options (default: <code>*</code>).</p>\n<p><strong><code>--count</code></strong> <em>count</em><br>: Count option when using the <code>--scan</code>, <code>--bigkeys</code> or <code>--hotkeys</code> (default: 10).</p>\n<p><strong><code>--quoted-pattern</code></strong> <em>pat</em><br>: Same as <code>--pattern</code>, but the specified string can be<br>  quoted, in order to pass an otherwise non binary-safe string.</p>\n<p><strong><code>--intrinsic-latency</code></strong> <em>sec</em><br>: Run a test to measure intrinsic system latency.<br>  The test will run for the specified amount of seconds.</p>\n<p><strong><code>--eval</code></strong> <em>file</em><br>: Send an EVAL command using the Lua script at <em>file</em>.</p>\n<p><strong><code>--ldb</code></strong><br>: Used with <code>--eval</code> enable the Server Lua debugger.</p>\n<p><strong><code>--ldb-sync-mode</code></strong><br>: Like <code>--ldb</code> but uses the synchronous Lua debugger, in<br>  this mode the server is blocked and script changes are<br>  not rolled back from the server memory.</p>\n<p><strong><code>--cluster</code></strong> <em>command</em> [<em>args</em>...] [<em>opts</em>...]<br>: Cluster Manager command and arguments (see below).</p>\n<p><strong><code>--verbose</code></strong><br>: Verbose mode.</p>\n<p><strong><code>--no-auth-warning</code></strong><br>: Don&#39;t show warning message when using password on command<br>  line interface.</p>\n<p><strong><code>--help</code></strong><br>: Output help and exit.</p>\n<p><strong><code>--version</code></strong><br>: Output version and exit.</p>\n<h2>Cluster Manager commands</h2>\n<p>For management of <a href=\"cluster-tutorial\">Valkey Cluster</a>, the following syntax is used:</p>\n<p><strong><code>valkey-cli</code></strong> <strong><code>--cluster</code></strong> <em>command</em> [<em>args</em>...] [<em>opts</em>...]</p>\n<pre><code>  Command        Args\n  --------------------------------------------------------------------------------\n  create         host1:port1 ... hostN:portN\n                 --cluster-replicas &lt;arg&gt;\n  check          &lt;host:port&gt; or &lt;host&gt; &lt;port&gt; - separated by either colon or space\n                 --cluster-search-multiple-owners\n  info           &lt;host:port&gt; or &lt;host&gt; &lt;port&gt; - separated by either colon or space\n  fix            &lt;host:port&gt; or &lt;host&gt; &lt;port&gt; - separated by either colon or space\n                 --cluster-search-multiple-owners\n                 --cluster-fix-with-unreachable-masters\n  reshard        &lt;host:port&gt; or &lt;host&gt; &lt;port&gt; - separated by either colon or space\n                 --cluster-from &lt;arg&gt;\n                 --cluster-to &lt;arg&gt;\n                 --cluster-slots &lt;arg&gt;\n                 --cluster-yes\n                 --cluster-timeout &lt;arg&gt;\n                 --cluster-pipeline &lt;arg&gt;\n                 --cluster-replace\n  rebalance      &lt;host:port&gt; or &lt;host&gt; &lt;port&gt; - separated by either colon or space\n                 --cluster-weight &lt;node1=w1...nodeN=wN&gt;\n                 --cluster-use-empty-masters\n                 --cluster-timeout &lt;arg&gt;\n                 --cluster-simulate\n                 --cluster-pipeline &lt;arg&gt;\n                 --cluster-threshold &lt;arg&gt;\n                 --cluster-replace\n  add-node       new_host:new_port existing_host:existing_port\n                 --cluster-replica\n                 --cluster-master-id &lt;arg&gt;\n  del-node       host:port node_id\n  call           host:port command arg arg .. arg\n                 --cluster-only-masters\n                 --cluster-only-replicas\n  set-timeout    host:port milliseconds\n  import         host:port\n                 --cluster-from &lt;arg&gt;\n                 --cluster-from-user &lt;arg&gt;\n                 --cluster-from-pass &lt;arg&gt;\n                 --cluster-from-askpass\n                 --cluster-copy\n                 --cluster-replace\n  backup         host:port backup_directory\n  help\n</code></pre>\n<h2>Command line usage</h2>\n<p>To run a Valkey command and return a standard output at the terminal, include the command to execute as separate arguments of <code>valkey-cli</code>:</p>\n<pre><code>$ valkey-cli INCR mycounter\n(integer) 7\n</code></pre>\n<p>The reply of the command is &quot;7&quot;. Since Valkey replies are typed (strings, arrays, integers, nil, errors, etc.), you see the type of the reply between parentheses. This additional information may not be ideal when the output of <code>valkey-cli</code> must be used as input of another command or redirected into a file.</p>\n<p><code>valkey-cli</code> only shows additional information for human readability when it detects the standard output is a tty, or terminal. For all other outputs it will auto-enable the <em>raw output mode</em>, as in the following example:</p>\n<pre><code>$ valkey-cli INCR mycounter &gt; /tmp/output.txt\n$ cat /tmp/output.txt\n8\n</code></pre>\n<p>Note that <code>(integer)</code> is omitted from the output because <code>valkey-cli</code> detects<br>the output is no longer written to the terminal. You can force raw output<br>even on the terminal with the <code>--raw</code> option:</p>\n<pre><code>$ valkey-cli --raw INCR mycounter\n9\n</code></pre>\n<p>You can force human readable output when writing to a file or in<br>pipe to other commands by using <code>--no-raw</code>.</p>\n<h2>String quoting and escaping</h2>\n<p>When <code>valkey-cli</code> parses a command, whitespace characters automatically delimit the arguments.<br>In interactive mode, a newline sends the command for parsing and execution.<br>To input string values that contain whitespaces or non-printable characters, you can use quoted and escaped strings.</p>\n<p>Quoted string values are enclosed in double (<code>&quot;</code>) or single (<code>&#39;</code>) quotation marks.<br>Escape sequences are used to put nonprintable characters in character and string literals.</p>\n<p>An escape sequence contains a backslash (<code>\\</code>) symbol followed by one of the escape sequence characters.</p>\n<p>Doubly-quoted strings support the following escape sequences:</p>\n<ul>\n<li><code>\\&quot;</code> - double-quote</li>\n<li><code>\\n</code> - newline</li>\n<li><code>\\r</code> - carriage return</li>\n<li><code>\\t</code> - horizontal tab</li>\n<li><code>\\b</code> - backspace</li>\n<li><code>\\a</code> - alert</li>\n<li><code>\\\\</code> - backslash</li>\n<li><code>\\xhh</code> - any ASCII character represented by a hexadecimal number (<em>hh</em>)</li>\n</ul>\n<p>Single quotes assume the string is literal, and allow only the following escape sequences:</p>\n<ul>\n<li><code>\\&#39;</code> - single quote</li>\n<li><code>\\\\</code> - backslash</li>\n</ul>\n<p>For example, to return <code>Hello World</code> on two lines:</p>\n<pre><code>127.0.0.1:6379&gt; SET mykey &quot;Hello\\nWorld&quot;\nOK\n127.0.0.1:6379&gt; GET mykey\nHello\nWorld\n</code></pre>\n<p>When you input strings that contain single or double quotes, as you might in passwords, for example, escape the string, like so: </p>\n<pre><code>127.0.0.1:6379&gt; AUTH some_admin_user &quot;&gt;^8T&gt;6Na{u|jp&gt;+v\\&quot;55\\@_;OU(OR]7mbAYGqsfyu48(j&#39;%hQH7;v*f1H${*gD(Se&#39;&quot;\n</code></pre>\n<h2>Host, port, password, and database</h2>\n<p>By default, <code>valkey-cli</code> connects to the server at the address 127.0.0.1 with port 6379.<br>You can change the port using several command line options. To specify a different host name or an IP address, use the <code>-h</code> option. In order to set a different port, use <code>-p</code>.</p>\n<pre><code>$ valkey-cli -h valkey15.example.com -p 6390 PING\nPONG\n</code></pre>\n<p>If your instance is password protected, the <code>-a &lt;password&gt;</code> option will<br>perform authentication saving the need of explicitly using the <code>AUTH</code> command:</p>\n<pre><code>$ valkey-cli -a myUnguessablePazzzzzword123 PING\nPONG\n</code></pre>\n<p><strong>NOTE:</strong> For security reasons, provide the password to <code>valkey-cli</code> automatically via the<br><code>REDISCLI_AUTH</code> environment variable.</p>\n<p>Finally, it&#39;s possible to send a command that operates on a database number<br>other than the default number zero by using the <code>-n &lt;dbnum&gt;</code> option:</p>\n<pre><code>$ valkey-cli FLUSHALL\nOK\n$ valkey-cli -n 1 INCR a\n(integer) 1\n$ valkey-cli -n 1 INCR a\n(integer) 2\n$ valkey-cli -n 2 INCR a\n(integer) 1\n</code></pre>\n<p>Some or all of this information can also be provided by using the <code>-u &lt;uri&gt;</code><br>option and the URI pattern <code>valkey://user:password@host:port/dbnum</code>:</p>\n<pre><code>$ valkey-cli -u valkey://LJenkins:p%40ssw0rd@valkey-16379.example.com:16379/0 PING\nPONG\n</code></pre>\n<p><strong>NOTE:</strong><br>User, password and dbnum are optional.<br>For authentication without a username, use username <code>default</code>.<br>For TLS, use the scheme <code>valkeys</code>.</p>\n<h2>SSL/TLS</h2>\n<p>By default, <code>valkey-cli</code> uses a plain TCP connection to connect to Valkey.<br>You may enable SSL/TLS using the <code>--tls</code> option, along with <code>--cacert</code> or<br><code>--cacertdir</code> to configure a trusted root certificate bundle or directory.</p>\n<p>If the target server requires authentication using a client side certificate,<br>you can specify a certificate and a corresponding private key using <code>--cert</code> and<br><code>--key</code>.</p>\n<h2>Getting input from other programs</h2>\n<p>There are two ways you can use <code>valkey-cli</code> in order to receive input from other<br>commands via the standard input. One is to use the target payload as the last argument<br>from <em>stdin</em>. For example, in order to set the Valkey key <code>net_services</code><br>to the content of the file <code>/etc/services</code> from a local file system, use the <code>-x</code><br>option:</p>\n<pre><code>$ valkey-cli -x SET net_services &lt; /etc/services\nOK\n$ valkey-cli GETRANGE net_services 0 50\n&quot;#\\n# Network services, Internet style\\n#\\n# Note that &quot;\n</code></pre>\n<p>In the first line of the above session, <code>valkey-cli</code> was executed with the <code>-x</code> option and a file was redirected to the CLI&#39;s<br>standard input as the value to satisfy the <code>SET net_services</code> command phrase. This is useful for scripting.</p>\n<p>A different approach is to feed <code>valkey-cli</code> a sequence of commands written in a<br>text file:</p>\n<pre><code>$ cat /tmp/commands.txt\nSET item:3374 100\nINCR item:3374\nAPPEND item:3374 xxx\nGET item:3374\n$ cat /tmp/commands.txt | valkey-cli\nOK\n(integer) 101\n(integer) 6\n&quot;101xxx&quot;\n</code></pre>\n<p>All the commands in <code>commands.txt</code> are executed consecutively by<br><code>valkey-cli</code> as if they were typed by the user in interactive mode. Strings can be<br>quoted inside the file if needed, so that it&#39;s possible to have single<br>arguments with spaces, newlines, or other special characters:</p>\n<pre><code>$ cat /tmp/commands.txt\nSET arg_example &quot;This is a single argument&quot;\nSTRLEN arg_example\n$ cat /tmp/commands.txt | valkey-cli\nOK\n(integer) 25\n</code></pre>\n<h2>Continuously run the same command</h2>\n<p>It is possible to execute a single command a specified number of times<br>with a user-selected pause between executions. This is useful in<br>different contexts - for example when we want to continuously monitor some<br>key content or <code>INFO</code> field output, or when we want to simulate some<br>recurring write event, such as pushing a new item into a list every 5 seconds.</p>\n<p>This feature is controlled by two options: <code>-r &lt;count&gt;</code> and <code>-i &lt;delay&gt;</code>.<br>The <code>-r</code> option states how many times to run a command and <code>-i</code> sets<br>the delay between the different command calls in seconds (with the ability<br>to specify values such as 0.1 to represent 100 milliseconds).</p>\n<p>By default the interval (or delay) is set to 0, so commands are just executed<br>ASAP:</p>\n<pre><code>$ valkey-cli -r 5 INCR counter_value\n(integer) 1\n(integer) 2\n(integer) 3\n(integer) 4\n(integer) 5\n</code></pre>\n<p>To run the same command indefinitely, use <code>-1</code> as the count value.<br>To monitor over time the RSS memory size it&#39;s possible to use the following command:</p>\n<pre><code>$ valkey-cli -r -1 -i 1 INFO | grep rss_human\nused_memory_rss_human:2.71M\nused_memory_rss_human:2.73M\nused_memory_rss_human:2.73M\nused_memory_rss_human:2.73M\n... a new line will be printed each second ...\n</code></pre>\n<h2>Mass insertion of data using <code>valkey-cli</code></h2>\n<p>Mass insertion using <code>valkey-cli</code> is covered in a separate page as it is a<br>worthwhile topic itself. Please refer to our <a href=\"mass-insertion\">mass insertion guide</a>.</p>\n<h2>CSV output</h2>\n<p>A CSV (Comma Separated Values) output feature exists within <code>valkey-cli</code> to export data from Valkey to an external program.  </p>\n<pre><code>$ valkey-cli LPUSH mylist a b c d\n(integer) 4\n$ valkey-cli --csv LRANGE mylist 0 -1\n&quot;d&quot;,&quot;c&quot;,&quot;b&quot;,&quot;a&quot;\n</code></pre>\n<p>Note that the <code>--csv</code> flag will only work on a single command, not the entirety of a DB as an export.</p>\n<h2>Running Lua scripts</h2>\n<p>The <code>valkey-cli</code> has extensive support for using the debugging facility<br>of Lua scripting, available with Valkey 3.2 onwards. For this feature, refer to the <a href=\"ldb\">Valkey Lua debugger documentation</a>.</p>\n<p>Even without using the debugger, <code>valkey-cli</code> can be used to<br>run scripts from a file as an argument:</p>\n<pre><code>$ cat /tmp/script.lua\nreturn server.call(&#39;SET&#39;,KEYS[1],ARGV[1])\n$ valkey-cli --eval /tmp/script.lua location:hastings:temp , 23\nOK\n</code></pre>\n<p>The Valkey <code>EVAL</code> command takes the list of keys the script uses, and the<br>other non key arguments, as different arrays. When calling <code>EVAL</code> you<br>provide the number of keys as a number. </p>\n<p>When calling <code>valkey-cli</code> with the <code>--eval</code> option above, there is no need to specify the number of keys<br>explicitly. Instead it uses the convention of separating keys and arguments<br>with a comma. This is why in the above call you see <code>location:hastings:temp , 23</code> as arguments.</p>\n<p>So <code>location:hastings:temp</code> will populate the <code>KEYS</code> array, and <code>23</code> the <code>ARGV</code> array.</p>\n<p>The <code>--eval</code> option is useful when writing simple scripts. For more<br>complex work, the Lua debugger is recommended. It is possible to mix the two approaches, since the debugger can also execute scripts from an external file.</p>\n<h1>Interactive mode</h1>\n<p>We have explored how to use the Valkey CLI as a command line program.<br>This is useful for scripts and certain types of testing, however most<br>people will spend the majority of time in <code>valkey-cli</code> using its interactive<br>mode.</p>\n<p>In interactive mode the user types Valkey commands at the prompt. The command<br>is sent to the server, processed, and the reply is parsed back and rendered<br>into a simpler form to read.</p>\n<p>Nothing special is needed for running the <code>valkey-cli</code> in interactive mode -<br>just execute it without any arguments</p>\n<pre><code>$ valkey-cli\n127.0.0.1:6379&gt; PING\nPONG\n</code></pre>\n<p>The string <code>127.0.0.1:6379&gt;</code> is the prompt. It displays the connected Valkey server instance&#39;s hostname and port.</p>\n<p>The prompt updates as the connected server changes or when operating on a database different from the database number zero:</p>\n<pre><code>127.0.0.1:6379&gt; SELECT 2\nOK\n127.0.0.1:6379[2]&gt; DBSIZE\n(integer) 1\n127.0.0.1:6379[2]&gt; SELECT 0\nOK\n127.0.0.1:6379&gt; DBSIZE\n(integer) 503\n</code></pre>\n<h2>Handling connections and reconnections</h2>\n<p>Using the <code>CONNECT</code> command in interactive mode makes it possible to connect<br>to a different instance, by specifying the <em>hostname</em> and <em>port</em> we want<br>to connect to:</p>\n<pre><code>127.0.0.1:6379&gt; CONNECT metal 6379\nmetal:6379&gt; PING\nPONG\n</code></pre>\n<p>As you can see the prompt changes accordingly when connecting to a different server instance.<br>If a connection is attempted to an instance that is unreachable, the <code>valkey-cli</code> goes into disconnected<br>mode and attempts to reconnect with each new command:</p>\n<pre><code>127.0.0.1:6379&gt; CONNECT 127.0.0.1 9999\nCould not connect to Valkey at 127.0.0.1:9999: Connection refused\nnot connected&gt; PING\nCould not connect to Valkey at 127.0.0.1:9999: Connection refused\nnot connected&gt; PING\nCould not connect to Valkey at 127.0.0.1:9999: Connection refused\n</code></pre>\n<p>Generally after a disconnection is detected, <code>valkey-cli</code> always attempts to<br>reconnect transparently; if the attempt fails, it shows the error and<br>enters the disconnected state. The following is an example of disconnection<br>and reconnection:</p>\n<pre><code>127.0.0.1:6379&gt; INFO SERVER\nCould not connect to Valkey at 127.0.0.1:6379: Connection refused\nnot connected&gt; PING\nPONG\n127.0.0.1:6379&gt; \n(now we are connected again)\n</code></pre>\n<p>When a reconnection is performed, <code>valkey-cli</code> automatically re-selects the<br>last database number selected. However, all other states about the<br>connection is lost, such as within a MULTI/EXEC transaction:</p>\n<pre><code>$ valkey-cli\n127.0.0.1:6379&gt; MULTI\nOK\n127.0.0.1:6379&gt; PING\nQUEUED\n\n( here the server is manually restarted )\n\n127.0.0.1:6379&gt; EXEC\n(error) ERR EXEC without MULTI\n</code></pre>\n<p>This is usually not an issue when using the <code>valkey-cli</code> in interactive mode for<br>testing, but this limitation should be known.</p>\n<h2>Editing, history, completion and hints</h2>\n<p>Because <code>valkey-cli</code> uses the &quot;linenoise&quot; line editing library shipped with<br>Valkey, it has line editing capabilities without depending on <code>libreadline</code> or<br>other optional libraries.</p>\n<p>Command execution history can be accessed in order to avoid retyping commands by pressing the arrow keys (up and down).<br>The history is preserved between restarts of the CLI, in a file named<br><code>.valkeycli_history</code> inside the user home directory, as specified<br>by the <code>HOME</code> environment variable. It is possible to use a different<br>history filename by setting the <code>REDISCLI_HISTFILE</code> environment variable,<br>and disable it by setting it to <code>/dev/null</code>.</p>\n<p>The <code>valkey-cli</code> is also able to perform command-name completion by pressing the TAB<br>key, as in the following example:</p>\n<pre><code>127.0.0.1:6379&gt; Z&lt;TAB&gt;\n127.0.0.1:6379&gt; ZADD&lt;TAB&gt;\n127.0.0.1:6379&gt; ZCARD&lt;TAB&gt;\n</code></pre>\n<p>Once Valkey command name has been entered at the prompt, the <code>valkey-cli</code> will display<br>syntax hints. Like command history, this behavior can be turned on and off via the <code>valkey-cli</code> preferences.</p>\n<h2>Preferences</h2>\n<p>There are two ways to customize <code>valkey-cli</code> behavior. The file <code>.valkeyclirc</code><br>in the home directory is loaded by the CLI on startup. You can override the<br>file&#39;s default location by setting the <code>REDISCLI_RCFILE</code> environment variable to<br>an alternative path. Preferences can also be set during a CLI session, in which<br>case they will last only the duration of the session.</p>\n<p>To set preferences, use the special <code>:set</code> command. The following preferences<br>can be set, either by typing the command in the CLI or adding it to the<br><code>.valkeyclirc</code> file:</p>\n<ul>\n<li><code>:set hints</code> - enables syntax hints</li>\n<li><code>:set nohints</code> - disables syntax hints</li>\n</ul>\n<h2>Running the same command N times</h2>\n<p>It is possible to run the same command multiple times in interactive mode by prefixing the command<br>name by a number:</p>\n<pre><code>127.0.0.1:6379&gt; 5 INCR mycounter\n(integer) 1\n(integer) 2\n(integer) 3\n(integer) 4\n(integer) 5\n</code></pre>\n<h2>Showing help about Valkey commands</h2>\n<p><code>valkey-cli</code> provides online help for most Valkey <a href=\"../commands/\">commands</a>, using the <code>HELP</code> command. The command can be used<br>in two forms:</p>\n<ul>\n<li><code>HELP @&lt;category&gt;</code> shows all the commands about a given category. The<br>categories are: <ul>\n<li><code>@generic</code></li>\n<li><code>@string</code></li>\n<li><code>@list</code></li>\n<li><code>@set</code></li>\n<li><code>@sorted_set</code></li>\n<li><code>@hash</code></li>\n<li><code>@pubsub</code></li>\n<li><code>@transactions</code></li>\n<li><code>@connection</code></li>\n<li><code>@server</code></li>\n<li><code>@scripting</code></li>\n<li><code>@hyperloglog</code></li>\n<li><code>@cluster</code></li>\n<li><code>@geo</code></li>\n<li><code>@stream</code></li>\n</ul>\n</li>\n<li><code>HELP &lt;commandname&gt;</code> shows specific help for the command given as argument.</li>\n</ul>\n<p>For example in order to show help for the <code>PFADD</code> command, use:</p>\n<pre><code>127.0.0.1:6379&gt; HELP PFADD\n\nPFADD key element [element ...]\nsummary: Adds the specified elements to the specified HyperLogLog.\nsince: 2.8.9\n</code></pre>\n<p>Note that <code>HELP</code> supports TAB completion as well.</p>\n<h2>Clearing the terminal screen</h2>\n<p>Using the <code>CLEAR</code> command in interactive mode clears the terminal&#39;s screen.</p>\n<h1>Special modes of operation</h1>\n<p>So far we saw two main modes of <code>valkey-cli</code>.</p>\n<ul>\n<li>Command line execution of Valkey commands.</li>\n<li>Interactive &quot;REPL&quot; usage.</li>\n</ul>\n<p>The CLI performs other auxiliary tasks related to Valkey that<br>are explained in the next sections:</p>\n<ul>\n<li>Monitoring tool to show continuous stats about a Valkey server.</li>\n<li>Scanning a Valkey database for very large keys.</li>\n<li>Key space scanner with pattern matching.</li>\n<li>Acting as a <a href=\"pubsub\">Pub/Sub</a> client to subscribe to channels.</li>\n<li>Monitoring the commands executed into a Valkey instance.</li>\n<li>Checking the <a href=\"latency\">latency</a> of a Valkey server in different ways.</li>\n<li>Checking the scheduler latency of the local computer.</li>\n<li>Transferring RDB backups from a remote Valkey server locally.</li>\n<li>Acting as a Valkey replica for showing what a replica receives.</li>\n<li>Simulating <a href=\"lru-cache\">LRU</a> workloads for showing stats about keys hits.</li>\n<li>A client for the Lua debugger.</li>\n</ul>\n<h2>Continuous stats mode</h2>\n<p>Continuous stats mode is probably one of the lesser known yet very useful features of <code>valkey-cli</code> to monitor Valkey instances in real time. To enable this mode, the <code>--stat</code> option is used.<br>The output is very clear about the behavior of the CLI in this mode:</p>\n<pre><code>$ valkey-cli --stat\n------- data ------ --------------------- load -------------------- - child -\nkeys       mem      clients blocked requests            connections\n506        1015.00K 1       0       24 (+0)             7\n506        1015.00K 1       0       25 (+1)             7\n506        3.40M    51      0       60461 (+60436)      57\n506        3.40M    51      0       146425 (+85964)     107\n507        3.40M    51      0       233844 (+87419)     157\n507        3.40M    51      0       321715 (+87871)     207\n508        3.40M    51      0       408642 (+86927)     257\n508        3.40M    51      0       497038 (+88396)     257\n</code></pre>\n<p>In this mode a new line is printed every second with useful information and differences of request values between old data points. Memory usage, client connection counts, and various other statistics about the connected Valkey database can be easily understood with this auxiliary <code>valkey-cli</code> tool.</p>\n<p>The <code>-i &lt;interval&gt;</code> option in this case works as a modifier in order to<br>change the frequency at which new lines are emitted. The default is one<br>second.</p>\n<h2>Scanning for big keys</h2>\n<p>In this special mode, <code>valkey-cli</code> works as a key space analyzer. It scans the<br>dataset for big keys, but also provides information about the data types<br>that the data set consists of. This mode is enabled with the <code>--bigkeys</code> option,<br>and produces verbose output:</p>\n<pre><code>$ valkey-cli --bigkeys\n\n# Scanning the entire keyspace to find biggest keys as well as\n# average sizes per key type.  You can use -i 0.01 to sleep 0.01 sec\n# per SCAN command (not usually needed).\n\n[00.00%] Biggest string found so far &#39;key-419&#39; with 3 bytes\n[05.14%] Biggest list   found so far &#39;mylist&#39; with 100004 items\n[35.77%] Biggest string found so far &#39;counter:__rand_int__&#39; with 6 bytes\n[73.91%] Biggest hash   found so far &#39;myobject&#39; with 3 fields\n\n-------- summary -------\n\nSampled 506 keys in the keyspace!\nTotal key length in bytes is 3452 (avg len 6.82)\n\nBiggest string found &#39;counter:__rand_int__&#39; has 6 bytes\nBiggest   list found &#39;mylist&#39; has 100004 items\nBiggest   hash found &#39;myobject&#39; has 3 fields\n\n504 strings with 1403 bytes (99.60% of keys, avg size 2.78)\n1 lists with 100004 items (00.20% of keys, avg size 100004.00)\n0 sets with 0 members (00.00% of keys, avg size 0.00)\n1 hashs with 3 fields (00.20% of keys, avg size 3.00)\n0 zsets with 0 members (00.00% of keys, avg size 0.00)\n</code></pre>\n<p>In the first part of the output, each new key larger than the previous larger<br>key (of the same type) encountered is reported. The summary section<br>provides general stats about the data inside the Valkey instance.</p>\n<p>The program uses the <code>SCAN</code> command, so it can be executed against a busy<br>server without impacting the operations, however the <code>-i</code> option can be<br>used in order to throttle the scanning process of the specified fraction<br>of second for each <code>SCAN</code> command. </p>\n<p>For example, <code>-i 0.01</code> will slow down the program execution considerably, but will also reduce the load on the server<br>to a negligible amount.</p>\n<p>Note that the summary also reports in a cleaner form the biggest keys found<br>for each time. The initial output is just to provide some interesting info<br>ASAP if running against a very large data set.</p>\n<h2>Getting a list of keys</h2>\n<p>It is also possible to scan the key space, again in a way that does not<br>block the Valkey server (which does happen when you use a command<br>like <code>KEYS *</code>), and print all the key names, or filter them for specific<br>patterns. This mode, like the <code>--bigkeys</code> option, uses the <code>SCAN</code> command,<br>so keys may be reported multiple times if the dataset is changing, but no<br>key would ever be missing, if that key was present since the start of the<br>iteration. Because of the command that it uses this option is called <code>--scan</code>.</p>\n<pre><code>$ valkey-cli --scan | head -10\nkey-419\nkey-71\nkey-236\nkey-50\nkey-38\nkey-458\nkey-453\nkey-499\nkey-446\nkey-371\n</code></pre>\n<p>Note that <code>head -10</code> is used in order to print only the first ten lines of the<br>output.</p>\n<p>Scanning is able to use the underlying pattern matching capability of<br>the <code>SCAN</code> command with the <code>--pattern</code> option.</p>\n<pre><code>$ valkey-cli --scan --pattern &#39;*-11*&#39;\nkey-114\nkey-117\nkey-118\nkey-113\nkey-115\nkey-112\nkey-119\nkey-11\nkey-111\nkey-110\nkey-116\n</code></pre>\n<p>Piping the output through the <code>wc</code> command can be used to count specific<br>kind of objects, by key name:</p>\n<pre><code>$ valkey-cli --scan --pattern &#39;user:*&#39; | wc -l\n3829433\n</code></pre>\n<p>You can use <code>-i 0.01</code> to add a delay between calls to the <code>SCAN</code> command.<br>This will make the command slower but will significantly reduce load on the server.</p>\n<h2>Pub/sub mode</h2>\n<p>The CLI is able to publish messages in Valkey Pub/Sub channels using<br>the <code>PUBLISH</code> command. Subscribing to channels in order to receive<br>messages is different - the terminal is blocked and waits for<br>messages, so this is implemented as a special mode in <code>valkey-cli</code>. Unlike<br>other special modes this mode is not enabled by using a special option,<br>but simply by using the <code>SUBSCRIBE</code> or <code>PSUBSCRIBE</code> command, which are available in<br>interactive or command mode:</p>\n<pre><code>$ valkey-cli PSUBSCRIBE &#39;*&#39;\nReading messages... (press Ctrl-C to quit)\n1) &quot;PSUBSCRIBE&quot;\n2) &quot;*&quot;\n3) (integer) 1\n</code></pre>\n<p>The <em>reading messages</em> message shows that we entered Pub/Sub mode.<br>When another client publishes some message in some channel, such as with the command <code>valkey-cli PUBLISH mychannel mymessage</code>, the CLI in Pub/Sub mode will show something such as:</p>\n<pre><code>1) &quot;pmessage&quot;\n2) &quot;*&quot;\n3) &quot;mychannel&quot;\n4) &quot;mymessage&quot;\n</code></pre>\n<p>This is very useful for debugging Pub/Sub issues.<br>To exit the Pub/Sub mode just process <code>CTRL-C</code>.</p>\n<h2>Monitoring commands executed in Valkey</h2>\n<p>Similarly to the Pub/Sub mode, the monitoring mode is entered automatically<br>once you use the <code>MONITOR</code> command. All commands received by the active Valkey instance will be printed to the standard output:</p>\n<pre><code>$ valkey-cli MONITOR\nOK\n1460100081.165665 [0 127.0.0.1:51706] &quot;set&quot; &quot;shipment:8000736522714:status&quot; &quot;sorting&quot;\n1460100083.053365 [0 127.0.0.1:51707] &quot;get&quot; &quot;shipment:8000736522714:status&quot;\n</code></pre>\n<p>Note that it is possible to pipe the output, so you can monitor<br>for specific patterns using tools such as <code>grep</code>.</p>\n<h2>Monitoring the latency of Valkey instances</h2>\n<p>Valkey is often used in contexts where latency is very critical. Latency<br>involves multiple moving parts within the application, from the client library<br>to the network stack, to the Valkey instance itself.</p>\n<p>The <code>valkey-cli</code> has multiple facilities for studying the latency of a Valkey<br>instance and understanding the latency&#39;s maximum, average and distribution.</p>\n<p>The basic latency-checking tool is the <code>--latency</code> option. Using this<br>option the CLI runs a loop where the <code>PING</code> command is sent to the Valkey<br>instance and the time to receive a reply is measured. This happens 100<br>times per second, and stats are updated in a real time in the console:</p>\n<pre><code>$ valkey-cli --latency\nmin: 0, max: 1, avg: 0.19 (427 samples)\n</code></pre>\n<p>The stats are provided in milliseconds. Usually, the average latency of<br>a very fast instance tends to be overestimated a bit because of the<br>latency due to the kernel scheduler of the system running <code>valkey-cli</code><br>itself, so the average latency of 0.19 above may easily be 0.01 or less.<br>However this is usually not a big problem, since most developers are interested in<br>events of a few milliseconds or more.</p>\n<p>Sometimes it is useful to study how the maximum and average latencies<br>evolve during time. The <code>--latency-history</code> option is used for that<br>purpose: it works exactly like <code>--latency</code>, but every 15 seconds (by<br>default) a new sampling session is started from scratch:</p>\n<pre><code>$ valkey-cli --latency-history\nmin: 0, max: 1, avg: 0.14 (1314 samples) -- 15.01 seconds range\nmin: 0, max: 1, avg: 0.18 (1299 samples) -- 15.00 seconds range\nmin: 0, max: 1, avg: 0.20 (113 samples)^C\n</code></pre>\n<p>Sampling sessions&#39; length can be changed with the <code>-i &lt;interval&gt;</code> option.</p>\n<p>The most advanced latency study tool, but also the most complex to<br>interpret for non-experienced users, is the ability to use color terminals<br>to show a spectrum of latencies. You&#39;ll see a colored output that indicates the<br>different percentages of samples, and different ASCII characters that indicate<br>different latency figures. This mode is enabled using the <code>--latency-dist</code><br>option:</p>\n<pre><code>$ valkey-cli --latency-dist\n(output not displayed, requires a color terminal, try it!)\n</code></pre>\n<p>There is another pretty unusual latency tool implemented inside <code>valkey-cli</code>.<br>It does not check the latency of a Valkey instance, but the latency of the<br>computer running <code>valkey-cli</code>. This latency is intrinsic to the kernel scheduler,<br>the hypervisor in case of virtualized instances, and so forth.</p>\n<p>Valkey calls it <em>intrinsic latency</em> because it&#39;s mostly opaque to the programmer.<br>If the Valkey instance has high latency regardless of all the obvious things<br>that may be the source cause, it&#39;s worth to check what&#39;s the best your system<br>can do by running <code>valkey-cli</code> in this special mode directly in the system you<br>are running Valkey servers on.</p>\n<p>By measuring the intrinsic latency, you know that this is the baseline,<br>and Valkey cannot outdo your system. In order to run the CLI<br>in this mode, use the <code>--intrinsic-latency &lt;test-time&gt;</code>. Note that the test time is in seconds and dictates how long the test should run.</p>\n<pre><code>$ ./valkey-cli --intrinsic-latency 5\nMax latency so far: 1 microseconds.\nMax latency so far: 7 microseconds.\nMax latency so far: 9 microseconds.\nMax latency so far: 11 microseconds.\nMax latency so far: 13 microseconds.\nMax latency so far: 15 microseconds.\nMax latency so far: 34 microseconds.\nMax latency so far: 82 microseconds.\nMax latency so far: 586 microseconds.\nMax latency so far: 739 microseconds.\n\n65433042 total runs (avg latency: 0.0764 microseconds / 764.14 nanoseconds per run).\nWorst run took 9671x longer than the average latency.\n</code></pre>\n<p>IMPORTANT: this command must be executed on the computer that runs the Valkey server instance, not on a different host. It does not connect to a Valkey instance and performs the test locally.</p>\n<p>In the above case, the system cannot do better than 739 microseconds of worst<br>case latency, so one can expect certain queries to occasionally run less than 1 millisecond.</p>\n<h2>Remote backups of RDB files</h2>\n<p>During a Valkey replication&#39;s first synchronization, the primary and the replica<br>exchange the whole data set in the form of an RDB file. This feature is exploited<br>by <code>valkey-cli</code> in order to provide a remote backup facility that allows a<br>transfer of an RDB file from any Valkey instance to the local computer running<br><code>valkey-cli</code>. To use this mode, call the CLI with the <code>--rdb &lt;dest-filename&gt;</code><br>option:</p>\n<pre><code>$ valkey-cli --rdb /tmp/dump.rdb\nSYNC sent to master, writing 13256 bytes to &#39;/tmp/dump.rdb&#39;\nTransfer finished with success.\n</code></pre>\n<p>This is a simple but effective way to ensure disaster recovery<br>RDB backups exist of your Valkey instance. When using this options in<br>scripts or <code>cron</code> jobs, make sure to check the return value of the command.<br>If it is non zero, an error occurred as in the following example:</p>\n<pre><code>$ valkey-cli --rdb /tmp/dump.rdb\nSYNC with master failed: -ERR Can&#39;t SYNC while not connected with my master\n$ echo $?\n1\n</code></pre>\n<h2>Replica mode</h2>\n<p>The replica mode of the CLI is an advanced feature useful for<br>Valkey developers and for debugging operations.<br>It allows for the inspection of the content a primary sends to its replicas in the replication<br>stream in order to propagate the writes to its replicas. The option<br>name is simply <code>--replica</code>. The following is a working example:</p>\n<pre><code>$ valkey-cli --replica\nSYNC with master, discarding 13256 bytes of bulk transfer...\nSYNC done. Logging commands from master.\n&quot;PING&quot;\n&quot;SELECT&quot;,&quot;0&quot;\n&quot;SET&quot;,&quot;last_name&quot;,&quot;Enigk&quot;\n&quot;PING&quot;\n&quot;INCR&quot;,&quot;mycounter&quot;\n</code></pre>\n<p>The command begins by discarding the RDB file of the first synchronization<br>and then logs each command received in CSV format.</p>\n<p>If you think some of the commands are not replicated correctly in your replicas<br>this is a good way to check what&#39;s happening, and also useful information<br>in order to improve the bug report.</p>\n<h2>Performing an LRU simulation</h2>\n<p>Valkey is often used as a cache with <a href=\"lru-cache\">LRU eviction</a>.<br>Depending on the number of keys and the amount of memory allocated for the<br>cache (specified via the <code>maxmemory</code> directive), the amount of cache hits<br>and misses will change. Sometimes, simulating the rate of hits is very<br>useful to correctly provision your cache.</p>\n<p>The <code>valkey-cli</code> has a special mode where it performs a simulation of GET and SET<br>operations, using an 80-20% power law distribution in the requests pattern.<br>This means that 20% of keys will be requested 80% of times, which is a<br>common distribution in caching scenarios.</p>\n<p>Theoretically, given the distribution of the requests and the Valkey memory<br>overhead, it should be possible to compute the hit rate analytically<br>with a mathematical formula. However, Valkey can be configured with<br>different LRU settings (number of samples) and LRU&#39;s implementation, which<br>is approximated in Valkey, changes a lot between different versions. Similarly<br>the amount of memory per key may change between versions. That is why this<br>tool was built: its main motivation was for testing the quality of Valkey&#39; LRU<br>implementation, but now is also useful for testing how a given version<br>behaves with the settings originally intended for deployment.</p>\n<p>To use this mode, specify the amount of keys in the test and configure a sensible <code>maxmemory</code> setting as a first attempt.</p>\n<p>IMPORTANT NOTE: Configuring the <code>maxmemory</code> setting in the Valkey configuration<br>is crucial: if there is no cap to the maximum memory usage, the hit will<br>eventually be 100% since all the keys can be stored in memory. If too many keys are specified with maximum memory, eventually all of the computer RAM will be used. It is also needed to configure an appropriate<br><em>maxmemory policy</em>; most of the time <code>allkeys-lru</code> is selected.</p>\n<p>In the following example there is a configured a memory limit of 100MB and an LRU<br>simulation using 10 million keys.</p>\n<p>WARNING: the test uses pipelining and will stress the server, don&#39;t use it<br>with production instances.</p>\n<pre><code>$ ./valkey-cli --lru-test 10000000\n156000 Gets/sec | Hits: 4552 (2.92%) | Misses: 151448 (97.08%)\n153750 Gets/sec | Hits: 12906 (8.39%) | Misses: 140844 (91.61%)\n159250 Gets/sec | Hits: 21811 (13.70%) | Misses: 137439 (86.30%)\n151000 Gets/sec | Hits: 27615 (18.29%) | Misses: 123385 (81.71%)\n145000 Gets/sec | Hits: 32791 (22.61%) | Misses: 112209 (77.39%)\n157750 Gets/sec | Hits: 42178 (26.74%) | Misses: 115572 (73.26%)\n154500 Gets/sec | Hits: 47418 (30.69%) | Misses: 107082 (69.31%)\n151250 Gets/sec | Hits: 51636 (34.14%) | Misses: 99614 (65.86%)\n</code></pre>\n<p>The program shows stats every second. In the first seconds the cache starts to be populated. The misses rate later stabilizes into the actual figure that can be expected:</p>\n<pre><code>120750 Gets/sec | Hits: 48774 (40.39%) | Misses: 71976 (59.61%)\n122500 Gets/sec | Hits: 49052 (40.04%) | Misses: 73448 (59.96%)\n127000 Gets/sec | Hits: 50870 (40.06%) | Misses: 76130 (59.94%)\n124250 Gets/sec | Hits: 50147 (40.36%) | Misses: 74103 (59.64%)\n</code></pre>\n<p>A miss rate of 59% may not be acceptable for certain use cases therefor<br>100MB of memory is not enough. Observe an example using a half gigabyte of memory. After several<br>minutes the output stabilizes to the following figures:</p>\n<pre><code>140000 Gets/sec | Hits: 135376 (96.70%) | Misses: 4624 (3.30%)\n141250 Gets/sec | Hits: 136523 (96.65%) | Misses: 4727 (3.35%)\n140250 Gets/sec | Hits: 135457 (96.58%) | Misses: 4793 (3.42%)\n140500 Gets/sec | Hits: 135947 (96.76%) | Misses: 4553 (3.24%)\n</code></pre>\n<p>With 500MB there is sufficient space for the key quantity (10 million) and distribution (80-20 style).</p>\n"
      },
      {
        "id": "key-specs",
        "topicName": "Command key specifications",
        "description": "What are command key specification and how to use them in your client",
        "htmlContent": "<p>Many of the commands in Valkey accept key names as input arguments.<br>The 9th element in the reply of <code>COMMAND</code> (and <code>COMMAND INFO</code>) is an array that consists of the command&#39;s key specifications.</p>\n<p>A <em>key specification</em> describes a rule for extracting the names of one or more keys from the arguments of a given command.<br>Key specifications provide a robust and flexible mechanism, compared to the <em>first key</em>, <em>last key</em> and <em>step</em> scheme employed until Redis OSS 7.0.<br>Before introducing these specifications, Valkey clients had no trivial programmatic means to extract key names for all commands.</p>\n<p>Cluster-aware Valkey clients had to have the keys&#39; extraction logic hard-coded in the cases of commands such as <code>EVAL</code> and <code>ZUNIONSTORE</code> that rely on a <em>numkeys</em> argument or <code>SORT</code> and its many clauses.<br>Alternatively, the <code>COMMAND GETKEYS</code> can be used to achieve a similar extraction effect but at a higher latency.</p>\n<p>A Valkey client isn&#39;t obligated to support key specifications.<br>It can continue using the legacy <em>first key</em>, <em>last key</em> and <em>step</em> scheme along with the <a href=\"../commands/command#flags\"><em>movablekeys</em> flag</a> that remain unchanged.</p>\n<p>However, a Valkey client that implements key specifications support can consolidate most of its keys&#39; extraction logic.<br>Even if the client encounters an unfamiliar type of key specification, it can always revert to the <code>COMMAND GETKEYS</code> command.</p>\n<p>That said, most cluster-aware clients only require a single key name to perform correct command routing, so it is possible that although a command features one unfamiliar specification, its other specification may still be usable by the client.</p>\n<p>Key specifications are maps with the following keys:</p>\n<ol>\n<li><strong>begin_search:</strong>: the starting index for keys&#39; extraction.</li>\n<li><strong>find_keys:</strong> the rule for identifying the keys relative to the BS.</li>\n<li><strong>notes</strong>: notes about this key spec, if there are any.</li>\n<li><strong>flags</strong>: indicate the type of data access.</li>\n</ol>\n<h2>begin_search</h2>\n<p>The <em>begin_search</em> value of a specification informs the client of the extraction&#39;s beginning.<br>The value is a map.<br>There are three types of <code>begin_search</code>:</p>\n<ol>\n<li><strong>index:</strong> key name arguments begin at a constant index.</li>\n<li><strong>keyword:</strong> key names start after a specific keyword (token).</li>\n<li><strong>unknown:</strong> an unknown type of specification - see the <a href=\"#incomplete\">incomplete flag section</a> for more details.</li>\n</ol>\n<h3>index</h3>\n<p>The <em>index</em> type of <code>begin_search</code> indicates that input keys appear at a constant index.<br>It is a map under the <em>spec</em> key with a single key:</p>\n<ol>\n<li><strong>index:</strong> the 0-based index from which the client should start extracting key names.</li>\n</ol>\n<h3>keyword</h3>\n<p>The <em>keyword</em> type of <code>begin_search</code> means a literal token precedes key name arguments.<br>It is a map under the <em>spec</em> with two keys:</p>\n<ol>\n<li><strong>keyword:</strong> the keyword (token) that marks the beginning of key name arguments.</li>\n<li><strong>startfrom:</strong> an index to the arguments array from which the client should begin searching.<br>  This can be a negative value, which means the search should start from the end of the arguments&#39; array, in reverse order.<br>  For example, <em>-2</em>&#39;s meaning is to search reverse from the penultimate argument.</li>\n</ol>\n<p>More examples of the <em>keyword</em> search type include:</p>\n<ul>\n<li><code>SET</code> has a <code>begin_search</code> specification of type <em>index</em> with a value of <em>1</em>.</li>\n<li><code>XREAD</code> has a <code>begin_search</code> specification of type <em>keyword</em> with the values <em>&quot;STREAMS&quot;</em> and <em>1</em> as <em>keyword</em> and <em>startfrom</em>, respectively.</li>\n<li><code>MIGRATE</code> has a <em>start_search</em> specification of type <em>keyword</em> with the values of <em>&quot;KEYS&quot;</em> and <em>-2</em>.</li>\n</ul>\n<h2>find_keys</h2>\n<p>The <code>find_keys</code> value of a key specification tells the client how to continue the search for key names.<br><code>find_keys</code> has three possible types:</p>\n<ol>\n<li><strong>range:</strong> keys stop at a specific index or relative to the last argument.</li>\n<li><strong>keynum:</strong> an additional argument specifies the number of input keys.</li>\n<li><strong>unknown:</strong> an unknown type of specification - see the <a href=\"#incomplete\">incomplete flag section</a> for more details.</li>\n</ol>\n<h3>range</h3>\n<p>The <em>range</em> type of <code>find_keys</code> is a map under the <em>spec</em> key with three keys:</p>\n<ol>\n<li><strong>lastkey:</strong> the index, relative to <code>begin_search</code>, of the last key argument.<br>  This can be a negative value, in which case it isn&#39;t relative.<br>  For example, <em>-1</em> indicates to keep extracting keys until the last argument, <em>-2</em> until one before the last, and so on.</li>\n<li><strong>keystep:</strong> the number of arguments that should be skipped, after finding a key, to find the next one.</li>\n<li><strong>limit:</strong> if <em>lastkey</em> is has the value of <em>-1</em>, we use the <em>limit</em> to stop the search by a factor.<br>  <em>0</em> and <em>1</em> mean no limit.<br>  <em>2</em> means half of the remaining arguments, 3 means a third, and so on.</li>\n</ol>\n<h3>keynum</h3>\n<p>The <em>keynum</em> type of <code>find_keys</code> is a map under the <em>spec</em> key with three keys:</p>\n<ul>\n<li><strong>keynumidx:</strong> the index, relative to <code>begin_search</code>, of the argument containing the number of keys.</li>\n<li><strong>firstkey:</strong> the index, relative to <code>begin_search</code>, of the first key.<br>This is usually the next argument after <em>keynumidx</em>, and its value, in this case, is greater by one.</li>\n<li><strong>keystep:</strong> Tthe number of arguments that should be skipped, after finding a key, to find the next one.</li>\n</ul>\n<p>Examples:</p>\n<ul>\n<li>The <code>SET</code> command has a <em>range</em> of <em>0</em>, <em>1</em> and <em>0</em>.</li>\n<li>The <code>MSET</code> command has a <em>range</em> of <em>-1</em>, <em>2</em> and <em>0</em>.</li>\n<li>The <code>XREAD</code> command has a <em>range</em> of <em>-1</em>, <em>1</em> and <em>2</em>.</li>\n<li>The <code>ZUNION</code> command has a <em>start_search</em> type <em>index</em> with the value <em>1</em>, and <code>find_keys</code> of type <em>keynum</em> with values of <em>0</em>, <em>1</em> and <em>1</em>.</li>\n</ul>\n<p><strong>Note:</strong><br>this isn&#39;t a perfect solution as the module writers can come up with anything.<br>However, this mechanism should allow the extraction of key name arguments for the vast majority of commands.</p>\n<h2>notes</h2>\n<p>Notes about non-obvious key specs considerations, if applicable.</p>\n<h2>flags</h2>\n<p>A key specification can have additional flags that provide more details about the key.<br>These flags are divided into three groups, as described below.</p>\n<h3>Access type flags</h3>\n<p>The following flags declare the type of access the command uses to a key&#39;s value or its metadata.<br>A key&#39;s metadata includes LRU/LFU counters, type, and cardinality.<br>These flags do not relate to the reply sent back to the client.</p>\n<p>Every key specification has precisely one of the following flags:</p>\n<ul>\n<li><strong>RW:</strong> the read-write flag.<br>The command modifies the data stored in the value of the key or its metadata.<br>This flag marks every operation that isn&#39;t distinctly a delete, an overwrite, or read-only.</li>\n<li><strong>RO:</strong> the read-only flag.<br>The command only reads the value of the key (although it doesn&#39;t necessarily return it).</li>\n<li><strong>OW:</strong> the overwrite flag.<br>The command overwrites the data stored in the value of the key.</li>\n<li><strong>RM:</strong> the remove flag.<br>The command deletes the key.</li>\n</ul>\n<h3>Logical operation flags</h3>\n<p>The following flags declare the type of operations performed on the data stored as the key&#39;s value and its TTL (if any), not the metadata.<br>These flags describe the logical operation that the command executes on data, driven by the input arguments.<br>The flags do not relate to modifying or returning metadata (such as a key&#39;s type, cardinality, or existence).</p>\n<p>Every key specification may include the following flag:</p>\n<ul>\n<li><strong>access:</strong> the access flag.<br>This flag indicates that the command returns, copies, or somehow uses the user&#39;s data that&#39;s stored in the key.</li>\n</ul>\n<p>In addition, the specification may include precisely one of the following:</p>\n<ul>\n<li><strong>update:</strong> the update flag.<br>The command updates the data stored in the key&#39;s value.<br>The new value may depend on the old value.<br>This flag marks every operation that isn&#39;t distinctly an insert or a delete.</li>\n<li><strong>insert:</strong> the insert flag.<br>The command only adds data to the value; existing data isn&#39;t modified or deleted.</li>\n<li><strong>delete:</strong> the delete flag.<br>The command explicitly deletes data from the value stored at the key.</li>\n</ul>\n<h3>Miscellaneous flags</h3>\n<p>Key specifications may have the following flags:</p>\n<ul>\n<li><strong>not_key:</strong> this flag indicates that the specified argument isn&#39;t a key.<br>This argument is treated the same as a key when computing which slot a command should be assigned to for Valkey cluster.<br>For all other purposes this argument should not be considered a key.</li>\n<li><strong>incomplete:</strong> this flag is explained below.</li>\n<li><strong>variable_flags:</strong> this flag is explained below.</li>\n</ul>\n<h3>incomplete</h3>\n<p>Some commands feature exotic approaches when it comes to specifying their keys, which makes extraction difficult.<br>Consider, for example, what would happen with a call to <code>MIGRATE</code> that includes the literal string <em>&quot;KEYS&quot;</em> as an argument to its <em>AUTH</em> clause.<br>Our key specifications would miss the mark, and extraction would begin at the wrong index.</p>\n<p>Thus, we recognize that key specifications are incomplete and may fail to extract all keys.<br>However, we assure that even incomplete specifications never yield the wrong names of keys, providing that the command is syntactically correct.</p>\n<p>In the case of <code>MIGRATE</code>, the search begins at the end (<em>startfrom</em> has the value of <em>-1</em>).<br>If and when we encounter a key named <em>&quot;KEYS&quot;</em>, we&#39;ll only extract the subset of the key name arguments after it.<br>That&#39;s why <code>MIGRATE</code> has the <em>incomplete</em> flag in its key specification.</p>\n<p>Another case of incompleteness is the <code>SORT</code> command.<br>Here, the <code>begin_search</code> and <code>find_keys</code> are of type <em>unknown</em>.<br>The client should revert to calling the <code>COMMAND GETKEYS</code> command to extract key names from the arguments, short of implementing it natively.<br>The difficulty arises, for example, because the string <em>&quot;STORE&quot;</em> is both a keyword (token) and a valid literal argument for <code>SORT</code>.</p>\n<p><strong>Note:</strong><br>the only commands with <em>incomplete</em> key specifications are <code>SORT</code> and <code>MIGRATE</code>.<br>We don&#39;t expect the addition of such commands in the future.</p>\n<h3>variable_flags</h3>\n<p>In some commands, the flags for the same key name argument can depend on other arguments.<br>For example, consider the <code>SET</code> command and its optional  <em>GET</em> argument.<br>Without the <em>GET</em> argument, <code>SET</code> is write-only, but it becomes a read and write command with it.<br>When this flag is present, it means that the key specification flags cover all possible options, but the effective flags depend on other arguments.</p>\n<h2>Examples</h2>\n<h3><code>SET</code>&#39;s key specifications</h3>\n<pre><code>  1) 1) &quot;flags&quot;\n     2) 1) RW\n        2) access\n        3) update\n     3) &quot;begin_search&quot;\n     4) 1) &quot;type&quot;\n        2) &quot;index&quot;\n        3) &quot;spec&quot;\n        4) 1) &quot;index&quot;\n           2) (integer) 1\n     5) &quot;find_keys&quot;\n     6) 1) &quot;type&quot;\n        2) &quot;range&quot;\n        3) &quot;spec&quot;\n        4) 1) &quot;lastkey&quot;\n           2) (integer) 0\n           3) &quot;keystep&quot;\n           4) (integer) 1\n           5) &quot;limit&quot;\n           6) (integer) 0\n</code></pre>\n<h3><code>ZUNION</code>&#39;s key specifications</h3>\n<pre><code>  1) 1) &quot;flags&quot;\n     2) 1) RO\n        2) access\n     3) &quot;begin_search&quot;\n     4) 1) &quot;type&quot;\n        2) &quot;index&quot;\n        3) &quot;spec&quot;\n        4) 1) &quot;index&quot;\n           2) (integer) 1\n     5) &quot;find_keys&quot;\n     6) 1) &quot;type&quot;\n        2) &quot;keynum&quot;\n        3) &quot;spec&quot;\n        4) 1) &quot;keynumidx&quot;\n           2) (integer) 0\n           3) &quot;firstkey&quot;\n           4) (integer) 1\n           5) &quot;keystep&quot;\n           6) (integer) 1\n</code></pre>\n"
      },
      {
        "id": "keyspace",
        "topicName": "Keyspace",
        "description": "Managing keys in Valkey: Key expiration, scanning, altering and querying the key space\n",
        "htmlContent": "<p>Valkey keys are binary safe; this means that you can use any binary sequence as a<br>key, from a string like &quot;foo&quot; to the content of a JPEG file.<br>The empty string is also a valid key.</p>\n<p>A few other rules about keys: </p>\n<ul>\n<li>Very long keys are not a good idea. For instance a key of 1024 bytes is a bad<br>idea not only memory-wise, but also because the lookup of the key in the<br>dataset may require several costly key-comparisons. Even when the task at hand<br>is to match the existence of a large value, hashing it (for example<br>with SHA1) is a better idea, especially from the perspective of memory<br>and bandwidth.</li>\n<li>Very short keys are often not a good idea. There is little point in writing<br>&quot;u1000flw&quot; as a key if you can instead write &quot;user:1000:followers&quot;.  The latter<br>is more readable and the added space is minor compared to the space used by<br>the key object itself and the value object. While short keys will obviously<br>consume a bit less memory, your job is to find the right balance.</li>\n<li>Try to stick with a schema. For instance &quot;object-type:id&quot; is a good<br>idea, as in &quot;user:1000&quot;. Dots or dashes are often used for multi-word<br>fields, as in &quot;comment:4321:reply.to&quot; or &quot;comment:4321:reply-to&quot;.</li>\n<li>The maximum allowed key size is 512 MB.</li>\n</ul>\n<h2>Altering and querying the key space</h2>\n<p>There are commands that are not defined on particular types, but are useful<br>in order to interact with the space of keys, and thus, can be used with<br>keys of any type.</p>\n<p>For example the <code>EXISTS</code> command returns 1 or 0 to signal if a given key<br>exists or not in the database, while the <code>DEL</code> command deletes a key<br>and associated value, whatever the value is.</p>\n<pre><code>&gt; set mykey hello\nOK\n&gt; exists mykey\n(integer) 1\n&gt; del mykey\n(integer) 1\n&gt; exists mykey\n(integer) 0\n</code></pre>\n<p>From the examples you can also see how <code>DEL</code> itself returns 1 or 0 depending on whether<br>the key was removed (it existed) or not (there was no such key with that<br>name).</p>\n<p>There are many key space related commands, but the above two are the<br>essential ones together with the <code>TYPE</code> command, which returns the kind<br>of value stored at the specified key:</p>\n<pre><code>&gt; set mykey x\nOK\n&gt; type mykey\nstring\n&gt; del mykey\n(integer) 1\n&gt; type mykey\nnone\n</code></pre>\n<h2>Key expiration</h2>\n<p>Before moving on, we should look at an important Valkey feature that works regardless of the type of value you&#39;re storing: key expiration. Key expiration lets you set a timeout for a key, also known as a &quot;time to live&quot;, or &quot;TTL&quot;. When the time to live elapses, the key is automatically destroyed. </p>\n<p>A few important notes about key expiration:</p>\n<ul>\n<li>They can be set both using seconds or milliseconds precision.</li>\n<li>However the expire time resolution is always 1 millisecond.</li>\n<li>Information about expires are replicated and persisted on disk, the time virtually passes when your Valkey server remains stopped (this means that Valkey saves the date at which a key will expire).</li>\n</ul>\n<p>Use the <code>EXPIRE</code> command to set a key&#39;s expiration:</p>\n<pre><code>&gt; set key some-value\nOK\n&gt; expire key 5\n(integer) 1\n&gt; get key (immediately)\n&quot;some-value&quot;\n&gt; get key (after some time)\n(nil)\n</code></pre>\n<p>The key vanished between the two <code>GET</code> calls, since the second call was<br>delayed more than 5 seconds. In the example above we used <code>EXPIRE</code> in<br>order to set the expire (it can also be used in order to set a different<br>expire to a key already having one, like <code>PERSIST</code> can be used in order<br>to remove the expire and make the key persistent forever). However we<br>can also create keys with expires using other Valkey commands. For example<br>using <code>SET</code> options:</p>\n<pre><code>&gt; set key 100 ex 10\nOK\n&gt; ttl key\n(integer) 9\n</code></pre>\n<p>The example above sets a key with the string value <code>100</code>, having an expire<br>of ten seconds. Later the <code>TTL</code> command is called in order to check the<br>remaining time to live for the key.</p>\n<p>In order to set and check expires in milliseconds, check the <code>PEXPIRE</code> and<br>the <code>PTTL</code> commands, and the full list of <code>SET</code> options.</p>\n<h2>Navigating the keyspace</h2>\n<h3>Scan</h3>\n<p>To incrementally  iterate over the keys in a Valkey database in an efficient manner, you can use the <code>SCAN</code> command.</p>\n<p>Since <code>SCAN</code> allows for incremental iteration, returning only a small number of elements per call, it can be used in production without the downside of commands like <code>KEYS</code> or <code>SMEMBERS</code> that may block the server for a long time (even several seconds) when called against big collections of keys or elements.</p>\n<p>However while blocking commands like <code>SMEMBERS</code> are able to provide all the elements that are part of a Set in a given moment.<br>The <code>SCAN</code> family of commands only offer limited guarantees about the returned elements since the collection that we incrementally iterate can change during the iteration process.</p>\n<h3>Keys</h3>\n<p>Another way to iterate over the keyspace is to use the <code>KEYS</code> command, but this approach should be used with care, since <code>KEYS</code> will block the Valkey server until all keys are returned.</p>\n<p><strong>Warning</strong>: consider <code>KEYS</code> as a command that should only be used in production<br>environments with extreme care.</p>\n<p><code>KEYS</code> may ruin performance when it is executed against large databases.<br>This command is intended for debugging and special operations, such as changing<br>your keyspace layout.<br>Don&#39;t use <code>KEYS</code> in your regular application code.<br>If you&#39;re looking for a way to find keys in a subset of your keyspace, consider<br>using <code>SCAN</code> or <a href=\"data-types#sets\">sets</a>.</p>\n<p>Supported glob-style patterns:</p>\n<ul>\n<li><code>h?llo</code> matches <code>hello</code>, <code>hallo</code> and <code>hxllo</code></li>\n<li><code>h*llo</code> matches <code>hllo</code> and <code>heeeello</code></li>\n<li><code>h[ae]llo</code> matches <code>hello</code> and <code>hallo,</code> but not <code>hillo</code></li>\n<li><code>h[^e]llo</code> matches <code>hallo</code>, <code>hbllo</code>, ... but not <code>hello</code></li>\n<li><code>h[a-b]llo</code> matches <code>hallo</code> and <code>hbllo</code></li>\n</ul>\n<p>Use <code>\\</code> to escape special characters if you want to match them verbatim.</p>\n"
      },
      {
        "id": "server",
        "topicName": "The Valkey server",
        "description": "Manual for valkey-server, the Valkey server program\n",
        "htmlContent": "<h2>Usage</h2>\n<p><strong><code>valkey-server</code></strong> [ <em>/path/to/valkey.conf</em> ] [ <em>OPTIONS</em> ] [<strong><code>-</code></strong>]<br><strong><code>valkey-server</code></strong> <strong><code>-v</code></strong> | <strong><code>--version</code></strong><br><strong><code>valkey-server</code></strong> <strong><code>-h</code></strong> | <strong><code>--help</code></strong><br><strong><code>valkey-server</code></strong> <strong><code>--test-memory</code></strong> <em>megabytes</em><br><strong><code>valkey-server</code></strong> <strong><code>--check-system</code></strong></p>\n<h2>Description</h2>\n<p><code>valkey-server</code> is the Valkey database program.</p>\n<p>What is Valkey? See <a href=\"introduction\">Introduction</a>.</p>\n<h2>Options</h2>\n<p>The configuration file and the configuration directives are documented in<br><a href=\"valkey.conf\">Configuration</a>. Use <code>-</code> to read configuration from stdin.</p>\n<p>Each of the configuration directives can be provided on the command line<br>with its name prefixed by two dashes. For example, <code>--port 6380</code> on the command<br>line is equivalent to <code>port 6380</code> in the config file.</p>\n<p>Additional options:</p>\n<p><strong><code>-v</code></strong>, <strong><code>--version</code></strong><br>: Output version and exit.</p>\n<p><strong><code>-h</code></strong>, <strong><code>--help</code></strong><br>: Output help and exit.</p>\n<p><strong><code>--test-memory</code></strong> <em>megabytes</em><br>: Run a memory test and exit.</p>\n<p><strong><code>--check-sytem</code></strong><br>: Output some operating system properties relevant for running Valkey and exit.</p>\n<p><strong><code>--sentinel</code></strong><br>: Start in <a href=\"sentinel\">sentinel</a> mode</p>\n<h2>Examples</h2>\n<p>Run the server with default config:</p>\n<pre><code>valkey-server\n</code></pre>\n<p>Read configuration from stdin:</p>\n<pre><code>echo &#39;maxmemory 128mb&#39; | valkey-server -\n</code></pre>\n<p>Start with a configuration file:</p>\n<pre><code>valkey-server /etc/valkey/6379.conf\n</code></pre>\n<p>Start with configuration as command line options:</p>\n<pre><code>valkey-server --port 7777\n</code></pre>\n<p>Start as a replica of another Valkey server that can accessed at 127.0.0.1:8888:</p>\n<pre><code>valkey-server --port 7777 --replicaof 127.0.0.1 8888\n</code></pre>\n<p>Start with a config file, then some additional options overriding the ones in<br>the config file, and finally some more options from stdin:</p>\n<pre><code>valkey-server /etc/myvalkey.conf --loglevel verbose -\n</code></pre>\n<p>Start with a config file and some additional options overriding the ones in<br>the config file:</p>\n<pre><code>valkey-server /etc/myvalkey.conf --loglevel verbose\n</code></pre>\n<h2>See also</h2>\n<p><a href=\"./\">Valkey documentation</a>, <a href=\"introduction\">Introduction</a>, <a href=\"valkey.conf\">Configuration</a>, <a href=\"installation\">Installation</a>, <a href=\"cli\">valkey-cli</a></p>\n"
      },
      {
        "id": "valkey.conf",
        "topicName": "Configuration",
        "description": "Overview of valkey.conf, the Valkey configuration file\n",
        "htmlContent": "<p>Valkey is able to start without a configuration file using a built-in default<br>configuration, however this setup is only recommended for testing and<br>development purposes.</p>\n<p>The proper way to configure Valkey is by providing a Valkey configuration file,<br>usually called <code>valkey.conf</code>.</p>\n<p>The <code>valkey.conf</code> file contains a number of directives that have a very simple<br>format:</p>\n<pre><code>keyword argument1 argument2 ... argumentN\n</code></pre>\n<p>This is an example of a configuration directive:</p>\n<pre><code>replicaof 127.0.0.1 6380\n</code></pre>\n<p>It is possible to provide strings containing spaces as arguments using<br>(double or single) quotes, as in the following example:</p>\n<pre><code>requirepass &quot;hello world&quot;\n</code></pre>\n<p>Single-quoted string can contain characters escaped by backslashes, and<br>double-quoted strings can additionally include any ASCII symbols encoded using<br>backslashed hexadecimal notation &quot;\\xff&quot;.</p>\n<p>The list of configuration directives, and their meaning and intended usage<br>is available in the self documented example valkey.conf shipped into the<br>Valkey distribution.</p>\n<ul>\n<li>The self documented <a href=\"https://raw.githubusercontent.com/valkey-io/valkey/7.2/valkey.conf\">valkey.conf for Valkey OSS 7.2</a>.</li>\n<li>The self documented <a href=\"https://raw.githubusercontent.com/redis/redis/7.2/redis.conf\">redis.conf for Redis OSS 7.2</a>.</li>\n<li>The self documented <a href=\"https://raw.githubusercontent.com/redis/redis/7.0/redis.conf\">redis.conf for Redis OSS 7.0</a>.</li>\n<li>The self documented <a href=\"https://raw.githubusercontent.com/redis/redis/6.2/redis.conf\">redis.conf for Redis OSS 6.2</a>.</li>\n</ul>\n<h2>Passing arguments via the command line</h2>\n<p>You can also pass Valkey configuration parameters<br>using the command line directly. This is very useful for testing purposes.<br>The following is an example that starts a new Valkey instance using port 6380<br>as a replica of the instance running at 127.0.0.1 port 6379.</p>\n<pre><code>./valkey-server --port 6380 --replicaof 127.0.0.1 6379\n</code></pre>\n<p>The format of the arguments passed via the command line is exactly the same<br>as the one used in the valkey.conf file, with the exception that the keyword<br>is prefixed with <code>--</code>.</p>\n<p>Note that internally this generates an in-memory temporary config file<br>(possibly concatenating the config file passed by the user, if any) where<br>arguments are translated into the format of valkey.conf.</p>\n<h2>Changing Valkey configuration while the server is running</h2>\n<p>It is possible to reconfigure Valkey on the fly without stopping and restarting<br>the service, or querying the current configuration programmatically using the<br>special commands <code>CONFIG SET</code> and <code>CONFIG GET</code>.</p>\n<p>Not all of the configuration directives are supported in this way, but most<br>are supported as expected.<br>Please refer to the <code>CONFIG SET</code> and <code>CONFIG GET</code> pages for more information.</p>\n<p>Note that modifying the configuration on the fly <strong>has no effects on the<br>valkey.conf file</strong> so at the next restart of Valkey the old configuration will<br>be used instead.</p>\n<p>Make sure to also modify the <code>valkey.conf</code> file accordingly to the configuration<br>you set using <code>CONFIG SET</code>.<br>You can do it manually, or you can use <code>CONFIG REWRITE</code>, which will automatically scan your <code>valkey.conf</code> file and update the fields which don&#39;t match the current configuration value.<br>Fields non existing but set to the default value are not added.<br>Comments inside your configuration file are retained.</p>\n<h2>Configuring Valkey as a cache</h2>\n<p>If you plan to use Valkey as a cache where every key will have an<br>expire set, you may consider using the following configuration instead<br>(assuming a max memory limit of 2 megabytes as an example):</p>\n<pre><code>maxmemory 2mb\nmaxmemory-policy allkeys-lru\n</code></pre>\n<p>In this configuration there is no need for the application to set a<br>time to live for keys using the <code>EXPIRE</code> command (or equivalent) since<br>all the keys will be evicted using an approximated LRU algorithm as long<br>as we hit the 2 megabyte memory limit.</p>\n<p>Basically, in this configuration Valkey acts in a similar way to memcached.<br>We have more extensive documentation about using Valkey as an LRU cache <a href=\"lru-cache\">here</a>.</p>\n"
      }
    ]
  },
  {
    "title": "CLIENT HANDLING",
    "items": [
      {
        "id": "client-side-caching",
        "topicName": "Client-side caching",
        "description": "Server-assisted, client-side caching in Valkey\n",
        "htmlContent": "<p>Client-side caching is a technique used to create high performance services.<br>It exploits the memory available on application servers, servers that are<br>usually distinct computers compared to the Valkey nodes, to store some subset<br>of the Valkey information directly in the application side.</p>\n<p>Normally when data is required, the application servers ask the Valkey about<br>such information, like in the following diagram:</p>\n<pre><code>+-------------+                                +----------+\n|             | ------- GET user:1234 -------&gt; |          |\n| Application |                                |  Valkey  |\n|             | &lt;---- username = Alice ------- |          |\n+-------------+                                +----------+\n</code></pre>\n<p>When client-side caching is used, the application will store the reply of<br>popular queries directly inside the application memory, so that it can<br>reuse such replies later, without contacting the Valkey again:</p>\n<pre><code>+-------------+                                +----------+\n|             |                                |          |\n| Application |       ( No chat needed )       |  Valkey  |\n|             |                                |          |\n+-------------+                                +----------+\n| Local cache |\n|             |\n| user:1234 = |\n| username    |\n| Alice       |\n+-------------+\n</code></pre>\n<p>While the application memory used for the local cache may not be very big,<br>the time needed in order to access the local computer memory is orders of<br>magnitude smaller compared to accessing a networked service like a Valkey.<br>Since often the same small percentage of data are accessed frequently,<br>this pattern can greatly reduce the latency for the application to get data<br>and, at the same time, the load in the Valkey side.</p>\n<p>Moreover there are many datasets where items change very infrequently.<br>For instance, most user posts in a social network are either immutable or<br>rarely edited by the user. Adding to this the fact that usually a small<br>percentage of the posts are very popular, either because a small set of users<br>have a lot of followers and/or because recent posts have a lot more<br>visibility, it is clear why such a pattern can be very useful.</p>\n<p>Usually the two key advantages of client-side caching are:</p>\n<ol>\n<li>Data is available with a very small latency.</li>\n<li>The Valkey system receives less queries, allowing it to serve the same dataset with a smaller number of nodes.</li>\n</ol>\n<h2>There are two hard problems in computer science...</h2>\n<p>A problem with the above pattern is how to invalidate the information that<br>the application is holding, in order to avoid presenting stale data to the<br>user. For example after the application above locally cached the information<br>for user:1234, Alice may update her username to Flora. Yet the application<br>may continue to serve the old username for user:1234.</p>\n<p>Sometimes, depending on the exact application we are modeling, this isn&#39;t a<br>big deal, so the client will just use a fixed maximum &quot;time to live&quot; for the<br>cached information. Once a given amount of time has elapsed, the information<br>will no longer be considered valid. More complex patterns, when using Valkey,<br>leverage the Pub/Sub system in order to send invalidation messages to<br>listening clients. This can be made to work but is tricky and costly from<br>the point of view of the bandwidth used, because often such patterns involve<br>sending the invalidation messages to every client in the application, even<br>if certain clients may not have any copy of the invalidated data. Moreover<br>every application query altering the data requires to use the <code>PUBLISH</code><br>command, costing the Valkey more CPU time to process this command.</p>\n<p>Regardless of what schema is used, there is a simple fact: many very large<br>applications implement some form of client-side caching, because it is the<br>next logical step to having a fast store or a fast cache server. For this<br>reason Valkey implements direct support for client-side caching, in order<br>to make this pattern much simpler to implement, more accessible, reliable,<br>and efficient.</p>\n<h2>The Valkey implementation of client-side caching</h2>\n<p>The Valkey client-side caching support is called <em>Tracking</em>, and has two modes:</p>\n<ul>\n<li>In the default mode, the server remembers what keys a given client accessed, and sends invalidation messages when the same keys are modified. This costs memory in the server side, but sends invalidation messages only for the set of keys that the client might have in memory.</li>\n<li>In the <em>broadcasting</em> mode, the server does not attempt to remember what keys a given client accessed, so this mode costs no memory at all in the server side. Instead clients subscribe to key prefixes such as <code>object:</code> or <code>user:</code>, and receive a notification message every time a key matching a subscribed prefix is touched.</li>\n</ul>\n<p>To recap, for now let&#39;s forget for a moment about the broadcasting mode, to<br>focus on the first mode. We&#39;ll describe broadcasting in more detail later.</p>\n<ol>\n<li>Clients can enable tracking if they want. Connections start without tracking enabled.</li>\n<li>When tracking is enabled, the server remembers what keys each client requested during the connection lifetime (by sending read commands about such keys).</li>\n<li>When a key is modified by some client, or is evicted because it has an associated expire time, or evicted because of a <em>maxmemory</em> policy, all the clients with tracking enabled that may have the key cached, are notified with an <em>invalidation message</em>.</li>\n<li>When clients receive invalidation messages, they are required to remove the corresponding keys, in order to avoid serving stale data.</li>\n</ol>\n<p>This is an example of the protocol:</p>\n<ul>\n<li>Client 1 <code>-&gt;</code> Server: CLIENT TRACKING ON</li>\n<li>Client 1 <code>-&gt;</code> Server: GET foo</li>\n<li>(The server remembers that Client 1 may have the key &quot;foo&quot; cached)</li>\n<li>(Client 1 may remember the value of &quot;foo&quot; inside its local memory)</li>\n<li>Client 2 <code>-&gt;</code> Server: SET foo SomeOtherValue</li>\n<li>Server <code>-&gt;</code> Client 1: INVALIDATE &quot;foo&quot;</li>\n</ul>\n<p>This looks great superficially, but if you imagine 10k connected clients all<br>asking for millions of keys over long living connection, the server ends up<br>storing too much information. For this reason Valkey uses two key ideas in<br>order to limit the amount of memory used server-side and the CPU cost of<br>handling the data structures implementing the feature:</p>\n<ul>\n<li>The server remembers the list of clients that may have cached a given key in a single global table. This table is called the <strong>Invalidation Table</strong>. The invalidation table can contain a maximum number of entries. If a new key is inserted, the server may evict an older entry by pretending that such key was modified (even if it was not), and sending an invalidation message to the clients. Doing so, it can reclaim the memory used for this key, even if this will force the clients having a local copy of the key to evict it.</li>\n<li>Inside the invalidation table we don&#39;t really need to store pointers to clients&#39; structures, that would force a garbage collection procedure when the client disconnects: instead what we do is just store client IDs (each Valkey client has a unique numerical ID). If a client disconnects, the information will be incrementally garbage collected as caching slots are invalidated.</li>\n<li>There is a single keys namespace, not divided by Valkey numbers. So if a client is caching the key <code>foo</code> in Valkey 2, and some other client changes the value of the key <code>foo</code> in Valkey 3, an invalidation message will still be sent. This way we can ignore Valkey numbers reducing both the memory usage and the implementation complexity.</li>\n</ul>\n<h2>Two connections mode</h2>\n<p>Using the new version of the Valkey protocol, RESP3, it is possible to run the data queries and receive the invalidation messages in the same connection. However many client implementations may prefer to implement client-side caching using two separated connections: one for data, and one for invalidation messages. For this reason when a client enables tracking, it can specify to redirect the invalidation messages to another connection by specifying the &quot;client ID&quot; of a different connection. Many data connections can redirect invalidation messages to the same connection, this is useful for clients implementing connection pooling. The two connections model is the only one that is also supported for RESP2 (which lacks the ability to multiplex different kind of information in the same connection).</p>\n<p>Here&#39;s an example of a complete session using the Valkey protocol in the old RESP2 mode involving the following steps: enabling tracking redirecting to another connection, asking for a key, and getting an invalidation message once the key gets modified.</p>\n<p>To start, the client opens a first connection that will be used for invalidations, requests the connection ID, and subscribes via Pub/Sub to the special channel that is used to get invalidation messages when in RESP2 modes (remember that RESP2 is the usual Valkey protocol, and not the more advanced protocol that you can use, optionally, using the <code>HELLO</code> command):</p>\n<pre><code>(Connection 1 -- used for invalidations)\nCLIENT ID\n:4\nSUBSCRIBE __redis__:invalidate\n*3\n$9\nsubscribe\n$20\n__redis__:invalidate\n:1\n</code></pre>\n<p>Now we can enable tracking from the data connection:</p>\n<pre><code>(Connection 2 -- data connection)\nCLIENT TRACKING on REDIRECT 4\n+OK\n\nGET foo\n$3\nbar\n</code></pre>\n<p>The client may decide to cache <code>&quot;foo&quot; =&gt; &quot;bar&quot;</code> in the local memory.</p>\n<p>A different client will now modify the value of the &quot;foo&quot; key:</p>\n<pre><code>(Some other unrelated connection)\nSET foo bar\n+OK\n</code></pre>\n<p>As a result, the invalidations connection will receive a message that invalidates the specified key.</p>\n<pre><code>(Connection 1 -- used for invalidations)\n*3\n$7\nmessage\n$20\n__redis__:invalidate\n*1\n$3\nfoo\n</code></pre>\n<p>The client will check if there are cached keys in this caching slot, and will evict the information that is no longer valid.</p>\n<p>Note that the third element of the Pub/Sub message is not a single key but<br>is a Valkey array with just a single element. Since we send an array, if there<br>are groups of keys to invalidate, we can do that in a single message.<br>In case of a flush (<code>FLUSHALL</code> or <code>FLUSHDB</code>), a <code>null</code> message will be sent.</p>\n<p>A very important thing to understand about client-side caching used with<br>RESP2 and a Pub/Sub connection in order to read the invalidation messages,<br>is that using Pub/Sub is entirely a trick <strong>in order to reuse old client<br>implementations</strong>, but actually the message is not really sent to a channel<br>and received by all the clients subscribed to it. Only the connection we<br>specified in the <code>REDIRECT</code> argument of the <code>CLIENT</code> command will actually<br>receive the Pub/Sub message, making the feature a lot more scalable.</p>\n<p>When RESP3 is used instead, invalidation messages are sent (either in the<br>same connection, or in the secondary connection when redirection is used)<br>as <code>push</code> messages (read the RESP3 specification for more information).</p>\n<h2>What tracking tracks</h2>\n<p>As you can see clients do not need, by default, to tell the server what keys<br>they are caching. Every key that is mentioned in the context of a read-only<br>command is tracked by the server, because it <em>could be cached</em>.</p>\n<p>This has the obvious advantage of not requiring the client to tell the server<br>what it is caching. Moreover in many clients implementations, this is what<br>you want, because a good solution could be to just cache everything that is not<br>already cached, using a first-in first-out approach: we may want to cache a<br>fixed number of objects, every new data we retrieve, we could cache it,<br>discarding the oldest cached object. More advanced implementations may instead<br>drop the least used object or alike.</p>\n<p>Note that anyway if there is write traffic on the server, caching slots<br>will get invalidated during the course of the time. In general when the<br>server assumes that what we get we also cache, we are making a tradeoff:</p>\n<ol>\n<li>It is more efficient when the client tends to cache many things with a policy that welcomes new objects.</li>\n<li>The server will be forced to retain more data about the client keys.</li>\n<li>The client will receive useless invalidation messages about objects it did not cache.</li>\n</ol>\n<p>So there is an alternative described in the next section.</p>\n<h2>Opt-in caching</h2>\n<p>Clients implementations may want to cache only selected keys, and communicate<br>explicitly to the server what they&#39;ll cache and what they will not. This will<br>require more bandwidth when caching new objects, but at the same time reduces<br>the amount of data that the server has to remember and the amount of<br>invalidation messages received by the client.</p>\n<p>In order to do this, tracking must be enabled using the OPTIN option:</p>\n<pre><code>CLIENT TRACKING on REDIRECT 1234 OPTIN\n</code></pre>\n<p>In this mode, by default, keys mentioned in read queries <em>are not supposed to be cached</em>, instead when a client wants to cache something, it must send a special command immediately before the actual command to retrieve the data:</p>\n<pre><code>CLIENT CACHING YES\n+OK\nGET foo\n&quot;bar&quot;\n</code></pre>\n<p>The <code>CACHING</code> command affects the command executed immediately after it,<br>however in case the next command is <code>MULTI</code>, all the commands in the<br>transaction will be tracked. Similarly in case of Lua scripts, all the<br>commands executed by the script will be tracked.</p>\n<h2>Broadcasting mode</h2>\n<p>So far we described the first client-side caching model that Valkey implements.<br>There is another one, called broadcasting, that sees the problem from the<br>point of view of a different tradeoff, does not consume any memory on the<br>server side, but instead sends more invalidation messages to clients.<br>In this mode we have the following main behaviors:</p>\n<ul>\n<li>Clients enable client-side caching using the <code>BCAST</code> option, specifying one or more prefixes using the <code>PREFIX</code> option. For instance: <code>CLIENT TRACKING on REDIRECT 10 BCAST PREFIX object: PREFIX user:</code>. If no prefix is specified at all, the prefix is assumed to be the empty string, so the client will receive invalidation messages for every key that gets modified. Instead if one or more prefixes are used, only keys matching one of the specified prefixes will be sent in the invalidation messages.</li>\n<li>The server does not store anything in the invalidation table. Instead it uses a different <strong>Prefixes Table</strong>, where each prefix is associated to a list of clients.</li>\n<li>No two prefixes can track overlapping parts of the keyspace. For instance, having the prefix &quot;foo&quot; and &quot;foob&quot; would not be allowed, since they would both trigger an invalidation for the key &quot;foobar&quot;. However, just using the prefix &quot;foo&quot; is sufficient.</li>\n<li>Every time a key matching any of the prefixes is modified, all the clients subscribed to that prefix, will receive the invalidation message.</li>\n<li>The server will consume CPU proportional to the number of registered prefixes. If you have just a few, it is hard to see any difference. With a big number of prefixes the CPU cost can become quite large.</li>\n<li>In this mode the server can perform the optimization of creating a single reply for all the clients subscribed to a given prefix, and send the same reply to all. This helps to lower the CPU usage.</li>\n</ul>\n<h2>The NOLOOP option</h2>\n<p>By default client-side tracking will send invalidation messages to the<br>client that modified the key. Sometimes clients want this, since they<br>implement very basic logic that does not involve automatically caching<br>writes locally. However, more advanced clients may want to cache even the<br>writes they are doing in the local in-memory table. In such case receiving<br>an invalidation message immediately after the write is a problem, since it<br>will force the client to evict the value it just cached.</p>\n<p>In this case it is possible to use the <code>NOLOOP</code> option: it works both<br>in normal and broadcasting mode. Using this option, clients are able to<br>tell the server they don&#39;t want to receive invalidation messages for keys<br>that they modified.</p>\n<h2>Avoiding race conditions</h2>\n<p>When implementing client-side caching redirecting the invalidation messages<br>to a different connection, you should be aware that there is a possible<br>race condition. See the following example interaction, where we&#39;ll call<br>the data connection &quot;D&quot; and the invalidation connection &quot;I&quot;:</p>\n<pre><code>[D] client -&gt; server: GET foo\n[I] server -&gt; client: Invalidate foo (somebody else touched it)\n[D] server -&gt; client: &quot;bar&quot; (the reply of &quot;GET foo&quot;)\n</code></pre>\n<p>As you can see, because the reply to the GET was slower to reach the<br>client, we received the invalidation message before the actual data that<br>is already no longer valid. So we&#39;ll keep serving a stale version of the<br>foo key. To avoid this problem, it is a good idea to populate the cache<br>when we send the command with a placeholder:</p>\n<pre><code>Client cache: set the local copy of &quot;foo&quot; to &quot;caching-in-progress&quot;\n[D] client-&gt; server: GET foo.\n[I] server -&gt; client: Invalidate foo (somebody else touched it)\nClient cache: delete &quot;foo&quot; from the local cache.\n[D] server -&gt; client: &quot;bar&quot; (the reply of &quot;GET foo&quot;)\nClient cache: don&#39;t set &quot;bar&quot; since the entry for &quot;foo&quot; is missing.\n</code></pre>\n<p>Such a race condition is not possible when using a single connection for both<br>data and invalidation messages, since the order of the messages is always known<br>in that case.</p>\n<h2>What to do when losing connection with the server</h2>\n<p>Similarly, if we lost the connection with the socket we use in order to<br>get the invalidation messages, we may end with stale data. In order to avoid<br>this problem, we need to do the following things:</p>\n<ol>\n<li>Make sure that if the connection is lost, the local cache is flushed.</li>\n<li>Both when using RESP2 with Pub/Sub, or RESP3, ping the invalidation channel periodically (you can send PING commands even when the connection is in Pub/Sub mode!). If the connection looks broken and we are not able to receive ping backs, after a maximum amount of time, close the connection and flush the cache.</li>\n</ol>\n<h2>What to cache</h2>\n<p>Clients may want to run internal statistics about the number of times<br>a given cached key was actually served in a request, to understand in the<br>future what is good to cache. In general:</p>\n<ul>\n<li>We don&#39;t want to cache many keys that change continuously.</li>\n<li>We don&#39;t want to cache many keys that are requested very rarely.</li>\n<li>We want to cache keys that are requested often and change at a reasonable rate. For an example of key not changing at a reasonable rate, think of a global counter that is continuously <code>INCR</code>emented.</li>\n</ul>\n<p>However simpler clients may just evict data using some random sampling just<br>remembering the last time a given cached value was served, trying to evict<br>keys that were not served recently.</p>\n<h2>Other hints for implementing client libraries</h2>\n<ul>\n<li>Handling TTLs: make sure you also request the key TTL and set the TTL in the local cache if you want to support caching keys with a TTL.</li>\n<li>Putting a max TTL on every key is a good idea, even if it has no TTL. This protects against bugs or connection issues that would make the client have old data in the local copy.</li>\n<li>Limiting the amount of memory used by clients is absolutely needed. There must be a way to evict old keys when new ones are added.</li>\n</ul>\n<h2>Limiting the amount of memory used by Valkey</h2>\n<p>Be sure to configure a suitable value for the maximum number of keys remembered by Valkey or alternatively use the BCAST mode that consumes no memory at all on the Valkey side. Note that the memory consumed by Valkey when BCAST is not used, is proportional both to the number of keys tracked and the number of clients requesting such keys.</p>\n"
      },
      {
        "id": "clients",
        "topicName": "Client handling",
        "description": "How the Valkey server manages client connections\n",
        "htmlContent": "<p>This document provides information about how Valkey handles clients at the network layer level: connections, timeouts, buffers, and other similar topics are covered here.</p>\n<h2>Accepting Client Connections</h2>\n<p>Valkey accepts clients connections on the configured TCP port and on the Unix socket if enabled. When a new client connection is accepted the following operations are performed:</p>\n<ul>\n<li>The client socket is put in the non-blocking state since Valkey uses multiplexing and non-blocking I/O.</li>\n<li>The <code>TCP_NODELAY</code> option is set in order to ensure that there are no delays to the connection.</li>\n<li>A <em>readable</em> file event is created so that Valkey is able to collect the client queries as soon as new data is available to read on the socket.</li>\n</ul>\n<p>After the client is initialized, Valkey checks if it is already at the limit<br>configured for the number of simultaneous clients (configured using the <code>maxclients</code> configuration directive, see the next section of this document for further information).</p>\n<p>When Valkey can&#39;t accept a new client connection because the maximum number of clients<br>has been reached, it tries to send an error to the client in order to<br>make it aware of this condition, closing the connection immediately.<br>The error message will reach the client even if the connection is<br>closed immediately by Valkey because the new socket output buffer is usually<br>big enough to contain the error, so the kernel will handle transmission<br>of the error.</p>\n<h2>What Order are Client Requests Served In?</h2>\n<p>The order is determined by a combination of the client socket file descriptor<br>number and order in which the kernel reports events, so the order should be<br>considered as unspecified.</p>\n<p>However, Valkey does the following two things when serving clients:</p>\n<ul>\n<li>It only performs a single <code>read()</code> system call every time there is something new to read from the client socket. This ensures that if we have multiple clients connected, and a few send queries at a high rate, other clients are not penalized and will not experience latency issues.</li>\n<li>However once new data is read from a client, all the queries contained in the current buffers are processed sequentially. This improves locality and does not need iterating a second time to see if there are clients that need some processing time.</li>\n</ul>\n<h2>Maximum Concurrent Connected Clients</h2>\n<p>The limit for the maximum number of clients that can be handled simultaneously<br>is configurable using the <code>maxclients</code> directive in <code>valkey.conf</code>. The default<br>is 10,000 clients.</p>\n<p>However, Valkey checks with the kernel what the maximum number of file<br>descriptors that we are able to open is (the <em>soft limit</em> is checked). If the<br>limit is less than the maximum number of clients we want to handle, plus<br>32 (that is the number of file descriptors Valkey reserves for internal uses),<br>then the maximum number of clients is updated to match the number<br>of clients it is <em>really able to handle</em> under the current operating system<br>limit.</p>\n<p>When <code>maxclients</code> is set to a number greater than Valkey can support, a message is logged at startup:</p>\n<pre><code>$ ./valkey-server --maxclients 100000\n[41422] 23 Jan 11:28:33.179 # Unable to set the max number of files limit to 100032 (Invalid argument), setting the max clients configuration to 10112.\n</code></pre>\n<p>When Valkey is configured in order to handle a specific number of clients it<br>is a good idea to make sure that the operating system limit for the maximum<br>number of file descriptors per process is also set accordingly.</p>\n<p>Under Linux these limits can be set both in the current session and as a<br>system-wide setting with the following commands:</p>\n<ul>\n<li><code>ulimit -Sn 100000 # This will only work if hard limit is big enough.</code></li>\n<li><code>sysctl -w fs.file-max=100000</code></li>\n</ul>\n<h2>Output Buffer Limits</h2>\n<p>Valkey needs to handle a variable-length output buffer for every client, since<br>a command can produce a large amount of data that needs to be transferred to the<br>client.</p>\n<p>However it is possible that a client sends more commands producing more output<br>to serve at a faster rate than that which Valkey can send the existing output to the<br>client. This is especially true with Pub/Sub clients in case a client is not<br>able to process new messages fast enough.</p>\n<p>Both conditions will cause the client output buffer to grow and consume<br>more and more memory. For this reason by default Sets limits to the<br>output buffer size for different kind of clients. When the limit is reached<br>the client connection is closed and the event logged in the Valkey log file.</p>\n<p>There are two kind of limits Valkey uses:</p>\n<ul>\n<li>The <strong>hard limit</strong> is a fixed limit that when reached will make Valkey close the client connection as soon as possible.</li>\n<li>The <strong>soft limit</strong> instead is a limit that depends on the time, for instance a soft limit of 32 megabytes per 10 seconds means that if the client has an output buffer bigger than 32 megabytes for, continuously, 10 seconds, the connection gets closed.</li>\n</ul>\n<p>Different kind of clients have different default limits:</p>\n<ul>\n<li><strong>Normal clients</strong> have a default limit of 0, that means, no limit at all, because most normal clients use blocking implementations sending a single command and waiting for the reply to be completely read before sending the next command, so it is always not desirable to close the connection in case of a normal client.</li>\n<li><strong>Pub/Sub clients</strong> have a default hard limit of 32 megabytes and a soft limit of 8 megabytes per 60 seconds.</li>\n<li><strong>Replicas</strong> have a default hard limit of 256 megabytes and a soft limit of 64 megabyte per 60 seconds.</li>\n</ul>\n<p>It is possible to change the limit at runtime using the <code>CONFIG SET</code> command or in a permanent way using the Valkey configuration file <code>valkey.conf</code>. See the example <code>valkey.conf</code> in the Valkey distribution for more information about how to set the limit.</p>\n<h2>Query Buffer Hard Limit</h2>\n<p>Every client is also subject to a query buffer limit. This is a non-configurable hard limit that will close the connection when the client query buffer (that is the buffer we use to accumulate commands from the client) reaches 1 GB, and is actually only an extreme limit to avoid a server crash in case of client or server software bugs.</p>\n<h2>Client Eviction</h2>\n<p>Valkey is built to handle a very large number of client connections.<br>Client connections tend to consume memory, and when there are many of them, the aggregate memory consumption can be extremely high, leading to data eviction or out-of-memory errors.<br>These cases can be mitigated to an extent using <a href=\"#output-buffer-limits\">output buffer limits</a>, but Valkey allows us a more robust configuration to limit the aggregate memory used by all clients&#39; connections.</p>\n<p>This mechanism is called <strong>client eviction</strong>, and it&#39;s essentially a safety mechanism that will disconnect clients once the aggregate memory usage of all clients is above a threshold.<br>The mechanism first attempts to disconnect clients that use the most memory.<br>It disconnects the minimal number of clients needed to return below the <code>maxmemory-clients</code> threshold.</p>\n<p><code>maxmemory-clients</code> defines the maximum aggregate memory usage of all clients connected to Valkey.<br>The aggregation takes into account all the memory used by the client connections: the <a href=\"#query-buffer-hard-limit\">query buffer</a>, the output buffer, and other intermediate buffers.</p>\n<p>Note that replica and primary connections aren&#39;t affected by the client eviction mechanism. Therefore, such connections are never evicted.</p>\n<p><code>maxmemory-clients</code> can be set permanently in the configuration file (<code>valkey.conf</code>) or via the <code>CONFIG SET</code> command.<br>This setting can either be 0 (meaning no limit), a size in bytes (possibly with <code>mb</code>/<code>gb</code> suffix),<br>or a percentage of <code>maxmemory</code> by using the <code>%</code> suffix (e.g. setting it to <code>10%</code> would mean 10% of the <code>maxmemory</code> configuration).</p>\n<p>The default setting is 0, meaning client eviction is turned off by default.<br>However, for any large production deployment, it is highly recommended to configure some non-zero <code>maxmemory-clients</code> value.<br>A value <code>5%</code>, for example, can be a good place to start.</p>\n<p>It is possible to flag a specific client connection to be excluded from the client eviction mechanism.<br>This is useful for control path connections.<br>If, for example, you have an application that monitors the server via the <code>INFO</code> command and alerts you in case of a problem, you might want to make sure this connection isn&#39;t evicted.<br>You can do so using the following command (from the relevant client&#39;s connection):</p>\n<p><code>CLIENT NO-EVICT</code> <code>on</code></p>\n<p>And you can revert that with:</p>\n<p><code>CLIENT NO-EVICT</code> <code>off</code></p>\n<p>For more information and an example refer to the <code>maxmemory-clients</code> section in the default <code>valkey.conf</code> file.</p>\n<p>Client eviction is available from Redis OSS 7.0.</p>\n<h2>Client Timeouts</h2>\n<p>By default recent versions of Valkey don&#39;t close the connection with the client<br>if the client is idle for many seconds: the connection will remain open forever.</p>\n<p>However if you don&#39;t like this behavior, you can configure a timeout, so that<br>if the client is idle for more than the specified number of seconds, the client connection will be closed.</p>\n<p>You can configure this limit via <code>valkey.conf</code> or simply using <code>CONFIG SET timeout &lt;value&gt;</code>.</p>\n<p>Note that the timeout only applies to normal clients and it <strong>does not apply to Pub/Sub clients</strong>, since a Pub/Sub connection is a <em>push style</em> connection so a client that is idle is the norm.</p>\n<p>Even if by default connections are not subject to timeout, there are two conditions when it makes sense to set a timeout:</p>\n<ul>\n<li>Mission critical applications where a bug in the client software may saturate the Valkey server with idle connections, causing service disruption.</li>\n<li>As a debugging mechanism in order to be able to connect with the server if a bug in the client software saturates the server with idle connections, making it impossible to interact with the server.</li>\n</ul>\n<p>Timeouts are not to be considered very precise: Valkey avoids setting timer events or running O(N) algorithms in order to check idle clients, so the check is performed incrementally from time to time. This means that it is possible that while the timeout is set to 10 seconds, the client connection will be closed, for instance, after 12 seconds if many clients are connected at the same time.</p>\n<h2>The CLIENT Command</h2>\n<p>The Valkey <code>CLIENT</code> command allows you to inspect the state of every connected client, to kill a specific client, and to name connections. It is a very powerful debugging tool if you use Valkey at scale.</p>\n<p><code>CLIENT LIST</code> is used in order to obtain a list of connected clients and their state:</p>\n<pre><code>127.0.0.1:6379&gt; client list\naddr=127.0.0.1:52555 fd=5 name= age=855 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=32768 obl=0 oll=0 omem=0 events=r cmd=client\naddr=127.0.0.1:52787 fd=6 name= age=6 idle=5 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=ping\n</code></pre>\n<p>In the above example two clients are connected to the Valkey server. Let&#39;s look at what some of the data returned represents:</p>\n<ul>\n<li><strong>addr</strong>: The client address, that is, the client IP and the remote port number it used to connect with the Valkey server.</li>\n<li><strong>fd</strong>: The client socket file descriptor number.</li>\n<li><strong>name</strong>: The client name as set by <code>CLIENT SETNAME</code>.</li>\n<li><strong>age</strong>: The number of seconds the connection existed for.</li>\n<li><strong>idle</strong>: The number of seconds the connection is idle.</li>\n<li><strong>flags</strong>: The kind of client (N means normal client, check the <a href=\"../commands/client-list\">full list of flags</a>).</li>\n<li><strong>omem</strong>: The amount of memory used by the client for the output buffer.</li>\n<li><strong>cmd</strong>: The last executed command.</li>\n</ul>\n<p>See the <a href=\"../commands/client-list\"><code>CLIENT LIST</code></a> documentation for the full listing of fields and their purpose.</p>\n<p>Once you have the list of clients, you can close a client&#39;s connection using the <code>CLIENT KILL</code> command, specifying the client address as its argument.</p>\n<p>The commands <code>CLIENT SETNAME</code> and <code>CLIENT GETNAME</code> can be used to set and get the connection name. Starting with Redis OSS 4.0, the client name is shown in the<br><code>SLOWLOG</code> output, to help identify clients that create latency issues.</p>\n<h2>TCP keepalive</h2>\n<p>Valkey has TCP keepalive (<code>SO_KEEPALIVE</code> socket option) enabled by default and set to about 300 seconds. This option is useful in order to detect dead peers (clients that cannot be reached even if they look connected). Moreover, if there is network equipment between clients and servers that need to see some traffic in order to take the connection open, the option will prevent unexpected connection closed events.</p>\n"
      },
      {
        "id": "protocol",
        "topicName": "Serialization protocol specification",
        "description": "Valkey's serialization protocol (RESP) is the wire protocol that clients implement",
        "htmlContent": "<p>To communicate with the Valkey server, Valkey clients use a protocol called REdis Serialization Protocol (RESP).<br>While the protocol was designed for Redis, it&#39;s used by many other client-server software projects.</p>\n<p>RESP is a compromise among the following considerations:</p>\n<ul>\n<li>Simple to implement.</li>\n<li>Fast to parse.</li>\n<li>Human readable.</li>\n</ul>\n<p>RESP can serialize different data types including integers, strings, and arrays.<br>It also features an error-specific type.<br>A client sends a request to the Valkey server as an array of strings.<br>The array&#39;s contents are the command and its arguments that the server should execute.<br>The server&#39;s reply type is command-specific.</p>\n<p>RESP is binary-safe and uses prefixed length to transfer bulk data so it does not require processing bulk data transferred from one process to another.</p>\n<p>RESP is the protocol you should implement in your Valkey client.</p>\n<p><strong>Note:</strong><br>The protocol outlined here is used only for client-server communication.<br><a href=\"cluster-spec\">Valkey Cluster</a> uses a different binary protocol for exchanging messages between nodes.</p>\n<h2>RESP versions</h2>\n<p>The first version of the RESP protocol was experimental and was never widely used.</p>\n<p>The next version, RESP2, early became the standard communication method for clients with Redis OSS.</p>\n<p><a href=\"https://github.com/redis/redis-specifications/blob/master/protocol/RESP3\">RESP3</a> is a superset of RESP2 that mainly aims to make a client author&#39;s life a little bit easier.<br>Redis OSS 6.0 introduced experimental opt-in support of RESP3&#39;s features (excluding streaming strings and streaming aggregates).<br>In addition, the introduction of the <code>HELLO</code> command allows clients to handshake and upgrade the connection&#39;s protocol version (see <a href=\"#client-handshake\">Client handshake</a>).</p>\n<p>Up to and including Redis OSS 7, both RESP2 and RESP3 clients can invoke all core commands.<br>However, commands may return differently typed replies for different protocol versions.</p>\n<p>Future versions of Valkey may change the default protocol version, but it is unlikely that RESP2 will become entirely deprecated.<br>It is possible, however, that new features in upcoming versions will require the use of RESP3.</p>\n<h2>Network layer</h2>\n<p>A client connects to a Valkey server by creating a TCP connection to its port (the default is 6379).</p>\n<p>While RESP is technically non-TCP specific, the protocol is used exclusively with TCP connections (or equivalent stream-oriented connections like Unix sockets) in the context of Valkey.</p>\n<h2>Request-Response model</h2>\n<p>The Valkey server accepts commands composed of different arguments.<br>Then, the server processes the command and sends the reply back to the client.</p>\n<p>This is the simplest model possible; however, there are some exceptions:</p>\n<ul>\n<li>Valkey requests can be <a href=\"#multiple-commands-and-pipelining\">pipelined</a>.<br>Pipelining enables clients to send multiple commands at once and wait for replies later.</li>\n<li>When a RESP2 connection subscribes to a <a href=\"pubsub\">Pub/Sub</a> channel, the protocol changes semantics and becomes a <em>push</em> protocol.<br>The client no longer requires sending commands because the server will automatically send new messages to the client (for the channels the client is subscribed to) as soon as they are received.</li>\n<li>The <code>MONITOR</code> command.<br>Invoking the <code>MONITOR</code> command switches the connection to an ad-hoc push mode.<br>The protocol of this mode is not specified but is obvious to parse.</li>\n<li><a href=\"security#protected-mode\">Protected mode</a>.<br>Connections opened from a non-loopback address to a Valkey while in protected mode are denied and terminated by the server.<br>Before terminating the connection, Valkey unconditionally sends a <code>-DENIED</code> reply, regardless of whether the client writes to the socket.</li>\n<li>The <a href=\"#pushes\">RESP3 Push type</a>.<br>As the name suggests, a push type allows the server to send out-of-band data to the connection.<br>The server may push data at any time, and the data isn&#39;t necessarily related to specific commands executed by the client.</li>\n<li>When RESP3 is used, the commands <code>SUBSCRIBE</code>, <code>UNSUBSCRIBE</code> and their pattern and sharded variants,<br>return either an error reply <em>or one or more Push replies, without any regular in-band reply</em>.<br>This is considered a design mistake of these commands but the behaviour is kept for backward compatibility.<br>Clients need to compensate for this behaviour.</li>\n</ul>\n<p>Excluding these exceptions, the Valkey protocol is a simple request-response protocol.</p>\n<h2>RESP protocol description</h2>\n<p>RESP is essentially a serialization protocol that supports several data types.<br>In RESP, the first byte of data determines its type.</p>\n<p>Valkey generally uses RESP as a <a href=\"#request-response-model\">request-response</a> protocol in the following way:</p>\n<ul>\n<li>Clients send commands to a Valkey server as an <a href=\"#arrays\">array</a> of <a href=\"#bulk-strings\">bulk strings</a>.<br>The first (and sometimes also the second) bulk string in the array is the command&#39;s name.<br>Subsequent elements of the array are the arguments for the command.</li>\n<li>The server replies with a RESP type.<br>The reply&#39;s type is determined by the command&#39;s implementation and possibly by the client&#39;s protocol version.</li>\n</ul>\n<p>RESP is a binary protocol that uses control sequences encoded in standard ASCII.<br>The <code>A</code> character, for example, is encoded with the binary byte of value 65.<br>Similarly, the characters CR (<code>\\r</code>), LF (<code>\\n</code>) and SP (<code> </code>) have binary byte values of 13, 10 and 32, respectively.</p>\n<p>The <code>\\r\\n</code> (CRLF) is the protocol&#39;s <em>terminator</em>, which <strong>always</strong> separates its parts.</p>\n<p>The first byte in an RESP-serialized payload always identifies its type.<br>Subsequent bytes constitute the type&#39;s contents.</p>\n<p>We categorize every RESP data type as either <em>simple</em>, <em>bulk</em> or <em>aggregate</em>.</p>\n<p>Simple types are similar to scalars in programming languages that represent plain literal values. Booleans and Integers are such examples.</p>\n<p>RESP strings are either <em>simple</em> or <em>bulk</em>.<br>Simple strings never contain carriage return (<code>\\r</code>) or line feed (<code>\\n</code>) characters.<br>Bulk strings can contain any binary data and may also be referred to as <em>binary</em> or <em>blob</em>.<br>Note that bulk strings may be further encoded and decoded, e.g. with a wide multi-byte encoding, by the client.</p>\n<p>Aggregates, such as Arrays and Maps, can have varying numbers of sub-elements and nesting levels.</p>\n<p>The following table summarizes the RESP data types that Valkey supports:</p>\n<table>\n<thead>\n<tr>\n<th>RESP data type</th>\n<th>Minimal protocol version</th>\n<th>Category</th>\n<th>First byte</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><a href=\"#simple-strings\">Simple strings</a></td>\n<td>RESP2</td>\n<td>Simple</td>\n<td><code>+</code></td>\n</tr>\n<tr>\n<td><a href=\"#simple-errors\">Simple Errors</a></td>\n<td>RESP2</td>\n<td>Simple</td>\n<td><code>-</code></td>\n</tr>\n<tr>\n<td><a href=\"#integers\">Integers</a></td>\n<td>RESP2</td>\n<td>Simple</td>\n<td><code>:</code></td>\n</tr>\n<tr>\n<td><a href=\"#bulk-strings\">Bulk strings</a></td>\n<td>RESP2</td>\n<td>Aggregate</td>\n<td><code>$</code></td>\n</tr>\n<tr>\n<td><a href=\"#arrays\">Arrays</a></td>\n<td>RESP2</td>\n<td>Aggregate</td>\n<td><code>*</code></td>\n</tr>\n<tr>\n<td><a href=\"#nulls\">Nulls</a></td>\n<td>RESP3</td>\n<td>Simple</td>\n<td><code>_</code></td>\n</tr>\n<tr>\n<td><a href=\"#booleans\">Booleans</a></td>\n<td>RESP3</td>\n<td>Simple</td>\n<td><code>#</code></td>\n</tr>\n<tr>\n<td><a href=\"#doubles\">Doubles</a></td>\n<td>RESP3</td>\n<td>Simple</td>\n<td><code>,</code></td>\n</tr>\n<tr>\n<td><a href=\"#big-numbers\">Big numbers</a></td>\n<td>RESP3</td>\n<td>Simple</td>\n<td><code>(</code></td>\n</tr>\n<tr>\n<td><a href=\"#bulk-errors\">Bulk errors</a></td>\n<td>RESP3</td>\n<td>Aggregate</td>\n<td><code>!</code></td>\n</tr>\n<tr>\n<td><a href=\"#verbatim-strings\">Verbatim strings</a></td>\n<td>RESP3</td>\n<td>Aggregate</td>\n<td><code>=</code></td>\n</tr>\n<tr>\n<td><a href=\"#maps\">Maps</a></td>\n<td>RESP3</td>\n<td>Aggregate</td>\n<td><code>%</code></td>\n</tr>\n<tr>\n<td><a href=\"#sets\">Sets</a></td>\n<td>RESP3</td>\n<td>Aggregate</td>\n<td><code>~</code></td>\n</tr>\n<tr>\n<td><a href=\"#pushes\">Pushes</a></td>\n<td>RESP3</td>\n<td>Aggregate</td>\n<td><code>&gt;</code></td>\n</tr>\n</tbody></table>\n<h3>Simple strings</h3>\n<p>Simple strings are encoded as a plus (<code>+</code>) character, followed by a string.<br>The string mustn&#39;t contain a CR (<code>\\r</code>) or LF (<code>\\n</code>) character and is terminated by CRLF (i.e., <code>\\r\\n</code>).</p>\n<p>Simple strings transmit short, non-binary strings with minimal overhead.<br>For example, many Valkey commands reply with just &quot;OK&quot; on success.<br>The encoding of this Simple String is the following 5 bytes:</p>\n<pre><code>+OK\\r\\n\n</code></pre>\n<p>When Valkey replies with a simple string, a client library should return to the caller a string value composed of the first character after the <code>+</code> up to the end of the string, excluding the final CRLF bytes.</p>\n<p>To send binary strings, use <a href=\"#bulk-strings\">bulk strings</a> instead.</p>\n<h3>Simple errors</h3>\n<p>RESP has specific data types for errors.<br>Simple errors, or simply just errors, are similar to <a href=\"#simple-strings\">simple strings</a>, but their first character is the minus (<code>-</code>) character.<br>The difference between simple strings and errors in RESP is that clients should treat errors as exceptions, whereas the string encoded in the error type is the error message itself.</p>\n<p>The basic format is:</p>\n<pre><code>-Error message\\r\\n\n</code></pre>\n<p>Valkey replies with an error only when something goes wrong, for example, when you try to operate against the wrong data type, or when the command does not exist.<br>The client should raise an exception when it receives an Error reply.</p>\n<p>The following are examples of error replies:</p>\n<pre><code>-ERR unknown command &#39;asdf&#39;\n-WRONGTYPE Operation against a key holding the wrong kind of value\n</code></pre>\n<p>The first upper-case word after the <code>-</code>, up to the first space or newline, represents the kind of error returned.<br>This word is called an <em>error prefix</em>.<br>Note that the error prefix is a convention used by Valkey rather than part of the RESP error type.</p>\n<p>For example, in Valkey, <code>ERR</code> is a generic error, whereas <code>WRONGTYPE</code> is a more specific error that implies that the client attempted an operation against the wrong data type.<br>The error prefix allows the client to understand the type of error returned by the server without checking the exact error message.</p>\n<p>A client implementation can return different types of exceptions for various errors, or provide a generic way for trapping errors by directly providing the error name to the caller as a string.</p>\n<p>However, such a feature should not be considered vital as it is rarely useful.<br>Also, simpler client implementations can return a generic error value, such as <code>false</code>.</p>\n<h3>Integers</h3>\n<p>This type is a CRLF-terminated string that represents a signed, base-10, 64-bit integer.</p>\n<p>RESP encodes integers in the following way:</p>\n<pre><code>:[&lt;+|-&gt;]&lt;value&gt;\\r\\n\n</code></pre>\n<ul>\n<li>The colon (<code>:</code>) as the first byte.</li>\n<li>An optional plus (<code>+</code>) or minus (<code>-</code>) as the sign.</li>\n<li>One or more decimal digits (<code>0</code>..<code>9</code>) as the integer&#39;s unsigned, base-10 value.</li>\n<li>The CRLF terminator.</li>\n</ul>\n<p>For example, <code>:0\\r\\n</code> and <code>:1000\\r\\n</code> are integer replies (of zero and one thousand, respectively).</p>\n<p>Many Valkey commands return RESP integers, including <code>INCR</code>, <code>LLEN</code>, and <code>LASTSAVE</code>.<br>An integer, by itself, has no special meaning other than in the context of the command that returned it.<br>For example, it is an incremental number for <code>INCR</code>, a UNIX timestamp for <code>LASTSAVE</code>, and so forth.<br>However, the returned integer is guaranteed to be in the range of a signed 64-bit integer.</p>\n<p>In some cases, integers can represent true and false Boolean values.<br>For instance, <code>SISMEMBER</code> returns 1 for true and 0 for false.</p>\n<p>Other commands, including <code>SADD</code>, <code>SREM</code>, and <code>SETNX</code>, return 1 when the data changes and 0 otherwise.</p>\n<h3>Bulk strings</h3>\n<p>A bulk string represents a single binary string.<br>The string can be of any size, but by default, Valkey limits it to 512 MB (see the <code>proto-max-bulk-len</code> configuration directive).</p>\n<p>RESP encodes bulk strings in the following way:</p>\n<pre><code>$&lt;length&gt;\\r\\n&lt;data&gt;\\r\\n\n</code></pre>\n<ul>\n<li>The dollar sign (<code>$</code>) as the first byte.</li>\n<li>One or more decimal digits (<code>0</code>..<code>9</code>) as the string&#39;s length, in bytes, as an unsigned, base-10 value.</li>\n<li>The CRLF terminator.</li>\n<li>The data.</li>\n<li>A final CRLF.</li>\n</ul>\n<p>So the string &quot;hello&quot; is encoded as follows:</p>\n<pre><code>$5\\r\\nhello\\r\\n\n</code></pre>\n<p>The empty string&#39;s encoding is:</p>\n<pre><code>$0\\r\\n\\r\\n\n</code></pre>\n<p><a name=\"nil-reply\"></a></p>\n<h3>Arrays</h3>\n<p>Clients send commands to the Valkey server as RESP arrays.<br>Similarly, some Valkey commands that return collections of elements use arrays as their replies.<br>An example is the <code>LRANGE</code> command that returns elements of a list.</p>\n<p>RESP Arrays&#39; encoding uses the following format:</p>\n<pre><code>*&lt;number-of-elements&gt;\\r\\n&lt;element-1&gt;...&lt;element-n&gt;\n</code></pre>\n<ul>\n<li>An asterisk (<code>*</code>) as the first byte.</li>\n<li>One or more decimal digits (<code>0</code>..<code>9</code>) as the number of elements in the array as an unsigned, base-10 value.</li>\n<li>The CRLF terminator.</li>\n<li>An additional RESP type for every element of the array.</li>\n</ul>\n<p>So an empty Array is just the following:</p>\n<pre><code>*0\\r\\n\n</code></pre>\n<p>Whereas the encoding of an array consisting of the two bulk strings &quot;hello&quot; and &quot;world&quot; is:</p>\n<pre><code>*2\\r\\n$5\\r\\nhello\\r\\n$5\\r\\nworld\\r\\n\n</code></pre>\n<p>As you can see, after the <code>*&lt;count&gt;CRLF</code> part prefixing the array, the other data types that compose the array are concatenated one after the other.<br>For example, an Array of three integers is encoded as follows:</p>\n<pre><code>*3\\r\\n:1\\r\\n:2\\r\\n:3\\r\\n\n</code></pre>\n<p>Arrays can contain mixed data types.<br>For instance, the following encoding is of a list of four integers and a bulk string:</p>\n<pre><code>*5\\r\\n\n:1\\r\\n\n:2\\r\\n\n:3\\r\\n\n:4\\r\\n\n$5\\r\\n\nhello\\r\\n\n</code></pre>\n<p>(The raw RESP encoding is split into multiple lines for readability).</p>\n<p>The first line the server sent is <code>*5\\r\\n</code>.<br>This numeric value tells the client that five reply types are about to follow it.<br>Then, every successive reply constitutes an element in the array.</p>\n<p>All of the aggregate RESP types support nesting.<br>For example, a nested array of two arrays is encoded as follows:</p>\n<pre><code>*2\\r\\n\n*3\\r\\n\n:1\\r\\n\n:2\\r\\n\n:3\\r\\n\n*2\\r\\n\n+Hello\\r\\n\n-World\\r\\n\n</code></pre>\n<p>(The raw RESP encoding is split into multiple lines for readability).</p>\n<p>The above encodes a two-element array.<br>The first element is an array that, in turn, contains three integers (1, 2, 3).<br>The second element is another array containing a simple string and an error.</p>\n<p><strong>Note:</strong><br>In some places, the RESP Array type may be referred to as <em>multi bulk</em>.<br>The two are the same.</p>\n<h3>Nulls</h3>\n<p>The null data type represents non-existent values.</p>\n<p>In RESP3, null is encoded using the underscore (<code>_</code>) character, followed by the CRLF terminator (<code>\\r\\n</code>).<br>Here&#39;s null&#39;s raw RESP encoding:</p>\n<pre><code>_\\r\\n\n</code></pre>\n<p>RESP2 features two specially crafted values for representing null values,<br>known as &quot;null bulk strings&quot; and &quot;null arrays&quot;.<br>This duality has always been a redundancy that added zero semantical value to the protocol itself.<br>The null type, introduced in RESP3, aims to fix this wrong.<br>Clients should handle all these representations of null in the same way.<br>For example, a Ruby library should return <code>nil</code> while a C library should return <code>NULL</code> (or set a special flag in the reply object).</p>\n<h4>Null bulk strings</h4>\n<p>Whereas RESP3 has a dedicated data type for <a href=\"#nulls\">null values</a>, RESP2 has no such type.<br>Instead, due to historical reasons, the representation of null values in RESP2 is via predetermined forms of the <a href=\"#bulk-strings\">bulk strings</a> and <a href=\"#arrays\">arrays</a> types.</p>\n<p>The null bulk string represents a non-existing value.<br>The <code>GET</code> command returns the Null Bulk String when the target key doesn&#39;t exist.</p>\n<p>It is encoded as a bulk string with the length of negative one (-1), like so:</p>\n<pre><code>$-1\\r\\n\n</code></pre>\n<p>A Valkey client should return a nil object when the server replies with a null bulk string rather than the empty string.</p>\n<h4>Null arrays</h4>\n<p>Whereas RESP3 has a dedicated data type for <a href=\"#nulls\">null values</a>, RESP2 has no such type. Instead, due to historical reasons, the representation of null values in RESP2 is via predetermined forms of the <a href=\"#bulk-strings\">Bulk Strings</a> and <a href=\"#arrays\">arrays</a> types.</p>\n<p>Null arrays exist as an alternative way of representing a null value.<br>For instance, when the <code>BLPOP</code> command times out, it returns a null array.</p>\n<p>The encoding of a null array is that of an array with the length of -1, i.e.</p>\n<pre><code>*-1\\r\\n\n</code></pre>\n<p>When Valkey replies with a null array, the client should return a null object rather than an empty array.</p>\n<h4>Null elements in arrays</h4>\n<p>Single elements of an array may be <a href=\"#nulls\">null</a>.<br>This is used in Valkey replies to signal that these elements are missing and not empty strings. This can happen, for example, with the <code>SORT</code> command when used with the <code>GET pattern</code> option<br>if the specified key is missing.</p>\n<p>Here&#39;s an example of an array reply containing a null element, represented as a RESP2 null bulk string:</p>\n<pre><code>*3\\r\\n\n$5\\r\\n\nhello\\r\\n\n$-1\\r\\n\n$5\\r\\n\nworld\\r\\n\n</code></pre>\n<p>Above, the second element is null.<br>The client library should return to its caller something like this:</p>\n<pre><code>[&quot;hello&quot;,nil,&quot;world&quot;]\n</code></pre>\n<h3>Booleans</h3>\n<p>RESP booleans are encoded as follows:</p>\n<pre><code>#&lt;t|f&gt;\\r\\n\n</code></pre>\n<ul>\n<li>The octothorpe character (<code>#</code>) as the first byte.</li>\n<li>A <code>t</code> character for true values, or an <code>f</code> character for false ones.</li>\n<li>The CRLF terminator.</li>\n</ul>\n<h3>Doubles</h3>\n<p>The Double RESP type encodes a double-precision floating point value.<br>Doubles are encoded as follows:</p>\n<pre><code>,[&lt;+|-&gt;]&lt;integral&gt;[.&lt;fractional&gt;][&lt;E|e&gt;[sign]&lt;exponent&gt;]\\r\\n\n</code></pre>\n<ul>\n<li>The comma character (<code>,</code>) as the first byte.</li>\n<li>An optional plus (<code>+</code>) or minus (<code>-</code>) as the sign.</li>\n<li>One or more decimal digits (<code>0</code>..<code>9</code>) as an unsigned, base-10 integral value.</li>\n<li>An optional dot (<code>.</code>), followed by one or more decimal digits (<code>0</code>..<code>9</code>) as an unsigned, base-10 fractional value.</li>\n<li>An optional capital or lowercase letter E (<code>E</code> or <code>e</code>), followed by an optional plus (<code>+</code>) or minus (<code>-</code>) as the exponent&#39;s sign, ending with one or more decimal digits (<code>0</code>..<code>9</code>) as an unsigned, base-10 exponent value.</li>\n<li>The CRLF terminator.</li>\n</ul>\n<p>Here&#39;s the encoding of the number 1.23:</p>\n<pre><code>,1.23\\r\\n\n</code></pre>\n<p>Because the fractional part is optional, the integer value of ten (10) can, therefore, be RESP-encoded both as an integer as well as a double:</p>\n<pre><code>:10\\r\\n\n,10\\r\\n\n</code></pre>\n<p>In such cases, the Valkey client should return native integer and double values, respectively, providing that these types are supported by the language of its implementation.</p>\n<p>The positive infinity, negative infinity and NaN values are encoded as follows:</p>\n<pre><code>,inf\\r\\n\n,-inf\\r\\n\n,nan\\r\\n\n</code></pre>\n<p><a name=\"big-number-reply\"></a></p>\n<h3>Big numbers</h3>\n<p>This type can encode integer values outside the range of signed 64-bit integers.</p>\n<p>Big numbers use the following encoding:</p>\n<pre><code>([+|-]&lt;number&gt;\\r\\n\n</code></pre>\n<ul>\n<li>The left parenthesis character (<code>(</code>) as the first byte.</li>\n<li>An optional plus (<code>+</code>) or minus (<code>-</code>) as the sign.</li>\n<li>One or more decimal digits (<code>0</code>..<code>9</code>) as an unsigned, base-10 value.</li>\n<li>The CRLF terminator.</li>\n</ul>\n<p>Example:</p>\n<pre><code>(3492890328409238509324850943850943825024385\\r\\n\n</code></pre>\n<p>Big numbers can be positive or negative but can&#39;t include fractionals.<br>Client libraries written in languages with a big number type should return a big number.<br>When big numbers aren&#39;t supported, the client should return a string and, when possible, signal to the caller that the reply is a big integer (depending on the API used by the client library).</p>\n<h3>Bulk errors</h3>\n<p>This type combines the purpose of <a href=\"#simple-errors\">simple errors</a> with the expressive power of <a href=\"#bulk-strings\">bulk strings</a>.</p>\n<p>It is encoded as:</p>\n<pre><code>!&lt;length&gt;\\r\\n&lt;error&gt;\\r\\n\n</code></pre>\n<ul>\n<li>An exclamation mark (<code>!</code>) as the first byte.</li>\n<li>One or more decimal digits (<code>0</code>..<code>9</code>) as the error&#39;s length, in bytes, as an unsigned, base-10 value.</li>\n<li>The CRLF terminator.</li>\n<li>The error itself.</li>\n<li>A final CRLF.</li>\n</ul>\n<p>As a convention, the error begins with an uppercase (space-delimited) word that conveys the error message.</p>\n<p>For instance, the error &quot;SYNTAX invalid syntax&quot; is represented by the following protocol encoding:</p>\n<pre><code>!21\\r\\n\nSYNTAX invalid syntax\\r\\n\n</code></pre>\n<p>(The raw RESP encoding is split into multiple lines for readability).</p>\n<h3>Verbatim strings</h3>\n<p>This type is similar to the <a href=\"#bulk-strings\">bulk string</a>, with the addition of providing a hint about the data&#39;s encoding.</p>\n<p>A verbatim string&#39;s RESP encoding is as follows:</p>\n<pre><code>=&lt;length&gt;\\r\\n&lt;encoding&gt;:&lt;data&gt;\\r\\n\n</code></pre>\n<ul>\n<li>An equal sign (<code>=</code>) as the first byte.</li>\n<li>One or more decimal digits (<code>0</code>..<code>9</code>) as the string&#39;s total length, in bytes, as an unsigned, base-10 value.</li>\n<li>The CRLF terminator.</li>\n<li>Exactly three (3) bytes represent the data&#39;s encoding.</li>\n<li>The colon (<code>:</code>) character separates the encoding and data.</li>\n<li>The data.</li>\n<li>A final CRLF.</li>\n</ul>\n<p>Example:</p>\n<pre><code>=15\\r\\n\ntxt:Some string\\r\\n\n</code></pre>\n<p>(The raw RESP encoding is split into multiple lines for readability).</p>\n<p>Some client libraries may ignore the difference between this type and the string type and return a native string in both cases.<br>However, interactive clients, such as command line interfaces (e.g., <a href=\"cli\"><code>valkey-cli</code></a>), can use this type and know that their output should be presented to the human user as is and without quoting the string.</p>\n<p>For example, the Valkey command <code>INFO</code> outputs a report that includes newlines.<br>When using RESP3, <code>valkey-cli</code> displays it correctly because it is sent as a Verbatim String reply (with its three bytes being &quot;txt&quot;).<br>When using RESP2, however, the <code>valkey-cli</code> is hard-coded to look for the <code>INFO</code> command to ensure its correct display to the user.</p>\n<h3>Maps</h3>\n<p>The RESP map encodes a collection of key-value tuples, i.e., a dictionary or a hash.</p>\n<p>It is encoded as follows:</p>\n<pre><code>%&lt;number-of-entries&gt;\\r\\n&lt;key-1&gt;&lt;value-1&gt;...&lt;key-n&gt;&lt;value-n&gt;\n</code></pre>\n<ul>\n<li>A percent character (<code>%</code>) as the first byte.</li>\n<li>One or more decimal digits (<code>0</code>..<code>9</code>) as the number of entries, or key-value tuples, in the map as an unsigned, base-10 value.</li>\n<li>The CRLF terminator.</li>\n<li>Two additional RESP types for every key and value in the map.</li>\n</ul>\n<p>For example, the following JSON object:</p>\n<pre><code>{\n    &quot;first&quot;: 1,\n    &quot;second&quot;: 2\n}\n</code></pre>\n<p>Can be encoded in RESP like so:</p>\n<pre><code>%2\\r\\n\n+first\\r\\n\n:1\\r\\n\n+second\\r\\n\n:2\\r\\n\n</code></pre>\n<p>(The raw RESP encoding is split into multiple lines for readability).</p>\n<p>Both map keys and values can be any of RESP&#39;s types.</p>\n<p>Valkey clients should return the idiomatic dictionary type that their language provides.<br>However, low-level programming languages (such as C, for example) will likely return an array along with type information that indicates to the caller that it is a dictionary.</p>\n<p><strong>Note:</strong><br>RESP2 doesn&#39;t have a map type.<br>A map in RESP2 is represented by a flat array containing the keys and the values.<br>The first element is a key, followed by the corresponding value, then the next key and so on, like this:<br><code>key1, value1, key2, value2, ...</code>.</p>\n<h3>Sets</h3>\n<p>Sets are somewhat like <a href=\"#arrays\">Arrays</a> but are unordered and should only contain unique elements.</p>\n<p>RESP set&#39;s encoding is:</p>\n<pre><code>~&lt;number-of-elements&gt;\\r\\n&lt;element-1&gt;...&lt;element-n&gt;\n</code></pre>\n<ul>\n<li>A tilde (<code>~</code>) as the first byte.</li>\n<li>One or more decimal digits (<code>0</code>..<code>9</code>) as the number of elements in the set as an unsigned, base-10 value.</li>\n<li>The CRLF terminator.</li>\n<li>An additional RESP type for every element of the Set.</li>\n</ul>\n<p>Clients should return the native set type if it is available in their programming language.<br>Alternatively, in the absence of a native set type, an array coupled with type information can be used (in C, for example).</p>\n<p><a name=\"push-event\"></a></p>\n<h3>Pushes</h3>\n<p>RESP&#39;s pushes contain out-of-band data.<br>They are an exception to the protocol&#39;s request-response model and provide a generic <em>push mode</em> for connections.</p>\n<p>Push events are encoded similarly to <a href=\"#arrays\">arrays</a>, differing only in their first byte:</p>\n<pre><code>&gt;&lt;number-of-elements&gt;\\r\\n&lt;element-1&gt;...&lt;element-n&gt;\n</code></pre>\n<ul>\n<li>A greater-than sign (<code>&gt;</code>) as the first byte.</li>\n<li>One or more decimal digits (<code>0</code>..<code>9</code>) as the number of elements in the message as an unsigned, base-10 value.</li>\n<li>The CRLF terminator.</li>\n<li>An additional RESP type for every element of the push event.</li>\n</ul>\n<p>Pushed data may precede or follow any of RESP&#39;s data types but never inside them.<br>That means a client won&#39;t find push data in the middle of a map reply, for example.<br>It also means that pushed data may appear before or after a command&#39;s reply, as well as by itself (without calling any command).</p>\n<p>Clients should react to pushes by invoking a callback that implements their handling of the pushed data.</p>\n<h2>Client handshake</h2>\n<p>New RESP connections should begin the session by calling the <code>HELLO</code> command.<br>This practice accomplishes two things:</p>\n<ol>\n<li>It allows servers to be backward compatible with RESP2 versions.<br>  This is needed in Valkey to make the transition to version 3 of the protocol gentler.</li>\n<li>The <code>HELLO</code> command returns information about the server and the protocol that the client can use for different goals.</li>\n</ol>\n<p>The <code>HELLO</code> command has the following high-level syntax:</p>\n<pre><code>HELLO &lt;protocol-version&gt; [optional-arguments]\n</code></pre>\n<p>The first argument of the command is the protocol version we want the connection to be set.<br>By default, the connection starts in RESP2 mode.<br>If we specify a connection version that is too big and unsupported by the server, it should reply with a <code>-NOPROTO</code> error. Example:</p>\n<pre><code>Client: HELLO 4\nServer: -NOPROTO sorry, this protocol version is not supported.\n</code></pre>\n<p>At that point, the client may retry with a lower protocol version.</p>\n<p>Similarly, the client can easily detect a server that is only able to speak RESP2:</p>\n<pre><code>Client: HELLO 3\nServer: -ERR unknown command &#39;HELLO&#39;\n</code></pre>\n<p>The client can then proceed and use RESP2 to communicate with the server.</p>\n<p>Note that even if the protocol&#39;s version is supported, the <code>HELLO</code> command may return an error, perform no action and remain in RESP2 mode.<br>For example, when used with invalid authentication credentials in the command&#39;s optional <code>!AUTH</code> clause:</p>\n<pre><code>Client: HELLO 3 AUTH default mypassword\nServer: -ERR invalid password\n(the connection remains in RESP2 mode)\n</code></pre>\n<p>A successful reply to the <code>HELLO</code> command is a map reply.<br>The information in the reply is partly server-dependent, but certain fields are mandatory for all the RESP3 implementations:</p>\n<ul>\n<li><strong>server</strong>: &quot;redis&quot; (or other software name).</li>\n<li><strong>version</strong>: the server&#39;s version.</li>\n<li><strong>proto</strong>: the highest supported version of the RESP protocol.</li>\n</ul>\n<p>In Valkey&#39; RESP3 implementation, the following fields are also emitted:</p>\n<ul>\n<li><strong>id</strong>: the connection&#39;s identifier (ID).</li>\n<li><strong>mode</strong>: &quot;standalone&quot;, &quot;sentinel&quot; or &quot;cluster&quot;.</li>\n<li><strong>role</strong>: &quot;primary&quot; or &quot;replica&quot;.</li>\n<li><strong>modules</strong>: list of loaded modules as an Array of Bulk Strings.</li>\n</ul>\n<h2>Sending commands to a Valkey server</h2>\n<p>Now that you are familiar with the RESP serialization format, you can use it to help write a Valkey client library.<br>We can further specify how the interaction between the client and the server works:</p>\n<ul>\n<li>A client sends the Valkey server an <a href=\"#arrays\">array</a> consisting of only bulk strings.</li>\n<li>A Valkey server replies to clients, sending any valid RESP data type as a reply.</li>\n</ul>\n<p>So, for example, a typical interaction could be the following.</p>\n<p>The client sends the command <code>LLEN mylist</code> to get the length of the list stored at the key <em>mylist</em>.<br>Then the server replies with an <a href=\"#integers\">integer</a> reply as in the following example (<code>C:</code> is the client, <code>S:</code> the server).</p>\n<pre><code>C: *2\\r\\n\nC: $4\\r\\n\nC: LLEN\\r\\n\nC: $6\\r\\n\nC: mylist\\r\\n\n\nS: :48293\\r\\n\n</code></pre>\n<p>As usual, we separate different parts of the protocol with newlines for simplicity, but the actual interaction is the client sending <code>*2\\r\\n$4\\r\\nLLEN\\r\\n$6\\r\\nmylist\\r\\n</code> as a whole.</p>\n<h2>Multiple commands and pipelining</h2>\n<p>A client can use the same connection to issue multiple commands.<br>Pipelining is supported, so multiple commands can be sent with a single write operation by the client.<br>The client can skip reading replies and continue to send the commands one after the other.<br>All the replies can be read at the end.</p>\n<p>For more information, see <a href=\"pipelining\">Pipelining</a>.</p>\n<h2>Inline commands</h2>\n<p>Sometimes you may need to send a command to the Valkey server but only have <code>telnet</code> available.<br>While the Valkey protocol is simple to implement, it is not ideal for interactive sessions, and <code>valkey-cli</code> may not always be available.<br>For this reason, Valkey also accepts commands in the <em>inline command</em> format.</p>\n<p>The following example demonstrates a server/client exchange using an inline command (the server chat starts with <code>S:</code>, the client chat with <code>C:</code>):</p>\n<pre><code>C: PING\nS: +PONG\n</code></pre>\n<p>Here&#39;s another example of an inline command where the server returns an integer:</p>\n<pre><code>C: EXISTS somekey\nS: :0\n</code></pre>\n<p>Basically, to issue an inline command, you write space-separated arguments in a telnet session.<br>Since no command starts with <code>*</code> (the identifying byte of RESP Arrays), Valkey detects this condition and parses your command inline.</p>\n<h2>High-performance parser for the Valkey protocol</h2>\n<p>While the Valkey protocol is human-readable and easy to implement, its implementation can exhibit performance similar to that of a binary protocol.</p>\n<p>RESP uses prefixed lengths to transfer bulk data.<br>That makes scanning the payload for special characters unnecessary (unlike parsing JSON, for example).<br>For the same reason, quoting and escaping the payload isn&#39;t needed.</p>\n<p>Reading the length of aggregate types (for example, bulk strings or arrays) can be processed with code that performs a single operation per character while at the same time scanning for the CR character.</p>\n<p>Example (in C):</p>\n<pre><code class=\"language-c\">#include &lt;stdio.h&gt;\n\nint main(void) {\n    unsigned char *p = &quot;$123\\r\\n&quot;;\n    int len = 0;\n\n    p++;\n    while(*p != &#39;\\r&#39;) {\n        len = (len*10)+(*p - &#39;0&#39;);\n        p++;\n    }\n\n    /* Now p points at &#39;\\r&#39;, and the len is in bulk_len. */\n    printf(&quot;%d\\n&quot;, len);\n    return 0;\n}\n</code></pre>\n<p>After the first CR is identified, it can be skipped along with the following LF without further processing.<br>Then, the bulk data can be read with a single read operation that doesn&#39;t inspect the payload in any way.<br>Finally, the remaining CR and LF characters are discarded without additional processing.</p>\n<p>While comparable in performance to a binary protocol, the Valkey protocol is significantly more straightforward to implement in most high-level languages, reducing the number of bugs in client software.</p>\n<h2>Tips for Valkey client authors</h2>\n<ul>\n<li>For testing purposes, use <a href=\"lua-api#lua-to-resp3-type-conversion\">Lua&#39;s type conversions</a> to have Valkey reply with any RESP2/RESP3 needed.<br>As an example, a RESP3 double can be generated like so:<pre><code>EVAL &quot;return { double = tonumber(ARGV[1]) }&quot; 0 1e0\n</code></pre>\n</li>\n</ul>\n"
      },
      {
        "id": "sentinel-clients",
        "topicName": "Sentinel client spec",
        "description": "How to build clients for Valkey Sentinel",
        "htmlContent": "<p>Valkey Sentinel is a monitoring solution for Valkey instances that handles<br>automatic failover of Valkey primaries and service discovery (who is the current<br>primary for a given group of instances?). Since Sentinel is both responsible<br>for reconfiguring instances during failovers, and providing configurations to<br>clients connecting to Valkey primaries or replicas, clients are required to have<br>explicit support for Valkey Sentinel.</p>\n<p>This document is targeted at Valkey clients developers that want to support Sentinel in their clients implementation with the following goals:</p>\n<ul>\n<li>Automatic configuration of clients via Sentinel.</li>\n<li>Improved safety of Valkey Sentinel automatic failover.</li>\n</ul>\n<p>For details about how Valkey Sentinel works, please check the <a href=\"sentinel\">Valkey Documentation</a>, as this document only contains information needed for Valkey client developers, and it is expected that readers are familiar with the way Valkey Sentinel works.</p>\n<h2>Valkey service discovery via Sentinel</h2>\n<p>Valkey Sentinel identifies every primary with a name like &quot;stats&quot; or &quot;cache&quot;.<br>Every name actually identifies a <em>group of instances</em>, composed of a primary<br>and a variable number of replicas.</p>\n<p>The address of the Valkey primary that is used for a specific purpose inside a network may change after events like an automatic failover, a manually triggered failover (for instance in order to upgrade a Valkey instance), and other reasons.</p>\n<p>Normally Valkey clients have some kind of hard-coded configuration that specifies the address of a Valkey primary instance within a network as IP address and port number. However if the primary address changes, manual intervention in every client is needed.</p>\n<p>A Valkey client supporting Sentinel can automatically discover the address of a Valkey primary from the primary name using Valkey Sentinel. So instead of a hard coded IP address and port, a client supporting Sentinel should optionally be able to take as input:</p>\n<ul>\n<li>A list of ip:port pairs pointing to known Sentinel instances.</li>\n<li>The name of the service, like &quot;cache&quot; or &quot;timelines&quot;.</li>\n</ul>\n<p>This is the procedure a client should follow in order to obtain the primary address starting from the list of Sentinels and the service name.</p>\n<h2>Step 1: connect to the first Sentinel</h2>\n<p>The client should iterate the list of Sentinel addresses. For every address it should try to connect to the Sentinel, using a short timeout (in the order of a few hundreds of milliseconds). On errors or timeouts the next Sentinel address should be tried.</p>\n<p>If all the Sentinel addresses were tried without success, an error should be returned to the client.</p>\n<p>The first Sentinel replying to the client request should be put at the start of the list, so that at the next reconnection, we&#39;ll try first the Sentinel that was reachable in the previous connection attempt, minimizing latency.</p>\n<h2>Step 2: ask for primary address</h2>\n<p>Once a connection with a Sentinel is established, the client should retry to execute the following command on the Sentinel:</p>\n<pre><code>SENTINEL get-master-addr-by-name master-name\n</code></pre>\n<p>Where <em>master-name</em> should be replaced with the actual service name specified by the user.</p>\n<p>The result from this call can be one of the following two replies:</p>\n<ul>\n<li>An ip:port pair.</li>\n<li>A null reply. This means Sentinel does not know this primary.</li>\n</ul>\n<p>If an ip:port pair is received, this address should be used to connect to the Valkey primary. Otherwise if a null reply is received, the client should try the next Sentinel in the list.</p>\n<h2>Step 3: call the ROLE command in the target instance</h2>\n<p>Once the client discovered the address of the primary instance, it should<br>attempt a connection with the primary, and call the <code>ROLE</code> command in order<br>to verify the role of the instance is actually a primary.</p>\n<p>If the instance is not a primary as expected, the client should wait a short amount of time (a few hundreds of milliseconds) and should try again starting from Step 1.</p>\n<h1>Handling reconnections</h1>\n<p>Once the service name is resolved into the primary address and a connection is established with the Valkey primary instance, every time a reconnection is needed, the client should resolve again the address using Sentinels restarting from Step 1. For instance Sentinel should contacted again the following cases:</p>\n<ul>\n<li>If the client reconnects after a timeout or socket error.</li>\n<li>If the client reconnects because it was explicitly closed or reconnected by the user.</li>\n</ul>\n<p>In the above cases and any other case where the client lost the connection with the Valkey server, the client should resolve the primary address again.</p>\n<h1>Sentinel failover disconnection</h1>\n<p>When Valkey Sentinel changes the configuration of<br>an instance, for example promoting a replica to a primary, demoting a primary to<br>replicate to the new primary after a failover, or simply changing the primary<br>address of a stale replica instance, it sends a <code>CLIENT KILL type normal</code><br>command to the instance in order to make sure all the clients are disconnected<br>from the reconfigured instance. This will force clients to resolve the primary<br>address again.</p>\n<p>If the client will contact a Sentinel with yet not updated information, the verification of the Valkey instance role via the <code>ROLE</code> command will fail, allowing the client to detect that the contacted Sentinel provided stale information, and will try again.</p>\n<p>Note: it is possible that a stale primary returns online at the same time a client contacts a stale Sentinel instance, so the client may connect with a stale primary, and yet the ROLE output will match. However when the primary is back again Sentinel will try to demote it to replica, triggering a new disconnection. The same reasoning applies to connecting to stale replicas that will get reconfigured to replicate with a different primary.</p>\n<h1>Connecting to replicas</h1>\n<p>Sometimes clients are interested to connect to replicas, for example in order to scale read requests. This protocol supports connecting to replicas by modifying step 2 slightly. Instead of calling the following command:</p>\n<pre><code>SENTINEL get-master-addr-by-name master-name\n</code></pre>\n<p>The clients should call instead:</p>\n<pre><code>SENTINEL replicas primary-name\n</code></pre>\n<p>In order to retrieve a list of replica instances.</p>\n<p>Symmetrically the client should verify with the <code>ROLE</code> command that the<br>instance is actually a replica, in order to avoid scaling read queries with<br>the primary.</p>\n<h1>Connection pools</h1>\n<p>For clients implementing connection pools, on reconnection of a single connection, the Sentinel should be contacted again, and in case of a primary address change all the existing connections should be closed and connected to the new address.</p>\n<h1>Error reporting</h1>\n<p>The client should correctly return the information to the user in case of errors. Specifically:</p>\n<ul>\n<li>If no Sentinel can be contacted (so that the client was never able to get the reply to <code>SENTINEL get-master-addr-by-name</code>), an error that clearly states that Valkey Sentinel is unreachable should be returned.</li>\n<li>If all the Sentinels in the pool replied with a null reply, the user should be informed with an error that Sentinels don&#39;t know this primary name.</li>\n</ul>\n<h1>Sentinels list automatic refresh</h1>\n<p>Optionally once a successful reply to <code>get-master-addr-by-name</code> is received, a client may update its internal list of Sentinel nodes following this procedure:</p>\n<ul>\n<li>Obtain a list of other Sentinels for this primary using the command <code>SENTINEL sentinels &lt;master-name&gt;</code>.</li>\n<li>Add every ip:port pair not already existing in our list at the end of the list.</li>\n</ul>\n<p>It is not needed for a client to be able to make the list persistent updating its own configuration. The ability to upgrade the in-memory representation of the list of Sentinels can be already useful to improve reliability.</p>\n<h1>Subscribe to Sentinel events to improve responsiveness</h1>\n<p>The <a href=\"sentinel\">Sentinel documentation</a> shows how clients can connect to<br>Sentinel instances using Pub/Sub in order to subscribe to changes in the<br>Valkey instances configurations.</p>\n<p>This mechanism can be used in order to speedup the reconfiguration of clients,<br>that is, clients may listen to Pub/Sub in order to know when a configuration<br>change happened in order to run the three steps protocol explained in this<br>document in order to resolve the new Valkey primary (or replica) address.</p>\n<p>However update messages received via Pub/Sub should not substitute the<br>above procedure, since there is no guarantee that a client is able to<br>receive all the update messages.</p>\n<blockquote>\n<p>NOTE: If not for backward compatibility, the Valkey project no longer uses the words &quot;master&quot; and &quot;slave&quot;. Unfortunately in the given commands these words are part of the protocol, so we’ll be able to remove such occurrences only when this API will be naturally deprecated.</p>\n</blockquote>\n"
      }
    ]
  },
  {
    "title": "DATA TYPES",
    "items": [
      {
        "id": "bitfields",
        "topicName": "Bitfields",
        "description": "Introduction to Bitfields\n",
        "htmlContent": "<p>Bitfields let you set, increment, and get integer values of arbitrary bit length.<br>For example, you can operate on anything from unsigned 1-bit integers to signed 63-bit integers.</p>\n<p>These values are stored using binary-encoded Strings.<br>Bitfields support atomic read, write and increment operations, making them a good choice for managing counters and similar numerical values.</p>\n<h2>Basic commands</h2>\n<ul>\n<li><code>BITFIELD</code> atomically sets, increments and reads one or more values.</li>\n<li><code>BITFIELD_RO</code> is a read-only variant of <code>BITFIELD</code>.</li>\n</ul>\n<h2>Example</h2>\n<p>Suppose you want to maintain two metrics for various bicycles: the current price and the number of owners over time. You can represent these counters with a 32-bit wide bitfield per for each bike.</p>\n<ul>\n<li>Bike 1 initially costs 1,000 (counter in offset 0) and has never had an owner. After being sold, it&#39;s now considered used and the price instantly drops to reflect its new condition, and it now has an owner (offset 1). After quite some time, the bike becomes a classic. The original owner sells it for a profit, so the price goes up and the number of owners does as well.Finally, you can look at the bike&#39;s current price and number of owners.</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; BITFIELD bike:1:stats SET u32 #0 1000\n1) (integer) 0\n127.0.0.1:6379&gt; BITFIELD bike:1:stats INCRBY u32 #0 -50 INCRBY u32 #1 1\n1) (integer) 950\n2) (integer) 1\n127.0.0.1:6379&gt; BITFIELD bike:1:stats INCRBY u32 #0 500 INCRBY u32 #1 1\n1) (integer) 1450\n2) (integer) 2\n127.0.0.1:6379&gt; BITFIELD bike:1:stats GET u32 #0 GET u32 #1\n1) (integer) 1450\n2) (integer) 2\n</code></pre>\n<h2>Performance</h2>\n<p><code>BITFIELD</code> is O(n), where <em>n</em> is the number of counters accessed.</p>\n"
      },
      {
        "id": "bitmaps",
        "topicName": "Bitmaps",
        "description": "Introduction to Bitmaps\n",
        "htmlContent": "<p>Bitmaps are not an actual data type, but a set of bit-oriented operations<br>defined on the String type which is treated like a bit vector.<br>Since strings are binary safe blobs and their maximum length is 512 MB,<br>they are suitable to set up to 2^32 different bits.</p>\n<p>You can perform bitwise operations on one or more strings.<br>Some examples of bitmap use cases include:</p>\n<ul>\n<li>Efficient set representations for cases where the members of a set correspond to the integers 0-N.</li>\n<li>Object permissions, where each bit represents a particular permission, similar to the way that file systems store permissions.</li>\n</ul>\n<h2>Basic commands</h2>\n<ul>\n<li><code>SETBIT</code> sets a bit at the provided offset to 0 or 1.</li>\n<li><code>GETBIT</code> returns the value of a bit at a given offset.</li>\n</ul>\n<p>See the <a href=\"../commands/#bitmap\">complete list of bitmap commands</a>.</p>\n<h2>Example</h2>\n<p>Suppose you have 1000 cyclists racing through the country-side, with sensors on their bikes labeled 0-999.<br>You want to quickly determine whether a given sensor has pinged a tracking server within the hour to check in on a rider. </p>\n<p>You can represent this scenario using a bitmap whose key references the current hour.</p>\n<ul>\n<li>Rider 123 pings the server on January 1, 2024 within the 00:00 hour. You can then confirm that rider 123 pinged the server. You can also check to see if rider 456 has pinged the server for that same hour.</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; SETBIT pings:2024-01-01-00:00 123 1\n(integer) 0\n127.0.0.1:6379&gt; GETBIT pings:2024-01-01-00:00 123\n(integer) 1\n127.0.0.1:6379&gt; GETBIT pings:2024-01-01-00:00 456\n(integer) 0\n</code></pre>\n<h2>Bit Operations</h2>\n<p>Bit operations are divided into two groups: constant-time single bit<br>operations, like setting a bit to 1 or 0, or getting its value, and<br>operations on groups of bits, for example counting the number of set<br>bits in a given range of bits (e.g., population counting).</p>\n<p>One of the biggest advantages of bitmaps is that they often provide<br>extreme space savings when storing information. For example in a system<br>where different users are represented by incremental user IDs, it is possible<br>to remember a single bit information (for example, knowing whether<br>a user wants to receive a newsletter) of 4 billion users using just 512 MB of memory.</p>\n<p>The <code>SETBIT</code> command takes as its first argument the bit number, and as its second<br>argument the value to set the bit to, which is 1 or 0. The command<br>automatically enlarges the string if the addressed bit is outside the<br>current string length.</p>\n<p><code>GETBIT</code> just returns the value of the bit at the specified index.<br>Out of range bits (addressing a bit that is outside the length of the string<br>stored into the target key) are always considered to be zero.</p>\n<p>There are three commands operating on group of bits:</p>\n<ol>\n<li><code>BITOP</code> performs bit-wise operations between different strings. The provided operations are AND, OR, XOR and NOT.</li>\n<li><code>BITCOUNT</code> performs population counting, reporting the number of bits set to 1.</li>\n<li><code>BITPOS</code> finds the first bit having the specified value of 0 or 1.</li>\n</ol>\n<p>Both <code>BITPOS</code> and <code>BITCOUNT</code> are able to operate with byte ranges of the<br>string, instead of running for the whole length of the string. We can trivially see the number of bits that have been set in a bitmap.</p>\n<pre><code>127.0.0.1:6379&gt; BITCOUNT pings:2024-01-01-00:00\n(integer) 1\n</code></pre>\n<p>For example imagine you want to know the longest streak of daily visits of<br>your web site users. You start counting days starting from zero, that is the<br>day you made your web site public, and set a bit with <code>SETBIT</code> every time<br>the user visits the web site. As a bit index you simply take the current unix<br>time, subtract the initial offset, and divide by the number of seconds in a day<br>(normally, 3600*24).</p>\n<p>This way for each user you have a small string containing the visit<br>information for each day. With <code>BITCOUNT</code> it is possible to easily get<br>the number of days a given user visited the web site, while with<br>a few <code>BITPOS</code> calls, or simply fetching and analyzing the bitmap client-side,<br>it is possible to easily compute the longest streak.</p>\n<p>Bitmaps are trivial to split into multiple keys, for example for<br>the sake of sharding the data set and because in general it is better to<br>avoid working with huge keys. To split a bitmap across different keys<br>instead of setting all the bits into a key, a trivial strategy is just<br>to store M bits per key and obtain the key name with <code>bit-number/M</code> and<br>the Nth bit to address inside the key with <code>bit-number MOD M</code>.</p>\n<h2>Performance</h2>\n<p><code>SETBIT</code> and <code>GETBIT</code> are O(1).<br><code>BITOP</code> is O(n), where <em>n</em> is the length of the longest string in the comparison.</p>\n"
      },
      {
        "id": "data-types",
        "topicName": "Data types",
        "description": "Overview of data types supported by Valkey",
        "htmlContent": "<p>Valkey is a data structure server.<br>At its core, Valkey provides a collection of native data types that help you solve a wide variety of problems, from <a href=\"client-side-caching\">caching</a> to <a href=\"lists\">queuing</a> to <a href=\"streams-intro\">event processing</a>.<br>Below is a short description of each data type, with links to broader overviews and command references.</p>\n<p>If you&#39;d like to try a comprehensive tutorial for each data structure, see their overview pages below.</p>\n<h2>Strings</h2>\n<p><a href=\"strings\">Strings</a> are the most basic Valkey data type, representing a sequence of bytes.<br>For more information, see:</p>\n<ul>\n<li><a href=\"strings\">Overview of Strings</a></li>\n<li><a href=\"../commands/#string\">String command reference</a></li>\n</ul>\n<h2>Lists</h2>\n<p><a href=\"lists\">Lists</a> are lists of strings sorted by insertion order.<br>For more information, see:</p>\n<ul>\n<li><a href=\"lists\">Overview of Lists</a></li>\n<li><a href=\"../commands/#list\">List command reference</a></li>\n</ul>\n<h2>Sets</h2>\n<p><a href=\"sets\">Sets</a> are unordered collections of unique strings that act like the sets from your favorite programming language (for example, <a href=\"https://docs.oracle.com/javase/7/docs/api/java/util/HashSet.html\">Java HashSets</a>, <a href=\"https://docs.python.org/3.10/library/stdtypes.html#set-types-set-frozenset\">Python sets</a>, and so on).<br>With a Set, you can add, remove, and test for existence in O(1) time (in other words, regardless of the number of set elements).<br>For more information, see:</p>\n<ul>\n<li><a href=\"sets\">Overview of Sets</a></li>\n<li><a href=\"../commands/#set\">Set command reference</a></li>\n</ul>\n<h2>Hashes</h2>\n<p><a href=\"hashes\">Hashes</a> are record types modeled as collections of field-value pairs.<br>As such, Hashes resemble <a href=\"https://docs.python.org/3/tutorial/datastructures.html#dictionaries\">Python dictionaries</a>, <a href=\"https://docs.oracle.com/javase/8/docs/api/java/util/HashMap.html\">Java HashMaps</a>, and <a href=\"https://ruby-doc.org/core-3.1.2/Hash.html\">Ruby hashes</a>.<br>For more information, see:</p>\n<ul>\n<li><a href=\"hashes\">Overview of Hashes</a></li>\n<li><a href=\"../commands/#hash\">Hashes command reference</a></li>\n</ul>\n<h2>Sorted sets</h2>\n<p><a href=\"sorted-sets\">Sorted Sets</a> are collections of unique strings that maintain order by each string&#39;s associated score.<br>For more information, see:</p>\n<ul>\n<li><a href=\"sorted-sets\">Overview of Sorted Sets</a></li>\n<li><a href=\"../commands/#sorted-set\">Sorted Set command reference</a></li>\n</ul>\n<h2>Streams</h2>\n<p>A <a href=\"streams-intro\">Stream</a> is a data structure that acts like an append-only log.<br>Streams help record events in the order they occur and then syndicate them for processing.<br>For more information, see:</p>\n<ul>\n<li><a href=\"streams-intro\">Overview of Streams</a></li>\n<li><a href=\"../commands/#stream\">Streams command reference</a></li>\n</ul>\n<h2>Geospatial indexes</h2>\n<p><a href=\"geospatial\">Geospatial indexes</a> are useful for finding locations within a given geographic radius or bounding box.<br>For more information, see:</p>\n<ul>\n<li><a href=\"geospatial\">Overview of Geospatial indexes</a></li>\n<li><a href=\"../commands/#geo\">Geospatial indexes command reference</a></li>\n</ul>\n<h2>Bitmaps</h2>\n<p><a href=\"bitmaps\">Bitmaps</a> let you perform bitwise operations on strings.<br>For more information, see:</p>\n<ul>\n<li><a href=\"bitmaps\">Overview of Bitmaps</a></li>\n<li><a href=\"../commands/#bitmap\">Bitmap command reference</a></li>\n</ul>\n<h2>Bitfields</h2>\n<p><a href=\"bitfields\">Bitfields</a> efficiently encode multiple counters in a string value.<br>Bitfields provide atomic get, set, and increment operations and support different overflow policies.<br>For more information, see:</p>\n<ul>\n<li><a href=\"bitfields\">Overview of Bitfields</a></li>\n<li>The <code>BITFIELD</code> command.</li>\n</ul>\n<h2>HyperLogLog</h2>\n<p>The <a href=\"hyperloglogs\">HyperLogLog</a> data structures provide probabilistic estimates of the cardinality (i.e., number of elements) of large sets. For more information, see:</p>\n<ul>\n<li><a href=\"hyperloglogs\">Overview of HyperLogLog</a></li>\n<li><a href=\"../commands/#hyperloglog\">HyperLogLog command reference</a></li>\n</ul>\n<h2>Extensions</h2>\n<p>To extend the features provided by the included data types, use one of these options:</p>\n<ol>\n<li>Write your own custom <a href=\"programmability\">server-side functions in Lua</a>.</li>\n<li>Write your own Valkey module using the <a href=\"modules-intro\">modules API</a> or check out the <a href=\"../modules/\">modules</a>.</li>\n</ol>\n"
      },
      {
        "id": "geospatial",
        "topicName": "Geospatial",
        "description": "Introduction to the Valkey Geospatial data type\n",
        "htmlContent": "<p>Geospatial indexes let you store coordinates and search for them.<br>This data structure is useful for finding nearby points within a given radius or bounding box.</p>\n<h2>Basic commands</h2>\n<ul>\n<li><code>GEOADD</code> adds a location to a given geospatial index (note that longitude comes before latitude with this command).</li>\n<li><code>GEOSEARCH</code> returns locations with a given radius or a bounding box.</li>\n</ul>\n<p>See the <a href=\"../commands/#geo\">complete list of geospatial index commands</a>.</p>\n<h2>Examples</h2>\n<p>Suppose you&#39;re building a mobile app that lets you find all of the bike rental stations closest to your current location.</p>\n<p>Add several locations to a geospatial index:</p>\n<pre><code>127.0.0.1:6379&gt; GEOADD bikes:rentable -122.27652 37.805186 station:1\n(integer) 1\n127.0.0.1:6379&gt; GEOADD bikes:rentable -122.2674626 37.8062344 station:2\n(integer) 1\n127.0.0.1:6379&gt; GEOADD bikes:rentable -122.2469854 37.8104049 station:3\n(integer) 1\n</code></pre>\n<p>Find all locations within a 5 kilometer radius of a given location, and return the distance to each location:</p>\n<pre><code>127.0.0.1:6379&gt; GEOSEARCH bikes:rentable FROMLONLAT -122.2612767 37.7936847 BYRADIUS 5 km WITHDIST\n1) 1) &quot;station:1&quot;\n   2) &quot;1.8523&quot;\n2) 1) &quot;station:2&quot;\n   2) &quot;1.4979&quot;\n3) 1) &quot;station:3&quot;\n   2) &quot;2.2441&quot;\n</code></pre>\n"
      },
      {
        "id": "hashes",
        "topicName": "Hashes",
        "description": "Introduction to Hashes\n",
        "htmlContent": "<p>Hashes are record types structured as collections of field-value pairs.<br>You can use hashes to represent basic objects and to store groupings of counters, among other things.</p>\n<pre><code>127.0.0.1:6379&gt; HSET bike:1 model Deimos brand Ergonom type &#39;Enduro bikes&#39; price 4972\n(integer) 4\n127.0.0.1:6379&gt; HGET bike:1 model\n&quot;Deimos&quot;\n127.0.0.1:6379&gt; HGET bike:1 price\n&quot;4972&quot;\n127.0.0.1:6379&gt; HGETALL bike:1\n1) &quot;model&quot;\n2) &quot;Deimos&quot;\n3) &quot;brand&quot;\n4) &quot;Ergonom&quot;\n5) &quot;type&quot;\n6) &quot;Enduro bikes&quot;\n7) &quot;price&quot;\n8) &quot;4972&quot;\n</code></pre>\n<p>While hashes are handy to represent <em>objects</em>, actually the number of fields you can<br>put inside a hash has no practical limits (other than available memory), so you can use<br>hashes in many different ways inside your application.</p>\n<p>The command <code>HSET</code> sets multiple fields of the hash, while <code>HGET</code> retrieves<br>a single field. <code>HMGET</code> is similar to <code>HGET</code> but returns an array of values:</p>\n<pre><code>127.0.0.1:6379&gt; HMGET bike:1 model price no-such-field\n1) &quot;Deimos&quot;\n2) &quot;4972&quot;\n3) (nil)\n</code></pre>\n<p>There are commands that are able to perform operations on individual fields<br>as well, like <code>HINCRBY</code>:</p>\n<pre><code>127.0.0.1:6379&gt; HINCRBY bike:1 price 100\n(integer) 5072\n127.0.0.1:6379&gt; HINCRBY bike:1 price -100\n(integer) 4972\n</code></pre>\n<p>It is worth noting that small hashes (i.e., a few elements with small values) are<br>encoded in special way in memory that make them very memory efficient.</p>\n<h2>Basic commands</h2>\n<ul>\n<li><code>HSET</code> sets the value of one or more fields on a hash.</li>\n<li><code>HGET</code> returns the value at a given field.</li>\n<li><code>HMGET</code> returns the values at one or more given fields.</li>\n<li><code>HINCRBY</code> increments the value at a given field by the integer provided.</li>\n</ul>\n<p>See the <a href=\"../commands/#hash\">complete list of hash commands</a>.</p>\n<h2>Examples</h2>\n<ul>\n<li>Store counters for the number of times bike:1 has been ridden, has crashed, or has changed owners:</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; HINCRBY bike:1:stats rides 1\n(integer) 1\n127.0.0.1:6379&gt; HINCRBY bike:1:stats rides 1\n(integer) 2\n127.0.0.1:6379&gt; HINCRBY bike:1:stats rides 1\n(integer) 3\n127.0.0.1:6379&gt; HINCRBY bike:1:stats crashes 1\n(integer) 1\n127.0.0.1:6379&gt; HINCRBY bike:1:stats owners 1\n(integer) 1\n127.0.0.1:6379&gt; HGET bike:1:stats rides\n&quot;3&quot;\n127.0.0.1:6379&gt; HMGET bike:1:stats owners crashes\n1) &quot;1&quot;\n2) &quot;1&quot;\n</code></pre>\n<h2>Performance</h2>\n<p>Most Hash commands are O(1).</p>\n<p>A few commands - such as <code>HKEYS</code>, <code>HVALS</code>, and <code>HGETALL</code> - are O(n), where <em>n</em> is the number of field-value pairs.</p>\n<h2>Limits</h2>\n<p>Every hash can store up to 4,294,967,295 (2^32 - 1) field-value pairs.<br>In practice, your hashes are limited only by the overall memory on the VMs hosting your Valkey deployment.</p>\n"
      },
      {
        "id": "hyperloglogs",
        "topicName": "HyperLogLog",
        "description": "HyperLogLog is a probabilistic data structure that estimates the cardinality of a set.\n",
        "htmlContent": "<p>HyperLogLog is a probabilistic data structure that estimates the cardinality of a set. As a probabilistic data structure, HyperLogLog trades perfect accuracy for efficient space utilization.</p>\n<p>The HyperLogLog implementation uses up to 12 KB and provides a standard error of 0.81%.</p>\n<p>Counting unique items usually requires an amount of memory<br>proportional to the number of items you want to count, because you need<br>to remember the elements you have already seen in the past in order to avoid<br>counting them multiple times. However, a set of algorithms exist that trade<br>memory for precision: they return an estimated measure with a standard error,<br>which, in the case of the Valkey implementation for HyperLogLog, is less than 1%.<br>The magic of this algorithm is that you no longer need to use an amount of memory<br>proportional to the number of items counted, and instead can use a<br>constant amount of memory; 12k bytes in the worst case, or a lot less if your<br>HyperLogLog (We&#39;ll just call them HLL from now) has seen very few elements.</p>\n<p>HLLs in Valkey, while technically a different data structure, are encoded<br>as a String, so you can call <code>GET</code> to serialize a HLL, and <code>SET</code><br>to deserialize it back to the server.</p>\n<p>Conceptually the HLL API is like using Sets to do the same task. You would<br><code>SADD</code> every observed element into a set, and would use <code>SCARD</code> to check the<br>number of elements inside the set, which are unique since <code>SADD</code> will not<br>re-add an existing element.</p>\n<p>While you don&#39;t really <em>add items</em> into an HLL, because the data structure<br>only contains a state that does not include actual elements, the API is the<br>same:</p>\n<ul>\n<li>Every time you see a new element, you add it to the count with <code>PFADD</code>.</li>\n<li>When you want to retrieve the current approximation of unique elements added using the <code>PFADD</code> command, you can use the <code>PFCOUNT</code> command. If you need to merge two different HLLs, the <code>PFMERGE</code> command is available. Since HLLs provide approximate counts of unique elements, the result of the merge will give you an approximation of the number of unique elements across both source HLLs.</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; PFADD bikes Hyperion Deimos Phoebe Quaoar\n(integer) 1\n127.0.0.1:6379&gt; PFCOUNT bikes\n(integer) 4\n127.0.0.1:6379&gt; PFADD commuter_bikes Salacia Mimas Quaoar\n(integer) 1\n127.0.0.1:6379&gt; PFMERGE all_bikes bikes commuter_bikes\nOK\n127.0.0.1:6379&gt; PFCOUNT all_bikes\n(integer) 6\n</code></pre>\n<p>Some examples of use cases for this data structure is counting unique queries<br>performed by users in a search form every day, number of unique visitors to a web page and other similar cases.</p>\n<p>Valkey is also able to perform the union of HLLs, please check the<br><a href=\"../commands/#hyperloglog\">full documentation</a> for more information.</p>\n<h2>Use cases</h2>\n<p><strong>Anonymous unique visits of a web page (SaaS, analytics tools)</strong> </p>\n<p>This application answers these questions: </p>\n<ul>\n<li>How many unique visits has this page had on this day? </li>\n<li>How many unique users have played this song? </li>\n<li>How many unique users have viewed this video?</li>\n</ul>\n<p><strong>Note:</strong><br>Storing the IP address or any other kind of personal identifier is against the law in some countries, which makes it impossible to get unique visitor statistics on your website.</p>\n<p>One HyperLogLog is created per page (video/song) per period, and every IP/identifier is added to it on every visit.</p>\n<h2>Basic commands</h2>\n<ul>\n<li><code>PFADD</code> adds an item to a HyperLogLog.</li>\n<li><code>PFCOUNT</code> returns an estimate of the number of items in the set.</li>\n<li><code>PFMERGE</code> combines two or more HyperLogLogs into one.</li>\n</ul>\n<p>See the <a href=\"../commands/#hyperloglog\">complete list of HyperLogLog commands</a>.</p>\n<h2>Performance</h2>\n<p>Writing (<code>PFADD</code>) to and reading from (<code>PFCOUNT</code>) the HyperLogLog is done in constant time and space.<br>Merging HLLs is O(n), where <em>n</em> is the number of sketches.</p>\n<h2>Limits</h2>\n<p>The HyperLogLog can estimate the cardinality of sets with up to 18,446,744,073,709,551,616 (2^64) members.</p>\n<h2>Learn more</h2>\n<ul>\n<li>This blog post on <a href=\"https://web.archive.org/web/20241019222035/http://antirez.com/news/75\">the HyperLogLog data structure</a> has a lot of details about the data structure and its implementation in Valkey.</li>\n</ul>\n"
      },
      {
        "id": "lists",
        "topicName": "Lists",
        "description": "Introduction to Lists\n",
        "htmlContent": "<p>Lists are linked lists of string values.<br>Lists are frequently used to:</p>\n<ul>\n<li>Implement stacks and queues.</li>\n<li>Build queue management for background worker systems.</li>\n</ul>\n<h2>Basic commands</h2>\n<ul>\n<li><code>LPUSH</code> adds a new element to the head of a list; <code>RPUSH</code> adds to the tail.</li>\n<li><code>LPOP</code> removes and returns an element from the head of a list; <code>RPOP</code> does the same but from the tails of a list. </li>\n<li><code>LLEN</code> returns the length of a list.</li>\n<li><code>LMOVE</code> atomically moves elements from one list to another.</li>\n<li><code>LTRIM</code> reduces a list to the specified range of elements.</li>\n</ul>\n<h3>Blocking commands</h3>\n<p>Lists support several blocking commands.<br>For example:</p>\n<ul>\n<li><code>BLPOP</code> removes and returns an element from the head of a list.<br>If the list is empty, the command blocks until an element becomes available or until the specified timeout is reached.</li>\n<li><code>BLMOVE</code> atomically moves elements from a source list to a target list.<br>If the source list is empty, the command will block until a new element becomes available.</li>\n</ul>\n<p>See the <a href=\"../commands/#list\">complete series of list commands</a>.</p>\n<h2>Examples</h2>\n<ul>\n<li>Treat a list like a queue (first in, first out):</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; LPUSH bikes:repairs bike:1\n(integer) 1\n127.0.0.1:6379&gt; LPUSH bikes:repairs bike:2\n(integer) 2\n127.0.0.1:6379&gt; RPOP bikes:repairs\n&quot;bike:1&quot;\n127.0.0.1:6379&gt; RPOP bikes:repairs\n&quot;bike:2&quot;\n</code></pre>\n<ul>\n<li>Treat a list like a stack (first in, last out):</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; LPUSH bikes:repairs bike:1\n(integer) 1\n127.0.0.1:6379&gt; LPUSH bikes:repairs bike:2\n(integer) 2\n127.0.0.1:6379&gt; LPOP bikes:repairs\n&quot;bike:2&quot;\n127.0.0.1:6379&gt; LPOP bikes:repairs\n&quot;bike:1&quot;\n</code></pre>\n<ul>\n<li>Check the length of a list:</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; LLEN bikes:repairs\n(integer) 0\n</code></pre>\n<ul>\n<li>Atomically pop an element from one list and push to another:</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; LPUSH bikes:repairs bike:1\n(integer) 1\n127.0.0.1:6379&gt; LPUSH bikes:repairs bike:2\n(integer) 2\n127.0.0.1:6379&gt; LMOVE bikes:repairs bikes:finished LEFT LEFT\n&quot;bike:2&quot;\n127.0.0.1:6379&gt; LRANGE bikes:repairs 0 -1\n1) &quot;bike:1&quot;\n127.0.0.1:6379&gt; LRANGE bikes:finished 0 -1\n1) &quot;bike:2&quot;\n</code></pre>\n<ul>\n<li>To limit the length of a list you can call <code>LTRIM</code>:</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; RPUSH bikes:repairs bike:1 bike:2 bike:3 bike:4 bike:5\n(integer) 5\n127.0.0.1:6379&gt; LTRIM bikes:repairs 0 2\nOK\n127.0.0.1:6379&gt; LRANGE bikes:repairs 0 -1\n1) &quot;bike:1&quot;\n2) &quot;bike:2&quot;\n3) &quot;bike:3&quot;\n</code></pre>\n<h3>What are Lists?</h3>\n<p>To explain the List data type it&#39;s better to start with a little bit of theory,<br>as the term <em>List</em> is often used in an improper way by information technology<br>folks. For instance &quot;Python Lists&quot; are not what the name may suggest (Linked<br>Lists), but rather Arrays (the same data type is called Array in<br>Ruby actually).</p>\n<p>From a very general point of view a List is just a sequence of ordered<br>elements: 10,20,1,2,3 is a list. But the properties of a List implemented using<br>an Array are very different from the properties of a List implemented using a<br><em>Linked List</em>.</p>\n<p>Lists are implemented via Linked Lists. This means that even if you have<br>millions of elements inside a list, the operation of adding a new element in<br>the head or in the tail of the list is performed <em>in constant time</em>. The speed of adding a<br>new element with the <code>LPUSH</code> command to the head of a list with ten<br>elements is the same as adding an element to the head of list with 10<br>million elements.</p>\n<p>What&#39;s the downside? Accessing an element <em>by index</em> is very fast in lists<br>implemented with an Array (constant time indexed access) and not so fast in<br>lists implemented by linked lists (where the operation requires an amount of<br>work proportional to the index of the accessed element).</p>\n<p>Lists are implemented with linked lists because for a database system it<br>is crucial to be able to add elements to a very long list in a very fast way.<br>Another strong advantage, as you&#39;ll see in a moment, is that Lists can be<br>taken at constant length in constant time.</p>\n<p>When fast access to the middle of a large collection of elements is important,<br>there is a different data structure that can be used, called sorted sets.<br>Sorted sets are covered in the <a href=\"sorted-sets\">Sorted sets</a> tutorial page.</p>\n<h3>First steps with Lists</h3>\n<p>The <code>LPUSH</code> command adds a new element into a list, on the<br>left (at the head), while the <code>RPUSH</code> command adds a new<br>element into a list, on the right (at the tail). Finally the<br><code>LRANGE</code> command extracts ranges of elements from lists:</p>\n<pre><code>127.0.0.1:6379&gt; RPUSH bikes:repairs bike:1\n(integer) 1\n127.0.0.1:6379&gt; RPUSH bikes:repairs bike:2\n(integer) 2\n127.0.0.1:6379&gt; LPUSH bikes:repairs bike:important_bike\n(integer) 3\n127.0.0.1:6379&gt; LRANGE bikes:repairs 0 -1\n1) &quot;bike:important_bike&quot;\n2) &quot;bike:1&quot;\n3) &quot;bike:2&quot;\n</code></pre>\n<p>Note that <code>LRANGE</code> takes two indexes, the first and the last<br>element of the range to return. Both the indexes can be negative, telling Valkey<br>to start counting from the end: so -1 is the last element, -2 is the<br>penultimate element of the list, and so forth.</p>\n<p>As you can see <code>RPUSH</code> appended the elements on the right of the list, while<br>the final <code>LPUSH</code> appended the element on the left.</p>\n<p>Both commands are <em>variadic commands</em>, meaning that you are free to push<br>multiple elements into a list in a single call:</p>\n<pre><code>127.0.0.1:6379&gt; RPUSH bikes:repairs bike:1 bike:2 bike:3\n(integer) 3\n127.0.0.1:6379&gt; LPUSH bikes:repairs bike:important_bike bike:very_important_bike\n127.0.0.1:6379&gt; LRANGE mylist 0 -1\n1) &quot;bike:very_important_bike&quot;\n2) &quot;bike:important_bike&quot;\n3) &quot;bike:1&quot;\n4) &quot;bike:2&quot;\n5) &quot;bike:3&quot;\n</code></pre>\n<p>An important operation defined on Lists is the ability to <em>pop elements</em>.<br>Popping elements is the operation of both retrieving the element from the list,<br>and eliminating it from the list, at the same time. You can pop elements<br>from left and right, similarly to how you can push elements in both sides<br>of the list. We&#39;ll add three elements and pop three elements, so at the end of this<br>sequence of commands the list is empty and there are no more elements to<br>pop:</p>\n<pre><code>127.0.0.1:6379&gt; RPUSH bikes:repairs bike:1 bike:2 bike:3\n(integer) 3\n127.0.0.1:6379&gt; RPOP bikes:repairs\n&quot;bike:3&quot;\n127.0.0.1:6379&gt; LPOP bikes:repairs\n&quot;bike:1&quot;\n127.0.0.1:6379&gt; RPOP bikes:repairs\n&quot;bike:2&quot;\n127.0.0.1:6379&gt; RPOP bikes:repairs\n(nil)\n</code></pre>\n<p>Valkey returned a NULL value to signal that there are no elements in the<br>list.</p>\n<h3>Common use cases for lists</h3>\n<p>Lists are useful for a number of tasks, two very representative use cases<br>are the following:</p>\n<ul>\n<li>Remember the latest updates posted by users into a social network.</li>\n<li>Communication between processes, using a consumer-producer pattern where the producer pushes items into a list, and a consumer (usually a <em>worker</em>) consumes those items and executes actions. Valkey has special list commands to make this use case both more reliable and efficient.</li>\n</ul>\n<p>For example both the popular Ruby libraries <a href=\"https://github.com/resque/resque\">resque</a> and<br><a href=\"https://github.com/mperham/sidekiq\">sidekiq</a> use Lists under the hood in order to<br>implement background jobs.</p>\n<p>The popular Twitter social network <a href=\"https://www.infoq.com/presentations/Real-Time-Delivery-Twitter\">takes the latest tweets</a><br>posted by users into Lists.</p>\n<p>To describe a common use case step by step, imagine your home page shows the latest<br>photos published in a photo sharing social network and you want to speedup access.</p>\n<ul>\n<li>Every time a user posts a new photo, we add its ID into a list with <code>LPUSH</code>.</li>\n<li>When users visit the home page, we use <code>LRANGE 0 9</code> in order to get the latest 10 posted items.</li>\n</ul>\n<h3>Capped lists</h3>\n<p>In many use cases we just want to use lists to store the <em>latest items</em>,<br>whatever they are: social network updates, logs, or anything else.</p>\n<p>Valkey allows us to use lists as a capped collection, only remembering the latest<br>N items and discarding all the oldest items using the <code>LTRIM</code> command.</p>\n<p>The <code>LTRIM</code> command is similar to <code>LRANGE</code>, but <strong>instead of displaying the<br>specified range of elements</strong> it sets this range as the new list value. All<br>the elements outside the given range are removed.</p>\n<p>For example, if you&#39;re adding bikes on the end of a list of repairs, but only<br>want to worry about the 3 that have been on the list the longest:</p>\n<pre><code>127.0.0.1:6379&gt; RPUSH bikes:repairs bike:1 bike:2 bike:3 bike:4 bike:5\n(integer) 5\n127.0.0.1:6379&gt; LTRIM bikes:repairs 0 2\nOK\n127.0.0.1:6379&gt; LRANGE bikes:repairs 0 -1\n1) &quot;bike:1&quot;\n2) &quot;bike:2&quot;\n3) &quot;bike:3&quot;\n</code></pre>\n<p>The above <code>LTRIM</code> command tells Valkey to keep just list elements from index<br>0 to 2, everything else will be discarded. This allows for a very simple but<br>useful pattern: doing a List push operation + a List trim operation together<br>to add a new element and discard elements exceeding a limit. Using<br><code>LTRIM</code> with negative indexes can then be used to keep only the 3 most recently added:</p>\n<pre><code>127.0.0.1:6379&gt; RPUSH bikes:repairs bike:1 bike:2 bike:3 bike:4 bike:5\n(integer) 5\n127.0.0.1:6379&gt; LTRIM bikes:repairs -3 -1\nOK\n127.0.0.1:6379&gt; LRANGE bikes:repairs 0 -1\n1) &quot;bike:3&quot;\n2) &quot;bike:4&quot;\n3) &quot;bike:5&quot;\n</code></pre>\n<p>The above combination adds new elements and keeps only the 3<br>newest elements into the list. With <code>LRANGE</code> you can access the top items<br>without any need to remember very old data.</p>\n<p>Note: while <code>LRANGE</code> is technically an O(N) command, accessing small ranges<br>towards the head or the tail of the list is a constant time operation.</p>\n<h2>Blocking operations on lists</h2>\n<p>Lists have a special feature that make them suitable to implement queues,<br>and in general as a building block for inter process communication systems:<br>blocking operations.</p>\n<p>Imagine you want to push items into a list with one process, and use<br>a different process in order to actually do some kind of work with those<br>items. This is the usual producer / consumer setup, and can be implemented<br>in the following simple way:</p>\n<ul>\n<li>To push items into the list, producers call <code>LPUSH</code>.</li>\n<li>To extract / process items from the list, consumers call <code>RPOP</code>.</li>\n</ul>\n<p>However it is possible that sometimes the list is empty and there is nothing<br>to process, so <code>RPOP</code> just returns NULL. In this case a consumer is forced to wait<br>some time and retry again with <code>RPOP</code>. This is called <em>polling</em>, and is not<br>a good idea in this context because it has several drawbacks:</p>\n<ol>\n<li>Forces Valkey and clients to process useless commands (all the requests when the list is empty will get no actual work done, they&#39;ll just return NULL).</li>\n<li>Adds a delay to the processing of items, since after a worker receives a NULL, it waits some time. To make the delay smaller, we could wait less between calls to <code>RPOP</code>, with the effect of amplifying problem number 1, i.e. more useless calls to Valkey.</li>\n</ol>\n<p>So Valkey implements commands called <code>BRPOP</code> and <code>BLPOP</code> which are versions<br>of <code>RPOP</code> and <code>LPOP</code> able to block if the list is empty: they&#39;ll return to<br>the caller only when a new element is added to the list, or when a user-specified<br>timeout is reached.</p>\n<p>This is an example of a <code>BRPOP</code> call we could use in the worker:</p>\n<pre><code>127.0.0.1:6379&gt; RPUSH bikes:repairs bike:1 bike:2\n(integer) 2\n127.0.0.1:6379&gt; BRPOP bikes:repairs 1\n1) &quot;bikes:repairs&quot;\n2) &quot;bike:2&quot;\n127.0.0.1:6379&gt; BRPOP bikes:repairs 1\n1) &quot;bikes:repairs&quot;\n2) &quot;bike:1&quot;\n127.0.0.1:6379&gt; BRPOP bikes:repairs 1\n(nil)\n(2.01s)\n</code></pre>\n<p>It means: &quot;wait for elements in the list <code>bikes:repairs</code>, but return if after 1 second<br>no element is available&quot;.</p>\n<p>Note that you can use 0 as timeout to wait for elements forever, and you can<br>also specify multiple lists and not just one, in order to wait on multiple<br>lists at the same time, and get notified when the first list receives an<br>element.</p>\n<p>A few things to note about <code>BRPOP</code>:</p>\n<ol>\n<li>Clients are served in an ordered way: the first client that blocked waiting for a list, is served first when an element is pushed by some other client, and so forth.</li>\n<li>The return value is different compared to <code>RPOP</code>: it is a two-element array since it also includes the name of the key, because <code>BRPOP</code> and <code>BLPOP</code> are able to block waiting for elements from multiple lists.</li>\n<li>If the timeout is reached, NULL is returned.</li>\n</ol>\n<p>There are more things you should know about lists and blocking ops. We<br>suggest that you read more on the following:</p>\n<ul>\n<li>It is possible to build safer queues or rotating queues using <code>LMOVE</code>.</li>\n<li>There is also a blocking variant of the command, called <code>BLMOVE</code>.</li>\n</ul>\n<h2>Automatic creation and removal of keys</h2>\n<p>So far in our examples we never had to create empty lists before pushing<br>elements, or removing empty lists when they no longer have elements inside.<br>It is Valkey&#39; responsibility to delete keys when lists are left empty, or to create<br>an empty list if the key does not exist and we are trying to add elements<br>to it, for example, with <code>LPUSH</code>.</p>\n<p>This is not specific to lists, it applies to all the Valkey data types<br>composed of multiple elements -- Streams, Sets, Sorted Sets and Hashes.</p>\n<p>Basically we can summarize the behavior with three rules:</p>\n<ol>\n<li>When we add an element to an aggregate data type, if the target key does not exist, an empty aggregate data type is created before adding the element.</li>\n<li>When we remove elements from an aggregate data type, if the value remains empty, the key is automatically destroyed. The Stream data type is the only exception to this rule.</li>\n<li>Calling a read-only command such as <code>LLEN</code> (which returns the length of the list), or a write command removing elements, with an empty key, always produces the same result as if the key is holding an empty aggregate type of the type the command expects to find.</li>\n</ol>\n<p>Examples of rule 1:</p>\n<pre><code>127.0.0.1:6379&gt; DEL new_bikes\n(integer) 0\n127.0.0.1:6379&gt; LPUSH new_bikes bike:1 bike:2 bike:3\n(integer) 3\n</code></pre>\n<p>However we can&#39;t perform operations against the wrong type if the key exists:</p>\n<pre><code>127.0.0.1:6379&gt; SET new_bikes bike:1\nOK\n127.0.0.1:6379&gt; TYPE new_bikes\nstring\n127.0.0.1:6379&gt; LPUSH new_bikes bike:2 bike:3\n(error) WRONGTYPE Operation against a key holding the wrong kind of value\n</code></pre>\n<p>Example of rule 2:</p>\n<pre><code>127.0.0.1:6379&gt; RPUSH bikes:repairs bike:1 bike:2 bike:3\n(integer) 3\n127.0.0.1:6379&gt; EXISTS bikes:repairs\n(integer) 1\n127.0.0.1:6379&gt; LPOP bikes:repairs\n&quot;bike:3&quot;\n127.0.0.1:6379&gt; LPOP bikes:repairs\n&quot;bike:2&quot;\n127.0.0.1:6379&gt; LPOP bikes:repairs\n&quot;bike:1&quot;\n127.0.0.1:6379&gt; EXISTS bikes:repairs\n(integer) 0\n</code></pre>\n<p>The key no longer exists after all the elements are popped.</p>\n<p>Example of rule 3:</p>\n<pre><code>127.0.0.1:6379&gt; DEL bikes:repairs\n(integer) 0\n127.0.0.1:6379&gt; LLEN bikes:repairs\n(integer) 0\n127.0.0.1:6379&gt; LPOP bikes:repairs\n(nil)\n</code></pre>\n<h2>Limits</h2>\n<p>The max length of a List is 2^32 - 1 (4,294,967,295) elements.</p>\n<h2>Performance</h2>\n<p>List operations that access its head or tail are O(1), which means they&#39;re highly efficient.<br>However, commands that manipulate elements within a list are usually O(n).<br>Examples of these include <code>LINDEX</code>, <code>LINSERT</code>, and <code>LSET</code>.<br>Exercise caution when running these commands, mainly when operating on large lists.</p>\n<h2>Alternatives</h2>\n<p>Consider <a href=\"streams-intro\">Streams</a> as an alternative to lists when you need to store and process an indeterminate series of events.</p>\n"
      },
      {
        "id": "sets",
        "topicName": "Sets",
        "description": "Introduction to Sets\n",
        "htmlContent": "<p>A Set is an unordered collection of unique strings (members).<br>You can use Sets to efficiently:</p>\n<ul>\n<li>Track unique items (e.g., track all unique IP addresses accessing a given blog post).</li>\n<li>Represent relations (e.g., the set of all users with a given role).</li>\n<li>Perform common set operations such as intersection, unions, and differences.</li>\n</ul>\n<h2>Basic commands</h2>\n<ul>\n<li><code>SADD</code> adds a new member to a set.</li>\n<li><code>SREM</code> removes the specified member from the set.</li>\n<li><code>SISMEMBER</code> tests a string for set membership.</li>\n<li><code>SINTER</code> returns the set of members that two or more sets have in common (i.e., the intersection).</li>\n<li><code>SCARD</code> returns the size (a.k.a. cardinality) of a set.</li>\n</ul>\n<p>See the <a href=\"../commands/#set\">complete list of set commands</a>.</p>\n<h2>Examples</h2>\n<ul>\n<li>Store the sets of bikes racing in France and the USA. Note that<br>if you add a member that already exists, it will be ignored.</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; SADD bikes:racing:france bike:1\n(integer) 1\n127.0.0.1:6379&gt; SADD bikes:racing:france bike:1\n(integer) 0\n127.0.0.1:6379&gt; SADD bikes:racing:france bike:2 bike:3\n(integer) 2\n127.0.0.1:6379&gt; SADD bikes:racing:usa bike:1 bike:4\n(integer) 2\n</code></pre>\n<ul>\n<li>Check whether bike:1 or bike:2 are racing in the US.</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; SISMEMBER bikes:racing:usa bike:1\n(integer) 1\n127.0.0.1:6379&gt; SISMEMBER bikes:racing:usa bike:2\n(integer) 0\n</code></pre>\n<ul>\n<li>Which bikes are competing in both races?</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; SINTER bikes:racing:france bikes:racing:usa\n1) &quot;bike:1&quot;\n</code></pre>\n<ul>\n<li>How many bikes are racing in France?</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; SCARD bikes:racing:france\n(integer) 3\n</code></pre>\n<h2>Tutorial</h2>\n<p>The <code>SADD</code> command adds new elements to a set. It&#39;s also possible<br>to do a number of other operations against sets like testing if a given element<br>already exists, performing the intersection, union or difference between<br>multiple sets, and so forth.</p>\n<pre><code>127.0.0.1:6379&gt; SADD bikes:racing:france bike:1 bike:2 bike:3\n(integer) 3\n127.0.0.1:6379&gt; SMEMBERS bikes:racing:france\n1) bike:3\n2) bike:1\n3) bike:2\n</code></pre>\n<p>Here I&#39;ve added three elements to my set and told Valkey to return all the<br>elements. There is no order guarantee with a set. Valkey is free to return the<br>elements in any order at every call.</p>\n<p>Valkey has commands to test for set membership. These commands can be used on single as well as multiple items:</p>\n<pre><code>127.0.0.1:6379&gt; SISMEMBER bikes:racing:france bike:1\n(integer) 1\n127.0.0.1:6379&gt; SMISMEMBER bikes:racing:france bike:2 bike:3 bike:4\n1) (integer) 1\n2) (integer) 1\n3) (integer) 0\n</code></pre>\n<p>We can also find the difference between two sets. For instance, we may want<br>to know which bikes are racing in France but not in the USA:</p>\n<pre><code>127.0.0.1:6379&gt; SADD bikes:racing:usa bike:1 bike:4\n(integer) 2\n127.0.0.1:6379&gt; SDIFF bikes:racing:france bikes:racing:usa\n1) &quot;bike:3&quot;\n2) &quot;bike:2&quot;\n</code></pre>\n<p>There are other non trivial operations that are still easy to implement<br>using the right Valkey commands. For instance we may want a list of all the<br>bikes racing in France, the USA, and some other races. We can do this using<br>the <code>SINTER</code> command, which performs the intersection between different<br>sets. In addition to intersection you can also perform<br>unions, difference, and more. For example<br>if we add a third race we can see some of these commands in action:</p>\n<pre><code>127.0.0.1:6379&gt; SADD bikes:racing:france bike:1 bike:2 bike:3\n(integer) 3\n127.0.0.1:6379&gt; SADD bikes:racing:usa bike:1 bike:4\n(integer) 2\n127.0.0.1:6379&gt; SADD bikes:racing:italy bike:1 bike:2 bike:3 bike:4\n(integer) 4\n127.0.0.1:6379&gt; SINTER bikes:racing:france bikes:racing:usa bikes:racing:italy\n1) &quot;bike:1&quot;\n127.0.0.1:6379&gt; SUNION bikes:racing:france bikes:racing:usa bikes:racing:italy\n1) &quot;bike:2&quot;\n2) &quot;bike:1&quot;\n3) &quot;bike:4&quot;\n4) &quot;bike:3&quot;\n127.0.0.1:6379&gt; SDIFF bikes:racing:france bikes:racing:usa bikes:racing:italy\n(empty array)\n127.0.0.1:6379&gt; SDIFF bikes:racing:france bikes:racing:usa\n1) &quot;bike:3&quot;\n2) &quot;bike:2&quot;\n127.0.0.1:6379&gt; SDIFF bikes:racing:usa bikes:racing:france\n1) &quot;bike:4&quot;\n</code></pre>\n<p>You&#39;ll note that the <code>SDIFF</code> command returns an empty array when the<br>difference between all sets is empty. You&#39;ll also note that the order of sets<br>passed to <code>SDIFF</code> matters, since the difference is not commutative.</p>\n<p>When you want to remove items from a set, you can use the <code>SREM</code> command to<br>remove one or more items from a set, or you can use the <code>SPOP</code> command to<br>remove a random item from a set. You can also <em>return</em> a random item from a<br>set without removing it using the <code>SRANDMEMBER</code> command:</p>\n<pre><code>127.0.0.1:6379&gt; SADD bikes:racing:france bike:1 bike:2 bike:3 bike:4 bike:5\n(integer) 5\n127.0.0.1:6379&gt; SREM bikes:racing:france bike:1\n(integer) 1\n127.0.0.1:6379&gt; SPOP bikes:racing:france\n&quot;bike:3&quot;\n127.0.0.1:6379&gt; SMEMBERS bikes:racing:france\n1) &quot;bike:2&quot;\n2) &quot;bike:4&quot;\n3) &quot;bike:5&quot;\n127.0.0.1:6379&gt; SRANDMEMBER bikes:racing:france\n&quot;bike:2&quot;\n</code></pre>\n<h2>Limits</h2>\n<p>The max size of a Set is 2^32 - 1 (4,294,967,295) members.</p>\n<h2>Performance</h2>\n<p>Most set operations, including adding, removing, and checking whether an item is a set member, are O(1).<br>This means that they&#39;re highly efficient.<br>However, for large sets with hundreds of thousands of members or more, you should exercise caution when running the <code>SMEMBERS</code> command.<br>This command is O(n) and returns the entire set in a single response.<br>As an alternative, consider the <code>SSCAN</code>, which lets you retrieve all members of a set iteratively.</p>\n"
      },
      {
        "id": "sorted-sets",
        "topicName": "Sorted Sets",
        "description": "Introduction to Sorted Sets\n",
        "htmlContent": "<p>A Sorted Set is a collection of unique strings (members) ordered by an associated score.<br>When more than one string has the same score, the strings are ordered lexicographically.<br>Some use cases for sorted sets include:</p>\n<ul>\n<li>Leaderboards. For example, you can use sorted sets to easily maintain  ordered lists of the highest scores in a massive online game.</li>\n<li>Rate limiters. In particular, you can use a sorted set to build a sliding-window rate limiter to prevent excessive API requests.</li>\n</ul>\n<p>You can think of sorted sets as a mix between a Set and<br>a Hash. Like sets, sorted sets are composed of unique, non-repeating<br>string elements, so in some sense a sorted set is a set as well.</p>\n<p>However while elements inside sets are not ordered, every element in<br>a sorted set is associated with a floating point value, called <em>the score</em><br>(this is why the type is also similar to a hash, since every element<br>is mapped to a value).</p>\n<p>Moreover, elements in a sorted set are <em>taken in order</em> (so they are not<br>ordered on request, order is a peculiarity of the data structure used to<br>represent sorted sets). They are ordered according to the following rule:</p>\n<ul>\n<li>If B and A are two elements with a different score, then A &gt; B if A.score is &gt; B.score.</li>\n<li>If B and A have exactly the same score, then A &gt; B if the A string is lexicographically greater than the B string. B and A strings can&#39;t be equal since sorted sets only have unique elements.</li>\n</ul>\n<p>Let&#39;s start with a simple example, we&#39;ll add all our racers and the score they got in the first race:</p>\n<pre><code>127.0.0.1:6379&gt; ZADD racer_scores 10 &quot;Norem&quot;\n(integer) 1\n127.0.0.1:6379&gt; ZADD racer_scores 12 &quot;Castilla&quot;\n(integer) 1\n127.0.0.1:6379&gt; ZADD racer_scores 8 &quot;Sam-Bodden&quot; 10 &quot;Royce&quot; 6 &quot;Ford&quot; 14 &quot;Prickett&quot;\n(integer) 4\n</code></pre>\n<p>As you can see <code>ZADD</code> is similar to <code>SADD</code>, but takes one additional argument<br>(placed before the element to be added) which is the score.<br><code>ZADD</code> is also variadic, so you are free to specify multiple score-value<br>pairs, even if this is not used in the example above.</p>\n<p>With sorted sets it is trivial to return a list of hackers sorted by their<br>birth year because actually <em>they are already sorted</em>.</p>\n<p>Implementation note: Sorted sets are implemented via a<br>dual-ported data structure containing both a skip list and a hash table, so<br>every time we add an element Valkey performs an O(log(N)) operation. That&#39;s<br>good, but when we ask for sorted elements Valkey does not have to do any work at<br>all, it&#39;s already sorted. Note that the <code>ZRANGE</code> order is low to high, while the <code>ZREVRANGE</code> order is high to low:</p>\n<pre><code>127.0.0.1:6379&gt; ZRANGE racer_scores 0 -1\n1) &quot;Ford&quot;\n2) &quot;Sam-Bodden&quot;\n3) &quot;Norem&quot;\n4) &quot;Royce&quot;\n5) &quot;Castilla&quot;\n6) &quot;Prickett&quot;\n127.0.0.1:6379&gt; ZREVRANGE racer_scores 0 -1\n1) &quot;Prickett&quot;\n2) &quot;Castilla&quot;\n3) &quot;Royce&quot;\n4) &quot;Norem&quot;\n5) &quot;Sam-Bodden&quot;\n6) &quot;Ford&quot;\n</code></pre>\n<p>Note: 0 and -1 means from element index 0 to the last element (-1 works<br>here just as it does in the case of the <code>LRANGE</code> command).</p>\n<p>It is possible to return scores as well, using the <code>WITHSCORES</code> argument:</p>\n<pre><code>127.0.0.1:6379&gt; ZRANGE racer_scores 0 -1 withscores\n 1) &quot;Ford&quot;\n 2) &quot;6&quot;\n 3) &quot;Sam-Bodden&quot;\n 4) &quot;8&quot;\n 5) &quot;Norem&quot;\n 6) &quot;10&quot;\n 7) &quot;Royce&quot;\n 8) &quot;10&quot;\n 9) &quot;Castilla&quot;\n10) &quot;12&quot;\n11) &quot;Prickett&quot;\n12) &quot;14&quot;\n</code></pre>\n<h3>Operating on ranges</h3>\n<p>Sorted sets are more powerful than this. They can operate on ranges.<br>Let&#39;s get all the racers with 10 or fewer points. We<br>use the <code>ZRANGEBYSCORE</code> command to do it:</p>\n<pre><code>127.0.0.1:6379&gt; ZRANGEBYSCORE racer_scores -inf 10\n1) &quot;Ford&quot;\n2) &quot;Sam-Bodden&quot;\n3) &quot;Norem&quot;\n4) &quot;Royce&quot;\n</code></pre>\n<p>We asked Valkey to return all the elements with a score between negative<br>infinity and 10 (both extremes are included).</p>\n<p>To remove an element we&#39;d simply call <code>ZREM</code> with the racer&#39;s name.<br>It&#39;s also possible to remove ranges of elements. Let&#39;s remove racer Castilla along with all<br>the racers with strictly fewer than 10 points:</p>\n<pre><code>127.0.0.1:6379&gt; ZREM racer_scores &quot;Castilla&quot;\n(integer) 1\n127.0.0.1:6379&gt; ZREMRANGEBYSCORE racer_scores -inf 9\n(integer) 2\n127.0.0.1:6379&gt; ZRANGE racer_scores 0 -1\n1) &quot;Norem&quot;\n2) &quot;Royce&quot;\n3) &quot;Prickett&quot;\n</code></pre>\n<p><code>ZREMRANGEBYSCORE</code> is perhaps not the best command name,<br>but it can be very useful, and returns the number of removed elements.</p>\n<p>Another extremely useful operation defined for sorted set elements<br>is the get-rank operation. It is possible to ask what is the<br>position of an element in the set of ordered elements.<br>The <code>ZREVRANK</code> command is also available in order to get the rank, considering<br>the elements sorted in a descending way.</p>\n<pre><code>127.0.0.1:6379&gt; ZRANK racer_scores &quot;Norem&quot;\n(integer) 0\n127.0.0.1:6379&gt; ZREVRANK racer_scores &quot;Norem&quot;\n(integer) 3\n</code></pre>\n<h3>Lexicographical scores</h3>\n<p>A family of commands allow<br>getting ranges lexicographically, assuming elements in a sorted set are all<br>inserted with the same identical score. Elements are compared with the C<br><code>memcmp</code> function, so it is guaranteed that there is no collation, and every<br>Valkey instance will reply with the same output.</p>\n<p>The main commands to operate with lexicographical ranges are <code>ZRANGEBYLEX</code>,<br><code>ZREVRANGEBYLEX</code>, <code>ZREMRANGEBYLEX</code> and <code>ZLEXCOUNT</code>.</p>\n<p>For example, let&#39;s add again our list of famous hackers, but this time<br>using a score of zero for all the elements. We&#39;ll see that because of the sorted sets ordering rules, they are already sorted lexicographically. Using <code>ZRANGEBYLEX</code> we can ask for lexicographical ranges:</p>\n<pre><code>127.0.0.1:6379&gt; ZADD racer_scores 0 &quot;Norem&quot; 0 &quot;Sam-Bodden&quot; 0 &quot;Royce&quot; 0 &quot;Castilla&quot; 0 &quot;Prickett&quot; 0 &quot;Ford&quot;\n(integer) 3\n127.0.0.1:6379&gt; ZRANGE racer_scores 0 -1\n1) &quot;Castilla&quot;\n2) &quot;Ford&quot;\n3) &quot;Norem&quot;\n4) &quot;Prickett&quot;\n5) &quot;Royce&quot;\n6) &quot;Sam-Bodden&quot;\n127.0.0.1:6379&gt; ZRANGEBYLEX racer_scores [A [L\n1) &quot;Castilla&quot;\n2) &quot;Ford&quot;\n</code></pre>\n<p>Ranges can be inclusive or exclusive (depending on the first character),<br>also string infinite and minus infinite are specified respectively with<br>the <code>+</code> and <code>-</code> strings. See the documentation for more information.</p>\n<p>This feature is important because it allows us to use sorted sets as a generic<br>index. For example, if you want to index elements by a 128-bit unsigned<br>integer argument, all you need to do is to add elements into a sorted<br>set with the same score (for example 0) but with a 16 byte prefix<br>consisting of <strong>the 128 bit number in big endian</strong>. Since numbers in big<br>endian, when ordered lexicographically (in raw bytes order) are actually<br>ordered numerically as well, you can ask for ranges in the 128 bit space,<br>and get the element&#39;s value discarding the prefix.</p>\n<h2>Updating the score: leaderboards</h2>\n<p>Just a final note about sorted sets before switching to the next topic.<br>Sorted sets&#39; scores can be updated at any time. Just calling <code>ZADD</code> against<br>an element already included in the sorted set will update its score<br>(and position) with O(log(N)) time complexity.  As such, sorted sets are suitable<br>when there are tons of updates.</p>\n<p>Because of this characteristic a common use case is leaderboards.<br>The typical application is a Facebook game where you combine the ability to<br>take users sorted by their high score, plus the get-rank operation, in order<br>to show the top-N users, and the user rank in the leader board (e.g., &quot;you are<br>the #4932 best score here&quot;).</p>\n<h2>Examples</h2>\n<ul>\n<li>There are two ways we can use a sorted set to represent a leaderboard. If we know a racer&#39;s new score, we can update it directly via the <code>ZADD</code> command. However, if we want to add points to an existing score, we can use the <code>ZINCRBY</code> command.</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; ZADD racer_scores 100 &quot;Wood&quot;\n(integer) 1\n127.0.0.1:6379&gt; ZADD racer_scores 100 &quot;Henshaw&quot;\n(integer) 1\n127.0.0.1:6379&gt; ZADD racer_scores 150 &quot;Henshaw&quot;\n(integer) 0\n127.0.0.1:6379&gt; ZINCRBY racer_scores 50 &quot;Wood&quot;\n&quot;150&quot;\n127.0.0.1:6379&gt; ZINCRBY racer_scores 50 &quot;Henshaw&quot;\n&quot;200&quot;\n</code></pre>\n<p>You&#39;ll see that <code>ZADD</code> returns 0 when the member already exists (the score is updated), while <code>ZINCRBY</code> returns the new score. The score for racer Henshaw went from 100, was changed to 150 with no regard for what score was there before, and then was incremented by 50 to 200.</p>\n<h2>Basic commands</h2>\n<ul>\n<li><code>ZADD</code> adds a new member and associated score to a sorted set. If the member already exists, the score is updated.</li>\n<li><code>ZRANGE</code> returns members of a sorted set, sorted within a given range.</li>\n<li><code>ZRANK</code> returns the rank of the provided member, assuming the sorted is in ascending order.</li>\n<li><code>ZREVRANK</code> returns the rank of the provided member, assuming the sorted set is in descending order.</li>\n</ul>\n<p>See the <a href=\"../commands/#sorted-set\">complete list of sorted set commands</a>.</p>\n<h2>Performance</h2>\n<p>Most sorted set operations are O(log(n)), where <em>n</em> is the number of members.</p>\n<p>Exercise some caution when running the <code>ZRANGE</code> command with large returns values (e.g., in the tens of thousands or more).<br>This command&#39;s time complexity is O(log(n) + m), where <em>m</em> is the number of results returned. </p>\n"
      },
      {
        "id": "streams-intro",
        "topicName": "Streams",
        "description": "Introduction to Streams\n",
        "htmlContent": "<p>A Stream is a data structure that acts like an append-only log but also implements several operations to overcome some of the limits of a typical append-only log. These include random access in O(1) time and complex consumption strategies, such as consumer groups.<br>You can use streams to record and simultaneously syndicate events in real time.<br>Examples of Stream use cases include:</p>\n<ul>\n<li>Event sourcing (e.g., tracking user actions, clicks, etc.)</li>\n<li>Sensor monitoring (e.g., readings from devices in the field) </li>\n<li>Notifications (e.g., storing a record of each user&#39;s notifications in a separate stream)</li>\n</ul>\n<p>Valkey generates a unique ID for each stream entry.<br>You can use these IDs to retrieve their associated entries later or to read and process all subsequent entries in the stream. Note that because these IDs are related to time, the ones shown here may vary and will be different from the IDs you see in your own Valkey instance.</p>\n<p>Streams support several trimming strategies (to prevent streams from growing unbounded) and more than one consumption strategy (see <code>XREAD</code>, <code>XREADGROUP</code>, and <code>XRANGE</code>).</p>\n<h2>Basic commands</h2>\n<ul>\n<li><code>XADD</code> adds a new entry to a stream.</li>\n<li><code>XREAD</code> reads one or more entries, starting at a given position and moving forward in time.</li>\n<li><code>XRANGE</code> returns a range of entries between two supplied entry IDs.</li>\n<li><code>XLEN</code> returns the length of a stream.</li>\n</ul>\n<p>See the <a href=\"../commands/#stream\">complete list of stream commands</a>.</p>\n<h2>Examples</h2>\n<ul>\n<li>When our racers pass a checkpoint, we add a stream entry for each racer that includes the racer&#39;s name, speed, position, and location ID:</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; XADD race:france * rider Castilla speed 30.2 position 1 location_id 1\n&quot;1692632086370-0&quot;\n127.0.0.1:6379&gt; XADD race:france * rider Norem speed 28.8 position 3 location_id 1\n&quot;1692632094485-0&quot;\n127.0.0.1:6379&gt; XADD race:france * rider Prickett speed 29.7 position 2 location_id 1\n&quot;1692632102976-0&quot;\n</code></pre>\n<ul>\n<li>Read two stream entries starting at ID <code>1692632086370-0</code>:</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; XRANGE race:france 1692632086370-0 + COUNT 2\n1) 1) &quot;1692632086370-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Castilla&quot;\n      3) &quot;speed&quot;\n      4) &quot;30.2&quot;\n      5) &quot;position&quot;\n      6) &quot;1&quot;\n      7) &quot;location_id&quot;\n      8) &quot;1&quot;\n2) 1) &quot;1692632094485-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Norem&quot;\n      3) &quot;speed&quot;\n      4) &quot;28.8&quot;\n      5) &quot;position&quot;\n      6) &quot;3&quot;\n      7) &quot;location_id&quot;\n      8) &quot;1&quot;\n</code></pre>\n<ul>\n<li>Read up to 100 new stream entries, starting at the end of the stream, and block for up to 300 ms if no entries are being written:</li>\n</ul>\n<pre><code>127.0.0.1:6379&gt; XREAD COUNT 100 BLOCK 300 STREAMS race:france $\n(nil)\n</code></pre>\n<h2>Performance</h2>\n<p>Adding an entry to a stream is O(1).<br>Accessing any single entry is O(n), where <em>n</em> is the length of the ID.<br>Since stream IDs are typically short and of a fixed length, this effectively reduces to a constant time lookup.<br>For details on why, note that streams are implemented as <a href=\"https://en.wikipedia.org/wiki/Radix_tree\">radix trees</a>.</p>\n<p>Simply put, Streams provide highly efficient inserts and reads.<br>See each command&#39;s time complexity for the details.</p>\n<h2>Streams basics</h2>\n<p>Streams are an append-only data structure. The fundamental write command, called <code>XADD</code>, appends a new entry to the specified stream.</p>\n<p>Each stream entry consists of one or more field-value pairs, somewhat like a dictionary or a Hash:</p>\n<pre><code>127.0.0.1:6379&gt; XADD race:france * rider Castilla speed 29.9 position 1 location_id 2\n&quot;1692632147973-0&quot;\n</code></pre>\n<p>The above call to the <code>XADD</code> command adds an entry <code>rider: Castilla, speed: 29.9, position: 1, location_id: 2</code> to the stream at key <code>race:france</code>, using an auto-generated entry ID, which is the one returned by the command, specifically <code>1692632147973-0</code>. It gets as its first argument the key name <code>race:france</code>, the second argument is the entry ID that identifies every entry inside a stream. However, in this case, we passed <code>*</code> because we want the server to generate a new ID for us. Every new ID will be monotonically increasing, so in more simple terms, every new entry added will have a higher ID compared to all the past entries. Auto-generation of IDs by the server is almost always what you want, and the reasons for specifying an ID explicitly are very rare. We&#39;ll talk more about this later. The fact that each Stream entry has an ID is another similarity with log files, where line numbers, or the byte offset inside the file, can be used in order to identify a given entry. Returning back at our <code>XADD</code> example, after the key name and ID, the next arguments are the field-value pairs composing our stream entry.</p>\n<p>It is possible to get the number of items inside a Stream just using the <code>XLEN</code> command:</p>\n<pre><code>127.0.0.1:6379&gt; XLEN race:france\n(integer) 4\n</code></pre>\n<h3>Entry IDs</h3>\n<p>The entry ID returned by the <code>XADD</code> command, and identifying univocally each entry inside a given stream, is composed of two parts:</p>\n<pre><code>&lt;millisecondsTime&gt;-&lt;sequenceNumber&gt;\n</code></pre>\n<p>The milliseconds time part is actually the local time in the local Valkey node generating the stream ID, however if the current milliseconds time happens to be smaller than the previous entry time, then the previous entry time is used instead, so if a clock jumps backward the monotonically incrementing ID property still holds. The sequence number is used for entries created in the same millisecond. Since the sequence number is 64 bit wide, in practical terms there is no limit to the number of entries that can be generated within the same millisecond.</p>\n<p>The format of such IDs may look strange at first, and the gentle reader may wonder why the time is part of the ID. The reason is that Streams support range queries by ID. Because the ID is related to the time the entry is generated, this gives the ability to query for time ranges basically for free. We will see this soon while covering the <code>XRANGE</code> command.</p>\n<p>If for some reason the user needs incremental IDs that are not related to time but are actually associated to another external system ID, as previously mentioned, the <code>XADD</code> command can take an explicit ID instead of the <code>*</code> wildcard ID that triggers auto-generation, like in the following examples:</p>\n<pre><code>127.0.0.1:6379&gt; XADD race:usa 0-1 racer Castilla\n0-1\n127.0.0.1:6379&gt; XADD race:usa 0-2 racer Norem\n0-2\n</code></pre>\n<p>Note that in this case, the minimum ID is 0-1 and that the command will not accept an ID equal or smaller than a previous one:</p>\n<pre><code>127.0.0.1:6379&gt; XADD race:usa 0-1 racer Prickett\n(error) ERR The ID specified in XADD is equal or smaller than the target stream top item\n</code></pre>\n<p>If you&#39;re running Redis OSS 7 or later, you can also provide an explicit ID consisting of the milliseconds part only. In this case, the sequence portion of the ID will be automatically generated. To do this, use the syntax below:</p>\n<pre><code>127.0.0.1:6379&gt; XADD race:usa 0-* racer Prickett\n0-3\n</code></pre>\n<h2>Getting data from Streams</h2>\n<p>Now we are finally able to append entries in our stream via <code>XADD</code>. However, while appending data to a stream is quite obvious, the way streams can be queried in order to extract data is not so obvious. If we continue with the analogy of the log file, one obvious way is to mimic what we normally do with the Unix command <code>tail -f</code>, that is, we may start to listen in order to get the new messages that are appended to the stream. Note that unlike the blocking list operations of Valkey, where a given element will reach a single client which is blocking in a <em>pop style</em> operation like <code>BLPOP</code>, with streams we want multiple consumers to see the new messages appended to the stream (the same way many <code>tail -f</code> processes can see what is added to a log). Using the traditional terminology we want the streams to be able to <em>fan out</em> messages to multiple clients.</p>\n<p>However, this is just one potential access mode. We could also see a stream in quite a different way: not as a messaging system, but as a <em>time series store</em>. In this case, maybe it&#39;s also useful to get the new messages appended, but another natural query mode is to get messages by ranges of time, or alternatively to iterate the messages using a cursor to incrementally check all the history. This is definitely another useful access mode.</p>\n<p>Finally, if we see a stream from the point of view of consumers, we may want to access the stream in yet another way, that is, as a stream of messages that can be partitioned to multiple consumers that are processing such messages, so that groups of consumers can only see a subset of the messages arriving in a single stream. In this way, it is possible to scale the message processing across different consumers, without single consumers having to process all the messages: each consumer will just get different messages to process. This is basically what Kafka (TM) does with consumer groups. Reading messages via consumer groups is yet another interesting mode of reading from a Stream.</p>\n<p>Streams support all three of the query modes described above via different commands. The next sections will show them all, starting from the simplest and most direct to use: range queries.</p>\n<h3>Querying by range: XRANGE and XREVRANGE</h3>\n<p>To query the stream by range we are only required to specify two IDs, <em>start</em> and <em>end</em>. The range returned will include the elements having start or end as ID, so the range is inclusive. The two special IDs <code>-</code> and <code>+</code> respectively mean the smallest and the greatest ID possible.</p>\n<pre><code>127.0.0.1:6379&gt; XRANGE race:france - +\n1) 1) &quot;1692632086370-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Castilla&quot;\n      3) &quot;speed&quot;\n      4) &quot;30.2&quot;\n      5) &quot;position&quot;\n      6) &quot;1&quot;\n      7) &quot;location_id&quot;\n      8) &quot;1&quot;\n2) 1) &quot;1692632094485-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Norem&quot;\n      3) &quot;speed&quot;\n      4) &quot;28.8&quot;\n      5) &quot;position&quot;\n      6) &quot;3&quot;\n      7) &quot;location_id&quot;\n      8) &quot;1&quot;\n3) 1) &quot;1692632102976-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Prickett&quot;\n      3) &quot;speed&quot;\n      4) &quot;29.7&quot;\n      5) &quot;position&quot;\n      6) &quot;2&quot;\n      7) &quot;location_id&quot;\n      8) &quot;1&quot;\n4) 1) &quot;1692632147973-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Castilla&quot;\n      3) &quot;speed&quot;\n      4) &quot;29.9&quot;\n      5) &quot;position&quot;\n      6) &quot;1&quot;\n      7) &quot;location_id&quot;\n      8) &quot;2&quot;\n</code></pre>\n<p>Each entry returned is an array of two items: the ID and the list of field-value pairs. We already said that the entry IDs have a relation with the time, because the part at the left of the <code>-</code> character is the Unix time in milliseconds of the local node that created the stream entry, at the moment the entry was created (however note that streams are replicated with fully specified <code>XADD</code> commands, so the replicas will have identical IDs to the primary). This means that I could query a range of time using <code>XRANGE</code>. In order to do so, however, I may want to omit the sequence part of the ID: if omitted, in the start of the range it will be assumed to be 0, while in the end part it will be assumed to be the maximum sequence number available. This way, querying using just two milliseconds Unix times, we get all the entries that were generated in that range of time, in an inclusive way. For instance, if I want to query a two milliseconds period I could use:</p>\n<pre><code>127.0.0.1:6379&gt; XRANGE race:france 1692632086369 1692632086371\n1) 1) &quot;1692632086370-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Castilla&quot;\n      3) &quot;speed&quot;\n      4) &quot;30.2&quot;\n      5) &quot;position&quot;\n      6) &quot;1&quot;\n      7) &quot;location_id&quot;\n      8) &quot;1&quot;\n</code></pre>\n<p>I have only a single entry in this range. However in real data sets, I could query for ranges of hours, or there could be many items in just two milliseconds, and the result returned could be huge. For this reason, <code>XRANGE</code> supports an optional <strong>COUNT</strong> option at the end. By specifying a count, I can just get the first <em>N</em> items. If I want more, I can get the last ID returned, increment the sequence part by one, and query again. Let&#39;s see this in the following example. Let&#39;s assume that the stream <code>race:france</code> was populated with 4 items. To start my iteration, getting 2 items per command, I start with the full range, but with a count of 2.</p>\n<pre><code>127.0.0.1:6379&gt; XRANGE race:france - + COUNT 2\n1) 1) &quot;1692632086370-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Castilla&quot;\n      3) &quot;speed&quot;\n      4) &quot;30.2&quot;\n      5) &quot;position&quot;\n      6) &quot;1&quot;\n      7) &quot;location_id&quot;\n      8) &quot;1&quot;\n2) 1) &quot;1692632094485-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Norem&quot;\n      3) &quot;speed&quot;\n      4) &quot;28.8&quot;\n      5) &quot;position&quot;\n      6) &quot;3&quot;\n      7) &quot;location_id&quot;\n      8) &quot;1&quot;\n</code></pre>\n<p>To continue the iteration with the next two items, I have to pick the last ID returned, that is <code>1692632094485-0</code>, and add the prefix <code>(</code> to it. The resulting exclusive range interval, that is <code>(1692632094485-0</code> in this case, can now be used as the new <em>start</em> argument for the next <code>XRANGE</code> call:</p>\n<pre><code>127.0.0.1:6379&gt; XRANGE race:france (1692632094485-0 + COUNT 2\n1) 1) &quot;1692632102976-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Prickett&quot;\n      3) &quot;speed&quot;\n      4) &quot;29.7&quot;\n      5) &quot;position&quot;\n      6) &quot;2&quot;\n      7) &quot;location_id&quot;\n      8) &quot;1&quot;\n2) 1) &quot;1692632147973-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Castilla&quot;\n      3) &quot;speed&quot;\n      4) &quot;29.9&quot;\n      5) &quot;position&quot;\n      6) &quot;1&quot;\n      7) &quot;location_id&quot;\n      8) &quot;2&quot;\n</code></pre>\n<p>Now that we&#39;ve retrieved 4 items out of a stream that only had 4 entries in it, if we try to retrieve more items, we&#39;ll get an empty array:</p>\n<pre><code>127.0.0.1:6379&gt; XRANGE race:france (1692632147973-0 + COUNT 2\n(empty array)\n</code></pre>\n<p>Since <code>XRANGE</code> complexity is <em>O(log(N))</em> to seek, and then <em>O(M)</em> to return M elements, with a small count the command has a logarithmic time complexity, which means that each step of the iteration is fast. So <code>XRANGE</code> is also the de facto <em>streams iterator</em> and does not require an <strong>XSCAN</strong> command.</p>\n<p>The command <code>XREVRANGE</code> is the equivalent of <code>XRANGE</code> but returning the elements in inverted order, so a practical use for <code>XREVRANGE</code> is to check what is the last item in a Stream:</p>\n<pre><code>127.0.0.1:6379&gt; XREVRANGE race:france + - COUNT 1\n1) 1) &quot;1692632147973-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Castilla&quot;\n      3) &quot;speed&quot;\n      4) &quot;29.9&quot;\n      5) &quot;position&quot;\n      6) &quot;1&quot;\n      7) &quot;location_id&quot;\n      8) &quot;2&quot;\n</code></pre>\n<p>Note that the <code>XREVRANGE</code> command takes the <em>start</em> and <em>stop</em> arguments in reverse order.</p>\n<h2>Listening for new items with XREAD</h2>\n<p>When we do not want to access items by a range in a stream, usually what we want instead is to <em>subscribe</em> to new items arriving to the stream. This concept may appear related to Valkey Pub/Sub, where you subscribe to a channel, or to Valkey blocking lists, where you wait for a key to get new elements to fetch, but there are fundamental differences in the way you consume a stream:</p>\n<ol>\n<li>A stream can have multiple clients (consumers) waiting for data. Every new item, by default, will be delivered to <em>every consumer</em> that is waiting for data in a given stream. This behavior is different than blocking lists, where each consumer will get a different element. However, the ability to <em>fan out</em> to multiple consumers is similar to Pub/Sub.</li>\n<li>While in Pub/Sub messages are <em>fire and forget</em> and are never stored anyway, and while when using blocking lists, when a message is received by the client it is <em>popped</em> (effectively removed) from the list, streams work in a fundamentally different way. All the messages are appended in the stream indefinitely (unless the user explicitly asks to delete entries): different consumers will know what is a new message from its point of view by remembering the ID of the last message received.</li>\n<li>Streams Consumer Groups provide a level of control that Pub/Sub or blocking lists cannot achieve, with different groups for the same stream, explicit acknowledgment of processed items, ability to inspect the pending items, claiming of unprocessed messages, and coherent history visibility for each single client, that is only able to see its private past history of messages.</li>\n</ol>\n<p>The command that provides the ability to listen for new messages arriving into a stream is called <code>XREAD</code>. It&#39;s a bit more complex than <code>XRANGE</code>, so we&#39;ll start showing simple forms, and later the whole command layout will be provided.</p>\n<pre><code>127.0.0.1:6379&gt; XREAD COUNT 2 STREAMS race:france 0\n1) 1) &quot;race:france&quot;\n   2) 1) 1) &quot;1692632086370-0&quot;\n         2) 1) &quot;rider&quot;\n            2) &quot;Castilla&quot;\n            3) &quot;speed&quot;\n            4) &quot;30.2&quot;\n            5) &quot;position&quot;\n            6) &quot;1&quot;\n            7) &quot;location_id&quot;\n            8) &quot;1&quot;\n      2) 1) &quot;1692632094485-0&quot;\n         2) 1) &quot;rider&quot;\n            2) &quot;Norem&quot;\n            3) &quot;speed&quot;\n            4) &quot;28.8&quot;\n            5) &quot;position&quot;\n            6) &quot;3&quot;\n            7) &quot;location_id&quot;\n            8) &quot;1&quot;\n</code></pre>\n<p>The above is the non-blocking form of <code>XREAD</code>. Note that the <strong>COUNT</strong> option is not mandatory, in fact the only mandatory option of the command is the <strong>STREAMS</strong> option, that specifies a list of keys together with the corresponding maximum ID already seen for each stream by the calling consumer, so that the command will provide the client only with messages with an ID greater than the one we specified.</p>\n<p>In the above command we wrote <code>STREAMS race:france 0</code> so we want all the messages in the Stream <code>race:france</code> having an ID greater than <code>0-0</code>. As you can see in the example above, the command returns the key name, because actually it is possible to call this command with more than one key to read from different streams at the same time. I could write, for instance: <code>STREAMS race:france race:italy 0 0</code>. Note how after the <strong>STREAMS</strong> option we need to provide the key names, and later the IDs. For this reason, the <strong>STREAMS</strong> option must always be the last option.<br>Any other options must come before the <strong>STREAMS</strong> option.</p>\n<p>Apart from the fact that <code>XREAD</code> can access multiple streams at once, and that we are able to specify the last ID we own to just get newer messages, in this simple form the command is not doing something so different compared to <code>XRANGE</code>. However, the interesting part is that we can turn <code>XREAD</code> into a <em>blocking command</em> easily, by specifying the <strong>BLOCK</strong> argument:</p>\n<pre><code>&gt; XREAD BLOCK 0 STREAMS race:france $\n</code></pre>\n<p>Note that in the example above, other than removing <strong>COUNT</strong>, I specified the new <strong>BLOCK</strong> option with a timeout of 0 milliseconds (that means to never timeout). Moreover, instead of passing a normal ID for the stream <code>race:france</code> I passed the special ID <code>$</code>. This special ID means that <code>XREAD</code> should use as last ID the maximum ID already stored in the stream <code>race:france</code>, so that we will receive only <em>new</em> messages, starting from the time we started listening. This is similar to the <code>tail -f</code> Unix command in some way.</p>\n<p>Note that when the <strong>BLOCK</strong> option is used, we do not have to use the special ID <code>$</code>. We can use any valid ID. If the command is able to serve our request immediately without blocking, it will do so, otherwise it will block. Normally if we want to consume the stream starting from new entries, we start with the ID <code>$</code>, and after that we continue using the ID of the last message received to make the next call, and so forth.</p>\n<p>The blocking form of <code>XREAD</code> is also able to listen to multiple Streams, just by specifying multiple key names. If the request can be served synchronously because there is at least one stream with elements greater than the corresponding ID we specified, it returns with the results. Otherwise, the command will block and will return the items of the first stream which gets new data (according to the specified ID).</p>\n<p>Similarly to blocking list operations, blocking stream reads are <em>fair</em> from the point of view of clients waiting for data, since the semantics is FIFO style. The first client that blocked for a given stream will be the first to be unblocked when new items are available.</p>\n<p><code>XREAD</code> has no other options than <strong>COUNT</strong> and <strong>BLOCK</strong>, so it&#39;s a pretty basic command with a specific purpose to attach consumers to one or multiple streams. More powerful features to consume streams are available using the consumer groups API, however reading via consumer groups is implemented by a different command called <code>XREADGROUP</code>, covered in the next section of this guide.</p>\n<h2>Consumer groups</h2>\n<p>When the task at hand is to consume the same stream from different clients, then <code>XREAD</code> already offers a way to <em>fan-out</em> to N clients, potentially also using replicas in order to provide more read scalability. However in certain problems what we want to do is not to provide the same stream of messages to many clients, but to provide a <em>different subset</em> of messages from the same stream to many clients. An obvious case where this is useful is that of messages which are slow to process: the ability to have N different workers that will receive different parts of the stream allows us to scale message processing, by routing different messages to different workers that are ready to do more work.</p>\n<p>In practical terms, if we imagine having three consumers C1, C2, C3, and a stream that contains the messages 1, 2, 3, 4, 5, 6, 7 then what we want is to serve the messages according to the following diagram:</p>\n<pre><code>1 -&gt; C1\n2 -&gt; C2\n3 -&gt; C3\n4 -&gt; C1\n5 -&gt; C2\n6 -&gt; C3\n7 -&gt; C1\n</code></pre>\n<p>In order to achieve this, Valkey uses a concept called <em>consumer groups</em>. It is very important to understand that Valkey consumer groups have nothing to do, from an implementation standpoint, with Kafka (TM) consumer groups. Yet they are similar in functionality, so I decided to keep Kafka&#39;s (TM) terminology, as it originally popularized this idea.</p>\n<p>A consumer group is like a <em>pseudo consumer</em> that gets data from a stream, and actually serves multiple consumers, providing certain guarantees:</p>\n<ol>\n<li>Each message is served to a different consumer so that it is not possible that the same message will be delivered to multiple consumers.</li>\n<li>Consumers are identified, within a consumer group, by a name, which is a case-sensitive string that the clients implementing consumers must choose. This means that even after a disconnect, the stream consumer group retains all the state, since the client will claim again to be the same consumer. However, this also means that it is up to the client to provide a unique identifier.</li>\n<li>Each consumer group has the concept of the <em>first ID never consumed</em> so that, when a consumer asks for new messages, it can provide just messages that were not previously delivered.</li>\n<li>Consuming a message, however, requires an explicit acknowledgment using a specific command. Valkey interprets the acknowledgment as: this message was correctly processed so it can be evicted from the consumer group.</li>\n<li>A consumer group tracks all the messages that are currently pending, that is, messages that were delivered to some consumer of the consumer group, but are yet to be acknowledged as processed. Thanks to this feature, when accessing the message history of a stream, each consumer <em>will only see messages that were delivered to it</em>.</li>\n</ol>\n<p>In a way, a consumer group can be imagined as some <em>amount of state</em> about a stream:</p>\n<pre><code>+----------------------------------------+\n| consumer_group_name: mygroup           |\n| consumer_group_stream: somekey         |\n| last_delivered_id: 1292309234234-92    |\n|                                        |\n| consumers:                             |\n|    &quot;consumer-1&quot; with pending messages  |\n|       1292309234234-4                  |\n|       1292309234232-8                  |\n|    &quot;consumer-42&quot; with pending messages |\n|       ... (and so forth)               |\n+----------------------------------------+\n</code></pre>\n<p>If you see this from this point of view, it is very simple to understand what a consumer group can do, how it is able to just provide consumers with their history of pending messages, and how consumers asking for new messages will just be served with message IDs greater than <code>last_delivered_id</code>. At the same time, if you look at the consumer group as an auxiliary data structure for Streams, it is obvious that a single stream can have multiple consumer groups, that have a different set of consumers. Actually, it is even possible for the same stream to have clients reading without consumer groups via <code>XREAD</code>, and clients reading via <code>XREADGROUP</code> in different consumer groups.</p>\n<p>Now it&#39;s time to zoom in to see the fundamental consumer group commands. They are the following:</p>\n<ul>\n<li><code>XGROUP</code> is used in order to create, destroy and manage consumer groups.</li>\n<li><code>XREADGROUP</code> is used to read from a stream via a consumer group.</li>\n<li><code>XACK</code> is the command that allows a consumer to mark a pending message as correctly processed.</li>\n</ul>\n<h2>Creating a consumer group</h2>\n<p>Assuming I have a key <code>race:france</code> of type stream already existing, in order to create a consumer group I just need to do the following:</p>\n<pre><code>127.0.0.1:6379&gt; XGROUP CREATE race:france france_riders $\nOK\n</code></pre>\n<p>As you can see in the command above when creating the consumer group we have to specify an ID, which in the example is just <code>$</code>. This is needed because the consumer group, among the other states, must have an idea about what message to serve next at the first consumer connecting, that is, what was the <em>last message ID</em> when the group was just created. If we provide <code>$</code> as we did, then only new messages arriving in the stream from now on will be provided to the consumers in the group. If we specify <code>0</code> instead the consumer group will consume <em>all</em> the messages in the stream history to start with. Of course, you can specify any other valid ID. What you know is that the consumer group will start delivering messages that are greater than the ID you specify. Because <code>$</code> means the current greatest ID in the stream, specifying <code>$</code> will have the effect of consuming only new messages.</p>\n<p><code>XGROUP CREATE</code> also supports creating the stream automatically, if it doesn&#39;t exist, using the optional <code>MKSTREAM</code> subcommand as the last argument:</p>\n<pre><code>127.0.0.1:6379&gt; XGROUP CREATE race:italy italy_riders $ MKSTREAM\nOK\n</code></pre>\n<p>Now that the consumer group is created we can immediately try to read messages via the consumer group using the <code>XREADGROUP</code> command. We&#39;ll read from consumers, that we will call Alice and Bob, to see how the system will return different messages to Alice or Bob.</p>\n<p><code>XREADGROUP</code> is very similar to <code>XREAD</code> and provides the same <strong>BLOCK</strong> option, otherwise it is a synchronous command. However there is a <em>mandatory</em> option that must be always specified, which is <strong>GROUP</strong> and has two arguments: the name of the consumer group, and the name of the consumer that is attempting to read. The option <strong>COUNT</strong> is also supported and is identical to the one in <code>XREAD</code>.</p>\n<p>We&#39;ll add riders to the race:italy stream and try reading something using the consumer group:<br>Note: <em>here rider is the field name, and the name is the associated value. Remember that stream items are small dictionaries.</em></p>\n<pre><code>127.0.0.1:6379&gt; XADD race:italy * rider Castilla\n&quot;1692632639151-0&quot;\n127.0.0.1:6379&gt; XADD race:italy * rider Royce\n&quot;1692632647899-0&quot;\n127.0.0.1:6379&gt; XADD race:italy * rider Sam-Bodden\n&quot;1692632662819-0&quot;\n127.0.0.1:6379&gt; XADD race:italy * rider Prickett\n&quot;1692632670501-0&quot;\n127.0.0.1:6379&gt; XADD race:italy * rider Norem\n&quot;1692632678249-0&quot;\n127.0.0.1:6379&gt; XREADGROUP GROUP italy_riders Alice COUNT 1 STREAMS race:italy &gt;\n1) 1) &quot;race:italy&quot;\n   2) 1) 1) &quot;1692632639151-0&quot;\n         2) 1) &quot;rider&quot;\n            2) &quot;Castilla&quot;\n</code></pre>\n<p><code>XREADGROUP</code> replies are just like <code>XREAD</code> replies. Note however the <code>GROUP &lt;group-name&gt; &lt;consumer-name&gt;</code> provided above. It states that I want to read from the stream using the consumer group <code>mygroup</code> and I&#39;m the consumer <code>Alice</code>. Every time a consumer performs an operation with a consumer group, it must specify its name, uniquely identifying this consumer inside the group.</p>\n<p>There is another very important detail in the command line above, after the mandatory <strong>STREAMS</strong> option the ID requested for the key <code>race:italy</code> is the special ID <code>&gt;</code>. This special ID is only valid in the context of consumer groups, and it means: <strong>messages never delivered to other consumers so far</strong>.</p>\n<p>This is almost always what you want, however it is also possible to specify a real ID, such as <code>0</code> or any other valid ID, in this case, however, what happens is that we request from <code>XREADGROUP</code> to just provide us with the <strong>history of pending messages</strong>, and in such case, will never see new messages in the group. So basically <code>XREADGROUP</code> has the following behavior based on the ID we specify:</p>\n<ul>\n<li>If the ID is the special ID <code>&gt;</code> then the command will return only new messages never delivered to other consumers so far, and as a side effect, will update the consumer group&#39;s <em>last ID</em>.</li>\n<li>If the ID is any other valid numerical ID, then the command will let us access our <em>history of pending messages</em>. That is, the set of messages that were delivered to this specified consumer (identified by the provided name), and never acknowledged so far with <code>XACK</code>.</li>\n</ul>\n<p>We can test this behavior immediately specifying an ID of 0, without any <strong>COUNT</strong> option: we&#39;ll just see the only pending message, that is, the one about Castilla:</p>\n<pre><code>127.0.0.1:6379&gt; XREADGROUP GROUP italy_riders Alice STREAMS race:italy 0\n1) 1) &quot;race:italy&quot;\n   2) 1) 1) &quot;1692632639151-0&quot;\n         2) 1) &quot;rider&quot;\n            2) &quot;Castilla&quot;\n</code></pre>\n<p>However, if we acknowledge the message as processed, it will no longer be part of the pending messages history, so the system will no longer report anything:</p>\n<pre><code>127.0.0.1:6379&gt; XACK race:italy italy_riders 1692632639151-0\n(integer) 1\n127.0.0.1:6379&gt; XREADGROUP GROUP italy_riders Alice STREAMS race:italy 0\n1) 1) &quot;race:italy&quot;\n   2) (empty array)\n</code></pre>\n<p>Don&#39;t worry if you yet don&#39;t know how <code>XACK</code> works, the idea is just that processed messages are no longer part of the history that we can access.</p>\n<p>Now it&#39;s Bob&#39;s turn to read something:</p>\n<pre><code>127.0.0.1:6379&gt; XREADGROUP GROUP italy_riders Bob COUNT 2 STREAMS race:italy &gt;\n1) 1) &quot;race:italy&quot;\n   2) 1) 1) &quot;1692632647899-0&quot;\n         2) 1) &quot;rider&quot;\n            2) &quot;Royce&quot;\n      2) 1) &quot;1692632662819-0&quot;\n         2) 1) &quot;rider&quot;\n            2) &quot;Sam-Bodden&quot;\n</code></pre>\n<p>Bob asked for a maximum of two messages and is reading via the same group <code>mygroup</code>. So what happens is that Valkey reports just <em>new</em> messages. As you can see the &quot;Castilla&quot; message is not delivered, since it was already delivered to Alice, so Bob gets Royce and Sam-Bodden and so forth.</p>\n<p>This way Alice, Bob, and any other consumer in the group, are able to read different messages from the same stream, to read their history of yet to process messages, or to mark messages as processed. This allows creating different topologies and semantics for consuming messages from a stream.</p>\n<p>There are a few things to keep in mind:</p>\n<ul>\n<li>Consumers are auto-created the first time they are mentioned, no need for explicit creation.</li>\n<li>Even with <code>XREADGROUP</code> you can read from multiple keys at the same time, however for this to work, you need to create a consumer group with the same name in every stream. This is not a common need, but it is worth mentioning that the feature is technically available.</li>\n<li><code>XREADGROUP</code> is a <em>write command</em> because even if it reads from the stream, the consumer group is modified as a side effect of reading, so it can only be called on primary instances.</li>\n</ul>\n<p>An example of a consumer implementation, using consumer groups, written in the Ruby language could be the following. The Ruby code is aimed to be readable by virtually any experienced programmer, even if they do not know Ruby:</p>\n<pre><code class=\"language-ruby\">require &#39;redis&#39;\n\nif ARGV.length == 0\n    puts &quot;Please specify a consumer name&quot;\n    exit 1\nend\n\nConsumerName = ARGV[0]\nGroupName = &quot;mygroup&quot;\nr = Redis.new\n\ndef process_message(id,msg)\n    puts &quot;[#{ConsumerName}] #{id} = #{msg.inspect}&quot;\nend\n\n$lastid = &#39;0-0&#39;\n\nputs &quot;Consumer #{ConsumerName} starting...&quot;\ncheck_backlog = true\nwhile true\n    # Pick the ID based on the iteration: the first time we want to\n    # read our pending messages, in case we crashed and are recovering.\n    # Once we consumed our history, we can start getting new messages.\n    if check_backlog\n        myid = $lastid\n    else\n        myid = &#39;&gt;&#39;\n    end\n\n    items = r.xreadgroup(&#39;GROUP&#39;,GroupName,ConsumerName,&#39;BLOCK&#39;,&#39;2000&#39;,&#39;COUNT&#39;,&#39;10&#39;,&#39;STREAMS&#39;,:my_stream_key,myid)\n\n    if items == nil\n        puts &quot;Timeout!&quot;\n        next\n    end\n\n    # If we receive an empty reply, it means we were consuming our history\n    # and that the history is now empty. Let&#39;s start to consume new messages.\n    check_backlog = false if items[0][1].length == 0\n\n    items[0][1].each{|i|\n        id,fields = i\n\n        # Process the message\n        process_message(id,fields)\n\n        # Acknowledge the message as processed\n        r.xack(:my_stream_key,GroupName,id)\n\n        $lastid = id\n    }\nend\n</code></pre>\n<p>As you can see the idea here is to start by consuming the history, that is, our list of pending messages. This is useful because the consumer may have crashed before, so in the event of a restart we want to re-read messages that were delivered to us without getting acknowledged. Note that we might process a message multiple times or one time (at least in the case of consumer failures, but there are also the limits of Valkey persistence and replication involved, see the specific section about this topic).</p>\n<p>Once the history was consumed, and we get an empty list of messages, we can switch to using the <code>&gt;</code> special ID in order to consume new messages.</p>\n<h2>Recovering from permanent failures</h2>\n<p>The example above allows us to write consumers that participate in the same consumer group, each taking a subset of messages to process, and when recovering from failures re-reading the pending messages that were delivered just to them. However in the real world consumers may permanently fail and never recover. What happens to the pending messages of the consumer that never recovers after stopping for any reason?</p>\n<p>Valkey consumer groups offer a feature that is used in these situations in order to <em>claim</em> the pending messages of a given consumer so that such messages will change ownership and will be re-assigned to a different consumer. The feature is very explicit. A consumer has to inspect the list of pending messages, and will have to claim specific messages using a special command, otherwise the server will leave the messages pending forever and assigned to the old consumer. In this way different applications can choose if to use such a feature or not, and exactly how to use it.</p>\n<p>The first step of this process is just a command that provides observability of pending entries in the consumer group and is called <code>XPENDING</code>.<br>This is a read-only command which is always safe to call and will not change ownership of any message.<br>In its simplest form, the command is called with two arguments, which are the name of the stream and the name of the consumer group.</p>\n<pre><code>127.0.0.1:6379&gt; XPENDING race:italy italy_riders\n1) (integer) 2\n2) &quot;1692632647899-0&quot;\n3) &quot;1692632662819-0&quot;\n4) 1) 1) &quot;Bob&quot;\n      2) &quot;2&quot;\n</code></pre>\n<p>When called in this way, the command outputs the total number of pending messages in the consumer group (two in this case), the lower and higher message ID among the pending messages, and finally a list of consumers and the number of pending messages they have.<br>We have only Bob with two pending messages because the single message that Alice requested was acknowledged using <code>XACK</code>.</p>\n<p>We can ask for more information by giving more arguments to <code>XPENDING</code>, because the full command signature is the following:</p>\n<pre><code>XPENDING &lt;key&gt; &lt;groupname&gt; [[IDLE &lt;min-idle-time&gt;] &lt;start-id&gt; &lt;end-id&gt; &lt;count&gt; [&lt;consumer-name&gt;]]\n</code></pre>\n<p>By providing a start and end ID (that can be just <code>-</code> and <code>+</code> as in <code>XRANGE</code>) and a count to control the amount of information returned by the command, we are able to know more about the pending messages. The optional final argument, the consumer name, is used if we want to limit the output to just messages pending for a given consumer, but won&#39;t use this feature in the following example.</p>\n<pre><code>127.0.0.1:6379&gt; XPENDING race:italy italy_riders - + 10\n1) 1) &quot;1692632647899-0&quot;\n   2) &quot;Bob&quot;\n   3) (integer) 74642\n   4) (integer) 1\n2) 1) &quot;1692632662819-0&quot;\n   2) &quot;Bob&quot;\n   3) (integer) 74642\n   4) (integer) 1\n</code></pre>\n<p>Now we have the details for each message: the ID, the consumer name, the <em>idle time</em> in milliseconds, which is how many milliseconds have passed since the last time the message was delivered to some consumer, and finally the number of times that a given message was delivered.<br>We have two messages from Bob, and they are idle for 60000+ milliseconds, about a minute.</p>\n<p>Note that nobody prevents us from checking what the first message content was by just using <code>XRANGE</code>.</p>\n<pre><code>127.0.0.1:6379&gt; XRANGE race:italy 1692632647899-0 1692632647899-0\n1) 1) &quot;1692632647899-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Royce&quot;\n</code></pre>\n<p>We have just to repeat the same ID twice in the arguments. Now that we have some ideas, Alice may decide that after 1 minute of not processing messages, Bob will probably not recover quickly, and it&#39;s time to <em>claim</em> such messages and resume the processing in place of Bob. To do so, we use the <code>XCLAIM</code> command.</p>\n<p>This command is very complex and full of options in its full form, since it is used for replication of consumer groups changes, but we&#39;ll use just the arguments that we need normally. In this case it is as simple as:</p>\n<pre><code>XCLAIM &lt;key&gt; &lt;group&gt; &lt;consumer&gt; &lt;min-idle-time&gt; &lt;ID-1&gt; &lt;ID-2&gt; ... &lt;ID-N&gt;\n</code></pre>\n<p>Basically we say, for this specific key and group, I want that the message IDs specified will change ownership, and will be assigned to the specified consumer name <code>&lt;consumer&gt;</code>. However, we also provide a minimum idle time, so that the operation will only work if the idle time of the mentioned messages is greater than the specified idle time. This is useful because maybe two clients are retrying to claim a message at the same time:</p>\n<pre><code>Client 1: XCLAIM race:italy italy_riders Alice 60000 1692632647899-0\nClient 2: XCLAIM race:italy italy_riders Lora 60000 1692632647899-0\n</code></pre>\n<p>However, as a side effect, claiming a message will reset its idle time and will increment its number of deliveries counter, so the second client will fail claiming it. In this way we avoid trivial re-processing of messages (even if in the general case you cannot obtain exactly once processing).</p>\n<p>This is the result of the command execution:</p>\n<pre><code>127.0.0.1:6379&gt; XCLAIM race:italy italy_riders Alice 60000 1692632647899-0\n1) 1) &quot;1692632647899-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Royce&quot;\n</code></pre>\n<p>The message was successfully claimed by Alice, who can now process the message and acknowledge it, and move things forward even if the original consumer is not recovering.</p>\n<p>It is clear from the example above that as a side effect of successfully claiming a given message, the <code>XCLAIM</code> command also returns it. However this is not mandatory. The <strong>JUSTID</strong> option can be used in order to return just the IDs of the message successfully claimed. This is useful if you want to reduce the bandwidth used between the client and the server (and also the performance of the command) and you are not interested in the message because your consumer is implemented in a way that it will rescan the history of pending messages from time to time.</p>\n<p>Claiming may also be implemented by a separate process: one that just checks the list of pending messages, and assigns idle messages to consumers that appear to be active. Active consumers can be obtained using one of the observability features of Streams. This is the topic of the next section.</p>\n<h2>Automatic claiming</h2>\n<p>The <code>XAUTOCLAIM</code> command, added in Redis OSS 6.2, implements the claiming process that we&#39;ve described above.<br><code>XPENDING</code> and <code>XCLAIM</code> provide the basic building blocks for different types of recovery mechanisms.<br>This command optimizes the generic process by having Valkey manage it and offers a simple solution for most recovery needs.</p>\n<p><code>XAUTOCLAIM</code> identifies idle pending messages and transfers ownership of them to a consumer.<br>The command&#39;s signature looks like this:</p>\n<pre><code>XAUTOCLAIM &lt;key&gt; &lt;group&gt; &lt;consumer&gt; &lt;min-idle-time&gt; &lt;start&gt; [COUNT count] [JUSTID]\n</code></pre>\n<p>So, in the example above, I could have used automatic claiming to claim a single message like this:</p>\n<pre><code>127.0.0.1:6379&gt; XAUTOCLAIM race:italy italy_riders Alice 60000 0-0 COUNT 1\n1) &quot;0-0&quot;\n2) 1) 1) &quot;1692632662819-0&quot;\n      2) 1) &quot;rider&quot;\n         2) &quot;Sam-Bodden&quot;\n</code></pre>\n<p>Like <code>XCLAIM</code>, the command replies with an array of the claimed messages, but it also returns a stream ID that allows iterating the pending entries.<br>The stream ID is a cursor, and I can use it in my next call to continue in claiming idle pending messages:</p>\n<pre><code>127.0.0.1:6379&gt; XAUTOCLAIM race:italy italy_riders Lora 60000 (1692632662819-0 COUNT 1\n1) &quot;1692632662819-0&quot;\n2) 1) 1) &quot;1692632647899-0&quot;\n      2) 1) &quot;rider&quot;\n         2) &quot;Royce&quot;\n</code></pre>\n<p>When <code>XAUTOCLAIM</code> returns the &quot;0-0&quot; stream ID as a cursor, that means that it reached the end of the consumer group pending entries list.<br>That doesn&#39;t mean that there are no new idle pending messages, so the process continues by calling <code>XAUTOCLAIM</code> from the beginning of the stream.</p>\n<h2>Claiming and the delivery counter</h2>\n<p>The counter that you observe in the <code>XPENDING</code> output is the number of deliveries of each message. The counter is incremented in two ways: when a message is successfully claimed via <code>XCLAIM</code> or when an <code>XREADGROUP</code> call is used in order to access the history of pending messages.</p>\n<p>When there are failures, it is normal that messages will be delivered multiple times, but eventually they usually get processed and acknowledged. However there might be a problem processing some specific message, because it is corrupted or crafted in a way that triggers a bug in the processing code. In such a case what happens is that consumers will continuously fail to process this particular message. Because we have the counter of the delivery attempts, we can use that counter to detect messages that for some reason are not processable. So once the deliveries counter reaches a given large number that you chose, it is probably wiser to put such messages in another stream and send a notification to the system administrator. This is basically the way that Streams implements the <em>dead letter</em> concept.</p>\n<h2>Streams observability</h2>\n<p>Messaging systems that lack observability are very hard to work with. Not knowing who is consuming messages, what messages are pending, the set of consumer groups active in a given stream, makes everything opaque. For this reason, Streams and consumer groups have different ways to observe what is happening. We already covered <code>XPENDING</code>, which allows us to inspect the list of messages that are under processing at a given moment, together with their idle time and number of deliveries.</p>\n<p>However we may want to do more than that, and the <code>XINFO</code> command is an observability interface that can be used with sub-commands in order to get information about streams or consumer groups.</p>\n<p>This command uses subcommands in order to show different information about the status of the stream and its consumer groups. For instance <strong>XINFO STREAM <key></strong> reports information about the stream itself.</p>\n<pre><code>127.0.0.1:6379&gt; XINFO STREAM race:italy\n 1) &quot;length&quot;\n 2) (integer) 5\n 3) &quot;radix-tree-keys&quot;\n 4) (integer) 1\n 5) &quot;radix-tree-nodes&quot;\n 6) (integer) 2\n 7) &quot;last-generated-id&quot;\n 8) &quot;1692632678249-0&quot;\n 9) &quot;groups&quot;\n10) (integer) 1\n11) &quot;first-entry&quot;\n12) 1) &quot;1692632639151-0&quot;\n    2) 1) &quot;rider&quot;\n       2) &quot;Castilla&quot;\n13) &quot;last-entry&quot;\n14) 1) &quot;1692632678249-0&quot;\n    2) 1) &quot;rider&quot;\n       2) &quot;Norem&quot;\n</code></pre>\n<p>The output shows information about how the stream is encoded internally, and also shows the first and last message in the stream. Another piece of information available is the number of consumer groups associated with this stream. We can dig further asking for more information about the consumer groups.</p>\n<pre><code>127.0.0.1:6379&gt; XINFO GROUPS race:italy\n1) 1) &quot;name&quot;\n   2) &quot;italy_riders&quot;\n   3) &quot;consumers&quot;\n   4) (integer) 3\n   5) &quot;pending&quot;\n   6) (integer) 2\n   7) &quot;last-delivered-id&quot;\n   8) &quot;1692632662819-0&quot;\n</code></pre>\n<p>As you can see in this and in the previous output, the <code>XINFO</code> command outputs a sequence of field-value items. Because it is an observability command this allows the human user to immediately understand what information is reported, and allows the command to report more information in the future by adding more fields without breaking compatibility with older clients. Other commands that must be more bandwidth efficient, like <code>XPENDING</code>, just report the information without the field names.</p>\n<p>The output of the example above, where the <strong>GROUPS</strong> subcommand is used, should be clear observing the field names. We can check in more detail the state of a specific consumer group by checking the consumers that are registered in the group.</p>\n<pre><code>127.0.0.1:6379&gt; XINFO CONSUMERS race:italy italy_riders\n1) 1) &quot;name&quot;\n   2) &quot;Alice&quot;\n   3) &quot;pending&quot;\n   4) (integer) 1\n   5) &quot;idle&quot;\n   6) (integer) 177546\n2) 1) &quot;name&quot;\n   2) &quot;Bob&quot;\n   3) &quot;pending&quot;\n   4) (integer) 0\n   5) &quot;idle&quot;\n   6) (integer) 424686\n3) 1) &quot;name&quot;\n   2) &quot;Lora&quot;\n   3) &quot;pending&quot;\n   4) (integer) 1\n   5) &quot;idle&quot;\n   6) (integer) 72241\n</code></pre>\n<p>In case you do not remember the syntax of the command, just ask the command itself for help:</p>\n<pre><code>&gt; XINFO HELP\n1) XINFO &lt;subcommand&gt; [&lt;arg&gt; [value] [opt] ...]. Subcommands are:\n2) CONSUMERS &lt;key&gt; &lt;groupname&gt;\n3)     Show consumers of &lt;groupname&gt;.\n4) GROUPS &lt;key&gt;\n5)     Show the stream consumer groups.\n6) STREAM &lt;key&gt; [FULL [COUNT &lt;count&gt;]\n7)     Show information about the stream.\n8) HELP\n9)     Prints this help.\n</code></pre>\n<h2>Differences with Kafka (TM) partitions</h2>\n<p>Consumer groups in Streams may resemble in some way Kafka (TM) partitioning-based consumer groups, however note that Streams are, in practical terms, very different. The partitions are only <em>logical</em> and the messages are just put into a single Valkey key, so the way the different clients are served is based on who is ready to process new messages, and not from which partition clients are reading. For instance, if the consumer C3 at some point fails permanently, Valkey will continue to serve C1 and C2 all the new messages arriving, as if now there are only two <em>logical</em> partitions.</p>\n<p>Similarly, if a given consumer is much faster at processing messages than the other consumers, this consumer will receive proportionally more messages in the same unit of time. This is possible since Valkey tracks all the unacknowledged messages explicitly, and remembers who received which message and the ID of the first message never delivered to any consumer.</p>\n<p>However, this also means that in Valkey if you really want to partition messages in the same stream into multiple Valkey instances, you have to use multiple keys and some sharding system such as Valkey Cluster or some other application-specific sharding system. A single Stream is not automatically partitioned to multiple instances.</p>\n<p>We could say that schematically the following is true:</p>\n<ul>\n<li>If you use 1 stream -&gt; 1 consumer, you are processing messages in order.</li>\n<li>If you use N streams with N consumers, so that only a given consumer hits a subset of the N streams, you can scale the above model of 1 stream -&gt; 1 consumer.</li>\n<li>If you use 1 stream -&gt; N consumers, you are load balancing to N consumers, however in that case, messages about the same logical item may be consumed out of order, because a given consumer may process message 3 faster than another consumer is processing message 4.</li>\n</ul>\n<p>So basically Kafka partitions are more similar to using N different Valkey keys, while Valkey consumer groups are a server-side load balancing system of messages from a given stream to N different consumers.</p>\n<h2>Capped Streams</h2>\n<p>Many applications do not want to collect data into a stream forever. Sometimes it is useful to have at maximum a given number of items inside a stream, other times once a given size is reached, it is useful to move data from Valkey to a storage which is not in memory and not as fast but suited to store the history for, potentially, decades to come. Streams have some support for this. One is the <strong>MAXLEN</strong> option of the <code>XADD</code> command. This option is very simple to use:</p>\n<pre><code>127.0.0.1:6379&gt; XADD race:italy MAXLEN 2 * rider Jones\n&quot;1692633189161-0&quot;\n127.0.0.1:6379&gt; XADD race:italy MAXLEN 2 * rider Wood\n&quot;1692633198206-0&quot;\n127.0.0.1:6379&gt; XADD race:italy MAXLEN 2 * rider Henshaw\n&quot;1692633208557-0&quot;\n127.0.0.1:6379&gt; XLEN race:italy\n(integer) 2\n127.0.0.1:6379&gt; XRANGE race:italy - +\n1) 1) &quot;1692633198206-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Wood&quot;\n2) 1) &quot;1692633208557-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Henshaw&quot;\n</code></pre>\n<p>Using <strong>MAXLEN</strong> the old entries are automatically evicted when the specified length is reached, so that the stream is left at a constant size. There is currently no option to tell the stream to just retain items that are not older than a given period, because such command, in order to run consistently, would potentially block for a long time in order to evict items. Imagine for example what happens if there is an insertion spike, then a long pause, and another insertion, all with the same maximum time. The stream would block to evict the data that became too old during the pause. So it is up to the user to do some planning and understand what is the maximum stream length desired. Moreover, while the length of the stream is proportional to the memory used, trimming by time is less simple to control and anticipate: it depends on the insertion rate which often changes over time (and when it does not change, then to just trim by size is trivial).</p>\n<p>However trimming with <strong>MAXLEN</strong> can be expensive: streams are represented by macro nodes into a radix tree, in order to be very memory efficient. Altering the single macro node, consisting of a few tens of elements, is not optimal. So it&#39;s possible to use the command in the following special form:</p>\n<pre><code>XADD race:italy MAXLEN ~ 1000 * ... entry fields here ...\n</code></pre>\n<p>The <code>~</code> argument between the <strong>MAXLEN</strong> option and the actual count means, I don&#39;t really need this to be exactly 1000 items. It can be 1000 or 1010 or 1030, just make sure to save at least 1000 items. With this argument, the trimming is performed only when we can remove a whole node. This makes it much more efficient, and it is usually what you want. You&#39;ll note here that the client libraries have various implementations of this. For example, the Python client defaults to approximate and has to be explicitly set to a true length.</p>\n<p>There is also the <code>XTRIM</code> command, which performs something very similar to what the <strong>MAXLEN</strong> option does above, except that it can be run by itself:</p>\n<pre><code>127.0.0.1:6379&gt; XTRIM race:italy MAXLEN 10\n(integer) 0\n</code></pre>\n<p>Or, as for the <code>XADD</code> option:</p>\n<pre><code>127.0.0.1:6379&gt; XTRIM race:italy MAXLEN ~ 10\n(integer) 0\n</code></pre>\n<p>However, <code>XTRIM</code> is designed to accept different trimming strategies. Another trimming strategy is <strong>MINID</strong>, that evicts entries with IDs lower than the one specified.</p>\n<p>As <code>XTRIM</code> is an explicit command, the user is expected to know about the possible shortcomings of different trimming strategies.</p>\n<p>Another useful eviction strategy that may be added to <code>XTRIM</code> in the future, is to remove by a range of IDs to ease use of <code>XRANGE</code> and <code>XTRIM</code> to move data from Valkey to other storage systems if needed.</p>\n<h2>Special IDs in the streams API</h2>\n<p>You may have noticed that there are several special IDs that can be used in the Valkey API. Here is a short recap, so that they can make more sense in the future.</p>\n<p>The first two special IDs are <code>-</code> and <code>+</code>, and are used in range queries with the <code>XRANGE</code> command. Those two IDs respectively mean the smallest ID possible (that is basically <code>0-1</code>) and the greatest ID possible (that is <code>18446744073709551615-18446744073709551615</code>). As you can see it is a lot cleaner to write <code>-</code> and <code>+</code> instead of those numbers.</p>\n<p>Then there are APIs where we want to say, the ID of the item with the greatest ID inside the stream. This is what <code>$</code> means. So for instance if I want only new entries with <code>XREADGROUP</code> I use this ID to signify I already have all the existing entries, but not the new ones that will be inserted in the future. Similarly when I create or set the ID of a consumer group, I can set the last delivered item to <code>$</code> in order to just deliver new entries to the consumers in the group.</p>\n<p>As you can see <code>$</code> does not mean <code>+</code>, they are two different things, as <code>+</code> is the greatest ID possible in every possible stream, while <code>$</code> is the greatest ID in a given stream containing given entries. Moreover APIs will usually only understand <code>+</code> or <code>$</code>, yet it was useful to avoid loading a given symbol with multiple meanings.</p>\n<p>Another special ID is <code>&gt;</code>, that is a special meaning only related to consumer groups and only when the <code>XREADGROUP</code> command is used. This special ID means that we want only entries that were never delivered to other consumers so far. So basically the <code>&gt;</code> ID is the <em>last delivered ID</em> of a consumer group.</p>\n<p>Finally the special ID <code>*</code>, that can be used only with the <code>XADD</code> command, means to auto select an ID for us for the new entry.</p>\n<p>So we have <code>-</code>, <code>+</code>, <code>$</code>, <code>&gt;</code> and <code>*</code>, and all have a different meaning, and most of the time, can be used in different contexts.</p>\n<h2>Persistence, replication and message safety</h2>\n<p>A Stream, like any other Valkey data structure, is asynchronously replicated to replicas and persisted into AOF and RDB files. However what may not be so obvious is that also the consumer groups full state is propagated to AOF, RDB and replicas, so if a message is pending in the primary, also the replica will have the same information. Similarly, after a restart, the AOF will restore the consumer groups&#39; state.</p>\n<p>However note that Streams and consumer groups are persisted and replicated using the Valkey default replication, so:</p>\n<ul>\n<li>AOF must be used with a strong fsync policy if persistence of messages is important in your application.</li>\n<li>By default the asynchronous replication will not guarantee that <code>XADD</code> commands or consumer groups state changes are replicated: after a failover something can be missing depending on the ability of replicas to receive the data from the primary.</li>\n<li>The <code>WAIT</code> command may be used in order to force the propagation of the changes to a set of replicas. However note that while this makes it very unlikely that data is lost, the Valkey failover process as operated by Sentinel or Valkey Cluster performs only a <em>best effort</em> check to failover to the replica which is the most updated, and under certain specific failure conditions may promote a replica that lacks some data.</li>\n</ul>\n<p>So when designing an application using Streams and consumer groups, make sure to understand the semantical properties your application should have during failures, and configure things accordingly, evaluating whether it is safe enough for your use case.</p>\n<h2>Removing single items from a stream</h2>\n<p>Streams also have a special command for removing items from the middle of a stream, just by ID. Normally for an append only data structure this may look like an odd feature, but it is actually useful for applications involving, for instance, privacy regulations. The command is called <code>XDEL</code> and receives the name of the stream followed by the IDs to delete:</p>\n<pre><code>127.0.0.1:6379&gt; XRANGE race:italy - + COUNT 2\n1) 1) &quot;1692633198206-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Wood&quot;\n2) 1) &quot;1692633208557-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Henshaw&quot;\n127.0.0.1:6379&gt; XDEL race:italy 1692633208557-0\n(integer) 1\n127.0.0.1:6379&gt; XRANGE race:italy - + COUNT 2\n1) 1) &quot;1692633198206-0&quot;\n   2) 1) &quot;rider&quot;\n      2) &quot;Wood&quot;\n</code></pre>\n<p>However in the current implementation, memory is not really reclaimed until a macro node is completely empty, so you should not abuse this feature.</p>\n<h2>Zero length streams</h2>\n<p>A difference between streams and other Valkey data structures is that when the other data structures no longer have any elements, as a side effect of calling commands that remove elements, the key itself will be removed. So for instance, a sorted set will be completely removed when a call to <code>ZREM</code> will remove the last element in the sorted set. Streams, on the other hand, are allowed to stay at zero elements, both as a result of using a <strong>MAXLEN</strong> option with a count of zero (<code>XADD</code> and <code>XTRIM</code> commands), or because <code>XDEL</code> was called.</p>\n<p>The reason why such an asymmetry exists is because Streams may have associated consumer groups, and we do not want to lose the state that the consumer groups defined just because there are no longer any items in the stream. Currently the stream is not deleted even when it has no associated consumer groups.</p>\n<h2>Total latency of consuming a message</h2>\n<p>Non blocking stream commands like <code>XRANGE</code> and <code>XREAD</code> or <code>XREADGROUP</code> without the BLOCK option are served synchronously like any other Valkey command, so to discuss latency of such commands is meaningless: it is more interesting to check the time complexity of the commands in the Valkey documentation. It should be enough to say that stream commands are at least as fast as sorted set commands when extracting ranges, and that <code>XADD</code> is very fast and can easily insert from half a million to one million items per second in an average machine if pipelining is used.</p>\n<p>However latency becomes an interesting parameter if we want to understand the delay of processing a message, in the context of blocking consumers in a consumer group, from the moment the message is produced via <code>XADD</code>, to the moment the message is obtained by the consumer because <code>XREADGROUP</code> returned with the message.</p>\n<h2>How serving blocked consumers works</h2>\n<p>Before providing the results of performed tests, it is interesting to understand what model Valkey uses in order to route stream messages (and in general actually how any blocking operation waiting for data is managed).</p>\n<ul>\n<li>The blocked client is referenced in a hash table that maps keys for which there is at least one blocking consumer, to a list of consumers that are waiting for such key. This way, given a key that received data, we can resolve all the clients that are waiting for such data.</li>\n<li>When a write happens, in this case when the <code>XADD</code> command is called, it calls the <code>signalKeyAsReady()</code> function. This function will put the key into a list of keys that need to be processed, because such keys may have new data for blocked consumers. Note that such <em>ready keys</em> will be processed later, so in the course of the same event loop cycle, it is possible that the key will receive other writes.</li>\n<li>Finally, before returning into the event loop, the <em>ready keys</em> are finally processed. For each key the list of clients waiting for data is scanned, and if applicable, such clients will receive the new data that arrived. In the case of streams the data is the messages in the applicable range requested by the consumer.</li>\n</ul>\n<p>As you can see, basically, before returning to the event loop both the client calling <code>XADD</code> and the clients blocked to consume messages, will have their reply in the output buffers, so the caller of <code>XADD</code> should receive the reply from Valkey at about the same time the consumers will receive the new messages.</p>\n<p>This model is <em>push-based</em>, since adding data to the consumers buffers will be performed directly by the action of calling <code>XADD</code>, so the latency tends to be quite predictable.</p>\n<h2>Latency tests results</h2>\n<p>In order to check these latency characteristics a test was performed using multiple instances of Ruby programs pushing messages having as an additional field the computer millisecond time, and Ruby programs reading the messages from the consumer group and processing them. The message processing step consisted of comparing the current computer time with the message timestamp, in order to understand the total latency.</p>\n<p>Results obtained:</p>\n<pre><code>Processed between 0 and 1 ms -&gt; 74.11%\nProcessed between 1 and 2 ms -&gt; 25.80%\nProcessed between 2 and 3 ms -&gt; 0.06%\nProcessed between 3 and 4 ms -&gt; 0.01%\nProcessed between 4 and 5 ms -&gt; 0.02%\n</code></pre>\n<p>So 99.9% of requests have a latency &lt;= 2 milliseconds, with the outliers that remain still very close to the average.</p>\n<p>Adding a few million unacknowledged messages to the stream does not change the gist of the benchmark, with most queries still processed with very short latency.</p>\n<p>A few remarks:</p>\n<ul>\n<li>Here we processed up to 10k messages per iteration, this means that the <code>COUNT</code> parameter of <code>XREADGROUP</code> was set to 10000. This adds a lot of latency but is needed in order to allow the slow consumers to be able to keep with the message flow. So you can expect a real world latency that is a lot smaller.</li>\n<li>The system used for this benchmark is very slow compared to today&#39;s standards.</li>\n</ul>\n"
      },
      {
        "id": "strings",
        "topicName": "Strings",
        "description": "Introduction to Strings\n",
        "htmlContent": "<p>Strings store sequences of bytes, including text, serialized objects, and binary arrays.<br>As such, strings are the simplest type of value you can associate with<br>a Valkey key.<br>They&#39;re often used for caching, but they support additional functionality that lets you implement counters and perform bitwise operations, too.</p>\n<p>Since Valkey keys are strings, when we use the string type as a value too,<br>we are mapping a string to another string. The string data type is useful<br>for a number of use cases, like caching HTML fragments or pages.</p>\n<pre><code>127.0.0.1:6379&gt; SET bike:1 Deimos\nOK\n127.0.0.1:6379&gt; GET bike:1\n&quot;Deimos&quot;\n</code></pre>\n<p>As you can see using the <code>SET</code> and the <code>GET</code> commands are the way we set<br>and retrieve a string value. Note that <code>SET</code> will replace any existing value<br>already stored into the key, in the case that the key already exists, even if<br>the key is associated with a non-string value. So <code>SET</code> performs an assignment.</p>\n<p>Values can be strings (including binary data) of every kind, for instance you<br>can store a jpeg image inside a value. A value can&#39;t be bigger than 512 MB.</p>\n<p>The <code>SET</code> command has interesting options, that are provided as additional<br>arguments. For example, I may ask <code>SET</code> to fail if the key already exists,<br>or the opposite, that it only succeed if the key already exists:</p>\n<pre><code>127.0.0.1:6379&gt; set bike:1 bike nx\n(nil)\n127.0.0.1:6379&gt; set bike:1 bike xx\nOK\n</code></pre>\n<p>There are a number of other commands for operating on strings. For example<br>the <code>GETSET</code> command sets a key to a new value, returning the old value as the<br>result. You can use this command, for example, if you have a<br>system that increments a Valkey key using <code>INCR</code><br>every time your web site receives a new visitor. You may want to collect this<br>information once every hour, without losing a single increment.<br>You can <code>GETSET</code> the key, assigning it the new value of &quot;0&quot; and reading the<br>old value back.</p>\n<p>The ability to set or retrieve the value of multiple keys in a single<br>command is also useful for reduced latency. For this reason there are<br>the <code>MSET</code> and <code>MGET</code> commands:</p>\n<pre><code>127.0.0.1:6379&gt; mset bike:1 &quot;Deimos&quot; bike:2 &quot;Ares&quot; bike:3 &quot;Vanth&quot;\nOK\n127.0.0.1:6379&gt; mget bike:1 bike:2 bike:3\n1) &quot;Deimos&quot;\n2) &quot;Ares&quot;\n3) &quot;Vanth&quot;\n</code></pre>\n<p>When <code>MGET</code> is used, Valkey returns an array of values.</p>\n<h3>Strings as counters</h3>\n<p>Even if strings are the basic values of Valkey, there are interesting operations<br>you can perform with them. For instance, one is atomic increment:</p>\n<pre><code>127.0.0.1:6379&gt; set total_crashes 0\nOK\n127.0.0.1:6379&gt; incr total_crashes\n(integer) 1\n127.0.0.1:6379&gt; incrby total_crashes 10\n(integer) 11\n</code></pre>\n<p>The <code>INCR</code> command parses the string value as an integer,<br>increments it by one, and finally sets the obtained value as the new value.<br>There are other similar commands like <code>INCRBY</code>,<br><code>DECR</code> and <code>DECRBY</code>. Internally it&#39;s<br>always the same command, acting in a slightly different way.</p>\n<p>What does it mean that INCR is atomic?<br>That even multiple clients issuing INCR against<br>the same key will never enter into a race condition. For instance, it will never<br>happen that client 1 reads &quot;10&quot;, client 2 reads &quot;10&quot; at the same time, both<br>increment to 11, and set the new value to 11. The final value will always be<br>12 and the read-increment-set operation is performed while all the other<br>clients are not executing a command at the same time.</p>\n<h2>Limits</h2>\n<p>By default, a single String can be a maximum of 512 MB.</p>\n<h2>Basic commands</h2>\n<h3>Getting and setting Strings</h3>\n<ul>\n<li><code>SET</code> stores a string value.</li>\n<li><code>SETNX</code> stores a string value only if the key doesn&#39;t already exist. Useful for implementing locks.</li>\n<li><code>GET</code> retrieves a string value.</li>\n<li><code>MGET</code> retrieves multiple string values in a single operation.</li>\n</ul>\n<h3>Managing counters</h3>\n<ul>\n<li><code>INCRBY</code> atomically increments (and decrements when passing a negative number) counters stored at a given key.</li>\n<li>Another command exists for floating point counters: <code>INCRBYFLOAT</code>.</li>\n</ul>\n<h3>Bitwise operations</h3>\n<p>To perform bitwise operations on a string, see the <a href=\"bitmaps\">bitmaps data type</a> docs.</p>\n<p>See the <a href=\"../commands/#string\">complete list of string commands</a>.</p>\n<h2>Performance</h2>\n<p>Most string operations are O(1), which means they&#39;re highly efficient.<br>However, be careful with the <code>SUBSTR</code>, <code>GETRANGE</code>, and <code>SETRANGE</code> commands, which can be O(n).<br>These random-access string commands may cause performance issues when dealing with large strings.</p>\n<h2>Alternatives</h2>\n<p>If you&#39;re storing structured data as a serialized string, you may also want to consider Valkey <a href=\"hashes\">hashes</a>.</p>\n"
      }
    ]
  },
  {
    "title": "SCRIPTING & PROGRAMMING",
    "items": [
      {
        "id": "command-arguments",
        "topicName": "Command arguments",
        "description": "How Valkey commands expose their documentation programmatically",
        "htmlContent": "<p>The <code>COMMAND DOCS</code> command returns documentation-focused information about available Valkey commands.<br>The map reply that the command returns includes the <em>arguments</em> key.<br>This key stores an array that describes the command&#39;s arguments.</p>\n<p>Every element in the <em>arguments</em> array is a map with the following fields:</p>\n<ul>\n<li><strong>name:</strong> the argument&#39;s name, always present.<br>The name of an argument is given for identification purposes alone.<br>It isn&#39;t displayed during the command&#39;s syntax rendering.<br>The same name can appear more than once in the entire argument tree, but it is unique compared to other sibling arguments&#39; names.<br>This allows obtaining a unique identifier for each argument (the concatenation of all names in the path from the root to any argument).</li>\n<li><strong>display_text:</strong> the argument&#39;s display string, present in arguments that have a displayable representation (all arguments that aren&#39;t oneof/block).<br>This is the string used in the command&#39;s syntax rendering.</li>\n<li><strong>type:</strong> the argument&#39;s type, always present.<br>An argument must have one of the following types:<ul>\n<li><strong>string:</strong> a string argument.</li>\n<li><strong>integer:</strong> an integer argument.</li>\n<li><strong>double:</strong> a double-precision argument.</li>\n<li><strong>key:</strong> a string that represents the name of a key.</li>\n<li><strong>pattern:</strong> a string that represents a glob-like pattern.</li>\n<li><strong>unix-time:</strong> an integer that represents a Unix timestamp.</li>\n<li><strong>pure-token:</strong> an argument is a token, meaning a reserved keyword, which may or may not be provided.<br>Not to be confused with free-text user input.</li>\n<li><strong>oneof</strong>: the argument is a container for nested arguments.<br>This type enables choice among several nested arguments (see the <code>XADD</code> example below).</li>\n<li><strong>block:</strong> the argument is a container for nested arguments.<br>This type enables grouping arguments and applying a property (such as <em>optional</em>) to all (see the <code>XADD</code> example below).</li>\n</ul>\n</li>\n<li><strong>key_spec_index:</strong> this value is available for every argument of the <em>key</em> type.<br>It is a 0-based index of the specification in the command&#39;s <a href=\"key-specs\">key specifications</a> that corresponds to the argument.</li>\n<li><strong>token</strong>: a constant literal that precedes the argument (user input) itself.</li>\n<li><strong>summary:</strong> a short description of the argument.</li>\n<li><strong>since:</strong> the debut Redis OSS version of the argument (or for module commands, the module version).</li>\n<li><strong>deprecated_since:</strong> the Redis OSS version that deprecated the command (or for module commands, the module version).</li>\n<li><strong>flags:</strong> an array of argument flags.<br>Possible flags are:<ul>\n<li><strong>optional</strong>: denotes that the argument is optional (for example, the <em>GET</em> clause of the  <code>SET</code> command).</li>\n<li><strong>multiple</strong>: denotes that the argument may be repeated (such as the <em>key</em> argument of <code>DEL</code>).</li>\n<li><strong>multiple-token:</strong> denotes the possible repetition of the argument with its preceding token (see <code>SORT</code>&#39;s <code>GET pattern</code> clause).</li>\n</ul>\n</li>\n<li><strong>value:</strong> the argument&#39;s value.<br>For arguments types other than <em>oneof</em> and <em>block</em>, this is a string that describes the value in the command&#39;s syntax.<br>For the <em>oneof</em> and <em>block</em> types, this is an array of nested arguments, each being a map as described in this section.</li>\n</ul>\n<h2>Example</h2>\n<p>The trimming clause of <code>XADD</code>, i.e., <code>[MAXLEN|MINID [=|~] threshold [LIMIT count]]</code>, is represented at the top-level as <em>block</em>-typed argument.</p>\n<p>It consists of four nested arguments:</p>\n<ol>\n<li><strong>trimming strategy:</strong> this nested argument has an <em>oneof</em> type with two nested arguments.<br>  Each of the nested arguments, <em>MAXLEN</em> and <em>MINID</em>, is typed as <em>pure-token</em>.</li>\n<li><strong>trimming operator:</strong> this nested argument is an optional <em>oneof</em> type with two nested arguments.<br>  Each of the nested arguments, <em>=</em> and <em>~</em>, is a <em>pure-token</em>.</li>\n<li><strong>threshold:</strong> this nested argument is a <em>string</em>.</li>\n<li><strong>count:</strong> this nested argument is an optional <em>integer</em> with a <em>token</em> (<em>LIMIT</em>).</li>\n</ol>\n<p>Here&#39;s <code>XADD</code>&#39;s arguments array:</p>\n<pre><code>1) 1) &quot;name&quot;\n   2) &quot;key&quot;\n   3) &quot;type&quot;\n   4) &quot;key&quot;\n   5) &quot;value&quot;\n   6) &quot;key&quot;\n2)  1) &quot;name&quot;\n    2) &quot;nomkstream&quot;\n    3) &quot;type&quot;\n    4) &quot;pure-token&quot;\n    5) &quot;token&quot;\n    6) &quot;NOMKSTREAM&quot;\n    7) &quot;since&quot;\n    8) &quot;6.2&quot;\n    9) &quot;flags&quot;\n   10) 1) optional\n3) 1) &quot;name&quot;\n   2) &quot;trim&quot;\n   3) &quot;type&quot;\n   4) &quot;block&quot;\n   5) &quot;flags&quot;\n   6) 1) optional\n   7) &quot;value&quot;\n   8) 1) 1) &quot;name&quot;\n         2) &quot;strategy&quot;\n         3) &quot;type&quot;\n         4) &quot;oneof&quot;\n         5) &quot;value&quot;\n         6) 1) 1) &quot;name&quot;\n               2) &quot;maxlen&quot;\n               3) &quot;type&quot;\n               4) &quot;pure-token&quot;\n               5) &quot;token&quot;\n               6) &quot;MAXLEN&quot;\n            2) 1) &quot;name&quot;\n               2) &quot;minid&quot;\n               3) &quot;type&quot;\n               4) &quot;pure-token&quot;\n               5) &quot;token&quot;\n               6) &quot;MINID&quot;\n               7) &quot;since&quot;\n               8) &quot;6.2&quot;\n      2) 1) &quot;name&quot;\n         2) &quot;operator&quot;\n         3) &quot;type&quot;\n         4) &quot;oneof&quot;\n         5) &quot;flags&quot;\n         6) 1) optional\n         7) &quot;value&quot;\n         8) 1) 1) &quot;name&quot;\n               2) &quot;equal&quot;\n               3) &quot;type&quot;\n               4) &quot;pure-token&quot;\n               5) &quot;token&quot;\n               6) &quot;=&quot;\n            2) 1) &quot;name&quot;\n               2) &quot;approximately&quot;\n               3) &quot;type&quot;\n               4) &quot;pure-token&quot;\n               5) &quot;token&quot;\n               6) &quot;~&quot;\n      3) 1) &quot;name&quot;\n         2) &quot;threshold&quot;\n         3) &quot;type&quot;\n         4) &quot;string&quot;\n         5) &quot;value&quot;\n         6) &quot;threshold&quot;\n      4)  1) &quot;name&quot;\n          2) &quot;count&quot;\n          3) &quot;type&quot;\n          4) &quot;integer&quot;\n          5) &quot;token&quot;\n          6) &quot;LIMIT&quot;\n          7) &quot;since&quot;\n          8) &quot;6.2&quot;\n          9) &quot;flags&quot;\n         10) 1) optional\n         11) &quot;value&quot;\n         12) &quot;count&quot;\n4) 1) &quot;name&quot;\n   2) &quot;id_or_auto&quot;\n   3) &quot;type&quot;\n   4) &quot;oneof&quot;\n   5) &quot;value&quot;\n   6) 1) 1) &quot;name&quot;\n         2) &quot;auto_id&quot;\n         3) &quot;type&quot;\n         4) &quot;pure-token&quot;\n         5) &quot;token&quot;\n         6) &quot;*&quot;\n      2) 1) &quot;name&quot;\n         2) &quot;id&quot;\n         3) &quot;type&quot;\n         4) &quot;string&quot;\n         5) &quot;value&quot;\n         6) &quot;id&quot;\n5) 1) &quot;name&quot;\n   2) &quot;field_value&quot;\n   3) &quot;type&quot;\n   4) &quot;block&quot;\n   5) &quot;flags&quot;\n   6) 1) multiple\n   7) &quot;value&quot;\n   8) 1) 1) &quot;name&quot;\n         2) &quot;field&quot;\n         3) &quot;type&quot;\n         4) &quot;string&quot;\n         5) &quot;value&quot;\n         6) &quot;field&quot;\n      2) 1) &quot;name&quot;\n         2) &quot;value&quot;\n         3) &quot;type&quot;\n         4) &quot;string&quot;\n         5) &quot;value&quot;\n         6) &quot;value&quot;\n</code></pre>\n"
      },
      {
        "id": "command-tips",
        "topicName": "Command tips",
        "description": "Get additional information about a command",
        "htmlContent": "<p>This page documents a small part of the reply of the <a href=\"../command\"><code>COMMAND</code></a>.<br>In the reply of the COMMAND command, each command is represented by an array.<br>The 8th element in this array is the command tips.<br>It&#39;s an array of strings.</p>\n<p>These provide Valkey clients with additional information about the command.<br>The information can instruct Valkey Cluster clients as to how the command should be executed and its output processed in a clustered deployment.</p>\n<p>Unlike the command&#39;s flags (see the 3rd element of <a href=\"../command\"><code>COMMAND</code></a>&#39;s reply), which are strictly internal to the server&#39;s operation, tips don&#39;t serve any purpose other than being reported to clients.</p>\n<h2><code>nondeterministic_output</code></h2>\n<p>This tip indicates that the command&#39;s output isn&#39;t deterministic.<br>That means that calls to the command may yield different results with the same arguments and data.<br>That difference could be the result of the command&#39;s random nature (e.g., <code>RANDOMKEY</code> and <code>SPOP</code>); the call&#39;s timing (e.g., <code>TTL</code>); or generic differences that relate to the server&#39;s state (e.g., <code>INFO</code> and <code>CLIENT LIST</code>).</p>\n<p><strong>Note:</strong><br>Prior to Redis OSS 7.0, this tip was the <code>random</code> command flag.</p>\n<h2><code>nondeterministic_output_order</code></h2>\n<p>The existence of this tip indicates that the command&#39;s output is deterministic, but its ordering is random (e.g., <code>HGETALL</code> and <code>SMEMBERS</code>).</p>\n<p><strong>Note:</strong><br>Prior to Redis OSS 7.0, this tip was the <code>sort_for_script</code> flag.</p>\n<h2><code>request_policy:</code><em>value</em></h2>\n<p>This tip can help clients determine the shards to send the command in clustering mode.<br>The default behavior a client should implement for commands without the <code>request_policy</code> tip is as follows:</p>\n<ol>\n<li>The command doesn&#39;t accept key name arguments: the client can execute the command on an arbitrary shard.</li>\n<li>For commands that accept one or more key name arguments: the client should route the command to a single shard, as determined by the hash slot of the input keys.</li>\n</ol>\n<p>In cases where the client should adopt a behavior different than the default, the <code>request_policy</code> tip can be one of:</p>\n<ul>\n<li><strong>all_nodes:</strong> the client should execute the command on all nodes - primaries and replicas alike.<br>An example is the <code>CONFIG SET</code> command.<br>This tip is in-use by commands that don&#39;t accept key name arguments.<br>The command operates atomically per shard.</li>\n</ul>\n<ul>\n<li><strong>all_shards:</strong> the client should execute the command on all primary shards (e.g., the <code>DBSIZE</code> command).<br>This tip is in-use by commands that don&#39;t accept key name arguments.<br>The command operates atomically per shard.</li>\n</ul>\n<ul>\n<li><strong>multi_shard:</strong> the client should execute the command on several shards.<br>The client should split the inputs according to the hash slots of its input key name arguments.<br>For example, the command <code>DEL {foo} {foo}1 bar</code> should be split to <code>DEL {foo} {foo}1</code> and <code>DEL bar</code>.<br>If the keys are hashed to more than a single slot, the command must be split even if all the slots are managed by the same shard.<br>Examples for such commands include <code>MSET</code>, <code>MGET</code> and <code>DEL</code>.<br>However, note that <code>SUNIONSTORE</code> isn&#39;t considered as <em>multi_shard</em> because all of its keys must belong to the same hash slot.</li>\n<li><strong>special:</strong> indicates a non-trivial form of the client&#39;s request policy, such as the <code>SCAN</code> command.</li>\n</ul>\n<h2><code>response_policy:</code><em>value</em></h2>\n<p>This tip can help clients determine the aggregate they need to compute from the replies of multiple shards in a cluster.<br>The default behavior for commands without a <code>request_policy</code> tip only applies to replies with of nested types (i.e., an array, a set, or a map).<br>The client&#39;s implementation for the default behavior should be as follows:</p>\n<ol>\n<li>The command doesn&#39;t accept key name arguments: the client can aggregate all replies within a single nested data structure.<br>For example, the array replies we get from calling <code>KEYS</code> against all shards.<br>These should be packed in a single in no particular order.</li>\n<li>For commands that accept one or more key name arguments: the client needs to retain the same order of replies as the input key names.<br>For example, <code>MGET</code>&#39;s aggregated reply.</li>\n</ol>\n<p>The <code>response_policy</code> tip is set for commands that reply with scalar data types, or when it&#39;s expected that clients implement a non-default aggregate.<br>This tip can be one of:</p>\n<ul>\n<li><strong>one_succeeded:</strong> the clients should return success if at least one shard didn&#39;t reply with an error.<br>The client should reply with the first non-error reply it obtains.<br>If all shards return an error, the client can reply with any one of these.<br>For example, consider a <code>SCRIPT KILL</code> command that&#39;s sent to all shards.<br>Although the script should be loaded in all of the cluster&#39;s shards, the <code>SCRIPT KILL</code> will typically run only on one at a given time.</li>\n<li><strong>all_succeeded:</strong> the client should return successfully only if there are no error replies.<br>Even a single error reply should disqualify the aggregate and be returned.<br>Otherwise, the client should return one of the non-error replies.<br>As an example, consider the <code>CONFIG SET</code>, <code>SCRIPT FLUSH</code> and <code>SCRIPT LOAD</code> commands.</li>\n<li><strong>agg_logical_and:</strong> the client should return the result of a logical <em>AND</em> operation on all replies (only applies to integer replies, usually from commands that return either <em>0</em> or <em>1</em>).<br>Consider the <code>SCRIPT EXISTS</code> command as an example.<br>It returns an array of <em>0</em>&#39;s and <em>1</em>&#39;s that denote the existence of its given SHA1 sums in the script cache.<br>The aggregated response should be <em>1</em> only when all shards had reported that a given script SHA1 sum is in their respective cache.</li>\n<li><strong>agg_logical_or:</strong> the client should return the result of a logical <em>AND</em> operation on all replies (only applies to integer replies, usually from commands that return either <em>0</em> or <em>1</em>).</li>\n<li><strong>agg_min:</strong> the client should return the minimal value from the replies (only applies to numerical replies).<br>The aggregate reply from a cluster-wide <code>WAIT</code> command, for example, should be the minimal value (number of synchronized replicas) from all shards.</li>\n<li><strong>agg_max:</strong> the client should return the maximal value from the replies (only applies to numerical replies).</li>\n<li><strong>agg_sum:</strong> the client should return the sum of replies (only applies to numerical replies).<br>Example: <code>DBSIZE</code>.</li>\n<li><strong>special:</strong> this type of tip indicates a non-trivial form of reply policy.<br><code>INFO</code> is an excellent example of that.</li>\n</ul>\n<h2>Example</h2>\n<pre><code>127.0.0.1:6379&gt; command info ping\n1)  1) &quot;ping&quot;\n    2) (integer) -1\n    3) 1) fast\n    4) (integer) 0\n    5) (integer) 0\n    6) (integer) 0\n    7) 1) @fast\n       2) @connection\n    8) 1) &quot;request_policy:all_shards&quot;\n       2) &quot;response_policy:all_succeeded&quot;\n    9) (empty array)\n   10) (empty array)\n</code></pre>\n"
      },
      {
        "id": "eval-intro",
        "topicName": "Scripting with Lua",
        "description": "Executing Lua in Valkey\n",
        "htmlContent": "<p>Valkey lets users upload and execute Lua scripts on the server.<br>Scripts can employ programmatic control structures and use most of the <a href=\"../commands/\">commands</a> while executing to access the database.<br>Because scripts execute in the server, reading and writing data from scripts is very efficient.</p>\n<p>Valkey guarantees the script&#39;s atomic execution.<br>While executing the script, all server activities are blocked during its entire runtime.<br>These semantics mean that all of the script&#39;s effects either have yet to happen or had already happened.</p>\n<p>Scripting offers several properties that can be valuable in many cases.<br>These include:</p>\n<ul>\n<li>Providing locality by executing logic where data lives. Data locality reduces overall latency and saves networking resources.</li>\n<li>Blocking semantics that ensure the script&#39;s atomic execution.</li>\n<li>Enabling the composition of simple capabilities that are either missing from Valkey or are too niche to be a part of it.</li>\n</ul>\n<p>Lua lets you run part of your application logic inside Valkey.<br>Such scripts can perform conditional updates across multiple keys, possibly combining several different data types atomically.</p>\n<p>Scripts are executed in Valkey by an embedded execution engine.<br>Presently, Valkey supports a single scripting engine, the <a href=\"https://www.lua.org/\">Lua 5.1</a> interpreter.<br>Please refer to the <a href=\"lua-api\">Valkey Lua API Reference</a> page for complete documentation.</p>\n<p>Although the server executes them, Eval scripts are regarded as a part of the client-side application, which is why they&#39;re not named, versioned, or persisted.<br>So all scripts may need to be reloaded by the application at any time if missing (after a server restart, fail-over to a replica, etc.).<br>As of version 7.0, <a href=\"functions-intro\">Valkey Functions</a> offer an alternative approach to programmability which allow the server itself to be extended with additional programmed logic.</p>\n<h2>Getting started</h2>\n<p>We&#39;ll start scripting with Valkey by using the <code>EVAL</code> command.</p>\n<p>Here&#39;s our first example:</p>\n<pre><code>&gt; EVAL &quot;return &#39;Hello, scripting!&#39;&quot; 0\n&quot;Hello, scripting!&quot;\n</code></pre>\n<p>In this example, <code>EVAL</code> takes two arguments.<br>The first argument is a string that consists of the script&#39;s Lua source code.<br>The script doesn&#39;t need to include any definitions of Lua function.<br>It is just a Lua program that will run in the Valkey engine&#39;s context.</p>\n<p>The second argument is the number of arguments that follow the script&#39;s body, starting from the third argument, representing Valkey key names.<br>In this example, we used the value <em>0</em> because we didn&#39;t provide the script with any arguments, whether the names of keys or not.</p>\n<h2>Script parameterization</h2>\n<p>It is possible, although highly ill-advised, to have the application dynamically generate script source code per its needs.<br>For example, the application could send these two entirely different, but at the same time perfectly identical scripts:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &quot;return &#39;Hello&#39;&quot; 0\n&quot;Hello&quot;\n127.0.0.1:6379&gt; EVAL &quot;return &#39;Scripting!&#39;&quot; 0\n&quot;Scripting!&quot;\n</code></pre>\n<p>Although this mode of operation isn&#39;t blocked by Valkey, it is an anti-pattern due to script cache considerations (more on the topic below).<br>Instead of having your application generate subtle variations of the same scripts, you can parametrize them and pass any arguments needed for to execute them.</p>\n<p>The following example demonstrates how to achieve the same effects as above, but via parameterization:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &quot;return ARGV[1]&quot; 0 Hello\n&quot;Hello&quot;\n127.0.0.1:6379&gt; EVAL &quot;return ARGV[1]&quot; 0 Parameterization!\n&quot;Parameterization!&quot;\n</code></pre>\n<p>At this point, it is essential to understand the distinction Valkey makes between input arguments that are names of keys and those that aren&#39;t.</p>\n<p>While key names in Valkey are just strings, unlike any other string values, these represent keys in the database.<br>The name of a key is a fundamental concept in Valkey and is the basis for operating the Valkey Cluster.</p>\n<p><strong>Important:</strong><br>to ensure the correct execution of scripts, both in standalone and clustered deployments, all names of keys that a script accesses must be explicitly provided as input key arguments.<br>The script <strong>should only</strong> access keys whose names are given as input arguments.<br>Scripts <strong>should never</strong> access keys with programmatically-generated names or based on the contents of data structures stored in the database.</p>\n<p>Any input to the function that isn&#39;t the name of a key is a regular input argument.</p>\n<p>In the example above, both <em>Hello</em> and <em>Parameterization!</em> regular input arguments for the script.<br>Because the script doesn&#39;t touch any keys, we use the numerical argument <em>0</em> to specify there are no key name arguments.<br>The execution context makes arguments available to the script through <a href=\"lua-api#the-keys-global-variable\"><em>KEYS</em></a> and <a href=\"lua-api#the-argv-global-variable\"><em>ARGV</em></a> global runtime variables.<br>The <em>KEYS</em> table is pre-populated with all key name arguments provided to the script before its execution, whereas the <em>ARGV</em> table serves a similar purpose but for regular arguments.</p>\n<p>The following attempts to demonstrate the distribution of input arguments between the scripts <em>KEYS</em> and <em>ARGV</em> runtime global variables:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &quot;return { KEYS[1], KEYS[2], ARGV[1], ARGV[2], ARGV[3] }&quot; 2 key1 key2 arg1 arg2 arg3\n1) &quot;key1&quot;\n2) &quot;key2&quot;\n3) &quot;arg1&quot;\n4) &quot;arg2&quot;\n5) &quot;arg3&quot;\n</code></pre>\n<p><strong>Note:</strong><br>as can been seen above, Lua&#39;s table arrays are returned as <a href=\"protocol#arrays\">RESP2 array replies</a>, so it is likely that your client&#39;s library will convert it to the native array data type in your programming language.<br>Please refer to the rules that govern <a href=\"lua-api#data-type-conversion\">data type conversion</a> for more pertinent information.</p>\n<h2>Interacting with Valkey from a script</h2>\n<p>It is possible to call Valkey commands from a Lua script either via <a href=\"lua-api#server.call\"><code>server.call()</code></a> or <a href=\"lua-api#server.pcall\"><code>server.pcall()</code></a>.</p>\n<p>The two are nearly identical.<br>Both execute a Valkey command along with its provided arguments, if these represent a well-formed command.<br>However, the difference between the two functions lies in the manner in which runtime errors (such as syntax errors, for example) are handled.<br>Errors raised from calling <code>server.call()</code> function are returned directly to the client that had executed it.<br>Conversely, errors encountered when calling the <code>server.pcall()</code> function are returned to the script&#39;s execution context instead for possible handling.</p>\n<p>For example, consider the following:</p>\n<pre><code>&gt; EVAL &quot;return server.call(&#39;SET&#39;, KEYS[1], ARGV[1])&quot; 1 foo bar\nOK\n</code></pre>\n<p>The above script accepts one key name and one value as its input arguments.<br>When executed, the script calls the <code>SET</code> command to set the input key, <em>foo</em>, with the string value &quot;bar&quot;.</p>\n<h2>Script cache</h2>\n<p>Until this point, we&#39;ve used the <code>EVAL</code> command to run our script.</p>\n<p>Whenever we call <code>EVAL</code>, we also include the script&#39;s source code with the request.<br>Repeatedly calling <code>EVAL</code> to execute the same set of parameterized scripts, wastes both network bandwidth and also has some overheads in Valkey.<br>Naturally, saving on network and compute resources is key, so, instead, Valkey provides a caching mechanism for scripts.</p>\n<p>Every script you execute with <code>EVAL</code> is stored in a dedicated cache that the server keeps.<br>The cache&#39;s contents are organized by the scripts&#39; SHA1 digest sums, so the SHA1 digest sum of a script uniquely identifies it in the cache.<br>You can verify this behavior by running <code>EVAL</code> and calling <code>INFO</code> afterward.<br>You&#39;ll notice that the <em>used_memory_scripts_eval</em> and <em>number_of_cached_scripts</em> metrics grow with every new script that&#39;s executed.</p>\n<p>As mentioned above, dynamically-generated scripts are an anti-pattern.<br>Generating scripts during the application&#39;s runtime may, and probably will, exhaust the host&#39;s memory resources for caching them.<br>Instead, scripts should be as generic as possible and provide customized execution via their arguments.</p>\n<p>A script is loaded to the server&#39;s cache by calling the <code>SCRIPT LOAD</code> command and providing its source code.<br>The server doesn&#39;t execute the script, but instead just compiles and loads it to the server&#39;s cache.<br>Once loaded, you can execute the cached script with the SHA1 digest returned from the server.</p>\n<p>Here&#39;s an example of loading and then executing a cached script:</p>\n<pre><code>127.0.0.1:6379&gt; SCRIPT LOAD &quot;return &#39;Immabe a cached script&#39;&quot;\n&quot;c664a3bf70bd1d45c4284ffebb65a6f2299bfc9f&quot;\n127.0.0.1:6379&gt; EVALSHA c664a3bf70bd1d45c4284ffebb65a6f2299bfc9f 0\n&quot;Immabe a cached script&quot;\n</code></pre>\n<h3>Cache volatility</h3>\n<p>The Valkey script cache is <strong>always volatile</strong>.<br>It isn&#39;t considered as a part of the database and is <strong>not persisted</strong>.<br>The cache may be cleared when the server restarts, during fail-over when a replica assumes the primary role, or explicitly by <code>SCRIPT FLUSH</code>.<br>That means that cached scripts are ephemeral, and the cache&#39;s contents can be lost at any time.</p>\n<p>Applications that use scripts should always call <code>EVALSHA</code> to execute them.<br>The server returns an error if the script&#39;s SHA1 digest is not in the cache.<br>For example:</p>\n<pre><code>127.0.0.1:6379&gt; EVALSHA ffffffffffffffffffffffffffffffffffffffff 0\n(error) NOSCRIPT No matching script\n</code></pre>\n<p>In this case, the application should first load it with <code>SCRIPT LOAD</code> and then call <code>EVALSHA</code> once more to run the cached script by its SHA1 sum.<br>Most of <a href=\"../clients/\">Valkey&#39; clients</a> already provide utility APIs for doing that automatically.<br>Please consult your client&#39;s documentation regarding the specific details.</p>\n<h3><code>EVALSHA</code> in the context of pipelining</h3>\n<p>Special care should be given executing <code>EVALSHA</code> in the context of a <a href=\"pipelining\">pipelined request</a>.<br>The commands in a pipelined request run in the order they are sent, but other clients&#39; commands may be interleaved for execution between these.<br>Because of that, the <code>NOSCRIPT</code> error can return from a pipelined request but can&#39;t be handled.</p>\n<p>Therefore, a client library&#39;s implementation should revert to using plain <code>EVAL</code> of parameterized in the context of a pipeline.</p>\n<h3>Script cache semantics</h3>\n<p>During normal operation, an application&#39;s scripts are meant to stay indefinitely in the cache (that is, until the server is restarted or the cache being flushed).<br>The underlying reasoning is that the script cache contents of a well-written application are unlikely to grow continuously.<br>Even large applications that use hundreds of cached scripts shouldn&#39;t be an issue in terms of cache memory usage.</p>\n<p>The only way to flush the script cache is by explicitly calling the <code>SCRIPT FLUSH</code> command.<br>Running the command will <em>completely flush</em> the scripts cache, removing all the scripts executed so far.<br>Typically, this is only needed when the instance is going to be instantiated for another customer or application in a cloud environment.</p>\n<p>Also, as already mentioned, restarting a Valkey instance flushes the non-persistent script cache.<br>However, from the point of view of the Valkey client, there are only two ways to make sure that a Valkey instance was not restarted between two different commands:</p>\n<ul>\n<li>The connection we have with the server is persistent and was never closed so far.</li>\n<li>The client explicitly checks the <code>run_id</code> field in the <code>INFO</code> command to ensure the server was not restarted and is still the same process.</li>\n</ul>\n<p>Practically speaking, it is much simpler for the client to assume that in the context of a given connection, cached scripts are guaranteed to be there unless the administrator explicitly invoked the <code>SCRIPT FLUSH</code> command.<br>The fact that the user can count on Valkey to retain cached scripts is semantically helpful in the context of pipelining.</p>\n<h2>The <code>SCRIPT</code> command</h2>\n<p>The Valkey <code>SCRIPT</code> provides several ways for controlling the scripting subsystem.<br>These are:</p>\n<ul>\n<li><p><code>SCRIPT FLUSH</code>: this command is the only way to force Valkey to flush the scripts cache.<br>It is most useful in environments where the same Valkey instance is reassigned to different uses.<br>It is also helpful for testing client libraries&#39; implementations of the scripting feature.</p>\n</li>\n<li><p><code>SCRIPT EXISTS</code>: given one or more SHA1 digests as arguments, this command returns an array of <em>1</em>&#39;s and <em>0</em>&#39;s.<br><em>1</em> means the specific SHA1 is recognized as a script already present in the scripting cache. <em>0</em>&#39;s meaning is that a script with this SHA1 wasn&#39;t loaded before (or at least never since the latest call to <code>SCRIPT FLUSH</code>).</p>\n</li>\n<li><p><code>SCRIPT LOAD script</code>: this command registers the specified script in the Valkey script cache.<br>It is a useful command in all the contexts where we want to ensure that <code>EVALSHA</code> doesn&#39;t not fail (for instance, in a pipeline or when called from a <a href=\"transactions\"><code>MULTI</code>/<code>EXEC</code> transaction</a>), without the need to execute the script.</p>\n</li>\n<li><p><code>SCRIPT SHOW</code>: this command shows the original source code for a script that is stored in the script cache.<br>It is useful to help users easily obtain scripts using signature.</p>\n</li>\n<li><p><code>SCRIPT KILL</code>: this command is the only way to interrupt a long-running script (a.k.a slow script), short of shutting down the server.<br>A script is deemed as slow once its execution&#39;s duration exceeds the configured <a href=\"programmability#maximum-execution-time\">maximum execution time</a> threshold.<br>The <code>SCRIPT KILL</code> command can be used only with scripts that did not modify the dataset during their execution (since stopping a read-only script does not violate the scripting engine&#39;s guaranteed atomicity).</p>\n</li>\n<li><p><code>SCRIPT DEBUG</code>: controls use of the built-in <a href=\"ldb\">Valkey Lua scripts debugger</a>.</p>\n</li>\n</ul>\n<h2>Script replication</h2>\n<p>In a primary-replica setup (see <a href=\"replication\">replication</a>), write commands performed by a script on the primary are also sent to replicas to maintain consistency.<br>When the script execution finishes, the sequence of commands that the script generated are wrapped into a <a href=\"transactions\"><code>MULTI</code>/<code>EXEC</code> transaction</a> and are sent to the replicas and written to the AOF file, if an AOF file is used. (See <a href=\"persistence\">Persistence</a>.)<br>This is called <em>effects replication</em>.</p>\n<p>In the past, it was also possible to use <em>verbatim replication</em> which means that a script was replicated as a whole, but this was removed in 7.0.</p>\n<p>The <a href=\"lua-api#server.replicate_commands\"><code>server.replicate_commands()</code></a> function is deprecated and has no effect, but it exists to avoid breaking existing scripts.</p>\n<h2>Debugging Eval scripts</h2>\n<p>Valkey has a built-in Lua debugger.<br>The Valkey Lua debugger is a remote debugger consisting of a server, which is Valkey itself, and a client, which is by default <a href=\"cli\"><code>valkey-cli</code></a>.</p>\n<p>The Lua debugger is described in the <a href=\"ldb\">Lua scripts debugging</a> section of the Valkey documentation.</p>\n<h2>Execution under low memory conditions</h2>\n<p>When memory usage in Valkey exceeds the <code>maxmemory</code> limit, the first write command encountered in the script that uses additional memory will cause the script to abort (unless <a href=\"lua-api#server.pcall\"><code>server.pcall</code></a> was used).</p>\n<p>However, an exception to the above is when the script&#39;s first write command does not use additional memory, as is the case with  (for example, <code>DEL</code> and <code>LREM</code>).<br>In this case, Valkey will allow all commands in the script to run to ensure atomicity.<br>If subsequent writes in the script consume additional memory, Valkey&#39; memory usage can exceed the threshold set by the <code>maxmemory</code> configuration directive.</p>\n<p>Another scenario in which a script can cause memory usage to cross the <code>maxmemory</code> threshold is when the execution begins when Valkey is slightly below <code>maxmemory</code>, so the script&#39;s first write command is allowed.<br>As the script executes, subsequent write commands consume more memory leading to the server using more RAM than the configured <code>maxmemory</code> directive.</p>\n<p>In those scenarios, you should consider setting the <code>maxmemory-policy</code> configuration directive to any values other than <code>noeviction</code>.<br>In addition, Lua scripts should be as fast as possible so that eviction can kick in between executions.</p>\n<p>Note that you can change this behaviour by using <a href=\"#eval-flags\">flags</a></p>\n<h2>Eval flags</h2>\n<p>Normally, when you run an Eval script, the server does not know how it accesses the database.<br>By default, Valkey assumes that all scripts read and write data.<br>However, starting with Redis OSS 7.0, there&#39;s a way to declare flags when creating a script in order to tell Valkey how it should behave.</p>\n<p>The way to do that is by using a Shebang statement on the first line of the script like so:</p>\n<pre><code>#!lua flags=no-writes,allow-stale\nlocal x = server.call(&#39;get&#39;,&#39;x&#39;)\nreturn x\n</code></pre>\n<p>Note that as soon as Valkey sees the <code>#!</code> comment, it&#39;ll treat the script as if it declares flags, even if no flags are defined,<br>it still has a different set of defaults compared to a script without a <code>#!</code> line.</p>\n<p>Another difference is that scripts without <code>#!</code> can run commands that access keys belonging to different cluster hash slots, but ones with <code>#!</code> inherit the default flags, so they cannot.</p>\n<p>Please refer to <a href=\"lua-api#script_flags\">Script flags</a> to learn about the various scripts and the defaults.</p>\n"
      },
      {
        "id": "functions-intro",
        "topicName": "Functions",
        "description": "Scripting with functions stored on the server\n",
        "htmlContent": "<p>Valkey Functions is an API for managing code to be executed on the server.<br>This feature is as a complement to <a href=\"eval-intro\">EVAL scripts</a>.</p>\n<h2>What&#39;s wrong with EVAL?</h2>\n<p>There&#39;s nothing wrong with <code>EVAL</code>, but there are some differences between EVAL scripts and Functions.<br>With the <a href=\"../commands/eval\"><code>EVAL</code></a> command, scripts are sent to the server for immediate execution.<br>The core use cases for <code>EVAL</code> scripts is executing part of your application logic inside Valkey, efficiently and atomically.<br>Such script can perform conditional updates across multiple keys, possibly combining several different data types.</p>\n<p>Using <code>EVAL</code> requires that the application sends the entire script for execution every time.<br>Because this results in network and script compilation overheads, Valkey provides an optimization in the form of the <a href=\"../commands/evalsha\"><code>EVALSHA</code></a> command.<br>By first calling <a href=\"../commands/script-load\"><code>SCRIPT LOAD</code></a> to obtain the script&#39;s SHA1, the application can invoke it repeatedly afterward with its digest alone.</p>\n<p>Valkey only caches the loaded scripts.<br>That means that the script cache can become lost at any time, such as after calling <code>SCRIPT FLUSH</code>, after restarting the server, or when failing over to a replica.<br>The application is responsible for reloading scripts during runtime if any are missing.<br>The underlying assumption is that scripts are a part of the application and not maintained by the Valkey server.</p>\n<p>This approach suits many light-weight scripting use cases, but introduces several difficulties once an application becomes complex and relies more heavily on scripting, namely:</p>\n<ol>\n<li>All client application instances must maintain a copy of all scripts. That means having some mechanism that applies script updates to all of the application&#39;s instances.</li>\n<li>Calling cached scripts within the context of a <a href=\"transactions\">transaction</a> increases the probability of the transaction failing because of a missing script. Being more likely to fail makes using cached scripts as building blocks of workflows less attractive.</li>\n<li>SHA1 digests are not readable for humans, making debugging the system hard (e.g. in a <a href=\"../commands/monitor\"><code>MONITOR</code></a> session).</li>\n<li>When used naively, <code>EVAL</code> promotes an anti-pattern in which the client application renders verbatim scripts instead of responsibly using the <a href=\"lua-api#runtime-globals\"><code>KEYS</code> and <code>ARGV</code> Lua APIs</a>.</li>\n<li>Because they are ephemeral, a script can&#39;t call another script. This makes sharing and reusing code between scripts nearly impossible, short of client-side preprocessing.</li>\n</ol>\n<p>To address these needs while avoiding breaking changes to already-established and well-liked ephemeral scripts, functions were introduced in version 7.0.</p>\n<h2>What are Valkey Functions?</h2>\n<p>Functions provide the same core functionality as scripts but are first-class artifacts of the database.<br>Valkey manages functions as an integral part of the database and ensures their availability via data persistence and replication.<br>Because functions are part of the database and therefore declared before use, applications aren&#39;t required to load them during runtime nor risk aborted transactions.<br>An application that uses functions depends only on their APIs rather than on the embedded script logic in the database.</p>\n<p>Whereas ephemeral scripts are considered a part of the application&#39;s domain, functions extend the database server itself with user-provided logic.<br>They can be loaded at startup and be used repeatedly by various applications and clients.<br>Functions are also persisted to the AOF file and replicated from primary to replicas, so they are as durable as the data itself.<br>When Valkey is used as an ephemeral cache, additional mechanisms (described below) are required to make functions more durable.</p>\n<p>Functions also simplify development by enabling code sharing.<br>Every function has a user-defined name and belongs to a library, and a library can consist of multiple functions.<br>The library&#39;s contents are immutable, and selective updates of its functions aren&#39;t allowed.<br>Instead, libraries are updated as a whole with all of their functions together in one operation.<br>This allows calling functions from other functions within the same library, or sharing code between functions by using a common code in library-internal methods, that can also take language native arguments.</p>\n<p>Like all other operations in Valkey, the execution of a function is atomic.<br>A function&#39;s execution blocks all server activities during its entire time, similarly to the semantics of <a href=\"transactions\">transactions</a>.<br>These semantics mean that all of the script&#39;s effects either have yet to happen or had already happened.<br>The blocking semantics of an executed function apply to all connected clients at all times.<br>Because running a function blocks the Valkey server, functions are meant to finish executing quickly, so you should avoid using long-running functions.</p>\n<p>Functions are written in <a href=\"lua-api\">Lua 5.1</a>.<br>Valkey functions can use all of Lua&#39;s available capabilities to ephemeral scripts,<br>with the only exception being the <a href=\"ldb\">Valkey Lua scripts debugger</a>.</p>\n<h2>Loading libraries and functions</h2>\n<p>Let&#39;s explore Valkey Functions via some tangible examples and Lua snippets.</p>\n<p>At this point, if you&#39;re unfamiliar with Lua in general and specifically in Valkey, you may benefit from reviewing some of the examples in <a href=\"eval-intro\">Introduction to Eval Scripts</a> and <a href=\"lua-api\">Lua API</a> pages for a better grasp of the language.</p>\n<p>Every Valkey function belongs to a library.<br>Loading a library to the database is done with the <a href=\"../commands/function-load\"><code>FUNCTION LOAD</code></a> command.<br>The library source code must start with a Shebang line that provides metadata about the library, like the language (always &quot;lua&quot;) and the library name.<br>The Shebang format is:</p>\n<pre><code>#!lua name=&lt;library name&gt;\n</code></pre>\n<p>Let&#39;s try loading an empty library:</p>\n<pre><code>127.0.0.1:6379&gt; FUNCTION LOAD &quot;#!lua name=mylib\\n&quot;\n(error) ERR No functions registered\n</code></pre>\n<p>The error is expected, as there are no functions in the loaded library. Every library needs to include at least one registered function to load successfully.<br>A registered function is named and acts as an entry point to the library.<br>When the target execution engine handles the <code>FUNCTION LOAD</code> command, it registers the library&#39;s functions.</p>\n<p>The Lua engine compiles and evaluates the library source code when loaded, and expects functions to be registered by calling the <code>server.register_function()</code> API.</p>\n<p>The following snippet demonstrates a simple library registering a single function named <em>knockknock</em>, returning a string reply:</p>\n<pre><code class=\"language-lua\">#!lua name=mylib\nserver.register_function(\n  &#39;knockknock&#39;,\n  function() return &#39;Who\\&#39;s there?&#39; end\n)\n</code></pre>\n<p>In the example above, we provide two arguments about the function to Lua&#39;s <code>server.register_function()</code> API: its registered name and a callback.</p>\n<p>We can load our library and use <code>FCALL</code> to call the registered function:</p>\n<pre><code>127.0.0.1:6379&gt; FUNCTION LOAD &quot;#!lua name=mylib\\nserver.register_function(&#39;knockknock&#39;, function() return &#39;Who\\\\&#39;s there?&#39; end)&quot;\nmylib\n127.0.0.1:6379&gt; FCALL knockknock 0\n&quot;Who&#39;s there?&quot;\n</code></pre>\n<p>Notice that the <code>FUNCTION LOAD</code> command returns the name of the loaded library, this name can later be used <code>FUNCTION LIST</code> and <code>FUNCTION DELETE</code>.</p>\n<p>We&#39;ve provided <a href=\"../commands/fcall\"><code>FCALL</code></a> with two arguments: the function&#39;s registered name and the numeric value <code>0</code>. This numeric value indicates the number of key names that follow it (the same way <code>EVAL</code> and <code>EVALSHA</code> works).</p>\n<p>We&#39;ll explain immediately how key names and additional arguments are available to the function. As this simple example doesn&#39;t involve keys, we simply use 0 for now.</p>\n<h2>Input keys and regular arguments</h2>\n<p>Before we move to the following example, it is vital to understand the distinction Valkey makes between arguments that are names of keys and those that aren&#39;t.</p>\n<p>While key names in Valkey are just strings, unlike any other string values, these represent keys in the database.<br>The name of a key is a fundamental concept in Valkey and is the basis for operating the Valkey Cluster.</p>\n<p><strong>Important:</strong><br>To ensure the correct execution of Valkey Functions, both in standalone and clustered deployments, all names of keys that a function accesses must be explicitly provided as input key arguments.</p>\n<p>Any input to the function that isn&#39;t the name of a key is a regular input argument.</p>\n<p>Now, let&#39;s pretend that our application stores some of its data in Hashes.<br>We want an <a href=\"../commands/hset\"><code>HSET</code></a>-like way to set and update fields in said Hashes and store the last modification time in a new field named <code>_last_modified_</code>.<br>We can implement a function to do all that.</p>\n<p>Our function will call <a href=\"../commands/time\"><code>TIME</code></a> to get the server&#39;s clock reading and update the target Hash with the new fields&#39; values and the modification&#39;s timestamp.<br>The function we&#39;ll implement accepts the following input arguments: the Hash&#39;s key name and the field-value pairs to update.</p>\n<p>The Lua API for Valkey Functions makes these inputs accessible as the first and second arguments to the function&#39;s callback.<br>The callback&#39;s first argument is a Lua table populated with all key names inputs to the function.<br>Similarly, the callback&#39;s second argument consists of all regular arguments.</p>\n<p>The following is a possible implementation for our function and its library registration:</p>\n<pre><code class=\"language-lua\">#!lua name=mylib\n\nlocal function my_hset(keys, args)\n  local hash = keys[1]\n  local time = server.call(&#39;TIME&#39;)[1]\n  return server.call(&#39;HSET&#39;, hash, &#39;_last_modified_&#39;, time, unpack(args))\nend\n\nserver.register_function(&#39;my_hset&#39;, my_hset)\n</code></pre>\n<p>If we create a new file named <em>mylib.lua</em> that consists of the library&#39;s definition, we can load it like so (without stripping the source code of helpful whitespaces):</p>\n<pre><code class=\"language-bash\">$ cat mylib.lua | valkey-cli -x FUNCTION LOAD REPLACE\n</code></pre>\n<p>We&#39;ve added the <code>REPLACE</code> modifier to the call to <code>FUNCTION LOAD</code> to tell Valkey that we want to overwrite the existing library definition.<br>Otherwise, we would have gotten an error from Valkey complaining that the library already exists.</p>\n<p>Now that the library&#39;s updated code is loaded to Valkey, we can proceed and call our function:</p>\n<pre><code>127.0.0.1:6379&gt; FCALL my_hset 1 myhash myfield &quot;some value&quot; another_field &quot;another value&quot;\n(integer) 3\n127.0.0.1:6379&gt; HGETALL myhash\n1) &quot;_last_modified_&quot;\n2) &quot;1640772721&quot;\n3) &quot;myfield&quot;\n4) &quot;some value&quot;\n5) &quot;another_field&quot;\n6) &quot;another value&quot;\n</code></pre>\n<p>In this case, we had invoked <code>FCALL</code> with <em>1</em> as the number of key name arguments.<br>That means that the function&#39;s first input argument is a name of a key (and is therefore included in the callback&#39;s <code>keys</code> table).<br>After that first argument, all following input arguments are considered regular arguments and constitute the <code>args</code> table passed to the callback as its second argument.</p>\n<h2>Expanding the library</h2>\n<p>We can add more functions to our library to benefit our application.<br>The additional metadata field we&#39;ve added to the Hash shouldn&#39;t be included in responses when accessing the Hash&#39;s data.<br>On the other hand, we do want to provide the means to obtain the modification timestamp for a given Hash key.</p>\n<p>We&#39;ll add two new functions to our library to accomplish these objectives:</p>\n<ol>\n<li>The <code>my_hgetall</code> Valkey Function will return all fields and their respective values from a given Hash key name, excluding the metadata (i.e., the <code>_last_modified_</code> field).</li>\n<li>The <code>my_hlastmodified</code> Valkey Function will return the modification timestamp for a given Hash key name.</li>\n</ol>\n<p>The library&#39;s source code could look something like the following:</p>\n<pre><code class=\"language-lua\">#!lua name=mylib\n\nlocal function my_hset(keys, args)\n  local hash = keys[1]\n  local time = server.call(&#39;TIME&#39;)[1]\n  return server.call(&#39;HSET&#39;, hash, &#39;_last_modified_&#39;, time, unpack(args))\nend\n\nlocal function my_hgetall(keys, args)\n  server.setresp(3)\n  local hash = keys[1]\n  local res = server.call(&#39;HGETALL&#39;, hash)\n  res[&#39;map&#39;][&#39;_last_modified_&#39;] = nil\n  return res\nend\n\nlocal function my_hlastmodified(keys, args)\n  local hash = keys[1]\n  return server.call(&#39;HGET&#39;, hash, &#39;_last_modified_&#39;)\nend\n\nserver.register_function(&#39;my_hset&#39;, my_hset)\nserver.register_function(&#39;my_hgetall&#39;, my_hgetall)\nserver.register_function(&#39;my_hlastmodified&#39;, my_hlastmodified)\n</code></pre>\n<p>While all of the above should be straightforward, note that the <code>my_hgetall</code> also calls <a href=\"lua-api#server.setresp\"><code>server.setresp(3)</code></a>.<br>That means that the function expects <a href=\"protocol\">RESP3</a> replies after calling <code>server.call()</code>, which, unlike the default RESP2 protocol, returns the replies as maps (associative arrays).<br>Doing so allows the function to delete (or set to <code>nil</code> as is the case with Lua tables) specific fields from the reply, and in our case, the <code>_last_modified_</code> field.</p>\n<p>Assuming you&#39;ve saved the library&#39;s implementation in the <em>mylib.lua</em> file, you can replace it with:</p>\n<pre><code class=\"language-bash\">$ cat mylib.lua | valkey-cli -x FUNCTION LOAD REPLACE\n</code></pre>\n<p>Once loaded, you can call the library&#39;s functions with <code>FCALL</code>:</p>\n<pre><code>127.0.0.1:6379&gt; FCALL my_hgetall 1 myhash\n1) &quot;myfield&quot;\n2) &quot;some value&quot;\n3) &quot;another_field&quot;\n4) &quot;another value&quot;\n127.0.0.1:6379&gt; FCALL my_hlastmodified 1 myhash\n&quot;1640772721&quot;\n</code></pre>\n<p>You can also get the library&#39;s details with the <code>FUNCTION LIST</code> command:</p>\n<pre><code>127.0.0.1:6379&gt; FUNCTION LIST\n1) 1) &quot;library_name&quot;\n   2) &quot;mylib&quot;\n   3) &quot;engine&quot;\n   4) &quot;LUA&quot;\n   5) &quot;functions&quot;\n   6) 1) 1) &quot;name&quot;\n         2) &quot;my_hset&quot;\n         3) &quot;description&quot;\n         4) (nil)\n         5) &quot;flags&quot;\n         6) (empty array)\n      2) 1) &quot;name&quot;\n         2) &quot;my_hgetall&quot;\n         3) &quot;description&quot;\n         4) (nil)\n         5) &quot;flags&quot;\n         6) (empty array)\n      3) 1) &quot;name&quot;\n         2) &quot;my_hlastmodified&quot;\n         3) &quot;description&quot;\n         4) (nil)\n         5) &quot;flags&quot;\n         6) (empty array)\n</code></pre>\n<p>You can see that it is easy to update our library with new capabilities.</p>\n<h2>Reusing code in the library</h2>\n<p>On top of bundling functions together into database-managed software artifacts, libraries also facilitate code sharing.<br>We can add to our library an error handling helper function called from other functions.<br>The helper function <code>check_keys()</code> verifies that the input <em>keys</em> table has a single key.<br>Upon success it returns <code>nil</code>, otherwise it returns an <a href=\"lua-api#server.error_reply\">error reply</a>.</p>\n<p>The updated library&#39;s source code would be:</p>\n<pre><code class=\"language-lua\">#!lua name=mylib\n\nlocal function check_keys(keys)\n  local error = nil\n  local nkeys = table.getn(keys)\n  if nkeys == 0 then\n    error = &#39;Hash key name not provided&#39;\n  elseif nkeys &gt; 1 then\n    error = &#39;Only one key name is allowed&#39;\n  end\n\n  if error ~= nil then\n    server.log(server.LOG_WARNING, error);\n    return server.error_reply(error)\n  end\n  return nil\nend\n\nlocal function my_hset(keys, args)\n  local error = check_keys(keys)\n  if error ~= nil then\n    return error\n  end\n\n  local hash = keys[1]\n  local time = server.call(&#39;TIME&#39;)[1]\n  return server.call(&#39;HSET&#39;, hash, &#39;_last_modified_&#39;, time, unpack(args))\nend\n\nlocal function my_hgetall(keys, args)\n  local error = check_keys(keys)\n  if error ~= nil then\n    return error\n  end\n\n  server.setresp(3)\n  local hash = keys[1]\n  local res = server.call(&#39;HGETALL&#39;, hash)\n  res[&#39;map&#39;][&#39;_last_modified_&#39;] = nil\n  return res\nend\n\nlocal function my_hlastmodified(keys, args)\n  local error = check_keys(keys)\n  if error ~= nil then\n    return error\n  end\n\n  local hash = keys[1]\n  return server.call(&#39;HGET&#39;, keys[1], &#39;_last_modified_&#39;)\nend\n\nserver.register_function(&#39;my_hset&#39;, my_hset)\nserver.register_function(&#39;my_hgetall&#39;, my_hgetall)\nserver.register_function(&#39;my_hlastmodified&#39;, my_hlastmodified)\n</code></pre>\n<p>After you&#39;ve replaced the library in Valkey with the above, you can immediately try out the new error handling mechanism:</p>\n<pre><code>127.0.0.1:6379&gt; FCALL my_hset 0 myhash nope nope\n(error) Hash key name not provided\n127.0.0.1:6379&gt; FCALL my_hgetall 2 myhash anotherone\n(error) Only one key name is allowed\n</code></pre>\n<p>And your Valkey log file should have lines in it that are similar to:</p>\n<pre><code>...\n20075:M 1 Jan 2022 16:53:57.688 # Hash key name not provided\n20075:M 1 Jan 2022 16:54:01.309 # Only one key name is allowed\n</code></pre>\n<h2>Functions in cluster</h2>\n<p>As noted above, Valkey automatically handles propagation of loaded functions to replicas.<br>In a <a href=\"cluster-tutorial\">cluster</a>, it is necessary to load functions to all primaries.</p>\n<p>As one of the goals of functions is to live separately from the client application, this should not be part of the Valkey client library responsibilities. Instead, <code>valkey-cli --cluster-only-primaries --cluster call host:port FUNCTION LOAD ...</code> can be used to execute the load command on all primary nodes.</p>\n<p>Also, note that <code>valkey-cli --cluster add-node</code> automatically takes care to propagate the loaded functions from one of the existing nodes to the new node.</p>\n<h2>Functions and ephemeral Valkey instances</h2>\n<p>In some cases there may be a need to start a fresh Valkey server with a set of functions pre-loaded. Common reasons for that could be:</p>\n<ul>\n<li>Starting Valkey in a new environment</li>\n<li>Re-starting an ephemeral (cache-only) Valkey, that uses functions</li>\n</ul>\n<p>In such cases, we need to make sure that the pre-loaded functions are available before Valkey accepts inbound user connections and commands.</p>\n<p>To do that, it is possible to use <code>valkey-cli --functions-rdb</code> to extract the functions from an existing server. This generates an RDB file that can be loaded by Valkey at startup.</p>\n<h2>Function flags</h2>\n<p>Valkey needs to have some information about how a function is going to behave when executed, in order to properly enforce resource usage policies and maintain data consistency.</p>\n<p>For example, Valkey needs to know that a certain function is read-only before permitting it to execute using <code>FCALL_RO</code> on a read-only replica.</p>\n<p>By default, Valkey assumes that all functions may perform arbitrary read or write operations. Function Flags make it possible to declare more specific function behavior at the time of registration. Let&#39;s see how this works.</p>\n<p>In our previous example, we defined two functions that only read data. We can try executing them using <code>FCALL_RO</code> against a read-only replica.</p>\n<pre><code>127.0.0.1:6379&gt; FCALL_RO my_hgetall 1 myhash\n(error) ERR Can not execute a function with write flag using fcall_ro.\n</code></pre>\n<p>Valkey returns this error because a function can, in theory, perform both read and write operations on the database.<br>As a safeguard and by default, Valkey assumes that the function does both, so it blocks its execution.<br>The server will reply with this error in the following cases:</p>\n<ol>\n<li>Executing a function with <code>FCALL</code> against a read-only replica.</li>\n<li>Using <code>FCALL_RO</code> to execute a function.</li>\n<li>A disk error was detected (Valkey is unable to persist so it rejects writes).</li>\n</ol>\n<p>In these cases, you can add the <code>no-writes</code> flag to the function&#39;s registration, disable the safeguard and allow them to run.<br>To register a function with flags use the <a href=\"lua-api#server.register_function_named_args\">named arguments</a> variant of <code>server.register_function</code>.</p>\n<p>The updated registration code snippet from the library looks like this:</p>\n<pre><code class=\"language-lua\">server.register_function(&#39;my_hset&#39;, my_hset)\nserver.register_function{\n  function_name=&#39;my_hgetall&#39;,\n  callback=my_hgetall,\n  flags={ &#39;no-writes&#39; }\n}\nserver.register_function{\n  function_name=&#39;my_hlastmodified&#39;,\n  callback=my_hlastmodified,\n  flags={ &#39;no-writes&#39; }\n}\n</code></pre>\n<p>Once we&#39;ve replaced the library, Valkey allows running both <code>my_hgetall</code> and <code>my_hlastmodified</code> with <code>FCALL_RO</code> against a read-only replica:</p>\n<pre><code>127.0.0.1:6379&gt; FCALL_RO my_hgetall 1 myhash\n1) &quot;myfield&quot;\n2) &quot;some value&quot;\n3) &quot;another_field&quot;\n4) &quot;another value&quot;\n127.0.0.1:6379&gt; FCALL_RO my_hlastmodified 1 myhash\n&quot;1640772721&quot;\n</code></pre>\n<p>For the complete documentation flags, please refer to <a href=\"lua-api#script_flags\">Script flags</a>.</p>\n"
      },
      {
        "id": "lua-api",
        "topicName": "Lua API reference",
        "description": "Executing Lua in Valkey\n",
        "htmlContent": "<p>Valkey includes an embedded <a href=\"https://www.lua.org/\">Lua 5.1</a> interpreter.<br>The interpreter runs user-defined <a href=\"eval-intro\">ephemeral scripts</a> and <a href=\"functions-intro\">functions</a>. Scripts run in a sandboxed context and can only access specific Lua packages. This page describes the packages and APIs available inside the execution&#39;s context.</p>\n<h2>Sandbox context</h2>\n<p>The sandboxed Lua context attempts to prevent accidental misuse and reduce potential threats from the server&#39;s environment.</p>\n<p>Scripts should never try to access the Valkey server&#39;s underlying host systems.<br>That includes the file system, network, and any other attempt to perform a system call other than those supported by the API.</p>\n<p>Scripts should operate solely on data stored in Valkey and data provided as arguments to their execution.</p>\n<h3>Global variables and functions</h3>\n<p>The sandboxed Lua execution context blocks the declaration of global variables and functions.<br>The blocking of global variables is in place to ensure that scripts and functions don&#39;t attempt to maintain any runtime context other than the data stored in Valkey.<br>In the (somewhat uncommon) use case that a context needs to be maintain between executions,<br>you should store the context in Valkey&#39; keyspace.</p>\n<p>Valkey will return an error when trying to execute the following snippet:</p>\n<pre><code class=\"language-lua\">my_global_variable = &#39;some value&#39;\n</code></pre>\n<p>And similarly for the following global function declaration:</p>\n<pre><code class=\"language-lua\">function my_global_function()\n  -- Do something amazing\nend\n</code></pre>\n<p>You&#39;ll also get a similar error when your script attempts to access any global variables that are undefined in the runtime&#39;s context:</p>\n<pre><code class=\"language-lua\">-- The following will surely raise an error\nreturn an_undefined_global_variable\n</code></pre>\n<p>Instead, all variable and function definitions are required to be declared as local.<br>To do so, you&#39;ll need to prepend the <a href=\"https://www.lua.org/manual/5.1/manual.html#2.4.7\"><code>local</code></a> keyword to your declarations.<br>For example, the following snippet will be considered perfectly valid by Valkey:</p>\n<pre><code class=\"language-lua\">local my_local_variable = &#39;some value&#39;\n\nlocal function my_local_function()\n  -- Do something else, but equally amazing\nend\n</code></pre>\n<p><strong>Note:</strong><br>the sandbox attempts to prevent the use of globals.<br>Using Lua&#39;s debugging functionality or other approaches such as altering the meta table used for implementing the globals&#39; protection to circumvent the sandbox isn&#39;t hard.<br>However, it is difficult to circumvent the protection by accident.<br>If the user messes with the Lua global state, the consistency of AOF and replication can&#39;t be guaranteed.<br>In other words, just don&#39;t do it.</p>\n<h3>Imported Lua modules</h3>\n<p>Using imported Lua modules is not supported inside the sandboxed execution context.<br>The sandboxed execution context prevents the loading modules by disabling Lua&#39;s <a href=\"https://www.lua.org/pil/8.1.html\"><code>require</code> function</a>.</p>\n<p>The only libraries that Valkey ships with and that you can use in scripts are listed under the <a href=\"#runtime-libraries\">Runtime libraries</a> section.</p>\n<h2>Runtime globals</h2>\n<p>While the sandbox prevents users from declaring globals, the execution context is pre-populated with several of these.</p>\n<p>For some of them, a &quot;since version&quot; is specified.<br>The ones without &quot;since version&quot; specified are available in all maintained versions.</p>\n<h3><a name=\"the-keys-global-variable\"></a>The <code>KEYS</code> global variable</h3>\n<ul>\n<li>Available in scripts: yes</li>\n<li>Available in functions: no</li>\n</ul>\n<p><strong>Important:</strong><br>to ensure the correct execution of scripts, both in standalone and clustered deployments, all names of keys that a function accesses must be explicitly provided as input key arguments.<br>The script <strong>should only</strong> access keys whose names are given as input arguments.<br>Scripts <strong>should never</strong> access keys with programmatically-generated names or based on the contents of data structures stored in the database.</p>\n<p>The <code>KEYS</code> global variable is available only for <a href=\"eval-intro\">ephemeral scripts</a>.<br>It is pre-populated with all key name input arguments.</p>\n<h3><a name=\"the-argv-global-variable\"></a>The <code>ARGV</code> global variable</h3>\n<ul>\n<li>Available in scripts: yes</li>\n<li>Available in functions: no</li>\n</ul>\n<p>The <code>ARGV</code> global variable is available only in <a href=\"eval-intro\">ephemeral scripts</a>.<br>It is pre-populated with all regular input arguments.</p>\n<h3>The <code>server</code> singleton</h3>\n<ul>\n<li>Since version: 7.2.5</li>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>The <code>server</code> singleton is an object instance that&#39;s accessible from all scripts.<br>It provides the API to interact with Valkey from scripts.<br>Following is the API provided by the <code>server</code> object instance.</p>\n<p><strong>Note:</strong><br>For compatibility with Redis, Valkey also exposes a <code>redis</code> top-level object, that exposes the exact same set of APIs as the <code>server</code> object.<br>Valkey does not intend to drop compatibility for this <code>redis</code> API, but it is recommended to use the <code>server</code> object for newly developed scripts.</p>\n<h2><a name=\"server_object\"></a> <code>server</code> object fields (functions and variables)</h2>\n<h3><a name=\"server.call\"></a> <code>server.call(command [,arg...])</code></h3>\n<ul>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>The <code>server.call()</code> function calls a given Valkey command and returns its reply.<br>Its inputs are the command and arguments, and once called, it executes the command in Valkey and returns the reply.</p>\n<p>For example, we can call the <code>ECHO</code> command from a script and return its reply like so:</p>\n<pre><code class=\"language-lua\">return server.call(&#39;ECHO&#39;, &#39;Echo, echo... eco... o...&#39;)\n</code></pre>\n<p>If and when <code>server.call()</code> triggers a runtime exception, the raw exception is raised back to the user as an error, automatically.<br>Therefore, attempting to execute the following ephemeral script will fail and generate a runtime exception because <code>ECHO</code> accepts exactly one argument:</p>\n<pre><code class=\"language-lua\">127.0.0.1:6379&gt; EVAL &quot;return server.call(&#39;ECHO&#39;, &#39;Echo,&#39;, &#39;echo... &#39;, &#39;eco... &#39;, &#39;o...&#39;)&quot; 0\n(error) ERR Wrong number of args calling Valkey command from script script: b0345693f4b77517a711221050e76d24ae60b7f7, on @user_script:1.\n</code></pre>\n<p>Note that the call can fail due to various reasons, see <a href=\"eval-intro#execution-under-low-memory-conditions\">Execution under low memory conditions</a> and <a href=\"#script_flags\">Script flags</a></p>\n<p>To handle Valkey runtime errors use <code>server.pcall()</code> instead.</p>\n<h3><a name=\"server.pcall\"></a> <code>server.pcall(command [,arg...])</code></h3>\n<ul>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>This function enables handling runtime errors raised by the Valkey server.<br>The <code>server.pcall()</code> function  behaves exactly like <a href=\"#server.call\"><code>server.call()</code></a>, except that it:</p>\n<ul>\n<li>Always returns a reply.</li>\n<li>Never throws a runtime exception, and returns in its stead a <a href=\"#server.error_reply\"><code>server.error_reply</code></a> in case that a runtime exception is thrown by the server.</li>\n</ul>\n<p>The following demonstrates how to use <code>server.pcall()</code> to intercept and handle runtime exceptions from within the context of an ephemeral script.</p>\n<pre><code class=\"language-lua\">local reply = server.pcall(&#39;ECHO&#39;, unpack(ARGV))\nif reply[&#39;err&#39;] ~= nil then\n  -- Handle the error sometime, but for now just log it\n  server.log(server.LOG_WARNING, reply[&#39;err&#39;])\n  reply[&#39;err&#39;] = &#39;ERR Something is wrong, but no worries, everything is under control&#39;\nend\nreturn reply\n</code></pre>\n<p>Evaluating this script with more than one argument will return:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &quot;...&quot; 0 hello world\n(error) ERR Something is wrong, but no worries, everything is under control\n</code></pre>\n<h3><a name=\"server.error_reply\"></a> <code>server.error_reply(x)</code></h3>\n<ul>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>This is a helper function that returns an <a href=\"protocol#simply-errors\">error reply</a>.<br>The helper accepts a single string argument and returns a Lua table with the <code>err</code> field set to that string.</p>\n<p>The outcome of the following code is that <code>error1</code> and <code>error2</code> are identical for all intents and purposes:</p>\n<pre><code class=\"language-lua\">local text = &#39;ERR My very special error&#39;\nlocal reply1 = { err = text }\nlocal reply2 = server.error_reply(text)\n</code></pre>\n<p>Therefore, both forms are valid as means for returning an error reply from scripts:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &quot;return { err = &#39;ERR My very special table error&#39; }&quot; 0\n(error) ERR My very special table error\n127.0.0.1:6379&gt; EVAL &quot;return server.error_reply(&#39;ERR My very special reply error&#39;)&quot; 0\n(error) ERR My very special reply error\n</code></pre>\n<p>For returning Valkey status replies refer to <a href=\"#server.status_reply\"><code>server.status_reply()</code></a>.<br>Refer to the <a href=\"#data-type-conversion\">Data type conversion</a> for returning other response types.</p>\n<p><strong>Note:</strong><br>By convention, Valkey uses the first word of an error string as a unique error code for specific errors or <code>ERR</code> for general-purpose errors.<br>Scripts are advised to follow this convention, as shown in the example above, but this is not mandatory.</p>\n<h3><a name=\"server.status_reply\"></a> <code>server.status_reply(x)</code></h3>\n<ul>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>This is a helper function that returns a <a href=\"protocol#simple-strings\">simple string reply</a>.<br>&quot;OK&quot; is an example of a standard Valkey status reply.<br>The Lua API represents status replies as tables with a single field, <code>ok</code>, set with a simple status string.</p>\n<p>The outcome of the following code is that <code>status1</code> and <code>status2</code> are identical for all intents and purposes:</p>\n<pre><code class=\"language-lua\">local text = &#39;Frosty&#39;\nlocal status1 = { ok = text }\nlocal status2 = server.status_reply(text)\n</code></pre>\n<p>Therefore, both forms are valid as means for returning status replies from scripts:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &quot;return { ok = &#39;TICK&#39; }&quot; 0\nTICK\n127.0.0.1:6379&gt; EVAL &quot;return server.status_reply(&#39;TOCK&#39;)&quot; 0\nTOCK\n</code></pre>\n<p>For returning Valkey error replies refer to <a href=\"#server.error_reply\"><code>server.error_reply()</code></a>.<br>Refer to the <a href=\"#data-type-conversion\">Data type conversion</a> for returning other response types.</p>\n<h3><a name=\"server.sha1hex\"></a> <code>server.sha1hex(x)</code></h3>\n<ul>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>This function returns the SHA1 hexadecimal digest of its single string argument.</p>\n<p>You can, for example, obtain the empty string&#39;s SHA1 digest:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &quot;return server.sha1hex(&#39;&#39;)&quot; 0\n&quot;da39a3ee5e6b4b0d3255bfef95601890afd80709&quot;\n</code></pre>\n<h3><a name=\"server.log\"></a> <code>server.log(level, message)</code></h3>\n<ul>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>This function writes to the Valkey server log.</p>\n<p>It expects two input arguments: the log level and a message.<br>The message is a string to write to the log file.<br>Log level can be on of these:</p>\n<ul>\n<li><code>server.LOG_DEBUG</code></li>\n<li><code>server.LOG_VERBOSE</code></li>\n<li><code>server.LOG_NOTICE</code></li>\n<li><code>server.LOG_WARNING</code></li>\n</ul>\n<p>These levels map to the server&#39;s log levels.<br>The log only records messages equal or greater in level than the server&#39;s <code>loglevel</code> configuration directive.</p>\n<p>The following snippet:</p>\n<pre><code class=\"language-lua\">server.log(server.LOG_WARNING, &#39;Something is terribly wrong&#39;)\n</code></pre>\n<p>will produce a line similar to the following in your server&#39;s log:</p>\n<pre><code>[32343] 22 Mar 15:21:39 # Something is terribly wrong\n</code></pre>\n<h3><a name=\"server.setresp\"></a> <code>server.setresp(x)</code></h3>\n<ul>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>This function allows the executing script to switch between <a href=\"protocol\">RESP</a> protocol versions for the replies returned by <a href=\"#server.call\"><code>server.call()</code></a> and <a href=\"#server.pcall\"><code>server.pcall()</code></a>.<br>It expects a single numerical argument as the protocol&#39;s version.<br>The default protocol version is <em>2</em>, but it can be switched to version <em>3</em>.</p>\n<p>Here&#39;s an example of switching to RESP3 replies:</p>\n<pre><code class=\"language-lua\">server.setresp(3)\n</code></pre>\n<p>Please refer to the <a href=\"#data-type-conversion\">Data type conversion</a> for more information about type conversions.</p>\n<h3><a name=\"server.set_repl\"></a> <code>server.set_repl(x)</code></h3>\n<ul>\n<li>Available in scripts: yes</li>\n<li>Available in functions: no</li>\n</ul>\n<p><strong>Note:</strong><br>Prior to Redis OSS 7.0, scripts were replicated verbatim by default.<br>Since Redis OSS 7.0 (and Valkey), script effects replication is the only replication mode available.</p>\n<p>The <code>server.set_repl()</code> function instructs the server how to treat subsequent write commands in terms of replication.<br>It accepts a single input argument that only be one of the following:</p>\n<ul>\n<li><code>server.REPL_ALL</code>: replicates the effects to the AOF and replicas.</li>\n<li><code>server.REPL_AOF</code>: replicates the effects to the AOF alone.</li>\n<li><code>server.REPL_REPLICA</code>: replicates the effects to the replicas alone.</li>\n<li><code>server.REPL_SLAVE</code>: same as <code>REPL_REPLICA</code>, maintained for backward compatibility.</li>\n<li><code>server.REPL_NONE</code>: disables effect replication entirely.</li>\n</ul>\n<p>By default, the scripting engine is initialized to the <code>server.REPL_ALL</code> setting when a script begins its execution.<br>You can call the <code>server.set_repl()</code> function at any time during the script&#39;s execution to switch between the different replication modes.</p>\n<p>A simple example follows:</p>\n<pre><code class=\"language-lua\">server.replicate_commands() -- Enable effects replication in versions lower than Redis OSS v7.0\nserver.call(&#39;SET&#39;, KEYS[1], ARGV[1])\nserver.set_repl(server.REPL_NONE)\nserver.call(&#39;SET&#39;, KEYS[2], ARGV[2])\nserver.set_repl(server.REPL_ALL)\nserver.call(&#39;SET&#39;, KEYS[3], ARGV[3])\n</code></pre>\n<p>If you run this script by calling <code>EVAL &quot;...&quot; 3 A B C 1 2 3</code>, the result will be that only the keys <em>A</em> and <em>C</em> are created on the replicas and AOF.</p>\n<h3><a name=\"server.replicate_commands\"></a> <code>server.replicate_commands()</code></h3>\n<ul>\n<li>Until version: 7.0.0</li>\n<li>Available in scripts: yes</li>\n<li>Available in functions: no</li>\n</ul>\n<p>This function switches the script&#39;s replication mode from verbatim replication to effects replication.<br>You can use it to override the default verbatim script replication mode used by Redis OSS until version 7.0.</p>\n<p><strong>Note:</strong><br>Verbatim script replication is no longer supported.<br>The only script replication mode supported is script effects&#39; replication.<br>For more information, please refer to <a href=\"eval-intro#replicating-commands-instead-of-scripts\"><code>Replicating commands instead of scripts</code></a></p>\n<h3><a name=\"server.breakpoint\"></a>  <code>server.breakpoint()</code></h3>\n<ul>\n<li>Available in scripts: yes</li>\n<li>Available in functions: no</li>\n</ul>\n<p>This function triggers a breakpoint when using the <a href=\"ldb\">Valkey Lua debugger</a>.</p>\n<h3><a name=\"server.debug\"></a> <code>server.debug(x)</code></h3>\n<ul>\n<li>Available in scripts: yes</li>\n<li>Available in functions: no</li>\n</ul>\n<p>This function prints its argument in the <a href=\"ldb\">Valkey Lua debugger</a> console.</p>\n<h3><a name=\"server.acl_check_cmd\"></a> <code>server.acl_check_cmd(command [,arg...])</code></h3>\n<ul>\n<li>Since version: 7.0.0</li>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>This function is used for checking if the current user running the script has <a href=\"acl\">ACL</a> permissions to execute the given command with the given arguments.</p>\n<p>The return value is a boolean <code>true</code> in case the current user has permissions to execute the command (via a call to <a href=\"#server.call\">server.call</a> or <a href=\"#server.pcall\">server.pcall</a>) or <code>false</code> in case they don&#39;t.</p>\n<p>The function will raise an error if the passed command or its arguments are invalid.</p>\n<h3><a name=\"server.register_function\"></a> <code>server.register_function</code></h3>\n<ul>\n<li>Since version: 7.0.0</li>\n<li>Available in scripts: no</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>This function is only available from the context of the <code>FUNCTION LOAD</code> command.<br>When called, it registers a function to the loaded library.<br>The function can be called either with positional or named arguments.</p>\n<h4><a name=\"server.register_function_pos_args\"></a> positional arguments: <code>server.register_function(name, callback)</code></h4>\n<p>The first argument to <code>server.register_function</code> is a Lua string representing the function name.<br>The second argument to <code>server.register_function</code> is a Lua function.</p>\n<p>Usage example:</p>\n<pre><code>127.0.0.1:6379&gt; FUNCTION LOAD &quot;#!lua name=mylib\\n server.register_function(&#39;noop&#39;, function() end)&quot;\n</code></pre>\n<h4><a name=\"server.register_function_named_args\"></a> Named arguments:  <code>server.register_function{function_name=name, callback=callback, flags={flag1, flag2, ..}, description=description}</code></h4>\n<p>The named arguments variant accepts the following arguments:</p>\n<ul>\n<li><em>function_name</em>: the function&#39;s name.</li>\n<li><em>callback</em>: the function&#39;s callback.</li>\n<li><em>flags</em>: an array of strings, each a function flag (optional).</li>\n<li><em>description</em>: function&#39;s description (optional).</li>\n</ul>\n<p>Both <em>function_name</em> and <em>callback</em> are mandatory.</p>\n<p>Usage example:</p>\n<pre><code>127.0.0.1:6379&gt; FUNCTION LOAD &quot;#!lua name=mylib\\n server.register_function{function_name=&#39;noop&#39;, callback=function() end, flags={ &#39;no-writes&#39; }, description=&#39;Does nothing&#39;}&quot;\n</code></pre>\n<h4><a name=\"script_flags\"></a> Script flags</h4>\n<p><strong>Important:</strong><br>Use script flags with care, which may negatively impact if misused.<br>Note that the default for Eval scripts are different than the default for functions that are mentioned below, see <a href=\"eval-intro#eval-flags\">Eval Flags</a></p>\n<p>When you register a function or load an Eval script, the server does not know how it accesses the database.<br>By default, Valkey assumes that all scripts read and write data.<br>This results in the following behavior:</p>\n<ol>\n<li>They can read and write data.</li>\n<li>They can run in cluster mode, and are not able to run commands accessing keys of different hash slots.</li>\n<li>Execution against a stale replica is denied to avoid inconsistent reads.</li>\n<li>Execution under low memory is denied to avoid exceeding the configured threshold.</li>\n</ol>\n<p>You can use the following flags and instruct the server to treat the scripts&#39; execution differently:</p>\n<ul>\n<li><p><code>no-writes</code>: this flag indicates that the script only reads data but never writes.</p>\n<p>  By default, Valkey will deny the execution of flagged scripts (Functions and Eval scripts with <a href=\"eval-intro#eval-flags\">shebang</a>) against read-only replicas, as they may attempt to perform writes.<br>  Similarly, the server will not allow calling scripts with <code>FCALL_RO</code> / <code>EVAL_RO</code>.<br>  Lastly, when data persistence is at risk due to a disk error, execution is blocked as well.</p>\n<p>  Using this flag allows executing the script:</p>\n<ol>\n<li>With <code>FCALL_RO</code> / <code>EVAL_RO</code></li>\n<li>On read-only replicas.</li>\n<li>Even if there&#39;s a disk error (Valkey is unable to persist so it rejects writes).</li>\n<li>When over the memory limit since it implies the script doesn&#39;t increase memory consumption (see <code>allow-oom</code> below)</li>\n</ol>\n<p>  However, note that the server will return an error if the script attempts to call a write command.<br>  Also note that currently <code>PUBLISH</code>, <code>SPUBLISH</code> and <code>PFCOUNT</code> are also considered write commands in scripts, because they could attempt to propagate commands to replicas and AOF file.</p>\n<p>  For more information please refer to <a href=\"programmability#read-only_scripts\">Read-only scripts</a></p>\n</li>\n<li><p><code>allow-oom</code>: use this flag to allow a script to execute when the server is out of memory (OOM).</p>\n<p>  Unless used, Valkey will deny the execution of flagged scripts (Functions and Eval scripts with <a href=\"eval-intro#eval-flags\">shebang</a>) when in an OOM state.<br>  Furthermore, when you use this flag, the script can call any Valkey command, including commands that aren&#39;t usually allowed in this state.<br>  Specifying <code>no-writes</code> or using <code>FCALL_RO</code> / <code>EVAL_RO</code> also implies the script can run in OOM state (without specifying <code>allow-oom</code>)</p>\n</li>\n<li><p><code>allow-stale</code>: a flag that enables running the flagged scripts (Functions and Eval scripts with <a href=\"eval-intro#eval-flags\">shebang</a>) against a stale replica when the <code>replica-serve-stale-data</code> config is set to <code>no</code> .</p>\n<p>  Valkey can be set to prevent data consistency problems from using old data by having stale replicas return a runtime error.<br>  For scripts that do not access the data, this flag can be set to allow stale Valkey replicas to run the script.<br>  Note however that the script will still be unable to execute any command that accesses stale data.</p>\n</li>\n<li><p><code>no-cluster</code>: the flag causes the script to return an error in Valkey cluster mode.</p>\n<p>  Valkey allows scripts to be executed both in standalone and cluster modes.<br>  Setting this flag prevents executing the script against nodes in the cluster.</p>\n</li>\n<li><p><code>allow-cross-slot-keys</code>: The flag that allows a script to access keys from multiple slots.</p>\n<p>  Valkey typically prevents any single command from accessing keys that hash to multiple slots.<br>  This flag allows scripts to break this rule and access keys within the script that access multiple slots.<br>  Declared keys to the script are still always required to hash to a single slot.<br>  Accessing keys from multiple slots is discouraged as applications should be designed to only access keys from a single slot at a time, allowing slots to move between Valkey servers.</p>\n<p>  This flag has no effect when cluster mode is disabled.</p>\n</li>\n</ul>\n<p>Please refer to <a href=\"functions-intro#function-flags\">Function Flags</a> and <a href=\"eval-intro#eval-flags\">Eval Flags</a> for a detailed example.</p>\n<h3><a name=\"server.server_version\"></a> <code>server.SERVER_VERSION</code></h3>\n<ul>\n<li>Since version: 7.2.5</li>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>Returns the current Valkey server version as a Lua string.<br>The reply&#39;s format is <code>MM.mm.PP</code>, where:</p>\n<ul>\n<li><strong>MM:</strong> is the major version.</li>\n<li><strong>mm:</strong> is the minor version.</li>\n<li><strong>PP:</strong> is the patch level.</li>\n</ul>\n<h3><a name=\"server.redis_version\"></a> <code>server.REDIS_VERSION</code></h3>\n<ul>\n<li>Since version: 7.0.0</li>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>Returns the current Redis compatibility version as a Lua string.<br>The reply&#39;s format is <code>MM.mm.PP</code>, where:</p>\n<ul>\n<li><strong>MM:</strong> is the major version.</li>\n<li><strong>mm:</strong> is the minor version.</li>\n<li><strong>PP:</strong> is the patch level.</li>\n</ul>\n<h3><a name=\"server.redis_version_num\"></a> <code>server.SERVER_VERSION_NUM</code></h3>\n<ul>\n<li>Since version: 7.2.5</li>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>Returns the current Valkey server version as a number.<br>The reply is a hexadecimal value structured as <code>0x00MMmmPP</code>, where:</p>\n<ul>\n<li><strong>MM:</strong> is the major version.</li>\n<li><strong>mm:</strong> is the minor version.</li>\n<li><strong>PP:</strong> is the patch level.</li>\n</ul>\n<h3><a name=\"server.redis_version_num\"></a> <code>server.REDIS_VERSION_NUM</code></h3>\n<ul>\n<li>Since version: 7.0.0</li>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>Returns the current Redis compatibility version as a number.<br>The reply is a hexadecimal value structured as <code>0x00MMmmPP</code>, where:</p>\n<ul>\n<li><strong>MM:</strong> is the major version.</li>\n<li><strong>mm:</strong> is the minor version.</li>\n<li><strong>PP:</strong> is the patch level.</li>\n</ul>\n<h2>Data type conversion</h2>\n<p>Unless a runtime exception is raised, <code>server.call()</code> and <code>server.pcall()</code> return the reply from the executed command to the Lua script.<br>Valkey&#39;s replies from these functions are converted automatically into Lua&#39;s native data types.</p>\n<p>Similarly, when a Lua script returns a reply with the <code>return</code> keyword,<br>that reply is automatically converted to RESP protocol.</p>\n<p>Put differently: There&#39;s a one-to-one mapping between Valkey&#39;s replies and Lua&#39;s data types and a one-to-one mapping between Lua&#39;s data types and the <a href=\"protocol\">RESP Protocol</a> data types.<br>The underlying design is such that if a RESP type is converted into a Lua type and converted back into a RESP type, the result is the same as the initial value.</p>\n<p>Type conversion from Valkey replies (i.e. the replies from <code>server.call()</code> and <code>server.pcall()</code>) to Lua data types depends on the RESP protocol version used by the script.<br>The default protocol version during script executions is RESP2.<br>The script may switch the replies&#39; protocol versions by calling the <code>server.setresp()</code> function.</p>\n<p>Type conversion from a script&#39;s returned Lua data type depends on the user&#39;s choice of protocol (see the <code>HELLO</code> command).</p>\n<p>The following sections describe the type conversion rules between Lua and Valkey per the protocol&#39;s version.</p>\n<h3>RESP2 to Lua type conversion</h3>\n<p>The following type conversion rules apply to the execution&#39;s context by default as well as after calling <code>server.setresp(2)</code>:</p>\n<ul>\n<li><a href=\"protocol#integers\">RESP2 integer reply</a> -&gt; Lua number</li>\n<li><a href=\"protocol#bulk-strings\">RESP2 bulk string reply</a> -&gt; Lua string</li>\n<li><a href=\"protocol#arrays\">RESP2 array reply</a> -&gt; Lua table (may have other Valkey data types nested)</li>\n<li><a href=\"protocol#simple-strings\">RESP2 status reply</a> -&gt; Lua table with a single <em>ok</em> field containing the status string</li>\n<li><a href=\"protocol#simple-errors\">RESP2 error reply</a> -&gt; Lua table with a single <em>err</em> field containing the error string</li>\n<li><a href=\"protocol#nulls\">RESP2 null bulk reply and null multi bulk reply</a> -&gt; Lua false boolean type</li>\n</ul>\n<h2>Lua to RESP2 type conversion</h2>\n<p>The following type conversion rules apply by default as well as after the user had called <code>HELLO 2</code>:</p>\n<ul>\n<li>Lua number -&gt; <a href=\"protocol#integers\">RESP2 integer reply</a> (the number is converted into an integer)</li>\n<li>Lua string -&gt; <a href=\"protocol#bulk-strings\">RESP bulk string reply</a></li>\n<li>Lua table (indexed, non-associative array) -&gt; <a href=\"protocol#arrays\">RESP2 array reply</a> (truncated at the first Lua <code>nil</code> value encountered in the table, if any)</li>\n<li>Lua table with a single <em>ok</em> field -&gt; <a href=\"protocol#simple-strings\">RESP2 status reply</a></li>\n<li>Lua table with a single <em>err</em> field -&gt; <a href=\"protocol#simple-errors\">RESP2 error reply</a></li>\n<li>Lua boolean false -&gt; <a href=\"protocol#nulls\">RESP2 null bulk reply</a></li>\n</ul>\n<p>There is an additional Lua-to-Valkey conversion rule that has no corresponding Valkey-to-Lua conversion rule:</p>\n<ul>\n<li>Lua Boolean <code>true</code> -&gt; <a href=\"protocol#integers\">RESP2 integer reply</a> with value of 1.</li>\n</ul>\n<p>There are three additional rules to note about converting Lua to Valkey data types:</p>\n<ul>\n<li>Lua has a single numerical type, Lua numbers.<br>There is no distinction between integers and floats.<br>So we always convert Lua numbers into integer replies, removing the decimal part of the number, if any.<br><strong>If you want to return a Lua float, it should be returned as a string</strong>,<br>exactly like Valkey itself does (see, for instance, the <code>ZSCORE</code> command).</li>\n<li>There&#39;s <a href=\"https://www.lua.org/pil/19.1.html\">no simple way to have nils inside Lua arrays</a> due<br>to Lua&#39;s table semantics.<br>Therefore, when Valkey converts a Lua array to RESP, the conversion stops when it encounters a Lua <code>nil</code> value.</li>\n<li>When a Lua table is an associative array that contains keys and their respective values, the converted Valkey reply will <strong>not</strong> include them.</li>\n</ul>\n<p>Lua to RESP2 type conversion examples:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &quot;return 10&quot; 0\n(integer) 10\n\n127.0.0.1:6379&gt; EVAL &quot;return { 1, 2, { 3, &#39;Hello World!&#39; } }&quot; 0\n1) (integer) 1\n2) (integer) 2\n3) 1) (integer) 3\n   1) &quot;Hello World!&quot;\n\n127.0.0.1:6379&gt; EVAL &quot;return server.call(&#39;get&#39;,&#39;foo&#39;)&quot; 0\n&quot;bar&quot;\n</code></pre>\n<p>The last example demonstrates receiving and returning the exact return value of <code>server.call()</code> (or <code>server.pcall()</code>) in Lua as it would be returned if the command had been called directly.</p>\n<p>The following example shows how floats and arrays that cont nils and keys are handled:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &quot;return { 1, 2, 3.3333, somekey = &#39;somevalue&#39;, &#39;foo&#39;, nil , &#39;bar&#39; }&quot; 0\n1) (integer) 1\n2) (integer) 2\n3) (integer) 3\n4) &quot;foo&quot;\n</code></pre>\n<p>As you can see, the float value of <em>3.333</em> gets converted to an integer <em>3</em>, the <em>somekey</em> key and its value are omitted, and the string &quot;bar&quot; isn&#39;t returned as there is a <code>nil</code> value that precedes it.</p>\n<h3>RESP3 to Lua type conversion</h3>\n<p>RESP3 is a newer version of the <a href=\"protocol\">protocol</a> used by Valkey.<br>It is available as an opt-in choice.</p>\n<p>An executing script may call the <a href=\"#server.setresp\"><code>server.setresp</code></a> function during its execution and switch the protocol version that&#39;s used for returning replies from Valkey&#39;s commands (that can be invoked via <a href=\"#server.call\"><code>server.call()</code></a> or <a href=\"#server.pcall\"><code>server.pcall()</code></a>).</p>\n<p>Once Valkey&#39;s replies are in RESP3 protocol, all of the <a href=\"#resp2-to-lua-type-conversion\">RESP2 to Lua conversion</a> rules apply, with the following additions:</p>\n<ul>\n<li><a href=\"protocol#maps\">Map reply</a> -&gt; Lua table with a single <em>map</em> field containing a Lua table representing the fields and values of the map.</li>\n<li><a href=\"protocol#sets\">Set reply</a> -&gt; Lua table with a single <em>set</em> field containing a Lua table representing the elements of the set as fields, each with the Lua Boolean value of <code>true</code>.</li>\n<li><a href=\"protocol#nulls\">Null</a> -&gt; Lua <code>nil</code>.</li>\n<li><a href=\"protocol#booleans\">True reply</a> -&gt; Lua true boolean value.</li>\n<li><a href=\"protocol#booleans\">False reply</a> -&gt; Lua false boolean value.</li>\n<li><a href=\"protocol#doubles\">Double reply</a> -&gt; Lua table with a single <code>double</code> field containing a Lua number representing the double value.</li>\n<li><a href=\"protocol#big-numbers\">Big number reply</a> -&gt; Lua table with a single <code>big_number</code> field containing a Lua string representing the big number value (since Redis OSS 7.0).</li>\n<li><a href=\"protocol#verbatim-strings\">Verbatim string reply</a> -&gt; Lua table with a single <code>verbatim_string</code> field containing a Lua table with two fields, <code>string</code> and <code>format</code>, representing the verbatim string and its format, respectively (since Redis OSS 7.0).</li>\n</ul>\n<h3>Lua to RESP3 type conversion</h3>\n<p>Regardless of the script&#39;s choice of protocol version set for replies with the [<code>server.setresp()</code> function] when it calls <code>server.call()</code> or <code>server.pcall()</code>, the user may opt-in to using RESP3 (with the <code>HELLO 3</code> command) for the connection.<br>Although the default protocol for incoming client connections is RESP2, the script should honor the user&#39;s preference and return adequately-typed RESP3 replies, so the following rules apply on top of those specified in the <a href=\"#lua-to-resp2-type-conversion\">Lua to RESP2 type conversion</a> section when that is the case.</p>\n<ul>\n<li>Lua Boolean -&gt; <a href=\"protocol#booleans\">RESP3 Boolean reply</a> (note that this is a change compared to the RESP2, in which returning a Boolean Lua <code>true</code> returned the number 1 to the Valkey client, and returning a <code>false</code> used to return a <code>null</code>.</li>\n<li>Lua table with a single <code>map</code> field set to an associative Lua table -&gt; <a href=\"protocol#maps\">RESP3 map reply</a>.</li>\n<li>Lua table with a single <code>set</code> field set to an associative Lua table -&gt; <a href=\"protocol#sets\">RESP3 set reply</a>. Values can be set to anything and are discarded anyway.</li>\n<li>Lua table with a single <code>double</code> field to an associative Lua table -&gt; <a href=\"protocol#doubles\">RESP3 double reply</a>.</li>\n<li>Lua nil -&gt; <a href=\"protocol#nulls\">RESP3 null</a>.</li>\n</ul>\n<p>However, if the connection is set use the RESP2 protocol, and even if the script replies with RESP3-typed responses, Valkey will automatically perform a RESP3 to RESP2 conversion of the reply as is the case for regular commands.<br>That means, for example, that returning the RESP3 map type to a RESP2 connection will result in the reply being converted to a flat RESP2 array that consists of alternating field names and their values, rather than a RESP3 map.</p>\n<h2>Additional notes about scripting</h2>\n<h3>Using <code>SELECT</code> inside scripts</h3>\n<p>You can call the <code>SELECT</code> command from your Lua scripts, like you can with any normal client connection.<br>The database selected by the Lua script only affects the execution context of the script, and does not modify the database that&#39;s selected by the client calling the script.</p>\n<h2>Runtime libraries</h2>\n<p>The Valkey Lua runtime context always comes with several pre-imported libraries.</p>\n<p>The following <a href=\"https://www.lua.org/manual/5.1/manual.html#5\">standard Lua libraries</a> are available to use:</p>\n<ul>\n<li>The <a href=\"https://www.lua.org/manual/5.1/manual.html#5.4\"><em>String Manipulation (string)</em> library</a></li>\n<li>The <a href=\"https://www.lua.org/manual/5.1/manual.html#5.5\"><em>Table Manipulation (table)</em> library</a></li>\n<li>The <a href=\"https://www.lua.org/manual/5.1/manual.html#5.6\"><em>Mathematical Functions (math)</em> library</a></li>\n<li>The <a href=\"#os-library\"><em>Operating System Facilities (os)</em> library</a></li>\n</ul>\n<p>In addition, the following external libraries are loaded and accessible to scripts:</p>\n<ul>\n<li>The <a href=\"#struct-library\"><em>struct</em> library</a></li>\n<li>The <a href=\"#cjson-library\"><em>cjson</em> library</a></li>\n<li>The <a href=\"#cmsgpack-library\"><em>cmsgpack</em> library</a></li>\n<li>The <a href=\"#bitop-library\"><em>bitop</em> library</a></li>\n</ul>\n<h3><a name=\"os-library\"></a> <em>os</em> library</h3>\n<ul>\n<li>Since version: 8.0.0</li>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p><em>os</em> provides a set of functions for dealing with date, time, and system commands.<br>More details can be found in the <a href=\"https://www.lua.org/manual/5.1/manual.html#5.8\">Operating System Facilities</a>.<br>Note that for sandbox security, currently only the following os functions is exposed:</p>\n<ul>\n<li><code>os.clock()</code></li>\n</ul>\n<h3><a name=\"struct-library\"></a> <em>struct</em> library</h3>\n<ul>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p><em>struct</em> is a library for packing and unpacking C-like structures in Lua.<br>It provides the following functions:</p>\n<ul>\n<li><a href=\"#struct.pack\"><code>struct.pack()</code></a></li>\n<li><a href=\"#struct.unpack\"><code>struct.unpack()</code></a></li>\n<li><a href=\"#struct.size\"><code>struct.size()</code></a></li>\n</ul>\n<p>All of <em>struct</em>&#39;s functions expect their first argument to be a <a href=\"#struct-formats\">format string</a>.</p>\n<h4><a name=\"struct-formats\"></a> <em>struct</em> formats</h4>\n<p>The following are valid format strings for <em>struct</em>&#39;s functions:</p>\n<ul>\n<li><code>&gt;</code>: big endian</li>\n<li><code>&lt;</code>: little endian</li>\n<li><code>![num]</code>: alignment</li>\n<li><code>x</code>: padding</li>\n<li><code>b/B</code>: signed/unsigned byte</li>\n<li><code>h/H</code>: signed/unsigned short</li>\n<li><code>l/L</code>: signed/unsigned long</li>\n<li><code>T</code>: size_t</li>\n<li><code>i/In</code>: signed/unsigned integer with size <em>n</em> (defaults to the size of int)</li>\n<li><code>cn</code>: sequence of <em>n</em> chars (from/to a string); when packing, n == 0 means the<br>whole string; when unpacking, n == 0 means use the previously read number as<br>the string&#39;s length.</li>\n<li><code>s</code>: zero-terminated string</li>\n<li><code>f</code>: float</li>\n<li><code>d</code>: double</li>\n<li><code> </code> (space): ignored</li>\n</ul>\n<h4><a name=\"struct.pack\"></a> <code>struct.pack(x)</code></h4>\n<p>This function returns a struct-encoded string from values.<br>It accepts a <a href=\"#struct-formats\"><em>struct</em> format string</a> as its first argument, followed by the values that are to be encoded.</p>\n<p>Usage example:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &quot;return struct.pack(&#39;HH&#39;, 1, 2)&quot; 0\n&quot;\\x01\\x00\\x02\\x00&quot;\n</code></pre>\n<h4><a name=\"struct.unpack\"></a> <code>struct.unpack(x)</code></h4>\n<p>This function returns the decoded values from a struct.<br>It accepts a <a href=\"#struct-formats\"><em>struct</em> format string</a> as its first argument, followed by encoded struct&#39;s string.</p>\n<p>Usage example:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &quot;return { struct.unpack(&#39;HH&#39;, ARGV[1]) }&quot; 0 &quot;\\x01\\x00\\x02\\x00&quot;\n1) (integer) 1\n2) (integer) 2\n3) (integer) 5\n</code></pre>\n<h4><a name=\"struct.size\"></a> <code>struct.size(x)</code></h4>\n<p>This function returns the size, in bytes, of a struct.<br>It accepts a <a href=\"#struct-formats\"><em>struct</em> format string</a> as its only argument.</p>\n<p>Usage example:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &quot;return struct.size(&#39;HH&#39;)&quot; 0\n(integer) 4\n</code></pre>\n<h3><a name=\"cjson-library\"></a> <em>cjson</em> library</h3>\n<ul>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>The <em>cjson</em> library provides fast <a href=\"https://json.org\">JSON</a> encoding and decoding from Lua.<br>It provides these functions.</p>\n<h4><a name=\"cjson.encode()\"></a> <code>cjson.encode(x)</code></h4>\n<p>This function returns a JSON-encoded string for the Lua data type provided as its argument.</p>\n<p>Usage example:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &quot;return cjson.encode({ [&#39;foo&#39;] = &#39;bar&#39; })&quot; 0\n&quot;{\\&quot;foo\\&quot;:\\&quot;bar\\&quot;}&quot;\n</code></pre>\n<h4><a name=\"cjson.decode()\"></a> <code>cjson.decode(x)</code></h4>\n<p>This function returns a Lua data type from the JSON-encoded string provided as its argument.</p>\n<p>Usage example:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &quot;return cjson.decode(ARGV[1])[&#39;foo&#39;]&quot; 0 &#39;{&quot;foo&quot;:&quot;bar&quot;}&#39;\n&quot;bar&quot;\n</code></pre>\n<h3><a name=\"cmsgpack-library\"></a> <em>cmsgpack</em> library</h3>\n<ul>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>The <em>cmsgpack</em> library provides fast <a href=\"https://msgpack.org/index.html\">MessagePack</a> encoding and decoding from Lua.<br>It provides these functions.</p>\n<h4><a name=\"cmsgpack.pack()\"></a> <code>cmsgpack.pack(x)</code></h4>\n<p>This function returns the packed string encoding of the Lua data type it is given as an argument.</p>\n<p>Usage example:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &quot;return cmsgpack.pack({&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;})&quot; 0\n&quot;\\x93\\xa3foo\\xa3bar\\xa3baz&quot;\n</code></pre>\n<h4><a name=\"cmsgpack.unpack()\"></a> <code>cmsgpack.unpack(x)</code></h4>\n<p>This function returns the unpacked values from decoding its input string argument.</p>\n<p>Usage example:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &quot;return cmsgpack.unpack(ARGV[1])&quot; 0 &quot;\\x93\\xa3foo\\xa3bar\\xa3baz&quot;\n1) &quot;foo&quot;\n2) &quot;bar&quot;\n3) &quot;baz&quot;\n</code></pre>\n<h3><a name=\"bitop-library\"></a> <em>bit</em> library</h3>\n<ul>\n<li>Available in scripts: yes</li>\n<li>Available in functions: yes</li>\n</ul>\n<p>The <em>bit</em> library provides bitwise operations on numbers.<br>Its documentation resides at <a href=\"https://bitop.luajit.org/api.html\">Lua BitOp documentation</a><br>It provides the following functions.</p>\n<h4><a name=\"bit.tobit()\"></a> <code>bit.tobit(x)</code></h4>\n<p>Normalizes a number to the numeric range for bit operations and returns it.</p>\n<p>Usage example:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &#39;return bit.tobit(1)&#39; 0\n(integer) 1\n</code></pre>\n<h4><a name=\"bit.tohex()\"></a> <code>bit.tohex(x [,n])</code></h4>\n<p>Converts its first argument to a hex string. The number of hex digits is given by the absolute value of the optional second argument.</p>\n<p>Usage example:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &#39;return bit.tohex(422342)&#39; 0\n&quot;000671c6&quot;\n</code></pre>\n<h4><a name=\"bit.bnot()\"></a> <code>bit.bnot(x)</code></h4>\n<p>Returns the bitwise <strong>not</strong> of its argument.</p>\n<h4><a name=\"bit.ops\"></a> <code>bit.bnot(x)</code> <code>bit.bor(x1 [,x2...])</code>, <code>bit.band(x1 [,x2...])</code> and <code>bit.bxor(x1 [,x2...])</code></h4>\n<p>Returns either the bitwise <strong>or</strong>, bitwise <strong>and</strong>, or bitwise <strong>xor</strong> of all of its arguments.<br>Note that more than two arguments are allowed.</p>\n<p>Usage example:</p>\n<pre><code>127.0.0.1:6379&gt; EVAL &#39;return bit.bor(1,2,4,8,16,32,64,128)&#39; 0\n(integer) 255\n</code></pre>\n<h4><a name=\"bit.shifts\"></a> <code>bit.lshift(x, n)</code>, <code>bit.rshift(x, n)</code> and <code>bit.arshift(x, n)</code></h4>\n<p>Returns either the bitwise logical <strong>left-shift</strong>, bitwise logical <strong>right-shift</strong>, or bitwise <strong>arithmetic right-shift</strong> of its first argument by the number of bits given by the second argument.</p>\n<h4><a name=\"bit.ro\"></a> <code>bit.rol(x, n)</code> and <code>bit.ror(x, n)</code></h4>\n<p>Returns either the bitwise <strong>left rotation</strong>, or bitwise <strong>right rotation</strong> of its first argument by the number of bits given by the second argument.<br>Bits shifted out on one side are shifted back in on the other side.</p>\n<h4><a name=\"bit.bswap()\"></a> <code>bit.bswap(x)</code></h4>\n<p>Swaps the bytes of its argument and returns it.<br>This can be used to convert little-endian 32-bit numbers to big-endian 32-bit numbers and vice versa.</p>\n"
      },
      {
        "id": "programmability",
        "topicName": "Programmability",
        "description": "Extending Valkey with Lua and Valkey Functions\n",
        "htmlContent": "<p>Valkey provides a programming interface that lets you execute custom scripts on the server itself.<br>You can use <a href=\"functions-intro\">Functions</a> to create, manage and run scripts.<br>You can also use <a href=\"eval-intro\">Lua scripting with the EVAL command</a> to program the server.</p>\n<h2>Background</h2>\n<p>Valkey is a <em>&quot;domain-specific language for abstract data types&quot;</em>.<br>The language that Valkey speaks consists of its <a href=\"../commands/\">commands</a>.<br>Most the commands specialize at manipulating core <a href=\"data-types\">data types</a> in different ways.<br>In many cases, these commands provide all the functionality that a developer requires for managing application data in Valkey.</p>\n<p>The term <strong>programmability</strong> in Valkey means having the ability to execute arbitrary user-defined logic by the server.<br>We refer to such pieces of logic as <strong>scripts</strong>.<br>In our case, scripts enable processing the data where it lives, a.k.a <em>data locality</em>.<br>Furthermore, the responsible embedding of programmatic workflows in the Valkey server can help in reducing network traffic and improving overall performance.<br>Developers can use this capability for implementing robust, application-specific APIs.<br>Such APIs can encapsulate business logic and maintain a data model across multiple keys and different data structures.</p>\n<p>User scripts are executed in Valkey by an embedded, sandboxed scripting engine.<br>Presently, Valkey supports a single scripting engine, the <a href=\"https://www.lua.org/\">Lua 5.1</a> interpreter.</p>\n<p>Please refer to the <a href=\"lua-api\">Valkey Lua API Reference</a> page for complete documentation.</p>\n<h2>Running scripts</h2>\n<p>Valkey provides two means for running scripts.</p>\n<p>Firstly, the <code>EVAL</code> command enables running server-side scripts.<br>Eval scripts provide a quick and straightforward way to have Valkey run your scripts ad-hoc.<br>However, using them means that the scripted logic is a part of your application (not an extension of the Valkey server).<br>Every applicative instance that runs a script must have the script&#39;s source code readily available for loading at any time.<br>That is because scripts are only cached by the server and are volatile.<br>As your application grows, this approach can become harder to develop and maintain.</p>\n<p>Secondly, added in v7.0, Valkey Functions are essentially scripts that are first-class database elements.<br>As such, functions decouple scripting from application logic and enable independent development, testing, and deployment of scripts.<br>To use functions, they need to be loaded first, and then they are available for use by all connected clients.<br>In this case, loading a function to the database becomes an administrative deployment task (such as loading a Valkey module, for example), which separates the script from the application.</p>\n<p>Please refer to the following pages for more information:</p>\n<ul>\n<li><a href=\"eval-intro\">Valkey Eval Scripts</a></li>\n<li><a href=\"functions-intro\">Valkey Functions</a></li>\n</ul>\n<p>When running a script or a function, Valkey guarantees its atomic execution.<br>The script&#39;s execution blocks all server activities during its entire time, similarly to the semantics of <a href=\"transactions\">transactions</a>.<br>These semantics mean that all of the script&#39;s effects either have yet to happen or had already happened.<br>The blocking semantics of an executed script apply to all connected clients at all times.</p>\n<p>Note that the potential downside of this blocking approach is that executing slow scripts is not a good idea.<br>It is not hard to create fast scripts because scripting&#39;s overhead is very low.<br>However, if you intend to use a slow script in your application, be aware that all other clients are blocked and can&#39;t execute any command while it is running.</p>\n<h2>Read-only scripts</h2>\n<p>A read-only script is a script that only executes commands that don&#39;t modify any keys within Valkey.<br>Read-only scripts can be executed either by adding the <code>no-writes</code> <a href=\"lua-api#script_flags\">flag</a> to the script or by executing the script with one of the read-only script command variants: <code>EVAL_RO</code>, <code>EVALSHA_RO</code>, or <code>FCALL_RO</code>.<br>They have the following properties:</p>\n<ul>\n<li>They can always be executed on replicas.</li>\n<li>They can always be killed by the <code>SCRIPT KILL</code> command. </li>\n<li>They never fail with OOM error when Valkey is over the memory limit.</li>\n<li>They are not blocked during write pauses, such as those that occur during coordinated failovers.</li>\n<li>They cannot execute any command that may modify the data set.</li>\n<li>Currently <code>PUBLISH</code>, <code>SPUBLISH</code> and <code>PFCOUNT</code> are also considered write commands in scripts, because they could attempt to propagate commands to replicas and AOF file.</li>\n</ul>\n<p>In addition to the benefits provided by all read-only scripts, the read-only script commands have the following advantages:</p>\n<ul>\n<li>They can be used to configure an ACL user to only be able to execute read-only scripts.</li>\n<li>Many clients also better support routing the read-only script commands to replicas for applications that want to use replicas for read scaling.</li>\n</ul>\n<h4>Read-only script history</h4>\n<p>Read-only scripts and read-only script commands were introduced in Redis OSS 7.0</p>\n<ul>\n<li>Before Redis OSS 7.0.1 <code>PUBLISH</code>, <code>SPUBLISH</code> and <code>PFCOUNT</code> were not considered write commands in scripts</li>\n<li>Before Redis OSS 7.0.1 the <code>no-writes</code> <a href=\"lua-api#script_flags\">flag</a> did not imply <code>allow-oom</code></li>\n<li>Before Redis OSS 7.0.1 the <code>no-writes</code> flag did not permit the script to run during write pauses.</li>\n</ul>\n<p>The recommended approach is to use the standard scripting commands with the <code>no-writes</code> flag unless you need one of the previously mentioned features.</p>\n<h2>Sandboxed script context</h2>\n<p>Valkey places the engine that executes user scripts inside a sandbox.<br>The sandbox attempts to prevent accidental misuse and reduce potential threats from the server&#39;s environment.</p>\n<p>Scripts should never try to access the Valkey server&#39;s underlying host systems, such as the file system, network, or attempt to perform any other system call other than those supported by the API.</p>\n<p>Scripts should operate solely on data stored in Valkey and data provided as arguments to their execution.</p>\n<h2>Maximum execution time</h2>\n<p>Scripts are subject to a maximum execution time (set by default to five seconds).<br>This default timeout is enormous since a script usually runs in less than a millisecond.<br>The limit is in place to handle accidental infinite loops created during development.</p>\n<p>It is possible to modify the maximum time a script can be executed with millisecond precision,<br>either via <code>valkey.conf</code> or by using the <code>CONFIG SET</code> command.<br>The configuration parameter affecting max execution time is called <code>busy-reply-threshold</code>.</p>\n<p>When a script reaches the timeout threshold, it isn&#39;t terminated by Valkey automatically.<br>Doing so would violate the contract between Valkey and the scripting engine that ensures that scripts are atomic.<br>Interrupting the execution of a script has the potential of leaving the dataset with half-written changes.</p>\n<p>Therefore, when a script executes longer than the configured timeout, the following happens:</p>\n<ul>\n<li>Valkey logs that a script is running for too long.</li>\n<li>It starts accepting commands again from other clients but will reply with a BUSY error to all the clients sending normal commands. The only commands allowed in this state are <code>SCRIPT KILL</code>, <code>FUNCTION KILL</code>, and <code>SHUTDOWN NOSAVE</code>.</li>\n<li>It is possible to terminate a script that only executes read-only commands using the <code>SCRIPT KILL</code> and <code>FUNCTION KILL</code> commands. These commands do not violate the scripting semantic as no data was written to the dataset by the script yet.</li>\n<li>If the script had already performed even a single write operation, the only command allowed is <code>SHUTDOWN NOSAVE</code> that stops the server without saving the current data set on disk (basically, the server is aborted).</li>\n</ul>\n"
      }
    ]
  },
  {
    "title": "MODULES",
    "items": [
      {
        "id": "modules-api-ref",
        "topicName": "Modules API reference",
        "description": "Reference for the Valkey Modules API\n",
        "htmlContent": "<!-- This file is generated from module.c using\n     utils/generate-module-api-doc.rb -->\n\n<h2>Sections</h2>\n<ul>\n<li><a href=\"#section-heap-allocation-raw-functions\">Heap allocation raw functions</a></li>\n<li><a href=\"#section-commands-api\">Commands API</a></li>\n<li><a href=\"#section-module-information-and-time-measurement\">Module information and time measurement</a></li>\n<li><a href=\"#section-automatic-memory-management-for-modules\">Automatic memory management for modules</a></li>\n<li><a href=\"#section-string-objects-apis\">String objects APIs</a></li>\n<li><a href=\"#section-reply-apis\">Reply APIs</a></li>\n<li><a href=\"#section-commands-replication-api\">Commands replication API</a></li>\n<li><a href=\"#section-db-and-key-apis-generic-api\">DB and Key APIs – Generic API</a></li>\n<li><a href=\"#section-key-api-for-string-type\">Key API for String type</a></li>\n<li><a href=\"#section-key-api-for-list-type\">Key API for List type</a></li>\n<li><a href=\"#section-key-api-for-sorted-set-type\">Key API for Sorted Set type</a></li>\n<li><a href=\"#section-key-api-for-sorted-set-iterator\">Key API for Sorted Set iterator</a></li>\n<li><a href=\"#section-key-api-for-hash-type\">Key API for Hash type</a></li>\n<li><a href=\"#section-key-api-for-stream-type\">Key API for Stream type</a></li>\n<li><a href=\"#section-calling-commands-from-modules\">Calling commands from modules</a></li>\n<li><a href=\"#section-modules-data-types\">Modules data types</a></li>\n<li><a href=\"#section-rdb-loading-and-saving-functions\">RDB loading and saving functions</a></li>\n<li><a href=\"#section-key-digest-api-debug-digest-interface-for-modules-types\">Key digest API (DEBUG DIGEST interface for modules types)</a></li>\n<li><a href=\"#section-aof-api-for-modules-data-types\">AOF API for modules data types</a></li>\n<li><a href=\"#section-io-context-handling\">IO context handling</a></li>\n<li><a href=\"#section-logging\">Logging</a></li>\n<li><a href=\"#section-blocking-clients-from-modules\">Blocking clients from modules</a></li>\n<li><a href=\"#section-thread-safe-contexts\">Thread Safe Contexts</a></li>\n<li><a href=\"#section-module-keyspace-notifications-api\">Module Keyspace Notifications API</a></li>\n<li><a href=\"#section-modules-cluster-api\">Modules Cluster API</a></li>\n<li><a href=\"#section-modules-timers-api\">Modules Timers API</a></li>\n<li><a href=\"#section-modules-eventloop-api\">Modules EventLoop API</a></li>\n<li><a href=\"#section-modules-acl-api\">Modules ACL API</a></li>\n<li><a href=\"#section-modules-dictionary-api\">Modules Dictionary API</a></li>\n<li><a href=\"#section-modules-info-fields\">Modules Info fields</a></li>\n<li><a href=\"#section-modules-utility-apis\">Modules utility APIs</a></li>\n<li><a href=\"#section-modules-api-exporting-importing\">Modules API exporting / importing</a></li>\n<li><a href=\"#section-module-command-filter-api\">Module Command Filter API</a></li>\n<li><a href=\"#section-scanning-keyspace-and-hashes\">Scanning keyspace and hashes</a></li>\n<li><a href=\"#section-module-fork-api\">Module fork API</a></li>\n<li><a href=\"#section-server-hooks-implementation\">Server hooks implementation</a></li>\n<li><a href=\"#section-module-configurations-api\">Module Configurations API</a></li>\n<li><a href=\"#section-rdb-load-save-api\">RDB load/save API</a></li>\n<li><a href=\"#section-key-eviction-api\">Key eviction API</a></li>\n<li><a href=\"#section-miscellaneous-apis\">Miscellaneous APIs</a></li>\n<li><a href=\"#section-defrag-api\">Defrag API</a></li>\n<li><a href=\"#section-function-index\">Function index</a></li>\n</ul>\n<p><span id=\"section-heap-allocation-raw-functions\"></span></p>\n<h2>Heap allocation raw functions</h2>\n<p>Memory allocated with these functions are taken into account by key<br>eviction algorithms and are reported in memory usage information.</p>\n<p><span id=\"ValkeyModule_Alloc\"></span></p>\n<h3><code>ValkeyModule_Alloc</code></h3>\n<pre><code>void *ValkeyModule_Alloc(size_t bytes);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Use like <code>malloc()</code>. Memory allocated with this function is reported in<br>INFO memory, used for keys eviction according to maxmemory settings<br>and in general is taken into account as memory allocated by the server.<br>You should avoid using <code>malloc()</code>.<br>This function panics if unable to allocate enough memory.</p>\n<p><span id=\"ValkeyModule_TryAlloc\"></span></p>\n<h3><code>ValkeyModule_TryAlloc</code></h3>\n<pre><code>void *ValkeyModule_TryAlloc(size_t bytes);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Similar to <a href=\"#ValkeyModule_Alloc\"><code>ValkeyModule_Alloc</code></a>, but returns NULL in case of allocation failure, instead<br>of panicking.</p>\n<p><span id=\"ValkeyModule_Calloc\"></span></p>\n<h3><code>ValkeyModule_Calloc</code></h3>\n<pre><code>void *ValkeyModule_Calloc(size_t nmemb, size_t size);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Use like <code>calloc()</code>. Memory allocated with this function is reported in<br>INFO memory, used for keys eviction according to maxmemory settings<br>and in general is taken into account as memory allocated by the server.<br>You should avoid using <code>calloc()</code> directly.</p>\n<p><span id=\"ValkeyModule_TryCalloc\"></span></p>\n<h3><code>ValkeyModule_TryCalloc</code></h3>\n<pre><code>void *ValkeyModule_TryCalloc(size_t nmemb, size_t size);\n</code></pre>\n<p><strong>Available since:</strong> 8.0.0</p>\n<p>Similar to <a href=\"#ValkeyModule_Calloc\"><code>ValkeyModule_Calloc</code></a>, but returns NULL in case of allocation failure, instead<br>of panicking.</p>\n<p><span id=\"ValkeyModule_Realloc\"></span></p>\n<h3><code>ValkeyModule_Realloc</code></h3>\n<pre><code>void *ValkeyModule_Realloc(void *ptr, size_t bytes);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Use like <code>realloc()</code> for memory obtained with <a href=\"#ValkeyModule_Alloc\"><code>ValkeyModule_Alloc()</code></a>.</p>\n<p><span id=\"ValkeyModule_TryRealloc\"></span></p>\n<h3><code>ValkeyModule_TryRealloc</code></h3>\n<pre><code>void *ValkeyModule_TryRealloc(void *ptr, size_t bytes);\n</code></pre>\n<p><strong>Available since:</strong> 8.0.0</p>\n<p>Similar to <a href=\"#ValkeyModule_Realloc\"><code>ValkeyModule_Realloc</code></a>, but returns NULL in case of allocation failure,<br>instead of panicking.</p>\n<p><span id=\"ValkeyModule_Free\"></span></p>\n<h3><code>ValkeyModule_Free</code></h3>\n<pre><code>void ValkeyModule_Free(void *ptr);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Use like <code>free()</code> for memory obtained by <a href=\"#ValkeyModule_Alloc\"><code>ValkeyModule_Alloc()</code></a> and<br><a href=\"#ValkeyModule_Realloc\"><code>ValkeyModule_Realloc()</code></a>. However you should never try to free with<br><a href=\"#ValkeyModule_Free\"><code>ValkeyModule_Free()</code></a> memory allocated with <code>malloc()</code> inside your module.</p>\n<p><span id=\"ValkeyModule_Strdup\"></span></p>\n<h3><code>ValkeyModule_Strdup</code></h3>\n<pre><code>char *ValkeyModule_Strdup(const char *str);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Like <code>strdup()</code> but returns memory allocated with <a href=\"#ValkeyModule_Alloc\"><code>ValkeyModule_Alloc()</code></a>.</p>\n<p><span id=\"ValkeyModule_PoolAlloc\"></span></p>\n<h3><code>ValkeyModule_PoolAlloc</code></h3>\n<pre><code>void *ValkeyModule_PoolAlloc(ValkeyModuleCtx *ctx, size_t bytes);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return heap allocated memory that will be freed automatically when the<br>module callback function returns. Mostly suitable for small allocations<br>that are short living and must be released when the callback returns<br>anyway. The returned memory is aligned to the architecture word size<br>if at least word size bytes are requested, otherwise it is just<br>aligned to the next power of two, so for example a 3 bytes request is<br>4 bytes aligned while a 2 bytes request is 2 bytes aligned.</p>\n<p>There is no realloc style function since when this is needed to use the<br>pool allocator is not a good idea.</p>\n<p>The function returns NULL if <code>bytes</code> is 0.</p>\n<p><span id=\"section-commands-api\"></span></p>\n<h2>Commands API</h2>\n<p>These functions are used to implement custom commands.</p>\n<p>For examples, see <a href=\"https://valkey.io/topics/modules-intro\">https://valkey.io/topics/modules-intro</a>.</p>\n<p><span id=\"ValkeyModule_IsKeysPositionRequest\"></span></p>\n<h3><code>ValkeyModule_IsKeysPositionRequest</code></h3>\n<pre><code>int ValkeyModule_IsKeysPositionRequest(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return non-zero if a module command, that was declared with the<br>flag &quot;getkeys-api&quot;, is called in a special way to get the keys positions<br>and not to get executed. Otherwise zero is returned.</p>\n<p><span id=\"ValkeyModule_KeyAtPosWithFlags\"></span></p>\n<h3><code>ValkeyModule_KeyAtPosWithFlags</code></h3>\n<pre><code>void ValkeyModule_KeyAtPosWithFlags(ValkeyModuleCtx *ctx, int pos, int flags);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>When a module command is called in order to obtain the position of<br>keys, since it was flagged as &quot;getkeys-api&quot; during the registration,<br>the command implementation checks for this special call using the<br><a href=\"#ValkeyModule_IsKeysPositionRequest\"><code>ValkeyModule_IsKeysPositionRequest()</code></a> API and uses this function in<br>order to report keys.</p>\n<p>The supported flags are the ones used by <a href=\"#ValkeyModule_SetCommandInfo\"><code>ValkeyModule_SetCommandInfo</code></a>, see <code>VALKEYMODULE_CMD_KEY_</code>*.</p>\n<p>The following is an example of how it could be used:</p>\n<pre><code>if (ValkeyModule_IsKeysPositionRequest(ctx)) {\n    ValkeyModule_KeyAtPosWithFlags(ctx, 2, VALKEYMODULE_CMD_KEY_RO | VALKEYMODULE_CMD_KEY_ACCESS);\n    ValkeyModule_KeyAtPosWithFlags(ctx, 1, VALKEYMODULE_CMD_KEY_RW | VALKEYMODULE_CMD_KEY_UPDATE |\n</code></pre>\n<p><code>VALKEYMODULE_CMD_KEY_ACCESS</code>);<br>    }</p>\n<p> Note: in the example above the get keys API could have been handled by key-specs (preferred).<br> Implementing the getkeys-api is required only when is it not possible to declare key-specs that cover all keys.</p>\n<p><span id=\"ValkeyModule_KeyAtPos\"></span></p>\n<h3><code>ValkeyModule_KeyAtPos</code></h3>\n<pre><code>void ValkeyModule_KeyAtPos(ValkeyModuleCtx *ctx, int pos);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>This API existed before <a href=\"#ValkeyModule_KeyAtPosWithFlags\"><code>ValkeyModule_KeyAtPosWithFlags</code></a> was added, now deprecated and<br>can be used for compatibility with older versions, before key-specs and flags<br>were introduced.</p>\n<p><span id=\"ValkeyModule_IsChannelsPositionRequest\"></span></p>\n<h3><code>ValkeyModule_IsChannelsPositionRequest</code></h3>\n<pre><code>int ValkeyModule_IsChannelsPositionRequest(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Return non-zero if a module command, that was declared with the<br>flag &quot;getchannels-api&quot;, is called in a special way to get the channel positions<br>and not to get executed. Otherwise zero is returned.</p>\n<p><span id=\"ValkeyModule_ChannelAtPosWithFlags\"></span></p>\n<h3><code>ValkeyModule_ChannelAtPosWithFlags</code></h3>\n<pre><code>void ValkeyModule_ChannelAtPosWithFlags(ValkeyModuleCtx *ctx,\n                                        int pos,\n                                        int flags);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>When a module command is called in order to obtain the position of<br>channels, since it was flagged as &quot;getchannels-api&quot; during the<br>registration, the command implementation checks for this special call<br>using the <a href=\"#ValkeyModule_IsChannelsPositionRequest\"><code>ValkeyModule_IsChannelsPositionRequest()</code></a> API and uses this<br>function in order to report the channels.</p>\n<p>The supported flags are:</p>\n<ul>\n<li><code>VALKEYMODULE_CMD_CHANNEL_SUBSCRIBE</code>: This command will subscribe to the channel.</li>\n<li><code>VALKEYMODULE_CMD_CHANNEL_UNSUBSCRIBE</code>: This command will unsubscribe from this channel.</li>\n<li><code>VALKEYMODULE_CMD_CHANNEL_PUBLISH</code>: This command will publish to this channel.</li>\n<li><code>VALKEYMODULE_CMD_CHANNEL_PATTERN</code>: Instead of acting on a specific channel, will act on any<br>                             channel specified by the pattern. This is the same access<br>                             used by the PSUBSCRIBE and PUNSUBSCRIBE commands.<br>                             Not intended to be used with PUBLISH permissions.</li>\n</ul>\n<p>The following is an example of how it could be used:</p>\n<pre><code>if (ValkeyModule_IsChannelsPositionRequest(ctx)) {\n    ValkeyModule_ChannelAtPosWithFlags(ctx, 1, VALKEYMODULE_CMD_CHANNEL_SUBSCRIBE | VALKEYMODULE_CMD_CHANNEL_PATTERN); \n    ValkeyModule_ChannelAtPosWithFlags(ctx, 1, `VALKEYMODULE_CMD_CHANNEL_PUBLISH`);\n}\n</code></pre>\n<p>Note: One usage of declaring channels is for evaluating ACL permissions. In this context,<br>unsubscribing is always allowed, so commands will only be checked against subscribe and<br>publish permissions. This is preferred over using <a href=\"#ValkeyModule_ACLCheckChannelPermissions\"><code>ValkeyModule_ACLCheckChannelPermissions</code></a>, since<br>it allows the ACLs to be checked before the command is executed.</p>\n<p><span id=\"ValkeyModule_CreateCommand\"></span></p>\n<h3><code>ValkeyModule_CreateCommand</code></h3>\n<pre><code>int ValkeyModule_CreateCommand(ValkeyModuleCtx *ctx,\n                               const char *name,\n                               ValkeyModuleCmdFunc cmdfunc,\n                               const char *strflags,\n                               int firstkey,\n                               int lastkey,\n                               int keystep);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Register a new command in the server, that will be handled by<br>calling the function pointer &#39;cmdfunc&#39; using the ValkeyModule calling<br>convention.</p>\n<p>The function returns <code>VALKEYMODULE_ERR</code> in these cases:</p>\n<ul>\n<li>If creation of module command is called outside the <code>ValkeyModule_OnLoad</code>.</li>\n<li>The specified command is already busy.</li>\n<li>The command name contains some chars that are not allowed.</li>\n<li>A set of invalid flags were passed.</li>\n</ul>\n<p>Otherwise <code>VALKEYMODULE_OK</code> is returned and the new command is registered.</p>\n<p>This function must be called during the initialization of the module<br>inside the <code>ValkeyModule_OnLoad()</code> function. Calling this function outside<br>of the initialization function is not defined.</p>\n<p>The command function type is the following:</p>\n<pre><code> int MyCommand_ValkeyCommand(ValkeyModuleCtx *ctx, ValkeyModuleString **argv, int argc);\n</code></pre>\n<p>And is supposed to always return <code>VALKEYMODULE_OK</code>.</p>\n<p>The set of flags &#39;strflags&#39; specify the behavior of the command, and should<br>be passed as a C string composed of space separated words, like for<br>example &quot;write deny-oom&quot;. The set of flags are:</p>\n<ul>\n<li><strong>&quot;write&quot;</strong>:     The command may modify the data set (it may also read<br>             from it).</li>\n<li><strong>&quot;readonly&quot;</strong>:  The command returns data from keys but never writes.</li>\n<li><strong>&quot;admin&quot;</strong>:     The command is an administrative command (may change<br>             replication or perform similar tasks).</li>\n<li><strong>&quot;deny-oom&quot;</strong>:  The command may use additional memory and should be<br>             denied during out of memory conditions.</li>\n<li><strong>&quot;deny-script&quot;</strong>:   Don&#39;t allow this command in Lua scripts.</li>\n<li><strong>&quot;allow-loading&quot;</strong>: Allow this command while the server is loading data.<br>                 Only commands not interacting with the data set<br>                 should be allowed to run in this mode. If not sure<br>                 don&#39;t use this flag.</li>\n<li><strong>&quot;pubsub&quot;</strong>:    The command publishes things on Pub/Sub channels.</li>\n<li><strong>&quot;random&quot;</strong>:    The command may have different outputs even starting<br>             from the same input arguments and key values.<br>             Starting from Redis OSS 7.0 this flag has been deprecated.<br>             Declaring a command as &quot;random&quot; can be done using<br>             command tips, see <a href=\"https://valkey.io/topics/command-tips\">https://valkey.io/topics/command-tips</a>.</li>\n<li><strong>&quot;allow-stale&quot;</strong>: The command is allowed to run on replicas that don&#39;t<br>               serve stale data. Don&#39;t use if you don&#39;t know what<br>               this means.</li>\n<li><strong>&quot;no-monitor&quot;</strong>: Don&#39;t propagate the command on monitor. Use this if<br>              the command has sensitive data among the arguments.</li>\n<li><strong>&quot;no-slowlog&quot;</strong>: Deprecated, please use &quot;no-commandlog&quot;.</li>\n<li><strong>&quot;no-commandlog&quot;</strong>: Don&#39;t log this command in the commandlog. Use this if<br>              the command has sensitive data among the arguments.</li>\n<li><strong>&quot;fast&quot;</strong>:      The command time complexity is not greater<br>             than O(log(N)) where N is the size of the collection or<br>             anything else representing the normal scalability<br>             issue with the command.</li>\n<li><strong>&quot;getkeys-api&quot;</strong>: The command implements the interface to return<br>               the arguments that are keys. Used when start/stop/step<br>               is not enough because of the command syntax.</li>\n<li><strong>&quot;no-cluster&quot;</strong>: The command should not register in Cluster<br>              since is not designed to work with it because, for<br>              example, is unable to report the position of the<br>              keys, programmatically creates key names, or any<br>              other reason.</li>\n<li><strong>&quot;no-auth&quot;</strong>:    This command can be run by an un-authenticated client.<br>              Normally this is used by a command that is used<br>              to authenticate a client.</li>\n<li><strong>&quot;may-replicate&quot;</strong>: This command may generate replication traffic, even<br>                 though it&#39;s not a write command.</li>\n<li><strong>&quot;no-mandatory-keys&quot;</strong>: All the keys this command may take are optional</li>\n<li><strong>&quot;blocking&quot;</strong>: The command has the potential to block the client.</li>\n<li><strong>&quot;allow-busy&quot;</strong>: Permit the command while the server is blocked either by<br>              a script or by a slow module command, see<br>              ValkeyModule_Yield.</li>\n<li><strong>&quot;getchannels-api&quot;</strong>: The command implements the interface to return<br>                   the arguments that are channels.</li>\n</ul>\n<p>The last three parameters specify which arguments of the new command are<br>keys. See <a href=\"https://valkey.io/commands/command\">https://valkey.io/commands/command</a> for more information.</p>\n<ul>\n<li><code>firstkey</code>: One-based index of the first argument that&#39;s a key.<br>        Position 0 is always the command name itself.<br>        0 for commands with no keys.</li>\n<li><code>lastkey</code>:  One-based index of the last argument that&#39;s a key.<br>        Negative numbers refer to counting backwards from the last<br>        argument (-1 means the last argument provided)<br>        0 for commands with no keys.</li>\n<li><code>keystep</code>:  Step between first and last key indexes.<br>        0 for commands with no keys.</li>\n</ul>\n<p>This information is used by ACL, Cluster and the <code>COMMAND</code> command.</p>\n<p>NOTE: The scheme described above serves a limited purpose and can<br>only be used to find keys that exist at constant indices.<br>For non-trivial key arguments, you may pass 0,0,0 and use<br><a href=\"#ValkeyModule_SetCommandInfo\"><code>ValkeyModule_SetCommandInfo</code></a> to set key specs using a more advanced scheme and use<br><a href=\"#ValkeyModule_SetCommandACLCategories\"><code>ValkeyModule_SetCommandACLCategories</code></a> to set ACL categories of the commands.</p>\n<p><span id=\"ValkeyModule_GetCommand\"></span></p>\n<h3><code>ValkeyModule_GetCommand</code></h3>\n<pre><code>ValkeyModuleCommand *ValkeyModule_GetCommand(ValkeyModuleCtx *ctx,\n                                             const char *name);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Get an opaque structure, representing a module command, by command name.<br>This structure is used in some of the command-related APIs.</p>\n<p>NULL is returned in case of the following errors:</p>\n<ul>\n<li>Command not found</li>\n<li>The command is not a module command</li>\n<li>The command doesn&#39;t belong to the calling module</li>\n</ul>\n<p><span id=\"ValkeyModule_CreateSubcommand\"></span></p>\n<h3><code>ValkeyModule_CreateSubcommand</code></h3>\n<pre><code>int ValkeyModule_CreateSubcommand(ValkeyModuleCommand *parent,\n                                  const char *name,\n                                  ValkeyModuleCmdFunc cmdfunc,\n                                  const char *strflags,\n                                  int firstkey,\n                                  int lastkey,\n                                  int keystep);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Very similar to <a href=\"#ValkeyModule_CreateCommand\"><code>ValkeyModule_CreateCommand</code></a> except that it is used to create<br>a subcommand, associated with another, container, command.</p>\n<p>Example: If a module has a configuration command, MODULE.CONFIG, then<br>GET and SET should be individual subcommands, while MODULE.CONFIG is<br>a command, but should not be registered with a valid <code>funcptr</code>:</p>\n<pre><code> if (ValkeyModule_CreateCommand(ctx,&quot;module.config&quot;,NULL,&quot;&quot;,0,0,0) == VALKEYMODULE_ERR)\n     return VALKEYMODULE_ERR;\n\n ValkeyModuleCommand *parent = ValkeyModule_GetCommand(ctx,,&quot;module.config&quot;);\n\n if (ValkeyModule_CreateSubcommand(parent,&quot;set&quot;,cmd_config_set,&quot;&quot;,0,0,0) == VALKEYMODULE_ERR)\n    return VALKEYMODULE_ERR;\n\n if (ValkeyModule_CreateSubcommand(parent,&quot;get&quot;,cmd_config_get,&quot;&quot;,0,0,0) == VALKEYMODULE_ERR)\n    return VALKEYMODULE_ERR;\n</code></pre>\n<p>Returns <code>VALKEYMODULE_OK</code> on success and <code>VALKEYMODULE_ERR</code> in case of the following errors:</p>\n<ul>\n<li>Error while parsing <code>strflags</code></li>\n<li>Command is marked as <code>no-cluster</code> but cluster mode is enabled</li>\n<li><code>parent</code> is already a subcommand (we do not allow more than one level of command nesting)</li>\n<li><code>parent</code> is a command with an implementation (<code>ValkeyModuleCmdFunc</code>) (A parent command should be a pure container of<br>subcommands)</li>\n<li><code>parent</code> already has a subcommand called <code>name</code></li>\n<li>Creating a subcommand is called outside of <code>ValkeyModule_OnLoad</code>.</li>\n</ul>\n<p><span id=\"ValkeyModule_AddACLCategory\"></span></p>\n<h3><code>ValkeyModule_AddACLCategory</code></h3>\n<pre><code>int ValkeyModule_AddACLCategory(ValkeyModuleCtx *ctx, const char *name);\n</code></pre>\n<p><strong>Available since:</strong> 8.0.0</p>\n<p><a href=\"#ValkeyModule_AddACLCategory\"><code>ValkeyModule_AddACLCategory</code></a> can be used to add new ACL command categories. Category names<br>can only contain alphanumeric characters, underscores, or dashes. Categories can only be added<br>during the <code>ValkeyModule_OnLoad</code> function. Once a category has been added, it can not be removed.<br>Any module can register a command to any added categories using <a href=\"#ValkeyModule_SetCommandACLCategories\"><code>ValkeyModule_SetCommandACLCategories</code></a>.</p>\n<p>Returns:</p>\n<ul>\n<li><code>VALKEYMODULE_OK</code> on successfully adding the new ACL category.</li>\n<li><code>VALKEYMODULE_ERR</code> on failure.</li>\n</ul>\n<p>On error the errno is set to:</p>\n<ul>\n<li>EINVAL if the name contains invalid characters.</li>\n<li>EBUSY if the category name already exists.</li>\n<li>ENOMEM if the number of categories reached the max limit of 64 categories.</li>\n</ul>\n<p><span id=\"ValkeyModule_SetCommandACLCategories\"></span></p>\n<h3><code>ValkeyModule_SetCommandACLCategories</code></h3>\n<pre><code>int ValkeyModule_SetCommandACLCategories(ValkeyModuleCommand *command,\n                                         const char *aclflags);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p><a href=\"#ValkeyModule_SetCommandACLCategories\"><code>ValkeyModule_SetCommandACLCategories</code></a> can be used to set ACL categories to module<br>commands and subcommands. The set of ACL categories should be passed as<br>a space separated C string &#39;aclflags&#39;.</p>\n<p>Example, the acl flags &#39;write slow&#39; marks the command as part of the write and<br>slow ACL categories.</p>\n<p>On success <code>VALKEYMODULE_OK</code> is returned. On error <code>VALKEYMODULE_ERR</code> is returned.</p>\n<p>This function can only be called during the <code>ValkeyModule_OnLoad</code> function. If called<br>outside of this function, an error is returned.</p>\n<p><span id=\"ValkeyModule_SetCommandInfo\"></span></p>\n<h3><code>ValkeyModule_SetCommandInfo</code></h3>\n<pre><code>int ValkeyModule_SetCommandInfo(ValkeyModuleCommand *command,\n                                const ValkeyModuleCommandInfo *info);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Set additional command information.</p>\n<p>Affects the output of <code>COMMAND</code>, <code>COMMAND INFO</code> and <code>COMMAND DOCS</code>, Cluster,<br>ACL and is used to filter commands with the wrong number of arguments before<br>the call reaches the module code.</p>\n<p>This function can be called after creating a command using <a href=\"#ValkeyModule_CreateCommand\"><code>ValkeyModule_CreateCommand</code></a><br>and fetching the command pointer using <a href=\"#ValkeyModule_GetCommand\"><code>ValkeyModule_GetCommand</code></a>. The information can<br>only be set once for each command and has the following structure:</p>\n<pre><code>typedef struct ValkeyModuleCommandInfo {\n    const ValkeyModuleCommandInfoVersion *version;\n    const char *summary;\n    const char *complexity;\n    const char *since;\n    ValkeyModuleCommandHistoryEntry *history;\n    const char *tips;\n    int arity;\n    ValkeyModuleCommandKeySpec *key_specs;\n    ValkeyModuleCommandArg *args;\n} ValkeyModuleCommandInfo;\n</code></pre>\n<p>All fields except <code>version</code> are optional. Explanation of the fields:</p>\n<ul>\n<li><p><code>version</code>: This field enables compatibility with different server versions.<br>Always set this field to <code>VALKEYMODULE_COMMAND_INFO_VERSION</code>.</p>\n</li>\n<li><p><code>summary</code>: A short description of the command (optional).</p>\n</li>\n<li><p><code>complexity</code>: Complexity description (optional).</p>\n</li>\n<li><p><code>since</code>: The version where the command was introduced (optional).<br>Note: The version specified should be the module&#39;s, not the server version.</p>\n</li>\n<li><p><code>history</code>: An array of <code>ValkeyModuleCommandHistoryEntry</code> (optional), which is<br>a struct with the following fields:</p>\n<pre><code>  const char *since;\n  const char *changes;\n</code></pre>\n<p>  <code>since</code> is a version string and <code>changes</code> is a string describing the<br>  changes. The array is terminated by a zeroed entry, i.e. an entry with<br>  both strings set to NULL.</p>\n</li>\n<li><p><code>tips</code>: A string of space-separated tips regarding this command, meant for<br>clients and proxies. See <a href=\"https://valkey.io/topics/command-tips\">https://valkey.io/topics/command-tips</a>.</p>\n</li>\n<li><p><code>arity</code>: Number of arguments, including the command name itself. A positive<br>number specifies an exact number of arguments and a negative number<br>specifies a minimum number of arguments, so use -N to say &gt;= N. The server<br>validates a call before passing it to a module, so this can replace an<br>arity check inside the module command implementation. A value of 0 (or an<br>omitted arity field) is equivalent to -2 if the command has sub commands<br>and -1 otherwise.</p>\n</li>\n<li><p><code>key_specs</code>: An array of <code>ValkeyModuleCommandKeySpec</code>, terminated by an<br>element memset to zero. This is a scheme that tries to describe the<br>positions of key arguments better than the old <a href=\"#ValkeyModule_CreateCommand\"><code>ValkeyModule_CreateCommand</code></a> arguments<br><code>firstkey</code>, <code>lastkey</code>, <code>keystep</code> and is needed if those three are not<br>enough to describe the key positions. There are two steps to retrieve key<br>positions: <em>begin search</em> (BS) in which index should find the first key and<br><em>find keys</em> (FK) which, relative to the output of BS, describes how can we<br>will which arguments are keys. Additionally, there are key specific flags.</p>\n<p>  Key-specs cause the triplet (firstkey, lastkey, keystep) given in<br>  ValkeyModule_CreateCommand to be recomputed, but it is still useful to provide<br>  these three parameters in ValkeyModule_CreateCommand, to better support old server<br>  versions where ValkeyModule_SetCommandInfo is not available.</p>\n<p>  Note that key-specs don&#39;t fully replace the &quot;getkeys-api&quot; (see<br>  ValkeyModule_CreateCommand, ValkeyModule_IsKeysPositionRequest and ValkeyModule_KeyAtPosWithFlags) so<br>  it may be a good idea to supply both key-specs and implement the<br>  getkeys-api.</p>\n<p>  A key-spec has the following structure:</p>\n<pre><code>  typedef struct ValkeyModuleCommandKeySpec {\n      const char *notes;\n      uint64_t flags;\n      ValkeyModuleKeySpecBeginSearchType begin_search_type;\n      union {\n          struct {\n              int pos;\n          } index;\n          struct {\n              const char *keyword;\n              int startfrom;\n          } keyword;\n      } bs;\n      ValkeyModuleKeySpecFindKeysType find_keys_type;\n      union {\n          struct {\n              int lastkey;\n              int keystep;\n              int limit;\n          } range;\n          struct {\n              int keynumidx;\n              int firstkey;\n              int keystep;\n          } keynum;\n      } fk;\n  } ValkeyModuleCommandKeySpec;\n</code></pre>\n<p>  Explanation of the fields of ValkeyModuleCommandKeySpec:</p>\n<ul>\n<li><p><code>notes</code>: Optional notes or clarifications about this key spec.</p>\n</li>\n<li><p><code>flags</code>: A bitwise or of key-spec flags described below.</p>\n</li>\n<li><p><code>begin_search_type</code>: This describes how the first key is discovered.<br>There are two ways to determine the first key:</p>\n<ul>\n<li><code>VALKEYMODULE_KSPEC_BS_UNKNOWN</code>: There is no way to tell where the<br>key args start.</li>\n<li><code>VALKEYMODULE_KSPEC_BS_INDEX</code>: Key args start at a constant index.</li>\n<li><code>VALKEYMODULE_KSPEC_BS_KEYWORD</code>: Key args start just after a<br>specific keyword.</li>\n</ul>\n</li>\n<li><p><code>bs</code>: This is a union in which the <code>index</code> or <code>keyword</code> branch is used<br>depending on the value of the <code>begin_search_type</code> field.</p>\n<ul>\n<li><p><code>bs.index.pos</code>: The index from which we start the search for keys.<br>(<code>VALKEYMODULE_KSPEC_BS_INDEX</code> only.)</p>\n</li>\n<li><p><code>bs.keyword.keyword</code>: The keyword (string) that indicates the<br>beginning of key arguments. (<code>VALKEYMODULE_KSPEC_BS_KEYWORD</code> only.)</p>\n</li>\n<li><p><code>bs.keyword.startfrom</code>: An index in argv from which to start<br>searching. Can be negative, which means start search from the end,<br>in reverse. Example: -2 means to start in reverse from the<br>penultimate argument. (<code>VALKEYMODULE_KSPEC_BS_KEYWORD</code> only.)</p>\n</li>\n</ul>\n</li>\n<li><p><code>find_keys_type</code>: After the &quot;begin search&quot;, this describes which<br>arguments are keys. The strategies are:</p>\n<ul>\n<li><code>VALKEYMODULE_KSPEC_BS_UNKNOWN</code>: There is no way to tell where the<br>key args are located.</li>\n<li><code>VALKEYMODULE_KSPEC_FK_RANGE</code>: Keys end at a specific index (or<br>relative to the last argument).</li>\n<li><code>VALKEYMODULE_KSPEC_FK_KEYNUM</code>: There&#39;s an argument that contains<br>the number of key args somewhere before the keys themselves.</li>\n</ul>\n<p><code>find_keys_type</code> and <code>fk</code> can be omitted if this keyspec describes<br>exactly one key.</p>\n</li>\n<li><p><code>fk</code>: This is a union in which the <code>range</code> or <code>keynum</code> branch is used<br>depending on the value of the <code>find_keys_type</code> field.</p>\n<ul>\n<li><p><code>fk.range</code> (for <code>VALKEYMODULE_KSPEC_FK_RANGE</code>): A struct with the<br>following fields:</p>\n<ul>\n<li><p><code>lastkey</code>: Index of the last key relative to the result of the<br>begin search step. Can be negative, in which case it&#39;s not<br>relative. -1 indicates the last argument, -2 one before the<br>last and so on.</p>\n</li>\n<li><p><code>keystep</code>: How many arguments should we skip after finding a<br>key, in order to find the next one?</p>\n</li>\n<li><p><code>limit</code>: If <code>lastkey</code> is -1, we use <code>limit</code> to stop the search<br>by a factor. 0 and 1 mean no limit. 2 means 1/2 of the<br>remaining args, 3 means 1/3, and so on.</p>\n</li>\n</ul>\n</li>\n<li><p><code>fk.keynum</code> (for <code>VALKEYMODULE_KSPEC_FK_KEYNUM</code>): A struct with the<br>following fields:</p>\n<ul>\n<li><p><code>keynumidx</code>: Index of the argument containing the number of<br>keys to come, relative to the result of the begin search step.</p>\n</li>\n<li><p><code>firstkey</code>: Index of the fist key relative to the result of the<br>begin search step. (Usually it&#39;s just after <code>keynumidx</code>, in<br>which case it should be set to <code>keynumidx + 1</code>.)</p>\n</li>\n<li><p><code>keystep</code>: How many arguments should we skip after finding a<br>key, in order to find the next one?</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>  Key-spec flags:</p>\n<p>  The first four refer to what the command actually does with the <em>value or<br>  metadata of the key</em>, and not necessarily the user data or how it affects<br>  it. Each key-spec may must have exactly one of these. Any operation<br>  that&#39;s not distinctly deletion, overwrite or read-only would be marked as<br>  RW.</p>\n<ul>\n<li><p><code>VALKEYMODULE_CMD_KEY_RO</code>: Read-Only. Reads the value of the key, but<br>doesn&#39;t necessarily return it.</p>\n</li>\n<li><p><code>VALKEYMODULE_CMD_KEY_RW</code>: Read-Write. Modifies the data stored in the<br>value of the key or its metadata.</p>\n</li>\n<li><p><code>VALKEYMODULE_CMD_KEY_OW</code>: Overwrite. Overwrites the data stored in the<br>value of the key.</p>\n</li>\n<li><p><code>VALKEYMODULE_CMD_KEY_RM</code>: Deletes the key.</p>\n</li>\n</ul>\n<p>  The next four refer to <em>user data inside the value of the key</em>, not the<br>  metadata like LRU, type, cardinality. It refers to the logical operation<br>  on the user&#39;s data (actual input strings or TTL), being<br>  used/returned/copied/changed. It doesn&#39;t refer to modification or<br>  returning of metadata (like type, count, presence of data). ACCESS can be<br>  combined with one of the write operations INSERT, DELETE or UPDATE. Any<br>  write that&#39;s not an INSERT or a DELETE would be UPDATE.</p>\n<ul>\n<li><p><code>VALKEYMODULE_CMD_KEY_ACCESS</code>: Returns, copies or uses the user data<br>from the value of the key.</p>\n</li>\n<li><p><code>VALKEYMODULE_CMD_KEY_UPDATE</code>: Updates data to the value, new value may<br>depend on the old value.</p>\n</li>\n<li><p><code>VALKEYMODULE_CMD_KEY_INSERT</code>: Adds data to the value with no chance of<br>modification or deletion of existing data.</p>\n</li>\n<li><p><code>VALKEYMODULE_CMD_KEY_DELETE</code>: Explicitly deletes some content from the<br>value of the key.</p>\n</li>\n</ul>\n<p>  Other flags:</p>\n<ul>\n<li><p><code>VALKEYMODULE_CMD_KEY_NOT_KEY</code>: The key is not actually a key, but<br>should be routed in cluster mode as if it was a key.</p>\n</li>\n<li><p><code>VALKEYMODULE_CMD_KEY_INCOMPLETE</code>: The keyspec might not point out all<br>the keys it should cover.</p>\n</li>\n<li><p><code>VALKEYMODULE_CMD_KEY_VARIABLE_FLAGS</code>: Some keys might have different<br>flags depending on arguments.</p>\n</li>\n</ul>\n</li>\n<li><p><code>args</code>: An array of <code>ValkeyModuleCommandArg</code>, terminated by an element memset<br>to zero. <code>ValkeyModuleCommandArg</code> is a structure with at the fields described<br>below.</p>\n<pre><code>  typedef struct ValkeyModuleCommandArg {\n      const char *name;\n      ValkeyModuleCommandArgType type;\n      int key_spec_index;\n      const char *token;\n      const char *summary;\n      const char *since;\n      int flags;\n      struct ValkeyModuleCommandArg *subargs;\n  } ValkeyModuleCommandArg;\n</code></pre>\n<p>  Explanation of the fields:</p>\n<ul>\n<li><p><code>name</code>: Name of the argument.</p>\n</li>\n<li><p><code>type</code>: The type of the argument. See below for details. The types<br><code>VALKEYMODULE_ARG_TYPE_ONEOF</code> and <code>VALKEYMODULE_ARG_TYPE_BLOCK</code> require<br>an argument to have sub-arguments, i.e. <code>subargs</code>.</p>\n</li>\n<li><p><code>key_spec_index</code>: If the <code>type</code> is <code>VALKEYMODULE_ARG_TYPE_KEY</code> you must<br>provide the index of the key-spec associated with this argument. See<br><code>key_specs</code> above. If the argument is not a key, you may specify -1.</p>\n</li>\n<li><p><code>token</code>: The token preceding the argument (optional). Example: the<br>argument <code>seconds</code> in <code>SET</code> has a token <code>EX</code>. If the argument consists<br>of only a token (for example <code>NX</code> in <code>SET</code>) the type should be<br><code>VALKEYMODULE_ARG_TYPE_PURE_TOKEN</code> and <code>value</code> should be NULL.</p>\n</li>\n<li><p><code>summary</code>: A short description of the argument (optional).</p>\n</li>\n<li><p><code>since</code>: The first version which included this argument (optional).</p>\n</li>\n<li><p><code>flags</code>: A bitwise or of the macros <code>VALKEYMODULE_CMD_ARG_*</code>. See below.</p>\n</li>\n<li><p><code>value</code>: The display-value of the argument. This string is what should<br>be displayed when creating the command syntax from the output of<br><code>COMMAND</code>. If <code>token</code> is not NULL, it should also be displayed.</p>\n</li>\n</ul>\n<p>  Explanation of <code>ValkeyModuleCommandArgType</code>:</p>\n<ul>\n<li><code>VALKEYMODULE_ARG_TYPE_STRING</code>: String argument.</li>\n<li><code>VALKEYMODULE_ARG_TYPE_INTEGER</code>: Integer argument.</li>\n<li><code>VALKEYMODULE_ARG_TYPE_DOUBLE</code>: Double-precision float argument.</li>\n<li><code>VALKEYMODULE_ARG_TYPE_KEY</code>: String argument representing a keyname.</li>\n<li><code>VALKEYMODULE_ARG_TYPE_PATTERN</code>: String, but regex pattern.</li>\n<li><code>VALKEYMODULE_ARG_TYPE_UNIX_TIME</code>: Integer, but Unix timestamp.</li>\n<li><code>VALKEYMODULE_ARG_TYPE_PURE_TOKEN</code>: Argument doesn&#39;t have a placeholder.<br>It&#39;s just a token without a value. Example: the <code>KEEPTTL</code> option of the<br><code>SET</code> command.</li>\n<li><code>VALKEYMODULE_ARG_TYPE_ONEOF</code>: Used when the user can choose only one of<br>a few sub-arguments. Requires <code>subargs</code>. Example: the <code>NX</code> and <code>XX</code><br>options of <code>SET</code>.</li>\n<li><code>VALKEYMODULE_ARG_TYPE_BLOCK</code>: Used when one wants to group together<br>several sub-arguments, usually to apply something on all of them, like<br>making the entire group &quot;optional&quot;. Requires <code>subargs</code>. Example: the<br><code>LIMIT offset count</code> parameters in <code>ZRANGE</code>.</li>\n</ul>\n<p>  Explanation of the command argument flags:</p>\n<ul>\n<li><code>VALKEYMODULE_CMD_ARG_OPTIONAL</code>: The argument is optional (like GET in<br>the SET command).</li>\n<li><code>VALKEYMODULE_CMD_ARG_MULTIPLE</code>: The argument may repeat itself (like<br>key in DEL).</li>\n<li><code>VALKEYMODULE_CMD_ARG_MULTIPLE_TOKEN</code>: The argument may repeat itself,<br>and so does its token (like <code>GET pattern</code> in SORT).</li>\n</ul>\n</li>\n</ul>\n<p>On success <code>VALKEYMODULE_OK</code> is returned. On error <code>VALKEYMODULE_ERR</code> is returned<br>and <code>errno</code> is set to EINVAL if invalid info was provided or EEXIST if info<br>has already been set. If the info is invalid, a warning is logged explaining<br>which part of the info is invalid and why.</p>\n<p><span id=\"ValkeyModule_UpdateRuntimeArgs\"></span></p>\n<h3><code>ValkeyModule_UpdateRuntimeArgs</code></h3>\n<pre><code>int ValkeyModule_UpdateRuntimeArgs(ValkeyModuleCtx *ctx,\n                                   ValkeyModuleString **argv,\n                                   int argc);\n</code></pre>\n<p><strong>Available since:</strong> 8.1.0</p>\n<p><a href=\"#ValkeyModule_UpdateRuntimeArgs\"><code>ValkeyModule_UpdateRuntimeArgs</code></a> can be used to update the module argument values.<br>The function parameter &#39;argc&#39; indicates the number of updated arguments, and &#39;argv&#39;<br>represents the values of the updated arguments.<br>Once &#39;CONFIG REWRITE&#39; command is called, the updated argument values can be saved into conf file.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"section-module-information-and-time-measurement\"></span></p>\n<h2>Module information and time measurement</h2>\n<p><span id=\"ValkeyModule_IsModuleNameBusy\"></span></p>\n<h3><code>ValkeyModule_IsModuleNameBusy</code></h3>\n<pre><code>int ValkeyModule_IsModuleNameBusy(const char *name);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.3</p>\n<p>Return non-zero if the module name is busy.<br>Otherwise zero is returned.</p>\n<p><span id=\"ValkeyModule_Milliseconds\"></span></p>\n<h3><code>ValkeyModule_Milliseconds</code></h3>\n<pre><code>mstime_t ValkeyModule_Milliseconds(void);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return the current UNIX time in milliseconds.</p>\n<p><span id=\"ValkeyModule_MonotonicMicroseconds\"></span></p>\n<h3><code>ValkeyModule_MonotonicMicroseconds</code></h3>\n<pre><code>uint64_t ValkeyModule_MonotonicMicroseconds(void);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Return counter of micro-seconds relative to an arbitrary point in time.</p>\n<p><span id=\"ValkeyModule_Microseconds\"></span></p>\n<h3><code>ValkeyModule_Microseconds</code></h3>\n<pre><code>ustime_t ValkeyModule_Microseconds(void);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Return the current UNIX time in microseconds</p>\n<p><span id=\"ValkeyModule_CachedMicroseconds\"></span></p>\n<h3><code>ValkeyModule_CachedMicroseconds</code></h3>\n<pre><code>ustime_t ValkeyModule_CachedMicroseconds(void);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Return the cached UNIX time in microseconds.<br>It is updated in the server cron job and before executing a command.<br>It is useful for complex call stacks, such as a command causing a<br>key space notification, causing a module to execute a <a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call</code></a>,<br>causing another notification, etc.<br>It makes sense that all this callbacks would use the same clock.</p>\n<p><span id=\"ValkeyModule_BlockedClientMeasureTimeStart\"></span></p>\n<h3><code>ValkeyModule_BlockedClientMeasureTimeStart</code></h3>\n<pre><code>int ValkeyModule_BlockedClientMeasureTimeStart(ValkeyModuleBlockedClient *bc);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Mark a point in time that will be used as the start time to calculate<br>the elapsed execution time when <a href=\"#ValkeyModule_BlockedClientMeasureTimeEnd\"><code>ValkeyModule_BlockedClientMeasureTimeEnd()</code></a> is called.<br>Within the same command, you can call multiple times<br><a href=\"#ValkeyModule_BlockedClientMeasureTimeStart\"><code>ValkeyModule_BlockedClientMeasureTimeStart()</code></a> and <a href=\"#ValkeyModule_BlockedClientMeasureTimeEnd\"><code>ValkeyModule_BlockedClientMeasureTimeEnd()</code></a><br>to accumulate independent time intervals to the background duration.<br>This method always return <code>VALKEYMODULE_OK</code>.</p>\n<p>This function is not thread safe, If used in module thread and blocked callback (possibly main thread)<br>simultaneously, it&#39;s recommended to protect them with lock owned by caller instead of GIL.</p>\n<p><span id=\"ValkeyModule_BlockedClientMeasureTimeEnd\"></span></p>\n<h3><code>ValkeyModule_BlockedClientMeasureTimeEnd</code></h3>\n<pre><code>int ValkeyModule_BlockedClientMeasureTimeEnd(ValkeyModuleBlockedClient *bc);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Mark a point in time that will be used as the end time<br>to calculate the elapsed execution time.<br>On success <code>VALKEYMODULE_OK</code> is returned.<br>This method only returns <code>VALKEYMODULE_ERR</code> if no start time was<br>previously defined ( meaning <a href=\"#ValkeyModule_BlockedClientMeasureTimeStart\"><code>ValkeyModule_BlockedClientMeasureTimeStart</code></a> was not called ).</p>\n<p>This function is not thread safe, If used in module thread and blocked callback (possibly main thread)<br>simultaneously, it&#39;s recommended to protect them with lock owned by caller instead of GIL.</p>\n<p><span id=\"ValkeyModule_Yield\"></span></p>\n<h3><code>ValkeyModule_Yield</code></h3>\n<pre><code>void ValkeyModule_Yield(ValkeyModuleCtx *ctx,\n                        int flags,\n                        const char *busy_reply);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>This API allows modules to let the server process background tasks, and some<br>commands during long blocking execution of a module command.<br>The module can call this API periodically.<br>The flags is a bit mask of these:</p>\n<ul>\n<li><code>VALKEYMODULE_YIELD_FLAG_NONE</code>: No special flags, can perform some background<br>                           operations, but not process client commands.</li>\n<li><code>VALKEYMODULE_YIELD_FLAG_CLIENTS</code>: The server can also process client commands.</li>\n</ul>\n<p>The <code>busy_reply</code> argument is optional, and can be used to control the verbose<br>error string after the <code>-BUSY</code> error code.</p>\n<p>When the <code>VALKEYMODULE_YIELD_FLAG_CLIENTS</code> is used, the server will only start<br>processing client commands after the time defined by the<br><code>busy-reply-threshold</code> config, in which case the server will start rejecting most<br>commands with <code>-BUSY</code> error, but allow the ones marked with the <code>allow-busy</code><br>flag to be executed.<br>This API can also be used in thread safe context (while locked), and during<br>loading (in the <code>rdb_load</code> callback, in which case it&#39;ll reject commands with<br>the -LOADING error)</p>\n<p><span id=\"ValkeyModule_SetModuleOptions\"></span></p>\n<h3><code>ValkeyModule_SetModuleOptions</code></h3>\n<pre><code>void ValkeyModule_SetModuleOptions(ValkeyModuleCtx *ctx, int options);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Set flags defining capabilities or behavior bit flags.</p>\n<p><code>VALKEYMODULE_OPTIONS_HANDLE_IO_ERRORS</code>:<br>Generally, modules don&#39;t need to bother with this, as the process will just<br>terminate if a read error happens, however, setting this flag would allow<br>repl-diskless-load to work if enabled.<br>The module should use <a href=\"#ValkeyModule_IsIOError\"><code>ValkeyModule_IsIOError</code></a> after reads, before using the<br>data that was read, and in case of error, propagate it upwards, and also be<br>able to release the partially populated value and all it&#39;s allocations.</p>\n<p><code>VALKEYMODULE_OPTION_NO_IMPLICIT_SIGNAL_MODIFIED</code>:<br>See <a href=\"#ValkeyModule_SignalModifiedKey\"><code>ValkeyModule_SignalModifiedKey()</code></a>.</p>\n<p><code>VALKEYMODULE_OPTIONS_HANDLE_REPL_ASYNC_LOAD</code>:<br>Setting this flag indicates module awareness of diskless async replication (repl-diskless-load=swapdb)<br>and that the server could be serving reads during replication instead of blocking with LOADING status.</p>\n<p><code>VALKEYMODULE_OPTIONS_ALLOW_NESTED_KEYSPACE_NOTIFICATIONS</code>:<br>Declare that the module wants to get nested key-space notifications.<br>By default, the server will not fire key-space notifications that happened inside<br>a key-space notification callback. This flag allows to change this behavior<br>and fire nested key-space notifications. Notice: if enabled, the module<br>should protected itself from infinite recursion.</p>\n<p><code>VALKEYMODULE_OPTIONS_SKIP_COMMAND_VALIDATION</code>:<br>When set, this option allows the module to skip command validation.<br>This is useful in scenarios where the module needs to bypass<br>command validation for specific operations<br>to reduce overhead or handle trusted custom command logic.<br><a href=\"#ValkeyModule_Replicate\"><code>ValkeyModule_Replicate</code></a> and <a href=\"#ValkeyModule_EmitAOF\"><code>ValkeyModule_EmitAOF</code></a><br>are affected by this option, allowing them to operate without<br>command validation check.</p>\n<p><span id=\"ValkeyModule_SignalModifiedKey\"></span></p>\n<h3><code>ValkeyModule_SignalModifiedKey</code></h3>\n<pre><code>int ValkeyModule_SignalModifiedKey(ValkeyModuleCtx *ctx,\n                                   ValkeyModuleString *keyname);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Signals that the key is modified from user&#39;s perspective (i.e. invalidate WATCH<br>and client side caching).</p>\n<p>This is done automatically when a key opened for writing is closed, unless<br>the option <code>VALKEYMODULE_OPTION_NO_IMPLICIT_SIGNAL_MODIFIED</code> has been set using<br><a href=\"#ValkeyModule_SetModuleOptions\"><code>ValkeyModule_SetModuleOptions()</code></a>.</p>\n<p><span id=\"section-automatic-memory-management-for-modules\"></span></p>\n<h2>Automatic memory management for modules</h2>\n<p><span id=\"ValkeyModule_AutoMemory\"></span></p>\n<h3><code>ValkeyModule_AutoMemory</code></h3>\n<pre><code>void ValkeyModule_AutoMemory(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Enable automatic memory management.</p>\n<p>The function must be called as the first function of a command implementation<br>that wants to use automatic memory.</p>\n<p>When enabled, automatic memory management tracks and automatically frees<br>keys, call replies and <code>ValkeyModuleString</code> objects once the command returns. In most<br>cases this eliminates the need of calling the following functions:</p>\n<ol>\n<li><a href=\"#ValkeyModule_CloseKey\"><code>ValkeyModule_CloseKey()</code></a></li>\n<li><a href=\"#ValkeyModule_FreeCallReply\"><code>ValkeyModule_FreeCallReply()</code></a></li>\n<li><a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a></li>\n</ol>\n<p>These functions can still be used with automatic memory management enabled,<br>to optimize loops that make numerous allocations for example.</p>\n<p><span id=\"section-string-objects-apis\"></span></p>\n<h2>String objects APIs</h2>\n<p><span id=\"ValkeyModule_CreateString\"></span></p>\n<h3><code>ValkeyModule_CreateString</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_CreateString(ValkeyModuleCtx *ctx,\n                                              const char *ptr,\n                                              size_t len);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Create a new module string object. The returned string must be freed<br>with <a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a>, unless automatic memory is enabled.</p>\n<p>The string is created by copying the <code>len</code> bytes starting<br>at <code>ptr</code>. No reference is retained to the passed buffer.</p>\n<p>The module context &#39;ctx&#39; is optional and may be NULL if you want to create<br>a string out of the context scope. However in that case, the automatic<br>memory management will not be available, and the string memory must be<br>managed manually.</p>\n<p><span id=\"ValkeyModule_CreateStringPrintf\"></span></p>\n<h3><code>ValkeyModule_CreateStringPrintf</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_CreateStringPrintf(ValkeyModuleCtx *ctx,\n                                                    const char *fmt,\n                                                    ...);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Create a new module string object from a printf format and arguments.<br>The returned string must be freed with <a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a>, unless<br>automatic memory is enabled.</p>\n<p>The string is created using the sds formatter function <code>sdscatvprintf()</code>.</p>\n<p>The passed context &#39;ctx&#39; may be NULL if necessary, see the<br><a href=\"#ValkeyModule_CreateString\"><code>ValkeyModule_CreateString()</code></a> documentation for more info.</p>\n<p><span id=\"ValkeyModule_CreateStringFromLongLong\"></span></p>\n<h3><code>ValkeyModule_CreateStringFromLongLong</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_CreateStringFromLongLong(ValkeyModuleCtx *ctx,\n                                                          long long ll);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Like <a href=\"#ValkeyModule_CreateString\"><code>ValkeyModule_CreateString()</code></a>, but creates a string starting from a <code>long long</code><br>integer instead of taking a buffer and its length.</p>\n<p>The returned string must be released with <a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a> or by<br>enabling automatic memory management.</p>\n<p>The passed context &#39;ctx&#39; may be NULL if necessary, see the<br><a href=\"#ValkeyModule_CreateString\"><code>ValkeyModule_CreateString()</code></a> documentation for more info.</p>\n<p><span id=\"ValkeyModule_CreateStringFromULongLong\"></span></p>\n<h3><code>ValkeyModule_CreateStringFromULongLong</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_CreateStringFromULongLong(ValkeyModuleCtx *ctx,\n                                                           unsigned long long ull);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.3</p>\n<p>Like <a href=\"#ValkeyModule_CreateString\"><code>ValkeyModule_CreateString()</code></a>, but creates a string starting from a <code>unsigned long long</code><br>integer instead of taking a buffer and its length.</p>\n<p>The returned string must be released with <a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a> or by<br>enabling automatic memory management.</p>\n<p>The passed context &#39;ctx&#39; may be NULL if necessary, see the<br><a href=\"#ValkeyModule_CreateString\"><code>ValkeyModule_CreateString()</code></a> documentation for more info.</p>\n<p><span id=\"ValkeyModule_CreateStringFromDouble\"></span></p>\n<h3><code>ValkeyModule_CreateStringFromDouble</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_CreateStringFromDouble(ValkeyModuleCtx *ctx,\n                                                        double d);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Like <a href=\"#ValkeyModule_CreateString\"><code>ValkeyModule_CreateString()</code></a>, but creates a string starting from a double<br>instead of taking a buffer and its length.</p>\n<p>The returned string must be released with <a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a> or by<br>enabling automatic memory management.</p>\n<p><span id=\"ValkeyModule_CreateStringFromLongDouble\"></span></p>\n<h3><code>ValkeyModule_CreateStringFromLongDouble</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_CreateStringFromLongDouble(ValkeyModuleCtx *ctx,\n                                                            long double ld,\n                                                            int humanfriendly);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Like <a href=\"#ValkeyModule_CreateString\"><code>ValkeyModule_CreateString()</code></a>, but creates a string starting from a long<br>double.</p>\n<p>The returned string must be released with <a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a> or by<br>enabling automatic memory management.</p>\n<p>The passed context &#39;ctx&#39; may be NULL if necessary, see the<br><a href=\"#ValkeyModule_CreateString\"><code>ValkeyModule_CreateString()</code></a> documentation for more info.</p>\n<p><span id=\"ValkeyModule_CreateStringFromString\"></span></p>\n<h3><code>ValkeyModule_CreateStringFromString</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_CreateStringFromString(ValkeyModuleCtx *ctx,\n                                                        const ValkeyModuleString *str);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Like <a href=\"#ValkeyModule_CreateString\"><code>ValkeyModule_CreateString()</code></a>, but creates a string starting from another<br><code>ValkeyModuleString</code>.</p>\n<p>The returned string must be released with <a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a> or by<br>enabling automatic memory management.</p>\n<p>The passed context &#39;ctx&#39; may be NULL if necessary, see the<br><a href=\"#ValkeyModule_CreateString\"><code>ValkeyModule_CreateString()</code></a> documentation for more info.</p>\n<p><span id=\"ValkeyModule_CreateStringFromStreamID\"></span></p>\n<h3><code>ValkeyModule_CreateStringFromStreamID</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_CreateStringFromStreamID(ValkeyModuleCtx *ctx,\n                                                          const ValkeyModuleStreamID *id);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Creates a string from a stream ID. The returned string must be released with<br><a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a>, unless automatic memory is enabled.</p>\n<p>The passed context <code>ctx</code> may be NULL if necessary. See the<br><a href=\"#ValkeyModule_CreateString\"><code>ValkeyModule_CreateString()</code></a> documentation for more info.</p>\n<p><span id=\"ValkeyModule_FreeString\"></span></p>\n<h3><code>ValkeyModule_FreeString</code></h3>\n<pre><code>void ValkeyModule_FreeString(ValkeyModuleCtx *ctx, ValkeyModuleString *str);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Free a module string object obtained with one of the module API calls<br>that return new string objects.</p>\n<p>It is possible to call this function even when automatic memory management<br>is enabled. In that case the string will be released ASAP and removed<br>from the pool of string to release at the end.</p>\n<p>If the string was created with a NULL context &#39;ctx&#39;, it is also possible to<br>pass ctx as NULL when releasing the string (but passing a context will not<br>create any issue). Strings created with a context should be freed also passing<br>the context, so if you want to free a string out of context later, make sure<br>to create it using a NULL context.</p>\n<p>This API is not thread safe, access to these retained strings (if they originated<br>from a client command arguments) must be done with GIL locked.</p>\n<p><span id=\"ValkeyModule_RetainString\"></span></p>\n<h3><code>ValkeyModule_RetainString</code></h3>\n<pre><code>void ValkeyModule_RetainString(ValkeyModuleCtx *ctx, ValkeyModuleString *str);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Every call to this function, will make the string &#39;str&#39; requiring<br>an additional call to <a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a> in order to really<br>free the string. Note that the automatic freeing of the string obtained<br>enabling modules automatic memory management counts for one<br><a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a> call (it is just executed automatically).</p>\n<p>Normally you want to call this function when, at the same time<br>the following conditions are true:</p>\n<ol>\n<li>You have automatic memory management enabled.</li>\n<li>You want to create string objects.</li>\n<li>Those string objects you create need to live <em>after</em> the callback<br>function(for example a command implementation) creating them returns.</li>\n</ol>\n<p>Usually you want this in order to store the created string object<br>into your own data structure, for example when implementing a new data<br>type.</p>\n<p>Note that when memory management is turned off, you don&#39;t need<br>any call to RetainString() since creating a string will always result<br>into a string that lives after the callback function returns, if<br>no FreeString() call is performed.</p>\n<p>It is possible to call this function with a NULL context.</p>\n<p>When strings are going to be retained for an extended duration, it is good<br>practice to also call <a href=\"#ValkeyModule_TrimStringAllocation\"><code>ValkeyModule_TrimStringAllocation()</code></a> in order to<br>optimize memory usage.</p>\n<p>Threaded modules that reference retained strings from other threads <em>must</em><br>explicitly trim the allocation as soon as the string is retained. Not doing<br>so may result with automatic trimming which is not thread safe.</p>\n<p>This API is not thread safe, access to these retained strings (if they originated<br>from a client command arguments) must be done with GIL locked.</p>\n<p><span id=\"ValkeyModule_HoldString\"></span></p>\n<h3><code>ValkeyModule_HoldString</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_HoldString(ValkeyModuleCtx *ctx,\n                                            ValkeyModuleString *str);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.7</p>\n<p>This function can be used instead of <a href=\"#ValkeyModule_RetainString\"><code>ValkeyModule_RetainString()</code></a>.<br>The main difference between the two is that this function will always<br>succeed, whereas <a href=\"#ValkeyModule_RetainString\"><code>ValkeyModule_RetainString()</code></a> may fail because of an<br>assertion.</p>\n<p>The function returns a pointer to <code>ValkeyModuleString</code>, which is owned<br>by the caller. It requires a call to <a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a> to free<br>the string when automatic memory management is disabled for the context.<br>When automatic memory management is enabled, you can either call<br><a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a> or let the automation free it.</p>\n<p>This function is more efficient than <a href=\"#ValkeyModule_CreateStringFromString\"><code>ValkeyModule_CreateStringFromString()</code></a><br>because whenever possible, it avoids copying the underlying<br><code>ValkeyModuleString</code>. The disadvantage of using this function is that it<br>might not be possible to use <a href=\"#ValkeyModule_StringAppendBuffer\"><code>ValkeyModule_StringAppendBuffer()</code></a> on the<br>returned <code>ValkeyModuleString</code>.</p>\n<p>It is possible to call this function with a NULL context.</p>\n<p>When strings are going to be held for an extended duration, it is good<br>practice to also call <a href=\"#ValkeyModule_TrimStringAllocation\"><code>ValkeyModule_TrimStringAllocation()</code></a> in order to<br>optimize memory usage.</p>\n<p>Threaded modules that reference held strings from other threads <em>must</em><br>explicitly trim the allocation as soon as the string is held. Not doing<br>so may result with automatic trimming which is not thread safe.</p>\n<p>This API is not thread safe, access to these retained strings (if they originated<br>from a client command arguments) must be done with GIL locked.</p>\n<p><span id=\"ValkeyModule_StringPtrLen\"></span></p>\n<h3><code>ValkeyModule_StringPtrLen</code></h3>\n<pre><code>const char *ValkeyModule_StringPtrLen(const ValkeyModuleString *str,\n                                      size_t *len);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Given a string module object, this function returns the string pointer<br>and length of the string. The returned pointer and length should only<br>be used for read only accesses and never modified.</p>\n<p><span id=\"ValkeyModule_StringToLongLong\"></span></p>\n<h3><code>ValkeyModule_StringToLongLong</code></h3>\n<pre><code>int ValkeyModule_StringToLongLong(const ValkeyModuleString *str,\n                                  long long *ll);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Convert the string into a <code>long long</code> integer, storing it at <code>*ll</code>.<br>Returns <code>VALKEYMODULE_OK</code> on success. If the string can&#39;t be parsed<br>as a valid, strict <code>long long</code> (no spaces before/after), <code>VALKEYMODULE_ERR</code><br>is returned.</p>\n<p><span id=\"ValkeyModule_StringToULongLong\"></span></p>\n<h3><code>ValkeyModule_StringToULongLong</code></h3>\n<pre><code>int ValkeyModule_StringToULongLong(const ValkeyModuleString *str,\n                                   unsigned long long *ull);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.3</p>\n<p>Convert the string into a <code>unsigned long long</code> integer, storing it at <code>*ull</code>.<br>Returns <code>VALKEYMODULE_OK</code> on success. If the string can&#39;t be parsed<br>as a valid, strict <code>unsigned long long</code> (no spaces before/after), <code>VALKEYMODULE_ERR</code><br>is returned.</p>\n<p><span id=\"ValkeyModule_StringToDouble\"></span></p>\n<h3><code>ValkeyModule_StringToDouble</code></h3>\n<pre><code>int ValkeyModule_StringToDouble(const ValkeyModuleString *str, double *d);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Convert the string into a double, storing it at <code>*d</code>.<br>Returns <code>VALKEYMODULE_OK</code> on success or <code>VALKEYMODULE_ERR</code> if the string is<br>not a valid string representation of a double value.</p>\n<p><span id=\"ValkeyModule_StringToLongDouble\"></span></p>\n<h3><code>ValkeyModule_StringToLongDouble</code></h3>\n<pre><code>int ValkeyModule_StringToLongDouble(const ValkeyModuleString *str,\n                                    long double *ld);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Convert the string into a long double, storing it at <code>*ld</code>.<br>Returns <code>VALKEYMODULE_OK</code> on success or <code>VALKEYMODULE_ERR</code> if the string is<br>not a valid string representation of a double value.</p>\n<p><span id=\"ValkeyModule_StringToStreamID\"></span></p>\n<h3><code>ValkeyModule_StringToStreamID</code></h3>\n<pre><code>int ValkeyModule_StringToStreamID(const ValkeyModuleString *str,\n                                  ValkeyModuleStreamID *id);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Convert the string into a stream ID, storing it at <code>*id</code>.<br>Returns <code>VALKEYMODULE_OK</code> on success and returns <code>VALKEYMODULE_ERR</code> if the string<br>is not a valid string representation of a stream ID. The special IDs &quot;+&quot; and<br>&quot;-&quot; are allowed.</p>\n<p><span id=\"ValkeyModule_StringCompare\"></span></p>\n<h3><code>ValkeyModule_StringCompare</code></h3>\n<pre><code>int ValkeyModule_StringCompare(const ValkeyModuleString *a,\n                               const ValkeyModuleString *b);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Compare two string objects, returning -1, 0 or 1 respectively if<br>a &lt; b, a == b, a &gt; b. Strings are compared byte by byte as two<br>binary blobs without any encoding care / collation attempt.</p>\n<p><span id=\"ValkeyModule_StringAppendBuffer\"></span></p>\n<h3><code>ValkeyModule_StringAppendBuffer</code></h3>\n<pre><code>int ValkeyModule_StringAppendBuffer(ValkeyModuleCtx *ctx,\n                                    ValkeyModuleString *str,\n                                    const char *buf,\n                                    size_t len);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Append the specified buffer to the string &#39;str&#39;. The string must be a<br>string created by the user that is referenced only a single time, otherwise<br><code>VALKEYMODULE_ERR</code> is returned and the operation is not performed.</p>\n<p><span id=\"ValkeyModule_TrimStringAllocation\"></span></p>\n<h3><code>ValkeyModule_TrimStringAllocation</code></h3>\n<pre><code>void ValkeyModule_TrimStringAllocation(ValkeyModuleString *str);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Trim possible excess memory allocated for a <code>ValkeyModuleString</code>.</p>\n<p>Sometimes a <code>ValkeyModuleString</code> may have more memory allocated for<br>it than required, typically for argv arguments that were constructed<br>from network buffers. This function optimizes such strings by reallocating<br>their memory, which is useful for strings that are not short lived but<br>retained for an extended duration.</p>\n<p>This operation is <em>not thread safe</em> and should only be called when<br>no concurrent access to the string is guaranteed. Using it for an argv<br>string in a module command before the string is potentially available<br>to other threads is generally safe.</p>\n<p>Currently, the server may also automatically trim retained strings when a<br>module command returns. However, doing this explicitly should still be<br>a preferred option:</p>\n<ol>\n<li>Future versions of the server may abandon auto-trimming.</li>\n<li>Auto-trimming as currently implemented is <em>not thread safe</em>.<br>A background thread manipulating a recently retained string may end up<br>in a race condition with the auto-trim, which could result with<br>data corruption.</li>\n</ol>\n<p><span id=\"section-reply-apis\"></span></p>\n<h2>Reply APIs</h2>\n<p>These functions are used for sending replies to the client.</p>\n<p>Most functions always return <code>VALKEYMODULE_OK</code> so you can use it with<br>&#39;return&#39; in order to return from the command implementation with:</p>\n<pre><code>if (... some condition ...)\n    return ValkeyModule_ReplyWithLongLong(ctx,mycount);\n</code></pre>\n<h3>Reply with collection functions</h3>\n<p>After starting a collection reply, the module must make calls to other<br><code>ReplyWith*</code> style functions in order to emit the elements of the collection.<br>Collection types include: Array, Map, Set and Attribute.</p>\n<p>When producing collections with a number of elements that is not known<br>beforehand, the function can be called with a special flag<br><code>VALKEYMODULE_POSTPONED_LEN</code> (<code>VALKEYMODULE_POSTPONED_ARRAY_LEN</code> in the past),<br>and the actual number of elements can be later set with <code>ValkeyModule_ReplySet</code>*Length()<br>call (which will set the latest &quot;open&quot; count if there are multiple ones).</p>\n<p><span id=\"ValkeyModule_WrongArity\"></span></p>\n<h3><code>ValkeyModule_WrongArity</code></h3>\n<pre><code>int ValkeyModule_WrongArity(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Send an error about the number of arguments given to the command,<br>citing the command name in the error message. Returns <code>VALKEYMODULE_OK</code>.</p>\n<p>Example:</p>\n<pre><code>if (argc != 3) return ValkeyModule_WrongArity(ctx);\n</code></pre>\n<p><span id=\"ValkeyModule_ReplyWithLongLong\"></span></p>\n<h3><code>ValkeyModule_ReplyWithLongLong</code></h3>\n<pre><code>int ValkeyModule_ReplyWithLongLong(ValkeyModuleCtx *ctx, long long ll);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Send an integer reply to the client, with the specified <code>long long</code> value.<br>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithError\"></span></p>\n<h3><code>ValkeyModule_ReplyWithError</code></h3>\n<pre><code>int ValkeyModule_ReplyWithError(ValkeyModuleCtx *ctx, const char *err);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Reply with the error &#39;err&#39;.</p>\n<p>Note that &#39;err&#39; must contain all the error, including<br>the initial error code. The function only provides the initial &quot;-&quot;, so<br>the usage is, for example:</p>\n<pre><code>ValkeyModule_ReplyWithError(ctx,&quot;ERR Wrong Type&quot;);\n</code></pre>\n<p>and not just:</p>\n<pre><code>ValkeyModule_ReplyWithError(ctx,&quot;Wrong Type&quot;);\n</code></pre>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithErrorFormat\"></span></p>\n<h3><code>ValkeyModule_ReplyWithErrorFormat</code></h3>\n<pre><code>int ValkeyModule_ReplyWithErrorFormat(ValkeyModuleCtx *ctx,\n                                      const char *fmt,\n                                      ...);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Reply with the error create from a printf format and arguments.</p>\n<p>Note that &#39;fmt&#39; must contain all the error, including<br>the initial error code. The function only provides the initial &quot;-&quot;, so<br>the usage is, for example:</p>\n<pre><code>ValkeyModule_ReplyWithErrorFormat(ctx,&quot;ERR Wrong Type: %s&quot;,type);\n</code></pre>\n<p>and not just:</p>\n<pre><code>ValkeyModule_ReplyWithErrorFormat(ctx,&quot;Wrong Type: %s&quot;,type);\n</code></pre>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithSimpleString\"></span></p>\n<h3><code>ValkeyModule_ReplyWithSimpleString</code></h3>\n<pre><code>int ValkeyModule_ReplyWithSimpleString(ValkeyModuleCtx *ctx, const char *msg);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Reply with a simple string (<code>+... \\r\\n</code> in RESP protocol). This replies<br>are suitable only when sending a small non-binary string with small<br>overhead, like &quot;OK&quot; or similar replies.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithArray\"></span></p>\n<h3><code>ValkeyModule_ReplyWithArray</code></h3>\n<pre><code>int ValkeyModule_ReplyWithArray(ValkeyModuleCtx *ctx, long len);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Reply with an array type of &#39;len&#39; elements.</p>\n<p>After starting an array reply, the module must make <code>len</code> calls to other<br><code>ReplyWith*</code> style functions in order to emit the elements of the array.<br>See Reply APIs section for more details.</p>\n<p>Use <a href=\"#ValkeyModule_ReplySetArrayLength\"><code>ValkeyModule_ReplySetArrayLength()</code></a> to set deferred length.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithMap\"></span></p>\n<h3><code>ValkeyModule_ReplyWithMap</code></h3>\n<pre><code>int ValkeyModule_ReplyWithMap(ValkeyModuleCtx *ctx, long len);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Reply with a RESP3 Map type of &#39;len&#39; pairs.<br>Visit <a href=\"https://valkey.io/topics/protocol\">https://valkey.io/topics/protocol</a> for more info about RESP3.</p>\n<p>After starting a map reply, the module must make <code>len*2</code> calls to other<br><code>ReplyWith*</code> style functions in order to emit the elements of the map.<br>See Reply APIs section for more details.</p>\n<p>If the connected client is using RESP2, the reply will be converted to a flat<br>array.</p>\n<p>Use <a href=\"#ValkeyModule_ReplySetMapLength\"><code>ValkeyModule_ReplySetMapLength()</code></a> to set deferred length.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithSet\"></span></p>\n<h3><code>ValkeyModule_ReplyWithSet</code></h3>\n<pre><code>int ValkeyModule_ReplyWithSet(ValkeyModuleCtx *ctx, long len);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Reply with a RESP3 Set type of &#39;len&#39; elements.<br>Visit <a href=\"https://valkey.io/topics/protocol\">https://valkey.io/topics/protocol</a> for more info about RESP3.</p>\n<p>After starting a set reply, the module must make <code>len</code> calls to other<br><code>ReplyWith*</code> style functions in order to emit the elements of the set.<br>See Reply APIs section for more details.</p>\n<p>If the connected client is using RESP2, the reply will be converted to an<br>array type.</p>\n<p>Use <a href=\"#ValkeyModule_ReplySetSetLength\"><code>ValkeyModule_ReplySetSetLength()</code></a> to set deferred length.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithAttribute\"></span></p>\n<h3><code>ValkeyModule_ReplyWithAttribute</code></h3>\n<pre><code>int ValkeyModule_ReplyWithAttribute(ValkeyModuleCtx *ctx, long len);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Add attributes (metadata) to the reply. Should be done before adding the<br>actual reply. see <a href=\"https://valkey.io/topics/protocol#attribute-type\">https://valkey.io/topics/protocol#attribute-type</a></p>\n<p>After starting an attribute&#39;s reply, the module must make <code>len*2</code> calls to other<br><code>ReplyWith*</code> style functions in order to emit the elements of the attribute map.<br>See Reply APIs section for more details.</p>\n<p>Use <a href=\"#ValkeyModule_ReplySetAttributeLength\"><code>ValkeyModule_ReplySetAttributeLength()</code></a> to set deferred length.</p>\n<p>Not supported by RESP2 and will return <code>VALKEYMODULE_ERR</code>, otherwise<br>the function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithNullArray\"></span></p>\n<h3><code>ValkeyModule_ReplyWithNullArray</code></h3>\n<pre><code>int ValkeyModule_ReplyWithNullArray(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Reply to the client with a null array, simply null in RESP3,<br>null array in RESP2.</p>\n<p>Note: In RESP3 there&#39;s no difference between Null reply and<br>NullArray reply, so to prevent ambiguity it&#39;s better to avoid<br>using this API and use <a href=\"#ValkeyModule_ReplyWithNull\"><code>ValkeyModule_ReplyWithNull</code></a> instead.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithEmptyArray\"></span></p>\n<h3><code>ValkeyModule_ReplyWithEmptyArray</code></h3>\n<pre><code>int ValkeyModule_ReplyWithEmptyArray(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Reply to the client with an empty array.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplySetArrayLength\"></span></p>\n<h3><code>ValkeyModule_ReplySetArrayLength</code></h3>\n<pre><code>void ValkeyModule_ReplySetArrayLength(ValkeyModuleCtx *ctx, long len);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>When <a href=\"#ValkeyModule_ReplyWithArray\"><code>ValkeyModule_ReplyWithArray()</code></a> is used with the argument<br><code>VALKEYMODULE_POSTPONED_LEN</code>, because we don&#39;t know beforehand the number<br>of items we are going to output as elements of the array, this function<br>will take care to set the array length.</p>\n<p>Since it is possible to have multiple array replies pending with unknown<br>length, this function guarantees to always set the latest array length<br>that was created in a postponed way.</p>\n<p>For example in order to output an array like [1,[10,20,30]] we<br>could write:</p>\n<pre><code> ValkeyModule_ReplyWithArray(ctx,VALKEYMODULE_POSTPONED_LEN);\n ValkeyModule_ReplyWithLongLong(ctx,1);\n ValkeyModule_ReplyWithArray(ctx,VALKEYMODULE_POSTPONED_LEN);\n ValkeyModule_ReplyWithLongLong(ctx,10);\n ValkeyModule_ReplyWithLongLong(ctx,20);\n ValkeyModule_ReplyWithLongLong(ctx,30);\n ValkeyModule_ReplySetArrayLength(ctx,3); // Set len of 10,20,30 array.\n ValkeyModule_ReplySetArrayLength(ctx,2); // Set len of top array\n</code></pre>\n<p>Note that in the above example there is no reason to postpone the array<br>length, since we produce a fixed number of elements, but in the practice<br>the code may use an iterator or other ways of creating the output so<br>that is not easy to calculate in advance the number of elements.</p>\n<p><span id=\"ValkeyModule_ReplySetMapLength\"></span></p>\n<h3><code>ValkeyModule_ReplySetMapLength</code></h3>\n<pre><code>void ValkeyModule_ReplySetMapLength(ValkeyModuleCtx *ctx, long len);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Very similar to <a href=\"#ValkeyModule_ReplySetArrayLength\"><code>ValkeyModule_ReplySetArrayLength</code></a> except <code>len</code> should<br>exactly half of the number of <code>ReplyWith*</code> functions called in the<br>context of the map.<br>Visit <a href=\"https://valkey.io/topics/protocol\">https://valkey.io/topics/protocol</a> for more info about RESP3.</p>\n<p><span id=\"ValkeyModule_ReplySetSetLength\"></span></p>\n<h3><code>ValkeyModule_ReplySetSetLength</code></h3>\n<pre><code>void ValkeyModule_ReplySetSetLength(ValkeyModuleCtx *ctx, long len);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Very similar to <a href=\"#ValkeyModule_ReplySetArrayLength\"><code>ValkeyModule_ReplySetArrayLength</code></a><br>Visit <a href=\"https://valkey.io/topics/protocol\">https://valkey.io/topics/protocol</a> for more info about RESP3.</p>\n<p><span id=\"ValkeyModule_ReplySetAttributeLength\"></span></p>\n<h3><code>ValkeyModule_ReplySetAttributeLength</code></h3>\n<pre><code>void ValkeyModule_ReplySetAttributeLength(ValkeyModuleCtx *ctx, long len);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Very similar to <a href=\"#ValkeyModule_ReplySetMapLength\"><code>ValkeyModule_ReplySetMapLength</code></a><br>Visit <a href=\"https://valkey.io/topics/protocol\">https://valkey.io/topics/protocol</a> for more info about RESP3.</p>\n<p>Must not be called if <a href=\"#ValkeyModule_ReplyWithAttribute\"><code>ValkeyModule_ReplyWithAttribute</code></a> returned an error.</p>\n<p><span id=\"ValkeyModule_ReplyWithStringBuffer\"></span></p>\n<h3><code>ValkeyModule_ReplyWithStringBuffer</code></h3>\n<pre><code>int ValkeyModule_ReplyWithStringBuffer(ValkeyModuleCtx *ctx,\n                                       const char *buf,\n                                       size_t len);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Reply with a bulk string, taking in input a C buffer pointer and length.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithCString\"></span></p>\n<h3><code>ValkeyModule_ReplyWithCString</code></h3>\n<pre><code>int ValkeyModule_ReplyWithCString(ValkeyModuleCtx *ctx, const char *buf);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.6</p>\n<p>Reply with a bulk string, taking in input a C buffer pointer that is<br>assumed to be null-terminated.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithString\"></span></p>\n<h3><code>ValkeyModule_ReplyWithString</code></h3>\n<pre><code>int ValkeyModule_ReplyWithString(ValkeyModuleCtx *ctx,\n                                 ValkeyModuleString *str);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Reply with a bulk string, taking in input a <code>ValkeyModuleString</code> object.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithEmptyString\"></span></p>\n<h3><code>ValkeyModule_ReplyWithEmptyString</code></h3>\n<pre><code>int ValkeyModule_ReplyWithEmptyString(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Reply with an empty string.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithVerbatimStringType\"></span></p>\n<h3><code>ValkeyModule_ReplyWithVerbatimStringType</code></h3>\n<pre><code>int ValkeyModule_ReplyWithVerbatimStringType(ValkeyModuleCtx *ctx,\n                                             const char *buf,\n                                             size_t len,\n                                             const char *ext);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Reply with a binary safe string, which should not be escaped or filtered<br>taking in input a C buffer pointer, length and a 3 character type/extension.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithVerbatimString\"></span></p>\n<h3><code>ValkeyModule_ReplyWithVerbatimString</code></h3>\n<pre><code>int ValkeyModule_ReplyWithVerbatimString(ValkeyModuleCtx *ctx,\n                                         const char *buf,\n                                         size_t len);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Reply with a binary safe string, which should not be escaped or filtered<br>taking in input a C buffer pointer and length.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithNull\"></span></p>\n<h3><code>ValkeyModule_ReplyWithNull</code></h3>\n<pre><code>int ValkeyModule_ReplyWithNull(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Reply to the client with a NULL.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithBool\"></span></p>\n<h3><code>ValkeyModule_ReplyWithBool</code></h3>\n<pre><code>int ValkeyModule_ReplyWithBool(ValkeyModuleCtx *ctx, int b);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Reply with a RESP3 Boolean type.<br>Visit <a href=\"https://valkey.io/topics/protocol\">https://valkey.io/topics/protocol</a> for more info about RESP3.</p>\n<p>In RESP3, this is boolean type<br>In RESP2, it&#39;s a string response of &quot;1&quot; and &quot;0&quot; for true and false respectively.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithCallReply\"></span></p>\n<h3><code>ValkeyModule_ReplyWithCallReply</code></h3>\n<pre><code>int ValkeyModule_ReplyWithCallReply(ValkeyModuleCtx *ctx,\n                                    ValkeyModuleCallReply *reply);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Reply exactly what a command returned us with <a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call()</code></a>.<br>This function is useful when we use <a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call()</code></a> in order to<br>execute some command, as we want to reply to the client exactly the<br>same reply we obtained by the command.</p>\n<p>Return:</p>\n<ul>\n<li><code>VALKEYMODULE_OK</code> on success.</li>\n<li><code>VALKEYMODULE_ERR</code> if the given reply is in RESP3 format but the client expects RESP2.<br>In case of an error, it&#39;s the module writer responsibility to translate the reply<br>to RESP2 (or handle it differently by returning an error). Notice that for<br>module writer convenience, it is possible to pass <code>0</code> as a parameter to the fmt<br>argument of <a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call</code></a> so that the <code>ValkeyModuleCallReply</code> will return in the same<br>protocol (RESP2 or RESP3) as set in the current client&#39;s context.</li>\n</ul>\n<p><span id=\"ValkeyModule_ReplyWithDouble\"></span></p>\n<h3><code>ValkeyModule_ReplyWithDouble</code></h3>\n<pre><code>int ValkeyModule_ReplyWithDouble(ValkeyModuleCtx *ctx, double d);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Reply with a RESP3 Double type.<br>Visit <a href=\"https://valkey.io/topics/protocol\">https://valkey.io/topics/protocol</a> for more info about RESP3.</p>\n<p>Send a string reply obtained converting the double &#39;d&#39; into a bulk string.<br>This function is basically equivalent to converting a double into<br>a string into a C buffer, and then calling the function<br><a href=\"#ValkeyModule_ReplyWithStringBuffer\"><code>ValkeyModule_ReplyWithStringBuffer()</code></a> with the buffer and length.</p>\n<p>In RESP3 the string is tagged as a double, while in RESP2 it&#39;s just a plain string<br>that the user will have to parse.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithBigNumber\"></span></p>\n<h3><code>ValkeyModule_ReplyWithBigNumber</code></h3>\n<pre><code>int ValkeyModule_ReplyWithBigNumber(ValkeyModuleCtx *ctx,\n                                    const char *bignum,\n                                    size_t len);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Reply with a RESP3 BigNumber type.<br>Visit <a href=\"https://valkey.io/topics/protocol\">https://valkey.io/topics/protocol</a> for more info about RESP3.</p>\n<p>In RESP3, this is a string of length <code>len</code> that is tagged as a BigNumber,<br>however, it&#39;s up to the caller to ensure that it&#39;s a valid BigNumber.<br>In RESP2, this is just a plain bulk string response.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_ReplyWithLongDouble\"></span></p>\n<h3><code>ValkeyModule_ReplyWithLongDouble</code></h3>\n<pre><code>int ValkeyModule_ReplyWithLongDouble(ValkeyModuleCtx *ctx, long double ld);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Send a string reply obtained converting the long double &#39;ld&#39; into a bulk<br>string. This function is basically equivalent to converting a long double<br>into a string into a C buffer, and then calling the function<br><a href=\"#ValkeyModule_ReplyWithStringBuffer\"><code>ValkeyModule_ReplyWithStringBuffer()</code></a> with the buffer and length.<br>The double string uses human readable formatting (see<br><code>addReplyHumanLongDouble</code> in networking.c).</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"section-commands-replication-api\"></span></p>\n<h2>Commands replication API</h2>\n<p><span id=\"ValkeyModule_Replicate\"></span></p>\n<h3><code>ValkeyModule_Replicate</code></h3>\n<pre><code>int ValkeyModule_Replicate(ValkeyModuleCtx *ctx,\n                           const char *cmdname,\n                           const char *fmt,\n                           ...);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Replicate the specified command and arguments to replicas and AOF, as effect<br>of execution of the calling command implementation.</p>\n<p>The replicated commands are always wrapped into the MULTI/EXEC that<br>contains all the commands replicated in a given module command<br>execution. However the commands replicated with <a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call()</code></a><br>are the first items, the ones replicated with <a href=\"#ValkeyModule_Replicate\"><code>ValkeyModule_Replicate()</code></a><br>will all follow before the EXEC.</p>\n<p>Modules should try to use one interface or the other.</p>\n<p>This command follows exactly the same interface of <a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call()</code></a>,<br>so a set of format specifiers must be passed, followed by arguments<br>matching the provided format specifiers.</p>\n<p>Please refer to <a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call()</code></a> for more information.</p>\n<p>Using the special &quot;A&quot; and &quot;R&quot; modifiers, the caller can exclude either<br>the AOF or the replicas from the propagation of the specified command.<br>Otherwise, by default, the command will be propagated in both channels.</p>\n<h4>Note about calling this function from a thread safe context:</h4>\n<p>Normally when you call this function from the callback implementing a<br>module command, or any other callback provided by the Module API,<br>The server will accumulate all the calls to this function in the context of<br>the callback, and will propagate all the commands wrapped in a MULTI/EXEC<br>transaction. However when calling this function from a threaded safe context<br>that can live an undefined amount of time, and can be locked/unlocked in<br>at will, the behavior is different: MULTI/EXEC wrapper is not emitted<br>and the command specified is inserted in the AOF and replication stream<br>immediately.</p>\n<h4>Return value</h4>\n<p>The command returns <code>VALKEYMODULE_ERR</code> if the format specifiers are invalid<br>or the command name does not belong to a known command.</p>\n<p><span id=\"ValkeyModule_ReplicateVerbatim\"></span></p>\n<h3><code>ValkeyModule_ReplicateVerbatim</code></h3>\n<pre><code>int ValkeyModule_ReplicateVerbatim(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>This function will replicate the command exactly as it was invoked<br>by the client. Note that this function will not wrap the command into<br>a MULTI/EXEC stanza, so it should not be mixed with other replication<br>commands.</p>\n<p>Basically this form of replication is useful when you want to propagate<br>the command to the replicas and AOF file exactly as it was called, since<br>the command can just be re-executed to deterministically re-create the<br>new state starting from the old one.</p>\n<p>The function always returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"section-db-and-key-apis-generic-api\"></span></p>\n<h2>DB and Key APIs – Generic API</h2>\n<p><span id=\"ValkeyModule_GetClientId\"></span></p>\n<h3><code>ValkeyModule_GetClientId</code></h3>\n<pre><code>unsigned long long ValkeyModule_GetClientId(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return the ID of the current client calling the currently active module<br>command. The returned ID has a few guarantees:</p>\n<ol>\n<li>The ID is different for each different client, so if the same client<br>executes a module command multiple times, it can be recognized as<br>having the same ID, otherwise the ID will be different.</li>\n<li>The ID increases monotonically. Clients connecting to the server later<br>are guaranteed to get IDs greater than any past ID previously seen.</li>\n</ol>\n<p>Valid IDs are from 1 to 2^64 - 1. If 0 is returned it means there is no way<br>to fetch the ID in the context the function was currently called.</p>\n<p>After obtaining the ID, it is possible to check if the command execution<br>is actually happening in the context of AOF loading, using this macro:</p>\n<pre><code> if (ValkeyModule_IsAOFClient(ValkeyModule_GetClientId(ctx)) {\n     // Handle it differently.\n }\n</code></pre>\n<p><span id=\"ValkeyModule_GetClientUserNameById\"></span></p>\n<h3><code>ValkeyModule_GetClientUserNameById</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_GetClientUserNameById(ValkeyModuleCtx *ctx,\n                                                       uint64_t id);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.1</p>\n<p>Return the ACL user name used by the client with the specified client ID.<br>Client ID can be obtained with <a href=\"#ValkeyModule_GetClientId\"><code>ValkeyModule_GetClientId()</code></a> API. If the client does not<br>exist, NULL is returned and errno is set to ENOENT. If the client isn&#39;t<br>using an ACL user, NULL is returned and errno is set to ENOTSUP</p>\n<p><span id=\"ValkeyModule_MustObeyClient\"></span></p>\n<h3><code>ValkeyModule_MustObeyClient</code></h3>\n<pre><code>int ValkeyModule_MustObeyClient(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 8.1.0</p>\n<p>Returns 1 if commands are arriving from the primary client or AOF client<br>and should never be rejected.<br>This check can be used in places such as skipping validation of commands<br>on replicas (to not diverge from primary) or from AOF files.<br>Returns 0 otherwise (and also if ctx or if the client is NULL).</p>\n<p><span id=\"ValkeyModule_GetClientInfoById\"></span></p>\n<h3><code>ValkeyModule_GetClientInfoById</code></h3>\n<pre><code>int ValkeyModule_GetClientInfoById(void *ci, uint64_t id);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Return information about the client with the specified ID (that was<br>previously obtained via the <a href=\"#ValkeyModule_GetClientId\"><code>ValkeyModule_GetClientId()</code></a> API). If the<br>client exists, <code>VALKEYMODULE_OK</code> is returned, otherwise <code>VALKEYMODULE_ERR</code><br>is returned.</p>\n<p>When the client exist and the <code>ci</code> pointer is not NULL, but points to<br>a structure of type <code>ValkeyModuleClientInfoV</code>1, previously initialized with<br>the correct <code>VALKEYMODULE_CLIENTINFO_INITIALIZER_V1</code>, the structure is populated<br>with the following fields:</p>\n<pre><code> uint64_t flags;         // VALKEYMODULE_CLIENTINFO_FLAG_*\n uint64_t id;            // Client ID\n char addr[46];          // IPv4 or IPv6 address.\n uint16_t port;          // TCP port.\n uint16_t db;            // Selected DB.\n</code></pre>\n<p>Note: the client ID is useless in the context of this call, since we<br>      already know, however the same structure could be used in other<br>      contexts where we don&#39;t know the client ID, yet the same structure<br>      is returned.</p>\n<p>With flags having the following meaning:</p>\n<pre><code>VALKEYMODULE_CLIENTINFO_FLAG_SSL          Client using SSL connection.\nVALKEYMODULE_CLIENTINFO_FLAG_PUBSUB       Client in Pub/Sub mode.\nVALKEYMODULE_CLIENTINFO_FLAG_BLOCKED      Client blocked in command.\nVALKEYMODULE_CLIENTINFO_FLAG_TRACKING     Client with keys tracking on.\nVALKEYMODULE_CLIENTINFO_FLAG_UNIXSOCKET   Client using unix domain socket.\nVALKEYMODULE_CLIENTINFO_FLAG_MULTI        Client in MULTI state.\n</code></pre>\n<p>However passing NULL is a way to just check if the client exists in case<br>we are not interested in any additional information.</p>\n<p>This is the correct usage when we want the client info structure<br>returned:</p>\n<pre><code> ValkeyModuleClientInfo ci = VALKEYMODULE_CLIENTINFO_INITIALIZER;\n int retval = ValkeyModule_GetClientInfoById(&amp;ci,client_id);\n if (retval == VALKEYMODULE_OK) {\n     printf(&quot;Address: %s\\n&quot;, ci.addr);\n }\n</code></pre>\n<p><span id=\"ValkeyModule_GetClientNameById\"></span></p>\n<h3><code>ValkeyModule_GetClientNameById</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_GetClientNameById(ValkeyModuleCtx *ctx,\n                                                   uint64_t id);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.3</p>\n<p>Returns the name of the client connection with the given ID.</p>\n<p>If the client ID does not exist or if the client has no name associated with<br>it, NULL is returned.</p>\n<p><span id=\"ValkeyModule_SetClientNameById\"></span></p>\n<h3><code>ValkeyModule_SetClientNameById</code></h3>\n<pre><code>int ValkeyModule_SetClientNameById(uint64_t id, ValkeyModuleString *name);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.3</p>\n<p>Sets the name of the client with the given ID. This is equivalent to the client calling<br><code>CLIENT SETNAME name</code>.</p>\n<p>Returns <code>VALKEYMODULE_OK</code> on success. On failure, <code>VALKEYMODULE_ERR</code> is returned<br>and errno is set as follows:</p>\n<ul>\n<li>ENOENT if the client does not exist</li>\n<li>EINVAL if the name contains invalid characters</li>\n</ul>\n<p><span id=\"ValkeyModule_PublishMessage\"></span></p>\n<h3><code>ValkeyModule_PublishMessage</code></h3>\n<pre><code>int ValkeyModule_PublishMessage(ValkeyModuleCtx *ctx,\n                                ValkeyModuleString *channel,\n                                ValkeyModuleString *message);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Publish a message to subscribers (see PUBLISH command).</p>\n<p><span id=\"ValkeyModule_PublishMessageShard\"></span></p>\n<h3><code>ValkeyModule_PublishMessageShard</code></h3>\n<pre><code>int ValkeyModule_PublishMessageShard(ValkeyModuleCtx *ctx,\n                                     ValkeyModuleString *channel,\n                                     ValkeyModuleString *message);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Publish a message to shard-subscribers (see SPUBLISH command).</p>\n<p><span id=\"ValkeyModule_GetSelectedDb\"></span></p>\n<h3><code>ValkeyModule_GetSelectedDb</code></h3>\n<pre><code>int ValkeyModule_GetSelectedDb(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return the currently selected DB.</p>\n<p><span id=\"ValkeyModule_GetContextFlags\"></span></p>\n<h3><code>ValkeyModule_GetContextFlags</code></h3>\n<pre><code>int ValkeyModule_GetContextFlags(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.3</p>\n<p>Return the current context&#39;s flags. The flags provide information on the<br>current request context (whether the client is a Lua script or in a MULTI),<br>and about the instance in general, i.e replication and persistence.</p>\n<p>It is possible to call this function even with a NULL context, however<br>in this case the following flags will not be reported:</p>\n<ul>\n<li>LUA, MULTI, REPLICATED, DIRTY (see below for more info).</li>\n</ul>\n<p>Available flags and their meaning:</p>\n<ul>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_LUA</code>: The command is running in a Lua script</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_MULTI</code>: The command is running inside a transaction</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_REPLICATED</code>: The command was sent over the replication<br>link by the PRIMARY</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_PRIMARY</code>: The instance is a primary</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_REPLICA</code>: The instance is a replica</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_READONLY</code>: The instance is read-only</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_CLUSTER</code>: The instance is in cluster mode</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_AOF</code>: The instance has AOF enabled</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_RDB</code>: The instance has RDB enabled</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_MAXMEMORY</code>:  The instance has Maxmemory set</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_EVICT</code>:  Maxmemory is set and has an eviction<br>policy that may delete keys</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_OOM</code>: The server is out of memory according to the<br>maxmemory setting.</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_OOM_WARNING</code>: Less than 25% of memory remains before<br>                               reaching the maxmemory level.</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_LOADING</code>: Server is loading RDB/AOF</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_REPLICA_IS_STALE</code>: No active link with the primary.</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_REPLICA_IS_CONNECTING</code>: The replica is trying to<br>                                         connect with the primary.</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_REPLICA_IS_TRANSFERRING</code>: primary -&gt; Replica RDB<br>                                           transfer is in progress.</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_REPLICA_IS_ONLINE</code>: The replica has an active link<br>                                     with its primary. This is the<br>                                     contrary of STALE state.</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_ACTIVE_CHILD</code>: There is currently some background<br>                                process active (RDB, AUX or module).</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_MULTI_DIRTY</code>: The next EXEC will fail due to dirty<br>                               CAS (touched keys).</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_IS_CHILD</code>: The server is currently running inside<br>                            background child process.</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_RESP3</code>: Indicate the that client attached to this<br>                         context is using RESP3.</p>\n</li>\n<li><p><code>VALKEYMODULE_CTX_FLAGS_SERVER_STARTUP</code>: The instance is starting</p>\n</li>\n</ul>\n<p><span id=\"ValkeyModule_AvoidReplicaTraffic\"></span></p>\n<h3><code>ValkeyModule_AvoidReplicaTraffic</code></h3>\n<pre><code>int ValkeyModule_AvoidReplicaTraffic(void);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Returns true if a client sent the CLIENT PAUSE command to the server or<br>if the Cluster does a manual failover, pausing the clients.<br>This is needed when we have a primary with replicas, and want to write,<br>without adding further data to the replication channel, that the replicas<br>replication offset, match the one of the primary. When this happens, it is<br>safe to failover the primary without data loss.</p>\n<p>However modules may generate traffic by calling <a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call()</code></a> with<br>the &quot;!&quot; flag, or by calling <a href=\"#ValkeyModule_Replicate\"><code>ValkeyModule_Replicate()</code></a>, in a context outside<br>commands execution, for instance in timeout callbacks, threads safe<br>contexts, and so forth. When modules will generate too much traffic, it<br>will be hard for the primary and replicas offset to match, because there<br>is more data to send in the replication channel.</p>\n<p>So modules may want to try to avoid very heavy background work that has<br>the effect of creating data to the replication channel, when this function<br>returns true. This is mostly useful for modules that have background<br>garbage collection tasks, or that do writes and replicate such writes<br>periodically in timer callbacks or other periodic callbacks.</p>\n<p><span id=\"ValkeyModule_SelectDb\"></span></p>\n<h3><code>ValkeyModule_SelectDb</code></h3>\n<pre><code>int ValkeyModule_SelectDb(ValkeyModuleCtx *ctx, int newid);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Change the currently selected DB. Returns an error if the id<br>is out of range.</p>\n<p>Note that the client will retain the currently selected DB even after<br>the command implemented by the module calling this function<br>returns.</p>\n<p>If the module command wishes to change something in a different DB and<br>returns back to the original one, it should call <a href=\"#ValkeyModule_GetSelectedDb\"><code>ValkeyModule_GetSelectedDb()</code></a><br>before in order to restore the old DB number before returning.</p>\n<p><span id=\"ValkeyModule_KeyExists\"></span></p>\n<h3><code>ValkeyModule_KeyExists</code></h3>\n<pre><code>int ValkeyModule_KeyExists(ValkeyModuleCtx *ctx, robj *keyname);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Check if a key exists, without affecting its last access time.</p>\n<p>This is equivalent to calling <a href=\"#ValkeyModule_OpenKey\"><code>ValkeyModule_OpenKey</code></a> with the mode <code>VALKEYMODULE_READ</code> |<br><code>VALKEYMODULE_OPEN_KEY_NOTOUCH</code>, then checking if NULL was returned and, if not,<br>calling <a href=\"#ValkeyModule_CloseKey\"><code>ValkeyModule_CloseKey</code></a> on the opened key.</p>\n<p><span id=\"ValkeyModule_OpenKey\"></span></p>\n<h3><code>ValkeyModule_OpenKey</code></h3>\n<pre><code>ValkeyModuleKey *ValkeyModule_OpenKey(ValkeyModuleCtx *ctx,\n                                      robj *keyname,\n                                      int mode);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return a handle representing a key, so that it is possible<br>to call other APIs with the key handle as argument to perform<br>operations on the key.</p>\n<p>The return value is the handle representing the key, that must be<br>closed with <a href=\"#ValkeyModule_CloseKey\"><code>ValkeyModule_CloseKey()</code></a>.</p>\n<p>If the key does not exist and <code>VALKEYMODULE_WRITE</code> mode is requested, the handle<br>is still returned, since it is possible to perform operations on<br>a yet not existing key (that will be created, for example, after<br>a list push operation). If the mode is just <code>VALKEYMODULE_READ</code> instead, and the<br>key does not exist, NULL is returned. However it is still safe to<br>call <a href=\"#ValkeyModule_CloseKey\"><code>ValkeyModule_CloseKey()</code></a> and <a href=\"#ValkeyModule_KeyType\"><code>ValkeyModule_KeyType()</code></a> on a NULL<br>value.</p>\n<p>Extra flags that can be pass to the API under the mode argument:</p>\n<ul>\n<li><code>VALKEYMODULE_OPEN_KEY_NOTOUCH</code> - Avoid touching the LRU/LFU of the key when opened.</li>\n<li><code>VALKEYMODULE_OPEN_KEY_NONOTIFY</code> - Don&#39;t trigger keyspace event on key misses.</li>\n<li><code>VALKEYMODULE_OPEN_KEY_NOSTATS</code> - Don&#39;t update keyspace hits/misses counters.</li>\n<li><code>VALKEYMODULE_OPEN_KEY_NOEXPIRE</code> - Avoid deleting lazy expired keys.</li>\n<li><code>VALKEYMODULE_OPEN_KEY_NOEFFECTS</code> - Avoid any effects from fetching the key.</li>\n</ul>\n<p><span id=\"ValkeyModule_GetOpenKeyModesAll\"></span></p>\n<h3><code>ValkeyModule_GetOpenKeyModesAll</code></h3>\n<pre><code>int ValkeyModule_GetOpenKeyModesAll(void);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Returns the full OpenKey modes mask, using the return value<br>the module can check if a certain set of OpenKey modes are supported<br>by the server version in use.<br>Example:</p>\n<pre><code>   int supportedMode = ValkeyModule_GetOpenKeyModesAll();\n   if (supportedMode &amp; VALKEYMODULE_OPEN_KEY_NOTOUCH) {\n         // VALKEYMODULE_OPEN_KEY_NOTOUCH is supported\n   } else{\n         // VALKEYMODULE_OPEN_KEY_NOTOUCH is not supported\n   }\n</code></pre>\n<p><span id=\"ValkeyModule_CloseKey\"></span></p>\n<h3><code>ValkeyModule_CloseKey</code></h3>\n<pre><code>void ValkeyModule_CloseKey(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Close a key handle. The key handle is freed and should not be accessed anymore.</p>\n<p><span id=\"ValkeyModule_KeyType\"></span></p>\n<h3><code>ValkeyModule_KeyType</code></h3>\n<pre><code>int ValkeyModule_KeyType(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return the type of the key. If the key pointer is NULL then<br><code>VALKEYMODULE_KEYTYPE_EMPTY</code> is returned.</p>\n<p><span id=\"ValkeyModule_ValueLength\"></span></p>\n<h3><code>ValkeyModule_ValueLength</code></h3>\n<pre><code>size_t ValkeyModule_ValueLength(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return the length of the value associated with the key.<br>For strings this is the length of the string. For all the other types<br>is the number of elements (just counting keys for hashes).</p>\n<p>If the key pointer is NULL or the key is empty, zero is returned.</p>\n<p><span id=\"ValkeyModule_DeleteKey\"></span></p>\n<h3><code>ValkeyModule_DeleteKey</code></h3>\n<pre><code>int ValkeyModule_DeleteKey(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>If the key is open for writing, remove it, and setup the key to<br>accept new writes as an empty key (that will be created on demand).<br>On success <code>VALKEYMODULE_OK</code> is returned. If the key is not open for<br>writing <code>VALKEYMODULE_ERR</code> is returned.</p>\n<p><span id=\"ValkeyModule_UnlinkKey\"></span></p>\n<h3><code>ValkeyModule_UnlinkKey</code></h3>\n<pre><code>int ValkeyModule_UnlinkKey(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.7</p>\n<p>If the key is open for writing, unlink it (that is delete it in a<br>non-blocking way, not reclaiming memory immediately) and setup the key to<br>accept new writes as an empty key (that will be created on demand).<br>On success <code>VALKEYMODULE_OK</code> is returned. If the key is not open for<br>writing <code>VALKEYMODULE_ERR</code> is returned.</p>\n<p><span id=\"ValkeyModule_GetExpire\"></span></p>\n<h3><code>ValkeyModule_GetExpire</code></h3>\n<pre><code>mstime_t ValkeyModule_GetExpire(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return the key expire value, as milliseconds of remaining TTL.<br>If no TTL is associated with the key or if the key is empty,<br><code>VALKEYMODULE_NO_EXPIRE</code> is returned.</p>\n<p><span id=\"ValkeyModule_SetExpire\"></span></p>\n<h3><code>ValkeyModule_SetExpire</code></h3>\n<pre><code>int ValkeyModule_SetExpire(ValkeyModuleKey *key, mstime_t expire);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Set a new expire for the key. If the special expire<br><code>VALKEYMODULE_NO_EXPIRE</code> is set, the expire is cancelled if there was<br>one (the same as the PERSIST command).</p>\n<p>Note that the expire must be provided as a positive integer representing<br>the number of milliseconds of TTL the key should have.</p>\n<p>The function returns <code>VALKEYMODULE_OK</code> on success or <code>VALKEYMODULE_ERR</code> if<br>the key was not open for writing or is an empty key.</p>\n<p><span id=\"ValkeyModule_GetAbsExpire\"></span></p>\n<h3><code>ValkeyModule_GetAbsExpire</code></h3>\n<pre><code>mstime_t ValkeyModule_GetAbsExpire(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.2</p>\n<p>Return the key expire value, as absolute Unix timestamp.<br>If no TTL is associated with the key or if the key is empty,<br><code>VALKEYMODULE_NO_EXPIRE</code> is returned.</p>\n<p><span id=\"ValkeyModule_SetAbsExpire\"></span></p>\n<h3><code>ValkeyModule_SetAbsExpire</code></h3>\n<pre><code>int ValkeyModule_SetAbsExpire(ValkeyModuleKey *key, mstime_t expire);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.2</p>\n<p>Set a new expire for the key. If the special expire<br><code>VALKEYMODULE_NO_EXPIRE</code> is set, the expire is cancelled if there was<br>one (the same as the PERSIST command).</p>\n<p>Note that the expire must be provided as a positive integer representing<br>the absolute Unix timestamp the key should have.</p>\n<p>The function returns <code>VALKEYMODULE_OK</code> on success or <code>VALKEYMODULE_ERR</code> if<br>the key was not open for writing or is an empty key.</p>\n<p><span id=\"ValkeyModule_ResetDataset\"></span></p>\n<h3><code>ValkeyModule_ResetDataset</code></h3>\n<pre><code>void ValkeyModule_ResetDataset(int restart_aof, int async);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Performs similar operation to FLUSHALL, and optionally start a new AOF file (if enabled)<br>If <code>restart_aof</code> is true, you must make sure the command that triggered this call is not<br>propagated to the AOF file.<br>When async is set to true, db contents will be freed by a background thread.</p>\n<p><span id=\"ValkeyModule_DbSize\"></span></p>\n<h3><code>ValkeyModule_DbSize</code></h3>\n<pre><code>unsigned long long ValkeyModule_DbSize(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Returns the number of keys in the current db.</p>\n<p><span id=\"ValkeyModule_RandomKey\"></span></p>\n<h3><code>ValkeyModule_RandomKey</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_RandomKey(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Returns a name of a random key, or NULL if current db is empty.</p>\n<p><span id=\"ValkeyModule_GetKeyNameFromOptCtx\"></span></p>\n<h3><code>ValkeyModule_GetKeyNameFromOptCtx</code></h3>\n<pre><code>const ValkeyModuleString *ValkeyModule_GetKeyNameFromOptCtx(ValkeyModuleKeyOptCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Returns the name of the key currently being processed.</p>\n<p><span id=\"ValkeyModule_GetToKeyNameFromOptCtx\"></span></p>\n<h3><code>ValkeyModule_GetToKeyNameFromOptCtx</code></h3>\n<pre><code>const ValkeyModuleString *ValkeyModule_GetToKeyNameFromOptCtx(ValkeyModuleKeyOptCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Returns the name of the target key currently being processed.</p>\n<p><span id=\"ValkeyModule_GetDbIdFromOptCtx\"></span></p>\n<h3><code>ValkeyModule_GetDbIdFromOptCtx</code></h3>\n<pre><code>int ValkeyModule_GetDbIdFromOptCtx(ValkeyModuleKeyOptCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Returns the dbid currently being processed.</p>\n<p><span id=\"ValkeyModule_GetToDbIdFromOptCtx\"></span></p>\n<h3><code>ValkeyModule_GetToDbIdFromOptCtx</code></h3>\n<pre><code>int ValkeyModule_GetToDbIdFromOptCtx(ValkeyModuleKeyOptCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Returns the target dbid currently being processed.</p>\n<p><span id=\"section-key-api-for-string-type\"></span></p>\n<h2>Key API for String type</h2>\n<p>See also <a href=\"#ValkeyModule_ValueLength\"><code>ValkeyModule_ValueLength()</code></a>, which returns the length of a string.</p>\n<p><span id=\"ValkeyModule_StringSet\"></span></p>\n<h3><code>ValkeyModule_StringSet</code></h3>\n<pre><code>int ValkeyModule_StringSet(ValkeyModuleKey *key, ValkeyModuleString *str);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>If the key is open for writing, set the specified string &#39;str&#39; as the<br>value of the key, deleting the old value if any.<br>On success <code>VALKEYMODULE_OK</code> is returned. If the key is not open for<br>writing or there is an active iterator, <code>VALKEYMODULE_ERR</code> is returned.</p>\n<p><span id=\"ValkeyModule_StringDMA\"></span></p>\n<h3><code>ValkeyModule_StringDMA</code></h3>\n<pre><code>char *ValkeyModule_StringDMA(ValkeyModuleKey *key, size_t *len, int mode);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Prepare the key associated string value for DMA access, and returns<br>a pointer and size (by reference), that the user can use to read or<br>modify the string in-place accessing it directly via pointer.</p>\n<p>The &#39;mode&#39; is composed by bitwise OR-ing the following flags:</p>\n<pre><code>VALKEYMODULE_READ -- Read access\nVALKEYMODULE_WRITE -- Write access\n</code></pre>\n<p>If the DMA is not requested for writing, the pointer returned should<br>only be accessed in a read-only fashion.</p>\n<p>On error (wrong type) NULL is returned.</p>\n<p>DMA access rules:</p>\n<ol>\n<li><p>No other key writing function should be called since the moment<br>the pointer is obtained, for all the time we want to use DMA access<br>to read or modify the string.</p>\n</li>\n<li><p>Each time <a href=\"#ValkeyModule_StringTruncate\"><code>ValkeyModule_StringTruncate()</code></a> is called, to continue with the DMA<br>access, <a href=\"#ValkeyModule_StringDMA\"><code>ValkeyModule_StringDMA()</code></a> should be called again to re-obtain<br>a new pointer and length.</p>\n</li>\n<li><p>If the returned pointer is not NULL, but the length is zero, no<br>byte can be touched (the string is empty, or the key itself is empty)<br>so a <a href=\"#ValkeyModule_StringTruncate\"><code>ValkeyModule_StringTruncate()</code></a> call should be used if there is to enlarge<br>the string, and later call StringDMA() again to get the pointer.</p>\n</li>\n</ol>\n<p><span id=\"ValkeyModule_StringTruncate\"></span></p>\n<h3><code>ValkeyModule_StringTruncate</code></h3>\n<pre><code>int ValkeyModule_StringTruncate(ValkeyModuleKey *key, size_t newlen);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>If the key is open for writing and is of string type, resize it, padding<br>with zero bytes if the new length is greater than the old one.</p>\n<p>After this call, <a href=\"#ValkeyModule_StringDMA\"><code>ValkeyModule_StringDMA()</code></a> must be called again to continue<br>DMA access with the new pointer.</p>\n<p>The function returns <code>VALKEYMODULE_OK</code> on success, and <code>VALKEYMODULE_ERR</code> on<br>error, that is, the key is not open for writing, is not a string<br>or resizing for more than 512 MB is requested.</p>\n<p>If the key is empty, a string key is created with the new string value<br>unless the new length value requested is zero.</p>\n<p><span id=\"section-key-api-for-list-type\"></span></p>\n<h2>Key API for List type</h2>\n<p>Many of the list functions access elements by index. Since a list is in<br>essence a doubly-linked list, accessing elements by index is generally an<br>O(N) operation. However, if elements are accessed sequentially or with<br>indices close together, the functions are optimized to seek the index from<br>the previous index, rather than seeking from the ends of the list.</p>\n<p>This enables iteration to be done efficiently using a simple for loop:</p>\n<pre><code>long n = ValkeyModule_ValueLength(key);\nfor (long i = 0; i &lt; n; i++) {\n    ValkeyModuleString *elem = ValkeyModule_ListGet(key, i);\n    // Do stuff...\n}\n</code></pre>\n<p>Note that after modifying a list using <a href=\"#ValkeyModule_ListPop\"><code>ValkeyModule_ListPop</code></a>, <a href=\"#ValkeyModule_ListSet\"><code>ValkeyModule_ListSet</code></a> or<br><a href=\"#ValkeyModule_ListInsert\"><code>ValkeyModule_ListInsert</code></a>, the internal iterator is invalidated so the next operation<br>will require a linear seek.</p>\n<p>Modifying a list in any another way, for example using <a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call()</code></a>, while a key<br>is open will confuse the internal iterator and may cause trouble if the key<br>is used after such modifications. The key must be reopened in this case.</p>\n<p>See also <a href=\"#ValkeyModule_ValueLength\"><code>ValkeyModule_ValueLength()</code></a>, which returns the length of a list.</p>\n<p><span id=\"ValkeyModule_ListPush\"></span></p>\n<h3><code>ValkeyModule_ListPush</code></h3>\n<pre><code>int ValkeyModule_ListPush(ValkeyModuleKey *key,\n                          int where,\n                          ValkeyModuleString *ele);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Push an element into a list, on head or tail depending on &#39;where&#39; argument<br>(<code>VALKEYMODULE_LIST_HEAD</code> or <code>VALKEYMODULE_LIST_TAIL</code>). If the key refers to an<br>empty key opened for writing, the key is created. On success, <code>VALKEYMODULE_OK</code><br>is returned. On failure, <code>VALKEYMODULE_ERR</code> is returned and <code>errno</code> is set as<br>follows:</p>\n<ul>\n<li>EINVAL if key or ele is NULL.</li>\n<li>ENOTSUP if the key is of another type than list.</li>\n<li>EBADF if the key is not opened for writing.</li>\n</ul>\n<p>Note: Before Redis OSS 7.0, <code>errno</code> was not set by this function.</p>\n<p><span id=\"ValkeyModule_ListPop\"></span></p>\n<h3><code>ValkeyModule_ListPop</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_ListPop(ValkeyModuleKey *key, int where);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Pop an element from the list, and returns it as a module string object<br>that the user should be free with <a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a> or by enabling<br>automatic memory. The <code>where</code> argument specifies if the element should be<br>popped from the beginning or the end of the list (<code>VALKEYMODULE_LIST_HEAD</code> or<br><code>VALKEYMODULE_LIST_TAIL</code>). On failure, the command returns NULL and sets<br><code>errno</code> as follows:</p>\n<ul>\n<li>EINVAL if key is NULL.</li>\n<li>ENOTSUP if the key is empty or of another type than list.</li>\n<li>EBADF if the key is not opened for writing.</li>\n</ul>\n<p>Note: Before Redis OSS 7.0, <code>errno</code> was not set by this function.</p>\n<p><span id=\"ValkeyModule_ListGet\"></span></p>\n<h3><code>ValkeyModule_ListGet</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_ListGet(ValkeyModuleKey *key, long index);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Returns the element at index <code>index</code> in the list stored at <code>key</code>, like the<br>LINDEX command. The element should be free&#39;d using <a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a> or using<br>automatic memory management.</p>\n<p>The index is zero-based, so 0 means the first element, 1 the second element<br>and so on. Negative indices can be used to designate elements starting at the<br>tail of the list. Here, -1 means the last element, -2 means the penultimate<br>and so forth.</p>\n<p>When no value is found at the given key and index, NULL is returned and<br><code>errno</code> is set as follows:</p>\n<ul>\n<li>EINVAL if key is NULL.</li>\n<li>ENOTSUP if the key is not a list.</li>\n<li>EBADF if the key is not opened for reading.</li>\n<li>EDOM if the index is not a valid index in the list.</li>\n</ul>\n<p><span id=\"ValkeyModule_ListSet\"></span></p>\n<h3><code>ValkeyModule_ListSet</code></h3>\n<pre><code>int ValkeyModule_ListSet(ValkeyModuleKey *key,\n                         long index,\n                         ValkeyModuleString *value);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Replaces the element at index <code>index</code> in the list stored at <code>key</code>.</p>\n<p>The index is zero-based, so 0 means the first element, 1 the second element<br>and so on. Negative indices can be used to designate elements starting at the<br>tail of the list. Here, -1 means the last element, -2 means the penultimate<br>and so forth.</p>\n<p>On success, <code>VALKEYMODULE_OK</code> is returned. On failure, <code>VALKEYMODULE_ERR</code> is<br>returned and <code>errno</code> is set as follows:</p>\n<ul>\n<li>EINVAL if key or value is NULL.</li>\n<li>ENOTSUP if the key is not a list.</li>\n<li>EBADF if the key is not opened for writing.</li>\n<li>EDOM if the index is not a valid index in the list.</li>\n</ul>\n<p><span id=\"ValkeyModule_ListInsert\"></span></p>\n<h3><code>ValkeyModule_ListInsert</code></h3>\n<pre><code>int ValkeyModule_ListInsert(ValkeyModuleKey *key,\n                            long index,\n                            ValkeyModuleString *value);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Inserts an element at the given index.</p>\n<p>The index is zero-based, so 0 means the first element, 1 the second element<br>and so on. Negative indices can be used to designate elements starting at the<br>tail of the list. Here, -1 means the last element, -2 means the penultimate<br>and so forth. The index is the element&#39;s index after inserting it.</p>\n<p>On success, <code>VALKEYMODULE_OK</code> is returned. On failure, <code>VALKEYMODULE_ERR</code> is<br>returned and <code>errno</code> is set as follows:</p>\n<ul>\n<li>EINVAL if key or value is NULL.</li>\n<li>ENOTSUP if the key of another type than list.</li>\n<li>EBADF if the key is not opened for writing.</li>\n<li>EDOM if the index is not a valid index in the list.</li>\n</ul>\n<p><span id=\"ValkeyModule_ListDelete\"></span></p>\n<h3><code>ValkeyModule_ListDelete</code></h3>\n<pre><code>int ValkeyModule_ListDelete(ValkeyModuleKey *key, long index);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Removes an element at the given index. The index is 0-based. A negative index<br>can also be used, counting from the end of the list.</p>\n<p>On success, <code>VALKEYMODULE_OK</code> is returned. On failure, <code>VALKEYMODULE_ERR</code> is<br>returned and <code>errno</code> is set as follows:</p>\n<ul>\n<li>EINVAL if key or value is NULL.</li>\n<li>ENOTSUP if the key is not a list.</li>\n<li>EBADF if the key is not opened for writing.</li>\n<li>EDOM if the index is not a valid index in the list.</li>\n</ul>\n<p><span id=\"section-key-api-for-sorted-set-type\"></span></p>\n<h2>Key API for Sorted Set type</h2>\n<p>See also <a href=\"#ValkeyModule_ValueLength\"><code>ValkeyModule_ValueLength()</code></a>, which returns the length of a sorted set.</p>\n<p><span id=\"ValkeyModule_ZsetAdd\"></span></p>\n<h3><code>ValkeyModule_ZsetAdd</code></h3>\n<pre><code>int ValkeyModule_ZsetAdd(ValkeyModuleKey *key,\n                         double score,\n                         ValkeyModuleString *ele,\n                         int *flagsptr);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Add a new element into a sorted set, with the specified &#39;score&#39;.<br>If the element already exists, the score is updated.</p>\n<p>A new sorted set is created at value if the key is an empty open key<br>setup for writing.</p>\n<p>Additional flags can be passed to the function via a pointer, the flags<br>are both used to receive input and to communicate state when the function<br>returns. &#39;flagsptr&#39; can be NULL if no special flags are used.</p>\n<p>The input flags are:</p>\n<pre><code>VALKEYMODULE_ZADD_XX: Element must already exist. Do nothing otherwise.\nVALKEYMODULE_ZADD_NX: Element must not exist. Do nothing otherwise.\nVALKEYMODULE_ZADD_GT: If element exists, new score must be greater than the current score.\n                     Do nothing otherwise. Can optionally be combined with XX.\nVALKEYMODULE_ZADD_LT: If element exists, new score must be less than the current score.\n                     Do nothing otherwise. Can optionally be combined with XX.\n</code></pre>\n<p>The output flags are:</p>\n<pre><code>VALKEYMODULE_ZADD_ADDED: The new element was added to the sorted set.\nVALKEYMODULE_ZADD_UPDATED: The score of the element was updated.\nVALKEYMODULE_ZADD_NOP: No operation was performed because XX or NX flags.\n</code></pre>\n<p>On success the function returns <code>VALKEYMODULE_OK</code>. On the following errors<br><code>VALKEYMODULE_ERR</code> is returned:</p>\n<ul>\n<li>The key was not opened for writing.</li>\n<li>The key is of the wrong type.</li>\n<li>&#39;score&#39; double value is not a number (NaN).</li>\n</ul>\n<p><span id=\"ValkeyModule_ZsetIncrby\"></span></p>\n<h3><code>ValkeyModule_ZsetIncrby</code></h3>\n<pre><code>int ValkeyModule_ZsetIncrby(ValkeyModuleKey *key,\n                            double score,\n                            ValkeyModuleString *ele,\n                            int *flagsptr,\n                            double *newscore);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>This function works exactly like <a href=\"#ValkeyModule_ZsetAdd\"><code>ValkeyModule_ZsetAdd()</code></a>, but instead of setting<br>a new score, the score of the existing element is incremented, or if the<br>element does not already exist, it is added assuming the old score was<br>zero.</p>\n<p>The input and output flags, and the return value, have the same exact<br>meaning, with the only difference that this function will return<br><code>VALKEYMODULE_ERR</code> even when &#39;score&#39; is a valid double number, but adding it<br>to the existing score results into a NaN (not a number) condition.</p>\n<p>This function has an additional field &#39;newscore&#39;, if not NULL is filled<br>with the new score of the element after the increment, if no error<br>is returned.</p>\n<p><span id=\"ValkeyModule_ZsetRem\"></span></p>\n<h3><code>ValkeyModule_ZsetRem</code></h3>\n<pre><code>int ValkeyModule_ZsetRem(ValkeyModuleKey *key,\n                         ValkeyModuleString *ele,\n                         int *deleted);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Remove the specified element from the sorted set.<br>The function returns <code>VALKEYMODULE_OK</code> on success, and <code>VALKEYMODULE_ERR</code><br>on one of the following conditions:</p>\n<ul>\n<li>The key was not opened for writing.</li>\n<li>The key is of the wrong type.</li>\n</ul>\n<p>The return value does NOT indicate the fact the element was really<br>removed (since it existed) or not, just if the function was executed<br>with success.</p>\n<p>In order to know if the element was removed, the additional argument<br>&#39;deleted&#39; must be passed, that populates the integer by reference<br>setting it to 1 or 0 depending on the outcome of the operation.<br>The &#39;deleted&#39; argument can be NULL if the caller is not interested<br>to know if the element was really removed.</p>\n<p>Empty keys will be handled correctly by doing nothing.</p>\n<p><span id=\"ValkeyModule_ZsetScore\"></span></p>\n<h3><code>ValkeyModule_ZsetScore</code></h3>\n<pre><code>int ValkeyModule_ZsetScore(ValkeyModuleKey *key,\n                           ValkeyModuleString *ele,\n                           double *score);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>On success retrieve the double score associated at the sorted set element<br>&#39;ele&#39; and returns <code>VALKEYMODULE_OK</code>. Otherwise <code>VALKEYMODULE_ERR</code> is returned<br>to signal one of the following conditions:</p>\n<ul>\n<li>There is no such element &#39;ele&#39; in the sorted set.</li>\n<li>The key is not a sorted set.</li>\n<li>The key is an open empty key.</li>\n</ul>\n<p><span id=\"section-key-api-for-sorted-set-iterator\"></span></p>\n<h2>Key API for Sorted Set iterator</h2>\n<p><span id=\"ValkeyModule_ZsetRangeStop\"></span></p>\n<h3><code>ValkeyModule_ZsetRangeStop</code></h3>\n<pre><code>void ValkeyModule_ZsetRangeStop(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Stop a sorted set iteration.</p>\n<p><span id=\"ValkeyModule_ZsetRangeEndReached\"></span></p>\n<h3><code>ValkeyModule_ZsetRangeEndReached</code></h3>\n<pre><code>int ValkeyModule_ZsetRangeEndReached(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return the &quot;End of range&quot; flag value to signal the end of the iteration.</p>\n<p><span id=\"ValkeyModule_ZsetFirstInScoreRange\"></span></p>\n<h3><code>ValkeyModule_ZsetFirstInScoreRange</code></h3>\n<pre><code>int ValkeyModule_ZsetFirstInScoreRange(ValkeyModuleKey *key,\n                                       double min,\n                                       double max,\n                                       int minex,\n                                       int maxex);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Setup a sorted set iterator seeking the first element in the specified<br>range. Returns <code>VALKEYMODULE_OK</code> if the iterator was correctly initialized<br>otherwise <code>VALKEYMODULE_ERR</code> is returned in the following conditions:</p>\n<ol>\n<li>The value stored at key is not a sorted set or the key is empty.</li>\n</ol>\n<p>The range is specified according to the two double values &#39;min&#39; and &#39;max&#39;.<br>Both can be infinite using the following two macros:</p>\n<ul>\n<li><code>VALKEYMODULE_POSITIVE_INFINITE</code> for positive infinite value</li>\n<li><code>VALKEYMODULE_NEGATIVE_INFINITE</code> for negative infinite value</li>\n</ul>\n<p>&#39;minex&#39; and &#39;maxex&#39; parameters, if true, respectively setup a range<br>where the min and max value are exclusive (not included) instead of<br>inclusive.</p>\n<p><span id=\"ValkeyModule_ZsetLastInScoreRange\"></span></p>\n<h3><code>ValkeyModule_ZsetLastInScoreRange</code></h3>\n<pre><code>int ValkeyModule_ZsetLastInScoreRange(ValkeyModuleKey *key,\n                                      double min,\n                                      double max,\n                                      int minex,\n                                      int maxex);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Exactly like <a href=\"#ValkeyModule_ZsetFirstInScoreRange\"><code>ValkeyModule_ZsetFirstInScoreRange()</code></a> but the last element of<br>the range is selected for the start of the iteration instead.</p>\n<p><span id=\"ValkeyModule_ZsetFirstInLexRange\"></span></p>\n<h3><code>ValkeyModule_ZsetFirstInLexRange</code></h3>\n<pre><code>int ValkeyModule_ZsetFirstInLexRange(ValkeyModuleKey *key,\n                                     ValkeyModuleString *min,\n                                     ValkeyModuleString *max);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Setup a sorted set iterator seeking the first element in the specified<br>lexicographical range. Returns <code>VALKEYMODULE_OK</code> if the iterator was correctly<br>initialized otherwise <code>VALKEYMODULE_ERR</code> is returned in the<br>following conditions:</p>\n<ol>\n<li>The value stored at key is not a sorted set or the key is empty.</li>\n<li>The lexicographical range &#39;min&#39; and &#39;max&#39; format is invalid.</li>\n</ol>\n<p>&#39;min&#39; and &#39;max&#39; should be provided as two <code>ValkeyModuleString</code> objects<br>in the same format as the parameters passed to the ZRANGEBYLEX command.<br>The function does not take ownership of the objects, so they can be released<br>ASAP after the iterator is setup.</p>\n<p><span id=\"ValkeyModule_ZsetLastInLexRange\"></span></p>\n<h3><code>ValkeyModule_ZsetLastInLexRange</code></h3>\n<pre><code>int ValkeyModule_ZsetLastInLexRange(ValkeyModuleKey *key,\n                                    ValkeyModuleString *min,\n                                    ValkeyModuleString *max);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Exactly like <a href=\"#ValkeyModule_ZsetFirstInLexRange\"><code>ValkeyModule_ZsetFirstInLexRange()</code></a> but the last element of<br>the range is selected for the start of the iteration instead.</p>\n<p><span id=\"ValkeyModule_ZsetRangeCurrentElement\"></span></p>\n<h3><code>ValkeyModule_ZsetRangeCurrentElement</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_ZsetRangeCurrentElement(ValkeyModuleKey *key,\n                                                         double *score);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return the current sorted set element of an active sorted set iterator<br>or NULL if the range specified in the iterator does not include any<br>element.</p>\n<p><span id=\"ValkeyModule_ZsetRangeNext\"></span></p>\n<h3><code>ValkeyModule_ZsetRangeNext</code></h3>\n<pre><code>int ValkeyModule_ZsetRangeNext(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Go to the next element of the sorted set iterator. Returns 1 if there was<br>a next element, 0 if we are already at the latest element or the range<br>does not include any item at all.</p>\n<p><span id=\"ValkeyModule_ZsetRangePrev\"></span></p>\n<h3><code>ValkeyModule_ZsetRangePrev</code></h3>\n<pre><code>int ValkeyModule_ZsetRangePrev(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Go to the previous element of the sorted set iterator. Returns 1 if there was<br>a previous element, 0 if we are already at the first element or the range<br>does not include any item at all.</p>\n<p><span id=\"section-key-api-for-hash-type\"></span></p>\n<h2>Key API for Hash type</h2>\n<p>See also <a href=\"#ValkeyModule_ValueLength\"><code>ValkeyModule_ValueLength()</code></a>, which returns the number of fields in a hash.</p>\n<p><span id=\"ValkeyModule_HashSet\"></span></p>\n<h3><code>ValkeyModule_HashSet</code></h3>\n<pre><code>int ValkeyModule_HashSet(ValkeyModuleKey *key, int flags, ...);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Set the field of the specified hash field to the specified value.<br>If the key is an empty key open for writing, it is created with an empty<br>hash value, in order to set the specified field.</p>\n<p>The function is variadic and the user must specify pairs of field<br>names and values, both as <code>ValkeyModuleString</code> pointers (unless the<br>CFIELD option is set, see later). At the end of the field/value-ptr pairs,<br>NULL must be specified as last argument to signal the end of the arguments<br>in the variadic function.</p>\n<p>Example to set the hash argv[1] to the value argv[2]:</p>\n<pre><code> ValkeyModule_HashSet(key,VALKEYMODULE_HASH_NONE,argv[1],argv[2],NULL);\n</code></pre>\n<p>The function can also be used in order to delete fields (if they exist)<br>by setting them to the specified value of <code>VALKEYMODULE_HASH_DELETE</code>:</p>\n<pre><code> ValkeyModule_HashSet(key,VALKEYMODULE_HASH_NONE,argv[1],\n                     VALKEYMODULE_HASH_DELETE,NULL);\n</code></pre>\n<p>The behavior of the command changes with the specified flags, that can be<br>set to <code>VALKEYMODULE_HASH_NONE</code> if no special behavior is needed.</p>\n<pre><code>VALKEYMODULE_HASH_NX: The operation is performed only if the field was not\n                     already existing in the hash.\nVALKEYMODULE_HASH_XX: The operation is performed only if the field was\n                     already existing, so that a new value could be\n                     associated to an existing filed, but no new fields\n                     are created.\nVALKEYMODULE_HASH_CFIELDS: The field names passed are null terminated C\n                          strings instead of ValkeyModuleString objects.\nVALKEYMODULE_HASH_COUNT_ALL: Include the number of inserted fields in the\n                            returned number, in addition to the number of\n                            updated and deleted fields. (Added in Redis OSS\n                            6.2.)\n</code></pre>\n<p>Unless NX is specified, the command overwrites the old field value with<br>the new one.</p>\n<p>When using <code>VALKEYMODULE_HASH_CFIELDS</code>, field names are reported using<br>normal C strings, so for example to delete the field &quot;foo&quot; the following<br>code can be used:</p>\n<pre><code> ValkeyModule_HashSet(key,VALKEYMODULE_HASH_CFIELDS,&quot;foo&quot;,\n                     VALKEYMODULE_HASH_DELETE,NULL);\n</code></pre>\n<p>Return value:</p>\n<p>The number of fields existing in the hash prior to the call, which have been<br>updated (its old value has been replaced by a new value) or deleted. If the<br>flag <code>VALKEYMODULE_HASH_COUNT_ALL</code> is set, inserted fields not previously<br>existing in the hash are also counted.</p>\n<p>If the return value is zero, <code>errno</code> is set (since Redis OSS 6.2) as follows:</p>\n<ul>\n<li>EINVAL if any unknown flags are set or if key is NULL.</li>\n<li>ENOTSUP if the key is associated with a non Hash value.</li>\n<li>EBADF if the key was not opened for writing.</li>\n<li>ENOENT if no fields were counted as described under Return value above.<br>This is not actually an error. The return value can be zero if all fields<br>were just created and the <code>COUNT_ALL</code> flag was unset, or if changes were held<br>back due to the NX and XX flags.</li>\n</ul>\n<p>NOTICE: The return value semantics of this function are very different<br>between Redis OSS 6.2 and older versions. Modules that use it should determine<br>the server version and handle it accordingly.</p>\n<p><span id=\"ValkeyModule_HashGet\"></span></p>\n<h3><code>ValkeyModule_HashGet</code></h3>\n<pre><code>int ValkeyModule_HashGet(ValkeyModuleKey *key, int flags, ...);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Get fields from a hash value. This function is called using a variable<br>number of arguments, alternating a field name (as a <code>ValkeyModuleString</code><br>pointer) with a pointer to a <code>ValkeyModuleString</code> pointer, that is set to the<br>value of the field if the field exists, or NULL if the field does not exist.<br>At the end of the field/value-ptr pairs, NULL must be specified as last<br>argument to signal the end of the arguments in the variadic function.</p>\n<p>This is an example usage:</p>\n<pre><code> ValkeyModuleString *first, *second;\n ValkeyModule_HashGet(mykey,VALKEYMODULE_HASH_NONE,argv[1],&amp;first,\n                     argv[2],&amp;second,NULL);\n</code></pre>\n<p>As with <a href=\"#ValkeyModule_HashSet\"><code>ValkeyModule_HashSet()</code></a> the behavior of the command can be specified<br>passing flags different than <code>VALKEYMODULE_HASH_NONE</code>:</p>\n<p><code>VALKEYMODULE_HASH_CFIELDS</code>: field names as null terminated C strings.</p>\n<p><code>VALKEYMODULE_HASH_EXISTS</code>: instead of setting the value of the field<br>expecting a <code>ValkeyModuleString</code> pointer to pointer, the function just<br>reports if the field exists or not and expects an integer pointer<br>as the second element of each pair.</p>\n<p>Example of <code>VALKEYMODULE_HASH_CFIELDS</code>:</p>\n<pre><code> ValkeyModuleString *username, *hashedpass;\n ValkeyModule_HashGet(mykey,VALKEYMODULE_HASH_CFIELDS,&quot;username&quot;,&amp;username,&quot;hp&quot;,&amp;hashedpass, NULL);\n</code></pre>\n<p>Example of <code>VALKEYMODULE_HASH_EXISTS</code>:</p>\n<pre><code> int exists;\n ValkeyModule_HashGet(mykey,VALKEYMODULE_HASH_EXISTS,argv[1],&amp;exists,NULL);\n</code></pre>\n<p>The function returns <code>VALKEYMODULE_OK</code> on success and <code>VALKEYMODULE_ERR</code> if<br>the key is not a hash value.</p>\n<p>Memory management:</p>\n<p>The returned <code>ValkeyModuleString</code> objects should be released with<br><a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a>, or by enabling automatic memory management.</p>\n<p><span id=\"section-key-api-for-stream-type\"></span></p>\n<h2>Key API for Stream type</h2>\n<p>For an introduction to streams, see <a href=\"https://valkey.io/topics/streams-intro\">https://valkey.io/topics/streams-intro</a>.</p>\n<p>The type <code>ValkeyModuleStreamID</code>, which is used in stream functions, is a struct<br>with two 64-bit fields and is defined as</p>\n<pre><code>typedef struct ValkeyModuleStreamID {\n    uint64_t ms;\n    uint64_t seq;\n} ValkeyModuleStreamID;\n</code></pre>\n<p>See also <a href=\"#ValkeyModule_ValueLength\"><code>ValkeyModule_ValueLength()</code></a>, which returns the length of a stream, and the<br>conversion functions <a href=\"#ValkeyModule_StringToStreamID\"><code>ValkeyModule_StringToStreamID()</code></a> and <a href=\"#ValkeyModule_CreateStringFromStreamID\"><code>ValkeyModule_CreateStringFromStreamID()</code></a>.</p>\n<p><span id=\"ValkeyModule_StreamAdd\"></span></p>\n<h3><code>ValkeyModule_StreamAdd</code></h3>\n<pre><code>int ValkeyModule_StreamAdd(ValkeyModuleKey *key,\n                           int flags,\n                           ValkeyModuleStreamID *id,\n                           ValkeyModuleString **argv,\n                           long numfields);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Adds an entry to a stream. Like XADD without trimming.</p>\n<ul>\n<li><code>key</code>: The key where the stream is (or will be) stored</li>\n<li><code>flags</code>: A bit field of<ul>\n<li><code>VALKEYMODULE_STREAM_ADD_AUTOID</code>: Assign a stream ID automatically, like<br><code>*</code> in the XADD command.</li>\n</ul>\n</li>\n<li><code>id</code>: If the <code>AUTOID</code> flag is set, this is where the assigned ID is<br>returned. Can be NULL if <code>AUTOID</code> is set, if you don&#39;t care to receive the<br>ID. If <code>AUTOID</code> is not set, this is the requested ID.</li>\n<li><code>argv</code>: A pointer to an array of size <code>numfields * 2</code> containing the<br>fields and values.</li>\n<li><code>numfields</code>: The number of field-value pairs in <code>argv</code>.</li>\n</ul>\n<p>Returns <code>VALKEYMODULE_OK</code> if an entry has been added. On failure,<br><code>VALKEYMODULE_ERR</code> is returned and <code>errno</code> is set as follows:</p>\n<ul>\n<li>EINVAL if called with invalid arguments</li>\n<li>ENOTSUP if the key refers to a value of a type other than stream</li>\n<li>EBADF if the key was not opened for writing</li>\n<li>EDOM if the given ID was 0-0 or not greater than all other IDs in the<br>stream (only if the AUTOID flag is unset)</li>\n<li>EFBIG if the stream has reached the last possible ID</li>\n<li>ERANGE if the elements are too large to be stored.</li>\n</ul>\n<p><span id=\"ValkeyModule_StreamDelete\"></span></p>\n<h3><code>ValkeyModule_StreamDelete</code></h3>\n<pre><code>int ValkeyModule_StreamDelete(ValkeyModuleKey *key, ValkeyModuleStreamID *id);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Deletes an entry from a stream.</p>\n<ul>\n<li><code>key</code>: A key opened for writing, with no stream iterator started.</li>\n<li><code>id</code>: The stream ID of the entry to delete.</li>\n</ul>\n<p>Returns <code>VALKEYMODULE_OK</code> on success. On failure, <code>VALKEYMODULE_ERR</code> is returned<br>and <code>errno</code> is set as follows:</p>\n<ul>\n<li>EINVAL if called with invalid arguments</li>\n<li>ENOTSUP if the key refers to a value of a type other than stream or if the<br>key is empty</li>\n<li>EBADF if the key was not opened for writing or if a stream iterator is<br>associated with the key</li>\n<li>ENOENT if no entry with the given stream ID exists</li>\n</ul>\n<p>See also <a href=\"#ValkeyModule_StreamIteratorDelete\"><code>ValkeyModule_StreamIteratorDelete()</code></a> for deleting the current entry while<br>iterating using a stream iterator.</p>\n<p><span id=\"ValkeyModule_StreamIteratorStart\"></span></p>\n<h3><code>ValkeyModule_StreamIteratorStart</code></h3>\n<pre><code>int ValkeyModule_StreamIteratorStart(ValkeyModuleKey *key,\n                                     int flags,\n                                     ValkeyModuleStreamID *start,\n                                     ValkeyModuleStreamID *end);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Sets up a stream iterator.</p>\n<ul>\n<li><code>key</code>: The stream key opened for reading using <a href=\"#ValkeyModule_OpenKey\"><code>ValkeyModule_OpenKey()</code></a>.</li>\n<li><code>flags</code>:<ul>\n<li><code>VALKEYMODULE_STREAM_ITERATOR_EXCLUSIVE</code>: Don&#39;t include <code>start</code> and <code>end</code><br>in the iterated range.</li>\n<li><code>VALKEYMODULE_STREAM_ITERATOR_REVERSE</code>: Iterate in reverse order, starting<br>from the <code>end</code> of the range.</li>\n</ul>\n</li>\n<li><code>start</code>: The lower bound of the range. Use NULL for the beginning of the<br>stream.</li>\n<li><code>end</code>: The upper bound of the range. Use NULL for the end of the stream.</li>\n</ul>\n<p>Returns <code>VALKEYMODULE_OK</code> on success. On failure, <code>VALKEYMODULE_ERR</code> is returned<br>and <code>errno</code> is set as follows:</p>\n<ul>\n<li>EINVAL if called with invalid arguments</li>\n<li>ENOTSUP if the key refers to a value of a type other than stream or if the<br>key is empty</li>\n<li>EBADF if the key was not opened for writing or if a stream iterator is<br>already associated with the key</li>\n<li>EDOM if <code>start</code> or <code>end</code> is outside the valid range</li>\n</ul>\n<p>Returns <code>VALKEYMODULE_OK</code> on success and <code>VALKEYMODULE_ERR</code> if the key doesn&#39;t<br>refer to a stream or if invalid arguments were given.</p>\n<p>The stream IDs are retrieved using <a href=\"#ValkeyModule_StreamIteratorNextID\"><code>ValkeyModule_StreamIteratorNextID()</code></a> and<br>for each stream ID, the fields and values are retrieved using<br><a href=\"#ValkeyModule_StreamIteratorNextField\"><code>ValkeyModule_StreamIteratorNextField()</code></a>. The iterator is freed by calling<br><a href=\"#ValkeyModule_StreamIteratorStop\"><code>ValkeyModule_StreamIteratorStop()</code></a>.</p>\n<p>Example (error handling omitted):</p>\n<pre><code>ValkeyModule_StreamIteratorStart(key, 0, startid_ptr, endid_ptr);\nValkeyModuleStreamID id;\nlong numfields;\nwhile (ValkeyModule_StreamIteratorNextID(key, &amp;id, &amp;numfields) ==\n       VALKEYMODULE_OK) {\n    ValkeyModuleString *field, *value;\n    while (ValkeyModule_StreamIteratorNextField(key, &amp;field, &amp;value) ==\n           VALKEYMODULE_OK) {\n        //\n        // ... Do stuff ...\n        //\n        ValkeyModule_FreeString(ctx, field);\n        ValkeyModule_FreeString(ctx, value);\n    }\n}\nValkeyModule_StreamIteratorStop(key);\n</code></pre>\n<p><span id=\"ValkeyModule_StreamIteratorStop\"></span></p>\n<h3><code>ValkeyModule_StreamIteratorStop</code></h3>\n<pre><code>int ValkeyModule_StreamIteratorStop(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Stops a stream iterator created using <a href=\"#ValkeyModule_StreamIteratorStart\"><code>ValkeyModule_StreamIteratorStart()</code></a> and<br>reclaims its memory.</p>\n<p>Returns <code>VALKEYMODULE_OK</code> on success. On failure, <code>VALKEYMODULE_ERR</code> is returned<br>and <code>errno</code> is set as follows:</p>\n<ul>\n<li>EINVAL if called with a NULL key</li>\n<li>ENOTSUP if the key refers to a value of a type other than stream or if the<br>key is empty</li>\n<li>EBADF if the key was not opened for writing or if no stream iterator is<br>associated with the key</li>\n</ul>\n<p><span id=\"ValkeyModule_StreamIteratorNextID\"></span></p>\n<h3><code>ValkeyModule_StreamIteratorNextID</code></h3>\n<pre><code>int ValkeyModule_StreamIteratorNextID(ValkeyModuleKey *key,\n                                      ValkeyModuleStreamID *id,\n                                      long *numfields);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Finds the next stream entry and returns its stream ID and the number of<br>fields.</p>\n<ul>\n<li><code>key</code>: Key for which a stream iterator has been started using<br><a href=\"#ValkeyModule_StreamIteratorStart\"><code>ValkeyModule_StreamIteratorStart()</code></a>.</li>\n<li><code>id</code>: The stream ID returned. NULL if you don&#39;t care.</li>\n<li><code>numfields</code>: The number of fields in the found stream entry. NULL if you<br>don&#39;t care.</li>\n</ul>\n<p>Returns <code>VALKEYMODULE_OK</code> and sets <code>*id</code> and <code>*numfields</code> if an entry was found.<br>On failure, <code>VALKEYMODULE_ERR</code> is returned and <code>errno</code> is set as follows:</p>\n<ul>\n<li>EINVAL if called with a NULL key</li>\n<li>ENOTSUP if the key refers to a value of a type other than stream or if the<br>key is empty</li>\n<li>EBADF if no stream iterator is associated with the key</li>\n<li>ENOENT if there are no more entries in the range of the iterator</li>\n</ul>\n<p>In practice, if <a href=\"#ValkeyModule_StreamIteratorNextID\"><code>ValkeyModule_StreamIteratorNextID()</code></a> is called after a successful call<br>to <a href=\"#ValkeyModule_StreamIteratorStart\"><code>ValkeyModule_StreamIteratorStart()</code></a> and with the same key, it is safe to assume that<br>an <code>VALKEYMODULE_ERR</code> return value means that there are no more entries.</p>\n<p>Use <a href=\"#ValkeyModule_StreamIteratorNextField\"><code>ValkeyModule_StreamIteratorNextField()</code></a> to retrieve the fields and values.<br>See the example at <a href=\"#ValkeyModule_StreamIteratorStart\"><code>ValkeyModule_StreamIteratorStart()</code></a>.</p>\n<p><span id=\"ValkeyModule_StreamIteratorNextField\"></span></p>\n<h3><code>ValkeyModule_StreamIteratorNextField</code></h3>\n<pre><code>int ValkeyModule_StreamIteratorNextField(ValkeyModuleKey *key,\n                                         ValkeyModuleString **field_ptr,\n                                         ValkeyModuleString **value_ptr);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Retrieves the next field of the current stream ID and its corresponding value<br>in a stream iteration. This function should be called repeatedly after calling<br><a href=\"#ValkeyModule_StreamIteratorNextID\"><code>ValkeyModule_StreamIteratorNextID()</code></a> to fetch each field-value pair.</p>\n<ul>\n<li><code>key</code>: Key where a stream iterator has been started.</li>\n<li><code>field_ptr</code>: This is where the field is returned.</li>\n<li><code>value_ptr</code>: This is where the value is returned.</li>\n</ul>\n<p>Returns <code>VALKEYMODULE_OK</code> and points <code>*field_ptr</code> and <code>*value_ptr</code> to freshly<br>allocated <code>ValkeyModuleString</code> objects. The string objects are freed<br>automatically when the callback finishes if automatic memory is enabled. On<br>failure, <code>VALKEYMODULE_ERR</code> is returned and <code>errno</code> is set as follows:</p>\n<ul>\n<li>EINVAL if called with a NULL key</li>\n<li>ENOTSUP if the key refers to a value of a type other than stream or if the<br>key is empty</li>\n<li>EBADF if no stream iterator is associated with the key</li>\n<li>ENOENT if there are no more fields in the current stream entry</li>\n</ul>\n<p>In practice, if <a href=\"#ValkeyModule_StreamIteratorNextField\"><code>ValkeyModule_StreamIteratorNextField()</code></a> is called after a successful<br>call to <a href=\"#ValkeyModule_StreamIteratorNextID\"><code>ValkeyModule_StreamIteratorNextID()</code></a> and with the same key, it is safe to assume<br>that an <code>VALKEYMODULE_ERR</code> return value means that there are no more fields.</p>\n<p>See the example at <a href=\"#ValkeyModule_StreamIteratorStart\"><code>ValkeyModule_StreamIteratorStart()</code></a>.</p>\n<p><span id=\"ValkeyModule_StreamIteratorDelete\"></span></p>\n<h3><code>ValkeyModule_StreamIteratorDelete</code></h3>\n<pre><code>int ValkeyModule_StreamIteratorDelete(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Deletes the current stream entry while iterating.</p>\n<p>This function can be called after <a href=\"#ValkeyModule_StreamIteratorNextID\"><code>ValkeyModule_StreamIteratorNextID()</code></a> or after any<br>calls to <a href=\"#ValkeyModule_StreamIteratorNextField\"><code>ValkeyModule_StreamIteratorNextField()</code></a>.</p>\n<p>Returns <code>VALKEYMODULE_OK</code> on success. On failure, <code>VALKEYMODULE_ERR</code> is returned<br>and <code>errno</code> is set as follows:</p>\n<ul>\n<li>EINVAL if key is NULL</li>\n<li>ENOTSUP if the key is empty or is of another type than stream</li>\n<li>EBADF if the key is not opened for writing, if no iterator has been started</li>\n<li>ENOENT if the iterator has no current stream entry</li>\n</ul>\n<p><span id=\"ValkeyModule_StreamTrimByLength\"></span></p>\n<h3><code>ValkeyModule_StreamTrimByLength</code></h3>\n<pre><code>long long ValkeyModule_StreamTrimByLength(ValkeyModuleKey *key,\n                                          int flags,\n                                          long long length);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Trim a stream by length, similar to XTRIM with MAXLEN.</p>\n<ul>\n<li><code>key</code>: Key opened for writing.</li>\n<li><code>flags</code>: A bitfield of<ul>\n<li><code>VALKEYMODULE_STREAM_TRIM_APPROX</code>: Trim less if it improves performance,<br>like XTRIM with <code>~</code>.</li>\n</ul>\n</li>\n<li><code>length</code>: The number of stream entries to keep after trimming.</li>\n</ul>\n<p>Returns the number of entries deleted. On failure, a negative value is<br>returned and <code>errno</code> is set as follows:</p>\n<ul>\n<li>EINVAL if called with invalid arguments</li>\n<li>ENOTSUP if the key is empty or of a type other than stream</li>\n<li>EBADF if the key is not opened for writing</li>\n</ul>\n<p><span id=\"ValkeyModule_StreamTrimByID\"></span></p>\n<h3><code>ValkeyModule_StreamTrimByID</code></h3>\n<pre><code>long long ValkeyModule_StreamTrimByID(ValkeyModuleKey *key,\n                                      int flags,\n                                      ValkeyModuleStreamID *id);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Trim a stream by ID, similar to XTRIM with MINID.</p>\n<ul>\n<li><code>key</code>: Key opened for writing.</li>\n<li><code>flags</code>: A bitfield of<ul>\n<li><code>VALKEYMODULE_STREAM_TRIM_APPROX</code>: Trim less if it improves performance,<br>like XTRIM with <code>~</code>.</li>\n</ul>\n</li>\n<li><code>id</code>: The smallest stream ID to keep after trimming.</li>\n</ul>\n<p>Returns the number of entries deleted. On failure, a negative value is<br>returned and <code>errno</code> is set as follows:</p>\n<ul>\n<li>EINVAL if called with invalid arguments</li>\n<li>ENOTSUP if the key is empty or of a type other than stream</li>\n<li>EBADF if the key is not opened for writing</li>\n</ul>\n<p><span id=\"section-calling-commands-from-modules\"></span></p>\n<h2>Calling commands from modules</h2>\n<p><a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call()</code></a> sends a command to the server. The remaining functions handle the reply.</p>\n<p><span id=\"ValkeyModule_FreeCallReply\"></span></p>\n<h3><code>ValkeyModule_FreeCallReply</code></h3>\n<pre><code>void ValkeyModule_FreeCallReply(ValkeyModuleCallReply *reply);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Free a Call reply and all the nested replies it contains if it&#39;s an<br>array.</p>\n<p><span id=\"ValkeyModule_CallReplyType\"></span></p>\n<h3><code>ValkeyModule_CallReplyType</code></h3>\n<pre><code>int ValkeyModule_CallReplyType(ValkeyModuleCallReply *reply);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return the reply type as one of the following:</p>\n<ul>\n<li><code>VALKEYMODULE_REPLY_UNKNOWN</code></li>\n<li><code>VALKEYMODULE_REPLY_STRING</code></li>\n<li><code>VALKEYMODULE_REPLY_ERROR</code></li>\n<li><code>VALKEYMODULE_REPLY_INTEGER</code></li>\n<li><code>VALKEYMODULE_REPLY_ARRAY</code></li>\n<li><code>VALKEYMODULE_REPLY_NULL</code></li>\n<li><code>VALKEYMODULE_REPLY_MAP</code></li>\n<li><code>VALKEYMODULE_REPLY_SET</code></li>\n<li><code>VALKEYMODULE_REPLY_BOOL</code></li>\n<li><code>VALKEYMODULE_REPLY_DOUBLE</code></li>\n<li><code>VALKEYMODULE_REPLY_BIG_NUMBER</code></li>\n<li><code>VALKEYMODULE_REPLY_VERBATIM_STRING</code></li>\n<li><code>VALKEYMODULE_REPLY_ATTRIBUTE</code></li>\n<li><code>VALKEYMODULE_REPLY_PROMISE</code></li>\n</ul>\n<p><span id=\"ValkeyModule_CallReplyLength\"></span></p>\n<h3><code>ValkeyModule_CallReplyLength</code></h3>\n<pre><code>size_t ValkeyModule_CallReplyLength(ValkeyModuleCallReply *reply);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return the reply type length, where applicable.</p>\n<p><span id=\"ValkeyModule_CallReplyArrayElement\"></span></p>\n<h3><code>ValkeyModule_CallReplyArrayElement</code></h3>\n<pre><code>ValkeyModuleCallReply *ValkeyModule_CallReplyArrayElement(ValkeyModuleCallReply *reply,\n                                                          size_t idx);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return the &#39;idx&#39;-th nested call reply element of an array reply, or NULL<br>if the reply type is wrong or the index is out of range.</p>\n<p><span id=\"ValkeyModule_CallReplyInteger\"></span></p>\n<h3><code>ValkeyModule_CallReplyInteger</code></h3>\n<pre><code>long long ValkeyModule_CallReplyInteger(ValkeyModuleCallReply *reply);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return the <code>long long</code> of an integer reply.</p>\n<p><span id=\"ValkeyModule_CallReplyDouble\"></span></p>\n<h3><code>ValkeyModule_CallReplyDouble</code></h3>\n<pre><code>double ValkeyModule_CallReplyDouble(ValkeyModuleCallReply *reply);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Return the double value of a double reply.</p>\n<p><span id=\"ValkeyModule_CallReplyBigNumber\"></span></p>\n<h3><code>ValkeyModule_CallReplyBigNumber</code></h3>\n<pre><code>const char *ValkeyModule_CallReplyBigNumber(ValkeyModuleCallReply *reply,\n                                            size_t *len);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Return the big number value of a big number reply.</p>\n<p><span id=\"ValkeyModule_CallReplyVerbatim\"></span></p>\n<h3><code>ValkeyModule_CallReplyVerbatim</code></h3>\n<pre><code>const char *ValkeyModule_CallReplyVerbatim(ValkeyModuleCallReply *reply,\n                                           size_t *len,\n                                           const char **format);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Return the value of a verbatim string reply,<br>An optional output argument can be given to get verbatim reply format.</p>\n<p><span id=\"ValkeyModule_CallReplyBool\"></span></p>\n<h3><code>ValkeyModule_CallReplyBool</code></h3>\n<pre><code>int ValkeyModule_CallReplyBool(ValkeyModuleCallReply *reply);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Return the Boolean value of a Boolean reply.</p>\n<p><span id=\"ValkeyModule_CallReplySetElement\"></span></p>\n<h3><code>ValkeyModule_CallReplySetElement</code></h3>\n<pre><code>ValkeyModuleCallReply *ValkeyModule_CallReplySetElement(ValkeyModuleCallReply *reply,\n                                                        size_t idx);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Return the &#39;idx&#39;-th nested call reply element of a set reply, or NULL<br>if the reply type is wrong or the index is out of range.</p>\n<p><span id=\"ValkeyModule_CallReplyMapElement\"></span></p>\n<h3><code>ValkeyModule_CallReplyMapElement</code></h3>\n<pre><code>int ValkeyModule_CallReplyMapElement(ValkeyModuleCallReply *reply,\n                                     size_t idx,\n                                     ValkeyModuleCallReply **key,\n                                     ValkeyModuleCallReply **val);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Retrieve the &#39;idx&#39;-th key and value of a map reply.</p>\n<p>Returns:</p>\n<ul>\n<li><code>VALKEYMODULE_OK</code> on success.</li>\n<li><code>VALKEYMODULE_ERR</code> if idx out of range or if the reply type is wrong.</li>\n</ul>\n<p>The <code>key</code> and <code>value</code> arguments are used to return by reference, and may be<br>NULL if not required.</p>\n<p><span id=\"ValkeyModule_CallReplyAttribute\"></span></p>\n<h3><code>ValkeyModule_CallReplyAttribute</code></h3>\n<pre><code>ValkeyModuleCallReply *ValkeyModule_CallReplyAttribute(ValkeyModuleCallReply *reply);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Return the attribute of the given reply, or NULL if no attribute exists.</p>\n<p><span id=\"ValkeyModule_CallReplyAttributeElement\"></span></p>\n<h3><code>ValkeyModule_CallReplyAttributeElement</code></h3>\n<pre><code> int ValkeyModule_CallReplyAttributeElement(ValkeyModuleCallReply *reply,\n                                           size_t idx,\n                                           ValkeyModuleCallReply **key,\n                                           ValkeyModuleCallReply **val);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Retrieve the &#39;idx&#39;-th key and value of an attribute reply.</p>\n<p>Returns:</p>\n<ul>\n<li><code>VALKEYMODULE_OK</code> on success.</li>\n<li><code>VALKEYMODULE_ERR</code> if idx out of range or if the reply type is wrong.</li>\n</ul>\n<p>The <code>key</code> and <code>value</code> arguments are used to return by reference, and may be<br>NULL if not required.</p>\n<p><span id=\"ValkeyModule_CallReplyPromiseSetUnblockHandler\"></span></p>\n<h3><code>ValkeyModule_CallReplyPromiseSetUnblockHandler</code></h3>\n<pre><code> void ValkeyModule_CallReplyPromiseSetUnblockHandler(ValkeyModuleCallReply *reply,\n                                                    ValkeyModuleOnUnblocked on_unblock,\n                                                    void *private_data);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Set unblock handler (callback and private data) on the given promise <code>ValkeyModuleCallReply</code>.<br>The given reply must be of promise type (<code>VALKEYMODULE_REPLY_PROMISE</code>).</p>\n<p><span id=\"ValkeyModule_CallReplyPromiseAbort\"></span></p>\n<h3><code>ValkeyModule_CallReplyPromiseAbort</code></h3>\n<pre><code>int ValkeyModule_CallReplyPromiseAbort(ValkeyModuleCallReply *reply,\n                                       void **private_data);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Abort the execution of a given promise <code>ValkeyModuleCallReply</code>.<br>return <code>REDMODULE_OK</code> in case the abort was done successfully and <code>VALKEYMODULE_ERR</code><br>if its not possible to abort the execution (execution already finished).<br>In case the execution was aborted (<code>REDMODULE_OK</code> was returned), the <code>private_data</code> out parameter<br>will be set with the value of the private data that was given on &#39;<a href=\"#ValkeyModule_CallReplyPromiseSetUnblockHandler\"><code>ValkeyModule_CallReplyPromiseSetUnblockHandler</code></a>&#39;<br>so the caller will be able to release the private data.</p>\n<p>If the execution was aborted successfully, it is promised that the unblock handler will not be called.<br>That said, it is possible that the abort operation will successes but the operation will still continue.<br>This can happened if, for example, a module implements some blocking command and does not respect the<br>disconnect callback. For server-provided commands this can not happened.</p>\n<p><span id=\"ValkeyModule_CallReplyStringPtr\"></span></p>\n<h3><code>ValkeyModule_CallReplyStringPtr</code></h3>\n<pre><code>const char *ValkeyModule_CallReplyStringPtr(ValkeyModuleCallReply *reply,\n                                            size_t *len);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return the pointer and length of a string or error reply.</p>\n<p><span id=\"ValkeyModule_CreateStringFromCallReply\"></span></p>\n<h3><code>ValkeyModule_CreateStringFromCallReply</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_CreateStringFromCallReply(ValkeyModuleCallReply *reply);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return a new string object from a call reply of type string, error or<br>integer. Otherwise (wrong reply type) return NULL.</p>\n<p><span id=\"ValkeyModule_SetContextUser\"></span></p>\n<h3><code>ValkeyModule_SetContextUser</code></h3>\n<pre><code>void ValkeyModule_SetContextUser(ValkeyModuleCtx *ctx,\n                                 const ValkeyModuleUser *user);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.6</p>\n<p>Modifies the user that <a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call</code></a> will use (e.g. for ACL checks)</p>\n<p><span id=\"ValkeyModule_Call\"></span></p>\n<h3><code>ValkeyModule_Call</code></h3>\n<pre><code>ValkeyModuleCallReply *ValkeyModule_Call(ValkeyModuleCtx *ctx,\n                                         const char *cmdname,\n                                         const char *fmt,\n                                         ...);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Exported API to call any command from modules.</p>\n<ul>\n<li><p><strong>cmdname</strong>: The command to call.</p>\n</li>\n<li><p><strong>fmt</strong>: A format specifier string for the command&#39;s arguments. Each<br>of the arguments should be specified by a valid type specification. The<br>format specifier can also contain the modifiers <code>!</code>, <code>A</code>, <code>3</code> and <code>R</code> which<br>don&#39;t have a corresponding argument.</p>\n<ul>\n<li><code>b</code> -- The argument is a buffer and is immediately followed by another<br>   argument that is the buffer&#39;s length.</li>\n<li><code>c</code> -- The argument is a pointer to a plain C string (null-terminated).</li>\n<li><code>l</code> -- The argument is a <code>long long</code> integer.</li>\n<li><code>s</code> -- The argument is a ValkeyModuleString.</li>\n<li><code>v</code> -- The argument(s) is a vector of ValkeyModuleString.</li>\n<li><code>!</code> -- Sends the command and its arguments to replicas and AOF.</li>\n<li><code>A</code> -- Suppress AOF propagation, send only to replicas (requires <code>!</code>).</li>\n<li><code>R</code> -- Suppress replicas propagation, send only to AOF (requires <code>!</code>).</li>\n<li><code>3</code> -- Return a RESP3 reply. This will change the command reply.<br>   e.g., HGETALL returns a map instead of a flat array.</li>\n<li><code>0</code> -- Return the reply in auto mode, i.e. the reply format will be the<br>   same as the client attached to the given ValkeyModuleCtx. This will<br>   probably used when you want to pass the reply directly to the client.</li>\n<li><code>C</code> -- Run a command as the user attached to the context.<br>   User is either attached automatically via the client that directly<br>   issued the command and created the context or via ValkeyModule_SetContextUser.<br>   If the context is not directly created by an issued command (such as a<br>   background context and no user was set on it via ValkeyModule_SetContextUser,<br>   ValkeyModule_Call will fail.<br>   Checks if the command can be executed according to ACL rules and causes<br>   the command to run as the determined user, so that any future user<br>   dependent activity, such as ACL checks within scripts will proceed as<br>   expected.<br>   Otherwise, the command will run as the unrestricted user.</li>\n<li><code>S</code> -- Run the command in a script mode, this means that it will raise<br>   an error if a command which are not allowed inside a script<br>   (flagged with the <code>deny-script</code> flag) is invoked (like SHUTDOWN).<br>   In addition, on script mode, write commands are not allowed if there are<br>   not enough good replicas (as configured with <code>min-replicas-to-write</code>)<br>   or when the server is unable to persist to the disk.</li>\n<li><code>W</code> -- Do not allow to run any write command (flagged with the <code>write</code> flag).</li>\n<li><code>M</code> -- Do not allow <code>deny-oom</code> flagged commands when over the memory limit.</li>\n<li><code>E</code> -- Return error as ValkeyModuleCallReply. If there is an error before<br>   invoking the command, the error is returned using errno mechanism.<br>   This flag allows to get the error also as an error CallReply with<br>   relevant error message.</li>\n<li>&#39;D&#39; -- A &quot;Dry Run&quot; mode. Return before executing the underlying call().<br>   If everything succeeded, it will return with a NULL, otherwise it will<br>   return with a CallReply object denoting the error, as if it was called with<br>   the &#39;E&#39; code.</li>\n<li>&#39;K&#39; -- Allow running blocking commands. If enabled and the command gets blocked, a<br>   special VALKEYMODULE_REPLY_PROMISE will be returned. This reply type<br>   indicates that the command was blocked and the reply will be given asynchronously.<br>   The module can use this reply object to set a handler which will be called when<br>   the command gets unblocked using ValkeyModule_CallReplyPromiseSetUnblockHandler.<br>   The handler must be set immediately after the command invocation (without releasing<br>   the lock in between). If the handler is not set, the blocking command will<br>   still continue its execution but the reply will be ignored (fire and forget),<br>   notice that this is dangerous in case of role change, as explained below.<br>   The module can use ValkeyModule_CallReplyPromiseAbort to abort the command invocation<br>   if it was not yet finished (see ValkeyModule_CallReplyPromiseAbort documentation for more<br>   details). It is also the module&#39;s responsibility to abort the execution on role change, either by using<br>   server event (to get notified when the instance becomes a replica) or relying on the disconnect<br>   callback of the original client. Failing to do so can result in a write operation on a replica.<br>   Unlike other call replies, promise call reply <strong>must</strong> be freed while the GIL is locked.<br>   Notice that on unblocking, the only promise is that the unblock handler will be called,<br>   If the blocking ValkeyModule_Call caused the module to also block some real client (using ValkeyModule_BlockClient),<br>   it is the module responsibility to unblock this client on the unblock handler.<br>   On the unblock handler it is only allowed to perform the following:<br>   * Calling additional commands using ValkeyModule_Call<br>   * Open keys using ValkeyModule_OpenKey<br>   * Replicate data to the replica or AOF<br><br>   Specifically, it is not allowed to call any module API which are client related such as:<br>   * ValkeyModule_Reply* API&#39;s<br>   * ValkeyModule_BlockClient<br>   * ValkeyModule_GetCurrentUserName</li>\n</ul>\n</li>\n<li><p><strong>...</strong>: The actual arguments to the command.</p>\n</li>\n</ul>\n<p>On success a <code>ValkeyModuleCallReply</code> object is returned, otherwise<br>NULL is returned and errno is set to the following values:</p>\n<ul>\n<li>EBADF: wrong format specifier.</li>\n<li>EINVAL: wrong command arity.</li>\n<li>ENOENT: command does not exist.</li>\n<li>EPERM: operation in Cluster instance with key in non local slot.</li>\n<li>EROFS: operation in Cluster instance when a write command is sent<br>   in a readonly state.</li>\n<li>ENETDOWN: operation in Cluster instance when cluster is down.</li>\n<li>ENOTSUP: No ACL user for the specified module context</li>\n<li>EACCES: Command cannot be executed, according to ACL rules</li>\n<li>ENOSPC: Write or deny-oom command is not allowed</li>\n<li>ESPIPE: Command not allowed on script mode</li>\n</ul>\n<p>Example code fragment:</p>\n<pre><code> reply = ValkeyModule_Call(ctx,&quot;INCRBY&quot;,&quot;sc&quot;,argv[1],&quot;10&quot;);\n if (ValkeyModule_CallReplyType(reply) == VALKEYMODULE_REPLY_INTEGER) {\n   long long myval = ValkeyModule_CallReplyInteger(reply);\n   // Do something with myval.\n }\n</code></pre>\n<p>This API is documented here: <a href=\"https://valkey.io/topics/modules-intro\">https://valkey.io/topics/modules-intro</a></p>\n<p><span id=\"ValkeyModule_CallReplyProto\"></span></p>\n<h3><code>ValkeyModule_CallReplyProto</code></h3>\n<pre><code>const char *ValkeyModule_CallReplyProto(ValkeyModuleCallReply *reply,\n                                        size_t *len);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return a pointer, and a length, to the protocol returned by the command<br>that returned the reply object.</p>\n<p><span id=\"section-modules-data-types\"></span></p>\n<h2>Modules data types</h2>\n<p>When String DMA or using existing data structures is not enough, it is<br>possible to create new data types from scratch.<br>The module must provide a set of callbacks for handling the<br>new values exported (for example in order to provide RDB saving/loading,<br>AOF rewrite, and so forth). In this section we define this API.</p>\n<p><span id=\"ValkeyModule_CreateDataType\"></span></p>\n<h3><code>ValkeyModule_CreateDataType</code></h3>\n<pre><code>moduleType *ValkeyModule_CreateDataType(ValkeyModuleCtx *ctx,\n                                        const char *name,\n                                        int encver,\n                                        void *typemethods_ptr);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Register a new data type exported by the module. The parameters are the<br>following. Please for in depth documentation check the modules API<br>documentation, especially <a href=\"https://valkey.io/topics/modules-native-types\">https://valkey.io/topics/modules-native-types</a>.</p>\n<ul>\n<li><p><strong>name</strong>: A 9 characters data type name that MUST be unique in the<br>Modules ecosystem. Be creative... and there will be no collisions. Use<br>the charset A-Z a-z 9-0, plus the two &quot;-_&quot; characters. A good<br>idea is to use, for example <code>&lt;typename&gt;-&lt;vendor&gt;</code>. For example<br>&quot;tree-AntZ&quot; may mean &quot;Tree data structure by @antirez&quot;. To use both<br>lower case and upper case letters helps in order to prevent collisions.</p>\n</li>\n<li><p><strong>encver</strong>: Encoding version, which is, the version of the serialization<br>that a module used in order to persist data. As long as the &quot;name&quot;<br>matches, the RDB loading will be dispatched to the type callbacks<br>whatever &#39;encver&#39; is used, however the module can understand if<br>the encoding it must load are of an older version of the module.<br>For example the module &quot;tree-AntZ&quot; initially used encver=0. Later<br>after an upgrade, it started to serialize data in a different format<br>and to register the type with encver=1. However this module may<br>still load old data produced by an older version if the <code>rdb_load</code><br>callback is able to check the encver value and act accordingly.<br>The encver must be a positive value between 0 and 1023.</p>\n</li>\n<li><p><strong>typemethods_ptr</strong> is a pointer to a <code>ValkeyModuleTypeMethods</code> structure<br>that should be populated with the methods callbacks and structure<br>version, like in the following example:</p>\n<pre><code>  ValkeyModuleTypeMethods tm = {\n      .version = VALKEYMODULE_TYPE_METHOD_VERSION,\n      .rdb_load = myType_RDBLoadCallBack,\n      .rdb_save = myType_RDBSaveCallBack,\n      .aof_rewrite = myType_AOFRewriteCallBack,\n      .free = myType_FreeCallBack,\n\n      // Optional fields\n      .digest = myType_DigestCallBack,\n      .mem_usage = myType_MemUsageCallBack,\n      .aux_load = myType_AuxRDBLoadCallBack,\n      .aux_save = myType_AuxRDBSaveCallBack,\n      .free_effort = myType_FreeEffortCallBack,\n      .unlink = myType_UnlinkCallBack,\n      .copy = myType_CopyCallback,\n      .defrag = myType_DefragCallback\n\n      // Enhanced optional fields\n      .mem_usage2 = myType_MemUsageCallBack2,\n      .free_effort2 = myType_FreeEffortCallBack2,\n      .unlink2 = myType_UnlinkCallBack2,\n      .copy2 = myType_CopyCallback2,\n  }\n</code></pre>\n</li>\n<li><p><strong>rdb_load</strong>: A callback function pointer that loads data from RDB files.</p>\n</li>\n<li><p><strong>rdb_save</strong>: A callback function pointer that saves data to RDB files.</p>\n</li>\n<li><p><strong>aof_rewrite</strong>: A callback function pointer that rewrites data as commands.</p>\n</li>\n<li><p><strong>digest</strong>: A callback function pointer that is used for <code>DEBUG DIGEST</code>.</p>\n</li>\n<li><p><strong>free</strong>: A callback function pointer that can free a type value.</p>\n</li>\n<li><p><strong>aux_save</strong>: A callback function pointer that saves out of keyspace data to RDB files.<br>&#39;when&#39; argument is either <code>VALKEYMODULE_AUX_BEFORE_RDB</code> or <code>VALKEYMODULE_AUX_AFTER_RDB</code>.</p>\n</li>\n<li><p><strong>aux_load</strong>: A callback function pointer that loads out of keyspace data from RDB files.<br>Similar to <code>aux_save</code>, returns <code>VALKEYMODULE_OK</code> on success, and ERR otherwise.</p>\n</li>\n<li><p><strong>free_effort</strong>: A callback function pointer that used to determine whether the module&#39;s<br>memory needs to be lazy reclaimed. The module should return the complexity involved by<br>freeing the value. for example: how many pointers are gonna be freed. Note that if it<br>returns 0, we&#39;ll always do an async free.</p>\n</li>\n<li><p><strong>unlink</strong>: A callback function pointer that used to notifies the module that the key has<br>been removed from the DB by the server, and may soon be freed by a background thread. Note that<br>it won&#39;t be called on FLUSHALL/FLUSHDB (both sync and async), and the module can use the<br><code>ValkeyModuleEvent_FlushDB</code> to hook into that.</p>\n</li>\n<li><p><strong>copy</strong>: A callback function pointer that is used to make a copy of the specified key.<br>The module is expected to perform a deep copy of the specified value and return it.<br>In addition, hints about the names of the source and destination keys is provided.<br>A NULL return value is considered an error and the copy operation fails.<br>Note: if the target key exists and is being overwritten, the copy callback will be<br>called first, followed by a free callback to the value that is being replaced.</p>\n</li>\n<li><p><strong>defrag</strong>: A callback function pointer that is used to request the module to defrag<br>a key. The module should then iterate pointers and call the relevant <code>ValkeyModule_Defrag*()</code><br>functions to defragment pointers or complex types. The module should continue<br>iterating as long as <a href=\"#ValkeyModule_DefragShouldStop\"><code>ValkeyModule_DefragShouldStop()</code></a> returns a zero value, and return a<br>zero value if finished or non-zero value if more work is left to be done. If more work<br>needs to be done, <a href=\"#ValkeyModule_DefragCursorSet\"><code>ValkeyModule_DefragCursorSet()</code></a> and <a href=\"#ValkeyModule_DefragCursorGet\"><code>ValkeyModule_DefragCursorGet()</code></a> can be used to track<br>this work across different calls.<br>Normally, the defrag mechanism invokes the callback without a time limit, so<br><a href=\"#ValkeyModule_DefragShouldStop\"><code>ValkeyModule_DefragShouldStop()</code></a> always returns zero. The &quot;late defrag&quot; mechanism which has<br>a time limit and provides cursor support is used only for keys that are determined<br>to have significant internal complexity. To determine this, the defrag mechanism<br>uses the <code>free_effort</code> callback and the &#39;active-defrag-max-scan-fields&#39; config directive.<br>NOTE: The value is passed as a <code>void**</code> and the function is expected to update the<br>pointer if the top-level value pointer is defragmented and consequently changes.</p>\n</li>\n<li><p><strong>mem_usage2</strong>: Similar to <code>mem_usage</code>, but provides the <code>ValkeyModuleKeyOptCtx</code> parameter<br>so that meta information such as key name and db id can be obtained, and<br>the <code>sample_size</code> for size estimation (see MEMORY USAGE command).</p>\n</li>\n<li><p><strong>free_effort2</strong>: Similar to <code>free_effort</code>, but provides the <code>ValkeyModuleKeyOptCtx</code> parameter<br>so that meta information such as key name and db id can be obtained.</p>\n</li>\n<li><p><strong>unlink2</strong>: Similar to <code>unlink</code>, but provides the <code>ValkeyModuleKeyOptCtx</code> parameter<br>so that meta information such as key name and db id can be obtained.</p>\n</li>\n<li><p><strong>copy2</strong>: Similar to <code>copy</code>, but provides the <code>ValkeyModuleKeyOptCtx</code> parameter<br>so that meta information such as key names and db ids can be obtained.</p>\n</li>\n<li><p><strong>aux_save2</strong>: Similar to <code>aux_save</code>, but with small semantic change, if the module<br>saves nothing on this callback then no data about this aux field will be written to the<br>RDB and it will be possible to load the RDB even if the module is not loaded.</p>\n</li>\n</ul>\n<p>Note: the module name &quot;AAAAAAAAA&quot; is reserved and produces an error, it<br>happens to be pretty lame as well.</p>\n<p>If <a href=\"#ValkeyModule_CreateDataType\"><code>ValkeyModule_CreateDataType()</code></a> is called outside of <code>ValkeyModule_OnLoad()</code> function,<br>there is already a module registering a type with the same name,<br>or if the module name or encver is invalid, NULL is returned.<br>Otherwise the new type is registered into the server, and a reference of<br>type <code>ValkeyModuleType</code> is returned: the caller of the function should store<br>this reference into a global variable to make future use of it in the<br>modules type API, since a single module may register multiple types.<br>Example code fragment:</p>\n<pre><code> static ValkeyModuleType *BalancedTreeType;\n\n int ValkeyModule_OnLoad(ValkeyModuleCtx *ctx) {\n     // some code here ...\n     BalancedTreeType = ValkeyModule_CreateDataType(...);\n }\n</code></pre>\n<p><span id=\"ValkeyModule_ModuleTypeSetValue\"></span></p>\n<h3><code>ValkeyModule_ModuleTypeSetValue</code></h3>\n<pre><code>int ValkeyModule_ModuleTypeSetValue(ValkeyModuleKey *key,\n                                    moduleType *mt,\n                                    void *value);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>If the key is open for writing, set the specified module type object<br>as the value of the key, deleting the old value if any.<br>On success <code>VALKEYMODULE_OK</code> is returned. If the key is not open for<br>writing or there is an active iterator, <code>VALKEYMODULE_ERR</code> is returned.</p>\n<p><span id=\"ValkeyModule_ModuleTypeGetType\"></span></p>\n<h3><code>ValkeyModule_ModuleTypeGetType</code></h3>\n<pre><code>moduleType *ValkeyModule_ModuleTypeGetType(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Assuming <a href=\"#ValkeyModule_KeyType\"><code>ValkeyModule_KeyType()</code></a> returned <code>VALKEYMODULE_KEYTYPE_MODULE</code> on<br>the key, returns the module type pointer of the value stored at key.</p>\n<p>If the key is NULL, is not associated with a module type, or is empty,<br>then NULL is returned instead.</p>\n<p><span id=\"ValkeyModule_ModuleTypeGetValue\"></span></p>\n<h3><code>ValkeyModule_ModuleTypeGetValue</code></h3>\n<pre><code>void *ValkeyModule_ModuleTypeGetValue(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Assuming <a href=\"#ValkeyModule_KeyType\"><code>ValkeyModule_KeyType()</code></a> returned <code>VALKEYMODULE_KEYTYPE_MODULE</code> on<br>the key, returns the module type low-level value stored at key, as<br>it was set by the user via <a href=\"#ValkeyModule_ModuleTypeSetValue\"><code>ValkeyModule_ModuleTypeSetValue()</code></a>.</p>\n<p>If the key is NULL, is not associated with a module type, or is empty,<br>then NULL is returned instead.</p>\n<p><span id=\"section-rdb-loading-and-saving-functions\"></span></p>\n<h2>RDB loading and saving functions</h2>\n<p><span id=\"ValkeyModule_IsIOError\"></span></p>\n<h3><code>ValkeyModule_IsIOError</code></h3>\n<pre><code>int ValkeyModule_IsIOError(ValkeyModuleIO *io);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Returns true if any previous IO API failed.<br>for <code>Load*</code> APIs the <code>VALKEYMODULE_OPTIONS_HANDLE_IO_ERRORS</code> flag must be set with<br><a href=\"#ValkeyModule_SetModuleOptions\"><code>ValkeyModule_SetModuleOptions</code></a> first.</p>\n<p><span id=\"ValkeyModule_SaveUnsigned\"></span></p>\n<h3><code>ValkeyModule_SaveUnsigned</code></h3>\n<pre><code>void ValkeyModule_SaveUnsigned(ValkeyModuleIO *io, uint64_t value);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Save an unsigned 64 bit value into the RDB file. This function should only<br>be called in the context of the <code>rdb_save</code> method of modules implementing new<br>data types.</p>\n<p><span id=\"ValkeyModule_LoadUnsigned\"></span></p>\n<h3><code>ValkeyModule_LoadUnsigned</code></h3>\n<pre><code>uint64_t ValkeyModule_LoadUnsigned(ValkeyModuleIO *io);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Load an unsigned 64 bit value from the RDB file. This function should only<br>be called in the context of the <code>rdb_load</code> method of modules implementing<br>new data types.</p>\n<p><span id=\"ValkeyModule_SaveSigned\"></span></p>\n<h3><code>ValkeyModule_SaveSigned</code></h3>\n<pre><code>void ValkeyModule_SaveSigned(ValkeyModuleIO *io, int64_t value);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Like <a href=\"#ValkeyModule_SaveUnsigned\"><code>ValkeyModule_SaveUnsigned()</code></a> but for signed 64 bit values.</p>\n<p><span id=\"ValkeyModule_LoadSigned\"></span></p>\n<h3><code>ValkeyModule_LoadSigned</code></h3>\n<pre><code>int64_t ValkeyModule_LoadSigned(ValkeyModuleIO *io);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Like <a href=\"#ValkeyModule_LoadUnsigned\"><code>ValkeyModule_LoadUnsigned()</code></a> but for signed 64 bit values.</p>\n<p><span id=\"ValkeyModule_SaveString\"></span></p>\n<h3><code>ValkeyModule_SaveString</code></h3>\n<pre><code>void ValkeyModule_SaveString(ValkeyModuleIO *io, ValkeyModuleString *s);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>In the context of the <code>rdb_save</code> method of a module type, saves a<br>string into the RDB file taking as input a <code>ValkeyModuleString</code>.</p>\n<p>The string can be later loaded with <a href=\"#ValkeyModule_LoadString\"><code>ValkeyModule_LoadString()</code></a> or<br>other Load family functions expecting a serialized string inside<br>the RDB file.</p>\n<p><span id=\"ValkeyModule_SaveStringBuffer\"></span></p>\n<h3><code>ValkeyModule_SaveStringBuffer</code></h3>\n<pre><code>void ValkeyModule_SaveStringBuffer(ValkeyModuleIO *io,\n                                   const char *str,\n                                   size_t len);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Like <a href=\"#ValkeyModule_SaveString\"><code>ValkeyModule_SaveString()</code></a> but takes a raw C pointer and length<br>as input.</p>\n<p><span id=\"ValkeyModule_LoadString\"></span></p>\n<h3><code>ValkeyModule_LoadString</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_LoadString(ValkeyModuleIO *io);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>In the context of the <code>rdb_load</code> method of a module data type, loads a string<br>from the RDB file, that was previously saved with <a href=\"#ValkeyModule_SaveString\"><code>ValkeyModule_SaveString()</code></a><br>functions family.</p>\n<p>The returned string is a newly allocated <code>ValkeyModuleString</code> object, and<br>the user should at some point free it with a call to <a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a>.</p>\n<p>If the data structure does not store strings as <code>ValkeyModuleString</code> objects,<br>the similar function <a href=\"#ValkeyModule_LoadStringBuffer\"><code>ValkeyModule_LoadStringBuffer()</code></a> could be used instead.</p>\n<p><span id=\"ValkeyModule_LoadStringBuffer\"></span></p>\n<h3><code>ValkeyModule_LoadStringBuffer</code></h3>\n<pre><code>char *ValkeyModule_LoadStringBuffer(ValkeyModuleIO *io, size_t *lenptr);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Like <a href=\"#ValkeyModule_LoadString\"><code>ValkeyModule_LoadString()</code></a> but returns a heap allocated string that<br>was allocated with <a href=\"#ValkeyModule_Alloc\"><code>ValkeyModule_Alloc()</code></a>, and can be resized or freed with<br><a href=\"#ValkeyModule_Realloc\"><code>ValkeyModule_Realloc()</code></a> or <a href=\"#ValkeyModule_Free\"><code>ValkeyModule_Free()</code></a>.</p>\n<p>The size of the string is stored at &#39;*lenptr&#39; if not NULL.<br>The returned string is not automatically NULL terminated, it is loaded<br>exactly as it was stored inside the RDB file.</p>\n<p><span id=\"ValkeyModule_SaveDouble\"></span></p>\n<h3><code>ValkeyModule_SaveDouble</code></h3>\n<pre><code>void ValkeyModule_SaveDouble(ValkeyModuleIO *io, double value);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>In the context of the <code>rdb_save</code> method of a module data type, saves a double<br>value to the RDB file. The double can be a valid number, a NaN or infinity.<br>It is possible to load back the value with <a href=\"#ValkeyModule_LoadDouble\"><code>ValkeyModule_LoadDouble()</code></a>.</p>\n<p><span id=\"ValkeyModule_LoadDouble\"></span></p>\n<h3><code>ValkeyModule_LoadDouble</code></h3>\n<pre><code>double ValkeyModule_LoadDouble(ValkeyModuleIO *io);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>In the context of the <code>rdb_save</code> method of a module data type, loads back the<br>double value saved by <a href=\"#ValkeyModule_SaveDouble\"><code>ValkeyModule_SaveDouble()</code></a>.</p>\n<p><span id=\"ValkeyModule_SaveFloat\"></span></p>\n<h3><code>ValkeyModule_SaveFloat</code></h3>\n<pre><code>void ValkeyModule_SaveFloat(ValkeyModuleIO *io, float value);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>In the context of the <code>rdb_save</code> method of a module data type, saves a float<br>value to the RDB file. The float can be a valid number, a NaN or infinity.<br>It is possible to load back the value with <a href=\"#ValkeyModule_LoadFloat\"><code>ValkeyModule_LoadFloat()</code></a>.</p>\n<p><span id=\"ValkeyModule_LoadFloat\"></span></p>\n<h3><code>ValkeyModule_LoadFloat</code></h3>\n<pre><code>float ValkeyModule_LoadFloat(ValkeyModuleIO *io);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>In the context of the <code>rdb_save</code> method of a module data type, loads back the<br>float value saved by <a href=\"#ValkeyModule_SaveFloat\"><code>ValkeyModule_SaveFloat()</code></a>.</p>\n<p><span id=\"ValkeyModule_SaveLongDouble\"></span></p>\n<h3><code>ValkeyModule_SaveLongDouble</code></h3>\n<pre><code>void ValkeyModule_SaveLongDouble(ValkeyModuleIO *io, long double value);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>In the context of the <code>rdb_save</code> method of a module data type, saves a long double<br>value to the RDB file. The double can be a valid number, a NaN or infinity.<br>It is possible to load back the value with <a href=\"#ValkeyModule_LoadLongDouble\"><code>ValkeyModule_LoadLongDouble()</code></a>.</p>\n<p><span id=\"ValkeyModule_LoadLongDouble\"></span></p>\n<h3><code>ValkeyModule_LoadLongDouble</code></h3>\n<pre><code>long double ValkeyModule_LoadLongDouble(ValkeyModuleIO *io);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>In the context of the <code>rdb_save</code> method of a module data type, loads back the<br>long double value saved by <a href=\"#ValkeyModule_SaveLongDouble\"><code>ValkeyModule_SaveLongDouble()</code></a>.</p>\n<p><span id=\"section-key-digest-api-debug-digest-interface-for-modules-types\"></span></p>\n<h2>Key digest API (DEBUG DIGEST interface for modules types)</h2>\n<p><span id=\"ValkeyModule_DigestAddStringBuffer\"></span></p>\n<h3><code>ValkeyModule_DigestAddStringBuffer</code></h3>\n<pre><code>void ValkeyModule_DigestAddStringBuffer(ValkeyModuleDigest *md,\n                                        const char *ele,\n                                        size_t len);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Add a new element to the digest. This function can be called multiple times<br>one element after the other, for all the elements that constitute a given<br>data structure. The function call must be followed by the call to<br><a href=\"#ValkeyModule_DigestEndSequence\"><code>ValkeyModule_DigestEndSequence</code></a> eventually, when all the elements that are<br>always in a given order are added. See the Modules data types<br>documentation for more info. However this is a quick example that uses the<br>Set, Hash and List data types as an example.</p>\n<p>To add a sequence of unordered elements (for example in the case of a<br>Set), the pattern to use is:</p>\n<pre><code>foreach element {\n    AddElement(element);\n    EndSequence();\n}\n</code></pre>\n<p>Because Sets are not ordered, so every element added has a position that<br>does not depend from the other. However if instead our elements are<br>ordered in pairs, like field-value pairs of a Hash, then one should<br>use:</p>\n<pre><code>foreach key,value {\n    AddElement(key);\n    AddElement(value);\n    EndSequence();\n}\n</code></pre>\n<p>Because the key and value will be always in the above order, while instead<br>the single key-value pairs, can appear in any position into a hash.</p>\n<p>A list of ordered elements would be implemented with:</p>\n<pre><code>foreach element {\n    AddElement(element);\n}\nEndSequence();\n</code></pre>\n<p><span id=\"ValkeyModule_DigestAddLongLong\"></span></p>\n<h3><code>ValkeyModule_DigestAddLongLong</code></h3>\n<pre><code>void ValkeyModule_DigestAddLongLong(ValkeyModuleDigest *md, long long ll);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Like <a href=\"#ValkeyModule_DigestAddStringBuffer\"><code>ValkeyModule_DigestAddStringBuffer()</code></a> but takes a <code>long long</code> as input<br>that gets converted into a string before adding it to the digest.</p>\n<p><span id=\"ValkeyModule_DigestEndSequence\"></span></p>\n<h3><code>ValkeyModule_DigestEndSequence</code></h3>\n<pre><code>void ValkeyModule_DigestEndSequence(ValkeyModuleDigest *md);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>See the documentation for <code>ValkeyModule_DigestAddElement()</code>.</p>\n<p><span id=\"ValkeyModule_LoadDataTypeFromStringEncver\"></span></p>\n<h3><code>ValkeyModule_LoadDataTypeFromStringEncver</code></h3>\n<pre><code>void *ValkeyModule_LoadDataTypeFromStringEncver(const ValkeyModuleString *str,\n                                                const moduleType *mt,\n                                                int encver);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Decode a serialized representation of a module data type &#39;mt&#39;, in a specific encoding version &#39;encver&#39;<br>from string &#39;str&#39; and return a newly allocated value, or NULL if decoding failed.</p>\n<p>This call basically reuses the &#39;<code>rdb_load</code>&#39; callback which module data types<br>implement in order to allow a module to arbitrarily serialize/de-serialize<br>keys, similar to how the &#39;DUMP&#39; and &#39;RESTORE&#39; commands are implemented.</p>\n<p>Modules should generally use the <code>VALKEYMODULE_OPTIONS_HANDLE_IO_ERRORS</code> flag and<br>make sure the de-serialization code properly checks and handles IO errors<br>(freeing allocated buffers and returning a NULL).</p>\n<p>If this is NOT done, the server will handle corrupted (or just truncated) serialized<br>data by producing an error message and terminating the process.</p>\n<p><span id=\"ValkeyModule_LoadDataTypeFromString\"></span></p>\n<h3><code>ValkeyModule_LoadDataTypeFromString</code></h3>\n<pre><code>void *ValkeyModule_LoadDataTypeFromString(const ValkeyModuleString *str,\n                                          const moduleType *mt);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Similar to <a href=\"#ValkeyModule_LoadDataTypeFromStringEncver\"><code>ValkeyModule_LoadDataTypeFromStringEncver</code></a>, original version of the API, kept<br>for backward compatibility.</p>\n<p><span id=\"ValkeyModule_SaveDataTypeToString\"></span></p>\n<h3><code>ValkeyModule_SaveDataTypeToString</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_SaveDataTypeToString(ValkeyModuleCtx *ctx,\n                                                      void *data,\n                                                      const moduleType *mt);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Encode a module data type &#39;mt&#39; value &#39;data&#39; into serialized form, and return it<br>as a newly allocated <code>ValkeyModuleString</code>.</p>\n<p>This call basically reuses the &#39;<code>rdb_save</code>&#39; callback which module data types<br>implement in order to allow a module to arbitrarily serialize/de-serialize<br>keys, similar to how the &#39;DUMP&#39; and &#39;RESTORE&#39; commands are implemented.</p>\n<p><span id=\"ValkeyModule_GetKeyNameFromDigest\"></span></p>\n<h3><code>ValkeyModule_GetKeyNameFromDigest</code></h3>\n<pre><code>const ValkeyModuleString *ValkeyModule_GetKeyNameFromDigest(ValkeyModuleDigest *dig);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Returns the name of the key currently being processed.</p>\n<p><span id=\"ValkeyModule_GetDbIdFromDigest\"></span></p>\n<h3><code>ValkeyModule_GetDbIdFromDigest</code></h3>\n<pre><code>int ValkeyModule_GetDbIdFromDigest(ValkeyModuleDigest *dig);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Returns the database id of the key currently being processed.</p>\n<p><span id=\"section-aof-api-for-modules-data-types\"></span></p>\n<h2>AOF API for modules data types</h2>\n<p><span id=\"ValkeyModule_EmitAOF\"></span></p>\n<h3><code>ValkeyModule_EmitAOF</code></h3>\n<pre><code>void ValkeyModule_EmitAOF(ValkeyModuleIO *io,\n                          const char *cmdname,\n                          const char *fmt,\n                          ...);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Emits a command into the AOF during the AOF rewriting process. This function<br>is only called in the context of the <code>aof_rewrite</code> method of data types exported<br>by a module. The command works exactly like <a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call()</code></a> in the way<br>the parameters are passed, but it does not return anything as the error<br>handling is performed by the server itself.</p>\n<p><span id=\"section-io-context-handling\"></span></p>\n<h2>IO context handling</h2>\n<p><span id=\"ValkeyModule_GetKeyNameFromIO\"></span></p>\n<h3><code>ValkeyModule_GetKeyNameFromIO</code></h3>\n<pre><code>const ValkeyModuleString *ValkeyModule_GetKeyNameFromIO(ValkeyModuleIO *io);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.5</p>\n<p>Returns the name of the key currently being processed.<br>There is no guarantee that the key name is always available, so this may return NULL.</p>\n<p><span id=\"ValkeyModule_GetKeyNameFromModuleKey\"></span></p>\n<h3><code>ValkeyModule_GetKeyNameFromModuleKey</code></h3>\n<pre><code>const ValkeyModuleString *ValkeyModule_GetKeyNameFromModuleKey(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Returns a <code>ValkeyModuleString</code> with the name of the key from <code>ValkeyModuleKey</code>.</p>\n<p><span id=\"ValkeyModule_GetDbIdFromModuleKey\"></span></p>\n<h3><code>ValkeyModule_GetDbIdFromModuleKey</code></h3>\n<pre><code>int ValkeyModule_GetDbIdFromModuleKey(ValkeyModuleKey *key);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Returns a database id of the key from <code>ValkeyModuleKey</code>.</p>\n<p><span id=\"ValkeyModule_GetDbIdFromIO\"></span></p>\n<h3><code>ValkeyModule_GetDbIdFromIO</code></h3>\n<pre><code>int ValkeyModule_GetDbIdFromIO(ValkeyModuleIO *io);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Returns the database id of the key currently being processed.<br>There is no guarantee that this info is always available, so this may return -1.</p>\n<p><span id=\"section-logging\"></span></p>\n<h2>Logging</h2>\n<p><span id=\"ValkeyModule_Log\"></span></p>\n<h3><code>ValkeyModule_Log</code></h3>\n<pre><code>void ValkeyModule_Log(ValkeyModuleCtx *ctx,\n                      const char *levelstr,\n                      const char *fmt,\n                      ...);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Produces a log message to the standard server log, the format accepts<br>printf-alike specifiers, while level is a string describing the log<br>level to use when emitting the log, and must be one of the following:</p>\n<ul>\n<li>&quot;debug&quot; (<code>VALKEYMODULE_LOGLEVEL_DEBUG</code>)</li>\n<li>&quot;verbose&quot; (<code>VALKEYMODULE_LOGLEVEL_VERBOSE</code>)</li>\n<li>&quot;notice&quot; (<code>VALKEYMODULE_LOGLEVEL_NOTICE</code>)</li>\n<li>&quot;warning&quot; (<code>VALKEYMODULE_LOGLEVEL_WARNING</code>)</li>\n</ul>\n<p>If the specified log level is invalid, verbose is used by default.<br>There is a fixed limit to the length of the log line this function is able<br>to emit, this limit is not specified but is guaranteed to be more than<br>a few lines of text.</p>\n<p>The ctx argument may be NULL if cannot be provided in the context of the<br>caller for instance threads or callbacks, in which case a generic &quot;module&quot;<br>will be used instead of the module name.</p>\n<p><span id=\"ValkeyModule_LogIOError\"></span></p>\n<h3><code>ValkeyModule_LogIOError</code></h3>\n<pre><code>void ValkeyModule_LogIOError(ValkeyModuleIO *io,\n                             const char *levelstr,\n                             const char *fmt,\n                             ...);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Log errors from RDB / AOF serialization callbacks.</p>\n<p>This function should be used when a callback is returning a critical<br>error to the caller since cannot load or save the data for some<br>critical reason.</p>\n<p><span id=\"ValkeyModule__Assert\"></span></p>\n<h3><code>ValkeyModule__Assert</code></h3>\n<pre><code>void ValkeyModule__Assert(const char *estr, const char *file, int line);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Valkey assert function.</p>\n<p>The macro <code>ValkeyModule_Assert(expression)</code> is recommended, rather than<br>calling this function directly.</p>\n<p>A failed assertion will shut down the server and produce logging information<br>that looks identical to information generated by the server itself.</p>\n<p><span id=\"ValkeyModule_LatencyAddSample\"></span></p>\n<h3><code>ValkeyModule_LatencyAddSample</code></h3>\n<pre><code>void ValkeyModule_LatencyAddSample(const char *event, mstime_t latency);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Allows adding event to the latency monitor to be observed by the LATENCY<br>command. The call is skipped if the latency is smaller than the configured<br>latency-monitor-threshold.</p>\n<p><span id=\"section-blocking-clients-from-modules\"></span></p>\n<h2>Blocking clients from modules</h2>\n<p>For a guide about blocking commands in modules, see<br><a href=\"https://valkey.io/topics/modules-blocking-ops\">https://valkey.io/topics/modules-blocking-ops</a>.</p>\n<p><span id=\"ValkeyModule_RegisterAuthCallback\"></span></p>\n<h3><code>ValkeyModule_RegisterAuthCallback</code></h3>\n<pre><code>void ValkeyModule_RegisterAuthCallback(ValkeyModuleCtx *ctx,\n                                       ValkeyModuleAuthCallback cb);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>This API registers a callback to execute in addition to normal password based authentication.<br>Multiple callbacks can be registered across different modules. When a Module is unloaded, all the<br>auth callbacks registered by it are unregistered.<br>The callbacks are attempted (in the order of most recently registered first) when the AUTH/HELLO<br>(with AUTH field provided) commands are called.<br>The callbacks will be called with a module context along with a username and a password, and are<br>expected to take one of the following actions:<br>(1) Authenticate - Use the <code>ValkeyModule_AuthenticateClient</code>* API and return <code>VALKEYMODULE_AUTH_HANDLED</code>.<br>This will immediately end the auth chain as successful and add the OK reply.<br>(2) Deny Authentication - Return <code>VALKEYMODULE_AUTH_HANDLED</code> without authenticating or blocking the<br>client. Optionally, <code>err</code> can be set to a custom error message and <code>err</code> will be automatically<br>freed by the server.<br>This will immediately end the auth chain as unsuccessful and add the ERR reply.<br>(3) Block a client on authentication - Use the <a href=\"#ValkeyModule_BlockClientOnAuth\"><code>ValkeyModule_BlockClientOnAuth</code></a> API and return<br><code>VALKEYMODULE_AUTH_HANDLED</code>. Here, the client will be blocked until the <a href=\"#ValkeyModule_UnblockClient\"><code>ValkeyModule_UnblockClient</code></a> API is used<br>which will trigger the auth reply callback (provided through the <a href=\"#ValkeyModule_BlockClientOnAuth\"><code>ValkeyModule_BlockClientOnAuth</code></a>).<br>In this reply callback, the Module should authenticate, deny or skip handling authentication.<br>(4) Skip handling Authentication - Return <code>VALKEYMODULE_AUTH_NOT_HANDLED</code> without blocking the<br>client. This will allow the engine to attempt the next module auth callback.<br>If none of the callbacks authenticate or deny auth, then password based auth is attempted and<br>will authenticate or add failure logs and reply to the clients accordingly.</p>\n<p>Note: If a client is disconnected while it was in the middle of blocking module auth, that<br>occurrence of the AUTH or HELLO command will not be tracked in the INFO command stats.</p>\n<p>The following is an example of how non-blocking module based authentication can be used:</p>\n<pre><code> int auth_cb(ValkeyModuleCtx *ctx, ValkeyModuleString *username, ValkeyModuleString *password, ValkeyModuleString\n</code></pre>\n<p>**err) { const char *user = <a href=\"#ValkeyModule_StringPtrLen\"><code>ValkeyModule_StringPtrLen</code></a>(username, NULL); const char *pwd =<br><a href=\"#ValkeyModule_StringPtrLen\"><code>ValkeyModule_StringPtrLen</code></a>(password, NULL); if (!strcmp(user,&quot;foo&quot;) &amp;&amp; !strcmp(pwd,&quot;<code>valid_password</code>&quot;)) {<br>             ValkeyModule_AuthenticateClientWithACLUser(ctx, &quot;foo&quot;, 3, NULL, NULL, NULL);<br>             return VALKEYMODULE_AUTH_HANDLED;<br>         }</p>\n<pre><code>     else if (!strcmp(user,&quot;foo&quot;) &amp;&amp; !strcmp(pwd,&quot;wrong_password&quot;)) {\n         ValkeyModuleString *log = ValkeyModule_CreateString(ctx, &quot;Module Auth&quot;, 11);\n         ValkeyModule_ACLAddLogEntryByUserName(ctx, username, log, VALKEYMODULE_ACL_LOG_AUTH);\n         ValkeyModule_FreeString(ctx, log);\n         const char *err_msg = &quot;Auth denied by Misc Module.&quot;;\n         *err = ValkeyModule_CreateString(ctx, err_msg, strlen(err_msg));\n         return VALKEYMODULE_AUTH_HANDLED;\n     }\n     return VALKEYMODULE_AUTH_NOT_HANDLED;\n  }\n\n int ValkeyModule_OnLoad(ValkeyModuleCtx *ctx, ValkeyModuleString **argv, int argc) {\n     if (ValkeyModule_Init(ctx,&quot;authmodule&quot;,1,VALKEYMODULE_APIVER_1)== VALKEYMODULE_ERR)\n         return VALKEYMODULE_ERR;\n     ValkeyModule_RegisterAuthCallback(ctx, auth_cb);\n     return VALKEYMODULE_OK;\n }\n</code></pre>\n<p><span id=\"ValkeyModule_BlockClient\"></span></p>\n<h3><code>ValkeyModule_BlockClient</code></h3>\n<pre><code>ValkeyModuleBlockedClient *ValkeyModule_BlockClient(ValkeyModuleCtx *ctx,\n                                      ValkeyModuleCmdFunc reply_callback,\n                                      ValkeyModuleCmdFunc timeout_callback,\n                                      void (*free_privdata)(ValkeyModuleCtx *, void *),\n                                      long long timeout_ms);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Block a client in the context of a blocking command, returning a handle<br>which will be used, later, in order to unblock the client with a call to<br><a href=\"#ValkeyModule_UnblockClient\"><code>ValkeyModule_UnblockClient()</code></a>. The arguments specify callback functions<br>and a timeout after which the client is unblocked.</p>\n<p>The callbacks are called in the following contexts:</p>\n<pre><code>reply_callback:   called after a successful ValkeyModule_UnblockClient()\n                  call in order to reply to the client and unblock it.\n\ntimeout_callback: called when the timeout is reached or if `CLIENT UNBLOCK`\n                  is invoked, in order to send an error to the client.\n\nfree_privdata:    called in order to free the private data that is passed\n                  by ValkeyModule_UnblockClient() call.\n</code></pre>\n<p>Note: <a href=\"#ValkeyModule_UnblockClient\"><code>ValkeyModule_UnblockClient</code></a> should be called for every blocked client,<br>      even if client was killed, timed-out or disconnected. Failing to do so<br>      will result in memory leaks.</p>\n<p>There are some cases where <a href=\"#ValkeyModule_BlockClient\"><code>ValkeyModule_BlockClient()</code></a> cannot be used:</p>\n<ol>\n<li>If the client is a Lua script.</li>\n<li>If the client is executing a MULTI block.</li>\n</ol>\n<p>In these cases, a call to <a href=\"#ValkeyModule_BlockClient\"><code>ValkeyModule_BlockClient()</code></a> will <strong>not</strong> block the<br>client, but instead produce a specific error reply.</p>\n<p>A module that registers a <code>timeout_callback</code> function can also be unblocked<br>using the <code>CLIENT UNBLOCK</code> command, which will trigger the timeout callback.<br>If a callback function is not registered, then the blocked client will be<br>treated as if it is not in a blocked state and <code>CLIENT UNBLOCK</code> will return<br>a zero value.</p>\n<p>Measuring background time: By default the time spent in the blocked command<br>is not account for the total command duration. To include such time you should<br>use <a href=\"#ValkeyModule_BlockedClientMeasureTimeStart\"><code>ValkeyModule_BlockedClientMeasureTimeStart()</code></a> and <a href=\"#ValkeyModule_BlockedClientMeasureTimeEnd\"><code>ValkeyModule_BlockedClientMeasureTimeEnd()</code></a> one,<br>or multiple times within the blocking command background work.</p>\n<p><span id=\"ValkeyModule_BlockClientOnAuth\"></span></p>\n<h3><code>ValkeyModule_BlockClientOnAuth</code></h3>\n<pre><code>ValkeyModuleBlockedClient *ValkeyModule_BlockClientOnAuth(ValkeyModuleCtx *ctx,\n                                            ValkeyModuleAuthCallback reply_callback,\n                                            void (*free_privdata)(ValkeyModuleCtx *, void *));\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Block the current client for module authentication in the background. If module auth is not in<br>progress on the client, the API returns NULL. Otherwise, the client is blocked and the <code>ValkeyModule_BlockedClient</code><br>is returned similar to the <a href=\"#ValkeyModule_BlockClient\"><code>ValkeyModule_BlockClient</code></a> API.<br>Note: Only use this API from the context of a module auth callback.</p>\n<p><span id=\"ValkeyModule_BlockClientGetPrivateData\"></span></p>\n<h3><code>ValkeyModule_BlockClientGetPrivateData</code></h3>\n<pre><code>void *ValkeyModule_BlockClientGetPrivateData(ValkeyModuleBlockedClient *blocked_client);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Get the private data that was previusely set on a blocked client</p>\n<p><span id=\"ValkeyModule_BlockClientSetPrivateData\"></span></p>\n<h3><code>ValkeyModule_BlockClientSetPrivateData</code></h3>\n<pre><code>void ValkeyModule_BlockClientSetPrivateData(ValkeyModuleBlockedClient *blocked_client,\n                                            void *private_data);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Set private data on a blocked client</p>\n<p><span id=\"ValkeyModule_BlockClientOnKeys\"></span></p>\n<h3><code>ValkeyModule_BlockClientOnKeys</code></h3>\n<pre><code>ValkeyModuleBlockedClient *ValkeyModule_BlockClientOnKeys(ValkeyModuleCtx *ctx,\n                                                          ValkeyModuleCmdFunc reply_callback,\n                                                          ValkeyModuleCmdFunc timeout_callback,\n                                                          void (*free_privdata)(ValkeyModuleCtx *, void *),\n                                                          long long timeout_ms,\n                                                          ValkeyModuleString **keys,\n                                                          int numkeys,\n                                                          void *privdata);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>This call is similar to <a href=\"#ValkeyModule_BlockClient\"><code>ValkeyModule_BlockClient()</code></a>, however in this case we<br>don&#39;t just block the client, but also ask the server to unblock it automatically<br>once certain keys become &quot;ready&quot;, that is, contain more data.</p>\n<p>Basically this is similar to what a typical command usually does,<br>like BLPOP or BZPOPMAX: the client blocks if it cannot be served ASAP,<br>and later when the key receives new data (a list push for instance), the<br>client is unblocked and served.</p>\n<p>However in the case of this module API, when the client is unblocked?</p>\n<ol>\n<li>If you block on a key of a type that has blocking operations associated,<br>like a list, a sorted set, a stream, and so forth, the client may be<br>unblocked once the relevant key is targeted by an operation that normally<br>unblocks the native blocking operations for that type. So if we block<br>on a list key, an RPUSH command may unblock our client and so forth.</li>\n<li>If you are implementing your native data type, or if you want to add new<br>unblocking conditions in addition to &quot;1&quot;, you can call the modules API<br><a href=\"#ValkeyModule_SignalKeyAsReady\"><code>ValkeyModule_SignalKeyAsReady()</code></a>.</li>\n</ol>\n<p>Anyway we can&#39;t be sure if the client should be unblocked just because the<br>key is signaled as ready: for instance a successive operation may change the<br>key, or a client in queue before this one can be served, modifying the key<br>as well and making it empty again. So when a client is blocked with<br><a href=\"#ValkeyModule_BlockClientOnKeys\"><code>ValkeyModule_BlockClientOnKeys()</code></a> the reply callback is not called after<br><a href=\"#ValkeyModule_UnblockClient\"><code>ValkeyModule_UnblockClient()</code></a> is called, but every time a key is signaled as ready:<br>if the reply callback can serve the client, it returns <code>VALKEYMODULE_OK</code><br>and the client is unblocked, otherwise it will return <code>VALKEYMODULE_ERR</code><br>and we&#39;ll try again later.</p>\n<p>The reply callback can access the key that was signaled as ready by<br>calling the API <a href=\"#ValkeyModule_GetBlockedClientReadyKey\"><code>ValkeyModule_GetBlockedClientReadyKey()</code></a>, that returns<br>just the string name of the key as a <code>ValkeyModuleString</code> object.</p>\n<p>Thanks to this system we can setup complex blocking scenarios, like<br>unblocking a client only if a list contains at least 5 items or other<br>more fancy logics.</p>\n<p>Note that another difference with <a href=\"#ValkeyModule_BlockClient\"><code>ValkeyModule_BlockClient()</code></a>, is that here<br>we pass the private data directly when blocking the client: it will<br>be accessible later in the reply callback. Normally when blocking with<br><a href=\"#ValkeyModule_BlockClient\"><code>ValkeyModule_BlockClient()</code></a> the private data to reply to the client is<br>passed when calling <a href=\"#ValkeyModule_UnblockClient\"><code>ValkeyModule_UnblockClient()</code></a> but here the unblocking<br>is performed by the server itself, so we need to have some private data before<br>hand. The private data is used to store any information about the specific<br>unblocking operation that you are implementing. Such information will be<br>freed using the <code>free_privdata</code> callback provided by the user.</p>\n<p>However the reply callback will be able to access the argument vector of<br>the command, so the private data is often not needed.</p>\n<p>Note: Under normal circumstances <a href=\"#ValkeyModule_UnblockClient\"><code>ValkeyModule_UnblockClient</code></a> should not be<br>      called for clients that are blocked on keys (Either the key will<br>      become ready or a timeout will occur). If for some reason you do want<br>      to call ValkeyModule_UnblockClient it is possible: Client will be<br>      handled as if it were timed-out (You must implement the timeout<br>      callback in that case).</p>\n<p><span id=\"ValkeyModule_BlockClientOnKeysWithFlags\"></span></p>\n<h3><code>ValkeyModule_BlockClientOnKeysWithFlags</code></h3>\n<pre><code>ValkeyModuleBlockedClient *ValkeyModule_BlockClientOnKeysWithFlags(ValkeyModuleCtx *ctx,\n                                                                   ValkeyModuleCmdFunc reply_callback,\n                                                                   ValkeyModuleCmdFunc timeout_callback,\n                                                                   void (*free_privdata)(ValkeyModuleCtx *, void *),\n                                                                   long long timeout_ms,\n                                                                   ValkeyModuleString **keys,\n                                                                   int numkeys,\n                                                                   void *privdata,\n                                                                   int flags);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Same as <a href=\"#ValkeyModule_BlockClientOnKeys\"><code>ValkeyModule_BlockClientOnKeys</code></a>, but can take <code>VALKEYMODULE_BLOCK_</code>* flags<br>Can be either <code>VALKEYMODULE_BLOCK_UNBLOCK_DEFAULT</code>, which means default behavior (same<br>as calling <a href=\"#ValkeyModule_BlockClientOnKeys\"><code>ValkeyModule_BlockClientOnKeys</code></a>)</p>\n<p>The flags is a bit mask of these:</p>\n<ul>\n<li><code>VALKEYMODULE_BLOCK_UNBLOCK_DELETED</code>: The clients should to be awakened in case any of <code>keys</code> are deleted.<br>                                 Mostly useful for commands that require the key to exist (like XREADGROUP)</li>\n</ul>\n<p><span id=\"ValkeyModule_SignalKeyAsReady\"></span></p>\n<h3><code>ValkeyModule_SignalKeyAsReady</code></h3>\n<pre><code>void ValkeyModule_SignalKeyAsReady(ValkeyModuleCtx *ctx,\n                                   ValkeyModuleString *key);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>This function is used in order to potentially unblock a client blocked<br>on keys with <a href=\"#ValkeyModule_BlockClientOnKeys\"><code>ValkeyModule_BlockClientOnKeys()</code></a>. When this function is called,<br>all the clients blocked for this key will get their <code>reply_callback</code> called.</p>\n<p><span id=\"ValkeyModule_UnblockClient\"></span></p>\n<h3><code>ValkeyModule_UnblockClient</code></h3>\n<pre><code>int ValkeyModule_UnblockClient(ValkeyModuleBlockedClient *bc, void *privdata);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Unblock a client blocked by <code>ValkeyModule_BlockedClient</code>. This will trigger<br>the reply callbacks to be called in order to reply to the client.<br>The &#39;privdata&#39; argument will be accessible by the reply callback, so<br>the caller of this function can pass any value that is needed in order to<br>actually reply to the client.</p>\n<p>A common usage for &#39;privdata&#39; is a thread that computes something that<br>needs to be passed to the client, included but not limited some slow<br>to compute reply or some reply obtained via networking.</p>\n<p>Note 1: this function can be called from threads spawned by the module.</p>\n<p>Note 2: when we unblock a client that is blocked for keys using the API<br><a href=\"#ValkeyModule_BlockClientOnKeys\"><code>ValkeyModule_BlockClientOnKeys()</code></a>, the privdata argument here is not used.<br>Unblocking a client that was blocked for keys using this API will still<br>require the client to get some reply, so the function will use the<br>&quot;timeout&quot; handler in order to do so (The privdata provided in<br><a href=\"#ValkeyModule_BlockClientOnKeys\"><code>ValkeyModule_BlockClientOnKeys()</code></a> is accessible from the timeout<br>callback via <a href=\"#ValkeyModule_GetBlockedClientPrivateData\"><code>ValkeyModule_GetBlockedClientPrivateData</code></a>).</p>\n<p><span id=\"ValkeyModule_AbortBlock\"></span></p>\n<h3><code>ValkeyModule_AbortBlock</code></h3>\n<pre><code>int ValkeyModule_AbortBlock(ValkeyModuleBlockedClient *bc);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Abort a blocked client blocking operation: the client will be unblocked<br>without firing any callback.</p>\n<p><span id=\"ValkeyModule_SetDisconnectCallback\"></span></p>\n<h3><code>ValkeyModule_SetDisconnectCallback</code></h3>\n<pre><code>void ValkeyModule_SetDisconnectCallback(ValkeyModuleBlockedClient *bc,\n                                        ValkeyModuleDisconnectFunc callback);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Set a callback that will be called if a blocked client disconnects<br>before the module has a chance to call <a href=\"#ValkeyModule_UnblockClient\"><code>ValkeyModule_UnblockClient()</code></a></p>\n<p>Usually what you want to do there, is to cleanup your module state<br>so that you can call <a href=\"#ValkeyModule_UnblockClient\"><code>ValkeyModule_UnblockClient()</code></a> safely, otherwise<br>the client will remain blocked forever if the timeout is large.</p>\n<p>Notes:</p>\n<ol>\n<li><p>It is not safe to call Reply* family functions here, it is also<br>useless since the client is gone.</p>\n</li>\n<li><p>This callback is not called if the client disconnects because of<br>a timeout. In such a case, the client is unblocked automatically<br>and the timeout callback is called.</p>\n</li>\n</ol>\n<p><span id=\"ValkeyModule_IsBlockedReplyRequest\"></span></p>\n<h3><code>ValkeyModule_IsBlockedReplyRequest</code></h3>\n<pre><code>int ValkeyModule_IsBlockedReplyRequest(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return non-zero if a module command was called in order to fill the<br>reply for a blocked client.</p>\n<p><span id=\"ValkeyModule_IsBlockedTimeoutRequest\"></span></p>\n<h3><code>ValkeyModule_IsBlockedTimeoutRequest</code></h3>\n<pre><code>int ValkeyModule_IsBlockedTimeoutRequest(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return non-zero if a module command was called in order to fill the<br>reply for a blocked client that timed out.</p>\n<p><span id=\"ValkeyModule_GetBlockedClientPrivateData\"></span></p>\n<h3><code>ValkeyModule_GetBlockedClientPrivateData</code></h3>\n<pre><code>void *ValkeyModule_GetBlockedClientPrivateData(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Get the private data set by <a href=\"#ValkeyModule_UnblockClient\"><code>ValkeyModule_UnblockClient()</code></a></p>\n<p><span id=\"ValkeyModule_GetBlockedClientReadyKey\"></span></p>\n<h3><code>ValkeyModule_GetBlockedClientReadyKey</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_GetBlockedClientReadyKey(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Get the key that is ready when the reply callback is called in the context<br>of a client blocked by <a href=\"#ValkeyModule_BlockClientOnKeys\"><code>ValkeyModule_BlockClientOnKeys()</code></a>.</p>\n<p><span id=\"ValkeyModule_GetBlockedClientHandle\"></span></p>\n<h3><code>ValkeyModule_GetBlockedClientHandle</code></h3>\n<pre><code>ValkeyModuleBlockedClient *ValkeyModule_GetBlockedClientHandle(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Get the blocked client associated with a given context.<br>This is useful in the reply and timeout callbacks of blocked clients,<br>before sometimes the module has the blocked client handle references<br>around, and wants to cleanup it.</p>\n<p><span id=\"ValkeyModule_BlockedClientDisconnected\"></span></p>\n<h3><code>ValkeyModule_BlockedClientDisconnected</code></h3>\n<pre><code>int ValkeyModule_BlockedClientDisconnected(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Return true if when the free callback of a blocked client is called,<br>the reason for the client to be unblocked is that it disconnected<br>while it was blocked.</p>\n<p><span id=\"section-thread-safe-contexts\"></span></p>\n<h2>Thread Safe Contexts</h2>\n<p><span id=\"ValkeyModule_GetThreadSafeContext\"></span></p>\n<h3><code>ValkeyModule_GetThreadSafeContext</code></h3>\n<pre><code>ValkeyModuleCtx *ValkeyModule_GetThreadSafeContext(ValkeyModuleBlockedClient *bc);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Return a context which can be used inside threads to make calls requiring a<br>context with certain modules APIs. If &#39;bc&#39; is not NULL then the module will<br>be bound to a blocked client, and it will be possible to use the<br><code>ValkeyModule_Reply*</code> family of functions to accumulate a reply for when the<br>client will be unblocked. Otherwise the thread safe context will be<br>detached by a specific client.</p>\n<p>To call non-reply APIs, the thread safe context must be prepared with:</p>\n<pre><code>ValkeyModule_ThreadSafeContextLock(ctx);\n... make your call here ...\nValkeyModule_ThreadSafeContextUnlock(ctx);\n</code></pre>\n<p>This is not needed when using <code>ValkeyModule_Reply*</code> functions, assuming<br>that a blocked client was used when the context was created, otherwise<br>no <code>ValkeyModule_Reply</code>* call should be made at all.</p>\n<p>NOTE: If you&#39;re creating a detached thread safe context (bc is NULL),<br>consider using <a href=\"#ValkeyModule_GetDetachedThreadSafeContext\"><code>ValkeyModule_GetDetachedThreadSafeContext</code></a> which will also retain<br>the module ID and thus be more useful for logging.</p>\n<p><span id=\"ValkeyModule_GetDetachedThreadSafeContext\"></span></p>\n<h3><code>ValkeyModule_GetDetachedThreadSafeContext</code></h3>\n<pre><code>ValkeyModuleCtx *ValkeyModule_GetDetachedThreadSafeContext(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.9</p>\n<p>Return a detached thread safe context that is not associated with any<br>specific blocked client, but is associated with the module&#39;s context.</p>\n<p>This is useful for modules that wish to hold a global context over<br>a long term, for purposes such as logging.</p>\n<p><span id=\"ValkeyModule_FreeThreadSafeContext\"></span></p>\n<h3><code>ValkeyModule_FreeThreadSafeContext</code></h3>\n<pre><code>void ValkeyModule_FreeThreadSafeContext(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Release a thread safe context.</p>\n<p><span id=\"ValkeyModule_ThreadSafeContextLock\"></span></p>\n<h3><code>ValkeyModule_ThreadSafeContextLock</code></h3>\n<pre><code>void ValkeyModule_ThreadSafeContextLock(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Acquire the server lock before executing a thread safe API call.<br>This is not needed for <code>ValkeyModule_Reply*</code> calls when there is<br>a blocked client connected to the thread safe context.</p>\n<p><span id=\"ValkeyModule_ThreadSafeContextTryLock\"></span></p>\n<h3><code>ValkeyModule_ThreadSafeContextTryLock</code></h3>\n<pre><code>int ValkeyModule_ThreadSafeContextTryLock(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.8</p>\n<p>Similar to <a href=\"#ValkeyModule_ThreadSafeContextLock\"><code>ValkeyModule_ThreadSafeContextLock</code></a> but this function<br>would not block if the server lock is already acquired.</p>\n<p>If successful (lock acquired) <code>VALKEYMODULE_OK</code> is returned,<br>otherwise <code>VALKEYMODULE_ERR</code> is returned and errno is set<br>accordingly.</p>\n<p><span id=\"ValkeyModule_ThreadSafeContextUnlock\"></span></p>\n<h3><code>ValkeyModule_ThreadSafeContextUnlock</code></h3>\n<pre><code>void ValkeyModule_ThreadSafeContextUnlock(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.0</p>\n<p>Release the server lock after a thread safe API call was executed.</p>\n<p><span id=\"section-module-keyspace-notifications-api\"></span></p>\n<h2>Module Keyspace Notifications API</h2>\n<p><span id=\"ValkeyModule_SubscribeToKeyspaceEvents\"></span></p>\n<h3><code>ValkeyModule_SubscribeToKeyspaceEvents</code></h3>\n<pre><code>int ValkeyModule_SubscribeToKeyspaceEvents(ValkeyModuleCtx *ctx,\n                                           int types,\n                                           ValkeyModuleNotificationFunc callback);\n</code></pre>\n<p><strong>Available since:</strong> 4.0.9</p>\n<p>Subscribe to keyspace notifications. This is a low-level version of the<br>keyspace-notifications API. A module can register callbacks to be notified<br>when keyspace events occur.</p>\n<p>Notification events are filtered by their type (string events, set events,<br>etc), and the subscriber callback receives only events that match a specific<br>mask of event types.</p>\n<p>When subscribing to notifications with <a href=\"#ValkeyModule_SubscribeToKeyspaceEvents\"><code>ValkeyModule_SubscribeToKeyspaceEvents</code></a><br>the module must provide an event type-mask, denoting the events the subscriber<br>is interested in. This can be an ORed mask of any of the following flags:</p>\n<ul>\n<li><code>VALKEYMODULE_NOTIFY_GENERIC</code>: Generic commands like DEL, EXPIRE, RENAME</li>\n<li><code>VALKEYMODULE_NOTIFY_STRING</code>: String events</li>\n<li><code>VALKEYMODULE_NOTIFY_LIST</code>: List events</li>\n<li><code>VALKEYMODULE_NOTIFY_SET</code>: Set events</li>\n<li><code>VALKEYMODULE_NOTIFY_HASH</code>: Hash events</li>\n<li><code>VALKEYMODULE_NOTIFY_ZSET</code>: Sorted Set events</li>\n<li><code>VALKEYMODULE_NOTIFY_EXPIRED</code>: Expiration events</li>\n<li><code>VALKEYMODULE_NOTIFY_EVICTED</code>: Eviction events</li>\n<li><code>VALKEYMODULE_NOTIFY_STREAM</code>: Stream events</li>\n<li><code>VALKEYMODULE_NOTIFY_MODULE</code>: Module types events</li>\n<li><code>VALKEYMODULE_NOTIFY_KEYMISS</code>: Key-miss events<br>                        Notice, key-miss event is the only type<br>                        of event that is fired from within a read command.<br>                        Performing ValkeyModule_Call with a write command from within<br>                        this notification is wrong and discourage. It will<br>                        cause the read command that trigger the event to be<br>                        replicated to the AOF/Replica.</li>\n<li><code>VALKEYMODULE_NOTIFY_ALL</code>: All events (Excluding <code>VALKEYMODULE_NOTIFY_KEYMISS</code>)</li>\n<li><code>VALKEYMODULE_NOTIFY_LOADED</code>: A special notification available only for modules,<br>                       indicates that the key was loaded from persistence.<br>                       Notice, when this event fires, the given key<br>                       can not be retained, use ValkeyModule_CreateStringFromString<br>                       instead.</li>\n</ul>\n<p>We do not distinguish between key events and keyspace events, and it is up<br>to the module to filter the actions taken based on the key.</p>\n<p>The subscriber signature is:</p>\n<pre><code>int (*ValkeyModuleNotificationFunc) (ValkeyModuleCtx *ctx, int type,\n                                    const char *event,\n                                    ValkeyModuleString *key);\n</code></pre>\n<p><code>type</code> is the event type bit, that must match the mask given at registration<br>time. The event string is the actual command being executed, and key is the<br>relevant key.</p>\n<p>Notification callback gets executed with a context that can not be<br>used to send anything to the client, and has the db number where the event<br>occurred as its selected db number.</p>\n<p>Notice that it is not necessary to enable notifications in valkey.conf for<br>module notifications to work.</p>\n<p>Warning: the notification callbacks are performed in a synchronous manner,<br>so notification callbacks must to be fast, or they would slow the server down.<br>If you need to take long actions, use threads to offload them.</p>\n<p>Moreover, the fact that the notification is executed synchronously means<br>that the notification code will be executed in the middle of server logic<br>(commands logic, eviction, expire). Changing the key space while the logic<br>runs is dangerous and discouraged. In order to react to key space events with<br>write actions, please refer to <a href=\"#ValkeyModule_AddPostNotificationJob\"><code>ValkeyModule_AddPostNotificationJob</code></a>.</p>\n<p>See <a href=\"https://valkey.io/topics/notifications\">https://valkey.io/topics/notifications</a> for more information.</p>\n<p><span id=\"ValkeyModule_AddPostNotificationJob\"></span></p>\n<h3><code>ValkeyModule_AddPostNotificationJob</code></h3>\n<pre><code>int ValkeyModule_AddPostNotificationJob(ValkeyModuleCtx *ctx,\n                                        ValkeyModulePostNotificationJobFunc callback,\n                                        void *privdata,\n                                        void (*free_privdata)(void *));\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>When running inside a key space notification callback, it is dangerous and highly discouraged to perform any write<br>operation (See <a href=\"#ValkeyModule_SubscribeToKeyspaceEvents\"><code>ValkeyModule_SubscribeToKeyspaceEvents</code></a>). In order to still perform write actions in this scenario,<br>the server provides <a href=\"#ValkeyModule_AddPostNotificationJob\"><code>ValkeyModule_AddPostNotificationJob</code></a> API. The API allows to register a job callback which the server will<br>call when the following condition are promised to be fulfilled:</p>\n<ol>\n<li>It is safe to perform any write operation.</li>\n<li>The job will be called atomically along side the key space notification.</li>\n</ol>\n<p>Notice, one job might trigger key space notifications that will trigger more jobs.<br>This raises a concerns of entering an infinite loops, we consider infinite loops<br>as a logical bug that need to be fixed in the module, an attempt to protect against<br>infinite loops by halting the execution could result in violation of the feature correctness<br>and so the server will make no attempt to protect the module from infinite loops.</p>\n<p>&#39;<code>free_pd</code>&#39; can be NULL and in such case will not be used.</p>\n<p>Return <code>VALKEYMODULE_OK</code> on success and <code>VALKEYMODULE_ERR</code> if was called while loading data from disk (AOF or RDB) or<br>if the instance is a readonly replica.</p>\n<p><span id=\"ValkeyModule_GetNotifyKeyspaceEvents\"></span></p>\n<h3><code>ValkeyModule_GetNotifyKeyspaceEvents</code></h3>\n<pre><code>int ValkeyModule_GetNotifyKeyspaceEvents(void);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Get the configured bitmap of notify-keyspace-events (Could be used<br>for additional filtering in <code>ValkeyModuleNotificationFunc</code>)</p>\n<p><span id=\"ValkeyModule_NotifyKeyspaceEvent\"></span></p>\n<h3><code>ValkeyModule_NotifyKeyspaceEvent</code></h3>\n<pre><code>int ValkeyModule_NotifyKeyspaceEvent(ValkeyModuleCtx *ctx,\n                                     int type,\n                                     const char *event,\n                                     ValkeyModuleString *key);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Expose notifyKeyspaceEvent to modules</p>\n<p><span id=\"section-modules-cluster-api\"></span></p>\n<h2>Modules Cluster API</h2>\n<p><span id=\"ValkeyModule_RegisterClusterMessageReceiver\"></span></p>\n<h3><code>ValkeyModule_RegisterClusterMessageReceiver</code></h3>\n<pre><code>void ValkeyModule_RegisterClusterMessageReceiver(ValkeyModuleCtx *ctx,\n                                                 uint8_t type,\n                                                 ValkeyModuleClusterMessageReceiver callback);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Register a callback receiver for cluster messages of type &#39;type&#39;. If there<br>was already a registered callback, this will replace the callback function<br>with the one provided, otherwise if the callback is set to NULL and there<br>is already a callback for this function, the callback is unregistered<br>(so this API call is also used in order to delete the receiver).</p>\n<p>When a message of this type is received, the registered callback function<br>will be invoked with details, including the 40-byte node ID of the sender.</p>\n<p>In Valkey 8.1 and later, the node ID is null-terminated. Prior to 8.1, it was<br>not null-terminated</p>\n<p><span id=\"ValkeyModule_SendClusterMessage\"></span></p>\n<h3><code>ValkeyModule_SendClusterMessage</code></h3>\n<pre><code>int ValkeyModule_SendClusterMessage(ValkeyModuleCtx *ctx,\n                                    const char *target_id,\n                                    uint8_t type,\n                                    const char *msg,\n                                    uint32_t len);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Send a message to all the nodes in the cluster if <code>target</code> is NULL, otherwise<br>at the specified target, which is a <code>VALKEYMODULE_NODE_ID_LEN</code> bytes node ID, as<br>returned by the receiver callback or by the nodes iteration functions.</p>\n<p>In Valkey 8.1 and later, the cluster protocol overhead for this message is<br>~30B, to compare with earlier versions where it&#39;s ~2KB.</p>\n<p>The function returns <code>VALKEYMODULE_OK</code> if the message was successfully sent,<br>otherwise if the node is not connected or such node ID does not map to any<br>known cluster node, <code>VALKEYMODULE_ERR</code> is returned.</p>\n<p><span id=\"ValkeyModule_GetClusterNodesList\"></span></p>\n<h3><code>ValkeyModule_GetClusterNodesList</code></h3>\n<pre><code>char **ValkeyModule_GetClusterNodesList(ValkeyModuleCtx *ctx,\n                                        size_t *numnodes);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Return an array of string pointers, each string pointer points to a cluster<br>node ID of exactly <code>VALKEYMODULE_NODE_ID_LEN</code> bytes (without any null term).<br>The number of returned node IDs is stored into <code>*numnodes</code>.<br>However if this function is called by a module not running an an<br>instance with Cluster enabled, NULL is returned instead.</p>\n<p>The IDs returned can be used with <a href=\"#ValkeyModule_GetClusterNodeInfo\"><code>ValkeyModule_GetClusterNodeInfo()</code></a> in order<br>to get more information about single node.</p>\n<p>The array returned by this function must be freed using the function<br><a href=\"#ValkeyModule_FreeClusterNodesList\"><code>ValkeyModule_FreeClusterNodesList()</code></a>.</p>\n<p>Example:</p>\n<pre><code>size_t count, j;\nchar **ids = ValkeyModule_GetClusterNodesList(ctx,&amp;count);\nfor (j = 0; j &lt; count; j++) {\n    ValkeyModule_Log(ctx,&quot;notice&quot;,&quot;Node %.*s&quot;,\n        VALKEYMODULE_NODE_ID_LEN,ids[j]);\n}\nValkeyModule_FreeClusterNodesList(ids);\n</code></pre>\n<p><span id=\"ValkeyModule_FreeClusterNodesList\"></span></p>\n<h3><code>ValkeyModule_FreeClusterNodesList</code></h3>\n<pre><code>void ValkeyModule_FreeClusterNodesList(char **ids);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Free the node list obtained with <a href=\"#ValkeyModule_GetClusterNodesList\"><code>ValkeyModule_GetClusterNodesList</code></a>.</p>\n<p><span id=\"ValkeyModule_GetMyClusterID\"></span></p>\n<h3><code>ValkeyModule_GetMyClusterID</code></h3>\n<pre><code>const char *ValkeyModule_GetMyClusterID(void);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Return this node ID (<code>VALKEYMODULE_CLUSTER_ID_LEN</code> bytes) or NULL if the cluster<br>is disabled.</p>\n<p><span id=\"ValkeyModule_GetClusterSize\"></span></p>\n<h3><code>ValkeyModule_GetClusterSize</code></h3>\n<pre><code>size_t ValkeyModule_GetClusterSize(void);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Return the number of nodes in the cluster, regardless of their state<br>(handshake, noaddress, ...) so that the number of active nodes may actually<br>be smaller, but not greater than this number. If the instance is not in<br>cluster mode, zero is returned.</p>\n<p><span id=\"ValkeyModule_GetClusterNodeInfo\"></span></p>\n<h3><code>ValkeyModule_GetClusterNodeInfo</code></h3>\n<pre><code>int ValkeyModule_GetClusterNodeInfo(ValkeyModuleCtx *ctx,\n                                    const char *id,\n                                    char *ip,\n                                    char *primary_id,\n                                    int *port,\n                                    int *flags);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Populate the specified info for the node having as ID the specified &#39;id&#39;,<br>then returns <code>VALKEYMODULE_OK</code>. Otherwise if the format of node ID is invalid<br>or the node ID does not exist from the POV of this local node, <code>VALKEYMODULE_ERR</code><br>is returned.</p>\n<p>The arguments <code>ip</code>, <code>primary_id</code>, <code>port</code> and <code>flags</code> can be NULL in case we don&#39;t<br>need to populate back certain info. If an <code>ip</code> and <code>primary_id</code> (only populated<br>if the instance is a replica) are specified, they point to buffers holding<br>at least <code>VALKEYMODULE_NODE_ID_LEN</code> bytes. The strings written back as <code>ip</code><br>and <code>primary_id</code> are not null terminated.</p>\n<p>The list of flags reported is the following:</p>\n<ul>\n<li><code>VALKEYMODULE_NODE_MYSELF</code>:       This node</li>\n<li><code>VALKEYMODULE_NODE_PRIMARY</code>:      The node is a primary</li>\n<li><code>VALKEYMODULE_NODE_REPLICA</code>:      The node is a replica</li>\n<li><code>VALKEYMODULE_NODE_PFAIL</code>:        We see the node as failing</li>\n<li><code>VALKEYMODULE_NODE_FAIL</code>:         The cluster agrees the node is failing</li>\n<li><code>VALKEYMODULE_NODE_NOFAILOVER</code>:   The replica is configured to never failover</li>\n</ul>\n<p><span id=\"ValkeyModule_GetClusterNodeInfoForClient\"></span></p>\n<h3><code>ValkeyModule_GetClusterNodeInfoForClient</code></h3>\n<pre><code>int ValkeyModule_GetClusterNodeInfoForClient(ValkeyModuleCtx *ctx,;\n</code></pre>\n<p><strong>Available since:</strong> 8.0.0</p>\n<p>Like <a href=\"#ValkeyModule_GetClusterNodeInfo\"><code>ValkeyModule_GetClusterNodeInfo()</code></a>, but returns IP address specifically for the given<br>client, depending on whether the client is connected over IPv4 or IPv6.</p>\n<p>See also <a href=\"#ValkeyModule_GetClientId\"><code>ValkeyModule_GetClientId()</code></a>.</p>\n<p><span id=\"ValkeyModule_SetClusterFlags\"></span></p>\n<h3><code>ValkeyModule_SetClusterFlags</code></h3>\n<pre><code>void ValkeyModule_SetClusterFlags(ValkeyModuleCtx *ctx, uint64_t flags);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Set Cluster flags in order to change the normal behavior of<br>Cluster, especially with the goal of disabling certain functions.<br>This is useful for modules that use the Cluster API in order to create<br>a different distributed system, but still want to use the Cluster<br>message bus. Flags that can be set:</p>\n<ul>\n<li><code>CLUSTER_MODULE_FLAG_NO_FAILOVER</code></li>\n<li><code>CLUSTER_MODULE_FLAG_NO_REDIRECTION</code></li>\n</ul>\n<p>With the following effects:</p>\n<ul>\n<li><p><code>NO_FAILOVER</code>: prevent Cluster replicas from failing over a dead primary.<br>         Also disables the replica migration feature.</p>\n</li>\n<li><p><code>NO_REDIRECTION</code>: Every node will accept any key, without trying to perform<br>            partitioning according to the Cluster algorithm.<br>            Slots information will still be propagated across the<br>            cluster, but without effect.</p>\n</li>\n</ul>\n<p><span id=\"ValkeyModule_ClusterKeySlot\"></span></p>\n<h3><code>ValkeyModule_ClusterKeySlot</code></h3>\n<pre><code>unsigned int ValkeyModule_ClusterKeySlot(ValkeyModuleString *key);\n</code></pre>\n<p><strong>Available since:</strong> 8.0.0</p>\n<p>Returns the cluster slot of a key, similar to the <code>CLUSTER KEYSLOT</code> command.<br>This function works even if cluster mode is not enabled.</p>\n<p><span id=\"ValkeyModule_ClusterCanonicalKeyNameInSlot\"></span></p>\n<h3><code>ValkeyModule_ClusterCanonicalKeyNameInSlot</code></h3>\n<pre><code>const char *ValkeyModule_ClusterCanonicalKeyNameInSlot(unsigned int slot);\n</code></pre>\n<p><strong>Available since:</strong> 8.0.0</p>\n<p>Returns a short string that can be used as a key or as a hash tag in a key,<br>such that the key maps to the given cluster slot. Returns NULL if slot is not<br>a valid slot.</p>\n<p><span id=\"section-modules-timers-api\"></span></p>\n<h2>Modules Timers API</h2>\n<p>Module timers are a high precision &quot;green timers&quot; abstraction where<br>every module can register even millions of timers without problems, even if<br>the actual event loop will just have a single timer that is used to awake the<br>module timers subsystem in order to process the next event.</p>\n<p>All the timers are stored into a radix tree, ordered by expire time, when<br>the main server event loop timer callback is called, we try to process all<br>the timers already expired one after the other. Then we re-enter the event<br>loop registering a timer that will expire when the next to process module<br>timer will expire.</p>\n<p>Every time the list of active timers drops to zero, we unregister the<br>main event loop timer, so that there is no overhead when such feature is<br>not used.</p>\n<p><span id=\"ValkeyModule_CreateTimer\"></span></p>\n<h3><code>ValkeyModule_CreateTimer</code></h3>\n<pre><code>ValkeyModuleTimerID ValkeyModule_CreateTimer(ValkeyModuleCtx *ctx,\n                                             mstime_t period,\n                                             ValkeyModuleTimerProc callback,\n                                             void *data);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Create a new timer that will fire after <code>period</code> milliseconds, and will call<br>the specified function using <code>data</code> as argument. The returned timer ID can be<br>used to get information from the timer or to stop it before it fires.<br>Note that for the common use case of a repeating timer (Re-registration<br>of the timer inside the <code>ValkeyModuleTimerProc</code> callback) it matters when<br>this API is called:<br>If it is called at the beginning of &#39;callback&#39; it means<br>the event will triggered every &#39;period&#39;.<br>If it is called at the end of &#39;callback&#39; it means<br>there will &#39;period&#39; milliseconds gaps between events.<br>(If the time it takes to execute &#39;callback&#39; is negligible the two<br>statements above mean the same)</p>\n<p><span id=\"ValkeyModule_StopTimer\"></span></p>\n<h3><code>ValkeyModule_StopTimer</code></h3>\n<pre><code>int ValkeyModule_StopTimer(ValkeyModuleCtx *ctx,\n                           ValkeyModuleTimerID id,\n                           void **data);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Stop a timer, returns <code>VALKEYMODULE_OK</code> if the timer was found, belonged to the<br>calling module, and was stopped, otherwise <code>VALKEYMODULE_ERR</code> is returned.<br>If not NULL, the data pointer is set to the value of the data argument when<br>the timer was created.</p>\n<p><span id=\"ValkeyModule_GetTimerInfo\"></span></p>\n<h3><code>ValkeyModule_GetTimerInfo</code></h3>\n<pre><code>int ValkeyModule_GetTimerInfo(ValkeyModuleCtx *ctx,\n                              ValkeyModuleTimerID id,\n                              uint64_t *remaining,\n                              void **data);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Obtain information about a timer: its remaining time before firing<br>(in milliseconds), and the private data pointer associated with the timer.<br>If the timer specified does not exist or belongs to a different module<br>no information is returned and the function returns <code>VALKEYMODULE_ERR</code>, otherwise<br><code>VALKEYMODULE_OK</code> is returned. The arguments remaining or data can be NULL if<br>the caller does not need certain information.</p>\n<p><span id=\"section-modules-eventloop-api\"></span></p>\n<h2>Modules EventLoop API</h2>\n<p><span id=\"ValkeyModule_EventLoopAdd\"></span></p>\n<h3><code>ValkeyModule_EventLoopAdd</code></h3>\n<pre><code>int ValkeyModule_EventLoopAdd(int fd,\n                              int mask,\n                              ValkeyModuleEventLoopFunc func,\n                              void *user_data);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Add a pipe / socket event to the event loop.</p>\n<ul>\n<li><p><code>mask</code> must be one of the following values:</p>\n<ul>\n<li><code>VALKEYMODULE_EVENTLOOP_READABLE</code></li>\n<li><code>VALKEYMODULE_EVENTLOOP_WRITABLE</code></li>\n<li><code>VALKEYMODULE_EVENTLOOP_READABLE | VALKEYMODULE_EVENTLOOP_WRITABLE</code></li>\n</ul>\n</li>\n</ul>\n<p>On success <code>VALKEYMODULE_OK</code> is returned, otherwise<br><code>VALKEYMODULE_ERR</code> is returned and errno is set to the following values:</p>\n<ul>\n<li>ERANGE: <code>fd</code> is negative or higher than <code>maxclients</code> server config.</li>\n<li>EINVAL: <code>callback</code> is NULL or <code>mask</code> value is invalid.</li>\n</ul>\n<p><code>errno</code> might take other values in case of an internal error.</p>\n<p>Example:</p>\n<pre><code>void onReadable(int fd, void *user_data, int mask) {\n    char buf[32];\n    int bytes = read(fd,buf,sizeof(buf));\n    printf(&quot;Read %d bytes \\n&quot;, bytes);\n}\nValkeyModule_EventLoopAdd(fd, VALKEYMODULE_EVENTLOOP_READABLE, onReadable, NULL);\n</code></pre>\n<p><span id=\"ValkeyModule_EventLoopDel\"></span></p>\n<h3><code>ValkeyModule_EventLoopDel</code></h3>\n<pre><code>int ValkeyModule_EventLoopDel(int fd, int mask);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Delete a pipe / socket event from the event loop.</p>\n<ul>\n<li><p><code>mask</code> must be one of the following values:</p>\n<ul>\n<li><code>VALKEYMODULE_EVENTLOOP_READABLE</code></li>\n<li><code>VALKEYMODULE_EVENTLOOP_WRITABLE</code></li>\n<li><code>VALKEYMODULE_EVENTLOOP_READABLE | VALKEYMODULE_EVENTLOOP_WRITABLE</code></li>\n</ul>\n</li>\n</ul>\n<p>On success <code>VALKEYMODULE_OK</code> is returned, otherwise<br><code>VALKEYMODULE_ERR</code> is returned and errno is set to the following values:</p>\n<ul>\n<li>ERANGE: <code>fd</code> is negative or higher than <code>maxclients</code> server config.</li>\n<li>EINVAL: <code>mask</code> value is invalid.</li>\n</ul>\n<p><span id=\"ValkeyModule_EventLoopAddOneShot\"></span></p>\n<h3><code>ValkeyModule_EventLoopAddOneShot</code></h3>\n<pre><code>int ValkeyModule_EventLoopAddOneShot(ValkeyModuleEventLoopOneShotFunc func,\n                                     void *user_data);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>This function can be called from other threads to trigger callback on the server<br>main thread. On success <code>VALKEYMODULE_OK</code> is returned. If <code>func</code> is NULL<br><code>VALKEYMODULE_ERR</code> is returned and errno is set to EINVAL.</p>\n<p><span id=\"section-modules-acl-api\"></span></p>\n<h2>Modules ACL API</h2>\n<p>Implements a hook into the authentication and authorization within the server.</p>\n<p><span id=\"ValkeyModule_CreateModuleUser\"></span></p>\n<h3><code>ValkeyModule_CreateModuleUser</code></h3>\n<pre><code>ValkeyModuleUser *ValkeyModule_CreateModuleUser(const char *name);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Creates an ACL user that the module can use to authenticate a client.<br>After obtaining the user, the module should set what such user can do<br>using the <code>ValkeyModule_SetUserACL()</code> function. Once configured, the user<br>can be used in order to authenticate a connection, with the specified<br>ACL rules, using the <code>ValkeyModule_AuthClientWithUser()</code> function.</p>\n<p>Note that:</p>\n<ul>\n<li>Users created here are not listed by the ACL command.</li>\n<li>Users created here are not checked for duplicated name, so it&#39;s up to<br>the module calling this function to take care of not creating users<br>with the same name.</li>\n<li>The created user can be used to authenticate multiple connections.</li>\n</ul>\n<p>The caller can later free the user using the function<br><a href=\"#ValkeyModule_FreeModuleUser\"><code>ValkeyModule_FreeModuleUser()</code></a>. When this function is called, if there are<br>still clients authenticated with this user, they are disconnected.<br>The function to free the user should only be used when the caller really<br>wants to invalidate the user to define a new one with different<br>capabilities.</p>\n<p><span id=\"ValkeyModule_FreeModuleUser\"></span></p>\n<h3><code>ValkeyModule_FreeModuleUser</code></h3>\n<pre><code>int ValkeyModule_FreeModuleUser(ValkeyModuleUser *user);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Frees a given user and disconnects all of the clients that have been<br>authenticated with it. See <a href=\"#ValkeyModule_CreateModuleUser\"><code>ValkeyModule_CreateModuleUser</code></a> for detailed usage.</p>\n<p><span id=\"ValkeyModule_SetModuleUserACL\"></span></p>\n<h3><code>ValkeyModule_SetModuleUserACL</code></h3>\n<pre><code>int ValkeyModule_SetModuleUserACL(ValkeyModuleUser *user, const char *acl);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Sets the permissions of a user created through the module<br>interface. The syntax is the same as ACL SETUSER, so refer to the<br>documentation in acl.c for more information. See <a href=\"#ValkeyModule_CreateModuleUser\"><code>ValkeyModule_CreateModuleUser</code></a><br>for detailed usage.</p>\n<p>Returns <code>VALKEYMODULE_OK</code> on success and <code>VALKEYMODULE_ERR</code> on failure<br>and will set an errno describing why the operation failed.</p>\n<p><span id=\"ValkeyModule_SetModuleUserACLString\"></span></p>\n<h3><code>ValkeyModule_SetModuleUserACLString</code></h3>\n<pre><code>int ValkeyModule_SetModuleUserACLString(ValkeyModuleCtx *ctx,\n                                        ValkeyModuleUser *user,\n                                        const char *acl,\n                                        ValkeyModuleString **error);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.6</p>\n<p>Sets the permission of a user with a complete ACL string, such as one<br>would use on the ACL SETUSER command line API. This differs from<br><a href=\"#ValkeyModule_SetModuleUserACL\"><code>ValkeyModule_SetModuleUserACL</code></a>, which only takes single ACL operations at a time.</p>\n<p>Returns <code>VALKEYMODULE_OK</code> on success and <code>VALKEYMODULE_ERR</code> on failure<br>if a <code>ValkeyModuleString</code> is provided in error, a string describing the error<br>will be returned</p>\n<p><span id=\"ValkeyModule_GetModuleUserACLString\"></span></p>\n<h3><code>ValkeyModule_GetModuleUserACLString</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_GetModuleUserACLString(ValkeyModuleUser *user);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.6</p>\n<p>Get the ACL string for a given user<br>Returns a <code>ValkeyModuleString</code></p>\n<p><span id=\"ValkeyModule_GetCurrentUserName\"></span></p>\n<h3><code>ValkeyModule_GetCurrentUserName</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_GetCurrentUserName(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Retrieve the user name of the client connection behind the current context.<br>The user name can be used later, in order to get a <code>ValkeyModuleUser</code>.<br>See more information in <a href=\"#ValkeyModule_GetModuleUserFromUserName\"><code>ValkeyModule_GetModuleUserFromUserName</code></a>.</p>\n<p>The returned string must be released with <a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString()</code></a> or by<br>enabling automatic memory management.</p>\n<p>If the context is not associated with a client connection, NULL is returned<br>and errno is set to EINVAL.</p>\n<p><span id=\"ValkeyModule_GetModuleUserFromUserName\"></span></p>\n<h3><code>ValkeyModule_GetModuleUserFromUserName</code></h3>\n<pre><code>ValkeyModuleUser *ValkeyModule_GetModuleUserFromUserName(ValkeyModuleString *name);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>A <code>ValkeyModuleUser</code> can be used to check if command, key or channel can be executed or<br>accessed according to the ACLs rules associated with that user.<br>When a Module wants to do ACL checks on a general ACL user (not created by <a href=\"#ValkeyModule_CreateModuleUser\"><code>ValkeyModule_CreateModuleUser</code></a>),<br>it can get the <code>ValkeyModuleUser</code> from this API, based on the user name retrieved by <a href=\"#ValkeyModule_GetCurrentUserName\"><code>ValkeyModule_GetCurrentUserName</code></a>.</p>\n<p>Since a general ACL user can be deleted at any time, this <code>ValkeyModuleUser</code> should be used only in the context<br>where this function was called. In order to do ACL checks out of that context, the Module can store the user name,<br>and call this API at any other context.</p>\n<p>Returns NULL if the user is disabled or the user does not exist.<br>The caller should later free the user using the function <a href=\"#ValkeyModule_FreeModuleUser\"><code>ValkeyModule_FreeModuleUser()</code></a>.</p>\n<p><span id=\"ValkeyModule_ACLCheckCommandPermissions\"></span></p>\n<h3><code>ValkeyModule_ACLCheckCommandPermissions</code></h3>\n<pre><code>int ValkeyModule_ACLCheckCommandPermissions(ValkeyModuleUser *user,\n                                            ValkeyModuleString **argv,\n                                            int argc);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Checks if the command can be executed by the user, according to the ACLs associated with it.</p>\n<p>On success a <code>VALKEYMODULE_OK</code> is returned, otherwise<br><code>VALKEYMODULE_ERR</code> is returned and errno is set to the following values:</p>\n<ul>\n<li>ENOENT: Specified command does not exist.</li>\n<li>EACCES: Command cannot be executed, according to ACL rules</li>\n</ul>\n<p><span id=\"ValkeyModule_ACLCheckKeyPermissions\"></span></p>\n<h3><code>ValkeyModule_ACLCheckKeyPermissions</code></h3>\n<pre><code>int ValkeyModule_ACLCheckKeyPermissions(ValkeyModuleUser *user,\n                                        ValkeyModuleString *key,\n                                        int flags);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Check if the key can be accessed by the user according to the ACLs attached to the user<br>and the flags representing the key access. The flags are the same that are used in the<br>keyspec for logical operations. These flags are documented in <a href=\"#ValkeyModule_SetCommandInfo\"><code>ValkeyModule_SetCommandInfo</code></a> as<br>the <code>VALKEYMODULE_CMD_KEY_ACCESS</code>, <code>VALKEYMODULE_CMD_KEY_UPDATE</code>, <code>VALKEYMODULE_CMD_KEY_INSERT</code>,<br>and <code>VALKEYMODULE_CMD_KEY_DELETE</code> flags.</p>\n<p>If no flags are supplied, the user is still required to have some access to the key for<br>this command to return successfully.</p>\n<p>If the user is able to access the key then <code>VALKEYMODULE_OK</code> is returned, otherwise<br><code>VALKEYMODULE_ERR</code> is returned and errno is set to one of the following values:</p>\n<ul>\n<li>EINVAL: The provided flags are invalid.</li>\n<li>EACCESS: The user does not have permission to access the key.</li>\n</ul>\n<p><span id=\"ValkeyModule_ACLCheckChannelPermissions\"></span></p>\n<h3><code>ValkeyModule_ACLCheckChannelPermissions</code></h3>\n<pre><code>int ValkeyModule_ACLCheckChannelPermissions(ValkeyModuleUser *user,\n                                            ValkeyModuleString *ch,\n                                            int flags);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Check if the pubsub channel can be accessed by the user based off of the given<br>access flags. See <a href=\"#ValkeyModule_ChannelAtPosWithFlags\"><code>ValkeyModule_ChannelAtPosWithFlags</code></a> for more information about the<br>possible flags that can be passed in.</p>\n<p>If the user is able to access the pubsub channel then <code>VALKEYMODULE_OK</code> is returned, otherwise<br><code>VALKEYMODULE_ERR</code> is returned and errno is set to one of the following values:</p>\n<ul>\n<li>EINVAL: The provided flags are invalid.</li>\n<li>EACCESS: The user does not have permission to access the pubsub channel.</li>\n</ul>\n<p><span id=\"ValkeyModule_ACLAddLogEntry\"></span></p>\n<h3><code>ValkeyModule_ACLAddLogEntry</code></h3>\n<pre><code>int ValkeyModule_ACLAddLogEntry(ValkeyModuleCtx *ctx,\n                                ValkeyModuleUser *user,\n                                ValkeyModuleString *object,\n                                ValkeyModuleACLLogEntryReason reason);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Adds a new entry in the ACL log.<br>Returns <code>VALKEYMODULE_OK</code> on success and <code>VALKEYMODULE_ERR</code> on error.</p>\n<p>For more information about ACL log, please refer to <a href=\"https://valkey.io/commands/acl-log\">https://valkey.io/commands/acl-log</a></p>\n<p><span id=\"ValkeyModule_ACLAddLogEntryByUserName\"></span></p>\n<h3><code>ValkeyModule_ACLAddLogEntryByUserName</code></h3>\n<pre><code>int ValkeyModule_ACLAddLogEntryByUserName(ValkeyModuleCtx *ctx,\n                                          ValkeyModuleString *username,\n                                          ValkeyModuleString *object,\n                                          ValkeyModuleACLLogEntryReason reason);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Adds a new entry in the ACL log with the <code>username</code> <code>ValkeyModuleString</code> provided.<br>Returns <code>VALKEYMODULE_OK</code> on success and <code>VALKEYMODULE_ERR</code> on error.</p>\n<p>For more information about ACL log, please refer to <a href=\"https://valkey.io/commands/acl-log\">https://valkey.io/commands/acl-log</a></p>\n<p><span id=\"ValkeyModule_AuthenticateClientWithUser\"></span></p>\n<h3><code>ValkeyModule_AuthenticateClientWithUser</code></h3>\n<pre><code>int ValkeyModule_AuthenticateClientWithUser(ValkeyModuleCtx *ctx,\n                                            ValkeyModuleUser *module_user,\n                                            ValkeyModuleUserChangedFunc callback,\n                                            void *privdata,\n                                            uint64_t *client_id);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Authenticate the current context&#39;s user with the provided acl user.<br>Returns <code>VALKEYMODULE_ERR</code> if the user is disabled.</p>\n<p>See authenticateClientWithUser for information about callback, <code>client_id</code>,<br>and general usage for authentication.</p>\n<p><span id=\"ValkeyModule_AuthenticateClientWithACLUser\"></span></p>\n<h3><code>ValkeyModule_AuthenticateClientWithACLUser</code></h3>\n<pre><code>int ValkeyModule_AuthenticateClientWithACLUser(ValkeyModuleCtx *ctx,\n                                               const char *name,\n                                               size_t len,\n                                               ValkeyModuleUserChangedFunc callback,\n                                               void *privdata,\n                                               uint64_t *client_id);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Authenticate the current context&#39;s user with the provided acl user.<br>Returns <code>VALKEYMODULE_ERR</code> if the user is disabled or the user does not exist.</p>\n<p>See authenticateClientWithUser for information about callback, <code>client_id</code>,<br>and general usage for authentication.</p>\n<p><span id=\"ValkeyModule_DeauthenticateAndCloseClient\"></span></p>\n<h3><code>ValkeyModule_DeauthenticateAndCloseClient</code></h3>\n<pre><code>int ValkeyModule_DeauthenticateAndCloseClient(ValkeyModuleCtx *ctx,\n                                              uint64_t client_id);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Deauthenticate and close the client. The client resources will not be<br>immediately freed, but will be cleaned up in a background job. This is<br>the recommended way to deauthenticate a client since most clients can&#39;t<br>handle users becoming deauthenticated. Returns <code>VALKEYMODULE_ERR</code> when the<br>client doesn&#39;t exist and <code>VALKEYMODULE_OK</code> when the operation was successful.</p>\n<p>The client ID is returned from the <a href=\"#ValkeyModule_AuthenticateClientWithUser\"><code>ValkeyModule_AuthenticateClientWithUser</code></a> and<br><a href=\"#ValkeyModule_AuthenticateClientWithACLUser\"><code>ValkeyModule_AuthenticateClientWithACLUser</code></a> APIs, but can be obtained through<br>the CLIENT api or through server events.</p>\n<p>This function is not thread safe, and must be executed within the context<br>of a command or thread safe context.</p>\n<p><span id=\"ValkeyModule_RedactClientCommandArgument\"></span></p>\n<h3><code>ValkeyModule_RedactClientCommandArgument</code></h3>\n<pre><code>int ValkeyModule_RedactClientCommandArgument(ValkeyModuleCtx *ctx, int pos);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Redact the client command argument specified at the given position. Redacted arguments<br>are obfuscated in user facing commands such as SLOWLOG or MONITOR, as well as<br>never being written to server logs. This command may be called multiple times on the<br>same position.</p>\n<p>Note that the command name, position 0, can not be redacted.</p>\n<p>Returns <code>VALKEYMODULE_OK</code> if the argument was redacted and <code>VALKEYMODULE_ERR</code> if there<br>was an invalid parameter passed in or the position is outside the client<br>argument range.</p>\n<p><span id=\"ValkeyModule_GetClientCertificate\"></span></p>\n<h3><code>ValkeyModule_GetClientCertificate</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_GetClientCertificate(ValkeyModuleCtx *ctx,\n                                                      uint64_t client_id);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.9</p>\n<p>Return the X.509 client-side certificate used by the client to authenticate<br>this connection.</p>\n<p>The return value is an allocated <code>ValkeyModuleString</code> that is a X.509 certificate<br>encoded in PEM (Base64) format. It should be freed (or auto-freed) by the caller.</p>\n<p>A NULL value is returned in the following conditions:</p>\n<ul>\n<li>Connection ID does not exist</li>\n<li>Connection is not a TLS connection</li>\n<li>Connection is a TLS connection but no client certificate was used</li>\n</ul>\n<p><span id=\"section-modules-dictionary-api\"></span></p>\n<h2>Modules Dictionary API</h2>\n<p>Implements a sorted dictionary (actually backed by a radix tree) with<br>the usual get / set / del / num-items API, together with an iterator<br>capable of going back and forth.</p>\n<p><span id=\"ValkeyModule_CreateDict\"></span></p>\n<h3><code>ValkeyModule_CreateDict</code></h3>\n<pre><code>ValkeyModuleDict *ValkeyModule_CreateDict(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Create a new dictionary. The &#39;ctx&#39; pointer can be the current module context<br>or NULL, depending on what you want. Please follow the following rules:</p>\n<ol>\n<li>Use a NULL context if you plan to retain a reference to this dictionary<br>that will survive the time of the module callback where you created it.</li>\n<li>Use a NULL context if no context is available at the time you are creating<br>the dictionary (of course...).</li>\n<li>However use the current callback context as &#39;ctx&#39; argument if the<br>dictionary time to live is just limited to the callback scope. In this<br>case, if enabled, you can enjoy the automatic memory management that will<br>reclaim the dictionary memory, as well as the strings returned by the<br>Next / Prev dictionary iterator calls.</li>\n</ol>\n<p><span id=\"ValkeyModule_FreeDict\"></span></p>\n<h3><code>ValkeyModule_FreeDict</code></h3>\n<pre><code>void ValkeyModule_FreeDict(ValkeyModuleCtx *ctx, ValkeyModuleDict *d);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Free a dictionary created with <a href=\"#ValkeyModule_CreateDict\"><code>ValkeyModule_CreateDict()</code></a>. You need to pass the<br>context pointer &#39;ctx&#39; only if the dictionary was created using the<br>context instead of passing NULL.</p>\n<p><span id=\"ValkeyModule_DictSize\"></span></p>\n<h3><code>ValkeyModule_DictSize</code></h3>\n<pre><code>uint64_t ValkeyModule_DictSize(ValkeyModuleDict *d);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Return the size of the dictionary (number of keys).</p>\n<p><span id=\"ValkeyModule_DictSetC\"></span></p>\n<h3><code>ValkeyModule_DictSetC</code></h3>\n<pre><code>int ValkeyModule_DictSetC(ValkeyModuleDict *d,\n                          void *key,\n                          size_t keylen,\n                          void *ptr);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Store the specified key into the dictionary, setting its value to the<br>pointer &#39;ptr&#39;. If the key was added with success, since it did not<br>already exist, <code>VALKEYMODULE_OK</code> is returned. Otherwise if the key already<br>exists the function returns <code>VALKEYMODULE_ERR</code>.</p>\n<p><span id=\"ValkeyModule_DictReplaceC\"></span></p>\n<h3><code>ValkeyModule_DictReplaceC</code></h3>\n<pre><code>int ValkeyModule_DictReplaceC(ValkeyModuleDict *d,\n                              void *key,\n                              size_t keylen,\n                              void *ptr);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Like <a href=\"#ValkeyModule_DictSetC\"><code>ValkeyModule_DictSetC()</code></a> but will replace the key with the new<br>value if the key already exists.</p>\n<p><span id=\"ValkeyModule_DictSet\"></span></p>\n<h3><code>ValkeyModule_DictSet</code></h3>\n<pre><code>int ValkeyModule_DictSet(ValkeyModuleDict *d,\n                         ValkeyModuleString *key,\n                         void *ptr);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Like <a href=\"#ValkeyModule_DictSetC\"><code>ValkeyModule_DictSetC()</code></a> but takes the key as a <code>ValkeyModuleString</code>.</p>\n<p><span id=\"ValkeyModule_DictReplace\"></span></p>\n<h3><code>ValkeyModule_DictReplace</code></h3>\n<pre><code>int ValkeyModule_DictReplace(ValkeyModuleDict *d,\n                             ValkeyModuleString *key,\n                             void *ptr);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Like <a href=\"#ValkeyModule_DictReplaceC\"><code>ValkeyModule_DictReplaceC()</code></a> but takes the key as a <code>ValkeyModuleString</code>.</p>\n<p><span id=\"ValkeyModule_DictGetC\"></span></p>\n<h3><code>ValkeyModule_DictGetC</code></h3>\n<pre><code>void *ValkeyModule_DictGetC(ValkeyModuleDict *d,\n                            void *key,\n                            size_t keylen,\n                            int *nokey);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Return the value stored at the specified key. The function returns NULL<br>both in the case the key does not exist, or if you actually stored<br>NULL at key. So, optionally, if the &#39;nokey&#39; pointer is not NULL, it will<br>be set by reference to 1 if the key does not exist, or to 0 if the key<br>exists.</p>\n<p><span id=\"ValkeyModule_DictGet\"></span></p>\n<h3><code>ValkeyModule_DictGet</code></h3>\n<pre><code>void *ValkeyModule_DictGet(ValkeyModuleDict *d,\n                           ValkeyModuleString *key,\n                           int *nokey);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Like <a href=\"#ValkeyModule_DictGetC\"><code>ValkeyModule_DictGetC()</code></a> but takes the key as a <code>ValkeyModuleString</code>.</p>\n<p><span id=\"ValkeyModule_DictDelC\"></span></p>\n<h3><code>ValkeyModule_DictDelC</code></h3>\n<pre><code>int ValkeyModule_DictDelC(ValkeyModuleDict *d,\n                          void *key,\n                          size_t keylen,\n                          void *oldval);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Remove the specified key from the dictionary, returning <code>VALKEYMODULE_OK</code> if<br>the key was found and deleted, or <code>VALKEYMODULE_ERR</code> if instead there was<br>no such key in the dictionary. When the operation is successful, if<br>&#39;oldval&#39; is not NULL, then &#39;*oldval&#39; is set to the value stored at the<br>key before it was deleted. Using this feature it is possible to get<br>a pointer to the value (for instance in order to release it), without<br>having to call <a href=\"#ValkeyModule_DictGet\"><code>ValkeyModule_DictGet()</code></a> before deleting the key.</p>\n<p><span id=\"ValkeyModule_DictDel\"></span></p>\n<h3><code>ValkeyModule_DictDel</code></h3>\n<pre><code>int ValkeyModule_DictDel(ValkeyModuleDict *d,\n                         ValkeyModuleString *key,\n                         void *oldval);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Like <a href=\"#ValkeyModule_DictDelC\"><code>ValkeyModule_DictDelC()</code></a> but gets the key as a <code>ValkeyModuleString</code>.</p>\n<p><span id=\"ValkeyModule_DictIteratorStartC\"></span></p>\n<h3><code>ValkeyModule_DictIteratorStartC</code></h3>\n<pre><code>ValkeyModuleDictIter *ValkeyModule_DictIteratorStartC(ValkeyModuleDict *d,\n                                                      const char *op,\n                                                      void *key,\n                                                      size_t keylen);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Return an iterator, setup in order to start iterating from the specified<br>key by applying the operator &#39;op&#39;, which is just a string specifying the<br>comparison operator to use in order to seek the first element. The<br>operators available are:</p>\n<ul>\n<li><code>^</code>   – Seek the first (lexicographically smaller) key.</li>\n<li><code>$</code>   – Seek the last  (lexicographically bigger) key.</li>\n<li><code>&gt;</code>   – Seek the first element greater than the specified key.</li>\n<li><code>&gt;=</code>  – Seek the first element greater or equal than the specified key.</li>\n<li><code>&lt;</code>   – Seek the first element smaller than the specified key.</li>\n<li><code>&lt;=</code>  – Seek the first element smaller or equal than the specified key.</li>\n<li><code>==</code>  – Seek the first element matching exactly the specified key.</li>\n</ul>\n<p>Note that for <code>^</code> and <code>$</code> the passed key is not used, and the user may<br>just pass NULL with a length of 0.</p>\n<p>If the element to start the iteration cannot be seeked based on the<br>key and operator passed, <a href=\"#ValkeyModule_DictNext\"><code>ValkeyModule_DictNext()</code></a> / Prev() will just return<br><code>VALKEYMODULE_ERR</code> at the first call, otherwise they&#39;ll produce elements.</p>\n<p><span id=\"ValkeyModule_DictIteratorStart\"></span></p>\n<h3><code>ValkeyModule_DictIteratorStart</code></h3>\n<pre><code>ValkeyModuleDictIter *ValkeyModule_DictIteratorStart(ValkeyModuleDict *d,\n                                                     const char *op,\n                                                     ValkeyModuleString *key);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Exactly like <a href=\"#ValkeyModule_DictIteratorStartC\"><code>ValkeyModule_DictIteratorStartC</code></a>, but the key is passed as a<br><code>ValkeyModuleString</code>.</p>\n<p><span id=\"ValkeyModule_DictIteratorStop\"></span></p>\n<h3><code>ValkeyModule_DictIteratorStop</code></h3>\n<pre><code>void ValkeyModule_DictIteratorStop(ValkeyModuleDictIter *di);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Release the iterator created with <a href=\"#ValkeyModule_DictIteratorStart\"><code>ValkeyModule_DictIteratorStart()</code></a>. This call<br>is mandatory otherwise a memory leak is introduced in the module.</p>\n<p><span id=\"ValkeyModule_DictIteratorReseekC\"></span></p>\n<h3><code>ValkeyModule_DictIteratorReseekC</code></h3>\n<pre><code>int ValkeyModule_DictIteratorReseekC(ValkeyModuleDictIter *di,\n                                     const char *op,\n                                     void *key,\n                                     size_t keylen);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>After its creation with <a href=\"#ValkeyModule_DictIteratorStart\"><code>ValkeyModule_DictIteratorStart()</code></a>, it is possible to<br>change the currently selected element of the iterator by using this<br>API call. The result based on the operator and key is exactly like<br>the function <a href=\"#ValkeyModule_DictIteratorStart\"><code>ValkeyModule_DictIteratorStart()</code></a>, however in this case the<br>return value is just <code>VALKEYMODULE_OK</code> in case the seeked element was found,<br>or <code>VALKEYMODULE_ERR</code> in case it was not possible to seek the specified<br>element. It is possible to reseek an iterator as many times as you want.</p>\n<p><span id=\"ValkeyModule_DictIteratorReseek\"></span></p>\n<h3><code>ValkeyModule_DictIteratorReseek</code></h3>\n<pre><code>int ValkeyModule_DictIteratorReseek(ValkeyModuleDictIter *di,\n                                    const char *op,\n                                    ValkeyModuleString *key);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Like <a href=\"#ValkeyModule_DictIteratorReseekC\"><code>ValkeyModule_DictIteratorReseekC()</code></a> but takes the key as a<br><code>ValkeyModuleString</code>.</p>\n<p><span id=\"ValkeyModule_DictNextC\"></span></p>\n<h3><code>ValkeyModule_DictNextC</code></h3>\n<pre><code>void *ValkeyModule_DictNextC(ValkeyModuleDictIter *di,\n                             size_t *keylen,\n                             void **dataptr);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Return the current item of the dictionary iterator <code>di</code> and steps to the<br>next element. If the iterator already yield the last element and there<br>are no other elements to return, NULL is returned, otherwise a pointer<br>to a string representing the key is provided, and the <code>*keylen</code> length<br>is set by reference (if keylen is not NULL). The <code>*dataptr</code>, if not NULL<br>is set to the value of the pointer stored at the returned key as auxiliary<br>data (as set by the <a href=\"#ValkeyModule_DictSet\"><code>ValkeyModule_DictSet</code></a> API).</p>\n<p>Usage example:</p>\n<pre><code> ... create the iterator here ...\n char *key;\n void *data;\n while((key = ValkeyModule_DictNextC(iter,&amp;keylen,&amp;data)) != NULL) {\n     printf(&quot;%.*s %p\\n&quot;, (int)keylen, key, data);\n }\n</code></pre>\n<p>The returned pointer is of type void because sometimes it makes sense<br>to cast it to a <code>char*</code> sometimes to an unsigned <code>char*</code> depending on the<br>fact it contains or not binary data, so this API ends being more<br>comfortable to use.</p>\n<p>The validity of the returned pointer is until the next call to the<br>next/prev iterator step. Also the pointer is no longer valid once the<br>iterator is released.</p>\n<p><span id=\"ValkeyModule_DictPrevC\"></span></p>\n<h3><code>ValkeyModule_DictPrevC</code></h3>\n<pre><code>void *ValkeyModule_DictPrevC(ValkeyModuleDictIter *di,\n                             size_t *keylen,\n                             void **dataptr);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>This function is exactly like <a href=\"#ValkeyModule_DictNext\"><code>ValkeyModule_DictNext()</code></a> but after returning<br>the currently selected element in the iterator, it selects the previous<br>element (lexicographically smaller) instead of the next one.</p>\n<p><span id=\"ValkeyModule_DictNext\"></span></p>\n<h3><code>ValkeyModule_DictNext</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_DictNext(ValkeyModuleCtx *ctx,\n                                          ValkeyModuleDictIter *di,\n                                          void **dataptr);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Like <code>ValkeyModuleNextC()</code>, but instead of returning an internally allocated<br>buffer and key length, it returns directly a module string object allocated<br>in the specified context &#39;ctx&#39; (that may be NULL exactly like for the main<br>API <a href=\"#ValkeyModule_CreateString\"><code>ValkeyModule_CreateString</code></a>).</p>\n<p>The returned string object should be deallocated after use, either manually<br>or by using a context that has automatic memory management active.</p>\n<p><span id=\"ValkeyModule_DictPrev\"></span></p>\n<h3><code>ValkeyModule_DictPrev</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_DictPrev(ValkeyModuleCtx *ctx,\n                                          ValkeyModuleDictIter *di,\n                                          void **dataptr);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Like <a href=\"#ValkeyModule_DictNext\"><code>ValkeyModule_DictNext()</code></a> but after returning the currently selected<br>element in the iterator, it selects the previous element (lexicographically<br>smaller) instead of the next one.</p>\n<p><span id=\"ValkeyModule_DictCompareC\"></span></p>\n<h3><code>ValkeyModule_DictCompareC</code></h3>\n<pre><code>int ValkeyModule_DictCompareC(ValkeyModuleDictIter *di,\n                              const char *op,\n                              void *key,\n                              size_t keylen);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Compare the element currently pointed by the iterator to the specified<br>element given by key/keylen, according to the operator &#39;op&#39; (the set of<br>valid operators are the same valid for <a href=\"#ValkeyModule_DictIteratorStart\"><code>ValkeyModule_DictIteratorStart</code></a>).<br>If the comparison is successful the command returns <code>VALKEYMODULE_OK</code><br>otherwise <code>VALKEYMODULE_ERR</code> is returned.</p>\n<p>This is useful when we want to just emit a lexicographical range, so<br>in the loop, as we iterate elements, we can also check if we are still<br>on range.</p>\n<p>The function return <code>VALKEYMODULE_ERR</code> if the iterator reached the<br>end of elements condition as well.</p>\n<p><span id=\"ValkeyModule_DictCompare\"></span></p>\n<h3><code>ValkeyModule_DictCompare</code></h3>\n<pre><code>int ValkeyModule_DictCompare(ValkeyModuleDictIter *di,\n                             const char *op,\n                             ValkeyModuleString *key);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Like <a href=\"#ValkeyModule_DictCompareC\"><code>ValkeyModule_DictCompareC</code></a> but gets the key to compare with the current<br>iterator key as a <code>ValkeyModuleString</code>.</p>\n<p><span id=\"section-modules-info-fields\"></span></p>\n<h2>Modules Info fields</h2>\n<p><span id=\"ValkeyModule_InfoAddSection\"></span></p>\n<h3><code>ValkeyModule_InfoAddSection</code></h3>\n<pre><code>int ValkeyModule_InfoAddSection(ValkeyModuleInfoCtx *ctx, const char *name);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Used to start a new section, before adding any fields. the section name will<br>be prefixed by <code>&lt;modulename&gt;_</code> and must only include A-Z,a-z,0-9.<br>NULL or empty string indicates the default section (only <code>&lt;modulename&gt;</code>) is used.<br>When return value is <code>VALKEYMODULE_ERR</code>, the section should and will be skipped.</p>\n<p><span id=\"ValkeyModule_InfoBeginDictField\"></span></p>\n<h3><code>ValkeyModule_InfoBeginDictField</code></h3>\n<pre><code>int ValkeyModule_InfoBeginDictField(ValkeyModuleInfoCtx *ctx,\n                                    const char *name);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Starts a dict field, similar to the ones in INFO KEYSPACE. Use normal<br><code>ValkeyModule_InfoAddField</code>* functions to add the items to this field, and<br>terminate with <a href=\"#ValkeyModule_InfoEndDictField\"><code>ValkeyModule_InfoEndDictField</code></a>.</p>\n<p><span id=\"ValkeyModule_InfoEndDictField\"></span></p>\n<h3><code>ValkeyModule_InfoEndDictField</code></h3>\n<pre><code>int ValkeyModule_InfoEndDictField(ValkeyModuleInfoCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Ends a dict field, see <a href=\"#ValkeyModule_InfoBeginDictField\"><code>ValkeyModule_InfoBeginDictField</code></a></p>\n<p><span id=\"ValkeyModule_InfoAddFieldString\"></span></p>\n<h3><code>ValkeyModule_InfoAddFieldString</code></h3>\n<pre><code>int ValkeyModule_InfoAddFieldString(ValkeyModuleInfoCtx *ctx,\n                                    const char *field,\n                                    ValkeyModuleString *value);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Used by <code>ValkeyModuleInfoFunc</code> to add info fields.<br>Each field will be automatically prefixed by <code>&lt;modulename&gt;_</code>.<br>Field names or values must not include <code>\\r\\n</code> or <code>:</code>.</p>\n<p><span id=\"ValkeyModule_InfoAddFieldCString\"></span></p>\n<h3><code>ValkeyModule_InfoAddFieldCString</code></h3>\n<pre><code>int ValkeyModule_InfoAddFieldCString(ValkeyModuleInfoCtx *ctx,\n                                     const char *field,\n                                     const char *value);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>See <a href=\"#ValkeyModule_InfoAddFieldString\"><code>ValkeyModule_InfoAddFieldString()</code></a>.</p>\n<p><span id=\"ValkeyModule_InfoAddFieldDouble\"></span></p>\n<h3><code>ValkeyModule_InfoAddFieldDouble</code></h3>\n<pre><code>int ValkeyModule_InfoAddFieldDouble(ValkeyModuleInfoCtx *ctx,\n                                    const char *field,\n                                    double value);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>See <a href=\"#ValkeyModule_InfoAddFieldString\"><code>ValkeyModule_InfoAddFieldString()</code></a>.</p>\n<p><span id=\"ValkeyModule_InfoAddFieldLongLong\"></span></p>\n<h3><code>ValkeyModule_InfoAddFieldLongLong</code></h3>\n<pre><code>int ValkeyModule_InfoAddFieldLongLong(ValkeyModuleInfoCtx *ctx,\n                                      const char *field,\n                                      long long value);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>See <a href=\"#ValkeyModule_InfoAddFieldString\"><code>ValkeyModule_InfoAddFieldString()</code></a>.</p>\n<p><span id=\"ValkeyModule_InfoAddFieldULongLong\"></span></p>\n<h3><code>ValkeyModule_InfoAddFieldULongLong</code></h3>\n<pre><code>int ValkeyModule_InfoAddFieldULongLong(ValkeyModuleInfoCtx *ctx,\n                                       const char *field,\n                                       unsigned long long value);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>See <a href=\"#ValkeyModule_InfoAddFieldString\"><code>ValkeyModule_InfoAddFieldString()</code></a>.</p>\n<p><span id=\"ValkeyModule_RegisterInfoFunc\"></span></p>\n<h3><code>ValkeyModule_RegisterInfoFunc</code></h3>\n<pre><code>int ValkeyModule_RegisterInfoFunc(ValkeyModuleCtx *ctx,\n                                  ValkeyModuleInfoFunc cb);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Registers callback for the INFO command. The callback should add INFO fields<br>by calling the <code>ValkeyModule_InfoAddField*()</code> functions.</p>\n<p><span id=\"ValkeyModule_GetServerInfo\"></span></p>\n<h3><code>ValkeyModule_GetServerInfo</code></h3>\n<pre><code>ValkeyModuleServerInfoData *ValkeyModule_GetServerInfo(ValkeyModuleCtx *ctx,\n                                                       const char *section);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Get information about the server similar to the one that returns from the<br>INFO command. This function takes an optional &#39;section&#39; argument that may<br>be NULL. The return value holds the output and can be used with<br><a href=\"#ValkeyModule_ServerInfoGetField\"><code>ValkeyModule_ServerInfoGetField</code></a> and alike to get the individual fields.<br>When done, it needs to be freed with <a href=\"#ValkeyModule_FreeServerInfo\"><code>ValkeyModule_FreeServerInfo</code></a> or with the<br>automatic memory management mechanism if enabled.</p>\n<p><span id=\"ValkeyModule_FreeServerInfo\"></span></p>\n<h3><code>ValkeyModule_FreeServerInfo</code></h3>\n<pre><code>void ValkeyModule_FreeServerInfo(ValkeyModuleCtx *ctx,\n                                 ValkeyModuleServerInfoData *data);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Free data created with <a href=\"#ValkeyModule_GetServerInfo\"><code>ValkeyModule_GetServerInfo()</code></a>. You need to pass the<br>context pointer &#39;ctx&#39; only if the dictionary was created using the<br>context instead of passing NULL.</p>\n<p><span id=\"ValkeyModule_ServerInfoGetField\"></span></p>\n<h3><code>ValkeyModule_ServerInfoGetField</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_ServerInfoGetField(ValkeyModuleCtx *ctx,\n                                                    ValkeyModuleServerInfoData *data,\n                                                    const char *field);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Get the value of a field from data collected with <a href=\"#ValkeyModule_GetServerInfo\"><code>ValkeyModule_GetServerInfo()</code></a>. You<br>need to pass the context pointer &#39;ctx&#39; only if you want to use auto memory<br>mechanism to release the returned string. Return value will be NULL if the<br>field was not found.</p>\n<p><span id=\"ValkeyModule_ServerInfoGetFieldC\"></span></p>\n<h3><code>ValkeyModule_ServerInfoGetFieldC</code></h3>\n<pre><code>const char *ValkeyModule_ServerInfoGetFieldC(ValkeyModuleServerInfoData *data,\n                                             const char *field);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Similar to <a href=\"#ValkeyModule_ServerInfoGetField\"><code>ValkeyModule_ServerInfoGetField</code></a>, but returns a char* which should not be freed but the caller.</p>\n<p><span id=\"ValkeyModule_ServerInfoGetFieldSigned\"></span></p>\n<h3><code>ValkeyModule_ServerInfoGetFieldSigned</code></h3>\n<pre><code>long long ValkeyModule_ServerInfoGetFieldSigned(ValkeyModuleServerInfoData *data,\n                                                const char *field,\n                                                int *out_err);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Get the value of a field from data collected with <a href=\"#ValkeyModule_GetServerInfo\"><code>ValkeyModule_GetServerInfo()</code></a>. If the<br>field is not found, or is not numerical or out of range, return value will be<br>0, and the optional <code>out_err</code> argument will be set to <code>VALKEYMODULE_ERR</code>.</p>\n<p><span id=\"ValkeyModule_ServerInfoGetFieldUnsigned\"></span></p>\n<h3><code>ValkeyModule_ServerInfoGetFieldUnsigned</code></h3>\n<pre><code>unsigned long long ValkeyModule_ServerInfoGetFieldUnsigned(ValkeyModuleServerInfoData *data,\n                                                           const char *field,\n                                                           int *out_err);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Get the value of a field from data collected with <a href=\"#ValkeyModule_GetServerInfo\"><code>ValkeyModule_GetServerInfo()</code></a>. If the<br>field is not found, or is not numerical or out of range, return value will be<br>0, and the optional <code>out_err</code> argument will be set to <code>VALKEYMODULE_ERR</code>.</p>\n<p><span id=\"ValkeyModule_ServerInfoGetFieldDouble\"></span></p>\n<h3><code>ValkeyModule_ServerInfoGetFieldDouble</code></h3>\n<pre><code>double ValkeyModule_ServerInfoGetFieldDouble(ValkeyModuleServerInfoData *data,\n                                             const char *field,\n                                             int *out_err);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Get the value of a field from data collected with <a href=\"#ValkeyModule_GetServerInfo\"><code>ValkeyModule_GetServerInfo()</code></a>. If the<br>field is not found, or is not a double, return value will be 0, and the<br>optional <code>out_err</code> argument will be set to <code>VALKEYMODULE_ERR</code>.</p>\n<p><span id=\"section-modules-utility-apis\"></span></p>\n<h2>Modules utility APIs</h2>\n<p><span id=\"ValkeyModule_GetRandomBytes\"></span></p>\n<h3><code>ValkeyModule_GetRandomBytes</code></h3>\n<pre><code>void ValkeyModule_GetRandomBytes(unsigned char *dst, size_t len);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Return random bytes using SHA1 in counter mode with a /dev/urandom<br>initialized seed. This function is fast so can be used to generate<br>many bytes without any effect on the operating system entropy pool.<br>Currently this function is not thread safe.</p>\n<p><span id=\"ValkeyModule_GetRandomHexChars\"></span></p>\n<h3><code>ValkeyModule_GetRandomHexChars</code></h3>\n<pre><code>void ValkeyModule_GetRandomHexChars(char *dst, size_t len);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.0</p>\n<p>Like <a href=\"#ValkeyModule_GetRandomBytes\"><code>ValkeyModule_GetRandomBytes()</code></a> but instead of setting the string to<br>random bytes the string is set to random characters in the in the<br>hex charset [0-9a-f].</p>\n<p><span id=\"section-modules-api-exporting-importing\"></span></p>\n<h2>Modules API exporting / importing</h2>\n<p><span id=\"ValkeyModule_ExportSharedAPI\"></span></p>\n<h3><code>ValkeyModule_ExportSharedAPI</code></h3>\n<pre><code>int ValkeyModule_ExportSharedAPI(ValkeyModuleCtx *ctx,\n                                 const char *apiname,\n                                 void *func);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.4</p>\n<p>This function is called by a module in order to export some API with a<br>given name. Other modules will be able to use this API by calling the<br>symmetrical function <a href=\"#ValkeyModule_GetSharedAPI\"><code>ValkeyModule_GetSharedAPI()</code></a> and casting the return value to<br>the right function pointer.</p>\n<p>The function will return <code>VALKEYMODULE_OK</code> if the name is not already taken,<br>otherwise <code>VALKEYMODULE_ERR</code> will be returned and no operation will be<br>performed.</p>\n<p>IMPORTANT: the apiname argument should be a string literal with static<br>lifetime. The API relies on the fact that it will always be valid in<br>the future.</p>\n<p><span id=\"ValkeyModule_GetSharedAPI\"></span></p>\n<h3><code>ValkeyModule_GetSharedAPI</code></h3>\n<pre><code>void *ValkeyModule_GetSharedAPI(ValkeyModuleCtx *ctx, const char *apiname);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.4</p>\n<p>Request an exported API pointer. The return value is just a void pointer<br>that the caller of this function will be required to cast to the right<br>function pointer, so this is a private contract between modules.</p>\n<p>If the requested API is not available then NULL is returned. Because<br>modules can be loaded at different times with different order, this<br>function calls should be put inside some module generic API registering<br>step, that is called every time a module attempts to execute a<br>command that requires external APIs: if some API cannot be resolved, the<br>command should return an error.</p>\n<p>Here is an example:</p>\n<pre><code>int ... myCommandImplementation(void) {\n   if (getExternalAPIs() == 0) {\n        reply with an error here if we cannot have the APIs\n   }\n   // Use the API:\n   myFunctionPointer(foo);\n}\n</code></pre>\n<p>And the function registerAPI() is:</p>\n<pre><code>int getExternalAPIs(void) {\n    static int api_loaded = 0;\n    if (api_loaded != 0) return 1; // APIs already resolved.\n\n    myFunctionPointer = ValkeyModule_GetSharedAPI(&quot;...&quot;);\n    if (myFunctionPointer == NULL) return 0;\n\n    return 1;\n}\n</code></pre>\n<p><span id=\"section-module-command-filter-api\"></span></p>\n<h2>Module Command Filter API</h2>\n<p><span id=\"ValkeyModule_RegisterCommandFilter\"></span></p>\n<h3><code>ValkeyModule_RegisterCommandFilter</code></h3>\n<pre><code>ValkeyModuleCommandFilter *ValkeyModule_RegisterCommandFilter(ValkeyModuleCtx *ctx,\n                                                              ValkeyModuleCommandFilterFunc callback,\n                                                              int flags);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.5</p>\n<p>Register a new command filter function.</p>\n<p>Command filtering makes it possible for modules to extend the server by plugging<br>into the execution flow of all commands.</p>\n<p>A registered filter gets called before the server executes <em>any</em> command.  This<br>includes both core server commands and commands registered by any module.  The<br>filter applies in all execution paths including:</p>\n<ol>\n<li>Invocation by a client.</li>\n<li>Invocation through <a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call()</code></a> by any module.</li>\n<li>Invocation through Lua <code>server.call()</code>.</li>\n<li>Replication of a command from a primary.</li>\n</ol>\n<p>The filter executes in a special filter context, which is different and more<br>limited than a <code>ValkeyModuleCtx</code>.  Because the filter affects any command, it<br>must be implemented in a very efficient way to reduce the performance impact<br>on the server.  All Module API calls that require a valid context (such as<br><a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call()</code></a>, <a href=\"#ValkeyModule_OpenKey\"><code>ValkeyModule_OpenKey()</code></a>, etc.) are not supported in a<br>filter context.</p>\n<p>The <code>ValkeyModuleCommandFilterCtx</code> can be used to inspect or modify the<br>executed command and its arguments.  As the filter executes before the server<br>begins processing the command, any change will affect the way the command is<br>processed.  For example, a module can override server commands this way:</p>\n<ol>\n<li>Register a <code>MODULE.SET</code> command which implements an extended version of<br>the <code>SET</code> command.</li>\n<li>Register a command filter which detects invocation of <code>SET</code> on a specific<br>pattern of keys.  Once detected, the filter will replace the first<br>argument from <code>SET</code> to <code>MODULE.SET</code>.</li>\n<li>When filter execution is complete, the server considers the new command name<br>and therefore executes the module&#39;s own command.</li>\n</ol>\n<p>Note that in the above use case, if <code>MODULE.SET</code> itself uses<br><a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call()</code></a> the filter will be applied on that call as well.  If<br>that is not desired, the <code>VALKEYMODULE_CMDFILTER_NOSELF</code> flag can be set when<br>registering the filter.</p>\n<p>The <code>VALKEYMODULE_CMDFILTER_NOSELF</code> flag prevents execution flows that<br>originate from the module&#39;s own <a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call()</code></a> from reaching the filter.  This<br>flag is effective for all execution flows, including nested ones, as long as<br>the execution begins from the module&#39;s command context or a thread-safe<br>context that is associated with a blocking command.</p>\n<p>Detached thread-safe contexts are <em>not</em> associated with the module and cannot<br>be protected by this flag.</p>\n<p>If multiple filters are registered (by the same or different modules), they<br>are executed in the order of registration.</p>\n<p><span id=\"ValkeyModule_UnregisterCommandFilter\"></span></p>\n<h3><code>ValkeyModule_UnregisterCommandFilter</code></h3>\n<pre><code>int ValkeyModule_UnregisterCommandFilter(ValkeyModuleCtx *ctx,\n                                         ValkeyModuleCommandFilter *filter);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.5</p>\n<p>Unregister a command filter.</p>\n<p><span id=\"ValkeyModule_CommandFilterArgsCount\"></span></p>\n<h3><code>ValkeyModule_CommandFilterArgsCount</code></h3>\n<pre><code>int ValkeyModule_CommandFilterArgsCount(ValkeyModuleCommandFilterCtx *fctx);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.5</p>\n<p>Return the number of arguments a filtered command has.  The number of<br>arguments include the command itself.</p>\n<p><span id=\"ValkeyModule_CommandFilterArgGet\"></span></p>\n<h3><code>ValkeyModule_CommandFilterArgGet</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_CommandFilterArgGet(ValkeyModuleCommandFilterCtx *fctx,\n                                                     int pos);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.5</p>\n<p>Return the specified command argument.  The first argument (position 0) is<br>the command itself, and the rest are user-provided args.</p>\n<p><span id=\"ValkeyModule_CommandFilterArgInsert\"></span></p>\n<h3><code>ValkeyModule_CommandFilterArgInsert</code></h3>\n<pre><code>int ValkeyModule_CommandFilterArgInsert(ValkeyModuleCommandFilterCtx *fctx,\n                                        int pos,\n                                        ValkeyModuleString *arg);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.5</p>\n<p>Modify the filtered command by inserting a new argument at the specified<br>position.  The specified <code>ValkeyModuleString</code> argument may be used by the server<br>after the filter context is destroyed, so it must not be auto-memory<br>allocated, freed or used elsewhere.</p>\n<p><span id=\"ValkeyModule_CommandFilterArgReplace\"></span></p>\n<h3><code>ValkeyModule_CommandFilterArgReplace</code></h3>\n<pre><code>int ValkeyModule_CommandFilterArgReplace(ValkeyModuleCommandFilterCtx *fctx,\n                                         int pos,\n                                         ValkeyModuleString *arg);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.5</p>\n<p>Modify the filtered command by replacing an existing argument with a new one.<br>The specified <code>ValkeyModuleString</code> argument may be used by the server after the<br>filter context is destroyed, so it must not be auto-memory allocated, freed<br>or used elsewhere.</p>\n<p><span id=\"ValkeyModule_CommandFilterArgDelete\"></span></p>\n<h3><code>ValkeyModule_CommandFilterArgDelete</code></h3>\n<pre><code>int ValkeyModule_CommandFilterArgDelete(ValkeyModuleCommandFilterCtx *fctx,\n                                        int pos);\n</code></pre>\n<p><strong>Available since:</strong> 5.0.5</p>\n<p>Modify the filtered command by deleting an argument at the specified<br>position.</p>\n<p><span id=\"ValkeyModule_CommandFilterGetClientId\"></span></p>\n<h3><code>ValkeyModule_CommandFilterGetClientId</code></h3>\n<pre><code>unsigned long long ValkeyModule_CommandFilterGetClientId(ValkeyModuleCommandFilterCtx *fctx);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Get Client ID for client that issued the command we are filtering</p>\n<p><span id=\"ValkeyModule_MallocSize\"></span></p>\n<h3><code>ValkeyModule_MallocSize</code></h3>\n<pre><code>size_t ValkeyModule_MallocSize(void *ptr);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>For a given pointer allocated via <a href=\"#ValkeyModule_Alloc\"><code>ValkeyModule_Alloc()</code></a> or<br><a href=\"#ValkeyModule_Realloc\"><code>ValkeyModule_Realloc()</code></a>, return the amount of memory allocated for it.<br>Note that this may be different (larger) than the memory we allocated<br>with the allocation calls, since sometimes the underlying allocator<br>will allocate more memory.</p>\n<p><span id=\"ValkeyModule_MallocUsableSize\"></span></p>\n<h3><code>ValkeyModule_MallocUsableSize</code></h3>\n<pre><code>size_t ValkeyModule_MallocUsableSize(void *ptr);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.1</p>\n<p>Similar to <a href=\"#ValkeyModule_MallocSize\"><code>ValkeyModule_MallocSize</code></a>, the difference is that <a href=\"#ValkeyModule_MallocUsableSize\"><code>ValkeyModule_MallocUsableSize</code></a><br>returns the usable size of memory by the module.</p>\n<p><span id=\"ValkeyModule_MallocSizeString\"></span></p>\n<h3><code>ValkeyModule_MallocSizeString</code></h3>\n<pre><code>size_t ValkeyModule_MallocSizeString(ValkeyModuleString *str);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Same as <a href=\"#ValkeyModule_MallocSize\"><code>ValkeyModule_MallocSize</code></a>, except it works on <code>ValkeyModuleString</code> pointers.</p>\n<p><span id=\"ValkeyModule_MallocSizeDict\"></span></p>\n<h3><code>ValkeyModule_MallocSizeDict</code></h3>\n<pre><code>size_t ValkeyModule_MallocSizeDict(ValkeyModuleDict *dict);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Same as <a href=\"#ValkeyModule_MallocSize\"><code>ValkeyModule_MallocSize</code></a>, except it works on <code>ValkeyModuleDict</code> pointers.<br>Note that the returned value is only the overhead of the underlying structures,<br>it does not include the allocation size of the keys and values.</p>\n<p><span id=\"ValkeyModule_GetUsedMemoryRatio\"></span></p>\n<h3><code>ValkeyModule_GetUsedMemoryRatio</code></h3>\n<pre><code>float ValkeyModule_GetUsedMemoryRatio(void);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Return the a number between 0 to 1 indicating the amount of memory<br>currently used, relative to the server &quot;maxmemory&quot; configuration.</p>\n<ul>\n<li>0 - No memory limit configured.</li>\n<li>Between 0 and 1 - The percentage of the memory used normalized in 0-1 range.</li>\n<li>Exactly 1 - Memory limit reached.</li>\n<li>Greater 1 - More memory used than the configured limit.</li>\n</ul>\n<p><span id=\"section-scanning-keyspace-and-hashes\"></span></p>\n<h2>Scanning keyspace and hashes</h2>\n<p><span id=\"ValkeyModule_ScanCursorCreate\"></span></p>\n<h3><code>ValkeyModule_ScanCursorCreate</code></h3>\n<pre><code>ValkeyModuleScanCursor *ValkeyModule_ScanCursorCreate(void);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Create a new cursor to be used with <a href=\"#ValkeyModule_Scan\"><code>ValkeyModule_Scan</code></a></p>\n<p><span id=\"ValkeyModule_ScanCursorRestart\"></span></p>\n<h3><code>ValkeyModule_ScanCursorRestart</code></h3>\n<pre><code>void ValkeyModule_ScanCursorRestart(ValkeyModuleScanCursor *cursor);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Restart an existing cursor. The keys will be rescanned.</p>\n<p><span id=\"ValkeyModule_ScanCursorDestroy\"></span></p>\n<h3><code>ValkeyModule_ScanCursorDestroy</code></h3>\n<pre><code>void ValkeyModule_ScanCursorDestroy(ValkeyModuleScanCursor *cursor);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Destroy the cursor struct.</p>\n<p><span id=\"ValkeyModule_Scan\"></span></p>\n<h3><code>ValkeyModule_Scan</code></h3>\n<pre><code>int ValkeyModule_Scan(ValkeyModuleCtx *ctx,\n                      ValkeyModuleScanCursor *cursor,\n                      ValkeyModuleScanCB fn,\n                      void *privdata);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Scan API that allows a module to scan all the keys and value in<br>the selected db.</p>\n<p>Callback for scan implementation.</p>\n<pre><code>void scan_callback(ValkeyModuleCtx *ctx, ValkeyModuleString *keyname,\n                   ValkeyModuleKey *key, void *privdata);\n</code></pre>\n<ul>\n<li><code>ctx</code>: the module context provided to for the scan.</li>\n<li><code>keyname</code>: owned by the caller and need to be retained if used after this<br>function.</li>\n<li><code>key</code>: holds info on the key and value, it is provided as best effort, in<br>some cases it might be NULL, in which case the user should (can) use<br><a href=\"#ValkeyModule_OpenKey\"><code>ValkeyModule_OpenKey()</code></a> (and CloseKey too).<br>when it is provided, it is owned by the caller and will be free when the<br>callback returns.</li>\n<li><code>privdata</code>: the user data provided to <a href=\"#ValkeyModule_Scan\"><code>ValkeyModule_Scan()</code></a>.</li>\n</ul>\n<p>The way it should be used:</p>\n<pre><code> ValkeyModuleScanCursor *c = ValkeyModule_ScanCursorCreate();\n while(ValkeyModule_Scan(ctx, c, callback, privateData));\n ValkeyModule_ScanCursorDestroy(c);\n</code></pre>\n<p>It is also possible to use this API from another thread while the lock<br>is acquired during the actual call to <a href=\"#ValkeyModule_Scan\"><code>ValkeyModule_Scan</code></a>:</p>\n<pre><code> ValkeyModuleScanCursor *c = ValkeyModule_ScanCursorCreate();\n ValkeyModule_ThreadSafeContextLock(ctx);\n while(ValkeyModule_Scan(ctx, c, callback, privateData)){\n     ValkeyModule_ThreadSafeContextUnlock(ctx);\n     // do some background job\n     ValkeyModule_ThreadSafeContextLock(ctx);\n }\n ValkeyModule_ScanCursorDestroy(c);\n</code></pre>\n<p>The function will return 1 if there are more elements to scan and<br>0 otherwise, possibly setting errno if the call failed.</p>\n<p>It is also possible to restart an existing cursor using <a href=\"#ValkeyModule_ScanCursorRestart\"><code>ValkeyModule_ScanCursorRestart</code></a>.</p>\n<p>IMPORTANT: This API is very similar to the SCAN command from the<br>point of view of the guarantees it provides. This means that the API<br>may report duplicated keys, but guarantees to report at least one time<br>every key that was there from the start to the end of the scanning process.</p>\n<p>NOTE: If you do database changes within the callback, you should be aware<br>that the internal state of the database may change. For instance it is safe<br>to delete or modify the current key, but may not be safe to delete any<br>other key.<br>Moreover playing with the keyspace while iterating may have the<br>effect of returning more duplicates. A safe pattern is to store the keys<br>names you want to modify elsewhere, and perform the actions on the keys<br>later when the iteration is complete. However this can cost a lot of<br>memory, so it may make sense to just operate on the current key when<br>possible during the iteration, given that this is safe.</p>\n<p><span id=\"ValkeyModule_ScanKey\"></span></p>\n<h3><code>ValkeyModule_ScanKey</code></h3>\n<pre><code>int ValkeyModule_ScanKey(ValkeyModuleKey *key,\n                         ValkeyModuleScanCursor *cursor,\n                         ValkeyModuleScanKeyCB fn,\n                         void *privdata);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Scan api that allows a module to scan the elements in a hash, set or sorted set key</p>\n<p>Callback for scan implementation.</p>\n<pre><code>void scan_callback(ValkeyModuleKey *key, ValkeyModuleString* field, ValkeyModuleString* value, void *privdata);\n</code></pre>\n<ul>\n<li>key - the key context provided to for the scan.</li>\n<li>field - field name, owned by the caller and need to be retained if used<br>after this function.</li>\n<li>value - value string or NULL for set type, owned by the caller and need to<br>be retained if used after this function.</li>\n<li>privdata - the user data provided to <a href=\"#ValkeyModule_ScanKey\"><code>ValkeyModule_ScanKey</code></a>.</li>\n</ul>\n<p>The way it should be used:</p>\n<pre><code> ValkeyModuleScanCursor *c = ValkeyModule_ScanCursorCreate();\n ValkeyModuleKey *key = ValkeyModule_OpenKey(...)\n while(ValkeyModule_ScanKey(key, c, callback, privateData));\n ValkeyModule_CloseKey(key);\n ValkeyModule_ScanCursorDestroy(c);\n</code></pre>\n<p>It is also possible to use this API from another thread while the lock is acquired during<br>the actual call to <a href=\"#ValkeyModule_ScanKey\"><code>ValkeyModule_ScanKey</code></a>, and re-opening the key each time:</p>\n<pre><code> ValkeyModuleScanCursor *c = ValkeyModule_ScanCursorCreate();\n ValkeyModule_ThreadSafeContextLock(ctx);\n ValkeyModuleKey *key = ValkeyModule_OpenKey(...)\n while(ValkeyModule_ScanKey(ctx, c, callback, privateData)){\n     ValkeyModule_CloseKey(key);\n     ValkeyModule_ThreadSafeContextUnlock(ctx);\n     // do some background job\n     ValkeyModule_ThreadSafeContextLock(ctx);\n     ValkeyModuleKey *key = ValkeyModule_OpenKey(...)\n }\n ValkeyModule_CloseKey(key);\n ValkeyModule_ScanCursorDestroy(c);\n</code></pre>\n<p>The function will return 1 if there are more elements to scan and 0 otherwise,<br>possibly setting errno if the call failed.<br>It is also possible to restart an existing cursor using <a href=\"#ValkeyModule_ScanCursorRestart\"><code>ValkeyModule_ScanCursorRestart</code></a>.</p>\n<p>NOTE: Certain operations are unsafe while iterating the object. For instance<br>while the API guarantees to return at least one time all the elements that<br>are present in the data structure consistently from the start to the end<br>of the iteration (see HSCAN and similar commands documentation), the more<br>you play with the elements, the more duplicates you may get. In general<br>deleting the current element of the data structure is safe, while removing<br>the key you are iterating is not safe.</p>\n<p><span id=\"section-module-fork-api\"></span></p>\n<h2>Module fork API</h2>\n<p><span id=\"ValkeyModule_Fork\"></span></p>\n<h3><code>ValkeyModule_Fork</code></h3>\n<pre><code>int ValkeyModule_Fork(ValkeyModuleForkDoneHandler cb, void *user_data);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Create a background child process with the current frozen snapshot of the<br>main process where you can do some processing in the background without<br>affecting / freezing the traffic and no need for threads and GIL locking.<br>Note that the server allows for only one concurrent fork.<br>When the child wants to exit, it should call <a href=\"#ValkeyModule_ExitFromChild\"><code>ValkeyModule_ExitFromChild</code></a>.<br>If the parent wants to kill the child it should call <a href=\"#ValkeyModule_KillForkChild\"><code>ValkeyModule_KillForkChild</code></a><br>The done handler callback will be executed on the parent process when the<br>child existed (but not when killed)<br>Return: -1 on failure, on success the parent process will get a positive PID<br>of the child, and the child process will get 0.</p>\n<p><span id=\"ValkeyModule_SendChildHeartbeat\"></span></p>\n<h3><code>ValkeyModule_SendChildHeartbeat</code></h3>\n<pre><code>void ValkeyModule_SendChildHeartbeat(double progress);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>The module is advised to call this function from the fork child once in a while,<br>so that it can report progress and COW memory to the parent which will be<br>reported in INFO.<br>The <code>progress</code> argument should between 0 and 1, or -1 when not available.</p>\n<p><span id=\"ValkeyModule_ExitFromChild\"></span></p>\n<h3><code>ValkeyModule_ExitFromChild</code></h3>\n<pre><code>int ValkeyModule_ExitFromChild(int retcode);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Call from the child process when you want to terminate it.<br>retcode will be provided to the done handler executed on the parent process.</p>\n<p><span id=\"ValkeyModule_KillForkChild\"></span></p>\n<h3><code>ValkeyModule_KillForkChild</code></h3>\n<pre><code>int ValkeyModule_KillForkChild(int child_pid);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Can be used to kill the forked child process from the parent process.<br><code>child_pid</code> would be the return value of <a href=\"#ValkeyModule_Fork\"><code>ValkeyModule_Fork</code></a>.</p>\n<p><span id=\"section-server-hooks-implementation\"></span></p>\n<h2>Server hooks implementation</h2>\n<p><span id=\"ValkeyModule_SubscribeToServerEvent\"></span></p>\n<h3><code>ValkeyModule_SubscribeToServerEvent</code></h3>\n<pre><code>int ValkeyModule_SubscribeToServerEvent(ValkeyModuleCtx *ctx,\n                                        ValkeyModuleEvent event,\n                                        ValkeyModuleEventCallback callback);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Register to be notified, via a callback, when the specified server event<br>happens. The callback is called with the event as argument, and an additional<br>argument which is a void pointer and should be cased to a specific type<br>that is event-specific (but many events will just use NULL since they do not<br>have additional information to pass to the callback).</p>\n<p>If the callback is NULL and there was a previous subscription, the module<br>will be unsubscribed. If there was a previous subscription and the callback<br>is not null, the old callback will be replaced with the new one.</p>\n<p>The callback must be of this type:</p>\n<pre><code>int (*ValkeyModuleEventCallback)(ValkeyModuleCtx *ctx,\n                                ValkeyModuleEvent eid,\n                                uint64_t subevent,\n                                void *data);\n</code></pre>\n<p>The &#39;ctx&#39; is a normal module context that the callback can use in<br>order to call other modules APIs. The &#39;eid&#39; is the event itself, this<br>is only useful in the case the module subscribed to multiple events: using<br>the &#39;id&#39; field of this structure it is possible to check if the event<br>is one of the events we registered with this callback. The &#39;subevent&#39; field<br>depends on the event that fired.</p>\n<p>Finally the &#39;data&#39; pointer may be populated, only for certain events, with<br>more relevant data.</p>\n<p>Here is a list of events you can use as &#39;eid&#39; and related sub events:</p>\n<ul>\n<li><p><code>ValkeyModuleEvent_ReplicationRoleChanged</code>:</p>\n<p>  This event is called when the instance switches from primary<br>  to replica or the other way around, however the event is<br>  also called when the replica remains a replica but starts to<br>  replicate with a different primary.</p>\n<p>  The following sub events are available:</p>\n<ul>\n<li><code>VALKEYMODULE_SUBEVENT_REPLROLECHANGED_NOW_PRIMARY</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_REPLROLECHANGED_NOW_REPLICA</code></li>\n</ul>\n<p>  The &#39;data&#39; field can be casted by the callback to a<br>  <code>ValkeyModuleReplicationInfo</code> structure with the following fields:</p>\n<pre><code>  int primary; // true if primary, false if replica\n  char *primary_host; // primary instance hostname for NOW_REPLICA\n  int primary_port; // primary instance port for NOW_REPLICA\n  char *replid1; // Main replication ID\n  char *replid2; // Secondary replication ID\n  uint64_t repl1_offset; // Main replication offset\n  uint64_t repl2_offset; // Offset of replid2 validity\n</code></pre>\n</li>\n<li><p><code>ValkeyModuleEvent_Persistence</code></p>\n<p>  This event is called when RDB saving or AOF rewriting starts<br>  and ends. The following sub events are available:</p>\n<ul>\n<li><code>VALKEYMODULE_SUBEVENT_PERSISTENCE_RDB_START</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_PERSISTENCE_AOF_START</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_PERSISTENCE_SYNC_RDB_START</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_PERSISTENCE_SYNC_AOF_START</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_PERSISTENCE_ENDED</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_PERSISTENCE_FAILED</code></li>\n</ul>\n<p>  The above events are triggered not just when the user calls the<br>  relevant commands like BGSAVE, but also when a saving operation<br>  or AOF rewriting occurs because of internal server triggers.<br>  The SYNC_RDB_START sub events are happening in the foreground due to<br>  SAVE command, FLUSHALL, or server shutdown, and the other RDB and<br>  AOF sub events are executed in a background fork child, so any<br>  action the module takes can only affect the generated AOF or RDB,<br>  but will not be reflected in the parent process and affect connected<br>  clients and commands. Also note that the AOF_START sub event may end<br>  up saving RDB content in case of an AOF with rdb-preamble.</p>\n</li>\n<li><p><code>ValkeyModuleEvent_FlushDB</code></p>\n<p>  The FLUSHALL, FLUSHDB or an internal flush (for instance<br>  because of replication, after the replica synchronization)<br>  happened. The following sub events are available:</p>\n<ul>\n<li><code>VALKEYMODULE_SUBEVENT_FLUSHDB_START</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_FLUSHDB_END</code></li>\n</ul>\n<p>  The data pointer can be casted to a ValkeyModuleFlushInfo<br>  structure with the following fields:</p>\n<pre><code>  int32_t async;  // True if the flush is done in a thread.\n                  // See for instance FLUSHALL ASYNC.\n                  // In this case the END callback is invoked\n                  // immediately after the database is put\n                  // in the free list of the thread.\n  int32_t dbnum;  // Flushed database number, -1 for all the DBs\n                  // in the case of the FLUSHALL operation.\n</code></pre>\n<p>  The start event is called <em>before</em> the operation is initiated, thus<br>  allowing the callback to call DBSIZE or other operation on the<br>  yet-to-free keyspace.</p>\n</li>\n<li><p><code>ValkeyModuleEvent_Loading</code></p>\n<p>  Called on loading operations: at startup when the server is<br>  started, but also after a first synchronization when the<br>  replica is loading the RDB file from the primary.<br>  The following sub events are available:</p>\n<ul>\n<li><code>VALKEYMODULE_SUBEVENT_LOADING_RDB_START</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_LOADING_AOF_START</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_LOADING_REPL_START</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_LOADING_ENDED</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_LOADING_FAILED</code></li>\n</ul>\n<p>  Note that AOF loading may start with an RDB data in case of<br>  rdb-preamble, in which case you&#39;ll only receive an AOF_START event.</p>\n</li>\n<li><p><code>ValkeyModuleEvent_ClientChange</code></p>\n<p>  Called when a client connects or disconnects.<br>  The data pointer can be casted to a ValkeyModuleClientInfo<br>  structure, documented in ValkeyModule_GetClientInfoById().<br>  The following sub events are available:</p>\n<ul>\n<li><code>VALKEYMODULE_SUBEVENT_CLIENT_CHANGE_CONNECTED</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_CLIENT_CHANGE_DISCONNECTED</code></li>\n</ul>\n</li>\n<li><p><code>ValkeyModuleEvent_Shutdown</code></p>\n<p>  The server is shutting down. No subevents are available.</p>\n</li>\n<li><p><code>ValkeyModuleEvent_ReplicaChange</code></p>\n<p>  This event is called when the instance (that can be both a<br>  primary or a replica) get a new online replica, or lose a<br>  replica since it gets disconnected.<br>  The following sub events are available:</p>\n<ul>\n<li><code>VALKEYMODULE_SUBEVENT_REPLICA_CHANGE_ONLINE</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_REPLICA_CHANGE_OFFLINE</code></li>\n</ul>\n<p>  No additional information is available so far: future versions<br>  of the server will have an API in order to enumerate the replicas<br>  connected and their state.</p>\n</li>\n<li><p><code>ValkeyModuleEvent_CronLoop</code></p>\n<p>  This event is called every time the server calls the serverCron()<br>  function in order to do certain bookkeeping. Modules that are<br>  required to do operations from time to time may use this callback.<br>  Normally the server calls this function 10 times per second, but<br>  this changes depending on the &quot;hz&quot; configuration.<br>  No sub events are available.</p>\n<p>  The data pointer can be casted to a ValkeyModuleCronLoop<br>  structure with the following fields:</p>\n<pre><code>  int32_t hz;  // Approximate number of events per second.\n</code></pre>\n</li>\n<li><p><code>ValkeyModuleEvent_PrimaryLinkChange</code></p>\n<p>  This is called for replicas in order to notify when the<br>  replication link becomes functional (up) with our primary,<br>  or when it goes down. Note that the link is not considered<br>  up when we just connected to the primary, but only if the<br>  replication is happening correctly.<br>  The following sub events are available:</p>\n<ul>\n<li><code>VALKEYMODULE_SUBEVENT_PRIMARY_LINK_UP</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_PRIMARY_LINK_DOWN</code></li>\n</ul>\n</li>\n<li><p><code>ValkeyModuleEvent_ModuleChange</code></p>\n<p>  This event is called when a new module is loaded or one is unloaded.<br>  The following sub events are available:</p>\n<ul>\n<li><code>VALKEYMODULE_SUBEVENT_MODULE_LOADED</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_MODULE_UNLOADED</code></li>\n</ul>\n<p>  The data pointer can be casted to a ValkeyModuleModuleChange<br>  structure with the following fields:</p>\n<pre><code>  const char* module_name;  // Name of module loaded or unloaded.\n  int32_t module_version;  // Module version.\n</code></pre>\n</li>\n<li><p><code>ValkeyModuleEvent_LoadingProgress</code></p>\n<p>  This event is called repeatedly called while an RDB or AOF file<br>  is being loaded.<br>  The following sub events are available:</p>\n<ul>\n<li><code>VALKEYMODULE_SUBEVENT_LOADING_PROGRESS_RDB</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_LOADING_PROGRESS_AOF</code></li>\n</ul>\n<p>  The data pointer can be casted to a ValkeyModuleLoadingProgress<br>  structure with the following fields:</p>\n<pre><code>  int32_t hz;  // Approximate number of events per second.\n  int32_t progress;  // Approximate progress between 0 and 1024,\n                     // or -1 if unknown.\n</code></pre>\n</li>\n<li><p><code>ValkeyModuleEvent_SwapDB</code></p>\n<p>  This event is called when a SWAPDB command has been successfully<br>  Executed.<br>  For this event call currently there is no subevents available.</p>\n<p>  The data pointer can be casted to a ValkeyModuleSwapDbInfo<br>  structure with the following fields:</p>\n<pre><code>  int32_t dbnum_first;    // Swap Db first dbnum\n  int32_t dbnum_second;   // Swap Db second dbnum\n</code></pre>\n</li>\n<li><p><code>ValkeyModuleEvent_ReplBackup</code></p>\n<p>  WARNING: Replication Backup events are deprecated since Redis OSS 7.0 and are never fired.<br>  See ValkeyModuleEvent_ReplAsyncLoad for understanding how Async Replication Loading events<br>  are now triggered when repl-diskless-load is set to swapdb.</p>\n<p>  Called when repl-diskless-load config is set to swapdb,<br>  And the server needs to backup the current database for the<br>  possibility to be restored later. A module with global data and<br>  maybe with aux_load and aux_save callbacks may need to use this<br>  notification to backup / restore / discard its globals.<br>  The following sub events are available:</p>\n<ul>\n<li><code>VALKEYMODULE_SUBEVENT_REPL_BACKUP_CREATE</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_REPL_BACKUP_RESTORE</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_REPL_BACKUP_DISCARD</code></li>\n</ul>\n</li>\n<li><p><code>ValkeyModuleEvent_ReplAsyncLoad</code></p>\n<p>  Called when repl-diskless-load config is set to swapdb and a replication with a primary of same<br>  data set history (matching replication ID) occurs.<br>  In which case the server serves current data set while loading new database in memory from socket.<br>  Modules must have declared they support this mechanism in order to activate it, through<br>  VALKEYMODULE_OPTIONS_HANDLE_REPL_ASYNC_LOAD flag.<br>  The following sub events are available:</p>\n<ul>\n<li><code>VALKEYMODULE_SUBEVENT_REPL_ASYNC_LOAD_STARTED</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_REPL_ASYNC_LOAD_ABORTED</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_REPL_ASYNC_LOAD_COMPLETED</code></li>\n</ul>\n</li>\n<li><p><code>ValkeyModuleEvent_ForkChild</code></p>\n<p>  Called when a fork child (AOFRW, RDBSAVE, module fork...) is born/dies<br>  The following sub events are available:</p>\n<ul>\n<li><code>VALKEYMODULE_SUBEVENT_FORK_CHILD_BORN</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_FORK_CHILD_DIED</code></li>\n</ul>\n</li>\n<li><p><code>ValkeyModuleEvent_EventLoop</code></p>\n<p>  Called on each event loop iteration, once just before the event loop goes<br>  to sleep or just after it wakes up.<br>  The following sub events are available:</p>\n<ul>\n<li><code>VALKEYMODULE_SUBEVENT_EVENTLOOP_BEFORE_SLEEP</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_EVENTLOOP_AFTER_SLEEP</code></li>\n</ul>\n</li>\n<li><p><code>ValkeyModule_Event_Config</code></p>\n<p>  Called when a configuration event happens<br>  The following sub events are available:</p>\n<ul>\n<li><code>VALKEYMODULE_SUBEVENT_CONFIG_CHANGE</code></li>\n</ul>\n<p>  The data pointer can be casted to a ValkeyModuleConfigChange<br>  structure with the following fields:</p>\n<pre><code>  const char **config_names; // An array of C string pointers containing the\n                             // name of each modified configuration item\n  uint32_t num_changes;      // The number of elements in the config_names array\n</code></pre>\n</li>\n<li><p><code>ValkeyModule_Event_Key</code></p>\n<p>  Called when a key is removed from the keyspace. We can&#39;t modify any key in<br>  the event.<br>  The following sub events are available:</p>\n<ul>\n<li><code>VALKEYMODULE_SUBEVENT_KEY_DELETED</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_KEY_EXPIRED</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_KEY_EVICTED</code></li>\n<li><code>VALKEYMODULE_SUBEVENT_KEY_OVERWRITTEN</code></li>\n</ul>\n<p>  The data pointer can be casted to a ValkeyModuleKeyInfo<br>  structure with the following fields:</p>\n<pre><code>  ValkeyModuleKey *key;    // Key name\n</code></pre>\n</li>\n</ul>\n<p>The function returns <code>VALKEYMODULE_OK</code> if the module was successfully subscribed<br>for the specified event. If the API is called from a wrong context or unsupported event<br>is given then <code>VALKEYMODULE_ERR</code> is returned.</p>\n<p><span id=\"ValkeyModule_IsSubEventSupported\"></span></p>\n<h3><code>ValkeyModule_IsSubEventSupported</code></h3>\n<pre><code>int ValkeyModule_IsSubEventSupported(ValkeyModuleEvent event,\n                                     int64_t subevent);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.9</p>\n<p>For a given server event and subevent, return zero if the<br>subevent is not supported and non-zero otherwise.</p>\n<p><span id=\"section-module-configurations-api\"></span></p>\n<h2>Module Configurations API</h2>\n<p><span id=\"ValkeyModule_RegisterStringConfig\"></span></p>\n<h3><code>ValkeyModule_RegisterStringConfig</code></h3>\n<pre><code>int ValkeyModule_RegisterStringConfig(ValkeyModuleCtx *ctx,\n                                      const char *name,\n                                      const char *default_val,\n                                      unsigned int flags,\n                                      ValkeyModuleConfigGetStringFunc getfn,\n                                      ValkeyModuleConfigSetStringFunc setfn,\n                                      ValkeyModuleConfigApplyFunc applyfn,\n                                      void *privdata);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Create a string config that users can interact with via the server config file,<br><code>CONFIG SET</code>, <code>CONFIG GET</code>, and <code>CONFIG REWRITE</code> commands.</p>\n<p>The actual config value is owned by the module, and the <code>getfn</code>, <code>setfn</code> and optional<br><code>applyfn</code> callbacks that are provided to the server in order to access or manipulate the<br>value. The <code>getfn</code> callback retrieves the value from the module, while the <code>setfn</code><br>callback provides a value to be stored into the module config.<br>The optional <code>applyfn</code> callback is called after a <code>CONFIG SET</code> command modified one or<br>more configs using the <code>setfn</code> callback and can be used to atomically apply a config<br>after several configs were changed together.<br>If there are multiple configs with <code>applyfn</code> callbacks set by a single <code>CONFIG SET</code><br>command, they will be deduplicated if their <code>applyfn</code> function and <code>privdata</code> pointers<br>are identical, and the callback will only be run once.<br>Both the <code>setfn</code> and <code>applyfn</code> can return an error if the provided value is invalid or<br>cannot be used.<br>The config also declares a type for the value that is validated by the server and<br>provided to the module. The config system provides the following types:</p>\n<ul>\n<li>String: Binary safe string data.</li>\n<li>Enum: One of a finite number of string tokens, provided during registration.</li>\n<li>Numeric: 64 bit signed integer, which also supports min and max values.</li>\n<li>Bool: Yes or no value.</li>\n</ul>\n<p>The <code>setfn</code> callback is expected to return <code>VALKEYMODULE_OK</code> when the value is successfully<br>applied. It can also return <code>VALKEYMODULE_ERR</code> if the value can&#39;t be applied, and the<br>*err pointer can be set with a <code>ValkeyModuleString</code> error message to provide to the client.<br>This <code>ValkeyModuleString</code> will be freed by the server after returning from the set callback.</p>\n<p>All configs are registered with a name, a type, a default value, private data that is made<br>available in the callbacks, as well as several flags that modify the behavior of the config.<br>The name must only contain alphanumeric characters or dashes. The supported flags are:</p>\n<ul>\n<li><code>VALKEYMODULE_CONFIG_DEFAULT</code>: The default flags for a config. This creates a config that can be modified after<br>startup.</li>\n<li><code>VALKEYMODULE_CONFIG_IMMUTABLE</code>: This config can only be provided loading time.</li>\n<li><code>VALKEYMODULE_CONFIG_SENSITIVE</code>: The value stored in this config is redacted from all logging.</li>\n<li><code>VALKEYMODULE_CONFIG_HIDDEN</code>: The name is hidden from <code>CONFIG GET</code> with pattern matching.</li>\n<li><code>VALKEYMODULE_CONFIG_PROTECTED</code>: This config will be only be modifiable based off the value of<br>enable-protected-configs.</li>\n<li><code>VALKEYMODULE_CONFIG_DENY_LOADING</code>: This config is not modifiable while the server is loading data.</li>\n<li><code>VALKEYMODULE_CONFIG_MEMORY</code>: For numeric configs, this config will convert data unit notations into their byte<br>equivalent.</li>\n<li><code>VALKEYMODULE_CONFIG_BITFLAGS</code>: For enum configs, this config will allow multiple entries to be combined as bit<br>flags.</li>\n</ul>\n<p>Default values are used on startup to set the value if it is not provided via the config file<br>or command line. Default values are also used to compare to on a config rewrite.</p>\n<p>Notes:</p>\n<ol>\n<li>On string config sets that the string passed to the set callback will be freed after execution and the module<br>must retain it.</li>\n<li>On string config gets the string will not be consumed and will be valid after execution.</li>\n</ol>\n<p>Example implementation:</p>\n<pre><code>ValkeyModuleString *strval;\nint adjustable = 1;\nValkeyModuleString *getStringConfigCommand(const char *name, void *privdata) {\n    return strval;\n}\n\nint setStringConfigCommand(const char *name, ValkeyModuleString *new, void *privdata, ValkeyModuleString **err) {\n   if (adjustable) {\n       ValkeyModule_Free(strval);\n       ValkeyModule_RetainString(NULL, new);\n       strval = new;\n       return VALKEYMODULE_OK;\n   }\n   *err = ValkeyModule_CreateString(NULL, &quot;Not adjustable.&quot;, 15);\n   return VALKEYMODULE_ERR;\n}\n...\nValkeyModule_RegisterStringConfig(ctx, &quot;string&quot;, NULL, VALKEYMODULE_CONFIG_DEFAULT, getStringConfigCommand,\n</code></pre>\n<p>setStringConfigCommand, NULL, NULL);</p>\n<p>If the registration fails, <code>VALKEYMODULE_ERR</code> is returned and one of the following<br>errno is set:</p>\n<ul>\n<li>EBUSY: Registering the Config outside of <code>ValkeyModule_OnLoad</code>.</li>\n<li>EINVAL: The provided flags are invalid for the registration or the name of the config contains invalid characters.</li>\n<li>EALREADY: The provided configuration name is already used.</li>\n</ul>\n<p><span id=\"ValkeyModule_RegisterBoolConfig\"></span></p>\n<h3><code>ValkeyModule_RegisterBoolConfig</code></h3>\n<pre><code>int ValkeyModule_RegisterBoolConfig(ValkeyModuleCtx *ctx,\n                                    const char *name,\n                                    int default_val,\n                                    unsigned int flags,\n                                    ValkeyModuleConfigGetBoolFunc getfn,\n                                    ValkeyModuleConfigSetBoolFunc setfn,\n                                    ValkeyModuleConfigApplyFunc applyfn,\n                                    void *privdata);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Create a bool config that server clients can interact with via the<br><code>CONFIG SET</code>, <code>CONFIG GET</code>, and <code>CONFIG REWRITE</code> commands. See<br><a href=\"#ValkeyModule_RegisterStringConfig\"><code>ValkeyModule_RegisterStringConfig</code></a> for detailed information about configs.</p>\n<p><span id=\"ValkeyModule_RegisterEnumConfig\"></span></p>\n<h3><code>ValkeyModule_RegisterEnumConfig</code></h3>\n<pre><code>int ValkeyModule_RegisterEnumConfig(ValkeyModuleCtx *ctx,\n                                    const char *name,\n                                    int default_val,\n                                    unsigned int flags,\n                                    const char **enum_values,\n                                    const int *int_values,\n                                    int num_enum_vals,\n                                    ValkeyModuleConfigGetEnumFunc getfn,\n                                    ValkeyModuleConfigSetEnumFunc setfn,\n                                    ValkeyModuleConfigApplyFunc applyfn,\n                                    void *privdata);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Create an enum config that server clients can interact with via the<br><code>CONFIG SET</code>, <code>CONFIG GET</code>, and <code>CONFIG REWRITE</code> commands.<br>Enum configs are a set of string tokens to corresponding integer values, where<br>the string value is exposed to clients but the inter value is passed to the server<br>and the module. These values are defined in <code>enum_values</code>, an array<br>of null-terminated c strings, and <code>int_vals</code>, an array of enum values who has an<br>index partner in <code>enum_values</code>.<br>Example Implementation:<br>     const char *enum_vals[3] = {&quot;first&quot;, &quot;second&quot;, &quot;third&quot;};<br>     const int int_vals[3] = {0, 2, 4};<br>     int enum_val = 0;</p>\n<pre><code> int getEnumConfigCommand(const char *name, void *privdata) {\n     return enum_val;\n }\n\n int setEnumConfigCommand(const char *name, int val, void *privdata, const char **err) {\n     enum_val = val;\n     return VALKEYMODULE_OK;\n }\n ...\n ValkeyModule_RegisterEnumConfig(ctx, &quot;enum&quot;, 0, VALKEYMODULE_CONFIG_DEFAULT, enum_vals, int_vals, 3,\n</code></pre>\n<p>getEnumConfigCommand, setEnumConfigCommand, NULL, NULL);</p>\n<p>Note that you can use <code>VALKEYMODULE_CONFIG_BITFLAGS</code> so that multiple enum string<br>can be combined into one integer as bit flags, in which case you may want to<br>sort your enums so that the preferred combinations are present first.</p>\n<p>See <a href=\"#ValkeyModule_RegisterStringConfig\"><code>ValkeyModule_RegisterStringConfig</code></a> for detailed general information about configs.</p>\n<p><span id=\"ValkeyModule_RegisterNumericConfig\"></span></p>\n<h3><code>ValkeyModule_RegisterNumericConfig</code></h3>\n<pre><code>int ValkeyModule_RegisterNumericConfig(ValkeyModuleCtx *ctx,\n                                       const char *name,\n                                       long long default_val,\n                                       unsigned int flags,\n                                       long long min,\n                                       long long max,\n                                       ValkeyModuleConfigGetNumericFunc getfn,\n                                       ValkeyModuleConfigSetNumericFunc setfn,\n                                       ValkeyModuleConfigApplyFunc applyfn,\n                                       void *privdata);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Create an integer config that server clients can interact with via the<br><code>CONFIG SET</code>, <code>CONFIG GET</code>, and <code>CONFIG REWRITE</code> commands. See<br><a href=\"#ValkeyModule_RegisterStringConfig\"><code>ValkeyModule_RegisterStringConfig</code></a> for detailed information about configs.</p>\n<p><span id=\"ValkeyModule_LoadConfigs\"></span></p>\n<h3><code>ValkeyModule_LoadConfigs</code></h3>\n<pre><code>int ValkeyModule_LoadConfigs(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Applies all pending configurations on the module load. This should be called<br>after all of the configurations have been registered for the module inside of <code>ValkeyModule_OnLoad</code>.<br>This will return <code>VALKEYMODULE_ERR</code> if it is called outside <code>ValkeyModule_OnLoad</code>.<br>This API needs to be called when configurations are provided in either <code>MODULE LOADEX</code><br>or provided as startup arguments.</p>\n<p><span id=\"section-rdb-load-save-api\"></span></p>\n<h2>RDB load/save API</h2>\n<p><span id=\"ValkeyModule_RdbStreamCreateFromFile\"></span></p>\n<h3><code>ValkeyModule_RdbStreamCreateFromFile</code></h3>\n<pre><code>ValkeyModuleRdbStream *ValkeyModule_RdbStreamCreateFromFile(const char *filename);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Create a stream object to save/load RDB to/from a file.</p>\n<p>This function returns a pointer to <code>ValkeyModuleRdbStream</code> which is owned<br>by the caller. It requires a call to <a href=\"#ValkeyModule_RdbStreamFree\"><code>ValkeyModule_RdbStreamFree()</code></a> to free<br>the object.</p>\n<p><span id=\"ValkeyModule_RdbStreamFree\"></span></p>\n<h3><code>ValkeyModule_RdbStreamFree</code></h3>\n<pre><code>void ValkeyModule_RdbStreamFree(ValkeyModuleRdbStream *stream);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Release an RDB stream object.</p>\n<p><span id=\"ValkeyModule_RdbLoad\"></span></p>\n<h3><code>ValkeyModule_RdbLoad</code></h3>\n<pre><code>int ValkeyModule_RdbLoad(ValkeyModuleCtx *ctx,\n                         ValkeyModuleRdbStream *stream,\n                         int flags);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Load RDB file from the <code>stream</code>. Dataset will be cleared first and then RDB<br>file will be loaded.</p>\n<p><code>flags</code> must be zero. This parameter is for future use.</p>\n<p>On success <code>VALKEYMODULE_OK</code> is returned, otherwise <code>VALKEYMODULE_ERR</code> is returned<br>and errno is set accordingly.</p>\n<p>Example:</p>\n<pre><code>ValkeyModuleRdbStream *s = ValkeyModule_RdbStreamCreateFromFile(&quot;exp.rdb&quot;);\nValkeyModule_RdbLoad(ctx, s, 0);\nValkeyModule_RdbStreamFree(s);\n</code></pre>\n<p><span id=\"ValkeyModule_RdbSave\"></span></p>\n<h3><code>ValkeyModule_RdbSave</code></h3>\n<pre><code>int ValkeyModule_RdbSave(ValkeyModuleCtx *ctx,\n                         ValkeyModuleRdbStream *stream,\n                         int flags);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Save dataset to the RDB stream.</p>\n<p><code>flags</code> must be zero. This parameter is for future use.</p>\n<p>On success <code>VALKEYMODULE_OK</code> is returned, otherwise <code>VALKEYMODULE_ERR</code> is returned<br>and errno is set accordingly.</p>\n<p>Example:</p>\n<pre><code>ValkeyModuleRdbStream *s = ValkeyModule_RdbStreamCreateFromFile(&quot;exp.rdb&quot;);\nValkeyModule_RdbSave(ctx, s, 0);\nValkeyModule_RdbStreamFree(s);\n</code></pre>\n<p><span id=\"ValkeyModule_RegisterScriptingEngine\"></span></p>\n<h3><code>ValkeyModule_RegisterScriptingEngine</code></h3>\n<pre><code>int ValkeyModule_RegisterScriptingEngine(ValkeyModuleCtx *module_ctx,;\n</code></pre>\n<p><strong>Available since:</strong> 8.1.0</p>\n<p>Registers a new scripting engine in the server.</p>\n<ul>\n<li><p><code>module_ctx</code>: the module context object.</p>\n</li>\n<li><p><code>engine_name</code>: the name of the scripting engine. This name will match<br>against the engine name specified in the script header using a shebang.</p>\n</li>\n<li><p><code>engine_ctx</code>: engine specific context pointer.</p>\n</li>\n<li><p><code>engine_methods</code>: the struct with the scripting engine callback functions<br>pointers.</p>\n</li>\n</ul>\n<p>Returns <code>VALKEYMODULE_OK</code> if the engine is successfully registered, and<br><code>VALKEYMODULE_ERR</code> in case some failure occurs. In case of a failure, an error<br>message is logged.</p>\n<p><span id=\"ValkeyModule_UnregisterScriptingEngine\"></span></p>\n<h3><code>ValkeyModule_UnregisterScriptingEngine</code></h3>\n<pre><code>int ValkeyModule_UnregisterScriptingEngine(ValkeyModuleCtx *ctx,\n                                           const char *engine_name);\n</code></pre>\n<p><strong>Available since:</strong> 8.1.0</p>\n<p>Removes the scripting engine from the server.</p>\n<p><code>engine_name</code> is the name of the scripting engine.</p>\n<p>Returns <code>VALKEYMODULE_OK</code>.</p>\n<p><span id=\"ValkeyModule_GetFunctionExecutionState\"></span></p>\n<h3><code>ValkeyModule_GetFunctionExecutionState</code></h3>\n<pre><code>ValkeyModuleScriptingEngineExecutionState ValkeyModule_GetFunctionExecutionState(;\n</code></pre>\n<p><strong>Available since:</strong> 8.1.0</p>\n<p>Returns the state of the current function being executed by the scripting<br>engine.</p>\n<p><code>server_ctx</code> is the server runtime context.</p>\n<p>It will return <code>VMSE_STATE_KILLED</code> if the function was already killed either by<br>a <code>SCRIPT KILL</code>, or <code>FUNCTION KILL</code>.</p>\n<p><span id=\"section-key-eviction-api\"></span></p>\n<h2>Key eviction API</h2>\n<p><span id=\"ValkeyModule_SetLRU\"></span></p>\n<h3><code>ValkeyModule_SetLRU</code></h3>\n<pre><code>int ValkeyModule_SetLRU(ValkeyModuleKey *key, mstime_t lru_idle);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Set the key last access time for LRU based eviction. not relevant if the<br>servers&#39;s maxmemory policy is LFU based. Value is idle time in milliseconds.<br>returns <code>VALKEYMODULE_OK</code> if the LRU was updated, <code>VALKEYMODULE_ERR</code> otherwise.</p>\n<p><span id=\"ValkeyModule_GetLRU\"></span></p>\n<h3><code>ValkeyModule_GetLRU</code></h3>\n<pre><code>int ValkeyModule_GetLRU(ValkeyModuleKey *key, mstime_t *lru_idle);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Gets the key last access time.<br>Value is idletime in milliseconds or -1 if the server&#39;s eviction policy is<br>LFU based.<br>returns <code>VALKEYMODULE_OK</code> if when key is valid.</p>\n<p><span id=\"ValkeyModule_SetLFU\"></span></p>\n<h3><code>ValkeyModule_SetLFU</code></h3>\n<pre><code>int ValkeyModule_SetLFU(ValkeyModuleKey *key, long long lfu_freq);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Set the key access frequency. only relevant if the server&#39;s maxmemory policy<br>is LFU based.<br>The frequency is a logarithmic counter that provides an indication of<br>the access frequencyonly (must be &lt;= 255).<br>returns <code>VALKEYMODULE_OK</code> if the LFU was updated, <code>VALKEYMODULE_ERR</code> otherwise.</p>\n<p><span id=\"ValkeyModule_GetLFU\"></span></p>\n<h3><code>ValkeyModule_GetLFU</code></h3>\n<pre><code>int ValkeyModule_GetLFU(ValkeyModuleKey *key, long long *lfu_freq);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Gets the key access frequency or -1 if the server&#39;s eviction policy is not<br>LFU based.<br>returns <code>VALKEYMODULE_OK</code> if when key is valid.</p>\n<p><span id=\"section-miscellaneous-apis\"></span></p>\n<h2>Miscellaneous APIs</h2>\n<p><span id=\"ValkeyModule_GetModuleOptionsAll\"></span></p>\n<h3><code>ValkeyModule_GetModuleOptionsAll</code></h3>\n<pre><code>int ValkeyModule_GetModuleOptionsAll(void);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.0</p>\n<p>Returns the full module options flags mask, using the return value<br>the module can check if a certain set of module options are supported<br>by the server version in use.<br>Example:</p>\n<pre><code>   int supportedFlags = ValkeyModule_GetModuleOptionsAll();\n   if (supportedFlags &amp; VALKEYMODULE_OPTIONS_ALLOW_NESTED_KEYSPACE_NOTIFICATIONS) {\n         // VALKEYMODULE_OPTIONS_ALLOW_NESTED_KEYSPACE_NOTIFICATIONS is supported\n   } else{\n         // VALKEYMODULE_OPTIONS_ALLOW_NESTED_KEYSPACE_NOTIFICATIONS is not supported\n   }\n</code></pre>\n<p><span id=\"ValkeyModule_GetContextFlagsAll\"></span></p>\n<h3><code>ValkeyModule_GetContextFlagsAll</code></h3>\n<pre><code>int ValkeyModule_GetContextFlagsAll(void);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.9</p>\n<p>Returns the full ContextFlags mask, using the return value<br>the module can check if a certain set of flags are supported<br>by the server version in use.<br>Example:</p>\n<pre><code>   int supportedFlags = ValkeyModule_GetContextFlagsAll();\n   if (supportedFlags &amp; VALKEYMODULE_CTX_FLAGS_MULTI) {\n         // VALKEYMODULE_CTX_FLAGS_MULTI is supported\n   } else{\n         // VALKEYMODULE_CTX_FLAGS_MULTI is not supported\n   }\n</code></pre>\n<p><span id=\"ValkeyModule_GetKeyspaceNotificationFlagsAll\"></span></p>\n<h3><code>ValkeyModule_GetKeyspaceNotificationFlagsAll</code></h3>\n<pre><code>int ValkeyModule_GetKeyspaceNotificationFlagsAll(void);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.9</p>\n<p>Returns the full KeyspaceNotification mask, using the return value<br>the module can check if a certain set of flags are supported<br>by the server version in use.<br>Example:</p>\n<pre><code>   int supportedFlags = ValkeyModule_GetKeyspaceNotificationFlagsAll();\n   if (supportedFlags &amp; VALKEYMODULE_NOTIFY_LOADED) {\n         // VALKEYMODULE_NOTIFY_LOADED is supported\n   } else{\n         // VALKEYMODULE_NOTIFY_LOADED is not supported\n   }\n</code></pre>\n<p><span id=\"ValkeyModule_GetServerVersion\"></span></p>\n<h3><code>ValkeyModule_GetServerVersion</code></h3>\n<pre><code>int ValkeyModule_GetServerVersion(void);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.9</p>\n<p>Return the server version in format of 0x00MMmmpp.<br>Example for 6.0.7 the return value will be 0x00060007.</p>\n<p><span id=\"ValkeyModule_GetTypeMethodVersion\"></span></p>\n<h3><code>ValkeyModule_GetTypeMethodVersion</code></h3>\n<pre><code>int ValkeyModule_GetTypeMethodVersion(void);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Return the current server runtime value of <code>VALKEYMODULE_TYPE_METHOD_VERSION</code>.<br>You can use that when calling <a href=\"#ValkeyModule_CreateDataType\"><code>ValkeyModule_CreateDataType</code></a> to know which fields of<br><code>ValkeyModuleTypeMethods</code> are gonna be supported and which will be ignored.</p>\n<p><span id=\"ValkeyModule_ModuleTypeReplaceValue\"></span></p>\n<h3><code>ValkeyModule_ModuleTypeReplaceValue</code></h3>\n<pre><code>int ValkeyModule_ModuleTypeReplaceValue(ValkeyModuleKey *key,\n                                        moduleType *mt,\n                                        void *new_value,\n                                        void **old_value);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.0</p>\n<p>Replace the value assigned to a module type.</p>\n<p>The key must be open for writing, have an existing value, and have a moduleType<br>that matches the one specified by the caller.</p>\n<p>Unlike <a href=\"#ValkeyModule_ModuleTypeSetValue\"><code>ValkeyModule_ModuleTypeSetValue()</code></a> which will free the old value, this function<br>simply swaps the old value with the new value.</p>\n<p>The function returns <code>VALKEYMODULE_OK</code> on success, <code>VALKEYMODULE_ERR</code> on errors<br>such as:</p>\n<ol>\n<li>Key is not opened for writing.</li>\n<li>Key is not a module data type key.</li>\n<li>Key is a module datatype other than &#39;mt&#39;.</li>\n</ol>\n<p>If <code>old_value</code> is non-NULL, the old value is returned by reference.</p>\n<p><span id=\"ValkeyModule_GetCommandKeysWithFlags\"></span></p>\n<h3><code>ValkeyModule_GetCommandKeysWithFlags</code></h3>\n<pre><code>int *ValkeyModule_GetCommandKeysWithFlags(ValkeyModuleCtx *ctx,\n                                          ValkeyModuleString **argv,\n                                          int argc,\n                                          int *num_keys,\n                                          int **out_flags);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>For a specified command, parse its arguments and return an array that<br>contains the indexes of all key name arguments. This function is<br>essentially a more efficient way to do <code>COMMAND GETKEYS</code>.</p>\n<p>The <code>out_flags</code> argument is optional, and can be set to NULL.<br>When provided it is filled with <code>VALKEYMODULE_CMD_KEY_</code> flags in matching<br>indexes with the key indexes of the returned array.</p>\n<p>A NULL return value indicates the specified command has no keys, or<br>an error condition. Error conditions are indicated by setting errno<br>as follows:</p>\n<ul>\n<li>ENOENT: Specified command does not exist.</li>\n<li>EINVAL: Invalid command arity specified.</li>\n</ul>\n<p>NOTE: The returned array is not a Module object so it does not<br>get automatically freed even when auto-memory is used. The caller<br>must explicitly call <a href=\"#ValkeyModule_Free\"><code>ValkeyModule_Free()</code></a> to free it, same as the <code>out_flags</code> pointer if<br>used.</p>\n<p><span id=\"ValkeyModule_GetCommandKeys\"></span></p>\n<h3><code>ValkeyModule_GetCommandKeys</code></h3>\n<pre><code>int *ValkeyModule_GetCommandKeys(ValkeyModuleCtx *ctx,\n                                 ValkeyModuleString **argv,\n                                 int argc,\n                                 int *num_keys);\n</code></pre>\n<p><strong>Available since:</strong> 6.0.9</p>\n<p>Identical to <a href=\"#ValkeyModule_GetCommandKeysWithFlags\"><code>ValkeyModule_GetCommandKeysWithFlags</code></a> when flags are not needed.</p>\n<p><span id=\"ValkeyModule_GetCurrentCommandName\"></span></p>\n<h3><code>ValkeyModule_GetCurrentCommandName</code></h3>\n<pre><code>const char *ValkeyModule_GetCurrentCommandName(ValkeyModuleCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.5</p>\n<p>Return the name of the command currently running</p>\n<p><span id=\"section-defrag-api\"></span></p>\n<h2>Defrag API</h2>\n<p><span id=\"ValkeyModule_RegisterDefragFunc\"></span></p>\n<h3><code>ValkeyModule_RegisterDefragFunc</code></h3>\n<pre><code>int ValkeyModule_RegisterDefragFunc(ValkeyModuleCtx *ctx,\n                                    ValkeyModuleDefragFunc cb);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Register a defrag callback for global data, i.e. anything that the module<br>may allocate that is not tied to a specific data type.</p>\n<p><span id=\"ValkeyModule_DefragShouldStop\"></span></p>\n<h3><code>ValkeyModule_DefragShouldStop</code></h3>\n<pre><code>int ValkeyModule_DefragShouldStop(ValkeyModuleDefragCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>When the data type defrag callback iterates complex structures, this<br>function should be called periodically. A zero (false) return<br>indicates the callback may continue its work. A non-zero value (true)<br>indicates it should stop.</p>\n<p>When stopped, the callback may use <a href=\"#ValkeyModule_DefragCursorSet\"><code>ValkeyModule_DefragCursorSet()</code></a> to store its<br>position so it can later use <a href=\"#ValkeyModule_DefragCursorGet\"><code>ValkeyModule_DefragCursorGet()</code></a> to resume defragging.</p>\n<p>When stopped and more work is left to be done, the callback should<br>return 1. Otherwise, it should return 0.</p>\n<p>NOTE: Modules should consider the frequency in which this function is called,<br>so it generally makes sense to do small batches of work in between calls.</p>\n<p><span id=\"ValkeyModule_DefragCursorSet\"></span></p>\n<h3><code>ValkeyModule_DefragCursorSet</code></h3>\n<pre><code>int ValkeyModule_DefragCursorSet(ValkeyModuleDefragCtx *ctx,\n                                 unsigned long cursor);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Store an arbitrary cursor value for future re-use.</p>\n<p>This should only be called if <a href=\"#ValkeyModule_DefragShouldStop\"><code>ValkeyModule_DefragShouldStop()</code></a> has returned a non-zero<br>value and the defrag callback is about to exit without fully iterating its<br>data type.</p>\n<p>This behavior is reserved to cases where late defrag is performed. Late<br>defrag is selected for keys that implement the <code>free_effort</code> callback and<br>return a <code>free_effort</code> value that is larger than the defrag<br>&#39;active-defrag-max-scan-fields&#39; configuration directive.</p>\n<p>Smaller keys, keys that do not implement <code>free_effort</code> or the global<br>defrag callback are not called in late-defrag mode. In those cases, a<br>call to this function will return <code>VALKEYMODULE_ERR</code>.</p>\n<p>The cursor may be used by the module to represent some progress into the<br>module&#39;s data type. Modules may also store additional cursor-related<br>information locally and use the cursor as a flag that indicates when<br>traversal of a new key begins. This is possible because the API makes<br>a guarantee that concurrent defragmentation of multiple keys will<br>not be performed.</p>\n<p><span id=\"ValkeyModule_DefragCursorGet\"></span></p>\n<h3><code>ValkeyModule_DefragCursorGet</code></h3>\n<pre><code>int ValkeyModule_DefragCursorGet(ValkeyModuleDefragCtx *ctx,\n                                 unsigned long *cursor);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Fetch a cursor value that has been previously stored using <a href=\"#ValkeyModule_DefragCursorSet\"><code>ValkeyModule_DefragCursorSet()</code></a>.</p>\n<p>If not called for a late defrag operation, <code>VALKEYMODULE_ERR</code> will be returned and<br>the cursor should be ignored. See <a href=\"#ValkeyModule_DefragCursorSet\"><code>ValkeyModule_DefragCursorSet()</code></a> for more details on<br>defrag cursors.</p>\n<p><span id=\"ValkeyModule_DefragAlloc\"></span></p>\n<h3><code>ValkeyModule_DefragAlloc</code></h3>\n<pre><code>void *ValkeyModule_DefragAlloc(ValkeyModuleDefragCtx *ctx, void *ptr);\n</code></pre>\n<p><strong>Available since:</strong> 6.2.0</p>\n<p>Defrag a memory allocation previously allocated by <a href=\"#ValkeyModule_Alloc\"><code>ValkeyModule_Alloc</code></a>, <a href=\"#ValkeyModule_Calloc\"><code>ValkeyModule_Calloc</code></a>, etc.<br>The defragmentation process involves allocating a new memory block and copying<br>the contents to it, like <code>realloc()</code>.</p>\n<p>If defragmentation was not necessary, NULL is returned and the operation has<br>no other effect.</p>\n<p>If a non-NULL value is returned, the caller should use the new pointer instead<br>of the old one and update any reference to the old pointer, which must not<br>be used again.</p>\n<p><span id=\"ValkeyModule_DefragValkeyModuleString\"></span></p>\n<h3><code>ValkeyModule_DefragValkeyModuleString</code></h3>\n<pre><code>ValkeyModuleString *ValkeyModule_DefragValkeyModuleString(ValkeyModuleDefragCtx *ctx,\n                                                          ValkeyModuleString *str);\n</code></pre>\n<p><strong>Available since:</strong> 7.2.5</p>\n<p>Defrag a <code>ValkeyModuleString</code> previously allocated by <a href=\"#ValkeyModule_Alloc\"><code>ValkeyModule_Alloc</code></a>, <a href=\"#ValkeyModule_Calloc\"><code>ValkeyModule_Calloc</code></a>, etc.<br>See <a href=\"#ValkeyModule_DefragAlloc\"><code>ValkeyModule_DefragAlloc()</code></a> for more information on how the defragmentation process<br>works.</p>\n<p>NOTE: It is only possible to defrag strings that have a single reference.<br>Typically this means strings retained with <a href=\"#ValkeyModule_RetainString\"><code>ValkeyModule_RetainString</code></a> or <a href=\"#ValkeyModule_HoldString\"><code>ValkeyModule_HoldString</code></a><br>may not be defragmentable. One exception is command argvs which, if retained<br>by the module, will end up with a single reference (because the reference<br>on the server side is dropped as soon as the command callback returns).</p>\n<p><span id=\"ValkeyModule_GetKeyNameFromDefragCtx\"></span></p>\n<h3><code>ValkeyModule_GetKeyNameFromDefragCtx</code></h3>\n<pre><code>const ValkeyModuleString *ValkeyModule_GetKeyNameFromDefragCtx(ValkeyModuleDefragCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Returns the name of the key currently being processed.<br>There is no guarantee that the key name is always available, so this may return NULL.</p>\n<p><span id=\"ValkeyModule_GetDbIdFromDefragCtx\"></span></p>\n<h3><code>ValkeyModule_GetDbIdFromDefragCtx</code></h3>\n<pre><code>int ValkeyModule_GetDbIdFromDefragCtx(ValkeyModuleDefragCtx *ctx);\n</code></pre>\n<p><strong>Available since:</strong> 7.0.0</p>\n<p>Returns the database id of the key currently being processed.<br>There is no guarantee that this info is always available, so this may return -1.</p>\n<p><span id=\"section-function-index\"></span></p>\n<h2>Function index</h2>\n<ul>\n<li><a href=\"#ValkeyModule_ACLAddLogEntry\"><code>ValkeyModule_ACLAddLogEntry</code></a></li>\n<li><a href=\"#ValkeyModule_ACLAddLogEntryByUserName\"><code>ValkeyModule_ACLAddLogEntryByUserName</code></a></li>\n<li><a href=\"#ValkeyModule_ACLCheckChannelPermissions\"><code>ValkeyModule_ACLCheckChannelPermissions</code></a></li>\n<li><a href=\"#ValkeyModule_ACLCheckCommandPermissions\"><code>ValkeyModule_ACLCheckCommandPermissions</code></a></li>\n<li><a href=\"#ValkeyModule_ACLCheckKeyPermissions\"><code>ValkeyModule_ACLCheckKeyPermissions</code></a></li>\n<li><a href=\"#ValkeyModule_AbortBlock\"><code>ValkeyModule_AbortBlock</code></a></li>\n<li><a href=\"#ValkeyModule_AddACLCategory\"><code>ValkeyModule_AddACLCategory</code></a></li>\n<li><a href=\"#ValkeyModule_AddPostNotificationJob\"><code>ValkeyModule_AddPostNotificationJob</code></a></li>\n<li><a href=\"#ValkeyModule_Alloc\"><code>ValkeyModule_Alloc</code></a></li>\n<li><a href=\"#ValkeyModule_AuthenticateClientWithACLUser\"><code>ValkeyModule_AuthenticateClientWithACLUser</code></a></li>\n<li><a href=\"#ValkeyModule_AuthenticateClientWithUser\"><code>ValkeyModule_AuthenticateClientWithUser</code></a></li>\n<li><a href=\"#ValkeyModule_AutoMemory\"><code>ValkeyModule_AutoMemory</code></a></li>\n<li><a href=\"#ValkeyModule_AvoidReplicaTraffic\"><code>ValkeyModule_AvoidReplicaTraffic</code></a></li>\n<li><a href=\"#ValkeyModule_BlockClient\"><code>ValkeyModule_BlockClient</code></a></li>\n<li><a href=\"#ValkeyModule_BlockClientGetPrivateData\"><code>ValkeyModule_BlockClientGetPrivateData</code></a></li>\n<li><a href=\"#ValkeyModule_BlockClientOnAuth\"><code>ValkeyModule_BlockClientOnAuth</code></a></li>\n<li><a href=\"#ValkeyModule_BlockClientOnKeys\"><code>ValkeyModule_BlockClientOnKeys</code></a></li>\n<li><a href=\"#ValkeyModule_BlockClientOnKeysWithFlags\"><code>ValkeyModule_BlockClientOnKeysWithFlags</code></a></li>\n<li><a href=\"#ValkeyModule_BlockClientSetPrivateData\"><code>ValkeyModule_BlockClientSetPrivateData</code></a></li>\n<li><a href=\"#ValkeyModule_BlockedClientDisconnected\"><code>ValkeyModule_BlockedClientDisconnected</code></a></li>\n<li><a href=\"#ValkeyModule_BlockedClientMeasureTimeEnd\"><code>ValkeyModule_BlockedClientMeasureTimeEnd</code></a></li>\n<li><a href=\"#ValkeyModule_BlockedClientMeasureTimeStart\"><code>ValkeyModule_BlockedClientMeasureTimeStart</code></a></li>\n<li><a href=\"#ValkeyModule_CachedMicroseconds\"><code>ValkeyModule_CachedMicroseconds</code></a></li>\n<li><a href=\"#ValkeyModule_Call\"><code>ValkeyModule_Call</code></a></li>\n<li><a href=\"#ValkeyModule_CallReplyArrayElement\"><code>ValkeyModule_CallReplyArrayElement</code></a></li>\n<li><a href=\"#ValkeyModule_CallReplyAttribute\"><code>ValkeyModule_CallReplyAttribute</code></a></li>\n<li><a href=\"#ValkeyModule_CallReplyAttributeElement\"><code>ValkeyModule_CallReplyAttributeElement</code></a></li>\n<li><a href=\"#ValkeyModule_CallReplyBigNumber\"><code>ValkeyModule_CallReplyBigNumber</code></a></li>\n<li><a href=\"#ValkeyModule_CallReplyBool\"><code>ValkeyModule_CallReplyBool</code></a></li>\n<li><a href=\"#ValkeyModule_CallReplyDouble\"><code>ValkeyModule_CallReplyDouble</code></a></li>\n<li><a href=\"#ValkeyModule_CallReplyInteger\"><code>ValkeyModule_CallReplyInteger</code></a></li>\n<li><a href=\"#ValkeyModule_CallReplyLength\"><code>ValkeyModule_CallReplyLength</code></a></li>\n<li><a href=\"#ValkeyModule_CallReplyMapElement\"><code>ValkeyModule_CallReplyMapElement</code></a></li>\n<li><a href=\"#ValkeyModule_CallReplyPromiseAbort\"><code>ValkeyModule_CallReplyPromiseAbort</code></a></li>\n<li><a href=\"#ValkeyModule_CallReplyPromiseSetUnblockHandler\"><code>ValkeyModule_CallReplyPromiseSetUnblockHandler</code></a></li>\n<li><a href=\"#ValkeyModule_CallReplyProto\"><code>ValkeyModule_CallReplyProto</code></a></li>\n<li><a href=\"#ValkeyModule_CallReplySetElement\"><code>ValkeyModule_CallReplySetElement</code></a></li>\n<li><a href=\"#ValkeyModule_CallReplyStringPtr\"><code>ValkeyModule_CallReplyStringPtr</code></a></li>\n<li><a href=\"#ValkeyModule_CallReplyType\"><code>ValkeyModule_CallReplyType</code></a></li>\n<li><a href=\"#ValkeyModule_CallReplyVerbatim\"><code>ValkeyModule_CallReplyVerbatim</code></a></li>\n<li><a href=\"#ValkeyModule_Calloc\"><code>ValkeyModule_Calloc</code></a></li>\n<li><a href=\"#ValkeyModule_ChannelAtPosWithFlags\"><code>ValkeyModule_ChannelAtPosWithFlags</code></a></li>\n<li><a href=\"#ValkeyModule_CloseKey\"><code>ValkeyModule_CloseKey</code></a></li>\n<li><a href=\"#ValkeyModule_ClusterCanonicalKeyNameInSlot\"><code>ValkeyModule_ClusterCanonicalKeyNameInSlot</code></a></li>\n<li><a href=\"#ValkeyModule_ClusterKeySlot\"><code>ValkeyModule_ClusterKeySlot</code></a></li>\n<li><a href=\"#ValkeyModule_CommandFilterArgDelete\"><code>ValkeyModule_CommandFilterArgDelete</code></a></li>\n<li><a href=\"#ValkeyModule_CommandFilterArgGet\"><code>ValkeyModule_CommandFilterArgGet</code></a></li>\n<li><a href=\"#ValkeyModule_CommandFilterArgInsert\"><code>ValkeyModule_CommandFilterArgInsert</code></a></li>\n<li><a href=\"#ValkeyModule_CommandFilterArgReplace\"><code>ValkeyModule_CommandFilterArgReplace</code></a></li>\n<li><a href=\"#ValkeyModule_CommandFilterArgsCount\"><code>ValkeyModule_CommandFilterArgsCount</code></a></li>\n<li><a href=\"#ValkeyModule_CommandFilterGetClientId\"><code>ValkeyModule_CommandFilterGetClientId</code></a></li>\n<li><a href=\"#ValkeyModule_CreateCommand\"><code>ValkeyModule_CreateCommand</code></a></li>\n<li><a href=\"#ValkeyModule_CreateDataType\"><code>ValkeyModule_CreateDataType</code></a></li>\n<li><a href=\"#ValkeyModule_CreateDict\"><code>ValkeyModule_CreateDict</code></a></li>\n<li><a href=\"#ValkeyModule_CreateModuleUser\"><code>ValkeyModule_CreateModuleUser</code></a></li>\n<li><a href=\"#ValkeyModule_CreateString\"><code>ValkeyModule_CreateString</code></a></li>\n<li><a href=\"#ValkeyModule_CreateStringFromCallReply\"><code>ValkeyModule_CreateStringFromCallReply</code></a></li>\n<li><a href=\"#ValkeyModule_CreateStringFromDouble\"><code>ValkeyModule_CreateStringFromDouble</code></a></li>\n<li><a href=\"#ValkeyModule_CreateStringFromLongDouble\"><code>ValkeyModule_CreateStringFromLongDouble</code></a></li>\n<li><a href=\"#ValkeyModule_CreateStringFromLongLong\"><code>ValkeyModule_CreateStringFromLongLong</code></a></li>\n<li><a href=\"#ValkeyModule_CreateStringFromStreamID\"><code>ValkeyModule_CreateStringFromStreamID</code></a></li>\n<li><a href=\"#ValkeyModule_CreateStringFromString\"><code>ValkeyModule_CreateStringFromString</code></a></li>\n<li><a href=\"#ValkeyModule_CreateStringFromULongLong\"><code>ValkeyModule_CreateStringFromULongLong</code></a></li>\n<li><a href=\"#ValkeyModule_CreateStringPrintf\"><code>ValkeyModule_CreateStringPrintf</code></a></li>\n<li><a href=\"#ValkeyModule_CreateSubcommand\"><code>ValkeyModule_CreateSubcommand</code></a></li>\n<li><a href=\"#ValkeyModule_CreateTimer\"><code>ValkeyModule_CreateTimer</code></a></li>\n<li><a href=\"#ValkeyModule_DbSize\"><code>ValkeyModule_DbSize</code></a></li>\n<li><a href=\"#ValkeyModule_DeauthenticateAndCloseClient\"><code>ValkeyModule_DeauthenticateAndCloseClient</code></a></li>\n<li><a href=\"#ValkeyModule_DefragAlloc\"><code>ValkeyModule_DefragAlloc</code></a></li>\n<li><a href=\"#ValkeyModule_DefragCursorGet\"><code>ValkeyModule_DefragCursorGet</code></a></li>\n<li><a href=\"#ValkeyModule_DefragCursorSet\"><code>ValkeyModule_DefragCursorSet</code></a></li>\n<li><a href=\"#ValkeyModule_DefragShouldStop\"><code>ValkeyModule_DefragShouldStop</code></a></li>\n<li><a href=\"#ValkeyModule_DefragValkeyModuleString\"><code>ValkeyModule_DefragValkeyModuleString</code></a></li>\n<li><a href=\"#ValkeyModule_DeleteKey\"><code>ValkeyModule_DeleteKey</code></a></li>\n<li><a href=\"#ValkeyModule_DictCompare\"><code>ValkeyModule_DictCompare</code></a></li>\n<li><a href=\"#ValkeyModule_DictCompareC\"><code>ValkeyModule_DictCompareC</code></a></li>\n<li><a href=\"#ValkeyModule_DictDel\"><code>ValkeyModule_DictDel</code></a></li>\n<li><a href=\"#ValkeyModule_DictDelC\"><code>ValkeyModule_DictDelC</code></a></li>\n<li><a href=\"#ValkeyModule_DictGet\"><code>ValkeyModule_DictGet</code></a></li>\n<li><a href=\"#ValkeyModule_DictGetC\"><code>ValkeyModule_DictGetC</code></a></li>\n<li><a href=\"#ValkeyModule_DictIteratorReseek\"><code>ValkeyModule_DictIteratorReseek</code></a></li>\n<li><a href=\"#ValkeyModule_DictIteratorReseekC\"><code>ValkeyModule_DictIteratorReseekC</code></a></li>\n<li><a href=\"#ValkeyModule_DictIteratorStart\"><code>ValkeyModule_DictIteratorStart</code></a></li>\n<li><a href=\"#ValkeyModule_DictIteratorStartC\"><code>ValkeyModule_DictIteratorStartC</code></a></li>\n<li><a href=\"#ValkeyModule_DictIteratorStop\"><code>ValkeyModule_DictIteratorStop</code></a></li>\n<li><a href=\"#ValkeyModule_DictNext\"><code>ValkeyModule_DictNext</code></a></li>\n<li><a href=\"#ValkeyModule_DictNextC\"><code>ValkeyModule_DictNextC</code></a></li>\n<li><a href=\"#ValkeyModule_DictPrev\"><code>ValkeyModule_DictPrev</code></a></li>\n<li><a href=\"#ValkeyModule_DictPrevC\"><code>ValkeyModule_DictPrevC</code></a></li>\n<li><a href=\"#ValkeyModule_DictReplace\"><code>ValkeyModule_DictReplace</code></a></li>\n<li><a href=\"#ValkeyModule_DictReplaceC\"><code>ValkeyModule_DictReplaceC</code></a></li>\n<li><a href=\"#ValkeyModule_DictSet\"><code>ValkeyModule_DictSet</code></a></li>\n<li><a href=\"#ValkeyModule_DictSetC\"><code>ValkeyModule_DictSetC</code></a></li>\n<li><a href=\"#ValkeyModule_DictSize\"><code>ValkeyModule_DictSize</code></a></li>\n<li><a href=\"#ValkeyModule_DigestAddLongLong\"><code>ValkeyModule_DigestAddLongLong</code></a></li>\n<li><a href=\"#ValkeyModule_DigestAddStringBuffer\"><code>ValkeyModule_DigestAddStringBuffer</code></a></li>\n<li><a href=\"#ValkeyModule_DigestEndSequence\"><code>ValkeyModule_DigestEndSequence</code></a></li>\n<li><a href=\"#ValkeyModule_EmitAOF\"><code>ValkeyModule_EmitAOF</code></a></li>\n<li><a href=\"#ValkeyModule_EventLoopAdd\"><code>ValkeyModule_EventLoopAdd</code></a></li>\n<li><a href=\"#ValkeyModule_EventLoopAddOneShot\"><code>ValkeyModule_EventLoopAddOneShot</code></a></li>\n<li><a href=\"#ValkeyModule_EventLoopDel\"><code>ValkeyModule_EventLoopDel</code></a></li>\n<li><a href=\"#ValkeyModule_ExitFromChild\"><code>ValkeyModule_ExitFromChild</code></a></li>\n<li><a href=\"#ValkeyModule_ExportSharedAPI\"><code>ValkeyModule_ExportSharedAPI</code></a></li>\n<li><a href=\"#ValkeyModule_Fork\"><code>ValkeyModule_Fork</code></a></li>\n<li><a href=\"#ValkeyModule_Free\"><code>ValkeyModule_Free</code></a></li>\n<li><a href=\"#ValkeyModule_FreeCallReply\"><code>ValkeyModule_FreeCallReply</code></a></li>\n<li><a href=\"#ValkeyModule_FreeClusterNodesList\"><code>ValkeyModule_FreeClusterNodesList</code></a></li>\n<li><a href=\"#ValkeyModule_FreeDict\"><code>ValkeyModule_FreeDict</code></a></li>\n<li><a href=\"#ValkeyModule_FreeModuleUser\"><code>ValkeyModule_FreeModuleUser</code></a></li>\n<li><a href=\"#ValkeyModule_FreeServerInfo\"><code>ValkeyModule_FreeServerInfo</code></a></li>\n<li><a href=\"#ValkeyModule_FreeString\"><code>ValkeyModule_FreeString</code></a></li>\n<li><a href=\"#ValkeyModule_FreeThreadSafeContext\"><code>ValkeyModule_FreeThreadSafeContext</code></a></li>\n<li><a href=\"#ValkeyModule_GetAbsExpire\"><code>ValkeyModule_GetAbsExpire</code></a></li>\n<li><a href=\"#ValkeyModule_GetBlockedClientHandle\"><code>ValkeyModule_GetBlockedClientHandle</code></a></li>\n<li><a href=\"#ValkeyModule_GetBlockedClientPrivateData\"><code>ValkeyModule_GetBlockedClientPrivateData</code></a></li>\n<li><a href=\"#ValkeyModule_GetBlockedClientReadyKey\"><code>ValkeyModule_GetBlockedClientReadyKey</code></a></li>\n<li><a href=\"#ValkeyModule_GetClientCertificate\"><code>ValkeyModule_GetClientCertificate</code></a></li>\n<li><a href=\"#ValkeyModule_GetClientId\"><code>ValkeyModule_GetClientId</code></a></li>\n<li><a href=\"#ValkeyModule_GetClientInfoById\"><code>ValkeyModule_GetClientInfoById</code></a></li>\n<li><a href=\"#ValkeyModule_GetClientNameById\"><code>ValkeyModule_GetClientNameById</code></a></li>\n<li><a href=\"#ValkeyModule_GetClientUserNameById\"><code>ValkeyModule_GetClientUserNameById</code></a></li>\n<li><a href=\"#ValkeyModule_GetClusterNodeInfo\"><code>ValkeyModule_GetClusterNodeInfo</code></a></li>\n<li><a href=\"#ValkeyModule_GetClusterNodeInfoForClient\"><code>ValkeyModule_GetClusterNodeInfoForClient</code></a></li>\n<li><a href=\"#ValkeyModule_GetClusterNodesList\"><code>ValkeyModule_GetClusterNodesList</code></a></li>\n<li><a href=\"#ValkeyModule_GetClusterSize\"><code>ValkeyModule_GetClusterSize</code></a></li>\n<li><a href=\"#ValkeyModule_GetCommand\"><code>ValkeyModule_GetCommand</code></a></li>\n<li><a href=\"#ValkeyModule_GetCommandKeys\"><code>ValkeyModule_GetCommandKeys</code></a></li>\n<li><a href=\"#ValkeyModule_GetCommandKeysWithFlags\"><code>ValkeyModule_GetCommandKeysWithFlags</code></a></li>\n<li><a href=\"#ValkeyModule_GetContextFlags\"><code>ValkeyModule_GetContextFlags</code></a></li>\n<li><a href=\"#ValkeyModule_GetContextFlagsAll\"><code>ValkeyModule_GetContextFlagsAll</code></a></li>\n<li><a href=\"#ValkeyModule_GetCurrentCommandName\"><code>ValkeyModule_GetCurrentCommandName</code></a></li>\n<li><a href=\"#ValkeyModule_GetCurrentUserName\"><code>ValkeyModule_GetCurrentUserName</code></a></li>\n<li><a href=\"#ValkeyModule_GetDbIdFromDefragCtx\"><code>ValkeyModule_GetDbIdFromDefragCtx</code></a></li>\n<li><a href=\"#ValkeyModule_GetDbIdFromDigest\"><code>ValkeyModule_GetDbIdFromDigest</code></a></li>\n<li><a href=\"#ValkeyModule_GetDbIdFromIO\"><code>ValkeyModule_GetDbIdFromIO</code></a></li>\n<li><a href=\"#ValkeyModule_GetDbIdFromModuleKey\"><code>ValkeyModule_GetDbIdFromModuleKey</code></a></li>\n<li><a href=\"#ValkeyModule_GetDbIdFromOptCtx\"><code>ValkeyModule_GetDbIdFromOptCtx</code></a></li>\n<li><a href=\"#ValkeyModule_GetDetachedThreadSafeContext\"><code>ValkeyModule_GetDetachedThreadSafeContext</code></a></li>\n<li><a href=\"#ValkeyModule_GetExpire\"><code>ValkeyModule_GetExpire</code></a></li>\n<li><a href=\"#ValkeyModule_GetFunctionExecutionState\"><code>ValkeyModule_GetFunctionExecutionState</code></a></li>\n<li><a href=\"#ValkeyModule_GetKeyNameFromDefragCtx\"><code>ValkeyModule_GetKeyNameFromDefragCtx</code></a></li>\n<li><a href=\"#ValkeyModule_GetKeyNameFromDigest\"><code>ValkeyModule_GetKeyNameFromDigest</code></a></li>\n<li><a href=\"#ValkeyModule_GetKeyNameFromIO\"><code>ValkeyModule_GetKeyNameFromIO</code></a></li>\n<li><a href=\"#ValkeyModule_GetKeyNameFromModuleKey\"><code>ValkeyModule_GetKeyNameFromModuleKey</code></a></li>\n<li><a href=\"#ValkeyModule_GetKeyNameFromOptCtx\"><code>ValkeyModule_GetKeyNameFromOptCtx</code></a></li>\n<li><a href=\"#ValkeyModule_GetKeyspaceNotificationFlagsAll\"><code>ValkeyModule_GetKeyspaceNotificationFlagsAll</code></a></li>\n<li><a href=\"#ValkeyModule_GetLFU\"><code>ValkeyModule_GetLFU</code></a></li>\n<li><a href=\"#ValkeyModule_GetLRU\"><code>ValkeyModule_GetLRU</code></a></li>\n<li><a href=\"#ValkeyModule_GetModuleOptionsAll\"><code>ValkeyModule_GetModuleOptionsAll</code></a></li>\n<li><a href=\"#ValkeyModule_GetModuleUserACLString\"><code>ValkeyModule_GetModuleUserACLString</code></a></li>\n<li><a href=\"#ValkeyModule_GetModuleUserFromUserName\"><code>ValkeyModule_GetModuleUserFromUserName</code></a></li>\n<li><a href=\"#ValkeyModule_GetMyClusterID\"><code>ValkeyModule_GetMyClusterID</code></a></li>\n<li><a href=\"#ValkeyModule_GetNotifyKeyspaceEvents\"><code>ValkeyModule_GetNotifyKeyspaceEvents</code></a></li>\n<li><a href=\"#ValkeyModule_GetOpenKeyModesAll\"><code>ValkeyModule_GetOpenKeyModesAll</code></a></li>\n<li><a href=\"#ValkeyModule_GetRandomBytes\"><code>ValkeyModule_GetRandomBytes</code></a></li>\n<li><a href=\"#ValkeyModule_GetRandomHexChars\"><code>ValkeyModule_GetRandomHexChars</code></a></li>\n<li><a href=\"#ValkeyModule_GetSelectedDb\"><code>ValkeyModule_GetSelectedDb</code></a></li>\n<li><a href=\"#ValkeyModule_GetServerInfo\"><code>ValkeyModule_GetServerInfo</code></a></li>\n<li><a href=\"#ValkeyModule_GetServerVersion\"><code>ValkeyModule_GetServerVersion</code></a></li>\n<li><a href=\"#ValkeyModule_GetSharedAPI\"><code>ValkeyModule_GetSharedAPI</code></a></li>\n<li><a href=\"#ValkeyModule_GetThreadSafeContext\"><code>ValkeyModule_GetThreadSafeContext</code></a></li>\n<li><a href=\"#ValkeyModule_GetTimerInfo\"><code>ValkeyModule_GetTimerInfo</code></a></li>\n<li><a href=\"#ValkeyModule_GetToDbIdFromOptCtx\"><code>ValkeyModule_GetToDbIdFromOptCtx</code></a></li>\n<li><a href=\"#ValkeyModule_GetToKeyNameFromOptCtx\"><code>ValkeyModule_GetToKeyNameFromOptCtx</code></a></li>\n<li><a href=\"#ValkeyModule_GetTypeMethodVersion\"><code>ValkeyModule_GetTypeMethodVersion</code></a></li>\n<li><a href=\"#ValkeyModule_GetUsedMemoryRatio\"><code>ValkeyModule_GetUsedMemoryRatio</code></a></li>\n<li><a href=\"#ValkeyModule_HashGet\"><code>ValkeyModule_HashGet</code></a></li>\n<li><a href=\"#ValkeyModule_HashSet\"><code>ValkeyModule_HashSet</code></a></li>\n<li><a href=\"#ValkeyModule_HoldString\"><code>ValkeyModule_HoldString</code></a></li>\n<li><a href=\"#ValkeyModule_InfoAddFieldCString\"><code>ValkeyModule_InfoAddFieldCString</code></a></li>\n<li><a href=\"#ValkeyModule_InfoAddFieldDouble\"><code>ValkeyModule_InfoAddFieldDouble</code></a></li>\n<li><a href=\"#ValkeyModule_InfoAddFieldLongLong\"><code>ValkeyModule_InfoAddFieldLongLong</code></a></li>\n<li><a href=\"#ValkeyModule_InfoAddFieldString\"><code>ValkeyModule_InfoAddFieldString</code></a></li>\n<li><a href=\"#ValkeyModule_InfoAddFieldULongLong\"><code>ValkeyModule_InfoAddFieldULongLong</code></a></li>\n<li><a href=\"#ValkeyModule_InfoAddSection\"><code>ValkeyModule_InfoAddSection</code></a></li>\n<li><a href=\"#ValkeyModule_InfoBeginDictField\"><code>ValkeyModule_InfoBeginDictField</code></a></li>\n<li><a href=\"#ValkeyModule_InfoEndDictField\"><code>ValkeyModule_InfoEndDictField</code></a></li>\n<li><a href=\"#ValkeyModule_IsBlockedReplyRequest\"><code>ValkeyModule_IsBlockedReplyRequest</code></a></li>\n<li><a href=\"#ValkeyModule_IsBlockedTimeoutRequest\"><code>ValkeyModule_IsBlockedTimeoutRequest</code></a></li>\n<li><a href=\"#ValkeyModule_IsChannelsPositionRequest\"><code>ValkeyModule_IsChannelsPositionRequest</code></a></li>\n<li><a href=\"#ValkeyModule_IsIOError\"><code>ValkeyModule_IsIOError</code></a></li>\n<li><a href=\"#ValkeyModule_IsKeysPositionRequest\"><code>ValkeyModule_IsKeysPositionRequest</code></a></li>\n<li><a href=\"#ValkeyModule_IsModuleNameBusy\"><code>ValkeyModule_IsModuleNameBusy</code></a></li>\n<li><a href=\"#ValkeyModule_IsSubEventSupported\"><code>ValkeyModule_IsSubEventSupported</code></a></li>\n<li><a href=\"#ValkeyModule_KeyAtPos\"><code>ValkeyModule_KeyAtPos</code></a></li>\n<li><a href=\"#ValkeyModule_KeyAtPosWithFlags\"><code>ValkeyModule_KeyAtPosWithFlags</code></a></li>\n<li><a href=\"#ValkeyModule_KeyExists\"><code>ValkeyModule_KeyExists</code></a></li>\n<li><a href=\"#ValkeyModule_KeyType\"><code>ValkeyModule_KeyType</code></a></li>\n<li><a href=\"#ValkeyModule_KillForkChild\"><code>ValkeyModule_KillForkChild</code></a></li>\n<li><a href=\"#ValkeyModule_LatencyAddSample\"><code>ValkeyModule_LatencyAddSample</code></a></li>\n<li><a href=\"#ValkeyModule_ListDelete\"><code>ValkeyModule_ListDelete</code></a></li>\n<li><a href=\"#ValkeyModule_ListGet\"><code>ValkeyModule_ListGet</code></a></li>\n<li><a href=\"#ValkeyModule_ListInsert\"><code>ValkeyModule_ListInsert</code></a></li>\n<li><a href=\"#ValkeyModule_ListPop\"><code>ValkeyModule_ListPop</code></a></li>\n<li><a href=\"#ValkeyModule_ListPush\"><code>ValkeyModule_ListPush</code></a></li>\n<li><a href=\"#ValkeyModule_ListSet\"><code>ValkeyModule_ListSet</code></a></li>\n<li><a href=\"#ValkeyModule_LoadConfigs\"><code>ValkeyModule_LoadConfigs</code></a></li>\n<li><a href=\"#ValkeyModule_LoadDataTypeFromString\"><code>ValkeyModule_LoadDataTypeFromString</code></a></li>\n<li><a href=\"#ValkeyModule_LoadDataTypeFromStringEncver\"><code>ValkeyModule_LoadDataTypeFromStringEncver</code></a></li>\n<li><a href=\"#ValkeyModule_LoadDouble\"><code>ValkeyModule_LoadDouble</code></a></li>\n<li><a href=\"#ValkeyModule_LoadFloat\"><code>ValkeyModule_LoadFloat</code></a></li>\n<li><a href=\"#ValkeyModule_LoadLongDouble\"><code>ValkeyModule_LoadLongDouble</code></a></li>\n<li><a href=\"#ValkeyModule_LoadSigned\"><code>ValkeyModule_LoadSigned</code></a></li>\n<li><a href=\"#ValkeyModule_LoadString\"><code>ValkeyModule_LoadString</code></a></li>\n<li><a href=\"#ValkeyModule_LoadStringBuffer\"><code>ValkeyModule_LoadStringBuffer</code></a></li>\n<li><a href=\"#ValkeyModule_LoadUnsigned\"><code>ValkeyModule_LoadUnsigned</code></a></li>\n<li><a href=\"#ValkeyModule_Log\"><code>ValkeyModule_Log</code></a></li>\n<li><a href=\"#ValkeyModule_LogIOError\"><code>ValkeyModule_LogIOError</code></a></li>\n<li><a href=\"#ValkeyModule_MallocSize\"><code>ValkeyModule_MallocSize</code></a></li>\n<li><a href=\"#ValkeyModule_MallocSizeDict\"><code>ValkeyModule_MallocSizeDict</code></a></li>\n<li><a href=\"#ValkeyModule_MallocSizeString\"><code>ValkeyModule_MallocSizeString</code></a></li>\n<li><a href=\"#ValkeyModule_MallocUsableSize\"><code>ValkeyModule_MallocUsableSize</code></a></li>\n<li><a href=\"#ValkeyModule_Microseconds\"><code>ValkeyModule_Microseconds</code></a></li>\n<li><a href=\"#ValkeyModule_Milliseconds\"><code>ValkeyModule_Milliseconds</code></a></li>\n<li><a href=\"#ValkeyModule_ModuleTypeGetType\"><code>ValkeyModule_ModuleTypeGetType</code></a></li>\n<li><a href=\"#ValkeyModule_ModuleTypeGetValue\"><code>ValkeyModule_ModuleTypeGetValue</code></a></li>\n<li><a href=\"#ValkeyModule_ModuleTypeReplaceValue\"><code>ValkeyModule_ModuleTypeReplaceValue</code></a></li>\n<li><a href=\"#ValkeyModule_ModuleTypeSetValue\"><code>ValkeyModule_ModuleTypeSetValue</code></a></li>\n<li><a href=\"#ValkeyModule_MonotonicMicroseconds\"><code>ValkeyModule_MonotonicMicroseconds</code></a></li>\n<li><a href=\"#ValkeyModule_MustObeyClient\"><code>ValkeyModule_MustObeyClient</code></a></li>\n<li><a href=\"#ValkeyModule_NotifyKeyspaceEvent\"><code>ValkeyModule_NotifyKeyspaceEvent</code></a></li>\n<li><a href=\"#ValkeyModule_OpenKey\"><code>ValkeyModule_OpenKey</code></a></li>\n<li><a href=\"#ValkeyModule_PoolAlloc\"><code>ValkeyModule_PoolAlloc</code></a></li>\n<li><a href=\"#ValkeyModule_PublishMessage\"><code>ValkeyModule_PublishMessage</code></a></li>\n<li><a href=\"#ValkeyModule_PublishMessageShard\"><code>ValkeyModule_PublishMessageShard</code></a></li>\n<li><a href=\"#ValkeyModule_RandomKey\"><code>ValkeyModule_RandomKey</code></a></li>\n<li><a href=\"#ValkeyModule_RdbLoad\"><code>ValkeyModule_RdbLoad</code></a></li>\n<li><a href=\"#ValkeyModule_RdbSave\"><code>ValkeyModule_RdbSave</code></a></li>\n<li><a href=\"#ValkeyModule_RdbStreamCreateFromFile\"><code>ValkeyModule_RdbStreamCreateFromFile</code></a></li>\n<li><a href=\"#ValkeyModule_RdbStreamFree\"><code>ValkeyModule_RdbStreamFree</code></a></li>\n<li><a href=\"#ValkeyModule_Realloc\"><code>ValkeyModule_Realloc</code></a></li>\n<li><a href=\"#ValkeyModule_RedactClientCommandArgument\"><code>ValkeyModule_RedactClientCommandArgument</code></a></li>\n<li><a href=\"#ValkeyModule_RegisterAuthCallback\"><code>ValkeyModule_RegisterAuthCallback</code></a></li>\n<li><a href=\"#ValkeyModule_RegisterBoolConfig\"><code>ValkeyModule_RegisterBoolConfig</code></a></li>\n<li><a href=\"#ValkeyModule_RegisterClusterMessageReceiver\"><code>ValkeyModule_RegisterClusterMessageReceiver</code></a></li>\n<li><a href=\"#ValkeyModule_RegisterCommandFilter\"><code>ValkeyModule_RegisterCommandFilter</code></a></li>\n<li><a href=\"#ValkeyModule_RegisterDefragFunc\"><code>ValkeyModule_RegisterDefragFunc</code></a></li>\n<li><a href=\"#ValkeyModule_RegisterEnumConfig\"><code>ValkeyModule_RegisterEnumConfig</code></a></li>\n<li><a href=\"#ValkeyModule_RegisterInfoFunc\"><code>ValkeyModule_RegisterInfoFunc</code></a></li>\n<li><a href=\"#ValkeyModule_RegisterNumericConfig\"><code>ValkeyModule_RegisterNumericConfig</code></a></li>\n<li><a href=\"#ValkeyModule_RegisterScriptingEngine\"><code>ValkeyModule_RegisterScriptingEngine</code></a></li>\n<li><a href=\"#ValkeyModule_RegisterStringConfig\"><code>ValkeyModule_RegisterStringConfig</code></a></li>\n<li><a href=\"#ValkeyModule_Replicate\"><code>ValkeyModule_Replicate</code></a></li>\n<li><a href=\"#ValkeyModule_ReplicateVerbatim\"><code>ValkeyModule_ReplicateVerbatim</code></a></li>\n<li><a href=\"#ValkeyModule_ReplySetArrayLength\"><code>ValkeyModule_ReplySetArrayLength</code></a></li>\n<li><a href=\"#ValkeyModule_ReplySetAttributeLength\"><code>ValkeyModule_ReplySetAttributeLength</code></a></li>\n<li><a href=\"#ValkeyModule_ReplySetMapLength\"><code>ValkeyModule_ReplySetMapLength</code></a></li>\n<li><a href=\"#ValkeyModule_ReplySetSetLength\"><code>ValkeyModule_ReplySetSetLength</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithArray\"><code>ValkeyModule_ReplyWithArray</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithAttribute\"><code>ValkeyModule_ReplyWithAttribute</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithBigNumber\"><code>ValkeyModule_ReplyWithBigNumber</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithBool\"><code>ValkeyModule_ReplyWithBool</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithCString\"><code>ValkeyModule_ReplyWithCString</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithCallReply\"><code>ValkeyModule_ReplyWithCallReply</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithDouble\"><code>ValkeyModule_ReplyWithDouble</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithEmptyArray\"><code>ValkeyModule_ReplyWithEmptyArray</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithEmptyString\"><code>ValkeyModule_ReplyWithEmptyString</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithError\"><code>ValkeyModule_ReplyWithError</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithErrorFormat\"><code>ValkeyModule_ReplyWithErrorFormat</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithLongDouble\"><code>ValkeyModule_ReplyWithLongDouble</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithLongLong\"><code>ValkeyModule_ReplyWithLongLong</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithMap\"><code>ValkeyModule_ReplyWithMap</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithNull\"><code>ValkeyModule_ReplyWithNull</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithNullArray\"><code>ValkeyModule_ReplyWithNullArray</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithSet\"><code>ValkeyModule_ReplyWithSet</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithSimpleString\"><code>ValkeyModule_ReplyWithSimpleString</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithString\"><code>ValkeyModule_ReplyWithString</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithStringBuffer\"><code>ValkeyModule_ReplyWithStringBuffer</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithVerbatimString\"><code>ValkeyModule_ReplyWithVerbatimString</code></a></li>\n<li><a href=\"#ValkeyModule_ReplyWithVerbatimStringType\"><code>ValkeyModule_ReplyWithVerbatimStringType</code></a></li>\n<li><a href=\"#ValkeyModule_ResetDataset\"><code>ValkeyModule_ResetDataset</code></a></li>\n<li><a href=\"#ValkeyModule_RetainString\"><code>ValkeyModule_RetainString</code></a></li>\n<li><a href=\"#ValkeyModule_SaveDataTypeToString\"><code>ValkeyModule_SaveDataTypeToString</code></a></li>\n<li><a href=\"#ValkeyModule_SaveDouble\"><code>ValkeyModule_SaveDouble</code></a></li>\n<li><a href=\"#ValkeyModule_SaveFloat\"><code>ValkeyModule_SaveFloat</code></a></li>\n<li><a href=\"#ValkeyModule_SaveLongDouble\"><code>ValkeyModule_SaveLongDouble</code></a></li>\n<li><a href=\"#ValkeyModule_SaveSigned\"><code>ValkeyModule_SaveSigned</code></a></li>\n<li><a href=\"#ValkeyModule_SaveString\"><code>ValkeyModule_SaveString</code></a></li>\n<li><a href=\"#ValkeyModule_SaveStringBuffer\"><code>ValkeyModule_SaveStringBuffer</code></a></li>\n<li><a href=\"#ValkeyModule_SaveUnsigned\"><code>ValkeyModule_SaveUnsigned</code></a></li>\n<li><a href=\"#ValkeyModule_Scan\"><code>ValkeyModule_Scan</code></a></li>\n<li><a href=\"#ValkeyModule_ScanCursorCreate\"><code>ValkeyModule_ScanCursorCreate</code></a></li>\n<li><a href=\"#ValkeyModule_ScanCursorDestroy\"><code>ValkeyModule_ScanCursorDestroy</code></a></li>\n<li><a href=\"#ValkeyModule_ScanCursorRestart\"><code>ValkeyModule_ScanCursorRestart</code></a></li>\n<li><a href=\"#ValkeyModule_ScanKey\"><code>ValkeyModule_ScanKey</code></a></li>\n<li><a href=\"#ValkeyModule_SelectDb\"><code>ValkeyModule_SelectDb</code></a></li>\n<li><a href=\"#ValkeyModule_SendChildHeartbeat\"><code>ValkeyModule_SendChildHeartbeat</code></a></li>\n<li><a href=\"#ValkeyModule_SendClusterMessage\"><code>ValkeyModule_SendClusterMessage</code></a></li>\n<li><a href=\"#ValkeyModule_ServerInfoGetField\"><code>ValkeyModule_ServerInfoGetField</code></a></li>\n<li><a href=\"#ValkeyModule_ServerInfoGetFieldC\"><code>ValkeyModule_ServerInfoGetFieldC</code></a></li>\n<li><a href=\"#ValkeyModule_ServerInfoGetFieldDouble\"><code>ValkeyModule_ServerInfoGetFieldDouble</code></a></li>\n<li><a href=\"#ValkeyModule_ServerInfoGetFieldSigned\"><code>ValkeyModule_ServerInfoGetFieldSigned</code></a></li>\n<li><a href=\"#ValkeyModule_ServerInfoGetFieldUnsigned\"><code>ValkeyModule_ServerInfoGetFieldUnsigned</code></a></li>\n<li><a href=\"#ValkeyModule_SetAbsExpire\"><code>ValkeyModule_SetAbsExpire</code></a></li>\n<li><a href=\"#ValkeyModule_SetClientNameById\"><code>ValkeyModule_SetClientNameById</code></a></li>\n<li><a href=\"#ValkeyModule_SetClusterFlags\"><code>ValkeyModule_SetClusterFlags</code></a></li>\n<li><a href=\"#ValkeyModule_SetCommandACLCategories\"><code>ValkeyModule_SetCommandACLCategories</code></a></li>\n<li><a href=\"#ValkeyModule_SetCommandInfo\"><code>ValkeyModule_SetCommandInfo</code></a></li>\n<li><a href=\"#ValkeyModule_SetContextUser\"><code>ValkeyModule_SetContextUser</code></a></li>\n<li><a href=\"#ValkeyModule_SetDisconnectCallback\"><code>ValkeyModule_SetDisconnectCallback</code></a></li>\n<li><a href=\"#ValkeyModule_SetExpire\"><code>ValkeyModule_SetExpire</code></a></li>\n<li><a href=\"#ValkeyModule_SetLFU\"><code>ValkeyModule_SetLFU</code></a></li>\n<li><a href=\"#ValkeyModule_SetLRU\"><code>ValkeyModule_SetLRU</code></a></li>\n<li><a href=\"#ValkeyModule_SetModuleOptions\"><code>ValkeyModule_SetModuleOptions</code></a></li>\n<li><a href=\"#ValkeyModule_SetModuleUserACL\"><code>ValkeyModule_SetModuleUserACL</code></a></li>\n<li><a href=\"#ValkeyModule_SetModuleUserACLString\"><code>ValkeyModule_SetModuleUserACLString</code></a></li>\n<li><a href=\"#ValkeyModule_SignalKeyAsReady\"><code>ValkeyModule_SignalKeyAsReady</code></a></li>\n<li><a href=\"#ValkeyModule_SignalModifiedKey\"><code>ValkeyModule_SignalModifiedKey</code></a></li>\n<li><a href=\"#ValkeyModule_StopTimer\"><code>ValkeyModule_StopTimer</code></a></li>\n<li><a href=\"#ValkeyModule_Strdup\"><code>ValkeyModule_Strdup</code></a></li>\n<li><a href=\"#ValkeyModule_StreamAdd\"><code>ValkeyModule_StreamAdd</code></a></li>\n<li><a href=\"#ValkeyModule_StreamDelete\"><code>ValkeyModule_StreamDelete</code></a></li>\n<li><a href=\"#ValkeyModule_StreamIteratorDelete\"><code>ValkeyModule_StreamIteratorDelete</code></a></li>\n<li><a href=\"#ValkeyModule_StreamIteratorNextField\"><code>ValkeyModule_StreamIteratorNextField</code></a></li>\n<li><a href=\"#ValkeyModule_StreamIteratorNextID\"><code>ValkeyModule_StreamIteratorNextID</code></a></li>\n<li><a href=\"#ValkeyModule_StreamIteratorStart\"><code>ValkeyModule_StreamIteratorStart</code></a></li>\n<li><a href=\"#ValkeyModule_StreamIteratorStop\"><code>ValkeyModule_StreamIteratorStop</code></a></li>\n<li><a href=\"#ValkeyModule_StreamTrimByID\"><code>ValkeyModule_StreamTrimByID</code></a></li>\n<li><a href=\"#ValkeyModule_StreamTrimByLength\"><code>ValkeyModule_StreamTrimByLength</code></a></li>\n<li><a href=\"#ValkeyModule_StringAppendBuffer\"><code>ValkeyModule_StringAppendBuffer</code></a></li>\n<li><a href=\"#ValkeyModule_StringCompare\"><code>ValkeyModule_StringCompare</code></a></li>\n<li><a href=\"#ValkeyModule_StringDMA\"><code>ValkeyModule_StringDMA</code></a></li>\n<li><a href=\"#ValkeyModule_StringPtrLen\"><code>ValkeyModule_StringPtrLen</code></a></li>\n<li><a href=\"#ValkeyModule_StringSet\"><code>ValkeyModule_StringSet</code></a></li>\n<li><a href=\"#ValkeyModule_StringToDouble\"><code>ValkeyModule_StringToDouble</code></a></li>\n<li><a href=\"#ValkeyModule_StringToLongDouble\"><code>ValkeyModule_StringToLongDouble</code></a></li>\n<li><a href=\"#ValkeyModule_StringToLongLong\"><code>ValkeyModule_StringToLongLong</code></a></li>\n<li><a href=\"#ValkeyModule_StringToStreamID\"><code>ValkeyModule_StringToStreamID</code></a></li>\n<li><a href=\"#ValkeyModule_StringToULongLong\"><code>ValkeyModule_StringToULongLong</code></a></li>\n<li><a href=\"#ValkeyModule_StringTruncate\"><code>ValkeyModule_StringTruncate</code></a></li>\n<li><a href=\"#ValkeyModule_SubscribeToKeyspaceEvents\"><code>ValkeyModule_SubscribeToKeyspaceEvents</code></a></li>\n<li><a href=\"#ValkeyModule_SubscribeToServerEvent\"><code>ValkeyModule_SubscribeToServerEvent</code></a></li>\n<li><a href=\"#ValkeyModule_ThreadSafeContextLock\"><code>ValkeyModule_ThreadSafeContextLock</code></a></li>\n<li><a href=\"#ValkeyModule_ThreadSafeContextTryLock\"><code>ValkeyModule_ThreadSafeContextTryLock</code></a></li>\n<li><a href=\"#ValkeyModule_ThreadSafeContextUnlock\"><code>ValkeyModule_ThreadSafeContextUnlock</code></a></li>\n<li><a href=\"#ValkeyModule_TrimStringAllocation\"><code>ValkeyModule_TrimStringAllocation</code></a></li>\n<li><a href=\"#ValkeyModule_TryAlloc\"><code>ValkeyModule_TryAlloc</code></a></li>\n<li><a href=\"#ValkeyModule_TryCalloc\"><code>ValkeyModule_TryCalloc</code></a></li>\n<li><a href=\"#ValkeyModule_TryRealloc\"><code>ValkeyModule_TryRealloc</code></a></li>\n<li><a href=\"#ValkeyModule_UnblockClient\"><code>ValkeyModule_UnblockClient</code></a></li>\n<li><a href=\"#ValkeyModule_UnlinkKey\"><code>ValkeyModule_UnlinkKey</code></a></li>\n<li><a href=\"#ValkeyModule_UnregisterCommandFilter\"><code>ValkeyModule_UnregisterCommandFilter</code></a></li>\n<li><a href=\"#ValkeyModule_UnregisterScriptingEngine\"><code>ValkeyModule_UnregisterScriptingEngine</code></a></li>\n<li><a href=\"#ValkeyModule_UpdateRuntimeArgs\"><code>ValkeyModule_UpdateRuntimeArgs</code></a></li>\n<li><a href=\"#ValkeyModule_ValueLength\"><code>ValkeyModule_ValueLength</code></a></li>\n<li><a href=\"#ValkeyModule_WrongArity\"><code>ValkeyModule_WrongArity</code></a></li>\n<li><a href=\"#ValkeyModule_Yield\"><code>ValkeyModule_Yield</code></a></li>\n<li><a href=\"#ValkeyModule_ZsetAdd\"><code>ValkeyModule_ZsetAdd</code></a></li>\n<li><a href=\"#ValkeyModule_ZsetFirstInLexRange\"><code>ValkeyModule_ZsetFirstInLexRange</code></a></li>\n<li><a href=\"#ValkeyModule_ZsetFirstInScoreRange\"><code>ValkeyModule_ZsetFirstInScoreRange</code></a></li>\n<li><a href=\"#ValkeyModule_ZsetIncrby\"><code>ValkeyModule_ZsetIncrby</code></a></li>\n<li><a href=\"#ValkeyModule_ZsetLastInLexRange\"><code>ValkeyModule_ZsetLastInLexRange</code></a></li>\n<li><a href=\"#ValkeyModule_ZsetLastInScoreRange\"><code>ValkeyModule_ZsetLastInScoreRange</code></a></li>\n<li><a href=\"#ValkeyModule_ZsetRangeCurrentElement\"><code>ValkeyModule_ZsetRangeCurrentElement</code></a></li>\n<li><a href=\"#ValkeyModule_ZsetRangeEndReached\"><code>ValkeyModule_ZsetRangeEndReached</code></a></li>\n<li><a href=\"#ValkeyModule_ZsetRangeNext\"><code>ValkeyModule_ZsetRangeNext</code></a></li>\n<li><a href=\"#ValkeyModule_ZsetRangePrev\"><code>ValkeyModule_ZsetRangePrev</code></a></li>\n<li><a href=\"#ValkeyModule_ZsetRangeStop\"><code>ValkeyModule_ZsetRangeStop</code></a></li>\n<li><a href=\"#ValkeyModule_ZsetRem\"><code>ValkeyModule_ZsetRem</code></a></li>\n<li><a href=\"#ValkeyModule_ZsetScore\"><code>ValkeyModule_ZsetScore</code></a></li>\n<li><a href=\"#ValkeyModule__Assert\"><code>ValkeyModule__Assert</code></a></li>\n</ul>\n"
      },
      {
        "id": "modules-blocking-ops",
        "topicName": "Modules and blocking commands",
        "description": "How to implement blocking commands in a Valkey module\n",
        "htmlContent": "<p>Valkey has a few blocking commands among the built-in set of commands.<br>One of the most used is <code>BLPOP</code> (or the symmetric <code>BRPOP</code>) which blocks<br>waiting for elements arriving in a list.</p>\n<p>The interesting fact about blocking commands is that they do not block<br>the whole server, but just the client calling them. Usually the reason to<br>block is that we expect some external event to happen: this can be<br>some change in the Valkey data structures like in the <code>BLPOP</code> case, a<br>long computation happening in a thread, to receive some data from the<br>network, and so forth.</p>\n<p>Valkey modules have the ability to implement blocking commands as well,<br>this documentation shows how the API works and describes a few patterns<br>that can be used in order to model blocking commands.</p>\n<h2>How blocking and resuming works.</h2>\n<p><strong>Note:</strong> You may want to check the <code>helloblock.c</code> example in the Valkey source tree<br>inside the <code>src/modules</code> directory, for a simple to understand example<br>on how the blocking API is applied.</p>\n<p>In Valkey modules, commands are implemented by callback functions that<br>are invoked by the Valkey core when the specific command is called<br>by the user. Normally the callback terminates its execution sending<br>some reply to the client. Using the following function instead, the<br>function implementing the module command may request that the client<br>is put into the blocked state:</p>\n<pre><code class=\"language-C\">ValkeyModuleBlockedClient *ValkeyModule_BlockClient(ValkeyModuleCtx *ctx,\n                                                    ValkeyModuleCmdFunc reply_callback,\n                                                    ValkeyModuleCmdFunc timeout_callback,\n                                                    void (*free_privdata)(void*),\n                                                    long long timeout_ms);\n</code></pre>\n<p>The function returns a <code>ValkeyModuleBlockedClient</code> object, which is later<br>used in order to unblock the client. The arguments have the following<br>meaning:</p>\n<ul>\n<li><code>ctx</code> is the command execution context as usually in the rest of the API.</li>\n<li><code>reply_callback</code> is the callback, having the same prototype of a normal command function, that is called when the client is unblocked in order to return a reply to the client.</li>\n<li><code>timeout_callback</code> is the callback, having the same prototype of a normal command function that is called when the client reached the <code>ms</code> timeout.</li>\n<li><code>free_privdata</code> is the callback that is called in order to free the private data. Private data is a pointer to some data that is passed between the API used to unblock the client, to the callback that will send the reply to the client. We&#39;ll see how this mechanism works later in this document.</li>\n<li><code>ms</code> is the timeout in milliseconds. When the timeout is reached, the timeout callback is called and the client is automatically aborted.</li>\n</ul>\n<p>Once a client is blocked, it can be unblocked with the following API:</p>\n<pre><code class=\"language-C\">int ValkeyModule_UnblockClient(ValkeyModuleBlockedClient *bc, void *privdata);\n</code></pre>\n<p>The function takes as argument the blocked client object returned by<br>the previous call to <code>ValkeyModule_BlockClient()</code>, and unblock the client.<br>Immediately before the client gets unblocked, the <code>reply_callback</code> function<br>specified when the client was blocked is called: this function will<br>have access to the <code>privdata</code> pointer used here.</p>\n<p>IMPORTANT: The above function is thread safe, and can be called from within<br>a thread doing some work in order to implement the command that blocked<br>the client.</p>\n<p>The <code>privdata</code> data will be freed automatically using the <code>free_privdata</code><br>callback when the client is unblocked. This is useful <strong>since the reply<br>callback may never be called</strong> in case the client timeouts or disconnects<br>from the server, so it&#39;s important that it&#39;s up to an external function<br>to have the responsibility to free the data passed if needed.</p>\n<p>To better understand how the API works, we can imagine writing a command<br>that blocks a client for one second, and then send as reply &quot;Hello!&quot;.</p>\n<p>Note: arity checks and other non important things are not implemented<br>int his command, in order to take the example simple.</p>\n<pre><code class=\"language-C\">int Example_ValkeyCommand(ValkeyModuleCtx *ctx, ValkeyModuleString **argv,\n                         int argc)\n{\n    ValkeyModuleBlockedClient *bc =\n        ValkeyModule_BlockClient(ctx,reply_func,timeout_func,NULL,0);\n\n    pthread_t tid;\n    pthread_create(&amp;tid,NULL,threadmain,bc);\n\n    return VALKEYMODULE_OK;\n}\n\nvoid *threadmain(void *arg) {\n    ValkeyModuleBlockedClient *bc = arg;\n\n    sleep(1); /* Wait one second and unblock. */\n    ValkeyModule_UnblockClient(bc,NULL);\n}\n</code></pre>\n<p>The above command blocks the client ASAP, spawning a thread that will<br>wait a second and will unblock the client. Let&#39;s check the reply and<br>timeout callbacks, which are in our case very similar, since they<br>just reply the client with a different reply type.</p>\n<pre><code class=\"language-C\">int reply_func(ValkeyModuleCtx *ctx, ValkeyModuleString **argv,\n               int argc)\n{\n    return ValkeyModule_ReplyWithSimpleString(ctx,&quot;Hello!&quot;);\n}\n\nint timeout_func(ValkeyModuleCtx *ctx, ValkeyModuleString **argv,\n               int argc)\n{\n    return ValkeyModule_ReplyWithNull(ctx);\n}\n</code></pre>\n<p>The reply callback just sends the &quot;Hello!&quot; string to the client.<br>The important bit here is that the reply callback is called when the<br>client is unblocked from the thread.</p>\n<p>The timeout command returns <code>NULL</code>, as it often happens with actual<br>Valkey blocking commands timing out.</p>\n<h2>Passing reply data when unblocking</h2>\n<p>The above example is simple to understand but lacks an important<br>real world aspect of an actual blocking command implementation: often<br>the reply function will need to know what to reply to the client,<br>and this information is often provided as the client is unblocked.</p>\n<p>We could modify the above example so that the thread generates a<br>random number after waiting one second. You can think at it as an<br>actually expansive operation of some kind. Then this random number<br>can be passed to the reply function so that we return it to the command<br>caller. In order to make this working, we modify the functions as follow:</p>\n<pre><code class=\"language-C\">void *threadmain(void *arg) {\n    ValkeyModuleBlockedClient *bc = arg;\n\n    sleep(1); /* Wait one second and unblock. */\n\n    long *mynumber = ValkeyModule_Alloc(sizeof(long));\n    *mynumber = rand();\n    ValkeyModule_UnblockClient(bc,mynumber);\n}\n</code></pre>\n<p>As you can see, now the unblocking call is passing some private data,<br>that is the <code>mynumber</code> pointer, to the reply callback. In order to<br>obtain this private data, the reply callback will use the following<br>function:</p>\n<pre><code class=\"language-C\">void *ValkeyModule_GetBlockedClientPrivateData(ValkeyModuleCtx *ctx);\n</code></pre>\n<p>So our reply callback is modified like that:</p>\n<pre><code class=\"language-C\">int reply_func(ValkeyModuleCtx *ctx, ValkeyModuleString **argv,\n               int argc)\n{\n    long *mynumber = ValkeyModule_GetBlockedClientPrivateData(ctx);\n    /* IMPORTANT: don&#39;t free mynumber here, but in the\n     * free privdata callback. */\n    return ValkeyModule_ReplyWithLongLong(ctx,mynumber);\n}\n</code></pre>\n<p>Note that we also need to pass a <code>free_privdata</code> function when blocking<br>the client with <code>ValkeyModule_BlockClient()</code>, since the allocated<br>long value must be freed. Our callback will look like the following:</p>\n<pre><code class=\"language-C\">void free_privdata(void *privdata) {\n    ValkeyModule_Free(privdata);\n}\n</code></pre>\n<p>NOTE: It is important to stress that the private data is best freed in the<br><code>free_privdata</code> callback because the reply function may not be called<br>if the client disconnects or timeout.</p>\n<p>Also note that the private data is also accessible from the timeout<br>callback, always using the <code>GetBlockedClientPrivateData()</code> API.</p>\n<h2>Aborting the blocking of a client</h2>\n<p>One problem that sometimes arises is that we need to allocate resources<br>in order to implement the non blocking command. So we block the client,<br>then, for example, try to create a thread, but the thread creation function<br>returns an error. What to do in such a condition in order to recover? We<br>don&#39;t want to take the client blocked, nor we want to call <code>UnblockClient()</code><br>because this will trigger the reply callback to be called.</p>\n<p>In this case the best thing to do is to use the following function:</p>\n<pre><code class=\"language-C\">int ValkeyModule_AbortBlock(ValkeyModuleBlockedClient *bc);\n</code></pre>\n<p>Practically this is how to use it:</p>\n<pre><code class=\"language-C\">int Example_ValkeyCommand(ValkeyModuleCtx *ctx, ValkeyModuleString **argv,\n                         int argc)\n{\n    ValkeyModuleBlockedClient *bc =\n        ValkeyModule_BlockClient(ctx,reply_func,timeout_func,NULL,0);\n\n    pthread_t tid;\n    if (pthread_create(&amp;tid,NULL,threadmain,bc) != 0) {\n        ValkeyModule_AbortBlock(bc);\n        ValkeyModule_ReplyWithError(ctx,&quot;Sorry can&#39;t create a thread&quot;);\n    }\n\n    return VALKEYMODULE_OK;\n}\n</code></pre>\n<p>The client will be unblocked but the reply callback will not be called.</p>\n<h2>Implementing the command, reply and timeout callback using a single function</h2>\n<p>The following functions can be used in order to implement the reply and<br>callback with the same function that implements the primary command<br>function:</p>\n<pre><code class=\"language-C\">int ValkeyModule_IsBlockedReplyRequest(ValkeyModuleCtx *ctx);\nint ValkeyModule_IsBlockedTimeoutRequest(ValkeyModuleCtx *ctx);\n</code></pre>\n<p>So I could rewrite the example command without using a separated<br>reply and timeout callback:</p>\n<pre><code class=\"language-C\">int Example_ValkeyCommand(ValkeyModuleCtx *ctx, ValkeyModuleString **argv,\n                         int argc)\n{\n    if (ValkeyModule_IsBlockedReplyRequest(ctx)) {\n        long *mynumber = ValkeyModule_GetBlockedClientPrivateData(ctx);\n        return ValkeyModule_ReplyWithLongLong(ctx,mynumber);\n    } else if (ValkeyModule_IsBlockedTimeoutRequest) {\n        return ValkeyModule_ReplyWithNull(ctx);\n    }\n\n    ValkeyModuleBlockedClient *bc =\n        ValkeyModule_BlockClient(ctx,reply_func,timeout_func,NULL,0);\n\n    pthread_t tid;\n    if (pthread_create(&amp;tid,NULL,threadmain,bc) != 0) {\n        ValkeyModule_AbortBlock(bc);\n        ValkeyModule_ReplyWithError(ctx,&quot;Sorry can&#39;t create a thread&quot;);\n    }\n\n    return VALKEYMODULE_OK;\n}\n</code></pre>\n<p>Functionally is the same but there are people that will prefer the less<br>verbose implementation that concentrates most of the command logic in a<br>single function.</p>\n<h2>Working on copies of data inside a thread</h2>\n<p>An interesting pattern in order to work with threads implementing the<br>slow part of a command, is to work with a copy of the data, so that<br>while some operation is performed in a key, the user continues to see<br>the old version. However when the thread terminated its work, the<br>representations are swapped and the new, processed version, is used.</p>\n<p>An example of this approach is the<br><a href=\"https://github.com/antirez/neural-redis\">Neural Redis module</a><br>where neural networks are trained in different threads while the<br>user can still execute and inspect their older versions.</p>\n<h2>Thread safe contexts</h2>\n<p>See <a href=\"modules-api-ref#section-thread-safe-contexts\">Thread Safe Contexts</a> in<br>the Modules API reference for how Valkey modules APIs can be called in a safe<br>way from threads.</p>\n"
      },
      {
        "id": "modules-intro",
        "topicName": "Modules API",
        "description": "Introduction to writing Valkey modules\n",
        "htmlContent": "<p>The modules documentation is composed of the following pages:</p>\n<ul>\n<li>Introduction to Valkey modules (this file). An overview about Valkey Modules system and API. It&#39;s a good idea to start your reading here.</li>\n<li><a href=\"modules-native-types\">Implementing native data types</a> covers the implementation of native data types into modules.</li>\n<li><a href=\"modules-blocking-ops\">Blocking operations</a> shows how to write blocking commands that will not reply immediately, but will block the client, without blocking the Valkey server, and will provide a reply whenever will be possible.</li>\n<li><a href=\"modules-api-ref\">Valkey modules API reference</a> is generated from module.c top comments of ValkeyModule functions. It is a good reference in order to understand how each function works.</li>\n</ul>\n<p>Valkey modules make it possible to extend Valkey functionality using external<br>modules, rapidly implementing new Valkey commands with features<br>similar to what can be done inside the core itself.</p>\n<p>Valkey modules are dynamic libraries that can be loaded into Valkey at<br>startup, or using the <code>MODULE LOAD</code> command. Valkey exports a C API, in the<br>form of a single C header file called <code>valkeymodule.h</code>. Modules are meant<br>to be written in C, however it will be possible to use C++ or other languages<br>that have C binding functionalities.</p>\n<p>Modules are designed in order to be loaded into different versions of Valkey,<br>so a given module does not need to be designed, or recompiled, in order to<br>run with a specific version of Valkey. For this reason, the module will<br>register to the Valkey core using a specific API version. The current API<br>version is &quot;1&quot;.</p>\n<h2>Loading modules</h2>\n<p>In order to test the module you are developing, you can load the module<br>using the following <code>valkey.conf</code> configuration directive:</p>\n<pre><code>loadmodule /path/to/mymodule.so\n</code></pre>\n<p>It is also possible to load a module at runtime using the following command:</p>\n<pre><code>MODULE LOAD /path/to/mymodule.so\n</code></pre>\n<p>In order to list all loaded modules, use:</p>\n<pre><code>MODULE LIST\n</code></pre>\n<p>Finally, you can unload (and later reload if you wish) a module using the<br>following command:</p>\n<pre><code>MODULE UNLOAD mymodule\n</code></pre>\n<p>Note that <code>mymodule</code> above is not the filename without the <code>.so</code> suffix, but<br>instead, the name the module used to register itself into the Valkey core.<br>The name can be obtained using <code>MODULE LIST</code>. However it is good practice<br>that the filename of the dynamic library is the same as the name the module<br>uses to register itself into the Valkey core.</p>\n<h2>The simplest module you can write</h2>\n<p>In order to show the different parts of a module, here we&#39;ll show a very<br>simple module that implements a command that outputs a random number.</p>\n<pre><code class=\"language-C\">#include &quot;valkeymodule.h&quot;\n#include &lt;stdlib.h&gt;\n\nint HelloworldRand_ValkeyCommand(ValkeyModuleCtx *ctx, ValkeyModuleString **argv, int argc) {\n    ValkeyModule_ReplyWithLongLong(ctx,rand());\n    return VALKEYMODULE_OK;\n}\n\nint ValkeyModule_OnLoad(ValkeyModuleCtx *ctx, ValkeyModuleString **argv, int argc) {\n    if (ValkeyModule_Init(ctx,&quot;helloworld&quot;,1,VALKEYMODULE_APIVER_1)\n        == VALKEYMODULE_ERR) return VALKEYMODULE_ERR;\n\n    if (ValkeyModule_CreateCommand(ctx,&quot;helloworld.rand&quot;,\n        HelloworldRand_ValkeyCommand, &quot;fast random&quot;,\n        0, 0, 0) == VALKEYMODULE_ERR)\n        return VALKEYMODULE_ERR;\n\n    return VALKEYMODULE_OK;\n}\n</code></pre>\n<p>The example module has two functions. One implements a command called<br>HELLOWORLD.RAND. This function is specific of that module. However the<br>other function called <code>ValkeyModule_OnLoad()</code> must be present in each<br>Valkey module. It is the entry point for the module to be initialized,<br>register its commands, and potentially other private data structures<br>it uses.</p>\n<p>Note that it is a good idea for modules to call commands with the<br>name of the module followed by a dot, and finally the command name,<br>like in the case of <code>HELLOWORLD.RAND</code>. This way it is less likely to<br>have collisions.</p>\n<p>Note that if different modules have colliding commands, they&#39;ll not be<br>able to work in Valkey at the same time, since the function<br><code>ValkeyModule_CreateCommand</code> will fail in one of the modules, so the module<br>loading will abort returning an error condition.</p>\n<h2>Module initialization</h2>\n<p>The above example shows the usage of the function <code>ValkeyModule_Init()</code>.<br>It should be the first function called by the module <code>OnLoad</code> function.<br>The following is the function prototype:</p>\n<pre><code class=\"language-C\">int ValkeyModule_Init(ValkeyModuleCtx *ctx, const char *modulename,\n                     int module_version, int api_version);\n</code></pre>\n<p>The <code>Init</code> function announces the Valkey core that the module has a given<br>name, its version (that is reported by <code>MODULE LIST</code>), and that is willing<br>to use a specific version of the API.</p>\n<p>If the API version is wrong, the name is already taken, or there are other<br>similar errors, the function will return <code>VALKEYMODULE_ERR</code>, and the module<br><code>OnLoad</code> function should return ASAP with an error.</p>\n<p>Before the <code>Init</code> function is called, no other API function can be called,<br>otherwise the module will segfault and the Valkey instance will crash.</p>\n<p>The second function called, <code>ValkeyModule_CreateCommand</code>, is used in order<br>to register commands into the Valkey core. The following is the prototype:</p>\n<pre><code class=\"language-C\">int ValkeyModule_CreateCommand(ValkeyModuleCtx *ctx, const char *name,\n                              ValkeyModuleCmdFunc cmdfunc, const char *strflags,\n                              int firstkey, int lastkey, int keystep);\n</code></pre>\n<p>As you can see, most Valkey modules API calls all take as first argument<br>the <code>context</code> of the module, so that they have a reference to the module<br>calling it, to the command and client executing a given command, and so forth.</p>\n<p>To create a new command, the above function needs the context, the command&#39;s<br>name, a pointer to the function implementing the command, the command&#39;s flags<br>and the positions of key names in the command&#39;s arguments.</p>\n<p>The function that implements the command must have the following prototype:</p>\n<pre><code class=\"language-C\">int mycommand(ValkeyModuleCtx *ctx, ValkeyModuleString **argv, int argc);\n</code></pre>\n<p>The command function arguments are just the context, that will be passed<br>to all the other API calls, the command argument vector, and total number<br>of arguments, as passed by the user.</p>\n<p>As you can see, the arguments are provided as pointers to a specific data<br>type, the <code>ValkeyModuleString</code>. This is an opaque data type you have API<br>functions to access and use, direct access to its fields is never needed.</p>\n<p>Zooming into the example command implementation, we can find another call:</p>\n<pre><code class=\"language-C\">int ValkeyModule_ReplyWithLongLong(ValkeyModuleCtx *ctx, long long integer);\n</code></pre>\n<p>This function returns an integer to the client that invoked the command,<br>exactly like other Valkey commands do, like for example <code>INCR</code> or <code>SCARD</code>.</p>\n<h2>Module cleanup</h2>\n<p>In most cases, there is no need for special cleanup.<br>When a module is unloaded, Valkey will automatically unregister commands and<br>unsubscribe from notifications.<br>However in the case where a module contains some persistent memory or<br>configuration, a module may include an optional <code>ValkeyModule_OnUnload</code><br>function.<br>If a module provides this function, it will be invoked during the module unload<br>process.<br>The following is the function prototype:</p>\n<pre><code class=\"language-C\">int ValkeyModule_OnUnload(ValkeyModuleCtx *ctx);\n</code></pre>\n<p>The <code>OnUnload</code> function may prevent module unloading by returning<br><code>VALKEYMODULE_ERR</code>.<br>Otherwise, <code>VALKEYMODULE_OK</code> should be returned.</p>\n<h2>Setup and dependencies of a Valkey module</h2>\n<p>Valkey modules don&#39;t depend on Valkey or some other library, nor they<br>need to be compiled with a specific <code>valkeymodule.h</code> file. In order<br>to create a new module, just copy a recent version of <code>valkeymodule.h</code><br>in your source tree, link all the libraries you want, and create<br>a dynamic library having the <code>ValkeyModule_OnLoad()</code> function symbol<br>exported.</p>\n<p>The module will be able to load into different versions of Valkey.</p>\n<p>A module can be designed to support both newer and older Redis OSS versions where certain API functions are not available in all versions.<br>If an API function is not implemented in the currently running Redis OSS version, the function pointer is set to NULL.<br>This allows the module to check if a function exists before using it:</p>\n<pre><code class=\"language-C\">if (ValkeyModule_SetCommandInfo != NULL) {\n    ValkeyModule_SetCommandInfo(cmd, &amp;info);\n}\n</code></pre>\n<p>In recent versions of <code>valkeymodule.h</code>, a convenience macro <code>RMAPI_FUNC_SUPPORTED(funcname)</code> is defined.<br>Using the macro or just comparing with NULL is a matter of personal preference.</p>\n<h1>Passing configuration parameters to Valkey modules</h1>\n<p>When the module is loaded with the <code>MODULE LOAD</code> command, or using the<br><code>loadmodule</code> directive in the <code>valkey.conf</code> file, the user is able to pass<br>configuration parameters to the module by adding arguments after the module<br>file name:</p>\n<pre><code>loadmodule mymodule.so foo bar 1234\n</code></pre>\n<p>In the above example the strings <code>foo</code>, <code>bar</code> and <code>1234</code> will be passed<br>to the module <code>OnLoad()</code> function in the <code>argv</code> argument as an array<br>of ValkeyModuleString pointers. The number of arguments passed is into <code>argc</code>.</p>\n<p>The way you can access those strings will be explained in the rest of this<br>document. Normally the module will store the module configuration parameters<br>in some <code>static</code> global variable that can be accessed module wide, so that<br>the configuration can change the behavior of different commands.</p>\n<h2>Working with ValkeyModuleString objects</h2>\n<p>The command argument vector <code>argv</code> passed to module commands, and the<br>return value of other module APIs functions, are of type <code>ValkeyModuleString</code>.</p>\n<p>Usually you directly pass module strings to other API calls, however sometimes<br>you may need to directly access the string object.</p>\n<p>There are a few functions in order to work with string objects:</p>\n<pre><code class=\"language-C\">const char *ValkeyModule_StringPtrLen(ValkeyModuleString *string, size_t *len);\n</code></pre>\n<p>The above function accesses a string by returning its pointer and setting its<br>length in <code>len</code>.<br>You should never write to a string object pointer, as you can see from the<br><code>const</code> pointer qualifier.</p>\n<p>However, if you want, you can create new string objects using the following<br>API:</p>\n<pre><code class=\"language-C\">ValkeyModuleString *ValkeyModule_CreateString(ValkeyModuleCtx *ctx, const char *ptr, size_t len);\n</code></pre>\n<p>The string returned by the above command must be freed using a corresponding<br>call to <code>ValkeyModule_FreeString()</code>:</p>\n<pre><code class=\"language-C\">void ValkeyModule_FreeString(ValkeyModuleString *str);\n</code></pre>\n<p>However if you want to avoid having to free strings, the automatic memory<br>management, covered later in this document, can be a good alternative, by<br>doing it for you.</p>\n<p>Note that the strings provided via the argument vector <code>argv</code> never need<br>to be freed. You only need to free new strings you create, or new strings<br>returned by other APIs, where it is specified that the returned string must<br>be freed.</p>\n<h2>Creating strings from numbers or parsing strings as numbers</h2>\n<p>Creating a new string from an integer is a very common operation, so there<br>is a function to do this:</p>\n<pre><code class=\"language-C\">ValkeyModuleString *mystr = ValkeyModule_CreateStringFromLongLong(ctx,10);\n</code></pre>\n<p>Similarly in order to parse a string as a number:</p>\n<pre><code class=\"language-C\">long long myval;\nif (ValkeyModule_StringToLongLong(ctx,argv[1],&amp;myval) == VALKEYMODULE_OK) {\n    /* Do something with &#39;myval&#39; */\n}\n</code></pre>\n<h2>Accessing Valkey keys from modules</h2>\n<p>Most Valkey modules, in order to be useful, have to interact with the Valkey<br>data space (this is not always true, for example an ID generator may<br>never touch Valkey keys). Valkey modules have two different APIs in order to<br>access the Valkey data space, one is a low level API that provides very<br>fast access and a set of functions to manipulate Valkey data structures.<br>The other API is more high level, and allows to call Valkey commands and<br>fetch the result, similarly to how Lua scripts access Valkey.</p>\n<p>The high level API is also useful in order to access Valkey functionalities<br>that are not available as APIs.</p>\n<p>In general modules developers should prefer the low level API, because commands<br>implemented using the low level API run at a speed comparable to the speed<br>of native Valkey commands. However there are definitely use cases for the<br>higher level API. For example often the bottleneck could be processing the<br>data and not accessing it.</p>\n<p>Also note that sometimes using the low level API is not harder compared to<br>the higher level one.</p>\n<h2>Calling Valkey commands</h2>\n<p>The high level API to access Valkey is the sum of the <code>ValkeyModule_Call()</code><br>function, together with the functions needed in order to access the<br>reply object returned by <code>Call()</code>.</p>\n<p><code>ValkeyModule_Call</code> uses a special calling convention, with a format specifier<br>that is used to specify what kind of objects you are passing as arguments<br>to the function.</p>\n<p>Valkey commands are invoked just using a command name and a list of arguments.<br>However when calling commands, the arguments may originate from different<br>kind of strings: null-terminated C strings, ValkeyModuleString objects as<br>received from the <code>argv</code> parameter in the command implementation, binary<br>safe C buffers with a pointer and a length, and so forth.</p>\n<p>For example if I want to call <code>INCRBY</code> using a first argument (the key)<br>a string received in the argument vector <code>argv</code>, which is an array<br>of ValkeyModuleString object pointers, and a C string representing the<br>number &quot;10&quot; as second argument (the increment), I&#39;ll use the following<br>function call:</p>\n<pre><code class=\"language-C\">ValkeyModuleCallReply *reply;\nreply = ValkeyModule_Call(ctx,&quot;INCRBY&quot;,&quot;sc&quot;,argv[1],&quot;10&quot;);\n</code></pre>\n<p>The first argument is the context, and the second is always a null terminated<br>C string with the command name. The third argument is the format specifier<br>where each character corresponds to the type of the arguments that will follow.<br>In the above case <code>&quot;sc&quot;</code> means a ValkeyModuleString object, and a null<br>terminated C string. The other arguments are just the two arguments as<br>specified. In fact <code>argv[1]</code> is a ValkeyModuleString and <code>&quot;10&quot;</code> is a null<br>terminated C string.</p>\n<p>This is the full list of format specifiers:</p>\n<ul>\n<li><strong>c</strong> -- Null terminated C string pointer.</li>\n<li><strong>b</strong> -- C buffer, two arguments needed: C string pointer and <code>size_t</code> length.</li>\n<li><strong>s</strong> -- ValkeyModuleString as received in <code>argv</code> or by other Valkey module APIs returning a ValkeyModuleString object.</li>\n<li><strong>l</strong> -- Long long integer.</li>\n<li><strong>v</strong> -- Array of ValkeyModuleString objects.</li>\n<li><strong>!</strong> -- This modifier just tells the function to replicate the command to replicas and AOF. It is ignored from the point of view of arguments parsing.</li>\n<li><strong>A</strong> -- This modifier, when <code>!</code> is given, tells to suppress AOF propagation: the command will be propagated only to replicas.</li>\n<li><strong>R</strong> -- This modifier, when <code>!</code> is given, tells to suppress replicas propagation: the command will be propagated only to the AOF if enabled.</li>\n</ul>\n<p>The function returns a <code>ValkeyModuleCallReply</code> object on success, on<br>error NULL is returned.</p>\n<p>NULL is returned when the command name is invalid, the format specifier uses<br>characters that are not recognized, or when the command is called with the<br>wrong number of arguments. In the above cases the <code>errno</code> var is set to <code>EINVAL</code>. NULL is also returned when, in an instance with Cluster enabled, the target<br>keys are about non local hash slots. In this case <code>errno</code> is set to <code>EPERM</code>.</p>\n<h2>Working with ValkeyModuleCallReply objects.</h2>\n<p><code>ValkeyModuleCall</code> returns reply objects that can be accessed using the<br><code>ValkeyModule_CallReply*</code> family of functions.</p>\n<p>In order to obtain the type or reply (corresponding to one of the data types<br>supported by the Valkey protocol), the function <code>ValkeyModule_CallReplyType()</code><br>is used:</p>\n<pre><code class=\"language-C\">reply = ValkeyModule_Call(ctx,&quot;INCRBY&quot;,&quot;sc&quot;,argv[1],&quot;10&quot;);\nif (ValkeyModule_CallReplyType(reply) == VALKEYMODULE_REPLY_INTEGER) {\n    long long myval = ValkeyModule_CallReplyInteger(reply);\n    /* Do something with myval. */\n}\n</code></pre>\n<p>Valid reply types are:</p>\n<ul>\n<li><code>VALKEYMODULE_REPLY_STRING</code> Bulk string or status replies.</li>\n<li><code>VALKEYMODULE_REPLY_ERROR</code> Errors.</li>\n<li><code>VALKEYMODULE_REPLY_INTEGER</code> Signed 64 bit integers.</li>\n<li><code>VALKEYMODULE_REPLY_ARRAY</code> Array of replies.</li>\n<li><code>VALKEYMODULE_REPLY_NULL</code> NULL reply.</li>\n</ul>\n<p>Strings, errors and arrays have an associated length. For strings and errors<br>the length corresponds to the length of the string. For arrays the length<br>is the number of elements. To obtain the reply length the following function<br>is used:</p>\n<pre><code class=\"language-C\">size_t reply_len = ValkeyModule_CallReplyLength(reply);\n</code></pre>\n<p>In order to obtain the value of an integer reply, the following function is used, as already shown in the example above:</p>\n<pre><code class=\"language-C\">long long reply_integer_val = ValkeyModule_CallReplyInteger(reply);\n</code></pre>\n<p>Called with a reply object of the wrong type, the above function always<br>returns <code>LLONG_MIN</code>.</p>\n<p>Sub elements of array replies are accessed this way:</p>\n<pre><code class=\"language-C\">ValkeyModuleCallReply *subreply;\nsubreply = ValkeyModule_CallReplyArrayElement(reply,idx);\n</code></pre>\n<p>The above function returns NULL if you try to access out of range elements.</p>\n<p>Strings and errors (which are like strings but with a different type) can<br>be accessed using in the following way, making sure to never write to<br>the resulting pointer (that is returned as a <code>const</code> pointer so that<br>misusing must be pretty explicit):</p>\n<pre><code class=\"language-C\">size_t len;\nchar *ptr = ValkeyModule_CallReplyStringPtr(reply,&amp;len);\n</code></pre>\n<p>If the reply type is not a string or an error, NULL is returned.</p>\n<p>ValkeyCallReply objects are not the same as module string objects<br>(ValkeyModuleString types). However sometimes you may need to pass replies<br>of type string or integer, to API functions expecting a module string.</p>\n<p>When this is the case, you may want to evaluate if using the low level<br>API could be a simpler way to implement your command, or you can use<br>the following function in order to create a new string object from a<br>call reply of type string, error or integer:</p>\n<pre><code class=\"language-C\">ValkeyModuleString *mystr = ValkeyModule_CreateStringFromCallReply(myreply);\n</code></pre>\n<p>If the reply is not of the right type, NULL is returned.<br>The returned string object should be released with <code>ValkeyModule_FreeString()</code><br>as usually, or by enabling automatic memory management (see corresponding<br>section).</p>\n<h2>Releasing call reply objects</h2>\n<p>Reply objects must be freed using <code>ValkeyModule_FreeCallReply</code>. For arrays,<br>you need to free only the top level reply, not the nested replies.<br>Currently the module implementation provides a protection in order to avoid<br>crashing if you free a nested reply object for error, however this feature<br>is not guaranteed to be here forever, so should not be considered part<br>of the API.</p>\n<p>If you use automatic memory management (explained later in this document)<br>you don&#39;t need to free replies (but you still could if you wish to release<br>memory ASAP).</p>\n<h2>Returning values from Valkey commands</h2>\n<p>Like normal Valkey commands, new commands implemented via modules must be<br>able to return values to the caller. The API exports a set of functions for<br>this goal, in order to return the usual types of the Valkey protocol, and<br>arrays of such types as elements. Also errors can be returned with any<br>error string and code (the error code is the initial uppercase letters in<br>the error message, like the &quot;BUSY&quot; string in the &quot;BUSY the sever is busy&quot; error<br>message).</p>\n<p>All the functions to send a reply to the client are called<br><code>ValkeyModule_ReplyWith&lt;something&gt;</code>.</p>\n<p>To return an error, use:</p>\n<pre><code class=\"language-C\">ValkeyModule_ReplyWithError(ValkeyModuleCtx *ctx, const char *err);\n</code></pre>\n<p>There is a predefined error string for key of wrong type errors:</p>\n<pre><code>VALKEYMODULE_ERRORMSG_WRONGTYPE\n</code></pre>\n<p>Example usage:</p>\n<pre><code class=\"language-C\">ValkeyModule_ReplyWithError(ctx,&quot;ERR invalid arguments&quot;);\n</code></pre>\n<p>We already saw how to reply with a <code>long long</code> in the examples above:</p>\n<pre><code class=\"language-C\">ValkeyModule_ReplyWithLongLong(ctx,12345);\n</code></pre>\n<p>To reply with a simple string, that can&#39;t contain binary values or newlines,<br>(so it&#39;s suitable to send small words, like &quot;OK&quot;) we use:</p>\n<pre><code class=\"language-C\">ValkeyModule_ReplyWithSimpleString(ctx,&quot;OK&quot;);\n</code></pre>\n<p>It&#39;s possible to reply with &quot;bulk strings&quot; that are binary safe, using<br>two different functions:</p>\n<pre><code class=\"language-C\">int ValkeyModule_ReplyWithStringBuffer(ValkeyModuleCtx *ctx, const char *buf, size_t len);\n\nint ValkeyModule_ReplyWithString(ValkeyModuleCtx *ctx, ValkeyModuleString *str);\n</code></pre>\n<p>The first function gets a C pointer and length. The second a ValkeyModuleString<br>object. Use one or the other depending on the source type you have at hand.</p>\n<p>In order to reply with an array, you just need to use a function to emit the<br>array length, followed by as many calls to the above functions as the number<br>of elements of the array are:</p>\n<pre><code class=\"language-C\">ValkeyModule_ReplyWithArray(ctx,2);\nValkeyModule_ReplyWithStringBuffer(ctx,&quot;age&quot;,3);\nValkeyModule_ReplyWithLongLong(ctx,22);\n</code></pre>\n<p>To return nested arrays is easy, your nested array element just uses another<br>call to <code>ValkeyModule_ReplyWithArray()</code> followed by the calls to emit the<br>sub array elements.</p>\n<h2>Returning arrays with dynamic length</h2>\n<p>Sometimes it is not possible to know beforehand the number of items of<br>an array. As an example, think of a Valkey module implementing a FACTOR<br>command that given a number outputs the prime factors. Instead of<br>factorializing the number, storing the prime factors into an array, and<br>later produce the command reply, a better solution is to start an array<br>reply where the length is not known, and set it later. This is accomplished<br>with a special argument to <code>ValkeyModule_ReplyWithArray()</code>:</p>\n<pre><code class=\"language-C\">ValkeyModule_ReplyWithArray(ctx, VALKEYMODULE_POSTPONED_LEN);\n</code></pre>\n<p>The above call starts an array reply so we can use other <code>ReplyWith</code> calls<br>in order to produce the array items. Finally in order to set the length,<br>use the following call:</p>\n<pre><code class=\"language-C\">ValkeyModule_ReplySetArrayLength(ctx, number_of_items);\n</code></pre>\n<p>In the case of the FACTOR command, this translates to some code similar<br>to this:</p>\n<pre><code class=\"language-C\">ValkeyModule_ReplyWithArray(ctx, VALKEYMODULE_POSTPONED_LEN);\nnumber_of_factors = 0;\nwhile(still_factors) {\n    ValkeyModule_ReplyWithLongLong(ctx, some_factor);\n    number_of_factors++;\n}\nValkeyModule_ReplySetArrayLength(ctx, number_of_factors);\n</code></pre>\n<p>Another common use case for this feature is iterating over the arrays of<br>some collection and only returning the ones passing some kind of filtering.</p>\n<p>It is possible to have multiple nested arrays with postponed reply.<br>Each call to <code>SetArray()</code> will set the length of the latest corresponding<br>call to <code>ReplyWithArray()</code>:</p>\n<pre><code class=\"language-C\">ValkeyModule_ReplyWithArray(ctx, VALKEYMODULE_POSTPONED_LEN);\n// ... generate 100 elements ...\nValkeyModule_ReplyWithArray(ctx, VALKEYMODULE_POSTPONED_LEN);\n// ... generate 10 elements ...\nValkeyModule_ReplySetArrayLength(ctx, 10);\nValkeyModule_ReplySetArrayLength(ctx, 100);\n</code></pre>\n<p>This creates a 100 items array having as last element a 10 items array.</p>\n<h2>Arity and type checks</h2>\n<p>Often commands need to check that the number of arguments and type of the key<br>is correct. In order to report a wrong arity, there is a specific function<br>called <code>ValkeyModule_WrongArity()</code>. The usage is trivial:</p>\n<pre><code class=\"language-C\">if (argc != 2) return ValkeyModule_WrongArity(ctx);\n</code></pre>\n<p>Checking for the wrong type involves opening the key and checking the type:</p>\n<pre><code class=\"language-C\">ValkeyModuleKey *key = ValkeyModule_OpenKey(ctx,argv[1],\n    VALKEYMODULE_READ|VALKEYMODULE_WRITE);\n\nint keytype = ValkeyModule_KeyType(key);\nif (keytype != VALKEYMODULE_KEYTYPE_STRING &amp;&amp;\n    keytype != VALKEYMODULE_KEYTYPE_EMPTY)\n{\n    ValkeyModule_CloseKey(key);\n    return ValkeyModule_ReplyWithError(ctx,VALKEYMODULE_ERRORMSG_WRONGTYPE);\n}\n</code></pre>\n<p>Note that you often want to proceed with a command both if the key<br>is of the expected type, or if it&#39;s empty.</p>\n<h2>Low level access to keys</h2>\n<p>Low level access to keys allow to perform operations on value objects associated<br>to keys directly, with a speed similar to what Valkey uses internally to<br>implement the built-in commands.</p>\n<p>Once a key is opened, a key pointer is returned that will be used with all the<br>other low level API calls in order to perform operations on the key or its<br>associated value.</p>\n<p>Because the API is meant to be very fast, it cannot do too many run-time<br>checks, so the user must be aware of certain rules to follow:</p>\n<ul>\n<li>Opening the same key multiple times where at least one instance is opened for writing, is undefined and may lead to crashes.</li>\n<li>While a key is open, it should only be accessed via the low level key API. For example opening a key, then calling DEL on the same key using the <code>ValkeyModule_Call()</code> API will result into a crash. However it is safe to open a key, perform some operation with the low level API, closing it, then using other APIs to manage the same key, and later opening it again to do some more work.</li>\n</ul>\n<p>In order to open a key the <code>ValkeyModule_OpenKey</code> function is used. It returns<br>a key pointer, that we&#39;ll use with all the next calls to access and modify<br>the value:</p>\n<pre><code class=\"language-C\">ValkeyModuleKey *key;\nkey = ValkeyModule_OpenKey(ctx,argv[1],VALKEYMODULE_READ);\n</code></pre>\n<p>The second argument is the key name, that must be a <code>ValkeyModuleString</code> object.<br>The third argument is the mode: <code>VALKEYMODULE_READ</code> or <code>VALKEYMODULE_WRITE</code>.<br>It is possible to use <code>|</code> to bitwise OR the two modes to open the key in<br>both modes. Currently a key opened for writing can also be accessed for reading<br>but this is to be considered an implementation detail. The right mode should<br>be used in sane modules.</p>\n<p>You can open non existing keys for writing, since the keys will be created<br>when an attempt to write to the key is performed. However when opening keys<br>just for reading, <code>ValkeyModule_OpenKey</code> will return NULL if the key does not<br>exist.</p>\n<p>Once you are done using a key, you can close it with:</p>\n<pre><code class=\"language-C\">ValkeyModule_CloseKey(key);\n</code></pre>\n<p>Note that if automatic memory management is enabled, you are not forced to<br>close keys. When the module function returns, Valkey will take care to close<br>all the keys which are still open.</p>\n<h2>Getting the key type</h2>\n<p>In order to obtain the value of a key, use the <code>ValkeyModule_KeyType()</code> function:</p>\n<pre><code class=\"language-C\">int keytype = ValkeyModule_KeyType(key);\n</code></pre>\n<p>It returns one of the following values:</p>\n<pre><code>VALKEYMODULE_KEYTYPE_EMPTY\nVALKEYMODULE_KEYTYPE_STRING\nVALKEYMODULE_KEYTYPE_LIST\nVALKEYMODULE_KEYTYPE_HASH\nVALKEYMODULE_KEYTYPE_SET\nVALKEYMODULE_KEYTYPE_ZSET\n</code></pre>\n<p>The above are just the usual Valkey key types, with the addition of an empty<br>type, that signals the key pointer is associated with an empty key that<br>does not yet exists.</p>\n<h2>Creating new keys</h2>\n<p>To create a new key, open it for writing and then write to it using one<br>of the key writing functions. Example:</p>\n<pre><code class=\"language-C\">ValkeyModuleKey *key;\nkey = ValkeyModule_OpenKey(ctx,argv[1],VALKEYMODULE_WRITE);\nif (ValkeyModule_KeyType(key) == VALKEYMODULE_KEYTYPE_EMPTY) {\n    ValkeyModule_StringSet(key,argv[2]);\n}\n</code></pre>\n<h2>Deleting keys</h2>\n<p>Just use:</p>\n<pre><code class=\"language-C\">ValkeyModule_DeleteKey(key);\n</code></pre>\n<p>The function returns <code>VALKEYMODULE_ERR</code> if the key is not open for writing.<br>Note that after a key gets deleted, it is setup in order to be targeted<br>by new key commands. For example <code>ValkeyModule_KeyType()</code> will return it is<br>an empty key, and writing to it will create a new key, possibly of another<br>type (depending on the API used).</p>\n<h2>Managing key expires (TTLs)</h2>\n<p>To control key expires two functions are provided, that are able to set,<br>modify, get, and unset the time to live associated with a key.</p>\n<p>One function is used in order to query the current expire of an open key:</p>\n<pre><code class=\"language-C\">mstime_t ValkeyModule_GetExpire(ValkeyModuleKey *key);\n</code></pre>\n<p>The function returns the time to live of the key in milliseconds, or<br><code>VALKEYMODULE_NO_EXPIRE</code> as a special value to signal the key has no associated<br>expire or does not exist at all (you can differentiate the two cases checking<br>if the key type is <code>VALKEYMODULE_KEYTYPE_EMPTY</code>).</p>\n<p>In order to change the expire of a key the following function is used instead:</p>\n<pre><code class=\"language-C\">int ValkeyModule_SetExpire(ValkeyModuleKey *key, mstime_t expire);\n</code></pre>\n<p>When called on a non existing key, <code>VALKEYMODULE_ERR</code> is returned, because<br>the function can only associate expires to existing open keys (non existing<br>open keys are only useful in order to create new values with data type<br>specific write operations).</p>\n<p>Again the <code>expire</code> time is specified in milliseconds. If the key has currently<br>no expire, a new expire is set. If the key already have an expire, it is<br>replaced with the new value.</p>\n<p>If the key has an expire, and the special value <code>VALKEYMODULE_NO_EXPIRE</code> is<br>used as a new expire, the expire is removed, similarly to the Valkey<br><code>PERSIST</code> command. In case the key was already persistent, no operation is<br>performed.</p>\n<h2>Obtaining the length of values</h2>\n<p>There is a single function in order to retrieve the length of the value<br>associated to an open key. The returned length is value-specific, and is<br>the string length for strings, and the number of elements for the aggregated<br>data types (how many elements there is in a list, set, sorted set, hash).</p>\n<pre><code class=\"language-C\">size_t len = ValkeyModule_ValueLength(key);\n</code></pre>\n<p>If the key does not exist, 0 is returned by the function:</p>\n<h2>String type API</h2>\n<p>Setting a new string value, like the Valkey <code>SET</code> command does, is performed<br>using:</p>\n<pre><code class=\"language-C\">int ValkeyModule_StringSet(ValkeyModuleKey *key, ValkeyModuleString *str);\n</code></pre>\n<p>The function works exactly like the Valkey <code>SET</code> command itself, that is, if<br>there is a prior value (of any type) it will be deleted.</p>\n<p>Accessing existing string values is performed using DMA (direct memory<br>access) for speed. The API will return a pointer and a length, so that&#39;s<br>possible to access and, if needed, modify the string directly.</p>\n<pre><code class=\"language-C\">size_t len, j;\nchar *myptr = ValkeyModule_StringDMA(key,&amp;len,VALKEYMODULE_WRITE);\nfor (j = 0; j &lt; len; j++) myptr[j] = &#39;A&#39;;\n</code></pre>\n<p>In the above example we write directly on the string. Note that if you want<br>to write, you must be sure to ask for <code>WRITE</code> mode.</p>\n<p>DMA pointers are only valid if no other operations are performed with the key<br>before using the pointer, after the DMA call.</p>\n<p>Sometimes when we want to manipulate strings directly, we need to change<br>their size as well. For this scope, the <code>ValkeyModule_StringTruncate</code> function<br>is used. Example:</p>\n<pre><code class=\"language-C\">ValkeyModule_StringTruncate(mykey,1024);\n</code></pre>\n<p>The function truncates, or enlarges the string as needed, padding it with<br>zero bytes if the previous length is smaller than the new length we request.<br>If the string does not exist since <code>key</code> is associated to an open empty key,<br>a string value is created and associated to the key.</p>\n<p>Note that every time <code>StringTruncate()</code> is called, we need to re-obtain<br>the DMA pointer again, since the old may be invalid.</p>\n<p>For a complete list of string type functions, see <a href=\"modules-api-ref#section-key-api-for-string-type\">Key API for String<br>type</a> in the Modules API<br>reference.</p>\n<h2>List type API</h2>\n<p>It&#39;s possible to push and pop values from list values:</p>\n<pre><code class=\"language-C\">int ValkeyModule_ListPush(ValkeyModuleKey *key, int where, ValkeyModuleString *ele);\nValkeyModuleString *ValkeyModule_ListPop(ValkeyModuleKey *key, int where);\n</code></pre>\n<p>In both the APIs the <code>where</code> argument specifies if to push or pop from tail<br>or head, using the following macros:</p>\n<pre><code>VALKEYMODULE_LIST_HEAD\nVALKEYMODULE_LIST_TAIL\n</code></pre>\n<p>Elements returned by <code>ValkeyModule_ListPop()</code> are like strings created with<br><code>ValkeyModule_CreateString()</code>, they must be released with<br><code>ValkeyModule_FreeString()</code> or by enabling automatic memory management.</p>\n<p>For a complete list of set type functions, see <a href=\"modules-api-ref#section-key-api-for-list-type\">Key API for List<br>type</a> in the Modules API<br>reference.</p>\n<h2>Set type API</h2>\n<p>A direct API to set type keys is not yet implemented.<br>Use the <code>ValkeyModule_Call</code> API with set commands like SADD to access keys of type set.</p>\n<h2>Sorted set type API</h2>\n<p>See the <a href=\"modules-api-ref#section-key-api-for-sorted-set-type\">Key API for Sorted Set<br>type</a> section in the<br>Modules API reference.</p>\n<h2>Hash type API</h2>\n<p>See <a href=\"modules-api-ref#section-key-api-for-hash-type\">Key API for Hash type</a> in<br>the Modules API reference.</p>\n<h2>Replicating commands</h2>\n<p>If you want to use module commands exactly like normal Valkey commands, in the<br>context of replicated Valkey instances, or using the AOF file for persistence,<br>it is important for module commands to handle their replication in a consistent<br>way.</p>\n<p>When using the higher level APIs to invoke commands, replication happens<br>automatically if you use the &quot;!&quot; modifier in the format string of<br><code>ValkeyModule_Call()</code> as in the following example:</p>\n<pre><code class=\"language-C\">reply = ValkeyModule_Call(ctx,&quot;INCRBY&quot;,&quot;!sc&quot;,argv[1],&quot;10&quot;);\n</code></pre>\n<p>As you can see the format specifier is <code>&quot;!sc&quot;</code>. The bang is not parsed as a<br>format specifier, but it internally flags the command as &quot;must replicate&quot;.</p>\n<p>If you use the above programming style, there are no problems.<br>However sometimes things are more complex than that, and you use the low level<br>API. In this case, if there are no side effects in the command execution, and<br>it consistently always performs the same work, what is possible to do is to<br>replicate the command verbatim as the user executed it. To do that, you just<br>need to call the following function:</p>\n<pre><code class=\"language-C\">ValkeyModule_ReplicateVerbatim(ctx);\n</code></pre>\n<p>When you use the above API, you should not use any other replication function<br>since they are not guaranteed to mix well.</p>\n<p>However this is not the only option. It&#39;s also possible to exactly tell<br>Valkey what commands to replicate as the effect of the command execution, using<br>an API similar to <code>ValkeyModule_Call()</code> but that instead of calling the command<br>sends it to the AOF / replicas stream. Example:</p>\n<pre><code class=\"language-C\">ValkeyModule_Replicate(ctx,&quot;INCRBY&quot;,&quot;cl&quot;,&quot;foo&quot;,my_increment);\n</code></pre>\n<p>It&#39;s possible to call <code>ValkeyModule_Replicate</code> multiple times, and each<br>will emit a command. All the sequence emitted is wrapped between a<br><code>MULTI/EXEC</code> transaction, so that the AOF and replication effects are the<br>same as executing a single command.</p>\n<p>Note that <code>Call()</code> replication and <code>Replicate()</code> replication have a rule,<br>in case you want to mix both forms of replication (not necessarily a good<br>idea if there are simpler approaches). Commands replicated with <code>Call()</code><br>are always the first emitted in the final <code>MULTI/EXEC</code> block, while all<br>the commands emitted with <code>Replicate()</code> will follow.</p>\n<h2>Automatic memory management</h2>\n<p>Normally when writing programs in the C language, programmers need to manage<br>memory manually. This is why the Valkey modules API has functions to release<br>strings, close open keys, free replies, and so forth.</p>\n<p>However given that commands are executed in a contained environment and<br>with a set of strict APIs, Valkey is able to provide automatic memory management<br>to modules, at the cost of some performance (most of the time, a very low<br>cost).</p>\n<p>When automatic memory management is enabled:</p>\n<ol>\n<li>You don&#39;t need to close open keys.</li>\n<li>You don&#39;t need to free replies.</li>\n<li>You don&#39;t need to free ValkeyModuleString objects.</li>\n</ol>\n<p>However you can still do it, if you want. For example, automatic memory<br>management may be active, but inside a loop allocating a lot of strings,<br>you may still want to free strings no longer used.</p>\n<p>In order to enable automatic memory management, just call the following<br>function at the start of the command implementation:</p>\n<pre><code class=\"language-C\">ValkeyModule_AutoMemory(ctx);\n</code></pre>\n<p>Automatic memory management is usually the way to go, however experienced<br>C programmers may not use it in order to gain some speed and memory usage<br>benefit.</p>\n<h2>Allocating memory into modules</h2>\n<p>Normal C programs use <code>malloc()</code> and <code>free()</code> in order to allocate and<br>release memory dynamically. While in Valkey modules the use of malloc is<br>not technically forbidden, it is a lot better to use the Valkey Modules<br>specific functions, that are exact replacements for <code>malloc</code>, <code>free</code>,<br><code>realloc</code> and <code>strdup</code>. These functions are:</p>\n<pre><code class=\"language-C\">void *ValkeyModule_Alloc(size_t bytes);\nvoid* ValkeyModule_Realloc(void *ptr, size_t bytes);\nvoid ValkeyModule_Free(void *ptr);\nvoid ValkeyModule_Calloc(size_t nmemb, size_t size);\nchar *ValkeyModule_Strdup(const char *str);\n</code></pre>\n<p>They work exactly like their <code>libc</code> equivalent calls, however they use<br>the same allocator Valkey uses, and the memory allocated using these<br>functions is reported by the <code>INFO</code> command in the memory section, is<br>accounted when enforcing the <code>maxmemory</code> policy, and in general is<br>a first citizen of the Valkey executable. On the contrary, the method<br>allocated inside modules with libc <code>malloc()</code> is transparent to Valkey.</p>\n<p>Another reason to use the modules functions in order to allocate memory<br>is that, when creating native data types inside modules, the RDB loading<br>functions can return deserialized strings (from the RDB file) directly<br>as <code>ValkeyModule_Alloc()</code> allocations, so they can be used directly to<br>populate data structures after loading, instead of having to copy them<br>to the data structure.</p>\n<h2>Pool allocator</h2>\n<p>Sometimes in commands implementations, it is required to perform many<br>small allocations that will be not retained at the end of the command<br>execution, but are just functional to execute the command itself.</p>\n<p>This work can be more easily accomplished using the Valkey pool allocator:</p>\n<pre><code class=\"language-C\">void *ValkeyModule_PoolAlloc(ValkeyModuleCtx *ctx, size_t bytes);\n</code></pre>\n<p>It works similarly to <code>malloc()</code>, and returns memory aligned to the<br>next power of two of greater or equal to <code>bytes</code> (for a maximum alignment<br>of 8 bytes). However it allocates memory in blocks, so it the overhead<br>of the allocations is small, and more important, the memory allocated<br>is automatically released when the command returns.</p>\n<p>So in general short living allocations are a good candidates for the pool<br>allocator.</p>\n<h2>Writing commands compatible with Valkey Cluster</h2>\n<p>See the Modules API reference for the following commands:</p>\n<ul>\n<li><a href=\"modules-api-ref#ValkeyModule_IsKeysPositionRequest\"><code>ValkeyModule_IsKeysPositionRequest(ctx)</code></a></li>\n<li><a href=\"modules-api-ref#ValkeyModule_KeyAtPos\"><code>ValkeyModule_KeyAtPos(ctx, pos)</code></a></li>\n</ul>\n"
      },
      {
        "id": "modules-native-types",
        "topicName": "Modules API for native types",
        "description": "How to use native types in a Valkey module\n",
        "htmlContent": "<p>Valkey modules can access Valkey built-in data structures both at high level,<br>by calling Valkey commands, and at low level, by manipulating the data structures<br>directly.</p>\n<p>By using these capabilities in order to build new abstractions on top of existing<br>Valkey data structures, or by using strings DMA in order to encode modules<br>data structures into Strings, it is possible to create modules that<br><em>feel like</em> they are exporting new data types. However, for more complex<br>problems, this is not enough, and the implementation of new data structures<br>inside the module is needed.</p>\n<p>We call the ability of Valkey modules to implement new data structures that<br>feel like native Valkey ones <strong>native types support</strong>. This document describes<br>the API exported by the Valkey modules system in order to create new data<br>structures and handle the serialization in RDB files, the rewriting process<br>in AOF, the type reporting via the <code>TYPE</code> command, and so forth.</p>\n<h2>Overview of native types</h2>\n<p>A module exporting a native type is composed of the following main parts:</p>\n<ul>\n<li>The implementation of some kind of new data structure and of commands operating on the new data structure.</li>\n<li>A set of callbacks that handle: RDB saving, RDB loading, AOF rewriting, releasing of a value associated with a key, calculation of a value digest (hash) to be used with the <code>DEBUG DIGEST</code> command.</li>\n<li>A 9 characters name that is unique to each module native data type.</li>\n<li>An encoding version, used to persist into RDB files a module-specific data version, so that a module will be able to load older representations from RDB files.</li>\n</ul>\n<p>While to handle RDB loading, saving and AOF rewriting may look complex as a first glance, the modules API provide very high level function for handling all this, without requiring the user to handle read/write errors, so in practical terms, writing a new data structure for Valkey is a simple task.</p>\n<p>A <strong>very easy</strong> to understand but complete example of native type implementation<br>is available inside the Valkey distribution in the <code>/modules/hellotype.c</code> file.<br>The reader is encouraged to read the documentation by looking at this example<br>implementation to see how things are applied in the practice.</p>\n<h1>Registering a new data type</h1>\n<p>In order to register a new native type into the Valkey core, the module needs<br>to declare a global variable that will hold a reference to the data type.<br>The API to register the data type will return a data type reference that will<br>be stored in the global variable.</p>\n<pre><code class=\"language-C\">static ValkeyModuleType *MyType;\n#define MYTYPE_ENCODING_VERSION 0\n\nint ValkeyModule_OnLoad(ValkeyModuleCtx *ctx) {\nValkeyModuleTypeMethods tm = {\n    .version = VALKEYMODULE_TYPE_METHOD_VERSION,\n    .rdb_load = MyTypeRDBLoad,\n    .rdb_save = MyTypeRDBSave,\n    .aof_rewrite = MyTypeAOFRewrite,\n    .free = MyTypeFree\n};\n\n    MyType = ValkeyModule_CreateDataType(ctx, &quot;MyType-AZ&quot;,\n    MYTYPE_ENCODING_VERSION, &amp;tm);\n    if (MyType == NULL) return VALKEYMODULE_ERR;\n}\n</code></pre>\n<p>As you can see from the example above, a single API call is needed in order to<br>register the new type. However a number of function pointers are passed as<br>arguments. Certain are optionals while some are mandatory. The above set<br>of methods <em>must</em> be passed, while <code>.digest</code> and <code>.mem_usage</code> are optional<br>and are currently not actually supported by the modules internals, so for<br>now you can just ignore them.</p>\n<p>The <code>ctx</code> argument is the context that we receive in the <code>OnLoad</code> function.<br>The type <code>name</code> is a 9 character name in the character set that includes<br>from <code>A-Z</code>, <code>a-z</code>, <code>0-9</code>, plus the underscore <code>_</code> and minus <code>-</code> characters.</p>\n<p>Note that <strong>this name must be unique</strong> for each data type in the Valkey<br>ecosystem, so be creative, use both lower-case and upper case if it makes<br>sense, and try to use the convention of mixing the type name with the name<br>of the author of the module, to create a 9 character unique name.</p>\n<p><strong>NOTE:</strong> It is very important that the name is exactly 9 chars or the<br>registration of the type will fail. Read more to understand why.</p>\n<p>For example if I&#39;m building a <em>b-tree</em> data structure and my name is <em>antirez</em><br>I&#39;ll call my type <strong>btree1-az</strong>. The name, converted to a 64 bit integer,<br>is stored inside the RDB file when saving the type, and will be used when the<br>RDB data is loaded in order to resolve what module can load the data. If Valkey<br>finds no matching module, the integer is converted back to a name in order to<br>provide some clue to the user about what module is missing in order to load<br>the data.</p>\n<p>The type name is also used as a reply for the <code>TYPE</code> command when called<br>with a key holding the registered type.</p>\n<p>The <code>encver</code> argument is the encoding version used by the module to store data<br>inside the RDB file. For example I can start with an encoding version of 0,<br>but later when I release version 2.0 of my module, I can switch encoding to<br>something better. The new module will register with an encoding version of 1,<br>so when it saves new RDB files, the new version will be stored on disk. However<br>when loading RDB files, the module <code>rdb_load</code> method will be called even if<br>there is data found for a different encoding version (and the encoding version<br>is passed as argument to <code>rdb_load</code>), so that the module can still load old<br>RDB files.</p>\n<p>The last argument is a structure used in order to pass the type methods to the<br>registration function: <code>rdb_load</code>, <code>rdb_save</code>, <code>aof_rewrite</code>, <code>digest</code> and<br><code>free</code> and <code>mem_usage</code> are all callbacks with the following prototypes and uses:</p>\n<pre><code class=\"language-C\">typedef void *(*ValkeyModuleTypeLoadFunc)(ValkeyModuleIO *rdb, int encver);\ntypedef void (*ValkeyModuleTypeSaveFunc)(ValkeyModuleIO *rdb, void *value);\ntypedef void (*ValkeyModuleTypeRewriteFunc)(ValkeyModuleIO *aof, ValkeyModuleString *key, void *value);\ntypedef size_t (*ValkeyModuleTypeMemUsageFunc)(void *value);\ntypedef void (*ValkeyModuleTypeDigestFunc)(ValkeyModuleDigest *digest, void *value);\ntypedef void (*ValkeyModuleTypeFreeFunc)(void *value);\n</code></pre>\n<ul>\n<li><code>rdb_load</code> is called when loading data from the RDB file. It loads data in the same format as <code>rdb_save</code> produces.</li>\n<li><code>rdb_save</code> is called when saving data to the RDB file.</li>\n<li><code>aof_rewrite</code> is called when the AOF is being rewritten, and the module needs to tell Valkey what is the sequence of commands to recreate the content of a given key.</li>\n<li><code>digest</code> is called when <code>DEBUG DIGEST</code> is executed and a key holding this module type is found. Currently this is not yet implemented so the function ca be left empty.</li>\n<li><code>mem_usage</code> is called when the <code>MEMORY</code> command asks for the total memory consumed by a specific key, and is used in order to get the amount of bytes used by the module value.</li>\n<li><code>free</code> is called when a key with the module native type is deleted via <code>DEL</code> or in any other mean, in order to let the module reclaim the memory associated with such a value.</li>\n</ul>\n<h2>Ok, but <em>why</em> modules types require a 9 characters name?</h2>\n<p>Oh, I understand you need to understand this, so here is a very specific<br>explanation.</p>\n<p>When Valkey persists to RDB files, modules specific data types require to<br>be persisted as well. Now RDB files are sequences of key-value pairs<br>like the following:</p>\n<pre><code>[1 byte type] [key] [a type specific value]\n</code></pre>\n<p>The 1 byte type identifies strings, lists, sets, and so forth. In the case<br>of modules data, it is set to a special value of <code>module data</code>, but of<br>course this is not enough, we need the information needed to link a specific<br>value with a specific module type that is able to load and handle it.</p>\n<p>So when we save a <code>type specific value</code> about a module, we prefix it with<br>a 64 bit integer. 64 bits is large enough to store the information needed<br>in order to lookup the module that can handle that specific type, but is<br>short enough that we can prefix each module value we store inside the RDB<br>without making the final RDB file too big. At the same time, this solution<br>of prefixing the value with a 64 bit <em>signature</em> does not require to do<br>strange things like defining in the RDB header a list of modules specific<br>types. Everything is pretty simple.</p>\n<p>So, what you can store in 64 bits in order to identify a given module in<br>a reliable way? Well if you build a character set of 64 symbols, you can<br>easily store 9 characters of 6 bits, and you are left with 10 bits, that<br>are used in order to store the <em>encoding version</em> of the type, so that<br>the same type can evolve in the future and provide a different and more<br>efficient or updated serialization format for RDB files.</p>\n<p>So the 64 bit prefix stored before each module value is like the following:</p>\n<pre><code>6|6|6|6|6|6|6|6|6|10\n</code></pre>\n<p>The first 9 elements are 6-bits characters, the final 10 bits is the<br>encoding version.</p>\n<p>When the RDB file is loaded back, it reads the 64 bit value, masks the final<br>10 bits, and searches for a matching module in the modules types cache.<br>When a matching one is found, the method to load the RDB file value is called<br>with the 10 bits encoding version as argument, so that the module knows<br>what version of the data layout to load, if it can support multiple versions.</p>\n<p>Now the interesting thing about all this is that, if instead the module type<br>cannot be resolved, since there is no loaded module having this signature,<br>we can convert back the 64 bit value into a 9 characters name, and print<br>an error to the user that includes the module type name! So that she or he<br>immediately realizes what&#39;s wrong.</p>\n<h2>Setting and getting keys</h2>\n<p>After registering our new data type in the <code>ValkeyModule_OnLoad()</code> function,<br>we also need to be able to set Valkey keys having as value our native type.</p>\n<p>This normally happens in the context of commands that write data to a key.<br>The native types API allow to set and get keys to module native data types,<br>and to test if a given key is already associated to a value of a specific data<br>type.</p>\n<p>The API uses the normal modules <code>ValkeyModule_OpenKey()</code> low level key access<br>interface in order to deal with this. This is an example of setting a<br>native type private data structure to a Valkey key:</p>\n<pre><code class=\"language-C\">ValkeyModuleKey *key = ValkeyModule_OpenKey(ctx,keyname,VALKEYMODULE_WRITE);\nstruct some_private_struct *data = createMyDataStructure();\nValkeyModule_ModuleTypeSetValue(key,MyType,data);\n</code></pre>\n<p>The function <code>ValkeyModule_ModuleTypeSetValue()</code> is used with a key handle open<br>for writing, and gets three arguments: the key handle, the reference to the<br>native type, as obtained during the type registration, and finally a <code>void*</code><br>pointer that contains the private data implementing the module native type.</p>\n<p>Note that Valkey has no clues at all about what your data contains. It will<br>just call the callbacks you provided during the method registration in order<br>to perform operations on the type.</p>\n<p>Similarly we can retrieve the private data from a key using this function:</p>\n<pre><code>struct some_private_struct *data;\ndata = ValkeyModule_ModuleTypeGetValue(key);\n</code></pre>\n<p>We can also test for a key to have our native type as value:</p>\n<pre><code class=\"language-C\">if (ValkeyModule_ModuleTypeGetType(key) == MyType) {\n    /* ... do something ... */\n}\n</code></pre>\n<p>However for the calls to do the right thing, we need to check if the key<br>is empty, if it contains a value of the right kind, and so forth. So<br>the idiomatic code to implement a command writing to our native type<br>is along these lines:</p>\n<pre><code class=\"language-C\">ValkeyModuleKey *key = ValkeyModule_OpenKey(ctx,argv[1],\n    VALKEYMODULE_READ|VALKEYMODULE_WRITE);\nint type = ValkeyModule_KeyType(key);\nif (type != VALKEYMODULE_KEYTYPE_EMPTY &amp;&amp;\n    ValkeyModule_ModuleTypeGetType(key) != MyType)\n{\n    return ValkeyModule_ReplyWithError(ctx,VALKEYMODULE_ERRORMSG_WRONGTYPE);\n}\n</code></pre>\n<p>Then if we successfully verified the key is not of the wrong type, and<br>we are going to write to it, we usually want to create a new data structure if<br>the key is empty, or retrieve the reference to the value associated to the<br>key if there is already one:</p>\n<pre><code class=\"language-C\">/* Create an empty value object if the key is currently empty. */\nstruct some_private_struct *data;\nif (type == VALKEYMODULE_KEYTYPE_EMPTY) {\n    data = createMyDataStructure();\n    ValkeyModule_ModuleTypeSetValue(key,MyTyke,data);\n} else {\n    data = ValkeyModule_ModuleTypeGetValue(key);\n}\n/* Do something with &#39;data&#39;... */\n</code></pre>\n<h2>Free method</h2>\n<p>As already mentioned, when Valkey needs to free a key holding a native type<br>value, it needs help from the module in order to release the memory. This<br>is the reason why we pass a <code>free</code> callback during the type registration:</p>\n<pre><code class=\"language-C\">typedef void (*ValkeyModuleTypeFreeFunc)(void *value);\n</code></pre>\n<p>A trivial implementation of the free method can be something like this,<br>assuming our data structure is composed of a single allocation:</p>\n<pre><code class=\"language-C\">void MyTypeFreeCallback(void *value) {\n    ValkeyModule_Free(value);\n}\n</code></pre>\n<p>However a more real world one will call some function that performs a more<br>complex memory reclaiming, by casting the void pointer to some structure<br>and freeing all the resources composing the value.</p>\n<h2>RDB load and save methods</h2>\n<p>The RDB saving and loading callbacks need to create (and load back) a<br>representation of the data type on disk. Valkey offers a high level API<br>that can automatically store inside the RDB file the following types:</p>\n<ul>\n<li>Unsigned 64 bit integers.</li>\n<li>Signed 64 bit integers.</li>\n<li>Doubles.</li>\n<li>Strings.</li>\n</ul>\n<p>It is up to the module to find a viable representation using the above base<br>types. However note that while the integer and double values are stored<br>and loaded in an architecture and <em>endianness</em> agnostic way, if you use<br>the raw string saving API to, for example, save a structure on disk, you<br>have to care those details yourself.</p>\n<p>This is the list of functions performing RDB saving and loading:</p>\n<pre><code class=\"language-C\">void ValkeyModule_SaveUnsigned(ValkeyModuleIO *io, uint64_t value);\nuint64_t ValkeyModule_LoadUnsigned(ValkeyModuleIO *io);\nvoid ValkeyModule_SaveSigned(ValkeyModuleIO *io, int64_t value);\nint64_t ValkeyModule_LoadSigned(ValkeyModuleIO *io);\nvoid ValkeyModule_SaveString(ValkeyModuleIO *io, ValkeyModuleString *s);\nvoid ValkeyModule_SaveStringBuffer(ValkeyModuleIO *io, const char *str, size_t len);\nValkeyModuleString *ValkeyModule_LoadString(ValkeyModuleIO *io);\nchar *ValkeyModule_LoadStringBuffer(ValkeyModuleIO *io, size_t *lenptr);\nvoid ValkeyModule_SaveDouble(ValkeyModuleIO *io, double value);\ndouble ValkeyModule_LoadDouble(ValkeyModuleIO *io);\n</code></pre>\n<p>The functions don&#39;t require any error checking from the module, that can<br>always assume calls succeed.</p>\n<p>As an example, imagine I&#39;ve a native type that implements an array of<br>double values, with the following structure:</p>\n<pre><code class=\"language-C\">struct double_array {\n    size_t count;\n    double *values;\n};\n</code></pre>\n<p>My <code>rdb_save</code> method may look like the following:</p>\n<pre><code class=\"language-C\">void DoubleArrayRDBSave(ValkeyModuleIO *io, void *ptr) {\n    struct dobule_array *da = ptr;\n    ValkeyModule_SaveUnsigned(io,da-&gt;count);\n    for (size_t j = 0; j &lt; da-&gt;count; j++)\n        ValkeyModule_SaveDouble(io,da-&gt;values[j]);\n}\n</code></pre>\n<p>What we did was to store the number of elements followed by each double<br>value. So when later we&#39;ll have to load the structure in the <code>rdb_load</code><br>method we&#39;ll do something like this:</p>\n<pre><code class=\"language-C\">void *DoubleArrayRDBLoad(ValkeyModuleIO *io, int encver) {\n    if (encver != DOUBLE_ARRAY_ENC_VER) {\n        /* We should actually log an error here, or try to implement\n           the ability to load older versions of our data structure. */\n        return NULL;\n    }\n\n    struct double_array *da;\n    da = ValkeyModule_Alloc(sizeof(*da));\n    da-&gt;count = ValkeyModule_LoadUnsigned(io);\n    da-&gt;values = ValkeyModule_Alloc(da-&gt;count * sizeof(double));\n    for (size_t j = 0; j &lt; da-&gt;count; j++)\n        da-&gt;values[j] = ValkeyModule_LoadDouble(io);\n    return da;\n}\n</code></pre>\n<p>The load callback just reconstruct back the data structure from the data<br>we stored in the RDB file.</p>\n<p>Note that while there is no error handling on the API that writes and reads<br>from disk, still the load callback can return NULL on errors in case what<br>it reads does not look correct. Valkey will just panic in that case.</p>\n<h2>AOF rewriting</h2>\n<pre><code class=\"language-C\">void ValkeyModule_EmitAOF(ValkeyModuleIO *io, const char *cmdname, const char *fmt, ...);\n</code></pre>\n<h2>Allocating memory</h2>\n<p>Modules data types should try to use <code>ValkeyModule_Alloc()</code> functions family<br>in order to allocate, reallocate and release heap memory used to implement the native data structures (see the other Valkey Modules documentation for detailed information).</p>\n<p>This is not just useful in order for Valkey to be able to account for the memory used by the module, but there are also more advantages:</p>\n<ul>\n<li>Valkey uses the <code>jemalloc</code> allocator, that often prevents fragmentation problems that could be caused by using the libc allocator.</li>\n<li>When loading strings from the RDB file, the native types API is able to return strings allocated directly with <code>ValkeyModule_Alloc()</code>, so that the module can directly link this memory into the data structure representation, avoiding a useless copy of the data.</li>\n</ul>\n<p>Even if you are using external libraries implementing your data structures, the<br>allocation functions provided by the module API is exactly compatible with<br><code>malloc()</code>, <code>realloc()</code>, <code>free()</code> and <code>strdup()</code>, so converting the libraries<br>in order to use these functions should be trivial.</p>\n<p>In case you have an external library that uses libc <code>malloc()</code>, and you want<br>to avoid replacing manually all the calls with the Valkey Modules API calls,<br>an approach could be to use simple macros in order to replace the libc calls<br>with the Valkey API calls. Something like this could work:</p>\n<pre><code class=\"language-C\">#define malloc ValkeyModule_Alloc\n#define realloc ValkeyModule_Realloc\n#define free ValkeyModule_Free\n#define strdup ValkeyModule_Strdup\n</code></pre>\n<p>However take in mind that mixing libc calls with Valkey API calls will result<br>into troubles and crashes, so if you replace calls using macros, you need to<br>make sure that all the calls are correctly replaced, and that the code with<br>the substituted calls will never, for example, attempt to call<br><code>ValkeyModule_Free()</code> with a pointer allocated using libc <code>malloc()</code>.</p>\n"
      }
    ]
  },
  {
    "title": "HIGH AVAILABILITY",
    "items": [
      {
        "id": "cluster-spec",
        "topicName": "Cluster specification",
        "description": "Detailed specification for Valkey cluster\n",
        "htmlContent": "<p>Welcome to the <strong>Valkey Cluster Specification</strong>. Here you&#39;ll find information<br>about the algorithms and design rationales of Valkey Cluster. This document is a work<br>in progress as it is continuously synchronized with the actual implementation<br>of Valkey.</p>\n<h2>Main properties and rationales of the design</h2>\n<h3>Valkey Cluster goals</h3>\n<p>Valkey Cluster is a distributed implementation of Valkey with the following goals in order of importance in the design:</p>\n<ul>\n<li>High performance and linear scalability up to 1000 nodes. There are no proxies, asynchronous replication is used, and no merge operations are performed on values.</li>\n<li>Acceptable degree of write safety: the system tries (in a best-effort way) to retain all the writes originating from clients connected with the majority of the primary nodes. Usually there are small windows where acknowledged writes can be lost. Windows to lose acknowledged writes are larger when clients are in a minority partition.</li>\n<li>Availability: Valkey Cluster is able to survive partitions where the majority of the primary nodes are reachable and there is at least one reachable replica for every primary node that is no longer reachable. Moreover using <em>replicas migration</em>, primaries no longer replicated by any replica will receive one from a primary which is covered by multiple replicas.</li>\n</ul>\n<h3>Implemented subset</h3>\n<p>Valkey Cluster implements all the single key commands available in the<br>non-distributed version of Valkey. Commands performing complex multi-key<br>operations like set unions and intersections are implemented for cases where<br>all of the keys involved in the operation hash to the same slot.</p>\n<p>Valkey Cluster implements a concept called <strong>hash tags</strong> that can be used<br>to force certain keys to be stored in the same hash slot. However, during<br>manual resharding, multi-key operations may become unavailable for some time<br>while single-key operations are always available.</p>\n<p>Valkey Cluster does not support multiple databases like the standalone version<br>of Valkey. We only support database <code>0</code>; the <code>SELECT</code> command is not allowed.</p>\n<h2>Client and Server roles in the Valkey cluster protocol</h2>\n<p>In Valkey Cluster, nodes are responsible for holding the data,<br>and taking the state of the cluster, including mapping keys to the right nodes.<br>Cluster nodes are also able to auto-discover other nodes, detect non-working<br>nodes, and promote replica nodes to primary when needed in order<br>to continue to operate when a failure occurs.</p>\n<p>To perform their tasks all the cluster nodes are connected using a<br>TCP bus and a binary protocol, called the <strong>Valkey Cluster Bus</strong>.<br>Every node is connected to every other node in the cluster using the cluster<br>bus. Nodes use a gossip protocol to propagate information about the cluster<br>in order to discover new nodes, to send ping packets to make sure all the<br>other nodes are working properly, and to send cluster messages needed to<br>signal specific conditions. The cluster bus is also used in order to<br>propagate Pub/Sub messages across the cluster and to orchestrate manual<br>failovers when requested by users (manual failovers are failovers which<br>are not initiated by the Valkey Cluster failure detector, but by the<br>system administrator directly).</p>\n<p>Since cluster nodes are not able to proxy requests, clients may be redirected<br>to other nodes using redirection errors <code>-MOVED</code> and <code>-ASK</code>.<br>The client is in theory free to send requests to all the nodes in the cluster,<br>getting redirected if needed, so the client is not required to hold the<br>state of the cluster. However clients that are able to cache the map between<br>keys and nodes can improve the performance in a sensible way.</p>\n<h3>Write safety</h3>\n<p>Valkey Cluster uses asynchronous replication between nodes, and <strong>last failover wins</strong> implicit merge function. This means that the last elected primary dataset eventually replaces all the other replicas. There is always a window of time when it is possible to lose writes during partitions. However these windows are very different in the case of a client that is connected to the majority of primaries, and a client that is connected to the minority of primaries.</p>\n<p>Valkey Cluster tries harder to retain writes that are performed by clients connected to the majority of primaries, compared to writes performed in the minority side.<br>The following are examples of scenarios that lead to loss of acknowledged<br>writes received in the majority partitions during failures:</p>\n<ol>\n<li><p>A write may reach a primary, but while the primary may be able to reply to the client, the write may not be propagated to replicas via the asynchronous replication used between primary and replica nodes. If the primary dies without the write reaching the replicas, the write is lost forever if the primary is unreachable for a long enough period that one of its replicas is promoted. This is usually hard to observe in the case of a total, sudden failure of a primary node since primaries try to reply to clients (with the acknowledge of the write) and replicas (propagating the write) at about the same time. However it is a real world failure mode.</p>\n</li>\n<li><p>Another theoretically possible failure mode where writes are lost is the following:</p>\n</li>\n</ol>\n<ul>\n<li>A primary is unreachable because of a partition.</li>\n<li>It gets failed over by one of its replicas.</li>\n<li>After some time it may be reachable again.</li>\n<li>A client with an out-of-date routing table may write to the old primary before it is converted into a replica (of the new primary) by the cluster.</li>\n</ul>\n<p>The second failure mode is unlikely to happen because primary nodes are unable to communicate with the majority of the other primaries for enough time to be failed over will no longer accept writes, and when the partition is fixed writes are still refused for a small amount of time to allow other nodes to inform about configuration changes. This failure mode also requires that the client&#39;s routing table has not yet been updated.</p>\n<p>Writes targeting the minority side of a partition have a larger window in which to get lost. For example, Valkey Cluster loses a non-trivial number of writes on partitions where there is a minority of primaries and at least one or more clients, since all the writes sent to the primaries may potentially get lost if the primaries are failed over in the majority side.</p>\n<p>Specifically, for a primary to be failed over it must be unreachable by the majority of primaries for at least <code>NODE_TIMEOUT</code>, so if the partition is fixed before that time, no writes are lost. When the partition lasts for more than <code>NODE_TIMEOUT</code>, all the writes performed in the minority side up to that point may be lost. However the minority side of a Valkey Cluster will start refusing writes as soon as <code>NODE_TIMEOUT</code> time has elapsed without contact with the majority, so there is a maximum window after which the minority becomes no longer available. Hence, no writes are accepted or lost after that time.</p>\n<h3>Availability</h3>\n<p>Valkey Cluster is not available in the minority side of the partition. In the majority side of the partition assuming that there are at least the majority of primaries and a replica for every unreachable primary, the cluster becomes available again after <code>NODE_TIMEOUT</code> time plus a few more seconds required for a replica to get elected and failover its primary (failovers are usually executed in a matter of 1 or 2 seconds).</p>\n<p>This means that Valkey Cluster is designed to survive failures of a few nodes in the cluster, but it is not a suitable solution for applications that require availability in the event of large net splits.</p>\n<p>In the example of a cluster composed of N primary nodes where every node has a single replica, the majority side of the cluster will remain available as long as a single node is partitioned away, and will remain available with a probability of <code>1-(1/(N*2-1))</code> when two nodes are partitioned away (after the first node fails we are left with <code>N*2-1</code> nodes in total, and the probability of the only primary without a replica to fail is <code>1/(N*2-1))</code>.</p>\n<p>For example, in a cluster with 5 nodes and a single replica per node, there is a <code>1/(5*2-1) = 11.11%</code> probability that after two nodes are partitioned away from the majority, the cluster will no longer be available.</p>\n<p>Thanks to a Valkey Cluster feature called <strong>replicas migration</strong> the Cluster<br>availability is improved in many real world scenarios by the fact that<br>replicas migrate to orphaned primaries (primaries no longer having replicas).<br>So at every successful failure event, the cluster may reconfigure the replicas<br>layout in order to better resist the next failure.</p>\n<h3>Performance</h3>\n<p>In Valkey Cluster nodes don&#39;t proxy commands to the right node in charge for a given key, but instead they redirect clients to the right nodes serving a given portion of the key space.</p>\n<p>Eventually clients obtain an up-to-date representation of the cluster and which node serves which subset of keys, so during normal operations clients directly contact the right nodes in order to send a given command.</p>\n<p>Because of the use of asynchronous replication, nodes do not wait for other nodes&#39; acknowledgment of writes (if not explicitly requested using the <code>WAIT</code> command).</p>\n<p>Also, because multi-key commands are only limited to <em>near</em> keys, data is never moved between nodes except when resharding.</p>\n<p>Normal operations are handled exactly as in the case of a single Valkey instance. This means that in a Valkey Cluster with N primary nodes you can expect the same performance as a single Valkey instance multiplied by N as the design scales linearly. At the same time the query is usually performed in a single round trip, since clients usually retain persistent connections with the nodes, so latency figures are also the same as the single standalone Valkey node case.</p>\n<p>Very high performance and scalability while preserving weak but<br>reasonable forms of data safety and availability is the main goal of<br>Valkey Cluster.</p>\n<h3>Why merge operations are avoided</h3>\n<p>The Valkey Cluster design avoids conflicting versions of the same key-value pair in multiple nodes as in the case of the Valkey data model this is not always desirable. Values in Valkey are often very large; it is common to see lists or sorted sets with millions of elements. Also data types are semantically complex. Transferring and merging these kind of values can be a major bottleneck and/or may require the non-trivial involvement of application-side logic, additional memory to store meta-data, and so forth.</p>\n<p>There are no strict technological limits here. CRDTs or synchronously replicated<br>state machines can model complex data types similar to Valkey. However, the<br>actual run time behavior of such systems would not be similar to Valkey Cluster.<br>Valkey Cluster was designed in order to cover the exact use cases of the<br>non-clustered Valkey deployment.</p>\n<h2>Overview of Valkey Cluster main components</h2>\n<h3>Key distribution model</h3>\n<p>The cluster&#39;s key space is split into 16384 slots, effectively setting an upper limit<br>for the cluster size of 16384 primary nodes (however, the suggested max size of<br>nodes is on the order of ~ 1000 nodes).</p>\n<p>Each primary node in a cluster handles a subset of the 16384 hash slots.<br>The cluster is <strong>stable</strong> when there is no cluster reconfiguration in<br>progress (i.e. where hash slots are being moved from one node to another).<br>When the cluster is stable, a single hash slot will be served by a single node<br>(however the serving node can have one or more replicas that will replace it in the case of net splits or failures,<br>and that can be used in order to scale read operations where reading stale data is acceptable).</p>\n<p>The base algorithm used to map keys to hash slots is the following<br>(read the next paragraph for the hash tag exception to this rule):</p>\n<pre><code>HASH_SLOT = CRC16(key) mod 16384\n</code></pre>\n<p>The CRC16 is specified as follows:</p>\n<ul>\n<li>Name: XMODEM (also known as ZMODEM or CRC-16/ACORN)</li>\n<li>Width: 16 bit</li>\n<li>Poly: 1021 (That is actually x^16 + x^12 + x^5 + 1)</li>\n<li>Initialization: 0000</li>\n<li>Reflect Input byte: False</li>\n<li>Reflect Output CRC: False</li>\n<li>Xor constant to output CRC: 0000</li>\n<li>Output for &quot;123456789&quot;: 31C3</li>\n</ul>\n<p>14 out of 16 CRC16 output bits are used (this is why there is<br>a modulo 16384 operation in the formula above).</p>\n<p>In our tests CRC16 behaved remarkably well in distributing different kinds of<br>keys evenly across the 16384 slots.</p>\n<p><strong>Note</strong>: A reference implementation of the CRC16 algorithm used is available in the Appendix A of this document.</p>\n<h3>Hash tags</h3>\n<p>There is an exception for the computation of the hash slot that is used in order<br>to implement <strong>hash tags</strong>. Hash tags are a way to ensure that multiple keys<br>are allocated in the same hash slot. This is used in order to implement<br>multi-key operations in Valkey Cluster.</p>\n<p>To implement hash tags, the hash slot for a key is computed in a<br>slightly different way in certain conditions.<br>If the key contains a &quot;{...}&quot; pattern only the substring between<br><code>{</code> and <code>}</code> is hashed in order to obtain the hash slot. However since it is<br>possible that there are multiple occurrences of <code>{</code> or <code>}</code> the algorithm is<br>well specified by the following rules:</p>\n<ul>\n<li>IF the key contains a <code>{</code> character.</li>\n<li>AND IF there is a <code>}</code> character to the right of <code>{</code>.</li>\n<li>AND IF there are one or more characters between the first occurrence of <code>{</code> and the first occurrence of <code>}</code>.</li>\n</ul>\n<p>Then instead of hashing the key, only what is between the first occurrence of <code>{</code> and the following first occurrence of <code>}</code> is hashed.</p>\n<p>Examples:</p>\n<ul>\n<li>The two keys <code>{user1000}.following</code> and <code>{user1000}.followers</code> will hash to the same hash slot since only the substring <code>user1000</code> will be hashed in order to compute the hash slot.</li>\n<li>For the key <code>foo{}{bar}</code> the whole key will be hashed as usually since the first occurrence of <code>{</code> is followed by <code>}</code> on the right without characters in the middle.</li>\n<li>For the key <code>foo{{bar}}zap</code> the substring <code>{bar</code> will be hashed, because it is the substring between the first occurrence of <code>{</code> and the first occurrence of <code>}</code> on its right.</li>\n<li>For the key <code>foo{bar}{zap}</code> the substring <code>bar</code> will be hashed, since the algorithm stops at the first valid or invalid (without bytes inside) match of <code>{</code> and <code>}</code>.</li>\n<li>What follows from the algorithm is that if the key starts with <code>{}</code>, it is guaranteed to be hashed as a whole. This is useful when using binary data as key names.</li>\n</ul>\n<h4>Glob-style patterns</h4>\n<p>Commands accepting a glob-style pattern, including <code>KEYS</code>, <code>SCAN</code> and <code>SORT</code>, are optimized for patterns that imply a single slot.<br>This means that if all keys that can match a pattern must belong to a specific slot, only this slot is searched for keys matching the pattern.<br>The pattern slot optimization is introduced in Valkey 8.0.</p>\n<p>The optimization kicks in when the pattern meets the following conditions:</p>\n<ul>\n<li>the pattern contains a hashtag,</li>\n<li>there are no wildcards or escape characters before the hashtag, and</li>\n<li>the hashtag within curly braces doesn&#39;t contain any wildcards or escape characters.</li>\n</ul>\n<p>For example, <code>SCAN 0 MATCH {abc}*</code> can successfully recognize the hashtag and scans only the slot corresponding to <code>abc</code>.<br>However, the patterns <code>*{abc}</code>, <code>{a*c}</code>, or <code>{a\\*bc}</code> cannot recognize the hashtag, so all slots need to be scanned.</p>\n<h4>Hash slot example code</h4>\n<p>Adding the hash tags exception, the following is an implementation of the <code>HASH_SLOT</code> function in Ruby and C language.</p>\n<p>Ruby example code:</p>\n<pre><code>def HASH_SLOT(key)\n    s = key.index &quot;{&quot;\n    if s\n        e = key.index &quot;}&quot;,s+1\n        if e &amp;&amp; e != s+1\n            key = key[s+1..e-1]\n        end\n    end\n    crc16(key) % 16384\nend\n</code></pre>\n<p>C example code:</p>\n<pre><code>unsigned int HASH_SLOT(char *key, int keylen) {\n    int s, e; /* start-end indexes of { and } */\n\n    /* Search the first occurrence of &#39;{&#39;. */\n    for (s = 0; s &lt; keylen; s++)\n        if (key[s] == &#39;{&#39;) break;\n\n    /* No &#39;{&#39; ? Hash the whole key. This is the base case. */\n    if (s == keylen) return crc16(key,keylen) &amp; 16383;\n\n    /* &#39;{&#39; found? Check if we have the corresponding &#39;}&#39;. */\n    for (e = s+1; e &lt; keylen; e++)\n        if (key[e] == &#39;}&#39;) break;\n\n    /* No &#39;}&#39; or nothing between {} ? Hash the whole key. */\n    if (e == keylen || e == s+1) return crc16(key,keylen) &amp; 16383;\n\n    /* If we are here there is both a { and a } on its right. Hash\n     * what is in the middle between { and }. */\n    return crc16(key+s+1,e-s-1) &amp; 16383;\n}\n</code></pre>\n<h3>Cluster node attributes</h3>\n<p>Every node has a unique name in the cluster. The node name is the<br>hex representation of a 160 bit random number, obtained the first time a<br>node is started (usually using /dev/urandom).<br>The node will save its ID in the node configuration file, and will use the<br>same ID forever, or at least as long as the node configuration file is not<br>deleted by the system administrator, or a <em>hard reset</em> is requested<br>via the <code>CLUSTER RESET</code> command.</p>\n<p>The node ID is used to identify every node across the whole cluster.<br>It is possible for a given node to change its IP address without any need<br>to also change the node ID. The cluster is also able to detect the change<br>in IP/port and reconfigure using the gossip protocol running over the cluster<br>bus.</p>\n<p>The node ID is not the only information associated with each node, but is<br>the only one that is always globally consistent. Every node has also the<br>following set of information associated. Some information is about the<br>cluster configuration detail of this specific node, and is eventually<br>consistent across the cluster. Some other information, like the last time<br>a node was pinged, is instead local to each node.</p>\n<p>Every node maintains the following information about other nodes that it is<br>aware of in the cluster: The node ID, IP and port of the node, a set of<br>flags, what is the primary of the node if it is flagged as <code>replica</code>, last time<br>the node was pinged and the last time the pong was received, the current<br><em>configuration epoch</em> of the node (explained later in this specification),<br>the link state and finally the set of hash slots served.</p>\n<p>A detailed <a href=\"../commands/cluster-nodes\">explanation of all the node fields</a> is described in the <code>CLUSTER NODES</code> documentation.</p>\n<p>The <code>CLUSTER NODES</code> command can be sent to any node in the cluster and provides the state of the cluster and the information for each node according to the local view the queried node has of the cluster.</p>\n<p>The following is sample output of the <code>CLUSTER NODES</code> command sent to a primary<br>node in a small cluster of three nodes.</p>\n<pre><code>$ valkey-cli cluster nodes\nd1861060fe6a534d42d8a19aeb36600e18785e04 127.0.0.1:6379 myself - 0 1318428930 1 connected 0-1364\n3886e65cc906bfd9b1f7e7bde468726a052d1dae 127.0.0.1:6380 master - 1318428930 1318428931 2 connected 1365-2729\nd289c575dcbc4bdd2931585fd4339089e461a27d 127.0.0.1:6381 master - 1318428931 1318428931 3 connected 2730-4095\n</code></pre>\n<p>In the above listing the different fields are in order: node id, address:port, flags, last ping sent, last pong received, configuration epoch, link state, slots. Details about the above fields will be covered as soon as we talk of specific parts of Valkey Cluster.</p>\n<h3>The cluster bus</h3>\n<p>Every Valkey Cluster node has an additional TCP port for receiving<br>incoming connections from other Valkey Cluster nodes. This port will be derived by adding 10000 to the data port or it can be specified with the cluster-port config. </p>\n<p>Example 1:</p>\n<p>If a Valkey node is listening for client connections on port 6379,<br>and you do not add cluster-port parameter in valkey.conf,<br>the Cluster bus port 16379 will be opened.</p>\n<p>Example 2:</p>\n<p>If a Valkey node is listening for client connections on port 6379,<br>and you set cluster-port 20000 in valkey.conf,<br>the Cluster bus port 20000 will be opened.</p>\n<p>Node-to-node communication happens exclusively using the Cluster bus and<br>the Cluster bus protocol: a binary protocol composed of frames<br>of different types and sizes. The Cluster bus binary protocol is not<br>publicly documented since it is not intended for external software devices<br>to talk with Valkey Cluster nodes using this protocol. However you can<br>obtain more details about the Cluster bus protocol by reading the<br><code>cluster.h</code> and <code>cluster.c</code> files in the Valkey Cluster source code.</p>\n<h3>Cluster topology</h3>\n<p>Valkey Cluster is a full mesh where every node is connected with every other node using a TCP connection.</p>\n<p>In a cluster of N nodes, every node has N-1 outgoing TCP connections, and N-1 incoming connections.</p>\n<p>These TCP connections are kept alive all the time and are not created on demand.<br>When a node expects a pong reply in response to a ping in the cluster bus, before waiting long enough to mark the node as unreachable, it will try to<br>refresh the connection with the node by reconnecting from scratch.</p>\n<p>While Valkey Cluster nodes form a full mesh, <strong>nodes use a gossip protocol and<br>a configuration update mechanism in order to avoid exchanging too many<br>messages between nodes during normal conditions</strong>, so the number of messages<br>exchanged is not exponential.</p>\n<h3>Node handshake</h3>\n<p>Nodes always accept connections on the cluster bus port, and even reply to<br>pings when received, even if the pinging node is not trusted.<br>However, all other packets will be discarded by the receiving node if the<br>sending node is not considered part of the cluster.</p>\n<p>A node will accept another node as part of the cluster only in two ways:</p>\n<ul>\n<li><p>If a node presents itself with a <code>MEET</code> message (<code>CLUSTER MEET</code> command). A meet message is exactly<br>like a <code>PING</code> message, but forces the receiver to accept the node as part of<br>the cluster. Nodes will send <code>MEET</code> messages to other nodes <strong>only if</strong> the system administrator requests this via <code>CLUSTER MEET ip port</code>.</p>\n</li>\n<li><p>A node will also register another node as part of the cluster if a node that is already trusted will gossip about this other node. So if A knows B, and B knows C, eventually B will send gossip messages to A about C. When this happens, A will register C as part of the network, and will try to connect with C.</p>\n</li>\n</ul>\n<p>This means that as long as we join nodes in any connected graph, they&#39;ll eventually form a fully connected graph automatically. This means that the cluster is able to auto-discover other nodes, but only if there is a trusted relationship that was forced by the system administrator.</p>\n<p>This mechanism makes the cluster more robust but prevents different Valkey clusters from accidentally mixing after change of IP addresses or other network related events.</p>\n<h2>Redirection and resharding</h2>\n<h3>MOVED Redirection</h3>\n<p>A Valkey client is free to send queries to every node in the cluster, including<br>replica nodes. The node will analyze the query, and if it is acceptable<br>(that is, only a single key is mentioned in the query, or the multiple keys<br>mentioned are all to the same hash slot) it will lookup what<br>node is responsible for the hash slot where the key or keys belong.</p>\n<p>If the hash slot is served by the node, the query is simply processed, otherwise<br>the node will check its internal hash slot to node map, and will reply<br>to the client with a MOVED error, like in the following example:</p>\n<pre><code>GET x\n-MOVED 3999 127.0.0.1:6381\n</code></pre>\n<p>The error includes the hash slot of the key (3999) and the endpoint:port of the instance that can serve the query.<br>The client needs to reissue the query to the specified node&#39;s endpoint address and port.<br>The endpoint can be either an IP address, a hostname, or it can be empty (e.g. <code>-MOVED 3999 :6380</code>).<br>An empty endpoint indicates that the server node has an unknown endpoint, and the client should send the next request to the same endpoint as the current request but with the provided port. </p>\n<p>Note that even if the client waits a long time before reissuing the query,<br>and in the meantime the cluster configuration changed, the destination node<br>will reply again with a MOVED error if the hash slot 3999 is now served by<br>another node. The same happens if the contacted node had no updated information.</p>\n<p>So while from the point of view of the cluster nodes are identified by<br>IDs we try to simplify our interface with the client just exposing a map<br>between hash slots and Valkey nodes identified by endpoint:port pairs.</p>\n<p>The client is not required to, but should try to memorize that hash slot<br>3999 is served by 127.0.0.1:6381. This way once a new command needs to<br>be issued it can compute the hash slot of the target key and have a<br>greater chance of choosing the right node.</p>\n<p>An alternative is to just refresh the whole client-side cluster layout<br>using the <code>CLUSTER SHARDS</code>, or the deprecated <code>CLUSTER SLOTS</code>, command<br>when a MOVED redirection is received. When a redirection is encountered, it<br>is likely multiple slots were reconfigured rather than just one, so updating<br>the client configuration as soon as possible is often the best strategy.</p>\n<p>Note that when the Cluster is stable (no ongoing changes in the configuration),<br>eventually all the clients will obtain a map of hash slots -&gt; nodes, making<br>the cluster efficient, with clients directly addressing the right nodes<br>without redirections, proxies or other single point of failure entities.</p>\n<p>A client <strong>must be also able to handle -ASK redirections</strong> that are described<br>later in this document, otherwise it is not a complete Valkey Cluster client.</p>\n<h3>Live resharding</h3>\n<p>Valkey Cluster supports the ability to add and remove nodes while the cluster<br>is running. Adding or removing a node is abstracted into the same<br>operation: moving a hash slot from one node to another. This means<br>that the same basic mechanism can be used in order to rebalance the cluster, add<br>or remove nodes, and so forth.</p>\n<ul>\n<li>To add a new node to the cluster an empty node is added to the cluster and some set of hash slots are moved from existing nodes to the new node.</li>\n<li>To remove a node from the cluster the hash slots assigned to that node are moved to other existing nodes.</li>\n<li>To rebalance the cluster a given set of hash slots are moved between nodes.</li>\n</ul>\n<p>The core of the implementation is the ability to move hash slots around.<br>From a practical point of view a hash slot is just a set of keys, so<br>what Valkey Cluster really does during <em>resharding</em> is to move keys from<br>an instance to another instance. Moving a hash slot means moving all the keys<br>that happen to hash into this hash slot.</p>\n<p>To understand how this works we need to show the <code>CLUSTER</code> subcommands<br>that are used to manipulate the slots translation table in a Valkey Cluster node.</p>\n<p>The following subcommands are available (among others not useful in this case):</p>\n<ul>\n<li><code>CLUSTER ADDSLOTS</code> slot1 [slot2] ... [slotN]</li>\n<li><code>CLUSTER DELSLOTS</code> slot1 [slot2] ... [slotN]</li>\n<li><code>CLUSTER ADDSLOTSRANGE</code> start-slot1 end-slot1 [start-slot2 end-slot2] ... [start-slotN end-slotN]</li>\n<li><code>CLUSTER DELSLOTSRANGE</code> start-slot1 end-slot1 [start-slot2 end-slot2] ... [start-slotN end-slotN]</li>\n<li><code>CLUSTER SETSLOT</code> slot NODE node</li>\n<li><code>CLUSTER SETSLOT</code> slot MIGRATING node</li>\n<li><code>CLUSTER SETSLOT</code> slot IMPORTING node</li>\n</ul>\n<p>The first four commands, <code>ADDSLOTS</code>, <code>DELSLOTS</code>, <code>ADDSLOTSRANGE</code> and <code>DELSLOTSRANGE</code>, are simply used to assign<br>(or remove) slots to a Valkey node. Assigning a slot means to tell a given<br>primary node that it will be in charge of storing and serving content for<br>the specified hash slot.</p>\n<p>After the hash slots are assigned they will propagate across the cluster<br>using the gossip protocol, as specified later in the<br><em>configuration propagation</em> section.</p>\n<p>The <code>ADDSLOTS</code> and <code>ADDSLOTSRANGE</code> commands are usually used when a new cluster is created<br>from scratch to assign each primary node a subset of all the 16384 hash<br>slots available.</p>\n<p>The <code>DELSLOTS</code>  and <code>DELSLOTSRANGE</code> are mainly used for manual modification of a cluster configuration<br>or for debugging tasks: in practice it is rarely used.</p>\n<p>The <code>SETSLOT</code> subcommand is used to assign a slot to a specific node ID if<br>the <code>SETSLOT &lt;slot&gt; NODE</code> form is used. Otherwise the slot can be set in the<br>two special states <code>MIGRATING</code> and <code>IMPORTING</code>. Those two special states<br>are used in order to migrate a hash slot from one node to another.</p>\n<ul>\n<li>When a slot is set as MIGRATING, the node will accept all queries that<br>are about this hash slot, but only if the key in question<br>exists, otherwise the query is forwarded using a <code>-ASK</code> redirection to the<br>node that is target of the migration.</li>\n<li>When a slot is set as IMPORTING, the node will accept all queries that<br>are about this hash slot, but only if the request is<br>preceded by an <code>ASKING</code> command. If the <code>ASKING</code> command was not given<br>by the client, the query is redirected to the real hash slot owner via<br>a <code>-MOVED</code> redirection error, as would happen normally.</li>\n</ul>\n<p>Let&#39;s make this clearer with an example of hash slot migration.<br>Assume that we have two Valkey primary nodes, called A and B.<br>We want to move hash slot 8 from A to B, so we issue commands like this:</p>\n<ul>\n<li>We send B: CLUSTER SETSLOT 8 IMPORTING A</li>\n<li>We send A: CLUSTER SETSLOT 8 MIGRATING B</li>\n</ul>\n<p>All the other nodes will continue to point clients to node &quot;A&quot; every time<br>they are queried with a key that belongs to hash slot 8, so what happens<br>is that:</p>\n<ul>\n<li>All queries about existing keys are processed by &quot;A&quot;.</li>\n<li>All queries about non-existing keys in A are processed by &quot;B&quot;, because &quot;A&quot; will redirect clients to &quot;B&quot;.</li>\n</ul>\n<p>This way we no longer create new keys in &quot;A&quot;.<br>In the meantime, <code>valkey-cli</code> used during reshardings<br>and Valkey Cluster configuration will migrate existing keys in<br>hash slot 8 from A to B.<br>This is performed using the following command:</p>\n<pre><code>CLUSTER GETKEYSINSLOT slot count\n</code></pre>\n<p>The above command will return <code>count</code> keys in the specified hash slot.<br>For keys returned, <code>valkey-cli</code> sends node &quot;A&quot; a <code>MIGRATE</code> command, that<br>will migrate the specified keys from A to B in an atomic way (both instances<br>are locked for the time (usually very small time) needed to migrate keys so<br>there are no race conditions). This is how <code>MIGRATE</code> works:</p>\n<pre><code>MIGRATE target_host target_port &quot;&quot; target_database id timeout KEYS key1 key2 ...\n</code></pre>\n<p><code>MIGRATE</code> will connect to the target instance, send a serialized version of<br>the key, and once an OK code is received, the old key from its own dataset<br>will be deleted. From the point of view of an external client a key exists<br>either in A or B at any given time.</p>\n<p>In Valkey Cluster there is no need to specify a database other than 0, but<br><code>MIGRATE</code> is a general command that can be used for other tasks not<br>involving Valkey Cluster.<br><code>MIGRATE</code> is optimized to be as fast as possible even when moving complex<br>keys such as long lists, but in Valkey Cluster reconfiguring the<br>cluster where big keys are present is not considered a wise procedure if<br>there are latency constraints in the application using the database.</p>\n<p>When the migration process is finally finished, the <code>SETSLOT &lt;slot&gt; NODE &lt;node-id&gt;</code> command is sent to the two nodes involved in the migration in order to<br>set the slots to their normal state again. The same command is usually<br>sent to all other nodes to avoid waiting for the natural<br>propagation of the new configuration across the cluster.</p>\n<h4>Replication of <code>CLUSTER SETSLOT</code></h4>\n<p>Starting from Valkey 8.0, the <code>CLUSTER SETSLOT</code> command is replicated if the replicas are running Valkey version 8.0+.<br>The primary node waits up to 2 seconds, by default, for all healthy replicas to acknowledge the replication.<br>If not all health replicas acknowledge the replication within this time frame, the primary aborts the command,<br>and the client receives a <code>NOREPLICAS Not enough good replicas to write</code> error.<br>Operators can retry the command or customize the timeout using the <code>TIMEOUT</code> parameter to further increase the<br>reliability of live resharding:</p>\n<pre><code>CLUSTER SETSLOT slot [MIGRATING|IMPORTING|NODE] node-id [TIMEOUT timeout]\n</code></pre>\n<p>The <code>timeout</code> is specified in seconds, where a value of 0 indicates an indefinite wait time.</p>\n<p>Replicating the slot information and ensuring acknowledgement from health replicas significantly reduces<br>the likelihood of losing replication states if the primary fails after executing the command.<br>For example, consider a scenario where the target primary node <code>B</code> is finalizing a slot migration.<br>Before the <code>SETSLOT</code> command is replicated to its replica node <code>B’</code>, <code>B</code> might send a cluster <code>PONG</code><br>message to the source primary node <code>A</code>, promoting <code>A</code> to relinquish its ownership of the slot in question.<br>If <code>B</code> crashes right after this point, the replica node <code>B’</code>, which could be elected as the new primary,<br>would not be aware of the slot ownership transfer without the successful replication of <code>SETSLOT</code>.<br>This would leave the slot without an owner, leading to potential data loss and cluster topology inconsistency.</p>\n<h4>Election in empty shards</h4>\n<p>Starting from Valkey 8.0, Valkey clusters introduce the ability to elect a primary in empty shards.<br>This behavior ensures that even when a shard is in the process of receiving its first slot,<br>a primary can be elected. This prevents scenarios where there would be no primary available in the<br>empty shard to handle redirected requests from the official slot owner,<br>thereby maintaining availability during the live resharding.</p>\n<h3>ASK redirection</h3>\n<p>In the previous section, we briefly talked about ASK redirection. Why can&#39;t<br>we simply use MOVED redirection? Because while MOVED means that<br>we think the hash slot is permanently served by a different node and the<br>next queries should be tried against the specified node. ASK means to<br>send only the next query to the specified node.</p>\n<p>This is needed because the next query about hash slot 8 can be about a<br>key that is still in A, so we always want the client to try A and<br>then B if needed. Since this happens only for one hash slot out of 16384<br>available, the performance hit on the cluster is acceptable.</p>\n<p>We need to force that client behavior, so to make sure<br>that clients will only try node B after A was tried, node B will only<br>accept queries of a slot that is set as IMPORTING if the client sends the<br>ASKING command before sending the query.</p>\n<p>Basically the ASKING command sets a one-time flag on the client that forces<br>a node to serve a query about an IMPORTING slot.</p>\n<p>The full semantics of ASK redirection from the point of view of the client is as follows:</p>\n<ul>\n<li>If ASK redirection is received, send only the query that was redirected to the specified node but continue sending subsequent queries to the old node.</li>\n<li>Start the redirected query with the ASKING command.</li>\n<li>Don&#39;t yet update local client tables to map hash slot 8 to B.</li>\n</ul>\n<p>Once hash slot 8 migration is completed, A will send a MOVED message and<br>the client may permanently map hash slot 8 to the new endpoint and port pair.<br>Note that if a buggy client performs the map earlier this is not<br>a problem since it will not send the ASKING command before issuing the query,<br>so B will redirect the client to A using a MOVED redirection error.</p>\n<p>Slots migration is explained in similar terms but with different wording<br>(for the sake of redundancy in the documentation) in the <code>CLUSTER SETSLOT</code><br>command documentation.</p>\n<p>Starting from Valkey 8.0, when the primary in either the source or target shard fails during live resharding,<br>the primary in the other shard will automatically attempt to update its migrating/importing state to correctly pair<br>with the newly elected primary. If this update is successful, the ASK redirection will continue functioning without<br>requiring administrator intervention. In the event that slot migration fails, administrators can manually resume<br>the interrupted slot migration by running the command <code>valkey-cli --cluster fix &lt;ip:port&gt;</code>.</p>\n<p>Additionally, since Valkey 8.0, replicas are now able to return <code>ASK</code> redirects during slot migrations.<br>This capability was previously unavailable, as replicas were not aware of ongoing slot migrations in earlier versions.<br>See the <a href=\"../commands/readonly\">READONLY</a> command.</p>\n<h3>Client connections and redirection handling</h3>\n<p>To be efficient, Valkey Cluster clients maintain a map of the current slot<br>configuration. However, this configuration is not <em>required</em> to be up to date.<br>When contacting the wrong node results in a redirection, the client<br>can update its internal slot map accordingly.</p>\n<p>Clients usually need to fetch a complete list of slots and mapped node<br>addresses in two different situations:</p>\n<ul>\n<li>At startup, to populate the initial slots configuration</li>\n<li>When the client receives a <code>MOVED</code> redirection</li>\n</ul>\n<p>Note that a client may handle the <code>MOVED</code> redirection by updating just the<br>moved slot in its table; however this is usually not efficient because often<br>the configuration of multiple slots will be modified at once. For example, if a<br>replica is promoted to primary, all of the slots served by the old primary will<br>be remapped). It is much simpler to react to a <code>MOVED</code> redirection by<br>fetching the full map of slots to nodes from scratch.</p>\n<p>Client can issue a <code>CLUSTER SLOTS</code> command to retrieve an array of slot<br>ranges and the associated primary and replica nodes serving the specified ranges.</p>\n<p>The following is an example of output of <code>CLUSTER SLOTS</code>:</p>\n<pre><code>127.0.0.1:7000&gt; cluster slots\n1) 1) (integer) 5461\n   2) (integer) 10922\n   3) 1) &quot;127.0.0.1&quot;\n      2) (integer) 7001\n   4) 1) &quot;127.0.0.1&quot;\n      2) (integer) 7004\n2) 1) (integer) 0\n   2) (integer) 5460\n   3) 1) &quot;127.0.0.1&quot;\n      2) (integer) 7000\n   4) 1) &quot;127.0.0.1&quot;\n      2) (integer) 7003\n3) 1) (integer) 10923\n   2) (integer) 16383\n   3) 1) &quot;127.0.0.1&quot;\n      2) (integer) 7002\n   4) 1) &quot;127.0.0.1&quot;\n      2) (integer) 7005\n</code></pre>\n<p>The first two sub-elements of every element of the returned array are the<br>start and end slots of the range. The additional elements represent address-port<br>pairs. The first address-port pair is the primary serving the slot, and the<br>additional address-port pairs are the replicas serving the same slot. Replicas<br>will be listed only when not in an error condition (i.e., when their FAIL flag is not set).</p>\n<p>The first element in the output above says that slots from 5461 to 10922<br>(start and end included) are served by 127.0.0.1:7001, and it is possible<br>to scale read-only load contacting the replica at 127.0.0.1:7004.</p>\n<p><code>CLUSTER SLOTS</code> is not guaranteed to return ranges that cover the full<br>16384 slots if the cluster is misconfigured, so clients should initialize the<br>slots configuration map filling the target nodes with NULL objects, and<br>report an error if the user tries to execute commands about keys<br>that belong to unassigned slots.</p>\n<p>Before returning an error to the caller when a slot is found to<br>be unassigned, the client should try to fetch the slots configuration<br>again to check if the cluster is now configured properly.</p>\n<h3>Multi-keys operations</h3>\n<p>Using hash tags, clients are free to use multi-key operations.<br>For example the following operation is valid:</p>\n<pre><code>MSET {user:1000}.name Angela {user:1000}.surname White\n</code></pre>\n<p>Multi-key operations may become unavailable when a resharding of the<br>hash slot the keys belong to is in progress.</p>\n<p>More specifically, even during a resharding the multi-key operations targeting<br>keys that all exist and all still hash to the same slot (either the source or<br>destination node) are still available.</p>\n<p>Operations on keys that don&#39;t exist or are - during the resharding - split<br>between the source and destination nodes, will generate a <code>-TRYAGAIN</code> error.<br>The client can try the operation after some time, or report back the error.</p>\n<p>As soon as migration of the specified hash slot has terminated, all<br>multi-key operations are available again for that hash slot.</p>\n<h3>Scaling reads using replica nodes</h3>\n<p>Normally replica nodes will redirect clients to the authoritative primary for<br>the hash slot involved in a given command, however clients can use replicas<br>in order to scale reads using the <code>READONLY</code> command.</p>\n<p><code>READONLY</code> tells a Valkey Cluster replica node that the client is ok reading<br>possibly stale data and is not interested in running write queries.</p>\n<p>When the connection is in readonly mode, the cluster will send a redirection<br>to the client only if the operation involves keys not served<br>by the replica&#39;s primary node. This may happen because:</p>\n<ol>\n<li>The client sent a command about hash slots never served by the primary of this replica.</li>\n<li>The cluster was reconfigured (for example resharded) and the replica is no longer able to serve commands for a given hash slot.</li>\n</ol>\n<p>When this happens the client should update its hash slot map as explained in<br>the previous sections.</p>\n<p>The readonly state of the connection can be cleared using the <code>READWRITE</code> command.</p>\n<h2>Fault Tolerance</h2>\n<h3>Heartbeat and gossip messages</h3>\n<p>Valkey Cluster nodes continuously exchange ping and pong packets. Those two kinds of packets have the same structure, and both carry important configuration information. The only actual difference is the message type field. We&#39;ll refer to the sum of ping and pong packets as <em>heartbeat packets</em>.</p>\n<p>Usually nodes send ping packets that will trigger the receivers to reply with pong packets. However this is not necessarily true. It is possible for nodes to just send pong packets to send information to other nodes about their configuration, without triggering a reply. This is useful, for example, in order to broadcast a new configuration as soon as possible.</p>\n<p>Usually a node will ping a few random nodes every second so that the total number of ping packets sent (and pong packets received) by each node is a constant amount regardless of the number of nodes in the cluster.</p>\n<p>However every node makes sure to ping every other node that hasn&#39;t sent a ping or received a pong for longer than half the <code>NODE_TIMEOUT</code> time. Before <code>NODE_TIMEOUT</code> has elapsed, nodes also try to reconnect the TCP link with another node to make sure nodes are not believed to be unreachable only because there is a problem in the current TCP connection.</p>\n<p>The number of messages globally exchanged can be sizable if <code>NODE_TIMEOUT</code> is set to a small figure and the number of nodes (N) is very large, since every node will try to ping every other node for which they don&#39;t have fresh information every half the <code>NODE_TIMEOUT</code> time.</p>\n<p>For example in a 100 node cluster with a node timeout set to 60 seconds, every node will try to send 99 pings every 30 seconds, with a total amount of pings of 3.3 per second. Multiplied by 100 nodes, this is 330 pings per second in the total cluster.</p>\n<p>There are ways to lower the number of messages, however there have been no<br>reported issues with the bandwidth currently used by Valkey Cluster failure<br>detection, so for now the obvious and direct design is used. Note that even<br>in the above example, the 330 packets per second exchanged are evenly<br>divided among 100 different nodes, so the traffic each node receives<br>is acceptable.</p>\n<h3>Heartbeat packet content</h3>\n<p>Ping and pong packets contain a header that is common to all types of packets (for instance packets to request a failover vote), and a special gossip section that is specific to Ping and Pong packets.</p>\n<p>The common header has the following information:</p>\n<ul>\n<li>Node ID, a 160 bit pseudorandom string that is assigned the first time a node is created and remains the same for all the life of a Valkey Cluster node.</li>\n<li>The <code>currentEpoch</code> and <code>configEpoch</code> fields of the sending node that are used to mount the distributed algorithms used by Valkey Cluster (this is explained in detail in the next sections). If the node is a replica the <code>configEpoch</code> is the last known <code>configEpoch</code> of its primary.</li>\n<li>The node flags, indicating if the node is a replica, a primary, and other single-bit node information.</li>\n<li>A bitmap of the hash slots served by the sending node, or if the node is a replica, a bitmap of the slots served by its primary.</li>\n<li>The sender TCP base port that is the port used by Valkey to accept client commands.</li>\n<li>The cluster port that is the port used by Valkey for node-to-node communication.</li>\n<li>The state of the cluster from the point of view of the sender (down or ok).</li>\n<li>The primary node ID of the sending node, if it is a replica.</li>\n</ul>\n<p>Ping and pong packets also contain a gossip section. This section offers to the receiver a view of what the sender node thinks about other nodes in the cluster. The gossip section only contains information about a few random nodes among the set of nodes known to the sender. The number of nodes mentioned in a gossip section is proportional to the cluster size.</p>\n<p>For every node added in the gossip section the following fields are reported:</p>\n<ul>\n<li>Node ID.</li>\n<li>IP and port of the node.</li>\n<li>Node flags.</li>\n</ul>\n<p>Gossip sections allow receiving nodes to get information about the state of other nodes from the point of view of the sender. This is useful both for failure detection and to discover other nodes in the cluster.</p>\n<h3>Failure detection</h3>\n<p>Valkey Cluster failure detection is used to recognize when a primary or replica node is no longer reachable by the majority of nodes and then respond by promoting a replica to the role of primary. When replica promotion is not possible the cluster is put in an error state to stop receiving queries from clients.</p>\n<p>As already mentioned, every node takes a list of flags associated with other known nodes. There are two flags that are used for failure detection that are called <code>PFAIL</code> and <code>FAIL</code>. <code>PFAIL</code> means <em>Possible failure</em>, and is a non-acknowledged failure type. <code>FAIL</code> means that a node is failing and that this condition was confirmed by a majority of primaries within a fixed amount of time.</p>\n<p><strong>PFAIL flag:</strong></p>\n<p>A node flags another node with the <code>PFAIL</code> flag when the node is not reachable for more than <code>NODE_TIMEOUT</code> time. Both primary and replica nodes can flag another node as <code>PFAIL</code>, regardless of its type.</p>\n<p>The concept of non-reachability for a Valkey Cluster node is that we have an <strong>active ping</strong> (a ping that we sent for which we have yet to get a reply) pending for longer than <code>NODE_TIMEOUT</code>. For this mechanism to work the <code>NODE_TIMEOUT</code> must be large compared to the network round trip time. In order to add reliability during normal operations, nodes will try to reconnect with other nodes in the cluster as soon as half of the <code>NODE_TIMEOUT</code> has elapsed without a reply to a ping. This mechanism ensures that connections are kept alive so broken connections usually won&#39;t result in false failure reports between nodes.</p>\n<p><strong>FAIL flag:</strong></p>\n<p>The <code>PFAIL</code> flag alone is just local information every node has about other nodes, but it is not sufficient to trigger a replica promotion. For a node to be considered down the <code>PFAIL</code> condition needs to be escalated to a <code>FAIL</code> condition.</p>\n<p>As outlined in the node heartbeats section of this document, every node sends gossip messages to every other node including the state of a few random known nodes. Every node eventually receives a set of node flags for every other node. This way every node has a mechanism to signal other nodes about failure conditions they have detected.</p>\n<p>A <code>PFAIL</code> condition is escalated to a <code>FAIL</code> condition when the following set of conditions are met:</p>\n<ul>\n<li>Some node, that we&#39;ll call A, has another node B flagged as <code>PFAIL</code>.</li>\n<li>Node A collected, via gossip sections, information about the state of B from the point of view of the majority of primaries in the cluster.</li>\n<li>The majority of primaries signaled the <code>PFAIL</code> or <code>FAIL</code> condition within <code>NODE_TIMEOUT * FAIL_REPORT_VALIDITY_MULT</code> time. (The validity factor is set to 2 in the current implementation, so this is just two times the <code>NODE_TIMEOUT</code> time).</li>\n</ul>\n<p>If all the above conditions are true, Node A will:</p>\n<ul>\n<li>Mark the node as <code>FAIL</code>.</li>\n<li>Send a <code>FAIL</code> message (as opposed to a <code>FAIL</code> condition within a heartbeat message) to all the reachable nodes.</li>\n</ul>\n<p>The <code>FAIL</code> message will force every receiving node to mark the node in <code>FAIL</code> state, whether or not it already flagged the node in <code>PFAIL</code> state.</p>\n<p>Note that <em>the FAIL flag is mostly one way</em>. That is, a node can go from <code>PFAIL</code> to <code>FAIL</code>, but a <code>FAIL</code> flag can only be cleared in the following situations:</p>\n<ul>\n<li>The node is already reachable and is a replica. In this case the <code>FAIL</code> flag can be cleared as replicas are not failed over.</li>\n<li>The node is already reachable and is a primary not serving any slot. In this case the <code>FAIL</code> flag can be cleared as primaries without slots do not really participate in the cluster and are waiting to be configured in order to join the cluster.</li>\n<li>The node is already reachable and is a primary, but a long time (N times the <code>NODE_TIMEOUT</code>) has elapsed without any detectable replica promotion. It&#39;s better for it to rejoin the cluster and continue in this case.</li>\n</ul>\n<p>It is useful to note that while the <code>PFAIL</code> -&gt; <code>FAIL</code> transition uses a form of agreement, the agreement used is weak:</p>\n<ol>\n<li>Nodes collect views of other nodes over some time period, so even if the majority of primary nodes need to &quot;agree&quot;, actually this is just state that we collected from different nodes at different times and we are not sure, nor we require, that at a given moment the majority of primaries agreed. However we discard failure reports which are old, so the failure was signaled by the majority of primaries within a window of time.</li>\n<li>While every node detecting the <code>FAIL</code> condition will force that condition on other nodes in the cluster using the <code>FAIL</code> message, there is no way to ensure the message will reach all the nodes. For instance a node may detect the <code>FAIL</code> condition and because of a partition will not be able to reach any other node.</li>\n</ol>\n<p>However the Valkey Cluster failure detection has a liveness requirement: eventually all the nodes should agree about the state of a given node. There are two cases that can originate from split brain conditions. Either some minority of nodes believe the node is in <code>FAIL</code> state, or a minority of nodes believe the node is not in <code>FAIL</code> state. In both the cases eventually the cluster will have a single view of the state of a given node:</p>\n<p><strong>Case 1</strong>: If a majority of primaries have flagged a node as <code>FAIL</code>, because of failure detection and the <em>chain effect</em> it generates, every other node will eventually flag the primary as <code>FAIL</code>, since in the specified window of time enough failures will be reported.</p>\n<p><strong>Case 2</strong>: When only a minority of primaries have flagged a node as <code>FAIL</code>, the replica promotion will not happen (as it uses a more formal algorithm that makes sure everybody knows about the promotion eventually) and every node will clear the <code>FAIL</code> state as per the <code>FAIL</code> state clearing rules above (i.e. no promotion after N times the <code>NODE_TIMEOUT</code> has elapsed).</p>\n<p><strong>The <code>FAIL</code> flag is only used as a trigger to run the safe part of the algorithm</strong> for the replica promotion. In theory a replica may act independently and start a replica promotion when its primary is not reachable, and wait for the primaries to refuse to provide the acknowledgment if the primary is actually reachable by the majority. However the added complexity of the <code>PFAIL -&gt; FAIL</code> state, the weak agreement, and the <code>FAIL</code> message forcing the propagation of the state in the shortest amount of time in the reachable part of the cluster, have practical advantages. Because of these mechanisms, usually all the nodes will stop accepting writes at about the same time if the cluster is in an error state. This is a desirable feature from the point of view of applications using Valkey Cluster. Also erroneous election attempts initiated by replicas that can&#39;t reach its primary due to local problems (the primary is otherwise reachable by the majority of other primary nodes) are avoided.</p>\n<h2>Configuration handling, propagation, and failovers</h2>\n<h3>Cluster current epoch</h3>\n<p>Valkey Cluster uses a concept similar to the Raft algorithm &quot;term&quot;. In Valkey Cluster the term is called epoch instead, and it is used in order to give incremental versioning to events. When multiple nodes provide conflicting information, it becomes possible for another node to understand which state is the most up to date.</p>\n<p>The <code>currentEpoch</code> is a 64 bit unsigned number.</p>\n<p>At node creation every Valkey Cluster node, both replicas and primary nodes, set the <code>currentEpoch</code> to 0.</p>\n<p>Every time a packet is received from another node, if the epoch of the sender (part of the cluster bus messages header) is greater than the local node epoch, the <code>currentEpoch</code> is updated to the sender epoch.</p>\n<p>Because of these semantics, eventually all the nodes will agree to the greatest <code>currentEpoch</code> in the cluster.</p>\n<p>This information is used when the state of the cluster is changed and a node seeks agreement in order to perform some action.</p>\n<p>Currently this happens only during replica promotion, as described in the next section. Basically the epoch is a logical clock for the cluster and dictates that given information wins over one with a smaller epoch.</p>\n<h3>Configuration epoch</h3>\n<p>Every primary always advertises its <code>configEpoch</code> in ping and pong packets along with a bitmap advertising the set of slots it serves.</p>\n<p>The <code>configEpoch</code> is set to zero in primaries when a new node is created.</p>\n<p>A new <code>configEpoch</code> is created during replica election. Replicas trying to replace<br>failing primaries increment their epoch and try to get authorization from<br>a majority of primaries. When a replica is authorized, a new unique <code>configEpoch</code><br>is created and the replica turns into a primary using the new <code>configEpoch</code>.</p>\n<p>As explained in the next sections the <code>configEpoch</code> helps to resolve conflicts when different nodes claim divergent configurations (a condition that may happen because of network partitions and node failures).</p>\n<p>Replica nodes also advertise the <code>configEpoch</code> field in ping and pong packets, but in the case of replicas the field represents the <code>configEpoch</code> of its primary as of the last time they exchanged packets. This allows other instances to detect when a replica has an old configuration that needs to be updated (primary nodes will not grant votes to replicas with an old configuration).</p>\n<p>Every time the <code>configEpoch</code> changes for some known node, it is permanently stored in the nodes.conf file by all the nodes that receive this information. The same also happens for the <code>currentEpoch</code> value. These two variables are guaranteed to be saved and <code>fsync-ed</code> to disk when updated before a node continues its operations.</p>\n<p>The <code>configEpoch</code> values generated using a simple algorithm during failovers<br>are guaranteed to be new, incremental, and unique.</p>\n<h3>Replica election and promotion</h3>\n<p>Replica election and promotion is handled by replica nodes, with the help of the primary nodes that vote for the replica to promote.<br>A replica election happens when a primary is in <code>FAIL</code> state from the point of view of at least one of its replicas that has the prerequisites in order to become a primary.</p>\n<p>In order for a replica to promote itself to primary, it needs to start an election and win it. All the replicas for a given primary can start an election if the primary is in <code>FAIL</code> state, however only one replica will win the election and promote itself to primary.</p>\n<p>A replica starts an election when the following conditions are met:</p>\n<ul>\n<li>The replica&#39;s primary is in <code>FAIL</code> state.</li>\n<li>The primary was serving a non-zero number of slots.</li>\n<li>The replica replication link was disconnected from the primary for no longer than a given amount of time, in order to ensure the promoted replica&#39;s data is reasonably fresh. This time is user configurable.</li>\n</ul>\n<p>In order to be elected, the first step for a replica is to increment its <code>currentEpoch</code> counter, and request votes from primary instances.</p>\n<p>Votes are requested by the replica by broadcasting a <code>FAILOVER_AUTH_REQUEST</code> packet to every primary node of the cluster. Then it waits for a maximum time of two times the <code>NODE_TIMEOUT</code> for replies to arrive (but always for at least 2 seconds).</p>\n<p>Once a primary has voted for a given replica, replying positively with a <code>FAILOVER_AUTH_ACK</code>, it can no longer vote for another replica of the same primary for a period of <code>NODE_TIMEOUT * 2</code>. In this period it will not be able to reply to other authorization requests for the same primary. This is not needed to guarantee safety, but useful for preventing multiple replicas from getting elected (even if with a different <code>configEpoch</code>) at around the same time, which is usually not wanted.</p>\n<p>A replica discards any <code>AUTH_ACK</code> replies with an epoch that is less than the <code>currentEpoch</code> at the time the vote request was sent. This ensures it doesn&#39;t count votes intended for a previous election.</p>\n<p>Once the replica receives ACKs from the majority of primaries, it wins the election.<br>Otherwise if the majority is not reached within the period of two times <code>NODE_TIMEOUT</code> (but always at least 2 seconds), the election is aborted and a new one will be tried again after <code>NODE_TIMEOUT * 4</code> (and always at least 4 seconds).</p>\n<h3>Replica rank</h3>\n<p>As soon as a primary is in <code>FAIL</code> state, a replica waits a short period of time before trying to get elected. That delay is computed as follows:</p>\n<pre><code>DELAY = 500 milliseconds + random delay between 0 and 500 milliseconds +\n        REPLICA_RANK * 1000 milliseconds.\n</code></pre>\n<p>The fixed delay ensures that we wait for the <code>FAIL</code> state to propagate across the cluster, otherwise the replica may try to get elected while the primaries are still unaware of the <code>FAIL</code> state, refusing to grant their vote.</p>\n<p>The random delay is used to desynchronize replicas so they&#39;re unlikely to start an election at the same time.</p>\n<p>The <code>REPLICA_RANK</code> is the rank of this replica regarding the amount of replication data it has processed from the primary.<br>Replicas exchange messages when the primary is failing in order to establish a (best effort) rank:<br>the replica with the most updated replication offset is at rank 0, the second most updated at rank 1, and so forth.<br>In this way the most updated replicas try to get elected before others.</p>\n<p>Rank order is not strictly enforced; if a replica of higher rank fails to be<br>elected, the others will try shortly.</p>\n<p>Once a replica wins the election, it obtains a new unique and incremental <code>configEpoch</code> which is higher than that of any other existing primary. It starts advertising itself as primary in ping and pong packets, providing the set of served slots with a <code>configEpoch</code> that will win over the past ones.</p>\n<p>In order to speedup the reconfiguration of other nodes, a pong packet is broadcast to all the nodes of the cluster. Currently unreachable nodes will eventually be reconfigured when they receive a ping or pong packet from another node or will receive an <code>UPDATE</code> packet from another node if the information it publishes via heartbeat packets are detected to be out of date.</p>\n<p>The other nodes will detect that there is a new primary serving the same slots served by the old primary but with a greater <code>configEpoch</code>, and will upgrade their configuration. Replicas of the old primary (or the failed over primary if it rejoins the cluster) will not just upgrade the configuration but will also reconfigure to replicate from the new primary. How nodes rejoining the cluster are configured is explained in the next sections.</p>\n<h3>Masters reply to replica vote request</h3>\n<p>In the previous section, we discussed how replicas try to get elected. This section explains what happens from the point of view of a primary that is requested to vote for a given replica.</p>\n<p>Masters receive requests for votes in form of <code>FAILOVER_AUTH_REQUEST</code> requests from replicas.</p>\n<p>For a vote to be granted the following conditions need to be met:</p>\n<ol>\n<li>A primary only votes a single time for a given epoch, and refuses to vote for older epochs: every primary has a lastVoteEpoch field and will refuse to vote again as long as the <code>currentEpoch</code> in the auth request packet is not greater than the lastVoteEpoch. When a primary replies positively to a vote request, the lastVoteEpoch is updated accordingly, and safely stored on disk.</li>\n<li>A primary votes for a replica only if the replica&#39;s primary is flagged as <code>FAIL</code>.</li>\n<li>Auth requests with a <code>currentEpoch</code> that is less than the primary <code>currentEpoch</code> are ignored. Because of this the primary reply will always have the same <code>currentEpoch</code> as the auth request. If the same replica asks again to be voted, incrementing the <code>currentEpoch</code>, it is guaranteed that an old delayed reply from the primary can not be accepted for the new vote.</li>\n</ol>\n<p>Example of the issue caused by not using rule number 3:</p>\n<p>Primary <code>currentEpoch</code> is 5, lastVoteEpoch is 1 (this may happen after a few failed elections)</p>\n<ul>\n<li>Replica <code>currentEpoch</code> is 3.</li>\n<li>Replica tries to be elected with epoch 4 (3+1), primary replies with an ok with <code>currentEpoch</code> 5, however the reply is delayed.</li>\n<li>Replica will try to be elected again, at a later time, with epoch 5 (4+1), the delayed reply reaches the replica with <code>currentEpoch</code> 5, and is accepted as valid.</li>\n</ul>\n<ol start=\"4\">\n<li>Primaries don&#39;t vote for a replica of the same primary before <code>NODE_TIMEOUT * 2</code> has elapsed if a replica of that primary was already voted for. This is not strictly required as it is not possible for two replicas to win the election in the same epoch. However, in practical terms it ensures that when a replica is elected it has plenty of time to inform the other replicas and avoid the possibility that another replica will win a new election, performing an unnecessary second failover.</li>\n<li>Primaries make no effort to select the best replica in any way. If the replica&#39;s primary is in <code>FAIL</code> state and the primary did not vote in the current term, a positive vote is granted. The best replica is the most likely to start an election and win it before the other replicas, since it will usually be able to start the voting process earlier because of its <em>higher rank</em> as explained in the previous section.</li>\n<li>When a primary refuses to vote for a given replica there is no negative response, the request is simply ignored.</li>\n<li>Primaries don&#39;t vote for replicas sending a <code>configEpoch</code> that is less than any <code>configEpoch</code> in the primary table for the slots claimed by the replica. Remember that the replica sends the <code>configEpoch</code> of its primary, and the bitmap of the slots served by its primary. This means that the replica requesting the vote must have a configuration for the slots it wants to failover that is newer or equal the one of the primary granting the vote.</li>\n</ol>\n<h3>Practical example of configuration epoch usefulness during partitions</h3>\n<p>This section illustrates how the epoch concept is used to make the replica promotion process more resistant to partitions.</p>\n<ul>\n<li>A primary is no longer reachable indefinitely. The primary has three replicas A, B, C.</li>\n<li>Replica A wins the election and is promoted to primary.</li>\n<li>A network partition makes A not available for the majority of the cluster.</li>\n<li>Replica B wins the election and is promoted as primary.</li>\n<li>A partition makes B not available for the majority of the cluster.</li>\n<li>The previous partition is fixed, and A is available again.</li>\n</ul>\n<p>At this point B is down and A is available again with a role of primary (actually <code>UPDATE</code> messages would reconfigure it promptly, but here we assume all <code>UPDATE</code> messages were lost). At the same time, replica C will try to get elected in order to fail over B. This is what happens:</p>\n<ol>\n<li>C will try to get elected and will succeed, since for the majority of primaries its primary is actually down. It will obtain a new incremental <code>configEpoch</code>.</li>\n<li>A will not be able to claim to be the primary for its hash slots, because the other nodes already have the same hash slots associated with a higher configuration epoch (the one of B) compared to the one published by A.</li>\n<li>So, all the nodes will upgrade their table to assign the hash slots to C, and the cluster will continue its operations.</li>\n</ol>\n<p>As you&#39;ll see in the next sections, a stale node rejoining a cluster<br>will usually get notified as soon as possible about the configuration change<br>because as soon as it pings any other node, the receiver will detect it<br>has stale information and will send an <code>UPDATE</code> message.</p>\n<h3>Hash slots configuration propagation</h3>\n<p>An important part of Valkey Cluster is the mechanism used to propagate the information about which cluster node is serving a given set of hash slots. This is vital to both the startup of a fresh cluster and the ability to upgrade the configuration after a replica was promoted to serve the slots of its failing primary.</p>\n<p>The same mechanism allows nodes partitioned away for an indefinite amount of<br>time to rejoin the cluster in a sensible way.</p>\n<p>There are two ways hash slot configurations are propagated:</p>\n<ol>\n<li>Heartbeat messages. The sender of a ping or pong packet always adds information about the set of hash slots it (or its primary, if it is a replica) serves.</li>\n<li><code>UPDATE</code> messages. Since in every heartbeat packet there is information about the sender <code>configEpoch</code> and set of hash slots served, if a receiver of a heartbeat packet finds the sender information is stale, it will send a packet with new information, forcing the stale node to update its info.</li>\n</ol>\n<p>The receiver of a heartbeat or <code>UPDATE</code> message uses certain simple rules in<br>order to update its table mapping hash slots to nodes. When a new Valkey Cluster node is created, its local hash slot table is simply initialized to <code>NULL</code> entries so that each hash slot is not bound or linked to any node. This looks similar to the following:</p>\n<pre><code>0 -&gt; NULL\n1 -&gt; NULL\n2 -&gt; NULL\n...\n16383 -&gt; NULL\n</code></pre>\n<p>The first rule followed by a node in order to update its hash slot table is the following:</p>\n<p><strong>Rule 1</strong>: If a hash slot is unassigned (set to <code>NULL</code>), and a known node claims it, I&#39;ll modify my hash slot table and associate the claimed hash slots to it.</p>\n<p>So if we receive a heartbeat from node A claiming to serve hash slots 1 and 2 with a configuration epoch value of 3, the table will be modified to:</p>\n<pre><code>0 -&gt; NULL\n1 -&gt; A [3]\n2 -&gt; A [3]\n...\n16383 -&gt; NULL\n</code></pre>\n<p>When a new cluster is created, a system administrator needs to manually assign (using the <code>CLUSTER ADDSLOTS</code> command, via the valkey-cli command line tool, or by any other means) the slots served by each primary node only to the node itself, and the information will rapidly propagate across the cluster.</p>\n<p>However this rule is not enough. We know that hash slot mapping can change<br>during two events:</p>\n<ol>\n<li>A replica replaces its primary during a failover.</li>\n<li>A slot is resharded from a node to a different one.</li>\n</ol>\n<p>For now let&#39;s focus on failovers. When a replica fails over its primary, it obtains<br>a configuration epoch which is guaranteed to be greater than the one of its<br>primary (and more generally greater than any other configuration epoch<br>generated previously). For example node B, which is a replica of A, may failover<br>A with configuration epoch of 4. It will start to send heartbeat packets<br>(the first time mass-broadcasting cluster-wide) and because of the following<br>second rule, receivers will update their hash slot tables:</p>\n<p><strong>Rule 2</strong>: If a hash slot is already assigned, and a known node is advertising it using a <code>configEpoch</code> that is greater than the <code>configEpoch</code> of the primary currently associated with the slot, it&#39;ll rebind the hash slot to the new node.</p>\n<p>So after receiving messages from B that claim to serve hash slots 1 and 2 with configuration epoch of 4, the receivers will update their table in the following way:</p>\n<pre><code>0 -&gt; NULL\n1 -&gt; B [4]\n2 -&gt; B [4]\n...\n16383 -&gt; NULL\n</code></pre>\n<p>Liveness property: because of the second rule, eventually all nodes in the cluster will agree that the owner of a slot is the one with the greatest <code>configEpoch</code> among the nodes advertising it.</p>\n<p>This mechanism in Valkey Cluster is called <strong>last failover wins</strong>.</p>\n<p>The same happens during resharding. When a node importing a hash slot completes<br>the import operation, its configuration epoch is incremented to make sure the<br>change will be propagated throughout the cluster.</p>\n<h3>UPDATE messages, a closer look</h3>\n<p>With the previous section in mind, it is easier to see how update messages<br>work. Node A may rejoin the cluster after some time. It will send heartbeat<br>packets where it claims it serves hash slots 1 and 2 with configuration epoch<br>of 3. All the receivers with updated information will instead see that<br>the same hash slots are associated with node B having a higher configuration<br>epoch. Because of this they&#39;ll send an <code>UPDATE</code> message to A with the new<br>configuration for the slots. A will update its configuration because of the<br><strong>rule 2</strong> above.</p>\n<h3>How nodes rejoin the cluster</h3>\n<p>The same basic mechanism is used when a node rejoins a cluster.<br>Continuing with the example above, node A will be notified<br>that hash slots 1 and 2 are now served by B. Assuming that these two were<br>the only hash slots served by A, the count of hash slots served by A will<br>drop to 0! So A will <strong>reconfigure to be a replica of the new primary</strong>.</p>\n<p>The actual rule followed is a bit more complex than this. In general it may<br>happen that A rejoins after a lot of time, in the meantime it may happen that<br>hash slots originally served by A are served by multiple nodes, for example<br>hash slot 1 may be served by B, and hash slot 2 by C.</p>\n<p>So the actual <em>Valkey Cluster node role switch rule</em> is: <strong>A primary node will change its configuration to replicate (be a replica of) the node that stole its last hash slot</strong>.</p>\n<p>During reconfiguration, eventually the number of served hash slots will drop to zero, and the node will reconfigure accordingly. Note that in the base case this just means that the old primary will be a replica of the replica that replaced it after a failover. However in the general form the rule covers all possible cases.</p>\n<p>Replicas do exactly the same: they reconfigure to replicate the node that<br>stole the last hash slot of its former primary.</p>\n<h3>Replica migration</h3>\n<p>Valkey Cluster implements a concept called <em>replica migration</em> in order to<br>improve the availability of the system. The idea is that in a cluster with<br>a primary-replica setup, if the map between replicas and primaries is fixed<br>availability is limited over time if multiple independent failures of single<br>nodes happen.</p>\n<p>For example in a cluster where every primary has a single replica, the cluster<br>can continue operations as long as either the primary or the replica fail, but not<br>if both fail the same time. However there is a class of failures that are<br>the independent failures of single nodes caused by hardware or software issues<br>that can accumulate over time. For example:</p>\n<ul>\n<li>Master A has a single replica A1.</li>\n<li>Master A fails. A1 is promoted as new primary.</li>\n<li>Three hours later A1 fails in an independent manner (unrelated to the failure of A). No other replica is available for promotion since node A is still down. The cluster cannot continue normal operations.</li>\n</ul>\n<p>If the map between primaries and replicas is fixed, the only way to make the cluster<br>more resistant to the above scenario is to add replicas to every primary, however<br>this is costly as it requires more instances of Valkey to be executed, more<br>memory, and so forth.</p>\n<p>An alternative is to create an asymmetry in the cluster, and let the cluster<br>layout automatically change over time. For example the cluster may have three<br>primaries A, B, C. A and B have a single replica each, A1 and B1. However, the primary<br>C is different and has two replicas: C1 and C2.</p>\n<p>Replica migration is the process of automatic reconfiguration of a replica<br>in order to <em>migrate</em> to a primary that has no longer coverage (no working<br>replicas). With replica migration the scenario mentioned above turns into the<br>following:</p>\n<ul>\n<li>Master A fails. A1 is promoted.</li>\n<li>C2 migrates as replica of A1, that is otherwise not backed by any replica.</li>\n<li>Three hours later A1 fails as well.</li>\n<li>C2 is promoted as a new primary to replace A1.</li>\n<li>The cluster can continue the operations.</li>\n</ul>\n<h3>Replica migration algorithm</h3>\n<p>The migration algorithm does not use any form of agreement since the replica<br>layout in a Valkey Cluster is not part of the cluster configuration that needs<br>to be consistent and/or versioned with config epochs. Instead it uses an<br>algorithm to avoid mass-migration of replicas when a primary is not backed.<br>The algorithm guarantees that eventually (once the cluster configuration is<br>stable) every primary will be backed by at least one replica.</p>\n<p>This is how the algorithm works. To start we need to define what is a<br><em>good replica</em> in this context: a good replica is a replica not in <code>FAIL</code> state<br>from the point of view of a given node.</p>\n<p>The execution of the algorithm is triggered in every replica that detects that<br>there is at least a single primary without good replicas. However among all the<br>replicas detecting this condition, only a subset should act. This subset is<br>actually often a single replica unless different replicas have in a given moment<br>a slightly different view of the failure state of other nodes.</p>\n<p>The <em>acting replica</em> is the replica among the primaries with the maximum number<br>of attached replicas, that is not in FAIL state and has the smallest node ID.</p>\n<p>So for example if there are 10 primaries with 1 replica each, and 2 primaries with<br>5 replicas each, the replica that will try to migrate is - among the 2 primaries<br>having 5 replicas - the one with the lowest node ID. Given that no agreement<br>is used, it is possible that when the cluster configuration is not stable,<br>a race condition occurs where multiple replicas believe themselves to be<br>the non-failing replica with the lower node ID (it is unlikely for this to happen<br>in practice). If this happens, the result is multiple replicas migrating to the<br>same primary, which is harmless. If the race happens in a way that will leave<br>the ceding primary without replicas, as soon as the cluster is stable again<br>the algorithm will be re-executed again and will migrate a replica back to<br>the original primary.</p>\n<p>Eventually every primary will be backed by at least one replica. However,<br>the normal behavior is that a single replica migrates from a primary with<br>multiple replicas to an orphaned primary.</p>\n<p>The algorithm is controlled by a user-configurable parameter called<br><code>cluster-migration-barrier</code>: the number of good replicas a primary<br>must be left with before a replica can migrate away. For example, if this<br>parameter is set to 2, a replica can try to migrate only if its primary remains<br>with two working replicas.</p>\n<h3>configEpoch conflicts resolution algorithm</h3>\n<p>When new <code>configEpoch</code> values are created via replica promotion during<br>failovers, they are guaranteed to be unique.</p>\n<p>However there are two distinct events where new configEpoch values are<br>created in an unsafe way, just incrementing the local <code>currentEpoch</code> of<br>the local node and hoping there are no conflicts at the same time.<br>Both the events are system-administrator triggered:</p>\n<ol>\n<li><code>CLUSTER FAILOVER</code> command with <code>TAKEOVER</code> option is able to manually promote a replica node into a primary <em>without the majority of primaries being available</em>. This is useful, for example, in multi data center setups.</li>\n<li>Migration of slots for cluster rebalancing also generates new configuration epochs inside the local node without agreement for performance reasons.</li>\n</ol>\n<p>Specifically, during manual resharding, when a hash slot is migrated from<br>a node A to a node B, the resharding program will force B to upgrade<br>its configuration to an epoch which is the greatest found in the cluster,<br>plus 1 (unless the node is already the one with the greatest configuration<br>epoch), without requiring agreement from other nodes.<br>Usually a real world resharding involves moving several hundred hash slots<br>(especially in small clusters). Requiring an agreement to generate new<br>configuration epochs during resharding, for each hash slot moved, is<br>inefficient. Moreover it requires a fsync in each of the cluster nodes<br>every time in order to store the new configuration. Because of the way it is<br>performed instead, we only need a new config epoch when the first hash slot is moved,<br>making it much more efficient in production environments.</p>\n<p>However because of the two cases above, it is possible (though unlikely) to end<br>with multiple nodes having the same configuration epoch. A resharding operation<br>performed by the system administrator, and a failover happening at the same<br>time (plus a lot of bad luck) could cause <code>currentEpoch</code> collisions if<br>they are not propagated fast enough.</p>\n<p>Moreover, software bugs and filesystem corruptions can also contribute<br>to multiple nodes having the same configuration epoch.</p>\n<p>When primaries serving different hash slots have the same <code>configEpoch</code>, there<br>are no issues. It is more important that replicas failing over a primary have<br>unique configuration epochs.</p>\n<p>That said, manual interventions or resharding may change the cluster<br>configuration in different ways. The Valkey Cluster main liveness property<br>requires that slot configurations always converge, so under every circumstance<br>we really want all the primary nodes to have a different <code>configEpoch</code>.</p>\n<p>In order to enforce this, <strong>a conflict resolution algorithm</strong> is used in the<br>event that two nodes end up with the same <code>configEpoch</code>.</p>\n<ul>\n<li>IF a primary node detects another primary node is advertising itself with<br>the same <code>configEpoch</code>.</li>\n<li>AND IF the node has a lexicographically smaller Node ID compared to the other node claiming the same <code>configEpoch</code>.</li>\n<li>THEN it increments its <code>currentEpoch</code> by 1, and uses it as the new <code>configEpoch</code>.</li>\n</ul>\n<p>If there are any set of nodes with the same <code>configEpoch</code>, all the nodes but the one with the greatest Node ID will move forward, guaranteeing that, eventually, every node will pick a unique configEpoch regardless of what happened.</p>\n<p>This mechanism also guarantees that after a fresh cluster is created, all<br>nodes start with a different <code>configEpoch</code> (even if this is not actually<br>used) since <code>valkey-cli</code> makes sure to use <code>CLUSTER SET-CONFIG-EPOCH</code> at startup.<br>However if for some reason a node is left misconfigured, it will update<br>its configuration to a different configuration epoch automatically.</p>\n<h3>Node resets</h3>\n<p>Nodes can be software reset (without restarting them) in order to be reused<br>in a different role or in a different cluster. This is useful in normal<br>operations, in testing, and in cloud environments where a given node can<br>be reprovisioned to join a different set of nodes to enlarge or create a new<br>cluster.</p>\n<p>In Valkey Cluster nodes are reset using the <code>CLUSTER RESET</code> command. The<br>command is provided in two variants:</p>\n<ul>\n<li><code>CLUSTER RESET SOFT</code></li>\n<li><code>CLUSTER RESET HARD</code></li>\n</ul>\n<p>The command must be sent directly to the node to reset. If no reset type is<br>provided, a soft reset is performed.</p>\n<p>The following is a list of operations performed by a reset:</p>\n<ol>\n<li>Soft and hard reset: If the node is a replica, it is turned into a primary, and its dataset is discarded. If the node is a primary and contains keys the reset operation is aborted.</li>\n<li>Soft and hard reset: All the slots are released, and the manual failover state is reset.</li>\n<li>Soft and hard reset: All the other nodes in the nodes table are removed, so the node no longer knows any other node.</li>\n<li>Hard reset only: <code>currentEpoch</code>, <code>configEpoch</code>, and <code>lastVoteEpoch</code> are set to 0.</li>\n<li>Hard reset only: the Node ID is changed to a new random ID.</li>\n</ol>\n<p>Master nodes with non-empty data sets can&#39;t be reset (since normally you want to reshard data to the other nodes). However, under special conditions when this is appropriate (e.g. when a cluster is totally destroyed with the intent of creating a new one), <code>FLUSHALL</code> must be executed before proceeding with the reset.</p>\n<h3>Removing nodes from a cluster</h3>\n<p>It is possible to practically remove a node from an existing cluster by<br>resharding all its data to other nodes (if it is a primary node) and<br>shutting it down. However, the other nodes will still remember its node<br>ID and address, and will attempt to connect with it.</p>\n<p>For this reason, when a node is removed we want to also remove its entry<br>from all the other nodes tables. This is accomplished by using the<br><code>CLUSTER FORGET &lt;node-id&gt;</code> command.</p>\n<p>The command does two things:</p>\n<ol>\n<li>It removes the node with the specified node ID from the nodes table.</li>\n<li>It sets a 60 second ban which prevents a node with the same node ID from being re-added.</li>\n</ol>\n<p>The second operation is needed because Valkey Cluster uses gossip in order to auto-discover nodes, so removing the node X from node A, could result in node B gossiping about node X to A again. Because of the 60 second ban, the Valkey Cluster administration tools have 60 seconds in order to remove the node from all the nodes, preventing the re-addition of the node due to auto discovery.</p>\n<p>Further information is available in the <code>CLUSTER FORGET</code> documentation.</p>\n<h2>Publish/Subscribe</h2>\n<p>In a Valkey Cluster, clients can subscribe to every node, and can also<br>publish to every other node. The cluster will make sure that published<br>messages are forwarded as needed.</p>\n<p>The clients can send SUBSCRIBE to any node and can also send PUBLISH to any node.<br>It will simply broadcast each published message to all other nodes.</p>\n<p>Redis OSS 7.0 and later features sharded pub/sub, in which shard channels are assigned to slots by the same algorithm used to assign keys to slots.<br>A shard message must be sent to a node that owns the slot the shard channel is hashed to.<br>The cluster makes sure the published shard messages are forwarded to all nodes in the shard, so clients can subscribe to a shard channel by connecting to either the primary responsible for the slot, or to any of its replicas.</p>\n<h2>Appendix</h2>\n<h3>Appendix A: CRC16 reference implementation in ANSI C</h3>\n<pre><code>/*\n * Copyright 2001-2010 Georges Menie (www.menie.org)\n * Copyright 2010 Salvatore Sanfilippo (adapted to Redis coding style)\n * All rights reserved.\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n *     * Redistributions of source code must retain the above copyright\n *       notice, this list of conditions and the following disclaimer.\n *     * Redistributions in binary form must reproduce the above copyright\n *       notice, this list of conditions and the following disclaimer in the\n *       documentation and/or other materials provided with the distribution.\n *     * Neither the name of the University of California, Berkeley nor the\n *       names of its contributors may be used to endorse or promote products\n *       derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS&#39;&#39; AND ANY\n * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n * DISCLAIMED. IN NO EVENT SHALL THE REGENTS AND CONTRIBUTORS BE LIABLE FOR ANY\n * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\n * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n/* CRC16 implementation according to CCITT standards.\n *\n * Note by @antirez: this is actually the XMODEM CRC 16 algorithm, using the\n * following parameters:\n *\n * Name                       : &quot;XMODEM&quot;, also known as &quot;ZMODEM&quot;, &quot;CRC-16/ACORN&quot;\n * Width                      : 16 bit\n * Poly                       : 1021 (That is actually x^16 + x^12 + x^5 + 1)\n * Initialization             : 0000\n * Reflect Input byte         : False\n * Reflect Output CRC         : False\n * Xor constant to output CRC : 0000\n * Output for &quot;123456789&quot;     : 31C3\n */\n\nstatic const uint16_t crc16tab[256]= {\n    0x0000,0x1021,0x2042,0x3063,0x4084,0x50a5,0x60c6,0x70e7,\n    0x8108,0x9129,0xa14a,0xb16b,0xc18c,0xd1ad,0xe1ce,0xf1ef,\n    0x1231,0x0210,0x3273,0x2252,0x52b5,0x4294,0x72f7,0x62d6,\n    0x9339,0x8318,0xb37b,0xa35a,0xd3bd,0xc39c,0xf3ff,0xe3de,\n    0x2462,0x3443,0x0420,0x1401,0x64e6,0x74c7,0x44a4,0x5485,\n    0xa56a,0xb54b,0x8528,0x9509,0xe5ee,0xf5cf,0xc5ac,0xd58d,\n    0x3653,0x2672,0x1611,0x0630,0x76d7,0x66f6,0x5695,0x46b4,\n    0xb75b,0xa77a,0x9719,0x8738,0xf7df,0xe7fe,0xd79d,0xc7bc,\n    0x48c4,0x58e5,0x6886,0x78a7,0x0840,0x1861,0x2802,0x3823,\n    0xc9cc,0xd9ed,0xe98e,0xf9af,0x8948,0x9969,0xa90a,0xb92b,\n    0x5af5,0x4ad4,0x7ab7,0x6a96,0x1a71,0x0a50,0x3a33,0x2a12,\n    0xdbfd,0xcbdc,0xfbbf,0xeb9e,0x9b79,0x8b58,0xbb3b,0xab1a,\n    0x6ca6,0x7c87,0x4ce4,0x5cc5,0x2c22,0x3c03,0x0c60,0x1c41,\n    0xedae,0xfd8f,0xcdec,0xddcd,0xad2a,0xbd0b,0x8d68,0x9d49,\n    0x7e97,0x6eb6,0x5ed5,0x4ef4,0x3e13,0x2e32,0x1e51,0x0e70,\n    0xff9f,0xefbe,0xdfdd,0xcffc,0xbf1b,0xaf3a,0x9f59,0x8f78,\n    0x9188,0x81a9,0xb1ca,0xa1eb,0xd10c,0xc12d,0xf14e,0xe16f,\n    0x1080,0x00a1,0x30c2,0x20e3,0x5004,0x4025,0x7046,0x6067,\n    0x83b9,0x9398,0xa3fb,0xb3da,0xc33d,0xd31c,0xe37f,0xf35e,\n    0x02b1,0x1290,0x22f3,0x32d2,0x4235,0x5214,0x6277,0x7256,\n    0xb5ea,0xa5cb,0x95a8,0x8589,0xf56e,0xe54f,0xd52c,0xc50d,\n    0x34e2,0x24c3,0x14a0,0x0481,0x7466,0x6447,0x5424,0x4405,\n    0xa7db,0xb7fa,0x8799,0x97b8,0xe75f,0xf77e,0xc71d,0xd73c,\n    0x26d3,0x36f2,0x0691,0x16b0,0x6657,0x7676,0x4615,0x5634,\n    0xd94c,0xc96d,0xf90e,0xe92f,0x99c8,0x89e9,0xb98a,0xa9ab,\n    0x5844,0x4865,0x7806,0x6827,0x18c0,0x08e1,0x3882,0x28a3,\n    0xcb7d,0xdb5c,0xeb3f,0xfb1e,0x8bf9,0x9bd8,0xabbb,0xbb9a,\n    0x4a75,0x5a54,0x6a37,0x7a16,0x0af1,0x1ad0,0x2ab3,0x3a92,\n    0xfd2e,0xed0f,0xdd6c,0xcd4d,0xbdaa,0xad8b,0x9de8,0x8dc9,\n    0x7c26,0x6c07,0x5c64,0x4c45,0x3ca2,0x2c83,0x1ce0,0x0cc1,\n    0xef1f,0xff3e,0xcf5d,0xdf7c,0xaf9b,0xbfba,0x8fd9,0x9ff8,\n    0x6e17,0x7e36,0x4e55,0x5e74,0x2e93,0x3eb2,0x0ed1,0x1ef0\n};\n\nuint16_t crc16(const char *buf, int len) {\n    int counter;\n    uint16_t crc = 0;\n    for (counter = 0; counter &lt; len; counter++)\n            crc = (crc&lt;&lt;8) ^ crc16tab[((crc&gt;&gt;8) ^ *buf++)&amp;0x00FF];\n    return crc;\n}\n</code></pre>\n"
      },
      {
        "id": "cluster-tutorial",
        "topicName": "Cluster tutorial",
        "description": "Horizontal scaling with Valkey Cluster",
        "htmlContent": "<p>Valkey scales horizontally with a deployment topology called Valkey Cluster.<br>This topic will teach you how to set up, test, and operate Valkey Cluster in production.<br>You will learn about the availability and consistency characteristics of Valkey Cluster from the end user&#39;s point of view.</p>\n<p>If you plan to run a production Valkey Cluster deployment or want to understand better how Valkey Cluster works internally, consult the <a href=\"cluster-spec\">Valkey Cluster specification</a>.</p>\n<h2>Valkey Cluster 101</h2>\n<p>Valkey Cluster provides a way to run a Valkey installation where data is automatically sharded across multiple Valkey nodes.<br>Valkey Cluster also provides some degree of availability during partitions&mdash;in practical terms, the ability to continue operations when some nodes fail or are unable to communicate.<br>However, the cluster will become unavailable in the event of larger failures (for example, when the majority of primaries are unavailable).</p>\n<p>So, with Valkey Cluster, you get the ability to:</p>\n<ul>\n<li>Automatically split your dataset among multiple nodes.</li>\n<li>Continue operations when a subset of the nodes are experiencing failures or are unable to communicate with the rest of the cluster.</li>\n</ul>\n<h4>Valkey Cluster TCP ports</h4>\n<p>Every Valkey Cluster node requires two open TCP connections: a Valkey TCP port used to serve clients, e.g., 6379, and second port known as the <em>cluster bus port</em>.<br>By default, the cluster bus port is set by adding 10000 to the data port (e.g., 16379); however, you can override this in the <code>cluster-port</code> configuration.</p>\n<p>Cluster bus is a node-to-node communication channel that uses a binary protocol, which is more suited to exchanging information between nodes due to<br>little bandwidth and processing time.<br>Nodes use the cluster bus for failure detection, configuration updates, failover authorization, and so forth.<br>Clients should never try to communicate with the cluster bus port, but rather use the Valkey command port.<br>However, make sure you open both ports in your firewall, otherwise Valkey cluster nodes won&#39;t be able to communicate.</p>\n<p>For a Valkey Cluster to work properly you need, for each node:</p>\n<ol>\n<li>The client communication port (usually 6379) used to communicate with clients and be open to all the clients that need to reach the cluster, plus all the other cluster nodes that use the client port for key migrations.</li>\n<li>The cluster bus port must be reachable from all the other cluster nodes.</li>\n</ol>\n<p>If you don&#39;t open both TCP ports, your cluster will not work as expected.</p>\n<h4>Valkey Cluster and Docker</h4>\n<p>Currently, Valkey Cluster does not support NATted environments and in general<br>environments where IP addresses or TCP ports are remapped.</p>\n<p>Docker uses a technique called <em>port mapping</em>: programs running inside Docker containers may be exposed with a different port compared to the one the program believes to be using.<br>This is useful for running multiple containers using the same ports, at the same time, in the same server.</p>\n<p>To make Docker compatible with Valkey Cluster, you need to use Docker&#39;s <em>host networking mode</em>.<br>Please see the <code>--net=host</code> option in the <a href=\"https://docs.docker.com/engine/userguide/networking/dockernetworks/\">Docker documentation</a> for more information.</p>\n<h4>Valkey Cluster data sharding</h4>\n<p>Valkey Cluster does not use consistent hashing, but a different form of sharding<br>where every key is conceptually part of what we call a <strong>hash slot</strong>.</p>\n<p>There are 16384 hash slots in Valkey Cluster, and to compute the hash<br>slot for a given key, we simply take the CRC16 of the key modulo<br>16384.</p>\n<p>Every node in a Valkey Cluster is responsible for a subset of the hash slots,<br>so, for example, you may have a cluster with 3 nodes, where:</p>\n<ul>\n<li>Node A contains hash slots from 0 to 5500.</li>\n<li>Node B contains hash slots from 5501 to 11000.</li>\n<li>Node C contains hash slots from 11001 to 16383.</li>\n</ul>\n<p>This makes it easy to add and remove cluster nodes. For example, if<br>I want to add a new node D, I need to move some hash slots from nodes A, B, C<br>to D. Similarly, if I want to remove node A from the cluster, I can just<br>move the hash slots served by A to B and C. Once node A is empty,<br>I can remove it from the cluster completely.</p>\n<p>Moving hash slots from a node to another does not require stopping<br>any operations; therefore, adding and removing nodes, or changing the percentage of hash slots held by a node, requires no downtime.</p>\n<p>Valkey Cluster supports multiple key operations as long as all of the keys involved in a single command execution (or whole transaction, or Lua script<br>execution) belong to the same hash slot. The user can force multiple keys<br>to be part of the same hash slot by using a feature called <em>hash tags</em>.</p>\n<p>Hash tags are documented in the Valkey Cluster specification, but the gist is<br>that if there is a substring between {} brackets in a key, only what is<br>inside the string is hashed. For example, the keys <code>user:{123}:profile</code> and <code>user:{123}:account</code> are guaranteed to be in the same hash slot because they share the same hash tag. As a result, you can operate on these two keys in the same multi-key operation.</p>\n<h4>Valkey Cluster primary-replica model</h4>\n<p>To remain available when a subset of primary nodes are failing or are<br>not able to communicate with the majority of nodes, Valkey Cluster uses a<br>primary-replica model where every hash slot has from 1 (the primary itself) to N<br>replicas (N-1 additional replica nodes).</p>\n<p>In our example cluster with nodes A, B, C, if node B fails the cluster is not<br>able to continue, since we no longer have a way to serve hash slots in the<br>range 5501-11000.</p>\n<p>However, when the cluster is created (or at a later time), we add a replica<br>node to every primary, so that the final cluster is composed of A, B, C<br>that are primary nodes, and A1, B1, C1 that are replica nodes.<br>This way, the system can continue if node B fails.</p>\n<p>Node B1 replicates B, and B fails, the cluster will promote node B1 as the new<br>primary and will continue to operate correctly.</p>\n<p>However, note that if nodes B and B1 fail at the same time, Valkey Cluster will not be able to continue to operate.</p>\n<h4>Valkey Cluster consistency guarantees</h4>\n<p>Valkey Cluster does not guarantee <strong>strong consistency</strong>. In practical<br>terms this means that under certain conditions it is possible that Valkey<br>Cluster will lose writes that were acknowledged by the system to the client.</p>\n<p>The first reason why Valkey Cluster can lose writes is because it uses<br>asynchronous replication. This means that during writes the following<br>happens:</p>\n<ul>\n<li>Your client writes to the primary B.</li>\n<li>The primary B replies OK to your client.</li>\n<li>The primary B propagates the write to its replicas B1, B2 and B3.</li>\n</ul>\n<p>As you can see, B does not wait for an acknowledgement from B1, B2, B3 before<br>replying to the client, since this would be a prohibitive latency penalty<br>for Valkey, so if your client writes something, B acknowledges the write,<br>but crashes before being able to send the write to its replicas, one of the<br>replicas (that did not receive the write) can be promoted to primary, losing<br>the write forever.</p>\n<p>This is very similar to what happens with most databases that are<br>configured to flush data to disk every second, so it is a scenario you<br>are already able to reason about because of past experiences with traditional<br>database systems not involving distributed systems. Similarly you can<br>improve consistency by forcing the database to flush data to disk before<br>replying to the client, but this usually results in prohibitively low<br>performance. That would be the equivalent of synchronous replication in<br>the case of Valkey Cluster.</p>\n<p>Basically, there is a trade-off to be made between performance and consistency.</p>\n<p>Valkey Cluster has support for synchronous writes when absolutely needed,<br>implemented via the <code>WAIT</code> command. This makes losing writes a lot less<br>likely. However, note that Valkey Cluster does not implement strong consistency<br>even when synchronous replication is used: it is always possible, under more<br>complex failure scenarios, that a replica that was not able to receive the write<br>will be elected as primary.</p>\n<p>There is another notable scenario where Valkey Cluster will lose writes, that<br>happens during a network partition where a client is isolated with a minority<br>of instances including at least a primary.</p>\n<p>Take as an example our 6 nodes cluster composed of A, B, C, A1, B1, C1,<br>with 3 primaries and 3 replicas. There is also a client, that we will call Z1.</p>\n<p>After a partition occurs, it is possible that in one side of the<br>partition we have A, C, A1, B1, C1, and in the other side we have B and Z1.</p>\n<p>Z1 is still able to write to B, which will accept its writes. If the<br>partition heals in a very short time, the cluster will continue normally.<br>However, if the partition lasts enough time for B1 to be promoted to primary<br>on the majority side of the partition, the writes that Z1 has sent to B<br>in the meantime will be lost.</p>\n<p><strong>Note:</strong><br>There is a <strong>maximum window</strong> to the amount of writes Z1 will be able<br>to send to B: if enough time has elapsed for the majority side of the<br>partition to elect a replica as primary, every primary node in the minority<br>side will have stopped accepting writes.</p>\n<p>This amount of time is a very important configuration directive of Valkey<br>Cluster, and is called the <strong>node timeout</strong>.</p>\n<p>After node timeout has elapsed, a primary node is considered to be failing,<br>and can be replaced by one of its replicas.<br>Similarly, after node timeout has elapsed without a primary node to be able<br>to sense the majority of the other primary nodes, it enters an error state<br>and stops accepting writes.</p>\n<h2>Valkey Cluster configuration parameters</h2>\n<p>We are about to create an example cluster deployment.<br>Before we continue, let&#39;s introduce the configuration parameters that Valkey Cluster introduces<br>in the <code>valkey.conf</code> file.</p>\n<ul>\n<li><strong>cluster-enabled <code>&lt;yes/no&gt;</code></strong>: If yes, enables Valkey Cluster support in a specific Valkey instance. Otherwise the instance starts as a standalone instance as usual.</li>\n<li><strong>cluster-config-file <code>&lt;filename&gt;</code></strong>: Note that despite the name of this option, this is not a user editable configuration file, but the file where a Valkey Cluster node automatically persists the cluster configuration (the state, basically) every time there is a change, in order to be able to re-read it at startup. The file lists things like the other nodes in the cluster, their state, persistent variables, and so forth. Often this file is rewritten and flushed on disk as a result of some message reception.</li>\n<li><strong>cluster-node-timeout <code>&lt;milliseconds&gt;</code></strong>: The maximum amount of time a Valkey Cluster node can be unavailable, without it being considered as failing. If a primary node is not reachable for more than the specified amount of time, it will be failed over by its replicas. This parameter controls other important things in Valkey Cluster. Notably, every node that can&#39;t reach the majority of primary nodes for the specified amount of time, will stop accepting queries.</li>\n<li><strong>cluster-replica-validity-factor <code>&lt;factor&gt;</code></strong>: If set to zero, a replica will always consider itself valid, and will therefore always try to failover a primary, regardless of the amount of time the link between the primary and the replica remained disconnected. If the value is positive, a maximum disconnection time is calculated as the <em>node timeout</em> value multiplied by the factor provided with this option, and if the node is a replica, it will not try to start a failover if the primary link was disconnected for more than the specified amount of time. For example, if the node timeout is set to 5 seconds and the validity factor is set to 10, a replica disconnected from the primary for more than 50 seconds will not try to failover its primary. Note that any value different than zero may result in Valkey Cluster being unavailable after a primary failure if there is no replica that is able to failover it. In that case the cluster will return to being available only when the original primary rejoins the cluster.</li>\n<li><strong>cluster-migration-barrier <code>&lt;count&gt;</code></strong>: Minimum number of replicas a primary will remain connected with, for another replica to migrate to a primary which is no longer covered by any replica. See the appropriate section about replica migration in this tutorial for more information.</li>\n<li><strong>cluster-require-full-coverage <code>&lt;yes/no&gt;</code></strong>: If this is set to yes, as it is by default, the cluster stops accepting writes if some percentage of the key space is not covered by any node. If the option is set to no, the cluster will still serve queries even if only requests about a subset of keys can be processed.</li>\n<li><strong>cluster-allow-reads-when-down <code>&lt;yes/no&gt;</code></strong>: If this is set to no, as it is by default, a node in a Valkey Cluster will stop serving all traffic when the cluster is marked as failed, either when a node can&#39;t reach a quorum of primaries or when full coverage is not met. This prevents reading potentially inconsistent data from a node that is unaware of changes in the cluster. This option can be set to yes to allow reads from a node during the fail state, which is useful for applications that want to prioritize read availability but still want to prevent inconsistent writes. It can also be used for when using Valkey Cluster with only one or two shards, as it allows the nodes to continue serving writes when a primary fails but automatic failover is impossible.</li>\n</ul>\n<h2>Create and use a Valkey Cluster</h2>\n<p>To create and use a Valkey Cluster, follow these steps:</p>\n<ul>\n<li><a href=\"#create-a-valkey-cluster\">Create a Valkey Cluster</a></li>\n<li><a href=\"#interact-with-the-cluster\">Interact with the cluster</a></li>\n<li><a href=\"#write-an-example-app-with-redis-rb-cluster\">Write an example app with redis-rb-cluster</a></li>\n<li><a href=\"#reshard-the-cluster\">Reshard the cluster</a></li>\n<li><a href=\"#a-more-interesting-example-application\">A more interesting example application</a></li>\n<li><a href=\"#test-the-failover\">Test the failover</a></li>\n<li><a href=\"#manual-failover\">Manual failover</a></li>\n<li><a href=\"#add-a-new-node\">Add a new node</a></li>\n<li><a href=\"#remove-a-node\">Remove a node</a></li>\n<li><a href=\"#replica-migration\">Replica migration</a></li>\n<li><a href=\"#upgrade-nodes-in-a-valkey-cluster\">Upgrade nodes in a Valkey Cluster</a></li>\n<li><a href=\"#migrate-to-valkey-cluster\">Migrate to Valkey Cluster</a></li>\n</ul>\n<p>But, first, familiarize yourself with the requirements for creating a cluster.</p>\n<h4>Requirements to create a Valkey Cluster</h4>\n<p>To create a cluster, the first thing you need is to have a few empty Valkey instances running in <em>cluster mode</em>. </p>\n<p>At minimum, set the following directives in the <code>valkey.conf</code> file:</p>\n<pre><code>port 7000\ncluster-enabled yes\ncluster-config-file nodes.conf\ncluster-node-timeout 5000\nappendonly yes\n</code></pre>\n<p>To enable cluster mode, set the <code>cluster-enabled</code> directive to <code>yes</code>.<br>Every instance also contains the path of a file where the<br>configuration for this node is stored, which by default is <code>nodes.conf</code>.<br>This file is never touched by humans; it is simply generated at startup<br>by the Valkey Cluster instances, and updated every time it is needed.</p>\n<p>Note that the <strong>minimal cluster</strong> that works as expected must contain<br>at least three primary nodes. For deployment, we strongly recommend<br>a six-node cluster, with three primaries and three replicas.</p>\n<p>You can test this locally by creating the following directories named<br>after the port number of the instance you&#39;ll run inside any given directory.</p>\n<p>For example:</p>\n<pre><code>mkdir cluster-test\ncd cluster-test\nmkdir 7000 7001 7002 7003 7004 7005\n</code></pre>\n<p>Create a <code>valkey.conf</code> file inside each of the directories, from 7000 to 7005.<br>As a template for your configuration file just use the small example above,<br>but make sure to replace the port number <code>7000</code> with the right port number<br>according to the directory name.</p>\n<p>You can start each instance as follows, each running in a separate terminal tab:</p>\n<pre><code>cd 7000\nvalkey-server ./valkey.conf\n</code></pre>\n<p>You&#39;ll see from the logs that every node assigns itself a new ID:</p>\n<pre><code>[82462] 26 Nov 11:56:55.329 * No cluster configuration found, I&#39;m 97a3a64667477371c4479320d683e4c8db5858b1\n</code></pre>\n<p>This ID will be used forever by this specific instance in order for the instance<br>to have a unique name in the context of the cluster. Every node<br>remembers every other node using this IDs, and not by IP or port.<br>IP addresses and ports may change, but the unique node identifier will never<br>change for all the life of the node. We call this identifier simply <strong>Node ID</strong>.</p>\n<h4>Create a Valkey Cluster</h4>\n<p>Now that we have a number of instances running, you need to create your cluster by writing some meaningful configuration to the nodes.</p>\n<p>You can configure and execute individual instances manually or use the create-cluster script.<br>Let&#39;s go over how you do it manually.</p>\n<p>To create the cluster, run:</p>\n<pre><code>valkey-cli --cluster create 127.0.0.1:7000 127.0.0.1:7001 \\\n127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 \\\n--cluster-replicas 1\n</code></pre>\n<p>The command used here is <strong>create</strong>, since we want to create a new cluster.<br>The option <code>--cluster-replicas 1</code> means that we want a replica for every primary created.</p>\n<p>The other arguments are the list of addresses of the instances I want to use<br>to create the new cluster.</p>\n<p><code>valkey-cli</code> will propose a configuration. Accept the proposed configuration by typing <strong>yes</strong>.<br>The cluster will be configured and <em>joined</em>, which means that instances will be<br>bootstrapped into talking with each other. Finally, if everything has gone well, you&#39;ll see a message like this:</p>\n<pre><code>[OK] All 16384 slots covered\n</code></pre>\n<p>This means that there is at least one primary instance serving each of the<br>16384 available slots.</p>\n<p>If you don&#39;t want to create a Valkey Cluster by configuring and executing<br>individual instances manually as explained above, there is a much simpler<br>system (but you&#39;ll not learn the same amount of operational details).</p>\n<p>Find the <code>utils/create-cluster</code> directory in the Valkey distribution.<br>There is a script called <code>create-cluster</code> inside (same name as the directory<br>it is contained into), it&#39;s a simple bash script. In order to start<br>a 6 nodes cluster with 3 primaries and 3 replicas just type the following<br>commands:</p>\n<ol>\n<li><code>create-cluster start</code></li>\n<li><code>create-cluster create</code></li>\n</ol>\n<p>Reply to <code>yes</code> in step 2 when the <code>valkey-cli</code> utility wants you to accept<br>the cluster layout.</p>\n<p>You can now interact with the cluster, the first node will start at port 30001<br>by default. When you are done, stop the cluster with:</p>\n<ol start=\"3\">\n<li><code>create-cluster stop</code></li>\n</ol>\n<p>Please read the <code>README</code> inside this directory for more information on how<br>to run the script.</p>\n<h4>Interact with the cluster</h4>\n<p>To connect to Valkey Cluster, you&#39;ll need a cluster-aware Valkey client.<br>See the documentation for your <a href=\"../clients/\">client of choice</a> to determine its cluster support.</p>\n<p>You can also test your Valkey Cluster using the <code>valkey-cli</code> command line utility:</p>\n<pre><code>$ valkey-cli -c -p 7000\n127.0.0.1:7000&gt; set foo bar\n-&gt; Redirected to slot [12182] located at 127.0.0.1:7002\nOK\n127.0.0.1:7002&gt; set hello world\n-&gt; Redirected to slot [866] located at 127.0.0.1:7000\nOK\n127.0.0.1:7000&gt; get foo\n-&gt; Redirected to slot [12182] located at 127.0.0.1:7002\n&quot;bar&quot;\n127.0.0.1:7002&gt; get hello\n-&gt; Redirected to slot [866] located at 127.0.0.1:7000\n&quot;world&quot;\n</code></pre>\n<p><strong>Note:</strong><br>If you created the cluster using the script, your nodes may listen<br>on different ports, starting from 30001 by default.</p>\n<p>The <code>valkey-cli</code> cluster support is very basic, so it always uses the fact that<br>Valkey Cluster nodes are able to redirect a client to the right node.<br>A serious client is able to do better than that, and cache the map between<br>hash slots and nodes addresses, to directly use the right connection to the<br>right node. The map is refreshed only when something changed in the cluster<br>configuration, for example after a failover or after the system administrator<br>changed the cluster layout by adding or removing nodes.</p>\n<h4>Write an example app with redis-rb-cluster</h4>\n<p>Before going forward showing how to operate the Valkey Cluster, doing things<br>like a failover, or a resharding, we need to create some example application<br>or at least to be able to understand the semantics of a simple Valkey Cluster<br>client interaction.</p>\n<p>In this way we can run an example and at the same time try to make nodes<br>failing, or start a resharding, to see how Valkey Cluster behaves under real<br>world conditions. It is not very helpful to see what happens while nobody<br>is writing to the cluster.</p>\n<p>This section explains some basic usage of<br><a href=\"https://github.com/antirez/redis-rb-cluster\">redis-rb-cluster</a> showing two<br>examples.<br>The first is the following, and is the<br><a href=\"https://github.com/antirez/redis-rb-cluster/blob/master/example.rb\"><code>example.rb</code></a><br>file inside the redis-rb-cluster distribution:</p>\n<pre><code class=\"language-ruby\">require &#39;./cluster&#39;\n\nif ARGV.length != 2\n    startup_nodes = [\n        {:host =&gt; &quot;127.0.0.1&quot;, :port =&gt; 7000},\n        {:host =&gt; &quot;127.0.0.1&quot;, :port =&gt; 7001}\n    ]\nelse\n    startup_nodes = [\n        {:host =&gt; ARGV[0], :port =&gt; ARGV[1].to_i}\n    ]\nend\n\nrc = RedisCluster.new(startup_nodes,32,:timeout =&gt; 0.1)\n\nlast = false\n\nwhile not last\n    begin\n        last = rc.get(&quot;__last__&quot;)\n        last = 0 if !last\n    rescue =&gt; e\n        puts &quot;error #{e.to_s}&quot;\n        sleep 1\n    end\nend\n\n((last.to_i+1)..1000000000).each{|x|\n    begin\n        rc.set(&quot;foo#{x}&quot;,x)\n        puts rc.get(&quot;foo#{x}&quot;)\n        rc.set(&quot;__last__&quot;,x)\n    rescue =&gt; e\n        puts &quot;error #{e.to_s}&quot;\n    end\n    sleep 0.1\n}\n</code></pre>\n<p>The application does a very simple thing, it sets keys in the form <code>foo&lt;number&gt;</code> to <code>number</code>, one after the other. So if you run the program the result is the<br>following stream of commands:</p>\n<ul>\n<li>SET foo0 0</li>\n<li>SET foo1 1</li>\n<li>SET foo2 2</li>\n<li>And so forth...</li>\n</ul>\n<p>The program looks more complex than it should usually as it is designed to<br>show errors on the screen instead of exiting with an exception, so every<br>operation performed with the cluster is wrapped by <code>begin</code> <code>rescue</code> blocks.</p>\n<p>The <strong>line 14</strong> is the first interesting line in the program. It creates the<br>Valkey Cluster object, using as argument a list of <em>startup nodes</em>, the maximum<br>number of connections this object is allowed to take against different nodes,<br>and finally the timeout after a given operation is considered to be failed.</p>\n<p>The startup nodes don&#39;t need to be all the nodes of the cluster. The important<br>thing is that at least one node is reachable. Also note that redis-rb-cluster<br>updates this list of startup nodes as soon as it is able to connect with the<br>first node. You should expect such a behavior with any other serious client.</p>\n<p>Now that we have the Valkey Cluster object instance stored in the <strong>rc</strong> variable,<br>we are ready to use the object like if it was a normal Valkey object instance.</p>\n<p>This is exactly what happens in <strong>line 18 to 26</strong>: when we restart the example<br>we don&#39;t want to start again with <code>foo0</code>, so we store the counter inside<br>Valkey itself. The code above is designed to read this counter, or if the<br>counter does not exist, to assign it the value of zero.</p>\n<p>However note how it is a while loop, as we want to try again and again even<br>if the cluster is down and is returning errors. Normal applications don&#39;t need<br>to be so careful.</p>\n<p><strong>Lines between 28 and 37</strong> start the main loop where the keys are set or<br>an error is displayed.</p>\n<p>Note the <code>sleep</code> call at the end of the loop. In your tests you can remove<br>the sleep if you want to write to the cluster as fast as possible (relatively<br>to the fact that this is a busy loop without real parallelism of course, so<br>you&#39;ll get the usually 10k ops/second in the best of the conditions).</p>\n<p>Normally writes are slowed down in order for the example application to be<br>easier to follow by humans.</p>\n<p>Starting the application produces the following output:</p>\n<pre><code>ruby ./example.rb\n1\n2\n3\n4\n5\n6\n7\n8\n9\n^C (I stopped the program here)\n</code></pre>\n<p>This is not a very interesting program and we&#39;ll use a better one in a moment<br>but we can already see what happens during a resharding when the program<br>is running.</p>\n<h4>Reshard the cluster</h4>\n<p>Now we are ready to try a cluster resharding. To do this, please<br>keep the example.rb program running, so that you can see if there is some<br>impact on the program running. Also, you may want to comment the <code>sleep</code><br>call to have some more serious write load during resharding.</p>\n<p>Resharding basically means to move hash slots from a set of nodes to another<br>set of nodes.<br>Like cluster creation, it is accomplished using the valkey-cli utility.</p>\n<p>To start a resharding, just type:</p>\n<pre><code>valkey-cli --cluster reshard 127.0.0.1:7000\n</code></pre>\n<p>You only need to specify a single node, valkey-cli will find the other nodes<br>automatically.</p>\n<p>Currently valkey-cli is only able to reshard with the administrator support,<br>you can&#39;t just say move 5% of slots from this node to the other one (but<br>this is pretty trivial to implement). So it starts with questions. The first<br>is how much of a resharding do you want to do:</p>\n<pre><code>How many slots do you want to move (from 1 to 16384)?\n</code></pre>\n<p>We can try to reshard 1000 hash slots, that should already contain a non<br>trivial amount of keys if the example is still running without the sleep<br>call.</p>\n<p>Then valkey-cli needs to know what is the target of the resharding, that is,<br>the node that will receive the hash slots.<br>I&#39;ll use the first primary node, that is, 127.0.0.1:7000, but I need<br>to specify the Node ID of the instance. This was already printed in a<br>list by valkey-cli, but I can always find the ID of a node with the following<br>command if I need:</p>\n<pre><code>$ valkey-cli -p 7000 cluster nodes | grep myself\n97a3a64667477371c4479320d683e4c8db5858b1 :0 myself,master - 0 0 0 connected 0-5460\n</code></pre>\n<p>Ok so my target node is 97a3a64667477371c4479320d683e4c8db5858b1.</p>\n<p>Now you&#39;ll get asked from what nodes you want to take those keys.<br>I&#39;ll just type <code>all</code> in order to take a bit of hash slots from all the<br>other primary nodes.</p>\n<p>After the final confirmation you&#39;ll see a message for every slot that<br>valkey-cli is going to move from a node to another, and a dot will be printed<br>for every actual key moved from one side to the other.</p>\n<p>While the resharding is in progress you should be able to see your<br>example program running unaffected. You can stop and restart it multiple times<br>during the resharding if you want.</p>\n<p>At the end of the resharding, you can test the health of the cluster with<br>the following command:</p>\n<pre><code>valkey-cli --cluster check 127.0.0.1:7000\n</code></pre>\n<p>All the slots will be covered as usual, but this time the primary at<br>127.0.0.1:7000 will have more hash slots, something around 6461.</p>\n<p>Resharding can be performed automatically without the need to manually<br>enter the parameters in an interactive way. This is possible using a command<br>line like the following:</p>\n<pre><code>valkey-cli --cluster reshard &lt;host&gt;:&lt;port&gt; --cluster-from &lt;node-id&gt; --cluster-to &lt;node-id&gt; --cluster-slots &lt;number of slots&gt; --cluster-yes\n</code></pre>\n<p>This allows to build some automatism if you are likely to reshard often,<br>however currently there is no way for <code>valkey-cli</code> to automatically<br>rebalance the cluster checking the distribution of keys across the cluster<br>nodes and intelligently moving slots as needed. This feature will be added<br>in the future.</p>\n<p>The <code>--cluster-yes</code> option instructs the cluster manager to automatically answer<br>&quot;yes&quot; to the command&#39;s prompts, allowing it to run in a non-interactive mode.<br>Note that this option can also be activated by setting the<br><code>REDISCLI_CLUSTER_YES</code> environment variable.</p>\n<h4>A more interesting example application</h4>\n<p>The example application we wrote early is not very good.<br>It writes to the cluster in a simple way without even checking if what was<br>written is the right thing.</p>\n<p>From our point of view the cluster receiving the writes could just always<br>write the key <code>foo</code> to <code>42</code> to every operation, and we would not notice at<br>all.</p>\n<p>So in the <code>redis-rb-cluster</code> repository, there is a more interesting application<br>that is called <code>consistency-test.rb</code>. It uses a set of counters, by default 1000, and sends <code>INCR</code> commands in order to increment the counters.</p>\n<p>However instead of just writing, the application does two additional things:</p>\n<ul>\n<li>When a counter is updated using <code>INCR</code>, the application remembers the write.</li>\n<li>It also reads a random counter before every write, and check if the value is what we expected it to be, comparing it with the value it has in memory.</li>\n</ul>\n<p>What this means is that this application is a simple <strong>consistency checker</strong>,<br>and is able to tell you if the cluster lost some write, or if it accepted<br>a write that we did not receive acknowledgment for. In the first case we&#39;ll<br>see a counter having a value that is smaller than the one we remember, while<br>in the second case the value will be greater.</p>\n<p>Running the consistency-test application produces a line of output every<br>second:</p>\n<pre><code>$ ruby consistency-test.rb\n925 R (0 err) | 925 W (0 err) |\n5030 R (0 err) | 5030 W (0 err) |\n9261 R (0 err) | 9261 W (0 err) |\n13517 R (0 err) | 13517 W (0 err) |\n17780 R (0 err) | 17780 W (0 err) |\n22025 R (0 err) | 22025 W (0 err) |\n25818 R (0 err) | 25818 W (0 err) |\n</code></pre>\n<p>The line shows the number of <strong>R</strong>eads and <strong>W</strong>rites performed, and the<br>number of errors (query not accepted because of errors since the system was<br>not available).</p>\n<p>If some inconsistency is found, new lines are added to the output.<br>This is what happens, for example, if I reset a counter manually while<br>the program is running:</p>\n<pre><code>$ valkey-cli -h 127.0.0.1 -p 7000 set key_217 0\nOK\n\n(in the other tab I see...)\n\n94774 R (0 err) | 94774 W (0 err) |\n98821 R (0 err) | 98821 W (0 err) |\n102886 R (0 err) | 102886 W (0 err) | 114 lost |\n107046 R (0 err) | 107046 W (0 err) | 114 lost |\n</code></pre>\n<p>When I set the counter to 0 the real value was 114, so the program reports<br>114 lost writes (<code>INCR</code> commands that are not remembered by the cluster).</p>\n<p>This program is much more interesting as a test case, so we&#39;ll use it<br>to test the Valkey Cluster failover.</p>\n<h4>Test the failover</h4>\n<p>To trigger the failover, the simplest thing we can do (that is also<br>the semantically simplest failure that can occur in a distributed system)<br>is to crash a single process, in our case a single primary.</p>\n<p><strong>Note:</strong><br>During this test, you should take a tab open with the consistency test<br>application running.</p>\n<p>We can identify a primary and crash it with the following command:</p>\n<pre><code>$ valkey-cli -p 7000 cluster nodes | grep master\n3e3a6cb0d9a9a87168e266b0a0b24026c0aae3f0 127.0.0.1:7001 master - 0 1385482984082 0 connected 5960-10921\n2938205e12de373867bf38f1ca29d31d0ddb3e46 127.0.0.1:7002 master - 0 1385482983582 0 connected 11423-16383\n97a3a64667477371c4479320d683e4c8db5858b1 :0 myself,master - 0 0 0 connected 0-5959 10922-11422\n</code></pre>\n<p>Ok, so 7000, 7001, and 7002 are primaries. Let&#39;s crash node 7002 with the<br><strong>DEBUG SEGFAULT</strong> command:</p>\n<pre><code>$ valkey-cli -p 7002 debug segfault\nError: Server closed the connection\n</code></pre>\n<p>Now we can look at the output of the consistency test to see what it reported.</p>\n<pre><code>18849 R (0 err) | 18849 W (0 err) |\n23151 R (0 err) | 23151 W (0 err) |\n27302 R (0 err) | 27302 W (0 err) |\n\n... many error warnings here ...\n\n29659 R (578 err) | 29660 W (577 err) |\n33749 R (578 err) | 33750 W (577 err) |\n37918 R (578 err) | 37919 W (577 err) |\n42077 R (578 err) | 42078 W (577 err) |\n</code></pre>\n<p>As you can see during the failover the system was not able to accept 578 reads and 577 writes, however no inconsistency was created in the database. This may<br>sound unexpected as in the first part of this tutorial we stated that Valkey<br>Cluster can lose writes during the failover because it uses asynchronous<br>replication. What we did not say is that this is not very likely to happen<br>because Valkey sends the reply to the client, and the commands to replicate<br>to the replicas, about at the same time, so there is a very small window to<br>lose data. However the fact that it is hard to trigger does not mean that it<br>is impossible, so this does not change the consistency guarantees provided<br>by Valkey cluster.</p>\n<p>We can now check what is the cluster setup after the failover (note that<br>in the meantime I restarted the crashed instance so that it rejoins the<br>cluster as a replica):</p>\n<pre><code>$ valkey-cli -p 7000 cluster nodes\n3fc783611028b1707fd65345e763befb36454d73 127.0.0.1:7004 slave 3e3a6cb0d9a9a87168e266b0a0b24026c0aae3f0 0 1385503418521 0 connected\na211e242fc6b22a9427fed61285e85892fa04e08 127.0.0.1:7003 slave 97a3a64667477371c4479320d683e4c8db5858b1 0 1385503419023 0 connected\n97a3a64667477371c4479320d683e4c8db5858b1 :0 myself,master - 0 0 0 connected 0-5959 10922-11422\n3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e 127.0.0.1:7005 master - 0 1385503419023 3 connected 11423-16383\n3e3a6cb0d9a9a87168e266b0a0b24026c0aae3f0 127.0.0.1:7001 master - 0 1385503417005 0 connected 5960-10921\n2938205e12de373867bf38f1ca29d31d0ddb3e46 127.0.0.1:7002 slave 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e 0 1385503418016 3 connected\n</code></pre>\n<p>Now the primaries are running on ports 7000, 7001 and 7005. What was previously<br>a primary, that is the Valkey instance running on port 7002, is now a replica of<br>7005.</p>\n<p>The output of the <code>CLUSTER NODES</code> command may look intimidating, but it is actually pretty simple, and is composed of the following tokens:</p>\n<ul>\n<li>Node ID</li>\n<li>ip:port</li>\n<li>flags: master, replica, myself, fail, ...</li>\n<li>if it is a replica, the Node ID of the master</li>\n<li>Time of the last pending PING still waiting for a reply.</li>\n<li>Time of the last PONG received.</li>\n<li>Configuration epoch for this node (see the Cluster specification).</li>\n<li>Status of the link to this node.</li>\n<li>Slots served...</li>\n</ul>\n<h4>Manual failover</h4>\n<p>Sometimes it is useful to force a failover without actually causing any problem<br>on a primary. For example, to upgrade the Valkey process of one of the<br>primary nodes it is a good idea to failover it to turn it into a replica<br>with minimal impact on availability.</p>\n<p>Manual failovers are supported by Valkey Cluster using the <code>CLUSTER FAILOVER</code><br>command, that must be executed in one of the replicas of the primary you want<br>to failover.</p>\n<p>Manual failovers are special and are safer compared to failovers resulting from<br>actual primary failures. They occur in a way that avoids data loss in the<br>process, by switching clients from the original primary to the new primary only<br>when the system is sure that the new primary processed all the replication stream<br>from the old one.</p>\n<p>This is what you see in the replica log when you perform a manual failover:</p>\n<pre><code># Manual failover user request accepted.\n# Received replication offset for paused primary manual failover: 347540\n# All primary replication stream processed, manual failover can start.\n# Start of election delayed for 0 milliseconds (rank #0, offset 347540).\n# Starting a failover election for epoch 7545.\n# Failover election won: I&#39;m the new primary.\n</code></pre>\n<p>Clients sending write commands to the primary are blocked during the failover.<br>When the primary sends its replication offset to the replica, the replica<br>waits to reach the offset on its side. When the replication offset is reached,<br>the failover starts, and the old primary is informed about the configuration<br>switch. When the switch is complete, the clients are unblocked on the old<br>primary and they are redirected to the new primary.</p>\n<p><strong>Note:</strong><br>To promote a replica to primary, it must first be known as a replica by a majority of the primaries in the cluster.<br>  Otherwise, it cannot win the failover election.<br>  If the replica has just been added to the cluster (see <a href=\"#add-a-new-node-as-a-replica\">Add a new node as a replica</a>), you may need to wait a while before sending the <code>CLUSTER FAILOVER</code> command, to make sure the primaries in cluster are aware of the new replica.</p>\n<h4>Add a new node</h4>\n<p>Adding a new node is basically the process of adding an empty node and then<br>moving some data into it, in case it is a new primary, or telling it to<br>setup as a replica of a known node, in case it is a replica.</p>\n<p>We&#39;ll show both, starting with the addition of a new primary instance.</p>\n<p>In both cases the first step to perform is <strong>adding an empty node</strong>.</p>\n<p>This is as simple as to start a new node in port 7006 (we already used<br>from 7000 to 7005 for our existing 6 nodes) with the same configuration<br>used for the other nodes, except for the port number, so what you should<br>do in order to conform with the setup we used for the previous nodes:</p>\n<ul>\n<li>Create a new tab in your terminal application.</li>\n<li>Enter the <code>cluster-test</code> directory.</li>\n<li>Create a directory named <code>7006</code>.</li>\n<li>Create a valkey.conf file inside, similar to the one used for the other nodes but using 7006 as port number.</li>\n<li>Finally start the server with <code>../valkey-server ./valkey.conf</code></li>\n</ul>\n<p>At this point the server should be running.</p>\n<p>Now we can use <strong>valkey-cli</strong> as usual in order to add the node to<br>the existing cluster.</p>\n<pre><code>valkey-cli --cluster add-node 127.0.0.1:7006 127.0.0.1:7000\n</code></pre>\n<p>As you can see I used the <strong>add-node</strong> command specifying the address of the<br>new node as first argument, and the address of a random existing node in the<br>cluster as second argument.</p>\n<p>In practical terms valkey-cli here did very little to help us, it just<br>sent a <code>CLUSTER MEET</code> message to the node, something that is also possible<br>to accomplish manually. However valkey-cli also checks the state of the<br>cluster before to operate, so it is a good idea to perform cluster operations<br>always via valkey-cli even when you know how the internals work.</p>\n<p>Now we can connect to the new node to see if it really joined the cluster:</p>\n<pre><code>valkey 127.0.0.1:7006&gt; cluster nodes\n3e3a6cb0d9a9a87168e266b0a0b24026c0aae3f0 127.0.0.1:7001 master - 0 1385543178575 0 connected 5960-10921\n3fc783611028b1707fd65345e763befb36454d73 127.0.0.1:7004 slave 3e3a6cb0d9a9a87168e266b0a0b24026c0aae3f0 0 1385543179583 0 connected\nf093c80dde814da99c5cf72a7dd01590792b783b :0 myself,master - 0 0 0 connected\n2938205e12de373867bf38f1ca29d31d0ddb3e46 127.0.0.1:7002 slave 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e 0 1385543178072 3 connected\na211e242fc6b22a9427fed61285e85892fa04e08 127.0.0.1:7003 slave 97a3a64667477371c4479320d683e4c8db5858b1 0 1385543178575 0 connected\n97a3a64667477371c4479320d683e4c8db5858b1 127.0.0.1:7000 master - 0 1385543179080 0 connected 0-5959 10922-11422\n3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e 127.0.0.1:7005 master - 0 1385543177568 3 connected 11423-16383\n</code></pre>\n<p>Note that since this node is already connected to the cluster it is already<br>able to redirect client queries correctly and is generally speaking part of<br>the cluster. However it has two peculiarities compared to the other primaries:</p>\n<ul>\n<li>It holds no data as it has no assigned hash slots.</li>\n<li>Because it is a primary without assigned slots, it does not participate in the election process when a replica wants to become a primary.</li>\n</ul>\n<p>Now it is possible to assign hash slots to this node using the resharding<br>feature of <code>valkey-cli</code>.<br>It is basically useless to show this as we already<br>did in a previous section, there is no difference, it is just a resharding<br>having as a target the empty node.</p>\n<h5>Add a new node as a replica</h5>\n<p>Adding a new replica can be performed in two ways. The obvious one is to<br>use valkey-cli again, but with the --cluster-replica option, like this:</p>\n<pre><code>valkey-cli --cluster add-node 127.0.0.1:7006 127.0.0.1:7000 --cluster-replica\n</code></pre>\n<p>Note that the command line here is exactly like the one we used to add<br>a new primary, so we are not specifying to which primary we want to add<br>the replica. In this case, what happens is that valkey-cli will add the new<br>node as replica of a random primary among the primaries with fewer replicas.</p>\n<p>However you can specify exactly what primary you want to target with your<br>new replica with the following command line:</p>\n<pre><code>valkey-cli --cluster add-node 127.0.0.1:7006 127.0.0.1:7000 --cluster-replica --cluster-master-id 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e\n</code></pre>\n<p>This way we assign the new replica to a specific primary.</p>\n<p>A more manual way to add a replica to a specific primary is to add the new<br>node as an empty primary, and then turn it into a replica using the<br><code>CLUSTER REPLICATE</code> command. This also works if the node was added as a replica<br>but you want to move it as a replica of a different primary.</p>\n<p>For example in order to add a replica for the node 127.0.0.1:7005 that is<br>currently serving hash slots in the range 11423-16383, that has a Node ID<br>3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e, all I need to do is to connect<br>with the new node (already added as empty primary) and send the command:</p>\n<pre><code>valkey 127.0.0.1:7006&gt; cluster replicate 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e\n</code></pre>\n<p>That&#39;s it. Now we have a new replica for this set of hash slots, and all<br>the other nodes in the cluster already know (after a few seconds needed to<br>update their config). We can verify with the following command:</p>\n<pre><code>$ valkey-cli -p 7000 cluster nodes | grep slave | grep 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e\nf093c80dde814da99c5cf72a7dd01590792b783b 127.0.0.1:7006 replica 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e 0 1385543617702 3 connected\n2938205e12de373867bf38f1ca29d31d0ddb3e46 127.0.0.1:7002 replica 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e 0 1385543617198 3 connected\n</code></pre>\n<p>The node 3c3a0c... now has two replicas, running on ports 7002 (the existing one) and 7006 (the new one).</p>\n<h4>Remove a node</h4>\n<p>To remove a replica node just use the <code>del-node</code> command of valkey-cli:</p>\n<pre><code>valkey-cli --cluster del-node 127.0.0.1:7000 `&lt;node-id&gt;`\n</code></pre>\n<p>The first argument is just a random node in the cluster, the second argument<br>is the ID of the node you want to remove.</p>\n<p>You can remove a primary node in the same way as well, <strong>however in order to<br>remove a primary node it must be empty</strong>. If the primary is not empty you need<br>to reshard data away from it to all the other primary nodes before.</p>\n<p>An alternative to remove a primary node is to perform a manual failover of it<br>over one of its replicas and remove the node after it turned into a replica of the<br>new primary. Obviously this does not help when you want to reduce the actual<br>number of primaries in your cluster, in that case, a resharding is needed.</p>\n<p>There is a special scenario where you want to remove a failed node.<br>You should not use the <code>del-node</code> command because it tries to connect to all nodes and you will encounter a &quot;connection refused&quot; error.<br>Instead, you can use the <code>call</code> command:</p>\n<pre><code>valkey-cli --cluster call 127.0.0.1:7000 cluster forget `&lt;node-id&gt;`\n</code></pre>\n<p>This command will execute <code>CLUSTER FORGET</code> command on every node. </p>\n<h4>Replica migration</h4>\n<p>In Valkey Cluster, you can reconfigure a replica to replicate with a<br>different primary at any time just using this command:</p>\n<pre><code>CLUSTER REPLICATE &lt;master-node-id&gt;\n</code></pre>\n<p>However there is a special scenario where you want replicas to move from one<br>primary to another one automatically, without the help of the system administrator.<br>The automatic reconfiguration of replicas is called <em>replicas migration</em> and is<br>able to improve the reliability of a Valkey Cluster.</p>\n<p><strong>Note:</strong><br>You can read the details of replicas migration in the <a href=\"cluster-spec\">Valkey Cluster Specification</a>, here we&#39;ll only provide some information about the<br>general idea and what you should do in order to benefit from it.</p>\n<p>The reason why you may want to let your cluster replicas to move from one primary<br>to another under certain condition, is that usually the Valkey Cluster is as<br>resistant to failures as the number of replicas attached to a given primary.</p>\n<p>For example a cluster where every primary has a single replica can&#39;t continue<br>operations if the primary and its replica fail at the same time, simply because<br>there is no other instance to have a copy of the hash slots the primary was<br>serving. However while net-splits are likely to isolate a number of nodes<br>at the same time, many other kind of failures, like hardware or software failures<br>local to a single node, are a very notable class of failures that are unlikely<br>to happen at the same time, so it is possible that in your cluster where<br>every primary has a replica, the replica is killed at 4am, and the primary is killed<br>at 6am. This still will result in a cluster that can no longer operate.</p>\n<p>To improve reliability of the system we have the option to add additional<br>replicas to every primary, but this is expensive. Replica migration allows to<br>add more replicas to just a few primaries. So you have 10 primaries with 1 replica<br>each, for a total of 20 instances. However you add, for example, 3 instances<br>more as replicas of some of your primaries, so certain primaries will have more<br>than a single replica.</p>\n<p>With replicas migration what happens is that if a primary is left without<br>replicas, a replica from a primary that has multiple replicas will migrate to<br>the <em>orphaned</em> primary. So after your replica goes down at 4am as in the example<br>we made above, another replica will take its place, and when the primary<br>will fail as well at 5am, there is still a replica that can be elected so that<br>the cluster can continue to operate.</p>\n<p>So what you should know about replicas migration in short?</p>\n<ul>\n<li>The cluster will try to migrate a replica from the primary that has the greatest number of replicas in a given moment.</li>\n<li>To benefit from replica migration you have just to add a few more replicas to a single primary in your cluster, it does not matter what primary.</li>\n<li>There is a configuration parameter that controls the replica migration feature that is called <code>cluster-migration-barrier</code>: you can read more about it in the example <code>valkey.conf</code> file provided with Valkey Cluster.</li>\n</ul>\n<h4>Upgrade nodes in a Valkey Cluster</h4>\n<p>Upgrading replica nodes is easy since you just need to stop the node and restart<br>it with an updated version of Valkey. If there are clients scaling reads using<br>replica nodes, they should be able to reconnect to a different replica if a given<br>one is not available.</p>\n<p>Upgrading primaries is a bit more complex. The suggested procedure is to trigger<br>a manual failover to turn the old primary into a replica and then upgrading it.</p>\n<p>A complete rolling upgrade of all nodes in a cluster can be performed by<br>repeating the following procedure for each shard (a primary and its replicas):</p>\n<ol>\n<li><p>Add one or more upgraded nodes as new replicas to the primary. This step is<br>optional but it ensures that the number of replicas is not compromised during<br>the rolling upgrade. To add a new node, use <a href=\"../commands/cluster-meet\"><code>CLUSTER MEET</code></a> and <a href=\"../commands/cluster-replicate\"><code>CLUSTER REPLICATE</code></a> or use <code>valkey-cli</code> as<br>described under <a href=\"#add-a-new-node-as-a-replica\">Add a new node as a replica</a>.</p>\n<p>An alternative is to upgrade one replica at a time and have fewer replicas<br>online during the upgrade.</p>\n</li>\n<li><p>Upgrade the old replicas you want to keep by restarting them with the updated<br>version of Valkey. If you&#39;re replacing all the old nodes with new nodes, you<br>can skip this step.</p>\n</li>\n<li><p>Select one of the upgraded replicas to be the new primary. Wait until this<br>replica has caught up the replication offset with the primary. You can use<br><a href=\"../commands/info\"><code>INFO REPLICATION</code></a> and check for the line<br><code>master_link_status:up</code> to be present. This indicates that the initial sync<br>with the primary is complete.</p>\n<p>After the initial full sync, the replica might still lag behind in<br>replication. Send <code>INFO REPLICATION</code> to the primary and the replica and<br>compare the field <code>master_repl_offset</code> returned by both nodes. If the offsets<br>match, it means that all writes have been replicated. However, if the primary<br>receives a constant stream of writes, it&#39;s possible that the offsets will<br>never be equal. In this step, you can accept a small difference. It&#39;s usually<br>enough to wait for some seconds to minimize the difference.</p>\n</li>\n<li><p>Check that the new replica is known by all nodes in the cluster, or at least<br>by the primaries in the cluster. You can send <a href=\"../commands/cluster-nodes\"><code>CLUSTER NODES</code></a> to each of the nodes in the cluster and<br>check that they all are aware of the new node. Wait for some time and repeat<br>the check if necessary.</p>\n</li>\n<li><p>Trigger a manual failover by sending <a href=\"../commands/cluster-failover\"><code>CLUSTER FAILOVER</code></a> to the replica node selected to<br>become the new primary. See the <a href=\"#manual-failover\">Manual failover</a> section<br>in this document for more information.</p>\n</li>\n<li><p>Wait for the failover to complete. To check, you can use<br><a href=\"../commands/role\"><code>ROLE</code></a>, <a href=\"../commands/info\"><code>INFO REPLICATION</code></a><br>(which indicates <code>role:master</code> after successful failover) or <a href=\"../commands/cluster-nodes\"><code>CLUSTER NODES</code></a> to verify that the state of the cluster<br>has changed shortly after the command was sent.</p>\n</li>\n<li><p>Take the old primary (now a replica) out of service, or upgrade it and add it<br>again as a replica. Remove additional replicas kept for redundancy during the<br>upgrade, if any.</p>\n</li>\n</ol>\n<p>Repeat this sequence for each shard (each primary and its replicas) until all<br>nodes in the cluster have been upgraded.</p>\n<h4>Migrate to Valkey Cluster</h4>\n<p>Users willing to migrate to Valkey Cluster may have just a single primary, or<br>may already using a preexisting sharding setup, where keys<br>are split among N nodes, using some in-house algorithm or a sharding algorithm<br>implemented by their client library or Valkey proxy.</p>\n<p>In both cases it is possible to migrate to Valkey Cluster easily, however<br>what is the most important detail is if multiple-keys operations are used<br>by the application, and how. There are three different cases:</p>\n<ol>\n<li>Multiple keys operations, or transactions, or Lua scripts involving multiple keys, are not used. Keys are accessed independently (even if accessed via transactions or Lua scripts grouping multiple commands, about the same key, together).</li>\n<li>Multiple keys operations, or transactions, or Lua scripts involving multiple keys are used but only with keys having the same <strong>hash tag</strong>, which means that the keys used together all have a <code>{...}</code> sub-string that happens to be identical. For example the following multiple keys operation is defined in the context of the same hash tag: <code>SUNION {user:1000}.foo {user:1000}.bar</code>.</li>\n<li>Multiple keys operations, or transactions, or Lua scripts involving multiple keys are used with key names not having an explicit, or the same, hash tag.</li>\n</ol>\n<p>The third case is not handled by Valkey Cluster: the application requires to<br>be modified in order to not use multi keys operations or only use them in<br>the context of the same hash tag.</p>\n<p>Case 1 and 2 are covered, so we&#39;ll focus on those two cases, that are handled<br>in the same way, so no distinction will be made in the documentation.</p>\n<p>Assuming you have your preexisting data set split into N primaries, where<br>N=1 if you have no preexisting sharding, the following steps are needed<br>in order to migrate your data set to Valkey Cluster:</p>\n<ol>\n<li>Stop your clients. No automatic live-migration to Valkey Cluster is currently possible. You may be able to do it orchestrating a live migration in the context of your application / environment.</li>\n<li>Generate an append only file for all of your N primaries using the <code>BGREWRITEAOF</code> command, and waiting for the AOF file to be completely generated.</li>\n<li>Save your AOF files from aof-1 to aof-N somewhere. At this point you can stop your old instances if you wish (this is useful since in non-virtualized deployments you often need to reuse the same computers).</li>\n<li>Create a Valkey Cluster composed of N primaries and zero replicas. You&#39;ll add replicas later. Make sure all your nodes are using the append only file for persistence.</li>\n<li>Stop all the cluster nodes, substitute their append only file with your pre-existing append only files, aof-1 for the first node, aof-2 for the second node, up to aof-N.</li>\n<li>Restart your Valkey Cluster nodes with the new AOF files. They&#39;ll complain that there are keys that should not be there according to their configuration.</li>\n<li>Use <code>valkey-cli --cluster fix</code> command in order to fix the cluster so that keys will be migrated according to the hash slots each node is authoritative or not.</li>\n<li>Use <code>valkey-cli --cluster check</code> at the end to make sure your cluster is ok.</li>\n<li>Restart your clients modified to use a Valkey Cluster aware client library.</li>\n</ol>\n<p>There is an alternative way to import data from external instances to a Valkey<br>Cluster, which is to use the <code>valkey-cli --cluster import</code> command.</p>\n<p>The command moves all the keys of a running instance (deleting the keys from<br>the source instance) to the specified pre-existing Valkey Cluster. </p>\n<p><strong>Note:</strong><br>If not for backward compatibility, the Valkey project no longer uses the words &quot;master&quot; and &quot;slave&quot;. Unfortunately in this command these words are part of the protocol, so we&#39;ll be able to remove such occurrences only when this API will be naturally deprecated.</p>\n<h2>Learn more</h2>\n<ul>\n<li><a href=\"cluster-spec\">Valkey Cluster specification</a></li>\n<li><a href=\"https://docs.docker.com/engine/userguide/networking/dockernetworks/\">Docker documentation</a></li>\n</ul>\n"
      },
      {
        "id": "distlock",
        "topicName": "Distributed Locks",
        "description": "A distributed lock pattern with Valkey\n",
        "htmlContent": "<p>Distributed locks are a very useful primitive in many environments where<br>different processes must operate with shared resources in a mutually<br>exclusive way.</p>\n<p>There are a number of libraries and blog posts describing how to implement<br>a DLM (Distributed Lock Manager) with Valkey, but every library uses a different<br>approach, and many use a simple approach with lower guarantees compared to<br>what can be achieved with slightly more complex designs.</p>\n<p>This page describes a more canonical algorithm to implement<br>distributed locks with Valkey. We propose an algorithm, called <strong>Redlock</strong>,<br>which implements a DLM which we believe to be safer than the vanilla single<br>instance approach. We hope that the community will analyze it, provide<br>feedback, and use it as a starting point for the implementations or more<br>complex or alternative designs.</p>\n<h2>Implementations</h2>\n<p>Before describing the algorithm, here are a few links to implementations<br>already available that can be used for reference.</p>\n<ul>\n<li><a href=\"https://github.com/antirez/redlock-rb\">Redlock-rb</a> (Ruby implementation). There is also a <a href=\"https://github.com/leandromoreira/redlock-rb\">fork of Redlock-rb</a> that adds a gem for easy distribution.</li>\n<li><a href=\"https://github.com/SPSCommerce/redlock-py\">Redlock-py</a> (Python implementation).</li>\n<li><a href=\"https://github.com/brainix/pottery#redlock\">Pottery</a> (Python implementation).</li>\n<li><a href=\"https://github.com/joanvila/aioredlock\">Aioredlock</a> (Asyncio Python implementation).</li>\n<li><a href=\"https://github.com/malkusch/lock#redismutex\">RedisMutex</a> (PHP implementation with both <a href=\"https://github.com/phpredis/phpredis\">Redis extension</a> and <a href=\"https://github.com/predis/predis\">Predis library</a> clients support).</li>\n<li><a href=\"https://github.com/ronnylt/redlock-php\">Redlock-php</a> (PHP implementation).</li>\n<li><a href=\"https://github.com/cheprasov/php-redis-lock\">cheprasov/php-redis-lock</a> (PHP library for locks).</li>\n<li><a href=\"https://github.com/rtckit/reactphp-redlock\">rtckit/react-redlock</a> (Async PHP implementation).</li>\n<li><a href=\"https://github.com/go-redsync/redsync\">Redsync</a> (Go implementation).</li>\n<li><a href=\"https://github.com/mrniko/redisson\">Redisson</a> (Java implementation).</li>\n<li><a href=\"https://github.com/sbertrang/redis-distlock\">Redis::DistLock</a> (Perl implementation).</li>\n<li><a href=\"https://github.com/jacket-code/redlock-cpp\">Redlock-cpp</a> (C++ implementation).</li>\n<li><a href=\"https://github.com/sewenew/redis-plus-plus/#redlock\">Redis-plus-plus</a> (C++ implementation).</li>\n<li><a href=\"https://github.com/kidfashion/redlock-cs\">Redlock-cs</a> (C#/.NET implementation).</li>\n<li><a href=\"https://github.com/samcook/RedLock.net\">RedLock.net</a> (C#/.NET implementation). Includes async and lock extension support.</li>\n<li><a href=\"https://github.com/psibernetic/scarletlock\">ScarletLock</a> (C# .NET implementation with configurable datastore).</li>\n<li><a href=\"https://github.com/LiZhenNet/Redlock4Net\">Redlock4Net</a> (C# .NET implementation).</li>\n<li><a href=\"https://github.com/mike-marcacci/node-redlock\">node-redlock</a> (NodeJS implementation). Includes support for lock extension.</li>\n<li><a href=\"https://github.com/oslabs-beta/Deno-Redlock\">Deno DLM</a> (Deno implementation)</li>\n<li><a href=\"https://github.com/hexcowboy/rslock\">Rslock</a> (Rust implementation). Includes async and lock extension support.</li>\n</ul>\n<h2>Safety and Liveness Guarantees</h2>\n<p>We are going to model our design with just three properties that, from our point of view, are the minimum guarantees needed to use distributed locks in an effective way.</p>\n<ol>\n<li>Safety property: Mutual exclusion. At any given moment, only one client can hold a lock.</li>\n<li>Liveness property A: Deadlock free. Eventually it is always possible to acquire a lock, even if the client that locked a resource crashes or gets partitioned.</li>\n<li>Liveness property B: Fault tolerance. As long as the majority of Valkey nodes are up, clients are able to acquire and release locks.</li>\n</ol>\n<h2>Why Failover-based Implementations Are Not Enough</h2>\n<p>To understand what we want to improve, let’s analyze the current state of affairs with most Valkey-based distributed lock libraries.</p>\n<p>The simplest way to use Valkey to lock a resource is to create a key in an instance. The key is usually created with a limited time to live, using the Valkey expires feature, so that eventually it will get released (property 2 in our list). When the client needs to release the resource, it deletes the key.</p>\n<p>Superficially this works well, but there is a problem: this is a single point of failure in our architecture. What happens if the Valkey primary goes down?</p>\n<p>Well, let’s add a replica! And use it if the primary is unavailable. This is unfortunately not viable. By doing so we can’t implement our safety property of mutual exclusion, because Valkey replication is asynchronous.</p>\n<p>There is a race condition with this model:</p>\n<ol>\n<li>Client A acquires the lock in the primary.</li>\n<li>The primary crashes before the write to the key is transmitted to the replica.</li>\n<li>The replica gets promoted to primary.</li>\n<li>Client B acquires the lock to the same resource A already holds a lock for. <strong>SAFETY VIOLATION!</strong></li>\n</ol>\n<p>Sometimes it is perfectly fine that, under special circumstances, for example during a failure, multiple clients can hold the lock at the same time.<br>If this is the case, you can use your replication based solution. Otherwise we suggest to implement the solution described in this document.</p>\n<h2>Correct Implementation with a Single Instance</h2>\n<p>Before trying to overcome the limitation of the single instance setup described above, let’s check how to do it correctly in this simple case, since this is actually a viable solution in applications where a race condition from time to time is acceptable, and because locking into a single instance is the foundation we’ll use for the distributed algorithm described here.</p>\n<p>To acquire the lock, the way to go is the following:</p>\n<pre><code>    SET resource_name my_random_value NX PX 30000\n</code></pre>\n<p>The command will set the key only if it does not already exist (<code>NX</code> option), with an expire of 30000 milliseconds (<code>PX</code> option).<br>The key is set to a value “my_random_value”. This value must be unique across all clients and all lock requests.</p>\n<p>Basically the random value is used in order to release the lock in a safe way, with a script that tells Valkey: remove the key only if it exists and the value stored at the key is exactly the one I expect to be. This is accomplished by the following Lua script:</p>\n<pre><code>if server.call(&quot;get&quot;,KEYS[1]) == ARGV[1] then\n    return server.call(&quot;del&quot;,KEYS[1])\nelse\n    return 0\nend\n</code></pre>\n<p>This is important in order to avoid removing a lock that was created by another client. For example a client may acquire the lock, get blocked performing some operation for longer than the lock validity time (the time at which the key will expire), and later remove the lock, that was already acquired by some other client.<br>Using just <code>DEL</code> is not safe as a client may remove another client&#39;s lock. With the above script instead every lock is “signed” with a random string, so the lock will be removed only if it is still the one that was set by the client trying to remove it.</p>\n<p>What should this random string be? We assume it’s 20 bytes from <code>/dev/urandom</code>, but you can find cheaper ways to make it unique enough for your tasks.<br>For example a safe pick is to seed RC4 with <code>/dev/urandom</code>, and generate a pseudo random stream from that.<br>A simpler solution is to use a UNIX timestamp with microsecond precision, concatenating the timestamp with a client ID. It is not as safe, but probably sufficient for most environments.</p>\n<p>The &quot;lock validity time&quot; is the time we use as the key&#39;s time to live. It is both the auto release time, and the time the client has in order to perform the operation required before another client may be able to acquire the lock again, without technically violating the mutual exclusion guarantee, which is only limited to a given window of time from the moment the lock is acquired.</p>\n<p>So now we have a good way to acquire and release the lock. With this system, reasoning about a non-distributed system composed of a single, always available, instance, is safe. Let’s extend the concept to a distributed system where we don’t have such guarantees.</p>\n<h2>The Redlock Algorithm</h2>\n<p>In the distributed version of the algorithm we assume we have N Valkey primaries. Those nodes are totally independent, so we don’t use replication or any other implicit coordination system. We already described how to acquire and release the lock safely in a single instance. We take for granted that the algorithm will use this method to acquire and release the lock in a single instance. In our examples we set N=5, which is a reasonable value, so we need to run 5 Valkey primaries on different computers or virtual machines in order to ensure that they’ll fail in a mostly independent way.</p>\n<p>In order to acquire the lock, the client performs the following operations:</p>\n<ol>\n<li>It gets the current time in milliseconds.</li>\n<li>It tries to acquire the lock in all the N instances sequentially, using the same key name and random value in all the instances. During step 2, when setting the lock in each instance, the client uses a timeout which is small compared to the total lock auto-release time in order to acquire it. For example if the auto-release time is 10 seconds, the timeout could be in the ~ 5-50 milliseconds range. This prevents the client from remaining blocked for a long time trying to talk with a Valkey node which is down: if an instance is not available, we should try to talk with the next instance ASAP.</li>\n<li>The client computes how much time elapsed in order to acquire the lock, by subtracting from the current time the timestamp obtained in step 1. If and only if the client was able to acquire the lock in the majority of the instances (at least 3), and the total time elapsed to acquire the lock is less than lock validity time, the lock is considered to be acquired.</li>\n<li>If the lock was acquired, its validity time is considered to be the initial validity time minus the time elapsed, as computed in step 3.</li>\n<li>If the client failed to acquire the lock for some reason (either it was not able to lock N/2+1 instances or the validity time is negative), it will try to unlock all the instances (even the instances it believed it was not able to lock).</li>\n</ol>\n<h3>Is the Algorithm Asynchronous?</h3>\n<p>The algorithm relies on the assumption that while there is no synchronized clock across the processes, the local time in every process updates at approximately at the same rate, with a small margin of error compared to the auto-release time of the lock. This assumption closely resembles a real-world computer: every computer has a local clock and we can usually rely on different computers to have a clock drift which is small.</p>\n<p>At this point we need to better specify our mutual exclusion rule: it is guaranteed only as long as the client holding the lock terminates its work within the lock validity time (as obtained in step 3), minus some time (just a few milliseconds in order to compensate for clock drift between processes).</p>\n<p>This paper contains more information about similar systems requiring a bound <em>clock drift</em>: <a href=\"https://dl.acm.org/citation.cfm?id=74870\">Leases: an efficient fault-tolerant mechanism for distributed file cache consistency</a>.</p>\n<h3>Retry on Failure</h3>\n<p>When a client is unable to acquire the lock, it should try again after a random delay in order to try to desynchronize multiple clients trying to acquire the lock for the same resource at the same time (this may result in a split brain condition where nobody wins). Also the faster a client tries to acquire the lock in the majority of Valkey instances, the smaller the window for a split brain condition (and the need for a retry), so ideally the client should try to send the <code>SET</code> commands to the N instances at the same time using multiplexing.</p>\n<p>It is worth stressing how important it is for clients that fail to acquire the majority of locks, to release the (partially) acquired locks ASAP, so that there is no need to wait for key expiry in order for the lock to be acquired again (however if a network partition happens and the client is no longer able to communicate with the Valkey instances, there is an availability penalty to pay as it waits for key expiration).</p>\n<h3>Releasing the Lock</h3>\n<p>Releasing the lock is simple, and can be performed whether or not the client believes it was able to successfully lock a given instance.</p>\n<h3>Safety Arguments</h3>\n<p>Is the algorithm safe? Let&#39;s examine what happens in different scenarios.</p>\n<p>To start let’s assume that a client is able to acquire the lock in the majority of instances. All the instances will contain a key with the same time to live. However, the key was set at different times, so the keys will also expire at different times. But if the first key was set at worst at time T1 (the time we sample before contacting the first server) and the last key was set at worst at time T2 (the time we obtained the reply from the last server), we are sure that the first key to expire in the set will exist for at least <code>MIN_VALIDITY=TTL-(T2-T1)-CLOCK_DRIFT</code>. All the other keys will expire later, so we are sure that the keys will be simultaneously set for at least this time.</p>\n<p>During the time that the majority of keys are set, another client will not be able to acquire the lock, since N/2+1 SET NX operations can’t succeed if N/2+1 keys already exist. So if a lock was acquired, it is not possible to re-acquire it at the same time (violating the mutual exclusion property).</p>\n<p>However we want to also make sure that multiple clients trying to acquire the lock at the same time can’t simultaneously succeed.</p>\n<p>If a client locked the majority of instances using a time near, or greater, than the lock maximum validity time (the TTL we use for SET basically), it will consider the lock invalid and will unlock the instances, so we only need to consider the case where a client was able to lock the majority of instances in a time which is less than the validity time. In this case for the argument already expressed above, for <code>MIN_VALIDITY</code> no client should be able to re-acquire the lock. So multiple clients will be able to lock N/2+1 instances at the same time (with &quot;time&quot; being the end of Step 2) only when the time to lock the majority was greater than the TTL time, making the lock invalid.</p>\n<h3>Liveness Arguments</h3>\n<p>The system liveness is based on three main features:</p>\n<ol>\n<li>The auto release of the lock (since keys expire): eventually keys are available again to be locked.</li>\n<li>The fact that clients, usually, will cooperate removing the locks when the lock was not acquired, or when the lock was acquired and the work terminated, making it likely that we don’t have to wait for keys to expire to re-acquire the lock.</li>\n<li>The fact that when a client needs to retry a lock, it waits a time which is comparably greater than the time needed to acquire the majority of locks, in order to probabilistically make split brain conditions during resource contention unlikely.</li>\n</ol>\n<p>However, we pay an availability penalty equal to <code>TTL</code> time on network partitions, so if there are continuous partitions, we can pay this penalty indefinitely.<br>This happens every time a client acquires a lock and gets partitioned away before being able to remove the lock.</p>\n<p>Basically if there are infinite continuous network partitions, the system may become not available for an infinite amount of time.</p>\n<h3>Performance, Crash Recovery and fsync</h3>\n<p>Many users using Valkey as a lock server need high performance in terms of both latency to acquire and release a lock, and number of acquire / release operations that it is possible to perform per second. In order to meet this requirement, the strategy to talk with the N Valkey servers to reduce latency is definitely multiplexing (putting the socket in non-blocking mode, send all the commands, and read all the commands later, assuming that the RTT between the client and each instance is similar).</p>\n<p>However there is another consideration around persistence if we want to target a crash-recovery system model.</p>\n<p>Basically to see the problem here, let’s assume we configure Valkey without persistence at all. A client acquires the lock in 3 of 5 instances. One of the instances where the client was able to acquire the lock is restarted, at this point there are again 3 instances that we can lock for the same resource, and another client can lock it again, violating the safety property of exclusivity of lock.</p>\n<p>If we enable AOF persistence, things will improve quite a bit. For example we can upgrade a server by sending it a <code>SHUTDOWN</code> command and restarting it. Because Valkey expires are semantically implemented so that time still elapses when the server is off, all our requirements are fine.<br>However everything is fine as long as it is a clean shutdown. What about a power outage? If Valkey is configured, as by default, to fsync on disk every second, it is possible that after a restart our key is missing. In theory, if we want to guarantee the lock safety in the face of any kind of instance restart, we need to enable <code>fsync=always</code> in the persistence settings. This will affect performance due to the additional sync overhead.</p>\n<p>However things are better than they look like at a first glance. Basically,<br>the algorithm safety is retained as long as when an instance restarts after a<br>crash, it no longer participates to any <strong>currently active</strong> lock.  This means that the<br>set of currently active locks when the instance restarts were all obtained<br>by locking instances other than the one which is rejoining the system.</p>\n<p>To guarantee this we just need to make an instance, after a crash, unavailable<br>for at least a bit more than the max <code>TTL</code> we use.  This is the time needed<br>for all the keys about the locks that existed when the instance crashed to<br>become invalid and be automatically released.</p>\n<p>Using <em>delayed restarts</em> it is basically possible to achieve safety even<br>without any kind of Valkey persistence available, however note that this may<br>translate into an availability penalty. For example if a majority of instances<br>crash, the system will become globally unavailable for <code>TTL</code> (here globally means<br>that no resource at all will be lockable during this time).</p>\n<h3>Making the algorithm more reliable: Extending the lock</h3>\n<p>If the work performed by clients consists of small steps, it is possible to<br>use smaller lock validity times by default, and extend the algorithm implementing<br>a lock extension mechanism. Basically the client, if in the middle of the<br>computation while the lock validity is approaching a low value, may extend the<br>lock by sending a Lua script to all the instances that extends the TTL of the key<br>if the key exists and its value is still the random value the client assigned<br>when the lock was acquired.</p>\n<p>The client should only consider the lock re-acquired if it was able to extend<br>the lock into the majority of instances, and within the validity time<br>(basically the algorithm to use is very similar to the one used when acquiring<br>the lock).</p>\n<p>However this does not technically change the algorithm, so the maximum number<br>of lock reacquisition attempts should be limited, otherwise one of the liveness<br>properties is violated.</p>\n<h3>Disclaimer about consistency</h3>\n<p>Please consider thoroughly reviewing the <a href=\"#analysis-of-redlock\">Analysis of Redlock</a> section at the end of this page.<br>Martin Kleppman&#39;s article and antirez&#39;s answer to it are very relevant.<br>If you are concerned about consistency and correctness, you should pay attention to the following topics:</p>\n<ol>\n<li>You should implement fencing tokens.<br>  This is especially important for processes that can take significant time and applies to any distributed locking system.<br>  Extending locks&#39; lifetime is also an option, but don´t assume that a lock is retained as long as the process that had acquired it is alive.</li>\n<li>Valkey is not using monotonic clock for TTL expiration mechanism.<br>  That means that a wall-clock shift may result in a lock being acquired by more than one process.<br>  Even though the problem can be mitigated by preventing admins from manually setting the server&#39;s time and setting up NTP properly, there&#39;s still a chance of this issue occurring in real life and compromising consistency.</li>\n</ol>\n<h2>Want to help?</h2>\n<p>If you are into distributed systems, it would be great to have your opinion / analysis. Also reference implementations in other languages could be great.</p>\n<p>Thanks in advance!</p>\n<h2>Analysis of Redlock</h2>\n<hr>\n<ol>\n<li>Martin Kleppmann <a href=\"https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html\">analyzed Redlock here</a>. A counterpoint to this analysis can be <a href=\"https://web.archive.org/web/20241209045142/http://antirez.com/news/101\">found here</a>.</li>\n</ol>\n"
      },
      {
        "id": "replication",
        "topicName": "Replication",
        "description": "How Valkey supports high availability and failover with replication",
        "htmlContent": "<p>At the base of Valkey replication (excluding the high availability features provided as an additional layer by Valkey Cluster or Valkey Sentinel) there is a <em>leader follower</em> (primary-replica) replication that is simple to use and configure. It allows replica Valkey instances to be exact copies of primary instances. The replica will automatically reconnect to the primary every time the link breaks, and will attempt to be an exact copy of it <em>regardless</em> of what happens to the primary.</p>\n<p>This system works using three main mechanisms:</p>\n<ol>\n<li>When a primary and a replica instances are well-connected, the primary keeps the replica updated by sending a stream of commands to the replica to replicate the effects on the dataset happening in the primary side due to: client writes, keys expired or evicted, any other action changing the primary dataset.</li>\n<li>When the link between the primary and the replica breaks, for network issues or because a timeout is sensed in the primary or the replica, the replica reconnects and attempts to proceed with a partial resynchronization: it means that it will try to just obtain the part of the stream of commands it missed during the disconnection.</li>\n<li>When a partial resynchronization is not possible, the replica will ask for a full resynchronization. This will involve a more complex process in which the primary needs to create a snapshot of all its data, send it to the replica, and then continue sending the stream of commands as the dataset changes.</li>\n</ol>\n<p>Valkey uses by default asynchronous replication, which being low latency and<br>high performance, is the natural replication mode for the vast majority of Valkey<br>use cases. However, Valkey replicas asynchronously acknowledge the amount of data<br>they received periodically with the primary. So the primary does not wait every time<br>for a command to be processed by the replicas, however it knows, if needed, what<br>replica already processed what command. This allows having optional synchronous replication.</p>\n<p>Synchronous replication of certain data can be requested by the clients using<br>the <code>WAIT</code> command. However <code>WAIT</code> is only able to ensure there are the<br>specified number of acknowledged copies in the other Valkey instances, it does not<br>turn a set of Valkey instances into a CP system with strong consistency: acknowledged<br>writes can still be lost during a failover, depending on the exact configuration<br>of the Valkey persistence. However with <code>WAIT</code> the probability of losing a write<br>after a failure event is greatly reduced to certain hard to trigger failure<br>modes.</p>\n<p>You can check the Valkey Sentinel or Valkey Cluster documentation for more information<br>about high availability and failover. The rest of this document mainly describes the basic characteristics of Valkey basic replication.</p>\n<h3>Important facts about Valkey replication</h3>\n<ul>\n<li>Valkey uses asynchronous replication, with asynchronous replica-to-primary acknowledges of the amount of data processed.</li>\n<li>A primary can have multiple replicas.</li>\n<li>Replicas are able to accept connections from other replicas. Aside from connecting a number of replicas to the same primary, replicas can also be connected to other replicas in a cascading-like structure. All the sub-replicas will receive exactly the same replication stream from the primary.</li>\n<li>Valkey replication is non-blocking on the primary side. This means that the primary will continue to handle queries when one or more replicas perform the initial synchronization or a partial resynchronization.</li>\n<li>Replication is also largely non-blocking on the replica side. While the replica is performing the initial synchronization, it can handle queries using the old version of the dataset, assuming you configured Valkey to do so in valkey.conf.  Otherwise, you can configure Valkey replicas to return an error to clients if the replication stream is down. However, after the initial sync, the old dataset must be deleted and the new one must be loaded. The replica will block incoming connections during this brief window (that can be as long as many seconds for very large datasets). You can configure Valkey so that the deletion of the old data set happens in a different thread, however loading the new initial dataset will still happen in the main thread and block the replica.</li>\n<li>Replication can be used both for scalability, to have multiple replicas for read-only queries (for example, slow O(N) operations can be offloaded to replicas), or simply for improving data safety and high availability.</li>\n<li>You can use replication to avoid the cost of having the primary writing the full dataset to disk: a typical technique involves configuring your primary&#39;s <code>valkey.conf</code> to avoid persisting to disk at all, then connect a replica configured to save from time to time, or with AOF enabled. However, this setup must be handled with care, since a restarting primary will start with an empty dataset: if the replica tries to sync with it, the replica will be emptied as well.</li>\n</ul>\n<h2>Safety of replication when primary has persistence turned off</h2>\n<p>In setups where Valkey replication is used, it is strongly advised to have<br>persistence turned on in the primary and in the replicas. When this is not possible,<br>for example because of latency concerns due to very slow disks, instances should<br>be configured to <strong>avoid restarting automatically</strong> after a reboot.</p>\n<p>To better understand why primaries with persistence turned off configured to<br>auto restart are dangerous, check the following failure mode where data<br>is wiped from the primary and all its replicas:</p>\n<ol>\n<li>We have a setup with node A acting as primary, with persistence turned down, and nodes B and C replicating from node A.</li>\n<li>Node A crashes, however it has some auto-restart system, that restarts the process. However since persistence is turned off, the node restarts with an empty data set.</li>\n<li>Nodes B and C will replicate from node A, which is empty, so they&#39;ll effectively destroy their copy of the data.</li>\n</ol>\n<p>When Valkey Sentinel is used for high availability, also turning off persistence<br>on the primary, together with auto restart of the process, is dangerous. For example, the primary can restart fast enough for Sentinel to not detect a failure, so that the failure mode described above happens.</p>\n<p>Every time data safety is important, and replication is used with primary configured without persistence, auto restart of instances should be disabled.</p>\n<h2>How Valkey replication works</h2>\n<p>Every Valkey primary has a replication ID: it is a large pseudo random string<br>that marks a given story of the dataset. Each primary also takes an offset that<br>increments for every byte of replication stream that it is produced to be<br>sent to replicas, to update the state of the replicas with the new changes<br>modifying the dataset. The replication offset is incremented even if no replica<br>is actually connected, so basically every given pair of:</p>\n<pre><code>Replication ID, offset\n</code></pre>\n<p>Identifies an exact version of the dataset of a primary.</p>\n<p>When replicas connect to primaries, they use the <code>PSYNC</code> command to send<br>their old primary replication ID and the offsets they processed so far. This way<br>the primary can send just the incremental part needed. However if there is not<br>enough <em>backlog</em> in the primary buffers, or if the replica is referring to a<br>history (replication ID) which is no longer known, then a full resynchronization<br>happens: in this case the replica will get a full copy of the dataset, from scratch.</p>\n<p>This is how a full synchronization works in more details:</p>\n<p>The primary starts a background saving process to produce an RDB file. At the same time it starts to buffer all new write commands received from the clients. When the background saving is complete, the primary transfers the database file to the replica, which saves it on disk, and then loads it into memory. The primary will then send all buffered commands to the replica. This is done as a stream of commands and is in the same format of the Valkey protocol itself.</p>\n<p>You can try it yourself via telnet. Connect to the Valkey port while the<br>server is doing some work and issue the <code>SYNC</code> command. You&#39;ll see a bulk<br>transfer and then every command received by the primary will be re-issued<br>in the telnet session. Actually <code>SYNC</code> is an old protocol no longer used by<br>newer Valkey instances, but is still there for backward compatibility: it does<br>not allow partial resynchronizations, so now <code>PSYNC</code> is used instead.</p>\n<p>As already said, replicas are able to automatically reconnect when the primary-replica link goes down for some reason. If the primary receives multiple concurrent replica synchronization requests, it performs a single background save in to serve all of them.</p>\n<h2>Replication ID explained</h2>\n<p>In the previous section we said that if two instances have the same replication<br>ID and replication offset, they have exactly the same data. However it is useful<br>to understand what exactly is the replication ID, and why instances have actually<br>two replication IDs: the main ID and the secondary ID.</p>\n<p>A replication ID basically marks a given <em>history</em> of the data set. Every time<br>an instance restarts from scratch as a primary, or a replica is promoted to primary,<br>a new replication ID is generated for this instance. The replicas connected to<br>a primary will inherit its replication ID after the handshake. So two instances<br>with the same ID are related by the fact that they hold the same data, but<br>potentially at a different time. It is the offset that works as a logical time<br>to understand, for a given history (replication ID), who holds the most updated<br>data set.</p>\n<p>For instance, if two instances A and B have the same replication ID, but one<br>with offset 1000 and one with offset 1023, it means that the first lacks certain<br>commands applied to the data set. It also means that A, by applying just a few<br>commands, may reach exactly the same state of B.</p>\n<p>The reason why Valkey instances have two replication IDs is because of replicas<br>that are promoted to primaries. After a failover, the promoted replica requires<br>to still remember what was its past replication ID, because such replication ID<br>was the one of the former primary. In this way, when other replicas will sync<br>with the new primary, they will try to perform a partial resynchronization using the<br>old primary replication ID. This will work as expected, because when the replica<br>is promoted to primary, it sets its secondary ID to its main ID, remembering what<br>was the offset when this ID switch happened. Later it will select a new random<br>replication ID, because a new history begins. When handling the new replicas<br>connecting, the primary will match their IDs and offsets both with the current<br>ID and the secondary ID (up to a given offset, for safety). In short this means<br>that after a failover, replicas connecting to the newly promoted primary don&#39;t have<br>to perform a full sync.</p>\n<p>In case you wonder why a replica promoted to primary needs to change its<br>replication ID after a failover: it is possible that the old primary is still<br>working as a primary because of some network partition: retaining the same<br>replication ID would violate the fact that the same ID and same offset of any<br>two random instances mean they have the same data set.</p>\n<h2>Diskless replication</h2>\n<p>Normally a full resynchronization requires creating an RDB file on disk,<br>then reloading the same RDB from disk to feed the replicas with the data.</p>\n<p>With slow disks this can be a very stressing operation for the primary.<br>Valkey has support for diskless<br>replication. In this setup the child process directly sends the<br>RDB over the wire to replicas, without using the disk as intermediate storage.</p>\n<h2>Configuration</h2>\n<p>To configure basic Valkey replication is trivial: just add the following line to the replica configuration file:</p>\n<pre><code>replicaof 192.168.1.1 6379\n</code></pre>\n<p>Of course you need to replace 192.168.1.1 6379 with your primary IP address (or<br>hostname) and port. Alternatively, you can call the <code>REPLICAOF</code> command and the<br>primary host will start a sync with the replica.</p>\n<p>There are also a few parameters for tuning the replication backlog taken<br>in memory by the primary to perform the partial resynchronization. See the example<br><code>valkey.conf</code> shipped with the Valkey distribution for more information.</p>\n<p>Diskless replication can be enabled using the <code>repl-diskless-sync</code> configuration<br>parameter. The delay to start the transfer to wait for more replicas to<br>arrive after the first one is controlled by the <code>repl-diskless-sync-delay</code><br>parameter. Please refer to the example <code>valkey.conf</code> file in the Valkey distribution<br>for more details.</p>\n<h2>Read-only replica</h2>\n<p>Replicas are read-only by default.<br>This behavior is controlled by the <code>replica-read-only</code> option in the valkey.conf file, and can be enabled and disabled at runtime using <code>CONFIG SET</code>.</p>\n<p>Read-only replicas will reject all write commands, so that it is not possible to write to a replica because of a mistake. This does not mean that the feature is intended to expose a replica instance to the internet or more generally to a network where untrusted clients exist, because administrative commands like <code>DEBUG</code> or <code>CONFIG</code> are still enabled. The <a href=\"security\">Security</a> page describes how to secure a Valkey instance.</p>\n<p>You may wonder why it is possible to revert the read-only setting<br>and have replica instances that can be targeted by write operations.<br>The answer is that writable replicas exist only for historical reasons.<br>Using writable replicas can result in inconsistency between the primary and the replica, so it is not recommended to use writable replicas.<br>To understand in which situations this can be a problem, we need to understand how replication works.<br>Changes on the primary is replicated by propagating regular Valkey commands to the replica.<br>When a key expires on the primary, this is propagated as a DEL command.<br>If a key which exists on the primary but is deleted, expired or has a different type on the replica compared to the primary will react differently to commands like DEL, INCR or RPOP propagated from the primary than intended.<br>The propagated command may fail on the replica or result in a different outcome.<br>To minimize the risks (if you insist on using writable replicas) we suggest you follow these recommendations:</p>\n<ul>\n<li><p>Don&#39;t write to keys in a writable replica that are also used on the primary.<br>(This can be hard to guarantee if you don&#39;t have control over all the clients that write to the primary.)</p>\n</li>\n<li><p>Don&#39;t configure an instance as a writable replica as an intermediary step when upgrading a set of instances in a running system.<br>In general, don&#39;t configure an instance as a writable replica if it can ever be promoted to a primary if you want to guarantee data consistency.</p>\n</li>\n</ul>\n<p>Historically, there were some use cases that were considered legitimate for writable replicas.<br>As of version 7.0, these use cases are now all obsolete and the same can be achieved by other means.<br>For example:</p>\n<ul>\n<li><p>Computing slow Set or Sorted set operations and storing the result in temporary local keys using commands like <code>SUNIONSTORE</code> and <code>ZINTERSTORE</code>.<br>Instead, use commands that return the result without storing it, such as <code>SUNION</code> and <code>ZINTER</code>.</p>\n</li>\n<li><p>Using the <code>SORT</code> command (which is not considered a read-only command because of the optional STORE option and therefore cannot be used on a read-only replica).<br>Instead, use <code>SORT_RO</code>, which is a read-only command.</p>\n</li>\n<li><p>Using <code>EVAL</code> and <code>EVALSHA</code> are also not considered read-only commands, because the Lua script may call write commands.<br>Instead, use <code>EVAL_RO</code> and <code>EVALSHA_RO</code> where the Lua script can only call read-only commands.</p>\n</li>\n</ul>\n<p>While writes to a replica will be discarded if the replica and the primary resync or if the replica is restarted, there is no guarantee that they will sync automatically.</p>\n<p>Before version 4.0, writable replicas were incapable of expiring keys with a time to live set.<br>This means that if you use <code>EXPIRE</code> or other commands that set a maximum TTL for a key, the key will leak, and while you may no longer see it while accessing it with read commands, you will see it in the count of keys and it will still use memory.<br>Valkey is able to evict keys with TTL as primaries do, with the exceptions of keys written in DB numbers greater than 63 (but by default Valkey instances only have 16 databases).<br>Note though that even in versions greater than 4.0, using <code>EXPIRE</code> on a key that could ever exists on the primary can cause inconsistency between the replica and the primary.</p>\n<p>Also note that replica writes are only local, and are not propagated to sub-replicas attached to the instance. Sub-replicas instead will always receive the replication stream identical to the one sent by the top-level primary to the intermediate replicas. So for example in the following setup:</p>\n<pre><code>A ---&gt; B ---&gt; C\n</code></pre>\n<p>Even if <code>B</code> is writable, C will not see <code>B</code> writes and will instead have identical dataset as the primary instance <code>A</code>.</p>\n<h2>Setting a replica to authenticate to a primary</h2>\n<p>If your primary has a password via <code>requirepass</code>, it&#39;s trivial to configure the<br>replica to use that password in all sync operations.</p>\n<p>To do it on a running instance, use <code>valkey-cli</code> and type:</p>\n<pre><code>config set primaryauth &lt;password&gt;\n</code></pre>\n<p>To set it permanently, add this to your config file:</p>\n<pre><code>primaryauth &lt;password&gt;\n</code></pre>\n<h2>Allow writes only with N attached replicas</h2>\n<p>You can configure a Valkey primary to<br>accept write queries only if at least N replicas are currently connected to the<br>primary.</p>\n<p>However, because Valkey uses asynchronous replication it is not possible to ensure<br>the replica actually received a given write, so there is always a window for data<br>loss.</p>\n<p>This is how the feature works:</p>\n<ul>\n<li>Valkey replicas ping the primary every second, acknowledging the amount of replication stream processed.</li>\n<li>Valkey primaries will remember the last time it received a ping from every replica.</li>\n<li>The user can configure a minimum number of replicas that have a lag not greater than a maximum number of seconds.</li>\n</ul>\n<p>If there are at least N replicas, with a lag less than M seconds, then the write will be accepted.</p>\n<p>You may think of it as a best effort data safety mechanism, where consistency is not ensured for a given write, but at least the time window for data loss is restricted to a given number of seconds. In general bound data loss is better than unbound one.</p>\n<p>If the conditions are not met, the primary will instead reply with an error and the write will not be accepted.</p>\n<p>There are two configuration parameters for this feature:</p>\n<ul>\n<li>min-replicas-to-write <code>&lt;number of replicas&gt;</code></li>\n<li>min-replicas-max-lag <code>&lt;number of seconds&gt;</code></li>\n</ul>\n<p>For more information, please check the example <code>valkey.conf</code> file shipped with the<br>Valkey source distribution.</p>\n<h2>How Valkey replication deals with expires on keys</h2>\n<p>Valkey expires allow keys to have a limited time to live (TTL). Such a feature depends<br>on the ability of an instance to count the time, however Valkey replicas correctly<br>replicate keys with expires, even when such keys are altered using Lua<br>scripts.</p>\n<p>To implement such a feature Valkey cannot rely on the ability of the primary and<br>replica to have synced clocks, since this is a problem that cannot be solved<br>and would result in race conditions and diverging data sets, so Valkey<br>uses three main techniques to make the replication of expired keys<br>able to work:</p>\n<ol>\n<li>Replicas don&#39;t expire keys, instead they wait for primaries to expire the keys. When a primary expires a key (or evicts it because of LRU), it synthesizes a <code>DEL</code> command which is transmitted to all the replicas.</li>\n<li>However because of primary-driven expire, sometimes replicas may still have in memory keys that are already logically expired, since the primary was not able to provide the <code>DEL</code> command in time. To deal with that the replica uses its logical clock to report that a key does not exist <strong>only for read operations</strong> that don&#39;t violate the consistency of the data set (as new commands from the primary will arrive). In this way replicas avoid reporting logically expired keys that are still existing. In practical terms, an HTML fragments cache that uses replicas to scale will avoid returning items that are already older than the desired time to live.</li>\n<li>During Lua scripts executions no key expiries are performed. As a Lua script runs, conceptually the time in the primary is frozen, so that a given key will either exist or not for all the time the script runs. This prevents keys expiring in the middle of a script, and is needed to send the same script to the replica in a way that is guaranteed to have the same effects in the data set.</li>\n</ol>\n<p>Once a replica is promoted to a primary it will start to expire keys independently, and will not require any help from its old primary.</p>\n<h2>Configuring replication in Docker and NAT</h2>\n<p>When Docker, or other types of containers using port forwarding, or Network Address Translation is used, Valkey replication needs some extra care, especially when using Valkey Sentinel or other systems where the primary <code>INFO</code> or <code>ROLE</code> commands output is scanned to discover replicas&#39; addresses.</p>\n<p>The problem is that the <code>ROLE</code> command, and the replication section of<br>the <code>INFO</code> output, when issued into a primary instance, will show replicas<br>as having the IP address they use to connect to the primary, which, in<br>environments using NAT may be different compared to the logical address of the<br>replica instance (the one that clients should use to connect to replicas).</p>\n<p>Similarly the replicas will be listed with the listening port configured<br>into <code>valkey.conf</code>, that may be different from the forwarded port in case<br>the port is remapped.</p>\n<p>To fix both issues, it is possible to force<br>a replica to announce an arbitrary pair of IP and port to the primary.<br>The two configurations directives to use are:</p>\n<pre><code>replica-announce-ip 5.5.5.5\nreplica-announce-port 1234\n</code></pre>\n<p>And are documented in the example <code>valkey.conf</code> of recent Valkey distributions.</p>\n<h2>The INFO and ROLE command</h2>\n<p>There are two Valkey commands that provide a lot of information on the current<br>replication parameters of primary and replica instances. One is <code>INFO</code>. If the<br>command is called with the <code>replication</code> argument as <code>INFO replication</code> only<br>information relevant to the replication are displayed. Another more<br>computer-friendly command is <code>ROLE</code>, that provides the replication status of<br>primaries and replicas together with their replication offsets, list of connected<br>replicas and so forth.</p>\n<h2>Partial sync after restarts and failovers</h2>\n<p>When an instance is promoted to primary after a failover,<br>it will still be able to perform a partial resynchronization with the replicas<br>of the old primary. To do so, the replica remembers the old replication ID and<br>offset of its former primary, so can provide part of the backlog to the connecting<br>replicas even if they ask for the old replication ID.</p>\n<p>However the new replication ID of the promoted replica will be different, since it<br>constitutes a different history of the data set. For example, the primary can<br>return available and can continue accepting writes for some time, so using the<br>same replication ID in the promoted replica would violate the rule that a<br>replication ID and offset pair identifies only a single data set.</p>\n<p>Moreover, replicas - when powered off gently and restarted - are able to store<br>in the <code>RDB</code> file the information needed to resync with their<br>primary. This is useful in case of upgrades. When this is needed, it is better to<br>use the <code>SHUTDOWN</code> command in order to perform a <code>save &amp; quit</code> operation on the<br>replica.</p>\n<p>It is not possible to partially sync a replica that restarted via the<br>AOF file. However the instance may be turned to RDB persistence before shutting<br>down it, than can be restarted, and finally AOF can be enabled again.</p>\n<h2><code>Maxmemory</code> on replicas</h2>\n<p>By default, a replica will ignore <code>maxmemory</code> (unless it is promoted to a primary after a failover or manually).<br>It means that the eviction of keys will be handled by the primary, sending the DEL commands to the replica as keys evict in the primary side.</p>\n<p>This behavior ensures that primaries and replicas stay consistent, which is usually what you want.<br>However, if your replica is writable, or you want the replica to have a different memory setting, and you are sure all the writes performed to the replica are idempotent, then you may change this default (but be sure to understand what you are doing).</p>\n<p>Note that since the replica by default does not evict, it may end up using more memory than what is set via <code>maxmemory</code> (since there are certain buffers that may be larger on the replica, or data structures may sometimes take more memory and so forth).<br>Make sure you monitor your replicas, and make sure they have enough memory to never hit a real out-of-memory condition before the primary hits the configured <code>maxmemory</code> setting.</p>\n<p>To change this behavior, you can allow a replica to not ignore the <code>maxmemory</code>. The configuration directives to use is:</p>\n<pre><code>replica-ignore-maxmemory no\n</code></pre>\n"
      },
      {
        "id": "sentinel",
        "topicName": "High availability with Valkey Sentinel",
        "description": "High availability for non-clustered Valkey",
        "htmlContent": "<h2>Usage</h2>\n<p><strong><code>valkey-sentinel</code></strong> <em>/path/to/sentinel.conf</em></p>\n<p><strong><code>valkey-server</code></strong> <em>/path/to/sentinel.conf</em> <strong><code>--sentinel</code></strong></p>\n<h2>Description</h2>\n<p>Valkey Sentinel provides high availability for Valkey when not using <a href=\"cluster-tutorial\">Valkey Cluster</a>. </p>\n<p>Valkey Sentinel also provides other collateral tasks such as monitoring,<br>notifications and acts as a configuration provider for clients.</p>\n<p>This is the full list of Sentinel capabilities at a macroscopic level (i.e. the <em>big picture</em>):</p>\n<ul>\n<li><strong>Monitoring</strong>. Sentinel constantly checks if your primary and replica instances are working as expected.</li>\n<li><strong>Notification</strong>. Sentinel can notify the system administrator, or other computer programs, via the API, that something is wrong with one of the monitored Valkey instances.</li>\n<li><strong>Automatic failover</strong>. If a primary is not working as expected, Sentinel can start a failover process where a replica is promoted to primary, the other additional replicas are reconfigured to use the new primary, and the applications using the Valkey server are informed about the new address to use when connecting.</li>\n<li><strong>Configuration provider</strong>. Sentinel acts as a source of authority for clients service discovery: clients connect to Sentinels in order to ask for the address of the current Valkey primary responsible for a given service. If a failover occurs, Sentinels will report the new address.</li>\n</ul>\n<h2>Sentinel as a distributed system</h2>\n<p>Valkey Sentinel is a distributed system:</p>\n<p>Sentinel itself is designed to run in a configuration where there are multiple Sentinel processes cooperating together. The advantage of having multiple Sentinel processes cooperating are the following:</p>\n<ol>\n<li>Failure detection is performed when multiple Sentinels agree about the fact a given primary is no longer available. This lowers the probability of false positives.</li>\n<li>Sentinel works even if not all the Sentinel processes are working, making the system robust against failures. There is no fun in having a failover system which is itself a single point of failure, after all.</li>\n</ol>\n<p>The sum of Sentinels, Valkey instances (primaries and replicas) and clients<br>connecting to Sentinel and Valkey, are also a larger distributed system with<br>specific properties. In this document concepts will be introduced gradually<br>starting from basic information needed in order to understand the basic<br>properties of Sentinel, to more complex information (that are optional) in<br>order to understand how exactly Sentinel works.</p>\n<h2>Sentinel quick start</h2>\n<p>Valkey Sentinel is included in Valkey.</p>\n<h3>Running Sentinel</h3>\n<p>If you are using the <code>valkey-sentinel</code> executable (or if you have a symbolic<br>link with that name to the <code>valkey-server</code> executable) you can run Sentinel<br>with the following command line:</p>\n<pre><code>valkey-sentinel /path/to/sentinel.conf\n</code></pre>\n<p>Otherwise you can use directly the <code>valkey-server</code> executable starting it in<br>Sentinel mode:</p>\n<pre><code>valkey-server /path/to/sentinel.conf --sentinel\n</code></pre>\n<p>Both ways work the same.</p>\n<p>However <strong>it is mandatory</strong> to use a configuration file when running Sentinel, as this file will be used by the system in order to save the current state that will be reloaded in case of restarts. Sentinel will simply refuse to start if no configuration file is given or if the configuration file path is not writable.</p>\n<p>Sentinels by default run <strong>listening for connections to TCP port 26379</strong>, so<br>for Sentinels to work, port 26379 of your servers <strong>must be open</strong> to receive<br>connections from the IP addresses of the other Sentinel instances.<br>Otherwise Sentinels can&#39;t talk and can&#39;t agree about what to do, so failover<br>will never be performed.</p>\n<h3>Fundamental things to know about Sentinel before deploying</h3>\n<ol>\n<li>You need at least three Sentinel instances for a robust deployment.</li>\n<li>The three Sentinel instances should be placed into computers or virtual machines that are believed to fail in an independent way. So for example different physical servers or Virtual Machines executed on different availability zones.</li>\n<li>Sentinel + Valkey distributed system does not guarantee that acknowledged writes are retained during failures, since Valkey uses asynchronous replication. However there are ways to deploy Sentinel that make the window to lose writes limited to certain moments, while there are other less secure ways to deploy it.</li>\n<li>You need Sentinel support in your clients. Popular client libraries have Sentinel support, but not all.</li>\n<li>There is no HA setup which is safe if you don&#39;t test from time to time in development environments, or even better, if you can in production environments, if they work. You may have a misconfiguration that will become apparent only when it&#39;s too late (at 3am when your primary stops working).</li>\n<li><strong>Sentinel, Docker, or other forms of Network Address Translation or Port Mapping should be mixed with care</strong>: Docker performs port remapping, breaking Sentinel auto discovery of other Sentinel processes and the list of replicas for a primary. Check the <a href=\"#sentinel-docker-nat-and-possible-issues\">section about <em>Sentinel and Docker</em></a> later in this document for more information.</li>\n</ol>\n<h3>Configuring Sentinel</h3>\n<p>The Valkey source distribution contains a file called <code>sentinel.conf</code><br>that is a self-documented example configuration file you can use to<br>configure Sentinel, however a typical minimal configuration file looks like the<br>following:</p>\n<pre><code>sentinel monitor mymaster 127.0.0.1 6379 2\nsentinel down-after-milliseconds mymaster 60000\nsentinel failover-timeout mymaster 180000\nsentinel parallel-syncs mymaster 1\n\nsentinel monitor resque 192.168.1.3 6380 4\nsentinel down-after-milliseconds resque 10000\nsentinel failover-timeout resque 180000\nsentinel parallel-syncs resque 5\n</code></pre>\n<p>You only need to specify the primaries to monitor, giving to each separated<br>primary (that may have any number of replicas) a different name. There is no<br>need to specify replicas, which are auto-discovered. Sentinel will update the<br>configuration automatically with additional information about replicas (in<br>order to retain the information in case of restart). The configuration is<br>also rewritten every time a replica is promoted to primary during a failover<br>and every time a new Sentinel is discovered.</p>\n<p>The example configuration above basically monitors two sets of Valkey<br>instances, each composed of a primary and an undefined number of replicas.<br>One set of instances is called <code>mymaster</code>, and the other <code>resque</code>.</p>\n<p>The meaning of the arguments of <code>sentinel monitor</code> statements is the following:</p>\n<pre><code>sentinel monitor &lt;primary-name&gt; &lt;ip&gt; &lt;port&gt; &lt;quorum&gt;\n</code></pre>\n<p>For the sake of clarity, let&#39;s check line by line what the configuration<br>options mean:</p>\n<p>The first line is used to tell Valkey to monitor a primary called <em>mymaster</em>,<br>that is at address 127.0.0.1 and port 6379, with a quorum of 2. Everything<br>is pretty obvious but the <strong>quorum</strong> argument:</p>\n<ul>\n<li>The <strong>quorum</strong> is the number of Sentinels that need to agree about the fact the primary is not reachable, in order to really mark the primary as failing, and eventually start a failover procedure if possible.</li>\n<li>However <strong>the quorum is only used to detect the failure</strong>. In order to actually perform a failover, one of the Sentinels need to be elected leader for the failover and be authorized to proceed. This only happens with the vote of the <strong>majority of the Sentinel processes</strong>.</li>\n</ul>\n<p>So for example if you have 5 Sentinel processes, and the quorum for a given<br>primary is set to the value of 2, this is what happens:</p>\n<ul>\n<li>If two Sentinels agree at the same time about the primary being unreachable, one of the two will try to start a failover.</li>\n<li>If there are at least a total of three Sentinels reachable, the failover will be authorized and will actually start.</li>\n</ul>\n<p>In practical terms this means during failures <strong>Sentinel never starts a failover if the majority of Sentinel processes are unable to talk</strong> (aka no failover in the minority partition).</p>\n<h3>Other Sentinel options</h3>\n<p>The other options are almost always in the form:</p>\n<pre><code>sentinel &lt;option_name&gt; &lt;primary_name&gt; &lt;option_value&gt;\n</code></pre>\n<p>And are used for the following purposes:</p>\n<ul>\n<li><code>down-after-milliseconds</code> is the time in milliseconds an instance should not<br>be reachable (either does not reply to our PINGs or it is replying with an<br>error) for a Sentinel starting to think it is down.</li>\n<li><code>parallel-syncs</code> sets the number of replicas that can be reconfigured to use<br>the new primary after a failover at the same time. The lower the number, the<br>more time it will take for the failover process to complete, however if the<br>replicas are configured to serve old data, you may not want all the replicas to<br>re-synchronize with the primary at the same time. While the replication<br>process is mostly non blocking for a replica, there is a moment when it stops to<br>load the bulk data from the primary. You may want to make sure only one replica<br>at a time is not reachable by setting this option to the value of 1.</li>\n</ul>\n<p>Additional options are described in the rest of this document and<br>documented in the example <code>sentinel.conf</code> file shipped with the Valkey<br>distribution.</p>\n<p>Configuration parameters can be modified at runtime:</p>\n<ul>\n<li>Master-specific configuration parameters are modified using <code>SENTINEL SET</code>.</li>\n<li>Global configuration parameters are modified using <code>SENTINEL CONFIG SET</code>.</li>\n</ul>\n<p>See the <a href=\"#reconfiguring-sentinel-at-runtime\"><em>Reconfiguring Sentinel at runtime</em> section</a> for more information.</p>\n<h3>Example Sentinel deployments</h3>\n<p>Now that you know the basic information about Sentinel, you may wonder where<br>you should place your Sentinel processes, how many Sentinel processes you need<br>and so forth. This section shows a few example deployments.</p>\n<p>We use ASCII art in order to show you configuration examples in a <em>graphical</em><br>format, this is what the different symbols means:</p>\n<pre><code>+--------------------+\n| This is a computer |\n| or VM that fails   |\n| independently. We  |\n| call it a &quot;box&quot;    |\n+--------------------+\n</code></pre>\n<p>We write inside the boxes what they are running:</p>\n<pre><code>+--------------------+\n| Valkey primary M1   |\n| Valkey Sentinel S1 |\n+--------------------+\n</code></pre>\n<p>Different boxes are connected by lines, to show that they are able to talk:</p>\n<pre><code>+-------------+               +-------------+\n| Sentinel S1 |---------------| Sentinel S2 |\n+-------------+               +-------------+\n</code></pre>\n<p>Network partitions are shown as interrupted lines using slashes:</p>\n<pre><code>+-------------+                +-------------+\n| Sentinel S1 |------ // ------| Sentinel S2 |\n+-------------+                +-------------+\n</code></pre>\n<p>Also note that:</p>\n<ul>\n<li>Primaries are called M1, M2, M3, ..., Mn.</li>\n<li>Replicas are called R1, R2, R3, ..., Rn (R stands for <em>replica</em>).</li>\n<li>Sentinels are called S1, S2, S3, ..., Sn.</li>\n<li>Clients are called C1, C2, C3, ..., Cn.</li>\n<li>When an instance changes role because of Sentinel actions, we put it inside square brackets, so [M1] means an instance that is now a primary because of Sentinel intervention.</li>\n</ul>\n<p>Note that we will never show <strong>setups where just two Sentinels are used</strong>, since<br>Sentinels always need <strong>to talk with the majority</strong> in order to start a<br>failover.</p>\n<h4>Example 1: just two Sentinels, DON&#39;T DO THIS</h4>\n<pre><code>+----+         +----+\n| M1 |---------| R1 |\n| S1 |         | S2 |\n+----+         +----+\n\nConfiguration: quorum = 1\n</code></pre>\n<ul>\n<li>In this setup, if the primary M1 fails, R1 will be promoted since the two Sentinels can reach agreement about the failure (obviously with quorum set to 1) and can also authorize a failover because the majority is two. So apparently it could superficially work, however check the next points to see why this setup is broken.</li>\n<li>If the box where M1 is running stops working, also S1 stops working. The Sentinel running in the other box S2 will not be able to authorize a failover, so the system will become not available.</li>\n</ul>\n<p>Note that a majority is needed in order to order different failovers, and later propagate the latest configuration to all the Sentinels. Also note that the ability to failover in a single side of the above setup, without any agreement, would be very dangerous:</p>\n<pre><code>+----+           +------+\n| M1 |----//-----| [M1] |\n| S1 |           | S2   |\n+----+           +------+\n</code></pre>\n<p>In the above configuration we created two primaries (assuming S2 could failover<br>without authorization) in a perfectly symmetrical way. Clients may write<br>indefinitely to both sides, and there is no way to understand when the<br>partition heals what configuration is the right one, in order to prevent<br>a <em>permanent split brain condition</em>.</p>\n<p>So please <strong>deploy at least three Sentinels in three different boxes</strong> always.</p>\n<h4>Example 2: basic setup with three boxes</h4>\n<p>This is a very simple setup, that has the advantage to be simple to tune<br>for additional safety. It is based on three boxes, each box running both<br>a Valkey process and a Sentinel process.</p>\n<pre><code>       +----+\n       | M1 |\n       | S1 |\n       +----+\n          |\n+----+    |    +----+\n| R2 |----+----| R3 |\n| S2 |         | S3 |\n+----+         +----+\n\nConfiguration: quorum = 2\n</code></pre>\n<p>If the primary M1 fails, S2 and S3 will agree about the failure and will<br>be able to authorize a failover, making clients able to continue.</p>\n<p>In every Sentinel setup, as Valkey uses asynchronous replication, there is<br>always the risk of losing some writes because a given acknowledged write<br>may not be able to reach the replica which is promoted to primary. However in<br>the above setup there is a higher risk due to clients being partitioned away<br>with an old primary, like in the following picture:</p>\n<pre><code>         +----+\n         | M1 |\n         | S1 | &lt;- C1 (writes will be lost)\n         +----+\n            |\n            /\n            /\n+------+    |    +----+\n| [M2] |----+----| R3 |\n| S2   |         | S3 |\n+------+         +----+\n</code></pre>\n<p>In this case a network partition isolated the old primary M1, so the<br>replica R2 is promoted to primary. However clients, like C1, that are<br>in the same partition as the old primary, may continue to write data<br>to the old primary. This data will be lost forever since when the partition<br>will heal, the primary will be reconfigured as a replica of the new primary,<br>discarding its data set.</p>\n<p>This problem can be mitigated using the following Valkey replication<br>feature, that allows to stop accepting writes if a primary detects that<br>it is no longer able to transfer its writes to the specified number of replicas.</p>\n<pre><code>min-replicas-to-write 1\nmin-replicas-max-lag 10\n</code></pre>\n<p>With the above configuration (please see the self-commented <code>valkey.conf</code> example in the Valkey distribution for more information) a Valkey instance, when acting as a primary, will stop accepting writes if it can&#39;t write to at least 1 replica. Since replication is asynchronous <em>not being able to write</em> actually means that the replica is either disconnected, or is not sending us asynchronous acknowledges for more than the specified <code>max-lag</code> number of seconds.</p>\n<p>Using this configuration, the old Valkey primary M1 in the above example, will become unavailable after 10 seconds. When the partition heals, the Sentinel configuration will converge to the new one, the client C1 will be able to fetch a valid configuration and will continue with the new primary.</p>\n<p>However there is no free lunch. With this refinement, if the two replicas are<br>down, the primary will stop accepting writes. It&#39;s a trade off.</p>\n<h4>Example 3: Sentinel in the client boxes</h4>\n<p>Sometimes we have only two Valkey boxes available, one for the primary and<br>one for the replica. The configuration in the example 2 is not viable in<br>that case, so we can resort to the following, where Sentinels are placed<br>where clients are:</p>\n<pre><code>            +----+         +----+\n            | M1 |----+----| R1 |\n            |    |    |    |    |\n            +----+    |    +----+\n                      |\n         +------------+------------+\n         |            |            |\n         |            |            |\n      +----+        +----+      +----+\n      | C1 |        | C2 |      | C3 |\n      | S1 |        | S2 |      | S3 |\n      +----+        +----+      +----+\n\n      Configuration: quorum = 2\n</code></pre>\n<p>In this setup, the point of view Sentinels is the same as the clients: if<br>a primary is reachable by the majority of the clients, it is fine.<br>C1, C2, C3 here are generic clients, it does not mean that C1 identifies<br>a single client connected to Valkey. It is more likely something like<br>an application server, a Rails app, or something like that.</p>\n<p>If the box where M1 and S1 are running fails, the failover will happen<br>without issues, however it is easy to see that different network partitions<br>will result in different behaviors. For example Sentinel will not be able<br>to setup if the network between the clients and the Valkey servers is<br>disconnected, since the Valkey primary and replica will both be unavailable.</p>\n<p>Note that if C3 gets partitioned with M1 (hardly possible with<br>the network described above, but more likely possible with different<br>layouts, or because of failures at the software layer), we have a similar<br>issue as described in Example 2, with the difference that here we have<br>no way to break the symmetry, since there is just a replica and a primary, so<br>the primary can&#39;t stop accepting queries when it is disconnected from its replica,<br>otherwise the primary would never be available during replica failures.</p>\n<p>So this is a valid setup but the setup in the Example 2 has advantages<br>such as the HA system of Valkey running in the same boxes as Valkey itself<br>which may be simpler to manage, and the ability to put a bound on the amount<br>of time a primary in the minority partition can receive writes.</p>\n<h4>Example 4: Sentinel client side with less than three clients</h4>\n<p>The setup described in the Example 3 cannot be used if there are less than<br>three boxes in the client side (for example three web servers). In this<br>case we need to resort to a mixed setup like the following:</p>\n<pre><code>            +----+         +----+\n            | M1 |----+----| R1 |\n            | S1 |    |    | S2 |\n            +----+    |    +----+\n                      |\n               +------+-----+\n               |            |\n               |            |\n            +----+        +----+\n            | C1 |        | C2 |\n            | S3 |        | S4 |\n            +----+        +----+\n\n      Configuration: quorum = 3\n</code></pre>\n<p>This is similar to the setup in Example 3, but here we run four Sentinels<br>in the four boxes we have available. If the primary M1 becomes unavailable<br>the other three Sentinels will perform the failover.</p>\n<p>In theory this setup works removing the box where C2 and S4 are running, and<br>setting the quorum to 2. However it is unlikely that we want HA in the<br>Valkey side without having high availability in our application layer.</p>\n<h3>Sentinel, Docker, NAT, and possible issues</h3>\n<p>Docker uses a technique called port mapping: programs running inside Docker<br>containers may be exposed with a different port compared to the one the<br>program believes to be using. This is useful in order to run multiple<br>containers using the same ports, at the same time, in the same server.</p>\n<p>Docker is not the only software system where this happens, there are other<br>Network Address Translation setups where ports may be remapped, and sometimes<br>not ports but also IP addresses.</p>\n<p>Remapping ports and addresses creates issues with Sentinel in two ways:</p>\n<ol>\n<li>Sentinel auto-discovery of other Sentinels no longer works, since it is based on <em>hello</em> messages where each Sentinel announce at which port and IP address they are listening for connection. However Sentinels have no way to understand that an address or port is remapped, so it is announcing an information that is not correct for other Sentinels to connect.</li>\n<li>Replicas are listed in the <code>INFO</code> output of a Valkey primary in a similar way: the address is detected by the primary checking the remote peer of the TCP connection, while the port is advertised by the replica itself during the handshake, however the port may be wrong for the same reason as exposed in point 1.</li>\n</ol>\n<p>Since Sentinels auto detect replicas using primaries <code>INFO</code> output information,<br>the detected replicas will not be reachable, and Sentinel will never be able to<br>failover the primary, since there are no good replicas from the point of view of<br>the system, so there is currently no way to monitor with Sentinel a set of<br>primary and replica instances deployed with Docker, <strong>unless you instruct Docker<br>to map the port 1:1</strong>.</p>\n<p>For the first problem, in case you want to run a set of Sentinel<br>instances using Docker with forwarded ports (or any other NAT setup where ports<br>are remapped), you can use the following two Sentinel configuration directives<br>in order to force Sentinel to announce a specific set of IP and port:</p>\n<pre><code>sentinel announce-ip &lt;ip&gt;\nsentinel announce-port &lt;port&gt;\n</code></pre>\n<p>Note that Docker has the ability to run in <em>host networking mode</em> (check the <code>--net=host</code> option for more information). This should create no issues since ports are not remapped in this setup.</p>\n<h3>IP Addresses and DNS names</h3>\n<p>Older versions of Sentinel did not support host names and required IP addresses to be specified everywhere.<br>Starting with version 6.2, Sentinel has <em>optional</em> support for host names.</p>\n<p><strong>This capability is disabled by default. If you&#39;re going to enable DNS/hostnames support, please note:</strong></p>\n<ol>\n<li>The name resolution configuration on your Valkey and Sentinel nodes must be reliable and be able to resolve addresses quickly. Unexpected delays in address resolution may have a negative impact on Sentinel.</li>\n<li>You should use hostnames everywhere and avoid mixing hostnames and IP addresses. To do that, use <code>replica-announce-ip &lt;hostname&gt;</code> and <code>sentinel announce-ip &lt;hostname&gt;</code> for all Valkey and Sentinel instances, respectively.</li>\n</ol>\n<p>Enabling the <code>resolve-hostnames</code> global configuration allows Sentinel to accept host names:</p>\n<ul>\n<li>As part of a <code>sentinel monitor</code> command</li>\n<li>As a replica address, if the replica uses a host name value for <code>replica-announce-ip</code></li>\n</ul>\n<p>Sentinel will accept host names as valid inputs and resolve them, but will still refer to IP addresses when announcing an instance, updating configuration files, etc.</p>\n<p>Enabling the <code>announce-hostnames</code> global configuration makes Sentinel use host names instead. This affects replies to clients, values written in configuration files, the <code>REPLICAOF</code> command issued to replicas, etc.</p>\n<p>This behavior may not be compatible with all Sentinel clients, that may explicitly expect an IP address.</p>\n<p>Using host names may be useful when clients use TLS to connect to instances and require a name rather than an IP address in order to perform certificate ASN matching.</p>\n<h2>A quick tutorial</h2>\n<p>In the next sections of this document, all the details about <a href=\"#sentinel-api\"><em>Sentinel API</em></a>,<br>configuration and semantics will be covered incrementally. However for people<br>that want to play with the system ASAP, this section is a tutorial that shows<br>how to configure and interact with 3 Sentinel instances.</p>\n<p>Here we assume that the instances are executed at port 5000, 5001, 5002.<br>We also assume that you have a running Valkey primary at port 6379 with a<br>replica running at port 6380. We will use the IPv4 loopback address 127.0.0.1<br>everywhere during the tutorial, assuming you are running the simulation<br>on your personal computer.</p>\n<p>The three Sentinel configuration files should look like the following:</p>\n<pre><code>port 5000\nsentinel monitor mymaster 127.0.0.1 6379 2\nsentinel down-after-milliseconds mymaster 5000\nsentinel failover-timeout mymaster 60000\nsentinel parallel-syncs mymaster 1\n</code></pre>\n<p>The other two configuration files will be identical but using 5001 and 5002<br>as port numbers.</p>\n<p>A few things to note about the above configuration:</p>\n<ul>\n<li>The primary set is called <code>mymaster</code>. It identifies the primary and its replicas. Since each <em>primary set</em> has a different name, Sentinel can monitor different sets of primaries and replicas at the same time.</li>\n<li>The quorum was set to the value of 2 (last argument of <code>sentinel monitor</code> configuration directive).</li>\n<li>The <code>down-after-milliseconds</code> value is 5000 milliseconds, that is 5 seconds, so primaries will be detected as failing as soon as we don&#39;t receive any reply from our pings within this amount of time.</li>\n</ul>\n<p>Once you start the three Sentinels, you&#39;ll see a few messages they log, like:</p>\n<pre><code>+monitor master mymaster 127.0.0.1 6379 quorum 2\n</code></pre>\n<p>This is a Sentinel event, and you can receive this kind of events via Pub/Sub<br>if you <code>SUBSCRIBE</code> to the event name as specified later in <a href=\"#pubsub-messages\"><em>Pubsub Messages</em> section</a>.</p>\n<p>Sentinel generates and logs different events during failure detection and<br>failover.</p>\n<h2>Asking Sentinel about the state of a primary</h2>\n<p>The most obvious thing to do with Sentinel to get started, is check if the<br>primary it is monitoring is doing well:</p>\n<pre><code>$ valkey-cli -p 5000\n127.0.0.1:5000&gt; sentinel master mymaster\n 1) &quot;name&quot;\n 2) &quot;mymaster&quot;\n 3) &quot;ip&quot;\n 4) &quot;127.0.0.1&quot;\n 5) &quot;port&quot;\n 6) &quot;6379&quot;\n 7) &quot;runid&quot;\n 8) &quot;953ae6a589449c13ddefaee3538d356d287f509b&quot;\n 9) &quot;flags&quot;\n10) &quot;master&quot;\n11) &quot;link-pending-commands&quot;\n12) &quot;0&quot;\n13) &quot;link-refcount&quot;\n14) &quot;1&quot;\n15) &quot;last-ping-sent&quot;\n16) &quot;0&quot;\n17) &quot;last-ok-ping-reply&quot;\n18) &quot;735&quot;\n19) &quot;last-ping-reply&quot;\n20) &quot;735&quot;\n21) &quot;down-after-milliseconds&quot;\n22) &quot;5000&quot;\n23) &quot;info-refresh&quot;\n24) &quot;126&quot;\n25) &quot;role-reported&quot;\n26) &quot;master&quot;\n27) &quot;role-reported-time&quot;\n28) &quot;532439&quot;\n29) &quot;config-epoch&quot;\n30) &quot;1&quot;\n31) &quot;num-slaves&quot;\n32) &quot;1&quot;\n33) &quot;num-other-sentinels&quot;\n34) &quot;2&quot;\n35) &quot;quorum&quot;\n36) &quot;2&quot;\n37) &quot;failover-timeout&quot;\n38) &quot;60000&quot;\n39) &quot;parallel-syncs&quot;\n40) &quot;1&quot;\n</code></pre>\n<p>As you can see, it prints a number of information about the primary. There are<br>a few that are of particular interest for us:</p>\n<ol>\n<li><code>num-other-sentinels</code> is 2, so we know the Sentinel already detected two more Sentinels for this primary. If you check the logs you&#39;ll see the <code>+sentinel</code> events generated.</li>\n<li><code>flags</code> is just <code>master</code>. If the primary was down we could expect to see <code>s_down</code> or <code>o_down</code> flag as well here.</li>\n<li><code>num-slaves</code> is correctly set to 1, so Sentinel also detected that there is an attached replica to our primary.</li>\n</ol>\n<p>In order to explore more about this instance, you may want to try the following<br>two commands:</p>\n<pre><code>SENTINEL replicas mymaster\nSENTINEL sentinels mymaster\n</code></pre>\n<p>The first will provide similar information about the replicas connected to the<br>primary, and the second about the other Sentinels.</p>\n<h2>Obtaining the address of the current primary</h2>\n<p>As we already specified, Sentinel also acts as a configuration provider for<br>clients that want to connect to a set of primary and replicas. Because of<br>possible failovers or reconfigurations, clients have no idea about who is<br>the currently active primary for a given set of instances, so Sentinel exports<br>an API to ask this question:</p>\n<pre><code>127.0.0.1:5000&gt; SENTINEL get-master-addr-by-name mymaster\n1) &quot;127.0.0.1&quot;\n2) &quot;6379&quot;\n</code></pre>\n<h3>Testing the failover</h3>\n<p>At this point our toy Sentinel deployment is ready to be tested. We can<br>just kill our primary and check if the configuration changes. To do so<br>we can just do:</p>\n<pre><code>valkey-cli -p 6379 DEBUG sleep 30\n</code></pre>\n<p>This command will make our primary no longer reachable, sleeping for 30 seconds.<br>It basically simulates a primary hanging for some reason.</p>\n<p>If you check the Sentinel logs, you should be able to see a lot of action:</p>\n<ol>\n<li>Each Sentinel detects the primary is down with an <code>+sdown</code> event.</li>\n<li>This event is later escalated to <code>+odown</code>, which means that multiple Sentinels agree about the fact the primary is not reachable.</li>\n<li>Sentinels vote a Sentinel that will start the first failover attempt.</li>\n<li>The failover happens.</li>\n</ol>\n<p>If you ask again what is the current primary address for <code>mymaster</code>, eventually<br>we should get a different reply this time:</p>\n<pre><code>127.0.0.1:5000&gt; SENTINEL get-master-addr-by-name mymaster\n1) &quot;127.0.0.1&quot;\n2) &quot;6380&quot;\n</code></pre>\n<p>So far so good... At this point you may jump to create your Sentinel deployment<br>or can read more to understand all the Sentinel commands and internals.</p>\n<h2>Sentinel API</h2>\n<p>Sentinel provides an API in order to inspect its state, check the health<br>of monitored primaries and replicas, subscribe in order to receive specific<br>notifications, and change the Sentinel configuration at run time.</p>\n<p>By default Sentinel runs using TCP port 26379 (note that 6379 is the normal<br>Valkey port). Sentinels accept commands using the Valkey protocol, so you can<br>use <code>valkey-cli</code> or any other unmodified Valkey client in order to talk with<br>Sentinel.</p>\n<p>It is possible to directly query a Sentinel to check what is the state of<br>the monitored Valkey instances from its point of view, to see what other<br>Sentinels it knows, and so forth. Alternatively, using Pub/Sub, it is possible<br>to receive <em>push style</em> notifications from Sentinels, every time some event<br>happens, like a failover, or an instance entering an error condition, and<br>so forth.</p>\n<h3>Sentinel commands</h3>\n<p>The <code>SENTINEL</code> command is the main API for Sentinel. The following is the list of its subcommands (minimal version is noted for where applicable):</p>\n<ul>\n<li><strong>SENTINEL CONFIG GET <code>&lt;name&gt;</code></strong> (<code>&gt;= 6.2</code>) Get the current value of a global Sentinel configuration parameter. The specified name may be a wildcard, similar to the Valkey <code>CONFIG GET</code> command.</li>\n<li><strong>SENTINEL CONFIG SET <code>&lt;name&gt;</code> <code>&lt;value&gt;</code></strong> (<code>&gt;= 6.2</code>) Set the value of a global Sentinel configuration parameter.</li>\n<li><strong>SENTINEL CKQUORUM <code>&lt;primary name&gt;</code></strong> Check if the current Sentinel configuration is able to reach the quorum needed to failover a primary, and the majority needed to authorize the failover. This command should be used in monitoring systems to check if a Sentinel deployment is ok.</li>\n<li><strong>SENTINEL FLUSHCONFIG</strong> Force Sentinel to rewrite its configuration on disk, including the current Sentinel state. Normally Sentinel rewrites the configuration every time something changes in its state (in the context of the subset of the state which is persisted on disk across restart). However sometimes it is possible that the configuration file is lost because of operation errors, disk failures, package upgrade scripts or configuration managers. In those cases a way to force Sentinel to rewrite the configuration file is handy. This command works even if the previous configuration file is completely missing.</li>\n<li><strong>SENTINEL FAILOVER <code>&lt;primary name&gt;</code></strong> Force a failover as if the primary was not reachable, and without asking for agreement to other Sentinels (however a new version of the configuration will be published so that the other Sentinels will update their configurations).</li>\n<li><strong>SENTINEL GET-MASTER-ADDR-BY-NAME <code>&lt;primary name&gt;</code></strong> Return the ip and port number of the primary with that name. If a failover is in progress or terminated successfully for this primary it returns the address and port of the promoted replica.</li>\n<li><strong>SENTINEL INFO-CACHE</strong> Return cached <code>INFO</code> output from primaries and replicas.</li>\n<li><strong>SENTINEL IS-MASTER-DOWN-BY-ADDR <ip> <port> <current-epoch> <runid></strong> Check if the primary specified by ip:port is down from current Sentinel&#39;s point of view. This command is mostly for internal use.</li>\n<li><strong>SENTINEL MASTER <code>&lt;primary name&gt;</code></strong> Show the state and info of the specified primary.</li>\n<li><strong>SENTINEL MASTERS</strong> Show a list of monitored primaries and their state.</li>\n<li><strong>SENTINEL MONITOR</strong> Start Sentinel&#39;s monitoring. Refer to the <a href=\"#reconfiguring-sentinel-at-runtime\"><em>Reconfiguring Sentinel at Runtime</em> section</a> for more information.</li>\n<li><strong>SENTINEL MYID</strong> (<code>&gt;= 6.2</code>) Return the ID of the Sentinel instance.</li>\n<li><strong>SENTINEL PENDING-SCRIPTS</strong> This command returns information about pending scripts.</li>\n<li><strong>SENTINEL REMOVE</strong> Stop Sentinel&#39;s monitoring. Refer to the <a href=\"#reconfiguring-sentinel-at-runtime\"><em>Reconfiguring Sentinel at Runtime</em> section</a> for more information.</li>\n<li><strong>SENTINEL REPLICAS <code>&lt;primary name&gt;</code></strong> Show a list of replicas for this primary, and their state.</li>\n<li><strong>SENTINEL SENTINELS <code>&lt;primary name&gt;</code></strong> Show a list of sentinel instances for this primary, and their state.</li>\n<li><strong>SENTINEL SET</strong> Set Sentinel&#39;s monitoring configuration. Refer to the <a href=\"#reconfiguring-sentinel-at-runtime\"><em>Reconfiguring Sentinel at Runtime</em> section</a> for more information.</li>\n<li><strong>SENTINEL SIMULATE-FAILURE (crash-after-election|crash-after-promotion|help)</strong> This command simulates different Sentinel crash scenarios.</li>\n<li><strong>SENTINEL RESET <code>&lt;pattern&gt;</code></strong> This command will reset all the primaries with matching name. The pattern argument is a glob-style pattern. The reset process clears any previous state in a primary (including a failover in progress), and removes every replica and sentinel already discovered and associated with the primary.</li>\n</ul>\n<p>For connection management and administration purposes, Sentinel supports the following subset of Valkey&#39;s commands:</p>\n<ul>\n<li><strong>ACL</strong> (<code>&gt;= 6.2</code>) This command manages the Sentinel Access Control List. For more information refer to the <a href=\"acl\">ACL</a> documentation page and the <a href=\"#sentinel-access-control-list-authentication\"><em>Sentinel Access Control List authentication</em></a>.</li>\n<li><strong>AUTH</strong> Authenticate a client connection. For more information refer to the <code>AUTH</code> command and the <a href=\"#configuring-sentinel-instances-with-authentication\"><em>Configuring Sentinel instances with authentication</em> section</a>.</li>\n<li><strong>CLIENT</strong> This command manages client connections. For more information refer to its subcommands&#39; pages.</li>\n<li><strong>COMMAND</strong> (<code>&gt;= 6.2</code>) This command returns information about commands. For more information refer to the <code>COMMAND</code> command and its various subcommands.</li>\n<li><strong>HELLO</strong> (<code>&gt;= 6.0</code>) Switch the connection&#39;s protocol. For more information refer to the <code>HELLO</code> command.</li>\n<li><strong>INFO</strong> Return information and statistics about the Sentinel server. For more information see the <code>INFO</code> command.</li>\n<li><strong>PING</strong> This command simply returns PONG.</li>\n<li><strong>ROLE</strong> This command returns the string &quot;sentinel&quot; and a list of monitored primaries. For more information refer to the <code>ROLE</code> command.</li>\n<li><strong>SHUTDOWN</strong> Shut down the Sentinel instance.</li>\n</ul>\n<p>Lastly, Sentinel also supports the <code>SUBSCRIBE</code>, <code>UNSUBSCRIBE</code>, <code>PSUBSCRIBE</code> and <code>PUNSUBSCRIBE</code> commands. Refer to the <a href=\"#pubsub-messages\"><em>Pub/Sub Messages</em> section</a> for more details.</p>\n<h3>Reconfiguring Sentinel at Runtime</h3>\n<p>Sentinel provides an API in order to add, remove, or change the configuration of a given primary. Note that if you have multiple sentinels you should apply the changes to all to your instances for Valkey Sentinel to work properly. This means that changing the configuration of a single Sentinel does not automatically propagate the changes to the other Sentinels in the network.</p>\n<p>The following is a list of <code>SENTINEL</code> subcommands used in order to update the configuration of a Sentinel instance.</p>\n<ul>\n<li><strong>SENTINEL MONITOR <code>&lt;name&gt;</code> <code>&lt;ip&gt;</code> <code>&lt;port&gt;</code> <code>&lt;quorum&gt;</code></strong> This command tells the Sentinel to start monitoring a new primary with the specified name, ip, port, and quorum. It is identical to the <code>sentinel monitor</code> configuration directive in <code>sentinel.conf</code> configuration file, with the difference that you can&#39;t use a hostname in as <code>ip</code>, but you need to provide an IPv4 or IPv6 address.</li>\n<li><strong>SENTINEL REMOVE <code>&lt;name&gt;</code></strong> is used in order to remove the specified primary: the primary will no longer be monitored, and will totally be removed from the internal state of the Sentinel, so it will no longer listed by <code>SENTINEL masters</code> and so forth.</li>\n<li><strong>SENTINEL SET <code>&lt;name&gt;</code> [<code>&lt;option&gt;</code> <code>&lt;value&gt;</code> ...]</strong> The SET command is very similar to the <code>CONFIG SET</code> command of Valkey, and is used in order to change configuration parameters of a specific primary. Multiple option / value pairs can be specified (or none at all). All the configuration parameters that can be configured via <code>sentinel.conf</code> are also configurable using the SET command.</li>\n</ul>\n<p>The following is an example of <code>SENTINEL SET</code> command in order to modify the <code>down-after-milliseconds</code> configuration of a primary called <code>objects-cache</code>:</p>\n<pre><code>SENTINEL SET objects-cache-master down-after-milliseconds 1000\n</code></pre>\n<p>As already stated, <code>SENTINEL SET</code> can be used to set all the configuration parameters that are settable in the startup configuration file. Moreover it is possible to change just the primary quorum configuration without removing and re-adding the primary with <code>SENTINEL REMOVE</code> followed by <code>SENTINEL MONITOR</code>, but simply using:</p>\n<pre><code>SENTINEL SET objects-cache-master quorum 5\n</code></pre>\n<p>Note that there is no equivalent GET command since <code>SENTINEL MASTER</code> provides all the configuration parameters in a simple to parse format (as a field/value pairs array).</p>\n<p>Sentinel also allows getting and setting global configuration parameters which were only supported in the configuration file prior to that.</p>\n<ul>\n<li><strong>SENTINEL CONFIG GET <code>&lt;name&gt;</code></strong> Get the current value of a global Sentinel configuration parameter. The specified name may be a wildcard, similar to the Valkey <code>CONFIG GET</code> command.</li>\n<li><strong>SENTINEL CONFIG SET <code>&lt;name&gt;</code> <code>&lt;value&gt;</code></strong> Set the value of a global Sentinel configuration parameter.</li>\n</ul>\n<p>Global parameters that can be manipulated include:</p>\n<ul>\n<li><code>resolve-hostnames</code>, <code>announce-hostnames</code>. See <a href=\"#ip-addresses-and-dns-names\"><em>IP addresses and DNS names</em></a>.</li>\n<li><code>announce-ip</code>, <code>announce-port</code>. See <a href=\"#sentinel-docker-nat-and-possible-issues\"><em>Sentinel, Docker, NAT, and possible issues</em></a>.</li>\n<li><code>sentinel-user</code>, <code>sentinel-pass</code>. See <a href=\"#configuring-sentinel-instances-with-authentication\"><em>Configuring Sentinel instances with authentication</em></a>.</li>\n</ul>\n<h3>Adding or removing Sentinels</h3>\n<p>Adding a new Sentinel to your deployment is a simple process because of the<br>auto-discover mechanism implemented by Sentinel. All you need to do is to<br>start the new Sentinel configured to monitor the currently active primary.<br>Within 10 seconds the Sentinel will acquire the list of other Sentinels and<br>the set of replicas attached to the primary.</p>\n<p>If you need to add multiple Sentinels at once, it is suggested to add it<br>one after the other, waiting for all the other Sentinels to already know<br>about the first one before adding the next. This is useful in order to still<br>guarantee that majority can be achieved only in one side of a partition,<br>in the chance failures should happen in the process of adding new Sentinels.</p>\n<p>This can be easily achieved by adding every new Sentinel with a 30 seconds delay, and during absence of network partitions.</p>\n<p>At the end of the process it is possible to use the command<br><code>SENTINEL MASTER &lt;primary name&gt;</code> in order to check if all the Sentinels agree about<br>the total number of Sentinels monitoring the primary.</p>\n<p>Removing a Sentinel is a bit more complex: <strong>Sentinels never forget already seen<br>Sentinels</strong>, even if they are not reachable for a long time, since we don&#39;t<br>want to dynamically change the majority needed to authorize a failover and<br>the creation of a new configuration number. So in order to remove a Sentinel<br>the following steps should be performed in absence of network partitions:</p>\n<ol>\n<li>Stop the Sentinel process of the Sentinel you want to remove.</li>\n<li>Send a <code>SENTINEL RESET *</code> command to all the other Sentinel instances (instead of <code>*</code> you can use the exact primary name if you want to reset just a single primary). One after the other, waiting at least 30 seconds between instances.</li>\n<li>Check that all the Sentinels agree about the number of Sentinels currently active, by inspecting the output of <code>SENTINEL MASTER &lt;primary name&gt;</code> of every Sentinel.</li>\n</ol>\n<h3>Removing the old primary or unreachable replicas</h3>\n<p>Sentinels never forget about replicas of a given primary, even when they are<br>unreachable for a long time. This is useful, because Sentinels should be able<br>to correctly reconfigure a returning replica after a network partition or a<br>failure event.</p>\n<p>Moreover, after a failover, the failed over primary is virtually added as a<br>replica of the new primary, this way it will be reconfigured to replicate with<br>the new primary as soon as it will be available again.</p>\n<p>However sometimes you want to remove a replica (that may be the old primary)<br>forever from the list of replicas monitored by Sentinels.</p>\n<p>In order to do this, you need to send a <code>SENTINEL RESET &lt;primary name&gt;</code> command<br>to all the Sentinels: they&#39;ll refresh the list of replicas within the next<br>10 seconds, only adding the ones listed as correctly replicating from the<br>current primary <code>INFO</code> output.</p>\n<h3>Pubsub messages</h3>\n<p>A client can use a Sentinel as a Valkey-compatible Pub/Sub server<br>(but you can&#39;t use <code>PUBLISH</code>) in order to <code>SUBSCRIBE</code> or <code>PSUBSCRIBE</code> to<br>channels and get notified about specific events.</p>\n<p>The channel name is the same as the name of the event. For instance the<br>channel named <code>+sdown</code> will receive all the notifications related to instances<br>entering an <code>SDOWN</code> (SDOWN means the instance is no longer reachable from<br>the point of view of the Sentinel you are querying) condition.</p>\n<p>To get all the messages simply subscribe using <code>PSUBSCRIBE *</code>.</p>\n<p>The following is a list of channels and message formats you can receive using<br>this API. The first word is the channel / event name, the rest is the format of the data.</p>\n<p>Note: where <em>instance details</em> is specified it means that the following arguments are provided to identify the target instance:</p>\n<pre><code>&lt;instance-type&gt; &lt;name&gt; &lt;ip&gt; &lt;port&gt; @ &lt;primary-name&gt; &lt;primary-ip&gt; &lt;primary-port&gt;\n</code></pre>\n<p>The part identifying the primary (from the @ argument to the end) is optional<br>and is only specified if the instance is not a primary itself.</p>\n<ul>\n<li><strong>+reset-master</strong> <code>&lt;instance details&gt;</code> -- The primary was reset.</li>\n<li><strong>+slave</strong> <code>&lt;instance details&gt;</code> -- A new replica was detected and attached.</li>\n<li><strong>+failover-state-reconf-slaves</strong> <code>&lt;instance details&gt;</code> -- Failover state changed to <code>reconf-slaves</code> state.</li>\n<li><strong>+failover-detected</strong> <code>&lt;instance details&gt;</code> -- A failover started by another Sentinel or any other external entity was detected (An attached replica turned into a primary).</li>\n<li><strong>+slave-reconf-sent</strong> <code>&lt;instance details&gt;</code> -- The leader sentinel sent the <code>REPLICAOF</code> command to this instance in order to reconfigure it for the new replica.</li>\n<li><strong>+slave-reconf-inprog</strong> <code>&lt;instance details&gt;</code> -- The replica being reconfigured showed to be a replica of the new primary ip:port pair, but the synchronization process is not yet complete.</li>\n<li><strong>+slave-reconf-done</strong> <code>&lt;instance details&gt;</code> -- The replica is now synchronized with the new primary.</li>\n<li><strong>-dup-sentinel</strong> <code>&lt;instance details&gt;</code> -- One or more sentinels for the specified primary were removed as duplicated (this happens for instance when a Sentinel instance is restarted).</li>\n<li><strong>+sentinel</strong> <code>&lt;instance details&gt;</code> -- A new sentinel for this primary was detected and attached.</li>\n<li><strong>+sdown</strong> <code>&lt;instance details&gt;</code> -- The specified instance is now in Subjectively Down state.</li>\n<li><strong>-sdown</strong> <code>&lt;instance details&gt;</code> -- The specified instance is no longer in Subjectively Down state.</li>\n<li><strong>+odown</strong> <code>&lt;instance details&gt;</code> -- The specified instance is now in Objectively Down state.</li>\n<li><strong>-odown</strong> <code>&lt;instance details&gt;</code> -- The specified instance is no longer in Objectively Down state.</li>\n<li><strong>+new-epoch</strong> <code>&lt;instance details&gt;</code> -- The current epoch was updated.</li>\n<li><strong>+try-failover</strong> <code>&lt;instance details&gt;</code> -- New failover in progress, waiting to be elected by the majority.</li>\n<li><strong>+elected-leader</strong> <code>&lt;instance details&gt;</code> -- Won the election for the specified epoch, can do the failover.</li>\n<li><strong>+failover-state-select-slave</strong> <code>&lt;instance details&gt;</code> -- New failover state is <code>select-slave</code>: we are trying to find a suitable replica for promotion.</li>\n<li><strong>no-good-slave</strong> <code>&lt;instance details&gt;</code> -- There is no good replica to promote. Currently we&#39;ll try after some time, but probably this will change and the state machine will abort the failover at all in this case.</li>\n<li><strong>selected-slave</strong> <code>&lt;instance details&gt;</code> -- We found the specified good replica to promote.</li>\n<li><strong>failover-state-send-slaveof-noone</strong> <code>&lt;instance details&gt;</code> -- We are trying to reconfigure the promoted replica as primary, waiting for it to switch.</li>\n<li><strong>failover-end-for-timeout</strong> <code>&lt;instance details&gt;</code> -- The failover terminated for timeout, replicas will eventually be configured to replicate with the new primary anyway.</li>\n<li><strong>failover-end</strong> <code>&lt;instance details&gt;</code> -- The failover terminated with success. All the replicas appear to be reconfigured to replicate with the new primary.</li>\n<li><strong>switch-master</strong> <code>&lt;primary name&gt; &lt;oldip&gt; &lt;oldport&gt; &lt;newip&gt; &lt;newport&gt;</code> -- The primary new IP and address is the specified one after a configuration change. This is <strong>the message most external users are interested in</strong>.</li>\n<li><strong>+tilt</strong> -- Tilt mode entered.</li>\n<li><strong>-tilt</strong> -- Tilt mode exited.</li>\n</ul>\n<h3>Handling of -BUSY state</h3>\n<p>The -BUSY error is returned by a Valkey instance when a Lua script is running for<br>more time than the configured Lua script time limit. When this happens before<br>triggering a fail over Valkey Sentinel will try to send a <code>SCRIPT KILL</code><br>command, that will only succeed if the script was read-only.</p>\n<p>If the instance is still in an error condition after this try, it will<br>eventually be failed over.</p>\n<h2>Replicas priority</h2>\n<p>Valkey instances have a configuration parameter called <code>replica-priority</code>.<br>This information is exposed by Valkey replica instances in their <code>INFO</code> output,<br>and Sentinel uses it in order to pick a replica among the ones that can be<br>used in order to failover a primary:</p>\n<ol>\n<li>If the replica priority is set to 0, the replica is never promoted to primary.</li>\n<li>Replicas with a <em>lower</em> priority number are preferred by Sentinel.</li>\n</ol>\n<p>For example if there is a replica S1 in the same data center of the current<br>primary, and another replica S2 in another data center, it is possible to set<br>S1 with a priority of 10 and S2 with a priority of 100, so that if the primary<br>fails and both S1 and S2 are available, S1 will be preferred.</p>\n<p>For more information about the way replicas are selected, please check the <a href=\"#replica-selection-and-priority\"><em>Replica selection and priority</em> section</a> of this documentation.</p>\n<h3>Sentinel and Valkey authentication</h3>\n<p>When the primary is configured to require authentication from clients,<br>as a security measure, replicas need to also be aware of the credentials in<br>order to authenticate with the primary and create the primary-replica connection<br>used for the asynchronous replication protocol.</p>\n<h2>Valkey Access Control List authentication</h2>\n<p>User authentication and permission is managed with the <a href=\"acl\">Access Control List (ACL)</a>.</p>\n<p>In order for Sentinels to connect to Valkey server instances when they are<br>configured with ACL, the Sentinel configuration must include the<br>following directives:</p>\n<pre><code>sentinel auth-user &lt;primary-name&gt; &lt;username&gt;\nsentinel auth-pass &lt;primary-name&gt; &lt;password&gt;\n</code></pre>\n<p>Where <code>&lt;username&gt;</code> and <code>&lt;password&gt;</code> are the username and password for accessing the group&#39;s instances. These credentials should be provisioned on all of the group&#39;s Valkey instances with the minimal control permissions. For example:</p>\n<pre><code>127.0.0.1:6379&gt; ACL SETUSER sentinel-user ON &gt;somepassword allchannels +multi +slaveaof +ping +exec +subscribe +config|rewrite +role +publish +info +client|setname +client|kill +script|kill\n</code></pre>\n<h3>Valkey password-only authentication</h3>\n<p>Before ACL was introduced, authentication could be achieved using the following configuration directives:</p>\n<ul>\n<li><code>requirepass</code> in the primary, in order to set the authentication password, and to make sure the instance will not process requests for non authenticated clients.</li>\n<li><code>masterauth</code> in the replicas in order for the replicas to authenticate with the primary in order to correctly replicate data from it.</li>\n</ul>\n<p>When Sentinel is used, there is not a single primary, since after a failover<br>replicas may play the role of primaries, and old primaries can be reconfigured in<br>order to act as replicas, so what you want to do is to set the above directives<br>in all your instances, both primaries and replicas.</p>\n<p>This is also usually a sane setup since you don&#39;t want to protect<br>data only in the primary, having the same data accessible in the replicas.</p>\n<p>However, in the uncommon case where you need a replica that is accessible<br>without authentication, you can still do it by setting up <strong>a replica priority<br>of zero</strong>, to prevent this replica from being promoted to primary, and<br>configuring in this replica only the <code>masterauth</code> directive, without<br>using the <code>requirepass</code> directive, so that data will be readable by<br>unauthenticated clients.</p>\n<p>In order for Sentinels to connect to Valkey server instances when they are<br>configured with <code>requirepass</code>, the Sentinel configuration must include the<br><code>sentinel auth-pass</code> directive, in the format:</p>\n<pre><code>sentinel auth-pass &lt;primary-name&gt; &lt;password&gt;\n</code></pre>\n<h2>Configuring Sentinel instances with authentication</h2>\n<p>Sentinel instances themselves can be secured by requiring clients to authenticate via the <code>AUTH</code> command. Starting with Redis OSS 6.2, the <a href=\"acl\">Access Control List (ACL)</a> is available, whereas older versions support password-only authentication.</p>\n<p>Note that Sentinel&#39;s authentication configuration should be <strong>applied to each of the instances</strong> in your deployment, and <strong>all instances should use the same configuration</strong>. Furthermore, ACL and password-only authentication should not be used together.</p>\n<h3>Sentinel Access Control List authentication</h3>\n<p>The first step in securing a Sentinel instance with ACL is preventing any unauthorized access to it. To do that, you&#39;ll need to disable the default superuser (or at the very least set it up with a strong password) and create a new one and allow it access to Pub/Sub channels:</p>\n<pre><code>127.0.0.1:5000&gt; ACL SETUSER admin ON &gt;admin-password allchannels +@all\nOK\n127.0.0.1:5000&gt; ACL SETUSER default off\nOK\n</code></pre>\n<p>The default user is used by Sentinel to connect to other instances. You can provide the credentials of another superuser with the following configuration directives:</p>\n<pre><code>sentinel sentinel-user &lt;username&gt;\nsentinel sentinel-pass &lt;password&gt;\n</code></pre>\n<p>Where <code>&lt;username&gt;</code> and <code>&lt;password&gt;</code> are the Sentinel&#39;s superuser and password, respectively (e.g. <code>admin</code> and <code>admin-password</code> in the example above).</p>\n<p>Lastly, for authenticating incoming client connections, you can create a Sentinel restricted user profile such as the following:</p>\n<pre><code>127.0.0.1:5000&gt; ACL SETUSER sentinel-user ON &gt;user-password -@all +auth +client|getname +client|id +client|setname +command +hello +ping +role +sentinel|get-master-addr-by-name +sentinel|master +sentinel|myid +sentinel|replicas +sentinel|sentinels\n</code></pre>\n<p>Refer to the documentation of your Sentinel client of choice for further information.</p>\n<h3>Sentinel password-only authentication</h3>\n<p>To use Sentinel with password-only authentication, add the <code>requirepass</code> configuration directive to <strong>all</strong> your Sentinel instances as follows:</p>\n<pre><code>requirepass &quot;your_password_here&quot;\n</code></pre>\n<p>When configured this way, Sentinels will do two things:</p>\n<ol>\n<li>A password will be required from clients in order to send commands to Sentinels. This is obvious since this is how such configuration directive works in Valkey in general.</li>\n<li>Moreover the same password configured to access the local Sentinel, will be used by this Sentinel instance in order to authenticate to all the other Sentinel instances it connects to.</li>\n</ol>\n<p>This means that <strong>you will have to configure the same <code>requirepass</code> password in all the Sentinel instances</strong>. This way every Sentinel can talk with every other Sentinel without any need to configure for each Sentinel the password to access all the other Sentinels, that would be very impractical.</p>\n<p>Before using this configuration, make sure your client library can send the <code>AUTH</code> command to Sentinel instances.</p>\n<h3>Sentinel clients implementation</h3>\n<hr>\n<p>Sentinel requires explicit client support, unless the system is configured to execute a script that performs a transparent redirection of all the requests to the new primary instance (virtual IP or other similar systems). The topic of client libraries implementation is covered in the document <a href=\"sentinel-clients\">Sentinel clients guidelines</a>.</p>\n<h2>More advanced concepts</h2>\n<p>In the following sections we&#39;ll cover a few details about how Sentinel works,<br>without resorting to implementation details and algorithms that will be<br>covered in the final part of this document.</p>\n<h3>SDOWN and ODOWN failure state</h3>\n<p>Valkey Sentinel has two different concepts of <em>being down</em>, one is called<br>a <em>Subjectively Down</em> condition (SDOWN) and is a down condition that is<br>local to a given Sentinel instance. Another is called <em>Objectively Down</em><br>condition (ODOWN) and is reached when enough Sentinels (at least the<br>number configured as the <code>quorum</code> parameter of the monitored primary) have<br>an SDOWN condition, and get feedback from other Sentinels using<br>the <code>SENTINEL is-master-down-by-addr</code> command.</p>\n<p>From the point of view of a Sentinel an SDOWN condition is reached when it<br>does not receive a valid reply to PING requests for the number of seconds<br>specified in the configuration as <code>is-master-down-after-milliseconds</code><br>parameter.</p>\n<p>An acceptable reply to PING is one of the following:</p>\n<ul>\n<li>PING replied with +PONG.</li>\n<li>PING replied with -LOADING error.</li>\n<li>PING replied with -MASTERDOWN error.</li>\n</ul>\n<p>Any other reply (or no reply at all) is considered non valid.<br>However note that <strong>a logical primary that advertises itself as a replica in<br>the INFO output is considered to be down</strong>.</p>\n<p>Note that SDOWN requires that no acceptable reply is received for the whole<br>interval configured, so for instance if the interval is 30000 milliseconds<br>(30 seconds) and we receive an acceptable ping reply every 29 seconds, the<br>instance is considered to be working.</p>\n<p>SDOWN is not enough to trigger a failover: it only means a single Sentinel<br>believes a Valkey instance is not available. To trigger a failover, the<br>ODOWN state must be reached.</p>\n<p>To switch from SDOWN to ODOWN no strong consensus algorithm is used, but<br>just a form of gossip: if a given Sentinel gets reports that a primary<br>is not working from enough Sentinels <strong>in a given time range</strong>, the SDOWN is<br>promoted to ODOWN. If this acknowledge is later missing, the flag is cleared.</p>\n<p>A more strict authorization that uses an actual majority is required in<br>order to really start the failover, but no failover can be triggered without<br>reaching the ODOWN state.</p>\n<p>The ODOWN condition <strong>only applies to primaries</strong>. For other kind of instances<br>Sentinel doesn&#39;t require to act, so the ODOWN state is never reached for replicas<br>and other sentinels, but only SDOWN is.</p>\n<p>However SDOWN has also semantic implications. For example a replica in SDOWN<br>state is not selected to be promoted by a Sentinel performing a failover.</p>\n<h2>Sentinels and replicas auto discovery</h2>\n<p>Sentinels stay connected with other Sentinels in order to reciprocally<br>check the availability of each other, and to exchange messages. However you<br>don&#39;t need to configure a list of other Sentinel addresses in every Sentinel<br>instance you run, as Sentinel uses the Valkey instances Pub/Sub capabilities<br>in order to discover the other Sentinels that are monitoring the same primaries<br>and replicas.</p>\n<p>This feature is implemented by sending <em>hello messages</em> into the channel named<br><code>__sentinel__:hello</code>.</p>\n<p>Similarly you don&#39;t need to configure what is the list of the replicas attached<br>to a primary, as Sentinel will auto discover this list querying Valkey.</p>\n<ul>\n<li>Every Sentinel publishes a message to every monitored primary and replica Pub/Sub channel <code>__sentinel__:hello</code>, every two seconds, announcing its presence with ip, port, runid.</li>\n<li>Every Sentinel is subscribed to the Pub/Sub channel <code>__sentinel__:hello</code> of every primary and replica, looking for unknown sentinels. When new sentinels are detected, they are added as sentinels of this primary.</li>\n<li>Hello messages also include the full current configuration of the primary. If the receiving Sentinel has a configuration for a given primary which is older than the one received, it updates to the new configuration immediately.</li>\n<li>Before adding a new sentinel to a primary a Sentinel always checks if there is already a sentinel with the same runid or the same address (ip and port pair). In that case all the matching sentinels are removed, and the new added.</li>\n</ul>\n<h2>Sentinel reconfiguration of instances outside the failover procedure</h2>\n<p>Even when no failover is in progress, Sentinels will always try to set the<br>current configuration on monitored instances. Specifically:</p>\n<ul>\n<li>Replicas (according to the current configuration) that claim to be primaries, will be configured as replicas to replicate with the current primary.</li>\n<li>Replicas connected to a wrong primary, will be reconfigured to replicate with the right primary.</li>\n</ul>\n<p>For Sentinels to reconfigure replicas, the wrong configuration must be observed for some time, that is greater than the period used to broadcast new configurations.</p>\n<p>This prevents Sentinels with a stale configuration (for example because they just rejoined from a partition) will try to change the replicas configuration before receiving an update.</p>\n<p>Also note how the semantics of always trying to impose the current configuration makes the failover more resistant to partitions:</p>\n<ul>\n<li>Masters failed over are reconfigured as replicas when they return available.</li>\n<li>Replicas partitioned away during a partition are reconfigured once reachable.</li>\n</ul>\n<p>The important lesson to remember about this section is: <strong>Sentinel is a system where each process will always try to impose the last logical configuration to the set of monitored instances</strong>.</p>\n<h3>Replica selection and priority</h3>\n<p>When a Sentinel instance is ready to perform a failover, since the primary<br>is in <code>ODOWN</code> state and the Sentinel received the authorization to failover<br>from the majority of the Sentinel instances known, a suitable replica needs<br>to be selected.</p>\n<p>The replica selection process evaluates the following information about replicas:</p>\n<ol>\n<li>Disconnection time from the primary.</li>\n<li>Replica priority.</li>\n<li>Replication offset processed.</li>\n<li>Run ID.</li>\n</ol>\n<p>A replica that is found to be disconnected from the primary for more than ten<br>times the configured primary timeout (down-after-milliseconds option), plus<br>the time the primary is also not available from the point of view of the<br>Sentinel doing the failover, is considered to be not suitable for the failover<br>and is skipped.</p>\n<p>In more rigorous terms, a replica whose the <code>INFO</code> output suggests it has been<br>disconnected from the primary for more than:</p>\n<pre><code>(down-after-milliseconds * 10) + milliseconds_since_master_is_in_SDOWN_state\n</code></pre>\n<p>Is considered to be unreliable and is disregarded entirely.</p>\n<p>The replica selection only considers the replicas that passed the above test,<br>and sorts it based on the above criteria, in the following order.</p>\n<ol>\n<li>The replicas are sorted by <code>replica-priority</code> as configured in the <code>valkey.conf</code> file of the Valkey instance. A lower priority will be preferred.</li>\n<li>If the priority is the same, the replication offset processed by the replica is checked, and the replica that received more data from the primary is selected.</li>\n<li>If multiple replicas have the same priority and processed the same data from the primary, a further check is performed, selecting the replica with the lexicographically smaller run ID. Having a lower run ID is not a real advantage for a replica, but is useful in order to make the process of replica selection more deterministic, instead of resorting to select a random replica.</li>\n</ol>\n<p>In most cases, <code>replica-priority</code> does not need to be set explicitly so all<br>instances will use the same default value. If there is a particular fail-over<br>preference, <code>replica-priority</code> must be set on all instances, including primaries,<br>as a primary may become a replica at some future point in time - and it will then<br>need the proper <code>replica-priority</code> settings.</p>\n<p>A Valkey instance can be configured with a special <code>replica-priority</code> of zero<br>in order to be <strong>never selected</strong> by Sentinels as the new primary.<br>However a replica configured in this way will still be reconfigured by<br>Sentinels in order to replicate with the new primary after a failover, the<br>only difference is that it will never become a primary itself.</p>\n<h2>Algorithms and internals</h2>\n<p>In the following sections we will explore the details of Sentinel behavior.<br>It is not strictly needed for users to be aware of all the details, but a<br>deep understanding of Sentinel may help to deploy and operate Sentinel in<br>a more effective way.</p>\n<h3>Quorum</h3>\n<p>The previous sections showed that every primary monitored by Sentinel is associated to a configured <strong>quorum</strong>. It specifies the number of Sentinel processes<br>that need to agree about the unreachability or error condition of the primary in<br>order to trigger a failover.</p>\n<p>However, after the failover is triggered, in order for the failover to actually be performed, <strong>at least a majority of Sentinels must authorize the Sentinel to<br>failover</strong>. Sentinel never performs a failover in the partition where a<br>minority of Sentinels exist.</p>\n<p>Let&#39;s try to make things a bit more clear:</p>\n<ul>\n<li>Quorum: the number of Sentinel processes that need to detect an error condition in order for a primary to be flagged as <strong>ODOWN</strong>.</li>\n<li>The failover is triggered by the <strong>ODOWN</strong> state.</li>\n<li>Once the failover is triggered, the Sentinel trying to failover is required to ask for authorization to a majority of Sentinels (or more than the majority if the quorum is set to a number greater than the majority).</li>\n</ul>\n<p>The difference may seem subtle but is actually quite simple to understand and use.  For example if you have 5 Sentinel instances, and the quorum is set to 2, a failover will be triggered as soon as 2 Sentinels believe that the primary is not reachable, however one of the two Sentinels will be able to failover only if it gets authorization at least from 3 Sentinels.</p>\n<p>If instead the quorum is configured to 5, all the Sentinels must agree about the primary error condition, and the authorization from all Sentinels is required in order to failover.</p>\n<p>This means that the quorum can be used to tune Sentinel in two ways:</p>\n<ol>\n<li>If a quorum is set to a value smaller than the majority of Sentinels we deploy, we are basically making Sentinel more sensitive to primary failures, triggering a failover as soon as even just a minority of Sentinels is no longer able to talk with the primary.</li>\n<li>If a quorum is set to a value greater than the majority of Sentinels, we are making Sentinel able to failover only when there are a very large number (larger than majority) of well connected Sentinels which agree about the primary being down.</li>\n</ol>\n<h3>Configuration epochs</h3>\n<p>Sentinels require to get authorizations from a majority in order to start a<br>failover for a few important reasons:</p>\n<p>When a Sentinel is authorized, it gets a unique <strong>configuration epoch</strong> for the primary it is failing over. This is a number that will be used to version the new configuration after the failover is completed. Because a majority agreed that a given version was assigned to a given Sentinel, no other Sentinel will be able to use it. This means that every configuration of every failover is versioned with a unique version. We&#39;ll see why this is so important.</p>\n<p>Moreover Sentinels have a rule: if a Sentinel voted another Sentinel for the failover of a given primary, it will wait some time to try to failover the same primary again. This delay is the <code>2 * failover-timeout</code> you can configure in <code>sentinel.conf</code>. This means that Sentinels will not try to failover the same primary at the same time, the first to ask to be authorized will try, if it fails another will try after some time, and so forth.</p>\n<p>Valkey Sentinel guarantees the <em>liveness</em> property that if a majority of Sentinels are able to talk, eventually one will be authorized to failover if the primary is down.</p>\n<p>Valkey Sentinel also guarantees the <em>safety</em> property that every Sentinel will failover the same primary using a different <em>configuration epoch</em>.</p>\n<h3>Configuration propagation</h3>\n<p>Once a Sentinel is able to failover a primary successfully, it will start to broadcast the new configuration so that the other Sentinels will update their information about a given primary.</p>\n<p>For a failover to be considered successful, it requires that the Sentinel was able to send the <code>REPLICAOF NO ONE</code> command to the selected replica, and that the switch to primary was later observed in the <code>INFO</code> output of the primary.</p>\n<p>At this point, even if the reconfiguration of the replicas is in progress, the failover is considered to be successful, and all the Sentinels are required to start reporting the new configuration.</p>\n<p>The way a new configuration is propagated is the reason why we need that every<br>Sentinel failover is authorized with a different version number (configuration epoch).</p>\n<p>Every Sentinel continuously broadcast its version of the configuration of a primary using Valkey Pub/Sub messages, both in the primary and all the replicas.  At the same time all the Sentinels wait for messages to see what is the configuration<br>advertised by the other Sentinels.</p>\n<p>Configurations are broadcast in the <code>__sentinel__:hello</code> Pub/Sub channel.</p>\n<p>Because every configuration has a different version number, the greater version<br>always wins over smaller versions.</p>\n<p>So for example the configuration for the primary <code>mymaster</code> start with all the<br>Sentinels believing the primary is at 192.168.1.50:6379. This configuration<br>has version 1. After some time a Sentinel is authorized to failover with version 2. If the failover is successful, it will start to broadcast a new configuration, let&#39;s say 192.168.1.50:9000, with version 2. All the other instances will see this configuration and will update their configuration accordingly, since the new configuration has a greater version.</p>\n<p>This means that Sentinel guarantees a second liveness property: a set of<br>Sentinels that are able to communicate will all converge to the same configuration with the higher version number.</p>\n<p>Basically if the net is partitioned, every partition will converge to the higher<br>local configuration. In the special case of no partitions, there is a single<br>partition and every Sentinel will agree about the configuration.</p>\n<h3>Consistency under partitions</h3>\n<p>Valkey Sentinel configurations are eventually consistent, so every partition will<br>converge to the higher configuration available.<br>However in a real-world system using Sentinel there are three different players:</p>\n<ul>\n<li>Valkey instances.</li>\n<li>Sentinel instances.</li>\n<li>Clients.</li>\n</ul>\n<p>In order to define the behavior of the system we have to consider all three.</p>\n<p>The following is a simple network where there are 3 nodes, each running<br>a Valkey instance, and a Sentinel instance:</p>\n<pre><code>            +--------------+\n            | Sentinel 1   |----- Client A\n            | Valkey 1 (M) |\n            +--------------+\n                    |\n                    |\n+--------------+    |          +-------------+\n| Sentinel 2   |----+-- // ----| Sentinel 3  |----- Client B\n| Valkey 2 (S) |               | Valkey 3 (M)|\n+--------------+               +-------------+\n</code></pre>\n<p>In this system the original state was that Valkey 3 was the primary, while<br>Valkey 1 and 2 were replicas. A partition occurred isolating the old primary.<br>Sentinels 1 and 2 started a failover promoting Sentinel 1 as the new primary.</p>\n<p>The Sentinel properties guarantee that Sentinel 1 and 2 now have the new<br>configuration for the primary. However Sentinel 3 has still the old configuration<br>since it lives in a different partition.</p>\n<p>We know that Sentinel 3 will get its configuration updated when the network<br>partition will heal, however what happens during the partition if there<br>are clients partitioned with the old primary?</p>\n<p>Clients will be still able to write to Valkey 3, the old primary. When the<br>partition will rejoin, Valkey 3 will be turned into a replica of Valkey 1, and<br>all the data written during the partition will be lost.</p>\n<p>Depending on your configuration you may want or not that this scenario happens:</p>\n<ul>\n<li>If you are using Valkey as a cache, it could be handy that Client B is still able to write to the old primary, even if its data will be lost.</li>\n<li>If you are using Valkey as a store, this is not good and you need to configure the system in order to partially prevent this problem.</li>\n</ul>\n<p>Since Valkey is asynchronously replicated, there is no way to totally prevent data loss in this scenario, however you can bound the divergence between Valkey 3 and Valkey 1<br>using the following Valkey configuration option:</p>\n<pre><code>min-replicas-to-write 1\nmin-replicas-max-lag 10\n</code></pre>\n<p>With the above configuration (please see the self-commented <code>valkey.conf</code> example in the Valkey distribution for more information) a Valkey instance, when acting as a primary, will stop accepting writes if it can&#39;t write to at least 1 replica. Since replication is asynchronous <em>not being able to write</em> actually means that the replica is either disconnected, or is not sending us asynchronous acknowledges for more than the specified <code>max-lag</code> number of seconds.</p>\n<p>Using this configuration the Valkey 3 in the above example will become unavailable after 10 seconds. When the partition heals, the Sentinel 3 configuration will converge to<br>the new one, and Client B will be able to fetch a valid configuration and continue.</p>\n<p>In general Valkey + Sentinel as a whole are an <strong>eventually consistent system</strong> where the merge function is <strong>last failover wins</strong>, and the data from old primaries are discarded to replicate the data of the current primary, so there is always a window for losing acknowledged writes. This is due to Valkey asynchronous<br>replication and the discarding nature of the &quot;virtual&quot; merge function of the system. Note that this is not a limitation of Sentinel itself, and if you orchestrate the failover with a strongly consistent replicated state machine, the same properties will still apply. There are only two ways to avoid losing acknowledged writes:</p>\n<ol>\n<li>Use synchronous replication (and a proper consensus algorithm to run a replicated state machine).</li>\n<li>Use an eventually consistent system where different versions of the same object can be merged.</li>\n</ol>\n<p>Valkey (like it&#39;s predecessor Redis OSS) is currently not able to use any of the above systems, and using them is currently outside the development goals. However, there are proxies implementing solution &quot;2&quot; on top of Redis OSS stores such as SoundCloud <a href=\"https://github.com/soundcloud/roshi\">Roshi</a>, or Netflix <a href=\"https://github.com/Netflix/dynomite\">Dynomite</a>.</p>\n<h2>Sentinel persistent state</h2>\n<p>Sentinel state is persisted in the sentinel configuration file. For example<br>every time a new configuration is received, or created (leader Sentinels), for<br>a primary, the configuration is persisted on disk together with the configuration<br>epoch. This means that it is safe to stop and restart Sentinel processes.</p>\n<h3>TILT mode</h3>\n<p>Valkey Sentinel is heavily dependent on the computer time: for instance in<br>order to understand if an instance is available it remembers the time of the<br>latest successful reply to the PING command, and compares it with the current<br>time to understand how old it is.</p>\n<p>However if the computer time changes in an unexpected way, or if the computer<br>is very busy, or the process blocked for some reason, Sentinel may start to<br>behave in an unexpected way.</p>\n<p>The TILT mode is a special &quot;protection&quot; mode that a Sentinel can enter when<br>something odd is detected that can lower the reliability of the system.<br>The Sentinel timer interrupt is normally called 10 times per second, so we<br>expect that more or less 100 milliseconds will elapse between two calls<br>to the timer interrupt.</p>\n<p>What a Sentinel does is to register the previous time the timer interrupt<br>was called, and compare it with the current call: if the time difference<br>is negative or unexpectedly big (2 seconds or more) the TILT mode is entered<br>(or if it was already entered the exit from the TILT mode postponed).</p>\n<p>When in TILT mode the Sentinel will continue to monitor everything, but:</p>\n<ul>\n<li>It stops acting at all.</li>\n<li>It starts to reply negatively to <code>SENTINEL is-master-down-by-addr</code> requests as the ability to detect a failure is no longer trusted.</li>\n</ul>\n<p>If everything appears to be normal for 30 seconds, the TILT mode is exited.</p>\n<p>In the Sentinel TILT mode, if we send the INFO command, we could get the following response:</p>\n<pre><code>$ valkey-cli -p 26379\n127.0.0.1:26379&gt; info\n(Other information from Sentinel server skipped.)\n\n# Sentinel\nsentinel_masters:1\nsentinel_tilt:0\nsentinel_tilt_since_seconds:-1\nsentinel_running_scripts:0\nsentinel_scripts_queue_length:0\nsentinel_simulate_failure_flags:0\nmaster0:name=mymaster,status=ok,address=127.0.0.1:6379,slaves=0,sentinels=1\n</code></pre>\n<p>The field &quot;sentinel_tilt_since_seconds&quot; indicates how many seconds the Sentinel already is in the TILT mode.<br>If it is not in TILT mode, the value will be -1.</p>\n<p>Note that in some ways TILT mode could be replaced using the monotonic clock<br>API that many kernels offer. However it is not still clear if this is a good<br>solution since the current system avoids issues in case the process is just<br>suspended or not executed by the scheduler for a long time.</p>\n<p><strong>A note about the words &quot;master&quot; and &quot;slave&quot; used in this man page</strong>: If not for backward compatibility, the Valkey project no longer uses the words &quot;master&quot; and &quot;slave&quot;. Unfortunately in this command these words are part of the protocol, so we&#39;ll be able to remove such occurrences only when this API will be naturally deprecated.</p>\n"
      }
    ]
  },
  {
    "title": "ADMINISTRATION",
    "items": [
      {
        "id": "admin",
        "topicName": "Administration",
        "description": "Advice for configuring and managing Valkey in production",
        "htmlContent": "<h2>Valkey setup tips</h2>\n<h3>Linux</h3>\n<ul>\n<li><p>Deploy Valkey using the Linux operating system.<br>Valkey is also regularly tested on macOS and FreeBSD, and from time to time on other OpenBSD, NetBSD, DragonFlyBSD and Solaris-derived systems.<br>However, Linux is where most of the stress testing is performed, and where most production deployments are run.</p>\n</li>\n<li><p>Set the Linux kernel overcommit memory setting to 1. Add <code>vm.overcommit_memory = 1</code> to <code>/etc/sysctl.conf</code>. Then, reboot or run the command <code>sysctl vm.overcommit_memory=1</code> to activate the setting. See <a href=\"faq#background-saving-fails-with-a-fork-error-on-linux\">FAQ: Background saving fails with a fork() error on Linux?</a> for details. </p>\n</li>\n<li><p>To ensure the Linux kernel feature Transparent Huge Pages does not impact Valkey memory usage and latency, run the command: <code>echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</code> to disable it. See <a href=\"latency#latency-induced-by-transparent-huge-pages\">Latency Diagnosis - Latency induced by transparent huge pages</a> for additional context.</p>\n</li>\n</ul>\n<h3>Memory</h3>\n<ul>\n<li><p>Ensured that swap is enabled and that your swap file size is equal to amount of memory on your system. If Linux does not have swap set up, and your Valkey instance accidentally consumes too much memory, Valkey can crash when it is out of memory, or the Linux kernel OOM killer can kill the Valkey process. When swapping is enabled, you can detect latency spikes and act on them.</p>\n</li>\n<li><p>Set an explicit <code>maxmemory</code> option limit in your instance to make sure that it will report errors instead of failing when the system memory limit is near to be reached. Note that <code>maxmemory</code> should be set by calculating the overhead for Valkey, other than data, and the fragmentation overhead. So if you think you have 10 GB of free memory, set it to 8 or 9.</p>\n</li>\n<li><p>If you are using Valkey in a write-heavy application, while saving an RDB file on disk or rewriting the AOF log, Valkey can use up to 2 times the memory normally used. The additional memory used is proportional to the number of memory pages modified by writes during the saving process, so it is often proportional to the number of keys (or aggregate types items) touched during this time. Make sure to size your memory accordingly.</p>\n</li>\n<li><p>See the <code>LATENCY DOCTOR</code> and <code>MEMORY DOCTOR</code> commands to assist in troubleshooting.</p>\n</li>\n</ul>\n<h3>Imaging</h3>\n<ul>\n<li>When running under daemontools, use <code>daemonize no</code>.</li>\n</ul>\n<h3>Replication</h3>\n<ul>\n<li><p>Set up a non-trivial replication backlog in proportion to the amount of memory Valkey is using. The backlog allows replicas to sync with the primary instance much more easily.</p>\n</li>\n<li><p>If you use replication, Valkey performs RDB saves even if persistence is disabled. (This does not apply to diskless replication.) If you don&#39;t have disk usage on the primary, enable diskless replication.</p>\n</li>\n<li><p>If you are using replication, ensure that either your primary has persistence enabled, or that it does not automatically restart on crashes. Replicas will try to maintain an exact copy of the primary, so if a primary restarts with an empty data set, replicas will be wiped as well.</p>\n</li>\n</ul>\n<h3>Security</h3>\n<ul>\n<li>By default, Valkey does not require any authentication and listens to all the network interfaces. This is a big security issue if you leave Valkey exposed on the internet or other places where attackers can reach it. Please check our <a href=\"security\">security page</a> and the <a href=\"quickstart\">quick start</a> for information about how to secure Valkey.</li>\n</ul>\n<h2>Running Valkey on EC2</h2>\n<ul>\n<li>Use HVM based instances, not PV based instances.</li>\n<li>The use of Valkey persistence with EC2 EBS volumes needs to be handled with care because sometimes EBS volumes have high latency characteristics.</li>\n<li>You may want to try diskless replication if you have issues when replicas are synchronizing with the primary.</li>\n</ul>\n<h2>Upgrading or restarting a Valkey instance without downtime</h2>\n<p>Valkey is designed to be a long-running process in your server. You can modify many configuration options without a restart using the <code>CONFIG SET</code> command. You can also switch from AOF to RDB snapshots persistence, or the other way around, without restarting Valkey. Check the output of the <code>CONFIG GET *</code> command for more information.</p>\n<p>From time to time, a restart is required, for example, to upgrade the Valkey process to a newer version, or when you need to modify a configuration parameter that is currently not supported by the <code>CONFIG</code> command.</p>\n<p>Follow these steps to avoid downtime.</p>\n<ul>\n<li><p>Set up your new Valkey instance as a replica for your current Valkey instance. In order to do so, you need a different server, or a server that has enough RAM to keep two instances of Valkey running at the same time.</p>\n</li>\n<li><p>If you use a single server, ensure that the replica is started on a different port than the primary instance, otherwise the replica cannot start.</p>\n</li>\n<li><p>Wait for the replication initial synchronization to complete. Check the replica&#39;s log file.</p>\n</li>\n<li><p>Using <code>INFO</code>, ensure the primary and replica have the same number of keys. Use <code>valkey-cli</code> to check that the replica is working as expected and is replying to your commands.</p>\n</li>\n<li><p>Allow writes to the replica using <code>CONFIG SET replica-read-only no</code>.</p>\n</li>\n<li><p>Configure all your clients to use the new instance (the replica). Note that you may want to use the <code>CLIENT PAUSE</code> command to ensure that no client can write to the old primary during the switch.</p>\n</li>\n<li><p>Once you confirm that the primary is no longer receiving any queries (you can check this using the <code>MONITOR</code> command), elect the replica to primary using the <code>REPLICAOF NO ONE</code> command, and then shut down your primary.</p>\n</li>\n</ul>\n<p>If you are using <a href=\"sentinel\">Valkey Sentinel</a> or <a href=\"cluster-tutorial\">Valkey Cluster</a>, the simplest way to upgrade to newer versions is to upgrade one replica after the other. Then you can perform a manual failover to promote one of the upgraded replicas to primary, and finally promote the last replica.</p>\n"
      },
      {
        "id": "encryption",
        "topicName": "TLS",
        "description": "Valkey TLS support",
        "htmlContent": "<p>SSL/TLS is supported by Valkey as an optional feature<br>that needs to be enabled at compile time.</p>\n<h2>Getting Started</h2>\n<h3>Building</h3>\n<p>To build with TLS support you&#39;ll need OpenSSL development libraries (e.g.<br><code>libssl-dev</code> on Debian/Ubuntu).</p>\n<p>Build Valkey with the following command:</p>\n<pre><code class=\"language-sh\">make BUILD_TLS=yes\n</code></pre>\n<h3>Tests</h3>\n<p>To run Valkey test suite with TLS, you&#39;ll need TLS support for TCL (i.e.<br><code>tcl-tls</code> package on Debian/Ubuntu).</p>\n<ol>\n<li><p>Run <code>./utils/gen-test-certs.sh</code> to generate a root CA and a server<br>certificate.</p>\n</li>\n<li><p>Run <code>./runtest --tls</code> or <code>./runtest-cluster --tls</code> to run Valkey and Valkey<br>Cluster tests in TLS mode.</p>\n</li>\n</ol>\n<h3>Running manually</h3>\n<p>To manually run a Valkey server with TLS mode (assuming <code>gen-test-certs.sh</code> was<br>invoked so sample certificates/keys are available):</p>\n<pre><code>./src/valkey-server --tls-port 6379 --port 0 \\\n    --tls-cert-file ./tests/tls/valkey.crt \\\n    --tls-key-file ./tests/tls/valkey.key \\\n    --tls-ca-cert-file ./tests/tls/ca.crt\n</code></pre>\n<p>To connect to this Valkey server with <code>valkey-cli</code>:</p>\n<pre><code>./src/valkey-cli --tls \\\n    --cert ./tests/tls/valkey.crt \\\n    --key ./tests/tls/valkey.key \\\n    --cacert ./tests/tls/ca.crt\n</code></pre>\n<h3>Certificate configuration</h3>\n<p>In order to support TLS, Valkey must be configured with a X.509 certificate and a<br>private key. In addition, it is necessary to specify a CA certificate bundle<br>file or path to be used as a trusted root when validating certificates. To<br>support DH based ciphers, a DH params file can also be configured. For example:</p>\n<pre><code>tls-cert-file /path/to/valkey.crt\ntls-key-file /path/to/valkey.key\ntls-ca-cert-file /path/to/ca.crt\ntls-dh-params-file /path/to/valkey.dh\n</code></pre>\n<h3>TLS listening port</h3>\n<p>The <code>tls-port</code> configuration directive enables accepting SSL/TLS connections on<br>the specified port. This is <strong>in addition</strong> to listening on <code>port</code> for TCP<br>connections, so it is possible to access Valkey on different ports using TLS and<br>non-TLS connections simultaneously.</p>\n<p>You may specify <code>port 0</code> to disable the non-TLS port completely. To enable only<br>TLS on the default Valkey port, use:</p>\n<pre><code>port 0\ntls-port 6379\n</code></pre>\n<h3>Client certificate authentication</h3>\n<p>By default, Valkey uses mutual TLS and requires clients to authenticate with a<br>valid certificate (authenticated against trusted root CAs specified by<br><code>ca-cert-file</code> or <code>ca-cert-dir</code>).</p>\n<p>You may use <code>tls-auth-clients no</code> to disable client authentication.</p>\n<h3>Replication</h3>\n<p>A Valkey primary server handles connecting clients and replica servers in the same<br>way, so the above <code>tls-port</code> and <code>tls-auth-clients</code> directives apply to<br>replication links as well.</p>\n<p>On the replica server side, it is necessary to specify <code>tls-replication yes</code> to<br>use TLS for outgoing connections to the primary.</p>\n<h3>Cluster</h3>\n<p>When Valkey Cluster is used, use <code>tls-cluster yes</code> in order to enable TLS for the<br>cluster bus and cross-node connections.</p>\n<h3>Sentinel</h3>\n<p>Sentinel inherits its networking configuration from the common Valkey<br>configuration, so all of the above applies to Sentinel as well.</p>\n<p>When connecting to primary servers, Sentinel will use the <code>tls-replication</code><br>directive to determine if a TLS or non-TLS connection is required.</p>\n<p>In addition, the very same <code>tls-replication</code> directive will determine whether Sentinel&#39;s<br>port, that accepts connections from other Sentinels, will support TLS as well. That is,<br>Sentinel will be configured with <code>tls-port</code> if and only if <code>tls-replication</code> is enabled. </p>\n<h3>Additional configuration</h3>\n<p>Additional TLS configuration is available to control the choice of TLS protocol<br>versions, ciphers and cipher suites, etc. Please consult the self documented<br><code>valkey.conf</code> for more information.</p>\n<h3>Performance considerations</h3>\n<p>TLS adds a layer to the communication stack with overheads due to writing/reading to/from an SSL connection, encryption/decryption and integrity checks. Consequently, using TLS results in a decrease of the achievable throughput per Valkey instance.</p>\n"
      },
      {
        "id": "memory-optimization",
        "topicName": "Memory optimization",
        "description": "Strategies for optimizing memory usage in Valkey",
        "htmlContent": "<h2>Special encoding of small aggregate data types</h2>\n<p>Many data types are optimized to use less space up to a certain size.<br>Hashes, Lists, Sets composed of just integers, and Sorted Sets, when smaller than a given number of elements, and up to a maximum element size, are encoded in a very memory-efficient way that uses <em>up to 10 times less memory</em> (with 5 times less memory used being the average saving).</p>\n<p>This is completely transparent from the point of view of the user and API.<br>Since this is a CPU / memory tradeoff it is possible to tune the maximum<br>number of elements and maximum element size for special encoded types<br>using the following valkey.conf directives (defaults for Valkey 7.2 are shown):</p>\n<pre><code>hash-max-listpack-entries 512\nhash-max-listpack-value 64\nzset-max-listpack-entries 128\nzset-max-listpack-value 64\nset-max-intset-entries 512\nset-max-listpack-entries 128\nset-max-listpack-value 64\n</code></pre>\n<p>If a specially encoded value overflows the configured max size,<br>Valkey will automatically convert it into normal encoding.<br>This operation is very fast for small values,<br>but if you change the setting in order to use specially encoded values<br>for much larger aggregate types the suggestion is to run some<br>benchmarks and tests to check the conversion time.</p>\n<h2>Using 32-bit instances</h2>\n<p>When Valkey is compiled as a 32-bit target, it uses a lot less memory per key, since pointers are small,<br>but such an instance will be limited to 4 GB of maximum memory usage.<br>To compile Valkey as 32-bit binary use <em>make 32bit</em>.<br>RDB and AOF files are compatible between 32-bit and 64-bit instances<br>(and between little and big endian of course) so you can switch from 32 to 64-bit, or the contrary, without problems.</p>\n<h2>Bit and byte level operations</h2>\n<p>Valkey has bit and byte level operations: <code>GETRANGE</code>, <code>SETRANGE</code>, <code>GETBIT</code> and <code>SETBIT</code>.<br>Using these commands you can treat the String type as a random access array.<br>For instance, if you have an application where users are identified by a unique progressive integer number,<br>you can use a bitmap to save information about the subscription of users in a mailing list,<br>setting the bit for subscribed and clearing it for unsubscribed, or the other way around.<br>With 100 million users this data will take just 12 megabytes of RAM in a Valkey instance.<br>You can do the same using <code>GETRANGE</code> and <code>SETRANGE</code> to store one byte of information for each user.<br>This is just an example but it is possible to model several problems in very little space with these new primitives.</p>\n<h2>Use hashes when possible</h2>\n<p>Small hashes are encoded in a very small space, so you should try representing your data using hashes whenever possible.<br>For instance, if you have objects representing users in a web application,<br>instead of using different keys for name, surname, email, password, use a single hash with all the required fields.</p>\n<p>If you want to know more about this, read the next section.</p>\n<h2>Using hashes to abstract a very memory-efficient plain key-value store on top of Valkey</h2>\n<p>I understand the title of this section is a bit scary, but I&#39;m going to explain in detail what this is about.</p>\n<p>Basically it is possible to model a plain key-value store using Valkey<br>where values can just be just strings, which is not just more memory efficient<br>than Valkey plain keys but also much more memory efficient than memcached.</p>\n<p>Let&#39;s start with some facts: a few keys use a lot more memory than a single key<br>containing a hash with a few fields. How is this possible? We use a trick.<br>In theory to guarantee that we perform lookups in constant time<br>(also known as O(1) in big O notation) there is the need to use a data structure<br>with a constant time complexity in the average case, like a hash table.</p>\n<p>But many times hashes contain just a few fields. When hashes are small we can<br>instead just encode them in an O(N) data structure, like a linear<br>array with length-prefixed key-value pairs. Since we do this only when N<br>is small, the amortized time for <code>HGET</code> and <code>HSET</code> commands is still O(1): the<br>hash will be converted into a real hash table as soon as the number of elements<br>it contains grows too large (you can configure the limit in valkey.conf).</p>\n<p>This does not only work well from the point of view of time complexity, but<br>also from the point of view of constant times since a linear array of key-value pairs happens to play very well with the CPU cache (it has a better<br>cache locality than a hash table).</p>\n<p>However since hash fields and values are not (always) represented as full-featured Valkey objects, hash fields can&#39;t have an associated time to live<br>(expire) like a real key, and can only contain a string. But we are okay with<br>this, this was the intention anyway when the hash data type API was<br>designed (we trust simplicity more than features, so nested data structures<br>are not allowed, as expires of single fields are not allowed).</p>\n<p>So hashes are memory efficient. This is useful when using hashes<br>to represent objects or to model other problems when there are group of<br>related fields. But what about if we have a plain key value business?</p>\n<p>Imagine we want to use Valkey as a cache for many small objects, which can be JSON encoded objects, small HTML fragments, simple key -&gt; boolean values<br>and so forth. Basically, anything is a string -&gt; string map with small keys<br>and values.</p>\n<p>Now let&#39;s assume the objects we want to cache are numbered, like:</p>\n<ul>\n<li>object:102393</li>\n<li>object:1234</li>\n<li>object:5</li>\n</ul>\n<p>This is what we can do. Every time we perform a<br>SET operation to set a new value, we actually split the key into two parts,<br>one part used as a key, and the other part used as the field name for the hash. For instance, the<br>object named &quot;object:1234&quot; is actually split into:</p>\n<ul>\n<li>a Key named object:12</li>\n<li>a Field named 34</li>\n</ul>\n<p>So we use all the characters but the last two for the key, and the final<br>two characters for the hash field name. To set our key we use the following<br>command:</p>\n<pre><code>HSET object:12 34 somevalue\n</code></pre>\n<p>As you can see every hash will end up containing 100 fields, which is an optimal compromise between CPU and memory saved.</p>\n<p>There is another important thing to note, with this schema<br>every hash will have more or<br>less 100 fields regardless of the number of objects we cached. This is because our objects will always end with a number and not a random string. In some way, the final number can be considered as a form of implicit pre-sharding.</p>\n<p>What about small numbers? Like object:2? We handle this case using just<br>&quot;object:&quot; as a key name, and the whole number as the hash field name.<br>So object:2 and object:10 will both end inside the key &quot;object:&quot;, but one<br>as field name &quot;2&quot; and one as &quot;10&quot;.</p>\n<p>Every time a hash exceeds the number of elements or element size specified<br>it will be converted into a real hash table, and the memory saving will be lost.</p>\n<p>You may ask, why don&#39;t you do this implicitly in the normal key space so that<br>I don&#39;t have to care? There are two reasons: one is that we tend to make<br>tradeoffs explicit, and this is a clear tradeoff between many things: CPU,<br>memory, and max element size. The second is that the top-level key space must<br>support a lot of interesting things like expires, LRU data, and so<br>forth so it is not practical to do this in a general way.</p>\n<p>But the Valkey Way is that the user must understand how things work so that he can pick the best compromise and to understand how the system will<br>behave exactly.</p>\n<h2>Memory allocation</h2>\n<p>To store user keys, Valkey allocates at most as much memory as the <code>maxmemory</code><br>setting enables (however there are small extra allocations possible).</p>\n<p>The exact value can be set in the configuration file or set later via<br><code>CONFIG SET</code> (for more info, see <a href=\"lru-cache\">Using memory as an LRU cache</a>).<br>There are a few things that should be noted about how Valkey manages memory:</p>\n<ul>\n<li>Valkey will not always free up (return) memory to the OS when keys are removed.<br>This is not something special about Valkey, but it is how most malloc() implementations work.<br>For example, if you fill an instance with 5GB worth of data, and then<br>remove the equivalent of 2GB of data, the Resident Set Size (also known as<br>the RSS, which is the number of memory pages consumed by the process)<br>will probably still be around 5GB, even if Valkey will claim that the user<br>memory is around 3GB.  This happens because the underlying allocator can&#39;t easily release the memory.<br>For example, often most of the removed keys were allocated on the same pages as the other keys that still exist.</li>\n<li>The previous point means that you need to provision memory based on your<br><strong>peak memory usage</strong>. If your workload from time to time requires 10GB, even if<br>most of the time 5GB could do, you need to provision for 10GB.</li>\n<li>However allocators are smart and are able to reuse free chunks of memory,<br>so after you free 2GB of your 5GB data set, when you start adding more keys<br>again, you&#39;ll see the RSS (Resident Set Size) stay steady and not grow<br>more, as you add up to 2GB of additional keys. The allocator is basically<br>trying to reuse the 2GB of memory previously (logically) freed.</li>\n<li>Because of all this, the fragmentation ratio is not reliable when you<br>had a memory usage that at the peak is much larger than the currently used memory.<br>The fragmentation is calculated as the physical memory actually used (the RSS<br>value) divided by the amount of memory currently in use (as the sum of all<br>the allocations performed by Valkey). Because the RSS reflects the peak memory,<br>when the (virtually) used memory is low since a lot of keys/values were freed, but the RSS is high, the ratio <code>RSS / mem_used</code> will be very high.</li>\n</ul>\n<p>If <code>maxmemory</code> is not set Valkey will keep allocating memory as it sees<br>fit and thus it can (gradually) eat up all your free memory.<br>Therefore it is generally advisable to configure some limits. You may also<br>want to set <code>maxmemory-policy</code> to <code>noeviction</code> (which is <em>not</em> the default<br>value in some older versions of Valkey).</p>\n<p>It makes Valkey return an out-of-memory error for write commands if and when it reaches the<br>limit - which in turn may result in errors in the application but will not render the<br>whole machine dead because of memory starvation.</p>\n"
      },
      {
        "id": "migration",
        "topicName": "Migration from Redis to Valkey",
        "description": "How to migrate from Redis to Valkey",
        "htmlContent": "<p>This is a migration guide from Redis open source versions to Valkey.<br>You will learn how to migrate a standalone Redis server instance and a Redis Cluster. </p>\n<p>This guide provides migration steps for Redis server and Valkey deployed in Docker; however, they should also apply for other deployments.<br>Refer to <a href=\"installation\">install Valkey</a> for installation options.</p>\n<h2>Why to migrate to Valkey?</h2>\n<ul>\n<li>Valkey is the vendor-neutral and open-source software</li>\n<li>Enhanced performance with multi-threading and dual-channel replication</li>\n<li>Improved memory efficiency by using one dictionary per slot in cluster mode and embedding keys in dictionaries.</li>\n</ul>\n<h3>Migration compatibility matrix</h3>\n<p>You can migrate a Redis server to Valkey.<br>Valkey is compatible with Redis OSS 7.2 and all earlier open source Redis versions, as Valkey 7.2.4 is a fork of Redis 7.2.4.<br>Migrating from any open source Redis version to Valkey is effectively an upgrade.</p>\n<blockquote>\n<p>NOTE: In this guide, whenever a reference to a <code>redis-cli</code> or <code>valkey-cli</code> command is provided, the reference will only point to the Valkey version of the documentation.</p>\n</blockquote>\n<p>Redis Community Edition (CE), versions 7.4 and later, are not open source and the data files are not compatible with Valkey.<br>It may be possible to migrate the data to Valkey from proprietary Redis versions and other Redis-like software, but it requires another method and is not covered by this document.</p>\n<p>The following table provides migration options depending on the Redis version you run:</p>\n<table>\n<thead>\n<tr>\n<th>Redis</th>\n<th>Valkey</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>OSS 2.x - 7.2.x</td>\n<td>7.2.x</td>\n</tr>\n<tr>\n<td>OSS 2.x - 7.2.x</td>\n<td>8.0</td>\n</tr>\n<tr>\n<td>CE 7.4</td>\n<td>n/a</td>\n</tr>\n</tbody></table>\n<h2>Migrate a standalone instance</h2>\n<p>To migrate a standalone Redis server to Valkey, you have the following options:</p>\n<ul>\n<li><a href=\"#physical-migration\">Physical migration</a> by copying the most recent on-disk snapshot from the Redis server to Valkey and starting Valkey server with it</li>\n<li><a href=\"#replication\">Setting up replication</a> between Redis and Valkey </li>\n<li><a href=\"#migrate-specific-keys\">Migrating specific keys</a></li>\n</ul>\n<p>The example migration steps are provided for Redis 7.2.5 and Valkey version 7.2.6. </p>\n<p>Note that Redis and Valkey Docker containers are considered stand-alone servers, if they are not part of a cluster.</p>\n<h3>Physical migration</h3>\n<p>This is the easiest and fastest migration method. You make a fresh snapshot of your Redis instance and copy it over to Valkey. Valkey reads the data from the snapshot on startup and restores its contents into memory. The tradeoffs for this method are:</p>\n<ul>\n<li>The downtime to shutdown Redis and wait for Valkey to load the data. </li>\n<li>Potential risk of data loss on instances with heavy writes. To prevent it, you must disconnect all active connections before starting the migration.</li>\n</ul>\n<p>To perform a physical migration:</p>\n<ol>\n<li><p>Disconnect all active connections to the Redis instance.</p>\n</li>\n<li><p>Connect to your Redis container using <code>redis-cli</code>, and check the number of keys, using the <code>INFO KEYSPACE</code> command. This will be used later to verify that the entire database has been successfully migrated. In this example, <code>keys=6286</code> indicates that there are 6,286 keys in the database.</p>\n<pre><code>$ redis-cli -h 127.0.0.1 -p 6379\nredis 127.0.0.1:6379&gt; INFO KEYSPACE\n# Keyspace\ndb0:keys=6286,expires=0,avg_ttl=0\n</code></pre>\n</li>\n<li><p>Check the configuration for the directory (<code>dir</code>) where Redis stores its database files and the name of the database file (<code>dbfilename</code>). In this example, Redis saves the backup into the <code>/data/dump.rdb</code> file</p>\n<blockquote>\n<p>NOTE: If your Redis Docker container <code>/data</code> directory is mounted to a directory on your host, the RDB file is also written to that host directory.</p>\n</blockquote>\n<pre><code>redis 127.0.0.1:6379&gt; CONFIG GET dir dbfilename\n1) &quot;dir&quot;\n2) &quot;/data&quot;\n3) &quot;dbfilename&quot;\n4) &quot;dump.rdb&quot;\n</code></pre>\n</li>\n<li><p>Create the backup file. Since all active connections have been disconnected for this example, the <code>redis-cli</code> <a href=\"../commands/save\">SAVE</a> command can be used to create the backup file.</p>\n<pre><code>redis 127.0.0.1:6379&gt; SAVE\nOK\n</code></pre>\n</li>\n<li><p>Exit  <code>redis-cli</code> by pressing <code>CTRL-D</code> or typing <code>exit</code>.</p>\n</li>\n<li><p>Create a directory on your host to which you will mount the <code>/data</code> directory of the Valkey container.</p>\n</li>\n<li><p>Copy the RDB file from Redis to Valkey, using one of the following:</p>\n<ul>\n<li><p>If the Redis and Valkey containers are both mounted to a host directory: </p>\n<p>Copy the RDB file from the host directory mounted to the Redis container to the host directory being mounted to the Valkey container.</p>\n</li>\n<li><p>If the Redis container is not mounted to a host directory but the Valkey container is:</p>\n<p>Use <code>docker cp</code> to copy the RDB file from within the Redis container to the host directory that will be mounted to your Valkey container.</p>\n<blockquote>\n<p>NOTE: You may also want to copy the RDB file to a second location as a backup.</p>\n</blockquote>\n<pre><code>docker cp redis-container-name:/dir-name/dbfilename &lt;path/on/host&gt;/dbfilename\n</code></pre>\n</li>\n</ul>\n</li>\n<li><p>Stop the Redis server.</p>\n</li>\n<li><p>Start Valkey:</p>\n<blockquote>\n<p>NOTE: If you enabled AOF in your Valkey configuration, disable it on the first start. Otherwise, the copied RDB file will not be imported into Valkey.</p>\n</blockquote>\n<p>Run the following command:</p>\n<pre><code>docker run -d --name valkey-container-name -v &lt;path/on/host&gt;:&lt;path/in/Valkey/container&gt; image-name\n</code></pre>\n</li>\n<li><p>To verify that the data has been successfully migrated, determine the number of keys in the Valkey database. If the migration is successful, then the number of keys in the Valkey database match the number of keys in the Redis database that you obtained in step 2:</p>\n<pre><code>$ docker exec -it somevalkey valkey-cli\nvalkey 127.0.0.1:6379&gt; INFO KEYSPACE\n# Keyspace\ndb0:keys=6286,expires=0,avg_ttl=0\n</code></pre>\n</li>\n<li><p>To exit <code>valkey-cli</code>, press <code>Ctrl-D</code> or type <code>exit</code>.</p>\n</li>\n</ol>\n<h3>Replication</h3>\n<p>To minimize the downtime during migration, you can use replication. Both Redis and Valkey allow replaying data on another server to handle the workload.</p>\n<p>In this scenario we will configure Valkey to be the replica of Redis. For illustrative purposes, both Redis and Valkey are running in separate Docker containers connected to the same network.</p>\n<ol>\n<li><p>Retrieve the IP address of the Redis container. Replace the <code>myredis</code> placeholder with the name of your container. In this example, <code>172.17.0.2</code> is returned as the IP address of the <code>myredis</code> container.</p>\n<pre><code>$ docker inspect -f &#39;{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}&#39; myredis\n172.17.0.2\n</code></pre>\n</li>\n<li><p>Determine the port on which your Redis container is exposed. Note that for clarity, not all of the fields are shown in the response. In this example, the <code>myredis</code> container is exposed on port <code>6379</code>.</p>\n<pre><code>docker container ls\nCONTAINER ID   ...     PORTS      NAMES\nbffc575f261a   ...     6379/tcp   myvalkey\nab18318ce820   ...     6379/tcp   myredis\n</code></pre>\n</li>\n<li><p>Connect to your Valkey container and start the <code>valkey-cli</code> to configure replication using the <a href=\"../commands/replicaof\">REPLICAOF</a> command. In this example, the Redis IP address is <code>172.17.0.2</code> and the port is <code>6379</code>. Replace with the IP address and port of your Redis container obtained in steps 1 and 2.</p>\n<pre><code>docker exec -it myvalkey valkey-cli\nvalkey 127.0.0.1:6379&gt; REPLICAOF 172.17.0.2 6379\nOK\n</code></pre>\n</li>\n<li><p>Check the replication status in Valkey using the <code>INFO REPLICATION</code> command. If <code>master_link_status:up</code> is present, then the Redis and Valkey servers are synchronized. <a href=\"../commands/info\">INFO Command</a> describes the different output fields.</p>\n<pre><code>valkey 127.0.0.1:6379&gt; INFO REPLICATION\n# Replication\nrole:slave\nmaster_host:172.17.0.2\nmaster_port:6379\nmaster_link_status:up\nmaster_last_io_seconds_ago:4\nmaster_sync_in_progress:0\n....\n</code></pre>\n</li>\n<li><p>Once Redis and Valkey are synchronized, verify that your applications connect to Valkey and shut down your Redis instance.</p>\n<blockquote>\n<p>NOTE: Since the Redis 7.0 release, the <code>SHUTDOWN</code> command waits for a time period, set by the <code>shutdown-timeout</code> configuration variable, for any lagging replicas to sync. There may be potential data loss in the case where there are writes active on the Redis primary while it is syncing with the replica.</p>\n</blockquote>\n<p>You can shut down Redis in one of the following ways:</p>\n<ul>\n<li><p>Using <code>redis-cli</code>:</p>\n<pre><code>$ redis-cli SHUTDOWN\n</code></pre>\n</li>\n<li><p>If Redis was started directly in the foreground (using redis-server), you can simply stop it by pressing <code>Ctrl-C</code> in the terminal where it is running.</p>\n</li>\n</ul>\n</li>\n<li><p>In your Valkey container, stop the Valkey replication using the <code>REPLICAOF</code> command with <code>NO ONE</code> as the options:</p>\n<pre><code>valkey 127.0.0.1:6379&gt; REPLICAOF NO ONE\nOK\n</code></pre>\n</li>\n<li><p>You can verify that replication has stopped by running the <code>valkey-cli</code> command, <code>INFO REPLICATION</code>. If you see <code>role:master</code> and <code>connected_slaves:0</code>, then the Valkey container is now the master and is no longer connected to the Redis server. <a href=\"../commands/info\">INFO Command</a> describes the different output fields.</p>\n<pre><code>127.0.0.1:6379&gt; INFO REPLICATION\n# Replication\nrole:master\nconnected_slaves:0\nmaster_failover_state:no-failover\nmaster_replid:8d48c4667129cdb5933f9a12a1d5e6a24899602b\nmaster_replid2:602b7046ada6d2d6f0e89657e646d5932cc42791\nmaster_repl_offset:1336\nsecond_repl_offset:1337\nrepl_backlog_active:1\nrepl_backlog_size:1048576\nrepl_backlog_first_byte_offset:1\nrepl_backlog_histlen:1336\n</code></pre>\n</li>\n</ol>\n<blockquote>\n<p>NOTE: If not for backward compatibility, the Valkey project no longer uses the words &quot;master&quot; and &quot;slave&quot;. Unfortunately, in this command these words are part of the protocol, so we’ll be able to remove such occurrences only when this API is naturally deprecated.</p>\n</blockquote>\n<h3>Migrate specific keys</h3>\n<p>Both physical migration and replication migrate the entire keyspace over to Valkey. </p>\n<p>There may be cases when you need to migrate only a specific set of critical keys.<br>The <code>redis-cli</code> command, <a href=\"../commands/migrate\">MIGRATE</a> is used to migrate one or more keys.</p>\n<p>Requirements for this example:</p>\n<ul>\n<li><p>The Redis and Valkey Docker containers are on the same network and can communicate with each other.</p>\n</li>\n<li><p>The Redis and Valkey containers are running without authentication.</p>\n</li>\n</ul>\n<p>Perform the following steps:</p>\n<ol>\n<li><p>Determine the keys you wish to migrate. In this example, the <code>message</code> and  <code>mydata</code> keys are being migrated from the <code>myredis</code> container, and the <code>redis-cli</code> is used to view their current values.</p>\n<pre><code>$ docker exec -it myredis redis-cli\nredis 127.0.0.1:6379&gt; GET message\n&quot;Hello Valkey&quot;\nredis 127.0.0.1:6379&gt; HGETALL  mydata\n1) &quot;name&quot;\n2) &quot;Alice&quot;\n3) &quot;age&quot;\n4) &quot;33&quot;\n5) &quot;country&quot;\n6) &quot;Brazil&quot;\n7) &quot;favorite food&quot;\n8) &quot;beans&quot;\n</code></pre>\n</li>\n<li><p>Retrieve the IP address of your Valkey container. Replace <code>myvalkey</code> with the name of your Valkey container.</p>\n<pre><code>$ docker inspect -f &#39;{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}&#39; myvalkey\n172.21.0.3\n</code></pre>\n</li>\n<li><p>Start the <code>valkey-cli</code> in your Valkey container and get the database number using the <code>INFO KEYSPACE</code> command. In this example, the database number is <code>0</code> (db0).</p>\n<pre><code>valkey 127.0.0.1:6379&gt; INFO KEYSPACE\n# Keyspace\ndb0:keys=3,expires=0,avg_ttl=0\n</code></pre>\n<blockquote>\n<p>NOTE: If you haven&#39;t migrated or added any data to your Valkey database, then the <code>INFO KEYSPACE</code> command will not return any database number. You can use <code>0</code> for the <code>MIGRATE</code> command in step 4.</p>\n</blockquote>\n</li>\n<li><p>From the Redis server, run the <code>MIGRATE</code> command:</p>\n<pre><code>MIGRATE valkey-ip valkey-port &lt;key | &quot;&quot;&gt; valkey-db-number timeout-value [COPY] [REPLACE] [AUTH password | AUTH2 username password] [KEYS key [key ...]]\n</code></pre>\n<p> For example, to migrate the <code>message</code> and <code>mydata</code> keys to the Valkey instance with the IP address 172.21.0.3 and port 6379, the command would look similar to:</p>\n<pre><code>redis 127.0.0.1:6379&gt; MIGRATE 172.21.0.3 6379 &quot;&quot; 0 10 COPY REPLACE KEYS message mydata\n</code></pre>\n<p>where:</p>\n<ul>\n<li><code>&quot;&quot;</code> = Indicates that we are migrating multiple keys. You can use <code>key</code> name here if you are only migrating a single key.</li>\n<li><code>0</code> = The database number.</li>\n<li><code>10</code>= The maximum idle time, in milliseconds, allowed when communicating with the destination server.</li>\n<li><code>COPY</code> = Do not remove the key from the Redis database.</li>\n<li><code>REPLACE</code> = Replace existing key on the Valkey database.</li>\n<li><code>KEYS</code> = We are migrating multiple keys, and it is followed by the key names.</li>\n</ul>\n</li>\n<li><p>Exit <code>redis-cli</code> by pressing <code>Ctrl-D</code> or typing <code>exit</code>.</p>\n</li>\n<li><p>Connect to Valkey and check the migrated keys. replace <code>myvalkey</code> with the name of your Valkey container.</p>\n<pre><code>$ docker exec -it myvalkey valkey-cli\nvalkey 127.0.0.1:6379&gt; GET message\n&quot;Hello Valkey&quot;\nvalkey 127.0.0.1:6379&gt; HGETALL mydata\n1) &quot;name&quot;\n2) &quot;Alice&quot;\n3) &quot;age&quot;\n4) &quot;33&quot;\n5) &quot;country&quot;\n6) &quot;Brazil&quot;\n7) &quot;favorite food&quot;\n8) &quot;beans&quot;\n....\n</code></pre>\n</li>\n</ol>\n<h2>Migrate a Cluster</h2>\n<p>This section demonstrates how to migrate a cluster. The first step is to add the required number of Valkey nodes to the existing cluster as replicas. Once the new Valkey nodes replicate the data, one Valkey replica is promoted to be a new primary for each Redis primary. After the migration, the Redis nodes are removed from the cluster.</p>\n<blockquote>\n<p>NOTE: You can also use data migration tools such as <a href=\"https://redis.github.io/riot/#_introduction\">RIOT</a>, <a href=\"https://github.com/tair-opensource/RedisShake\">RedisShake</a>, and <a href=\"https://github.com/vipshop/redis-migrate-tool\">Redis-Migrate-Tool</a> but that is beyond the scope of this document.</p>\n</blockquote>\n<p>Requirements for this example:</p>\n<ul>\n<li>The Redis and Valkey cluster nodes are on the same network and can communicate with each other.</li>\n</ul>\n<p>For this scenario, there is a Redis Cluster consisting of 3 primary and 3 replica nodes up and running. </p>\n<p>To perform the migration:</p>\n<ol>\n<li><p>Use the <code>redis-cli</code> on one of the cluster nodes to check the current state of the cluster and to ensure all nodes are connected and active. In this cluster, there are three primary (master) and three replica (slave) nodes.</p>\n<pre><code>$ redis-cli -h 127.0.0.1 -p 6379 -c CLUSTER NODES\n70beedebe43e422b275ee1a7bac0d3819dedca98 172.22.0.3:6379@16379 master - 0 1725450849000 1 connected 0-5460\n8bbe836c59644f7395bbab09c6f8b36bc277e902 172.22.0.5:6379@16379 slave 58061fb2836bdb2f5a0973e1ccfd74a66166f329 0 1725450849510 3 connected\n65061b94da5b481dc35c2df7dae13c233d4b3ad2 172.22.0.4:6379@16379 master - 0 1725450848000 2 connected 5461-10922\na242941d0e3edad27a954bc14ac3a3413f3040aa 172.22.0.7:6379@16379 slave 65061b94da5b481dc35c2df7dae13c233d4b3ad2 0 1725450849000 2 connected\n3499854656f085ebb77b5b921389a91b7ae9d703 172.22.0.6:6379@16379 slave 70beedebe43e422b275ee1a7bac0d3819dedca98 0 1725450849829 1 connected\n58061fb2836bdb2f5a0973e1ccfd74a66166f329 172.22.0.2:6379@16379 myself,master - 0 1725450846000 3 connected 10923-16383\n</code></pre>\n</li>\n<li><p>Create a valkey.conf configuration file and specify the following parameters. Note that this configuration file enables clustering. <a href=\"https://raw.githubusercontent.com/valkey-io/valkey/7.2/valkey.conf\">Valkey configuration file example</a> provides a description of the various configuration arguments:</p>\n<pre><code># valkey.conf file\nport 6379\ncluster-enabled yes\ncluster-config-file nodes.conf\ncluster-node-timeout 5000\nappendonly yes\n</code></pre>\n</li>\n<li><p>Start a Valkey instance with your custom configuration file. The following command starts Valkey in Docker:</p>\n<pre><code>$ docker run  -d -v myvalkey/conf:/usr/local/etc/valkey --name valkey-1 --net mynetwork valkey/valkey valkey-server /usr/local/etc/valkey/valkey.conf\n</code></pre>\n<p>where:</p>\n<ul>\n<li><code>myvalkey/conf</code> is a local directory containing your <code>valkey.conf</code> configuration file that is being mapped to the <code>/usr/local/etc/valkey</code> directory within the Docker Valkey container.</li>\n<li><code>valkey-1</code> is the name of your container</li>\n<li><code>mynetwork</code> is the name of the network where Redis cluster is running.</li>\n<li><code>valkey/valkey</code> is the name of the Valkey image</li>\n</ul>\n</li>\n<li><p>Retrieve the IP address of the Valkey instance; replacing <code>valkey-1</code> with the name of your container.</p>\n<pre><code>$ docker inspect -f &#39;{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}&#39; valkey-1\n</code></pre>\n</li>\n<li><p>Add your new Valkey node to the Redis Cluster as a replica. Replace the <code>redis-1</code>, <code>valkey-node-ip</code>, and <code>existing-node-ip</code> placeholders with your values:</p>\n<pre><code>$ docker exec -it redis-1 bash\n$ redis-cli --cluster add-node valkey-node-ip:6379 existing-node-ip:6379 --cluster-replica\n</code></pre>\n</li>\n<li><p>Check the cluster status. The output of the <code>CLUSTER NODES</code> command is described in <a href=\"../commands/cluster-nodes\">CLUSTER NODES</a>.</p>\n<pre><code>$ redis-cli -c CLUSTER NODES\n</code></pre>\n<p> In the output, you will see the newly added node as a replica (slave). For example, we have added a Valkey node with the IP address <code>172.22.0.8:6379</code>. The cluster nodes list now includes a new entry as follows:</p>\n<pre><code>a98d5bac59672597b8509f24970e413002f896b6 172.22.0.8:6379@16379 slave 58061fb2836bdb2f5a0973e1ccfd74a66166f329 0 1725451086000 3 connected\n</code></pre>\n</li>\n<li><p>Verify that your newly added Valkey node is recognized as a replica by running the <code>INFO REPLICATION</code> command. The output displays information about the node&#39;s primary.</p>\n</li>\n<li><p>Start the <code>valkey-cli</code> in your new Valkey container and enter the following command to promote it to be primary. <a href=\"../commands/cluster-failover\">CLUSTER FAILOVER</a> provides additional information.</p>\n<pre><code>docker exec -it valkey-container-name valkey-cli\nvalkey 127.0.0.1:6379&gt; CLUSTER FAILOVER\nOK\n</code></pre>\n</li>\n<li><p>Use the <code>CLUSTER NODES</code> command to display the cluster state and verify that your new Valkey node is now a new primary.</p>\n</li>\n<li><p>Repeat steps 3-9 to add 2 more Valkey nodes and replace the Redis primary nodes.</p>\n</li>\n<li><p>Repeat steps 3-7 to add 3 Valkey replica nodes.</p>\n<p>To add a replica to a specific primary, do the following:</p>\n<p>a. Filter primary nodes. Connect to any node in the Cluster and run the following command, replacing <code>valkey-1</code> with then name of your Valkey container:</p>\n<pre><code>$ docker exec -it valkey-1 bash\n$ valkey-cli -c cluster nodes | grep master\n70beedebe43e422b275ee1a7bac0d3819dedca98 172.22.0.3:6379@16379 master - 0 1725451135799 1 connected 0-5460\n65061b94da5b481dc35c2df7dae13c233d4b3ad2 172.22.0.4:6379@16379 master - 0 1725451136000 2 connected 5461-10922\n58061fb2836bdb2f5a0973e1ccfd74a66166f329 172.22.0.2:6379@16379 myself,master - 0 1725451136000 3 connected 10923-16383\n</code></pre>\n<blockquote>\n<p>NOTE: The node ID is the 40-character globally unique string that is generated when the node is created. In this example, <code>70beedebe43e422b275ee1a7bac0d3819dedca98</code> is the ID of the primary (master) node with the IP address <code>172.22.0.3:6379</code>. The ID of a node is required when adding a new Valkey replica to a specific primary in step b.</p>\n</blockquote>\n<p>b. Add a new node to a specific primary, replacing node-id with your node ID:</p>\n<pre><code>$ valkey-cli --cluster add-node 172.22.0.10:6379 172.22.0.2:6379 --cluster-replica --cluster-master-id node-id\n</code></pre>\n</li>\n<li><p>Remove Redis nodes:</p>\n<pre><code>redis-cli --cluster del-node 127.0.0.1:6379 node-id\n</code></pre>\n<p> The first argument is just a random node in the cluster, the second argument is the ID of the node you want to remove.</p>\n</li>\n</ol>\n<blockquote>\n<p>NOTE: If not for backward compatibility, the Valkey project no longer uses the words &quot;master&quot; and &quot;slave&quot;. Unfortunately, in the given commands these words are part of the protocol, so we&#39;ll be able to remove such occurrences only when this API is naturally deprecated.</p>\n</blockquote>\n"
      },
      {
        "id": "persistence",
        "topicName": "Persistence",
        "description": "How Valkey writes data to disk",
        "htmlContent": "<p>Persistence refers to the writing of data to durable storage, such as a solid-state disk (SSD). Valkey provides a range of persistence options. These include:</p>\n<ul>\n<li><strong>RDB</strong> (Valkey Database): RDB persistence performs point-in-time snapshots of your dataset at specified intervals.</li>\n<li><strong>AOF</strong> (Append Only File): AOF persistence logs every write operation received by the server. These operations can then be replayed again at server startup, reconstructing the original dataset. Commands are logged using the same format as the Valkey protocol itself.</li>\n<li><strong>No persistence</strong>: You can disable persistence completely. This is sometimes used when caching.</li>\n<li><strong>RDB + AOF</strong>: You can also combine both AOF and RDB in the same instance.</li>\n</ul>\n<p>To learn more about how to evaluate your Valkey persistence strategy, read on.</p>\n<h2>RDB advantages</h2>\n<ul>\n<li>RDB is a very compact single-file point-in-time representation of your Valkey data. RDB files are perfect for backups. For instance you may want to archive your RDB files every hour for the latest 24 hours, and to save an RDB snapshot every day for 30 days. This allows you to easily restore different versions of the data set in case of disasters.</li>\n<li>RDB is very good for disaster recovery, being a single compact file that can be transferred to far data centers, or onto Amazon S3 (possibly encrypted).</li>\n<li>RDB maximizes Valkey performances since the only work the Valkey parent process needs to do in order to persist is forking a child that will do all the rest. The parent process will never perform disk I/O or alike.</li>\n<li>RDB allows faster restarts with big datasets compared to AOF.</li>\n<li>On replicas, RDB supports <a href=\"replication#partial-resynchronizations-after-restarts-and-failovers\">partial resynchronizations after restarts and failovers</a>.</li>\n</ul>\n<h2>RDB disadvantages</h2>\n<ul>\n<li>RDB is NOT good if you need to minimize the chance of data loss in case Valkey stops working (for example after a power outage). You can configure different <em>save points</em> where an RDB is produced (for instance after at least five minutes and 100 writes against the data set, you can have multiple save points). However you&#39;ll usually create an RDB snapshot every five minutes or more, so in case of Valkey stopping working without a correct shutdown for any reason you should be prepared to lose the latest minutes of data.</li>\n<li>RDB needs to fork() often in order to persist on disk using a child process. fork() can be time consuming if the dataset is big, and may result in Valkey stopping serving clients for some milliseconds or even for one second if the dataset is very big and the CPU performance is not great. AOF also needs to fork() but less frequently and you can tune how often you want to rewrite your logs without any trade-off on durability.</li>\n</ul>\n<h2>AOF advantages</h2>\n<ul>\n<li>Using AOF Valkey is much more durable: you can have different fsync policies: no fsync at all, fsync every second, fsync at every query. With the default policy of fsync every second, write performance is still great. fsync is performed using a background thread and the main thread will try hard to perform writes when no fsync is in progress, so you can only lose one second worth of writes.</li>\n<li>The AOF log is an append-only log, so there are no seeks, nor corruption problems if there is a power outage. Even if the log ends with a half-written command for some reason (disk full or other reasons) the valkey-check-aof tool is able to fix it easily.</li>\n<li>Valkey is able to automatically rewrite the AOF in background when it gets too big. The rewrite is completely safe as while Valkey continues appending to the old file, a completely new one is produced with the minimal set of operations needed to create the current data set, and once this second file is ready Valkey switches the two and starts appending to the new one.</li>\n<li>AOF contains a log of all the operations one after the other in an easy to understand and parse format. You can even easily export an AOF file. For instance even if you&#39;ve accidentally flushed everything using the <code>FLUSHALL</code> command, as long as no rewrite of the log was performed in the meantime, you can still save your data set just by stopping the server, removing the latest command, and restarting Valkey again.</li>\n</ul>\n<h2>AOF disadvantages</h2>\n<ul>\n<li>AOF files are usually bigger than the equivalent RDB files for the same dataset.</li>\n<li>AOF can be slower than RDB depending on the exact fsync policy. In general with fsync set to <em>every second</em> performance is still very high, and with fsync disabled it should be exactly as fast as RDB even under high load. Still RDB is able to provide more guarantees about the maximum latency even in the case of a huge write load.</li>\n</ul>\n<h2>Ok, so what should I use?</h2>\n<p>The general indication you should use both persistence methods is if<br>you want a degree of data safety comparable to what PostgreSQL can provide you.</p>\n<p>If you care a lot about your data, but still can live with a few minutes of<br>data loss in case of disasters, you can simply use RDB alone.</p>\n<p>There are many users using AOF alone, but we discourage it since to have an<br>RDB snapshot from time to time is a great idea for doing database backups,<br>for faster restarts, and in the event of bugs in the AOF engine.</p>\n<p>The following sections will illustrate a few more details about the two persistence models.</p>\n<h2>Snapshotting</h2>\n<p>By default Valkey saves snapshots of the dataset on disk, in a binary<br>file called <code>dump.rdb</code>. You can configure Valkey to have it save the<br>dataset every N seconds if there are at least M changes in the dataset,<br>or you can manually call the <code>SAVE</code> or <code>BGSAVE</code> commands.</p>\n<p>For example, this configuration will make Valkey automatically dump the<br>dataset to disk every 60 seconds if at least 1000 keys changed:</p>\n<pre><code>save 60 1000\n</code></pre>\n<p>This strategy is known as <em>snapshotting</em>.</p>\n<h2>No persistence</h2>\n<p>If you prefer <strong>not</strong> to have persistence (for example when using a Valkey instance solely as a cache) that is also a possibility.</p>\n<p>RDB snapshotting is enabled by default. To disable it, set the <code>save</code> configuration parameter to the empty string <code>&quot;&quot;</code> and remove any excess <code>save</code> lines that are present in the current configuration file.</p>\n<pre><code>save &quot;&quot;\n</code></pre>\n<p>Alternatively, you can also use the <code>--save &quot;&quot;</code> argument on the <code>valkey-server</code> binary.</p>\n<h3>How it works</h3>\n<p>Whenever Valkey needs to dump the dataset to disk, this is what happens:</p>\n<ul>\n<li><p>Valkey <a href=\"https://linux.die.net/man/2/fork\">forks</a>. We now have a child<br>and a parent process.</p>\n</li>\n<li><p>The child starts to write the dataset to a temporary RDB file.</p>\n</li>\n<li><p>When the child is done writing the new RDB file, it replaces the old<br>one.</p>\n</li>\n</ul>\n<p>This method allows Valkey to benefit from copy-on-write semantics.</p>\n<h2>Append-only file</h2>\n<p>Snapshotting is not very durable. If your computer running Valkey stops,<br>your power line fails, or you accidentally <code>kill -9</code> your instance, the<br>latest data written to Valkey will be lost.  While this may not be a big<br>deal for some applications, there are use cases for full durability, and<br>in these cases Valkey snapshotting alone is not a viable option.</p>\n<p>The <em>append-only file</em> is an alternative, fully-durable strategy for<br>Valkey.</p>\n<p>You can turn on the AOF in your configuration file:</p>\n<pre><code>appendonly yes\n</code></pre>\n<p>From now on, every time Valkey receives a command that changes the<br>dataset (e.g. <code>SET</code>) it will append it to the AOF.  When you restart<br>Valkey it will re-play the AOF to rebuild the state.</p>\n<p>Valkey uses a multi part AOF mechanism.<br>That is, the original single AOF file is split into base file (at most one) and incremental files (there may be more than one).<br>The base file represents an initial (RDB or AOF format) snapshot of the data present when the AOF is <a href=\"#log-rewriting\">rewritten</a>.<br>The incremental files contains incremental changes since the last base AOF file was created. All these files are put in a separate directory and are tracked by a manifest file.</p>\n<h3>Log rewriting</h3>\n<p>The AOF gets bigger and bigger as write operations are<br>performed.  For example, if you are incrementing a counter 100 times,<br>you&#39;ll end up with a single key in your dataset containing the final<br>value, but 100 entries in your AOF. 99 of those entries are not needed<br>to rebuild the current state.</p>\n<p>The rewrite is completely safe.<br>While Valkey continues appending to the old file,<br>a completely new one is produced with the minimal set of operations needed to create the current data set,<br>and once this second file is ready Valkey switches the two and starts appending to the new one.</p>\n<p>Valkey supports an interesting feature: it is able to rebuild the AOF in the background without interrupting service to clients.<br>Whenever you issue a <code>BGREWRITEAOF</code>, Valkey will write the shortest sequence of commands needed to rebuild the current dataset in memory.<br>Valkey will automatically trigger log rewriting automatically (see the example configuration file for more information).</p>\n<p>When an AOF rewrite is scheduled, the Valkey parent process opens a new incremental AOF file to continue writing.<br>The child process executes the rewrite logic and generates a new base AOF.<br>Valkey will use a temporary manifest file to track the newly generated base file and incremental file.<br>When they are ready, Valkey will perform an atomic replacement operation to make this temporary manifest file take effect.<br>In order to avoid the problem of creating many incremental files in case of repeated failures and retries of an AOF rewrite,<br>Valkey introduces an AOF rewrite limiting mechanism to ensure that failed AOF rewrites are retried at a slower and slower rate.</p>\n<h3>How durable is the append only file?</h3>\n<p>You can configure how many times Valkey will<br><a href=\"https://linux.die.net/man/2/fsync\"><code>fsync</code></a> data on disk. There are<br>three options:</p>\n<ul>\n<li><code>appendfsync always</code>: <code>fsync</code> every time new commands are appended to the AOF. Very very slow, very safe. Note that the commands are appended to the AOF after a batch of commands from multiple clients or a pipeline are executed, so it means a single write and a single fsync (before sending the replies).</li>\n<li><code>appendfsync everysec</code>: <code>fsync</code> every second. Fast enough and you may lose 1 second of data if there is a disaster.</li>\n<li><code>appendfsync no</code>: Never <code>fsync</code>, just put your data in the hands of the Operating System. The faster and less safe method. Normally Linux will flush data every 30 seconds with this configuration, but it&#39;s up to the kernel&#39;s exact tuning.</li>\n</ul>\n<p>The suggested (and default) policy is to <code>fsync</code> every second. It is<br>both fast and relatively safe. The <code>always</code> policy is very slow in<br>practice, but it supports group commit, so if there are multiple parallel<br>writes Valkey will try to perform a single <code>fsync</code> operation.</p>\n<h3>What should I do if my AOF gets truncated?</h3>\n<p>It is possible the server crashed while writing the AOF file, or the<br>volume where the AOF file is stored was full at the time of writing. When this happens the<br>AOF still contains consistent data representing a given point-in-time version<br>of the dataset (that may be old up to one second with the default AOF fsync<br>policy), but the last command in the AOF could be truncated.<br>The latest major versions of Valkey will be able to load the AOF anyway, just<br>discarding the last non well formed command in the file. In this case the<br>server will emit a log like the following:</p>\n<pre><code>* Reading RDB preamble from AOF file...\n* Reading the remaining AOF tail...\n# !!! Warning: short read while loading the AOF file !!!\n# !!! Truncating the AOF at offset 439 !!!\n# AOF loaded anyway because aof-load-truncated is enabled\n</code></pre>\n<p>You can change the default configuration to force Valkey to stop in such<br>cases if you want, but the default configuration is to continue regardless of<br>the fact the last command in the file is not well-formed, in order to guarantee<br>availability after a restart.</p>\n<p>Older versions of Valkey may not recover, and may require the following steps:</p>\n<ul>\n<li><p>Make a backup copy of your AOF file.</p>\n</li>\n<li><p>Fix the original file using the <code>valkey-check-aof</code> tool that ships with Valkey:</p>\n<pre><code>$ valkey-check-aof --fix &lt;filename&gt;\n</code></pre>\n</li>\n<li><p>Optionally use <code>diff -u</code> to check what is the difference between two files.</p>\n</li>\n<li><p>Restart the server with the fixed file.</p>\n</li>\n</ul>\n<h3>What should I do if my AOF gets corrupted?</h3>\n<p>If the AOF file is not just truncated, but corrupted with invalid byte<br>sequences in the middle, things are more complex. Valkey will complain<br>at startup and will abort:</p>\n<pre><code>* Reading the remaining AOF tail...\n# Bad file format reading the append only file: make a backup of your AOF file, then use ./valkey-check-aof --fix &lt;filename&gt;\n</code></pre>\n<p>The best thing to do is to run the <code>valkey-check-aof</code> utility, initially without<br>the <code>--fix</code> option, then understand the problem, jump to the given<br>offset in the file, and see if it is possible to manually repair the file:<br>The AOF uses the same format of the Valkey protocol and is quite simple to fix<br>manually. Otherwise it is possible to let the utility fix the file for us, but<br>in that case all the AOF portion from the invalid part to the end of the<br>file may be discarded, leading to a massive amount of data loss if the<br>corruption happened to be in the initial part of the file.</p>\n<h3>How it works</h3>\n<p>Log rewriting uses the same copy-on-write trick already in use for<br>snapshotting.  This is how it works:</p>\n<p><strong>Valkey multi-part AOF</strong></p>\n<ul>\n<li><p>Valkey <a href=\"https://linux.die.net/man/2/fork\">forks</a>, so now we have a child<br>and a parent process.</p>\n</li>\n<li><p>The child starts writing the new base AOF in a temporary file.</p>\n</li>\n<li><p>The parent opens a new increments AOF file to continue writing updates.<br>If the rewriting fails, the old base and increment files (if there are any) plus this newly opened increment file represent the complete updated dataset,<br>so we are safe.</p>\n</li>\n<li><p>When the child is done rewriting the base file, the parent gets a signal,<br>and uses the newly opened increment file and child generated base file to build a temp manifest,<br>and persist it.</p>\n</li>\n<li><p>Profit! Now Valkey does an atomic exchange of the manifest files so that the result of this AOF rewrite takes effect. Valkey also cleans up the old base file and any unused increment files.</p>\n</li>\n</ul>\n<h3>How I can switch to AOF, if I&#39;m currently using dump.rdb snapshots?</h3>\n<p>If you want to enable AOF in a server that is currently using RDB snapshots, you need to convert the data by enabling AOF via CONFIG command on the live server first.</p>\n<p><strong>IMPORTANT:</strong> not following this procedure (e.g. just changing the config and restarting the server) can result in data loss!</p>\n<p>Preparations:</p>\n<ul>\n<li>Make a backup of your latest dump.rdb file.</li>\n<li>Transfer this backup to a safe place.</li>\n</ul>\n<p>Switch to AOF on live database:</p>\n<ul>\n<li>Enable AOF: <code>valkey-cli config set appendonly yes</code></li>\n<li>Optionally disable RDB: <code>valkey-cli config set save &quot;&quot;</code></li>\n<li>Make sure writes are appended to the append only file correctly.</li>\n<li><strong>IMPORTANT:</strong> Update your <code>valkey.conf</code> (potentially through <code>CONFIG REWRITE</code>) and ensure that it matches the configuration above.<br>If you forget this step, when you restart the server, the configuration changes will be lost and the server will start again with the old configuration, resulting in a loss of your data.</li>\n</ul>\n<p>Next time you restart the server:</p>\n<ul>\n<li>Before restarting the server, wait for AOF rewrite to finish persisting the data.<br>You can do that by watching <code>INFO persistence</code>, waiting for <code>aof_rewrite_in_progress</code> and <code>aof_rewrite_scheduled</code> to be <code>0</code>, and validating that <code>aof_last_bgrewrite_status</code> is <code>ok</code>.</li>\n<li>After restarting the server, check that your database contains the same number of keys it contained previously.</li>\n</ul>\n<h2>Interactions between AOF and RDB persistence</h2>\n<p>Valkey makes sure to avoid triggering an AOF rewrite when an RDB<br>snapshotting operation is already in progress, or allowing a <code>BGSAVE</code> while the<br>AOF rewrite is in progress. This prevents two Valkey background processes<br>from doing heavy disk I/O at the same time.</p>\n<p>When snapshotting is in progress and the user explicitly requests a log<br>rewrite operation using <code>BGREWRITEAOF</code> the server will reply with an OK<br>status code telling the user the operation is scheduled, and the rewrite<br>will start once the snapshotting is completed.</p>\n<p>In the case both AOF and RDB persistence are enabled and Valkey restarts the<br>AOF file will be used to reconstruct the original dataset since it is<br>guaranteed to be the most complete.</p>\n<h2>Backing up Valkey data</h2>\n<p>Before starting this section, make sure to read the following sentence: <strong>Make Sure to Backup Your Database</strong>. Disks break, instances in the cloud disappear, and so forth: no backups means huge risk of data disappearing into /dev/null.</p>\n<p>Valkey is very data backup friendly since you can copy RDB files while the<br>database is running: the RDB is never modified once produced, and while it<br>gets produced it uses a temporary name and is renamed into its final destination<br>atomically using rename(2) only when the new snapshot is complete.</p>\n<p>This means that copying the RDB file is completely safe while the server is<br>running. This is what we suggest:</p>\n<ul>\n<li>Create a cron job in your server creating hourly snapshots of the RDB file in one directory, and daily snapshots in a different directory.</li>\n<li>Every time the cron script runs, make sure to call the <code>find</code> command to make sure too old snapshots are deleted: for instance you can take hourly snapshots for the latest 48 hours, and daily snapshots for one or two months. Make sure to name the snapshots with date and time information.</li>\n<li>At least one time every day make sure to transfer an RDB snapshot <em>outside your data center</em> or at least <em>outside the physical machine</em> running your Valkey instance.</li>\n</ul>\n<h3>Backing up AOF persistence</h3>\n<p>If you run a Valkey instance with only AOF persistence enabled, you can still perform backups.<br>AOF files are split into multiple files which reside in a single directory determined by the <code>appenddirname</code> configuration.<br>During normal operation all you need to do is copy/tar the files in this directory to achieve a backup. However, if this is done during a <a href=\"#log-rewriting\">rewrite</a>, you might end up with an invalid backup.<br>To work around this you must disable AOF rewrites during the backup:</p>\n<ol>\n<li>Turn off automatic rewrites with<br/><br><code>CONFIG SET</code> <code>auto-aof-rewrite-percentage 0</code><br/><br>Make sure you don&#39;t manually start a rewrite (using <code>BGREWRITEAOF</code>) during this time.</li>\n<li>Check there&#39;s no current rewrite in progress using<br/><br><code>INFO</code> <code>persistence</code><br/><br>and verifying <code>aof_rewrite_in_progress</code> is 0. If it&#39;s 1, then you&#39;ll need to wait for the rewrite to complete.</li>\n<li>Now you can safely copy the files in the <code>appenddirname</code> directory.</li>\n<li>Re-enable rewrites when done:<br/><br><code>CONFIG SET</code> <code>auto-aof-rewrite-percentage &lt;prev-value&gt;</code></li>\n</ol>\n<p><strong>Note:</strong> If you want to minimize the time AOF rewrites are disabled you may create hard links to the files in <code>appenddirname</code> (in step 3 above) and then re-enable rewrites (step 4) after the hard links are created.<br>Now you can copy/tar the hardlinks and delete them when done. This works because Valkey guarantees that it<br>only appends to files in this directory, or completely replaces them if necessary, so the content should be<br>consistent at any given point in time.</p>\n<p><strong>Note:</strong> If you want to handle the case of the server being restarted during the backup and make sure no rewrite will automatically start after the restart you can change step 1 above to also persist the updated configuration via <code>CONFIG REWRITE</code>.<br>Just make sure to re-enable automatic rewrites when done (step 4) and persist it with another <code>CONFIG REWRITE</code>.</p>\n<h2>Disaster recovery</h2>\n<p>Disaster recovery in the context of Valkey is basically the same story as<br>backups, plus the ability to transfer those backups in many different external<br>data centers. This way data is secured even in the case of some catastrophic<br>event affecting the main data center where Valkey is running and producing its<br>snapshots.</p>\n<p>We&#39;ll review the most interesting disaster recovery techniques<br>that don&#39;t have too high costs.</p>\n<ul>\n<li>Amazon S3 and other similar services are a good way for implementing your disaster recovery system. Simply transfer your daily or hourly RDB snapshot to S3 in an encrypted form. You can encrypt your data using <code>gpg -c</code> (in symmetric encryption mode). Make sure to store your password in many different safe places (for instance give a copy to the most important people of your organization). It is recommended to use multiple storage services for improved data safety.</li>\n<li>Transfer your snapshots using SCP (part of SSH) to far servers. This is a fairly simple and safe route: get a small VPS in a place that is very far from you, install ssh there, and generate a ssh client key without passphrase, then add it in the <code>authorized_keys</code> file of your small VPS. You are ready to transfer backups in an automated fashion. Get at least two VPS in two different providers<br>for best results.</li>\n</ul>\n<p>It is important to understand that this system can easily fail if not<br>implemented in the right way. At least, make absolutely sure that after the<br>transfer is completed you are able to verify the file size (that should match<br>the one of the file you copied) and possibly the SHA1 digest, if you are using<br>a VPS.</p>\n<p>You also need some kind of independent alert system if the transfer of fresh<br>backups is not working for some reason.</p>\n"
      },
      {
        "id": "releases",
        "topicName": "Releases and versioning",
        "description": "How new versions of Valkey are released and supported",
        "htmlContent": "<p>Valkey is usually among the most critical pieces of a software stack.<br>For this reason, Valkey&#39;s release cycle prioritizes highly stable releases at the cost of slower release cycles.</p>\n<p>All Valkey releases are published in the <a href=\"https://github.com/valkey-io/valkey/releases\">Valkey GitHub repository</a>.</p>\n<h2>Versioning</h2>\n<p>Valkey stable releases will generally follow <code>major.minor.patch</code> <a href=\"https://semver.org/\">semantic versioning schema</a>.<br>We follow semantic versioning to provide explicit guarantees regarding backward compatibility.</p>\n<p>When discussing compatibility, we refer to the following API contracts:</p>\n<ol>\n<li>Valkey commands including their inputs, outputs, and defined behavior</li>\n<li>The functions and APIs that can be executed from a Lua script</li>\n<li>The RDB version</li>\n<li>The protocol used to establish and replicate data from primaries to replicas</li>\n<li>The protocol between nodes within a Valkey cluster</li>\n<li>The Valkey Module API interface</li>\n<li>The AOF on disk format</li>\n</ol>\n<h3>Patch versions</h3>\n<p><em>Patch</em> versions are released with backwards compatible bug fixes and should not introduce new features.</p>\n<p>Upgrading from a previous patch version should be safe and seamless.<br>It should be safe to run a primary-replica pair or a Valkey cluster with servers running on different patch versions.</p>\n<p><em>Patch</em> versions may also introduce small improvements such as performance or memory optimizations that are easy to verify as safe.</p>\n<h3>Minor versions</h3>\n<p><em>Minor</em> versions are released with new functionality that is added in a backward compatible manner.<br>Examples of new functionality include new commands, info fields, or configuration parameters.</p>\n<p>Upgrading from a previous minor version should be safe, and will not introduce incompatibilities between servers in the cluster when default server configurations are used.</p>\n<p><strong>NOTE:</strong> Minor releases may include new commands and data types that can introduce incompatibility between servers in the cluster, but users need to opt-in to these features to cause this type of incompatibility.<br>For this reason, it is not recommended to run a Valkey cluster with servers running on different minor versions.<br>Users should avoid new features until all servers in the cluster have been upgraded.</p>\n<p>Commands may also be marked as <strong>deprecated</strong> in minor versions.<br>Deprecated commands are not removed, instead a replacement command or an alternative to using the command will be defined in the same minor version.</p>\n<h3>Major versions</h3>\n<p><em>Major</em> versions are released with significant functionality that may break backwards compatibility or alter key performance characteristics.<br>Examples of significant functionality includes altering the behavior of an existing command, removing previously deprecated commands, changing the default value of configs, and significant refactoring for performance improvements.</p>\n<p>Upgrading from a previous major version is intended to be safe, but should be approached with caution.<br>You should carefully read the release notes before performing a major version upgrade.<br>Although Major versions can introduce breaking changes, data replicated from primaries to replicas will always be sent in a backward compatible format.<br>You should always upgrade replicas before upgrading primaries in order to ensure data consistency.</p>\n<p>The Valkey community strives to make as few backwards breaking changes as possible.<br>When breaking changes are required, we will also strive to provide a way to mitigate the impact without incurring downtime to your application.</p>\n<h2>Release schedule</h2>\n<p>The Valkey community typically releases a stable major version once each year.<br>Stable minor versions are introduced as needed between major releases,<br>with at least one minor version published annually.</p>\n<h3>Release candidate</h3>\n<p>New minor and major versions of Valkey begin by branching off the <code>unstable</code> branch as an initial release candidate branch with a name that takes the form of <em><code>major.minor</code></em>, example <code>7.2</code>.<br>The first release candidate, or rc1, is released once it can be used for development purposes and for testing the new version.<br>Release candidate versions will start with a patch version of &quot;0&quot; and will take the form <em><code>major.minor.patch-rcN</code></em>, example <code>7.2.0-rc1</code> followed by <code>7.2.0-rc2</code>.<br>At this stage, most of the new features and changes in the new version are ready for review, and the version is released for the purpose of collecting public feedback.<br>Subsequent release candidates are released every couple of weeks, primarily for fixing bugs and refining features based off of user input.</p>\n<h3>Stable release</h3>\n<p>Once development has ended and the feedback for release candidate slows down, it is ready for the final release.<br>At this point, the release is marked as stable and is released with &quot;0&quot; as its patch-level version.</p>\n<p>Patches are released as needed to fix high-urgency issues, or once a stable version accumulates enough fixes to justify it.</p>\n<h2>Support</h2>\n<p>The latest stable release is always fully supported and maintained.</p>\n<p>The Valkey community will provide maintenance support, providing patch releases for bug fixes and all security fixes, for 3 years from when a minor version was first released.</p>\n<p>The Valkey community will also provide extended security support for the latest minor version of each major version for 5 years from when a version was first released.<br>The minor version to be used for this extended security support will be decided once the next major version has been launched.<br>The Valkey community will only patch security issues we believe to be possible to exploit, which will be up to the discretion of the TSC.</p>\n<p>For contacting the TSC on sensitive matters and security issues, please see <a href=\"https://github.com/valkey-io/valkey/blob/unstable/SECURITY\">SECURITY.md</a>.</p>\n<h3>List of supported versions</h3>\n<table>\n<thead>\n<tr>\n<th>Version</th>\n<th>Initial release</th>\n<th>Maintenance support end</th>\n<th>Extended Security support end</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>8.0</td>\n<td>2024-09-15</td>\n<td>2027-09-15</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td>7.2</td>\n<td>2024-04-16</td>\n<td>2027-04-16</td>\n<td>2029-04-16</td>\n</tr>\n</tbody></table>\n<h2>Unstable tree</h2>\n<p>The development tree of Valkey is located in the <code>unstable</code> branch in the <a href=\"https://github.com/valkey-io/valkey\">Valkey GitHub repository</a>.</p>\n<p>This branch is the source tree where most of the new features are under development.<br><code>unstable</code> is not considered production-ready: it may contain critical bugs, incomplete features, and is potentially unstable.</p>\n<p>However, we try hard to make sure that even the unstable branch is usable most of the time in a development environment without significant issues.</p>\n"
      },
      {
        "id": "security",
        "topicName": "Security",
        "description": "Security model and features in Valkey",
        "htmlContent": "<p>This document provides an introduction to the topic of security from the point of<br>view of Valkey. It covers the access control provided by Valkey, code security concerns,<br>attacks that can be triggered from the outside by selecting malicious inputs, and<br>other similar topics. </p>\n<p>For security-related contacts, open an issue on GitHub, or when you feel it<br>is really important to preserve the security of the communication, use the<br>GPG key at the end of this document.</p>\n<h2>Security model</h2>\n<p>Valkey is designed to be accessed by trusted clients inside trusted environments.<br>This means that usually it is not a good idea to expose the Valkey instance<br>directly to the internet or, in general, to an environment where untrusted<br>clients can directly access the Valkey TCP port or UNIX socket.</p>\n<p>For instance, in the common context of a web application implemented using Valkey<br>as a database, cache, or messaging system, the clients inside the front-end<br>(web side) of the application will query Valkey to generate pages or<br>to perform operations requested or triggered by the web application user.</p>\n<p>In this case, the web application mediates access between Valkey and<br>untrusted clients (the user browsers accessing the web application).</p>\n<p>In general, untrusted access to Valkey should<br>always be mediated by a layer implementing ACLs, validating user input,<br>and deciding what operations to perform against the Valkey instance.</p>\n<h2>Network security</h2>\n<p>Access to the Valkey port should be denied to everybody but trusted clients<br>in the network, so the servers running Valkey should be directly accessible<br>only by the computers implementing the application using Valkey.</p>\n<p>In the common case of a single computer directly exposed to the internet, such<br>as a virtualized Linux instance (Linode, EC2, ...), the Valkey port should be<br>firewalled to prevent access from the outside. Clients will still be able to<br>access Valkey using the loopback interface.</p>\n<p>Note that it is possible to bind Valkey to a single interface by adding a line<br>like the following to the <strong>valkey.conf</strong> file:</p>\n<pre><code>bind 127.0.0.1\n</code></pre>\n<p>Failing to protect the Valkey port from the outside can have a big security<br>impact because of the nature of Valkey. For instance, a single <code>FLUSHALL</code> command can be used by an external attacker to delete the whole data set.</p>\n<h2>Protected mode</h2>\n<p>Unfortunately, many users fail to protect Valkey instances from being accessed<br>from external networks. Many instances are simply left exposed on the<br>internet with public IPs. Valkey enters a special mode called <strong>protected mode</strong> when it is<br>executed with the default configuration (binding all the interfaces) and<br>without any password in order to access it. In this mode, Valkey only replies to queries from the<br>loopback interfaces, and replies to clients connecting from other<br>addresses with an error that explains the problem and how to configure<br>Valkey properly.</p>\n<p>We expect protected mode to seriously decrease the security issues caused<br>by unprotected Valkey instances executed without proper administration. However,<br>the system administrator can still ignore the error given by Valkey and<br>disable protected mode or manually bind all the interfaces.</p>\n<h2>Authentication</h2>\n<p>Valkey provides two ways to authenticate clients.<br>The recommended authentication method is via Access Control Lists, allowing named users to be created and assigned fine-grained permissions.<br>Read more about Access Control Lists <a href=\"acl\">here</a>.</p>\n<p>The legacy authentication method is enabled by editing the <strong>valkey.conf</strong> file, and providing a database password using the <code>requirepass</code> setting.<br>This password is then used by all clients.</p>\n<p>When the <code>requirepass</code> setting is enabled, Valkey will refuse any query by<br>unauthenticated clients. A client can authenticate itself by sending the<br><strong>AUTH</strong> command followed by the password.</p>\n<p>The password is set by the system administrator in clear text inside the<br>valkey.conf file. It should be long enough to prevent brute force attacks<br>for two reasons:</p>\n<ul>\n<li>Valkey is very fast at serving queries. Many passwords per second can be tested by an external client.</li>\n<li>The Valkey password is stored in the <strong>valkey.conf</strong> file and inside the client configuration. Since the system administrator does not need to remember it, the password can be very long.</li>\n</ul>\n<p>The goal of the authentication layer is to optionally provide a layer of<br>redundancy. If firewalling or any other system implemented to protect Valkey<br>from external attackers fail, an external client will still not be able to<br>access the Valkey instance without knowledge of the authentication password.</p>\n<p>Since the <code>AUTH</code> command, like every other Valkey command, is sent unencrypted, it<br>does not protect against an attacker that has enough access to the network to<br>perform eavesdropping.</p>\n<h2>TLS support</h2>\n<p>Valkey has optional support for TLS on all communication channels, including<br>client connections, replication links, and the Valkey Cluster bus protocol.</p>\n<h2>Attacks triggered by malicious inputs from external clients</h2>\n<p>There is a class of attacks that an attacker can trigger from the outside even<br>without external access to the instance. For example, an attacker might insert data into Valkey that triggers pathological (worst case)<br>algorithm complexity on data structures implemented inside Valkey internals.</p>\n<p>An attacker could supply, via a web form, a set of strings that<br>are known to hash to the same bucket in a hash table in order to turn the<br>O(1) expected time (the average time) to the O(N) worst case. This can consume more<br>CPU than expected and ultimately cause a Denial of Service.</p>\n<p>To prevent this specific attack, Valkey uses a per-execution, pseudo-random<br>seed to the hash function.</p>\n<p>Valkey implements the SORT command using the qsort algorithm. Currently,<br>the algorithm is not randomized, so it is possible to trigger a quadratic<br>worst-case behavior by carefully selecting the right set of inputs.</p>\n<h2>String escaping and NoSQL injection</h2>\n<p>The Valkey protocol has no concept of string escaping, so injection<br>is impossible under normal circumstances using a normal client library.<br>The protocol uses prefixed-length strings and is completely binary safe.</p>\n<p>Since Lua scripts executed by the <code>EVAL</code> and <code>EVALSHA</code> commands follow the<br>same rules, those commands are also safe.</p>\n<p>While it would be a strange use case, the application should avoid composing the body of the Lua script from strings obtained from untrusted sources.</p>\n<h2>Code security</h2>\n<p>Internally, Valkey uses all the well-known practices for writing secure code to<br>prevent buffer overflows, format bugs, and other memory corruption issues.</p>\n<p>Valkey does not require root privileges to run. It is recommended to<br>run it as an unprivileged <em>valkey</em> user that is only used for this purpose.</p>\n"
      },
      {
        "id": "signals",
        "topicName": "Signal handling",
        "description": "How Valkey handles common Unix signals",
        "htmlContent": "<p>This document provides information about how Valkey reacts to different POSIX signals such as <code>SIGTERM</code> and <code>SIGSEGV</code>.</p>\n<h2>SIGTERM and SIGINT</h2>\n<p>The <code>SIGTERM</code> and <code>SIGINT</code> signals tell Valkey to shut down gracefully. When the server receives this signal,<br>it does not immediately exit. Instead, it schedules<br>a shutdown similar to the one performed by the <code>SHUTDOWN</code> command. The scheduled shutdown starts as soon as possible, specifically as long as the<br>current command in execution terminates (if any), with a possible additional<br>delay of 0.1 seconds or less.</p>\n<p>If the server is blocked by a long-running Lua script,<br>kill the script with <code>SCRIPT KILL</code> if possible. The scheduled shutdown will<br>run just after the script is killed or terminates spontaneously.</p>\n<p>This shutdown process includes the following actions:</p>\n<ul>\n<li>If there are any replicas lagging behind in replication:<ul>\n<li>Pause clients attempting to write with <code>CLIENT PAUSE</code> and the <code>WRITE</code> option.</li>\n<li>Wait up to the configured <code>shutdown-timeout</code> (default 10 seconds) for replicas to catch up with the primary&#39;s replication offset.</li>\n</ul>\n</li>\n<li>If a background child is saving the RDB file or performing an AOF rewrite, the child process is killed.</li>\n<li>If the AOF is active, Valkey calls the <code>fsync</code> system call on the AOF file descriptor to flush the buffers on disk.</li>\n<li>If Valkey is configured to persist on disk using RDB files, a synchronous (blocking) save is performed. Since the save is synchronous, it doesn&#39;t use any additional memory.</li>\n<li>If the server is daemonized, the PID file is removed.</li>\n<li>If the Unix domain socket is enabled, it gets removed.</li>\n<li>The server exits with an exit code of zero.</li>\n</ul>\n<p>IF the RDB file can&#39;t be saved, the shutdown fails, and the server continues to run in order to ensure no data loss.<br>Likewise, if the user just turned on AOF, and the server triggered the first AOF rewrite in order to create the initial AOF file but this file can&#39;t be saved, the shutdown fails and the server continues to run.<br>No further attempt to shut down will be made unless a new <code>SIGTERM</code> is received or the <code>SHUTDOWN</code> command is issued.</p>\n<p>Since Redis OSS 7.0, the server waits for lagging replicas up to a configurable <code>shutdown-timeout</code>, 10 seconds by default, before shutting down.<br>This provides a best effort to minimize the risk of data loss in a situation where no save points are configured and AOF is deactivated.<br>Before version 7.0, shutting down a heavily loaded primary node in a diskless setup was more likely to result in data loss.<br>To minimize the risk of data loss in such setups, trigger a manual <code>FAILOVER</code> (or <code>CLUSTER FAILOVER</code>) to demote the primary to a replica and promote one of the replicas to a new primary before shutting down a primary node.</p>\n<h2>SIGSEGV, SIGBUS, SIGFPE and SIGILL</h2>\n<p>The following signals are handled as a Valkey crash:</p>\n<ul>\n<li>SIGSEGV</li>\n<li>SIGBUS</li>\n<li>SIGFPE</li>\n<li>SIGILL</li>\n</ul>\n<p>Once one of these signals is trapped, Valkey stops any current operation and performs the following actions:</p>\n<ul>\n<li>Adds a bug report to the log file. This includes a stack trace, dump of registers, and information about the state of clients.</li>\n<li>A fast memory test is performed as a first check of the reliability of the crashing system.</li>\n<li>If the server was daemonized, the PID file is removed.</li>\n<li>Finally the server unregisters its own signal handler for the received signal and resends the same signal to itself to make sure that the default action is performed, such as dumping the core on the file system.</li>\n</ul>\n<h2>What happens when a child process gets killed</h2>\n<p>When the child performing the Append Only File rewrite gets killed by a signal,<br>Valkey handles this as an error and discards the (probably partial or corrupted)<br>AOF file. It will attempt the rewrite again later.</p>\n<p>When the child performing an RDB save is killed, Valkey handles the<br>condition as a more severe error. While the failure of an<br>AOF file rewrite can cause AOF file enlargement, failed RDB file<br>creation reduces durability.</p>\n<p>As a result of the child producing the RDB file being killed by a signal,<br>or when the child exits with an error (non zero exit code), Valkey enters<br>a special error condition where no further write command is accepted.</p>\n<ul>\n<li>Valkey will continue to reply to read commands.</li>\n<li>Valkey will reply to all write commands with a <code>MISCONFIG</code> error.</li>\n</ul>\n<p>This error condition will persist until it becomes possible to create an RDB file successfully.</p>\n<h2>Kill the RDB file without errors</h2>\n<p>Sometimes the user may want to kill the RDB-saving child process without<br>generating an error. This can be done using the signal <code>SIGUSR1</code>. This signal is handled in a special way:<br>it kills the child process like any other signal, but the parent process will<br>not detect this as a critical error and will continue to serve write<br>requests.</p>\n"
      }
    ]
  },
  {
    "title": "PERFORMANCE & MONITORING",
    "items": [
      {
        "id": "benchmark",
        "topicName": "Benchmarking tool",
        "description": "Using the valkey-benchmark utility on a Valkey server\n",
        "htmlContent": "<h2>Usage</h2>\n<p><strong><code>valkey-benchmark</code></strong> [ <em>OPTIONS</em> ] [ <em>COMMAND</em> <em>ARGS</em>... ]</p>\n<h2>Description</h2>\n<p>Valkey includes the <code>valkey-benchmark</code> utility that simulates running commands done<br>by N clients while at the same time sending M total queries. The utility provides<br>a default set of tests, or you can supply a custom set of tests.</p>\n<h2>Options</h2>\n<p><strong><code>-h</code></strong> <em>hostname</em><br>: Server hostname (default 127.0.0.1)</p>\n<p><strong><code>-p</code></strong> <em>port</em><br>: Server port (default 6379)</p>\n<p><strong><code>-s</code></strong> <em>socket</em><br>: Server socket (overrides host and port)</p>\n<p><strong><code>-a</code></strong> <em>password</em><br>: Password for Valkey Auth</p>\n<p><strong><code>--user</code></strong> <em>username</em><br>: Used to send ACL style &#39;AUTH username pass&#39;. Needs -a.</p>\n<p><strong><code>-u</code></strong> <em>uri</em><br>: Server URI on format <code>valkey://user:password@host:port/dbnum</code>.<br>  User, password and dbnum are optional. For authentication<br>  without a username, use username &#39;default&#39;. For TLS, use<br>  the scheme &#39;valkeys&#39;.</p>\n<p><strong><code>-c</code></strong> <em>clients</em><br>: Number of parallel connections (default 50).<br>  Note: If <code>--cluster</code> is used then number of clients has to be<br>  the same or higher than the number of nodes.</p>\n<p><strong><code>-n</code></strong> <em>requests</em><br>: Total number of requests (default 100000)</p>\n<p><strong><code>-d</code></strong> <em>size</em><br>: Data size of SET/GET value in bytes (default 3)</p>\n<p><strong><code>--dbnum</code></strong> <em>db</em><br>: SELECT the specified db number (default 0)</p>\n<p><strong><code>-3</code></strong><br>: Start session in RESP3 protocol mode.</p>\n<p><strong><code>--threads</code></strong> <em>num</em><br>: Enable multi-thread mode.</p>\n<p><strong><code>--cluster</code></strong><br>: Enable cluster mode.<br>  If the command is supplied on the command line in cluster<br>  mode, the key must contain &quot;{tag}&quot;. Otherwise, the<br>  command will not be sent to the right cluster node.</p>\n<p><strong><code>--rfr</code></strong> <em>mode</em><br>: Enable read from replicas in cluster mode.<br>  This command must be used with the <code>--cluster</code> option.<br>  There are three modes for reading from replicas:</p>\n<p>  <strong>no</strong> - sends read requests to primaries only (default).</p>\n<p>  <strong>yes</strong> - sends read requests to replicas only.</p>\n<p>  <strong>all</strong> - sends read requests to all nodes.</p>\n<p>   Since write commands will be rejected by replicas,<br>   it is recommended to enable read from replicas only for read command tests.</p>\n<p><strong><code>--enable-tracking</code></strong><br>: Send CLIENT TRACKING ON before starting benchmark.</p>\n<p><strong><code>-k</code></strong> <em>boolean</em><br>: 1=keep alive 0=reconnect (default 1)</p>\n<p><strong><code>-r</code></strong> <em>keyspacelen</em><br>: Use random keys for SET/GET/INCR, random values for SADD,<br>  random members and scores for ZADD.<br>  Using this option the benchmark will expand the string<br>  <code>__rand_int__</code> inside an argument with a 12 digits number in<br>  the specified range from 0 to keyspacelen - 1. The<br>  substitution changes every time a command is executed.<br>  Default tests use this to hit random keys in the specified<br>  range.<br>  Note: If <code>-r</code> is omitted, all commands in a benchmark will<br>  use the same key.</p>\n<p><strong><code>-P</code></strong> <em>numreq</em><br>: Pipeline <em>numreq</em> requests. Default 1 (no pipeline).</p>\n<p><strong><code>-q</code></strong><br>: Quiet. Just show query/sec values</p>\n<p><strong><code>--precision</code></strong><br>: Number of decimal places to display in latency output (default 0)</p>\n<p><strong><code>--csv</code></strong><br>: Output in CSV format</p>\n<p><strong><code>-l</code></strong><br>: Loop. Run the tests forever</p>\n<p><strong><code>-t</code></strong> <em>tests</em><br>: Only run the comma separated list of tests. The test<br>  names are the same as the ones produced as output.<br>  The <code>-t</code> option is ignored if a specific command is supplied<br>  on the command line.</p>\n<p><strong><code>-I</code></strong><br>: Idle mode. Just open N idle connections and wait.</p>\n<p><strong><code>-x</code></strong><br>: Read last argument from STDIN.</p>\n<p><strong><code>--seed</code></strong> <em>num</em><br>: Set the seed for random number generator. Default seed is based on time.</p>\n<p><strong><code>--tls</code></strong><br>: Establish a secure TLS connection.</p>\n<p><strong><code>--sni</code></strong> <em>host</em><br>: Server name indication for TLS.</p>\n<p><strong><code>--cacert</code></strong> <em>file</em><br>: CA Certificate file to verify with.</p>\n<p><strong><code>--cacertdir</code></strong> <em>dir</em><br>: Directory where trusted CA certificates are stored.<br>  If neither cacert nor cacertdir are specified, the default<br>  system-wide trusted root certs configuration will apply.</p>\n<p><strong><code>--insecure</code></strong><br>: Allow insecure TLS connection by skipping cert validation.</p>\n<p><strong><code>--cert</code></strong> <em>file</em><br>: Client certificate to authenticate with.</p>\n<p><strong><code>--key</code></strong> <em>file</em><br>: Private key file to authenticate with.</p>\n<p><strong><code>--tls-ciphers</code></strong> <em>list</em><br>: Sets the list of preferred ciphers (TLSv1.2 and below)<br>  in order of preference from highest to lowest separated by colon (&quot;:&quot;).<br>  See the <strong>ciphers</strong>(1ssl) manpage for more information about the syntax of this string.</p>\n<p><strong><code>--tls-ciphersuites</code></strong> <em>list</em><br>: Sets the list of preferred ciphersuites (TLSv1.3)<br>  in order of preference from highest to lowest separated by colon (&quot;:&quot;).<br>  See the <strong>ciphers</strong>(1ssl) manpage for more information about the syntax of this string,<br>  and specifically for TLSv1.3 ciphersuites.</p>\n<p><strong><code>--help</code></strong><br>: Output help and exit.</p>\n<p><strong><code>--version</code></strong><br>: Output version and exit.</p>\n<h2>Examples</h2>\n<p>Run the benchmark with the default configuration against 127.0.0.1:6379. You<br>need to have a running Valkey instance before launching the benchmark:</p>\n<pre><code>$ valkey-benchmark\n</code></pre>\n<p>Run a benchmark with 20 parallel clients, pipelining 10 commands at a time,<br>using 2 threads and less verbose output:</p>\n<pre><code>$ valkey-benchmark -c 20 -P 10 --threads 2 -q\n</code></pre>\n<p>Use 20 parallel clients, for a total of 100k requests, against 192.168.1.1:</p>\n<pre><code>$ valkey-benchmark -h 192.168.1.1 -p 6379 -n 100000 -c 20\n</code></pre>\n<p>Fill 127.0.0.1:6379 with about 1 million keys only using the SET test:</p>\n<pre><code>$ valkey-benchmark -t set -n 1000000 -r 100000000\n</code></pre>\n<p>Benchmark 127.0.0.1:6379 for a few commands producing CSV output:</p>\n<pre><code>$ valkey-benchmark -t ping,set,get -n 100000 --csv\n</code></pre>\n<p>Benchmark a specific command line:</p>\n<pre><code>$ valkey-benchmark -r 10000 -n 10000 eval &#39;return redis.call(&quot;ping&quot;)&#39; 0\n</code></pre>\n<p>Fill a list with 10000 random elements:</p>\n<pre><code>$ valkey-benchmark -r 10000 -n 10000 lpush mylist __rand_int__\n</code></pre>\n<p>On user specified command lines <code>__rand_int__</code> is replaced with a random integer<br>with a range of values selected by the <code>-r</code> option.</p>\n<h3>Running only a subset of the tests</h3>\n<p>You don&#39;t need to run all the default tests every time you execute <code>valkey-benchmark</code>.<br>For example, to select only a subset of tests, use the <code>-t</code> option<br>as in the following example:</p>\n<pre><code>$ valkey-benchmark -t set,lpush -n 100000 -q\nSET: 74239.05 requests per second\nLPUSH: 79239.30 requests per second\n</code></pre>\n<p>This example runs the tests for the <code>SET</code> and <code>LPUSH</code> commands and uses quiet mode (see the <code>-q</code> switch).</p>\n<p>You can even benchmark a specific command:</p>\n<pre><code>$ valkey-benchmark -n 100000 -q script load &quot;server.call(&#39;set&#39;,&#39;foo&#39;,&#39;bar&#39;)&quot;\nscript load server.call(&#39;set&#39;,&#39;foo&#39;,&#39;bar&#39;): 69881.20 requests per second\n</code></pre>\n<h3>Selecting the size of the key space</h3>\n<p>By default, the benchmark runs against a single key. In Valkey the difference<br>between such a synthetic benchmark and a real one is not huge since it is an<br>in-memory system, however it is possible to stress cache misses and in general<br>to simulate a more real-world work load by using a large key space.</p>\n<p>This is obtained by using the <code>-r</code> switch. For instance if I want to run<br>one million SET operations, using a random key for every operation out of<br>100k possible keys, I&#39;ll use the following command line:</p>\n<pre><code>$ valkey-cli flushall\nOK\n\n$ valkey-benchmark -t set -r 100000 -n 1000000\n====== SET ======\n  1000000 requests completed in 13.86 seconds\n  50 parallel clients\n  3 bytes payload\n  keep alive: 1\n\n99.76% `&lt;=` 1 milliseconds\n99.98% `&lt;=` 2 milliseconds\n100.00% `&lt;=` 3 milliseconds\n100.00% `&lt;=` 3 milliseconds\n72144.87 requests per second\n\n$ valkey-cli dbsize\n(integer) 99993\n</code></pre>\n<h3>Using pipelining</h3>\n<p>By default every client (the benchmark simulates 50 clients if not otherwise<br>specified with <code>-c</code>) sends the next command only when the reply of the previous<br>command is received, this means that the server will likely need a read call<br>in order to read each command from every client. Also RTT is paid as well.</p>\n<p>Valkey supports <a href=\"pipelining\">pipelining</a>, so it is possible to send<br>multiple commands at once, a feature often exploited by real world applications.<br>Valkey pipelining is able to dramatically improve the number of operations per<br>second a server is able do deliver.</p>\n<p>Consider this example of running the benchmark using a<br>pipelining of 16 commands:</p>\n<pre><code>$ valkey-benchmark -n 1000000 -t set,get -P 16 -q\nSET: 403063.28 requests per second\nGET: 508388.41 requests per second\n</code></pre>\n<p>Using pipelining results in a significant increase in performance.</p>\n<h3>Pitfalls and misconceptions</h3>\n<p>The first point is obvious: the golden rule of a useful benchmark is to<br>only compare apples and apples. You can compare different versions of Valkey on the same workload or the same version of Valkey, but with<br>different options. If you plan to compare Valkey to something else, then it is<br>important to evaluate the functional and technical differences, and take them<br>in account.</p>\n<ul>\n<li>Valkey is a server: all commands involve network or IPC round trips. It is meaningless to compare it to embedded data stores, because the cost of most operations is primarily in network/protocol management.</li>\n<li>Valkey commands return an acknowledgment for all usual commands. Some other data stores do not. Comparing Valkey to stores involving one-way queries is only mildly useful.</li>\n<li>Naively iterating on synchronous Valkey commands does not benchmark Valkey itself, but rather measure your network (or IPC) latency and the client library intrinsic latency. To really test Valkey, you need multiple connections (like valkey-benchmark) and/or to use pipelining to aggregate several commands and/or multiple threads or processes.</li>\n<li>Valkey is an in-memory data store with some optional persistence options. If you plan to compare it to transactional servers (MySQL, PostgreSQL, etc ...), then you should consider activating AOF and decide on a suitable fsync policy.</li>\n<li>Valkey primarily operates as a single-threaded server from the POV of commands execution. While the server can employ threads for I/O operations and command parsing, the core command execution remains sequential. For CPU-intensive workloads requiring multiple cores, users should consider running multiple Valkey instances in parallel. It is not really fair to compare one single Valkey instance to a multi-threaded data store.</li>\n</ul>\n<p>The <code>valkey-benchmark</code> program is a quick and useful way to get some figures and<br>evaluate the performance of a Valkey instance on a given hardware. However,<br>by default, it does not represent the maximum throughput a Valkey instance can<br>sustain. Actually, by using pipelining and a fast client (hiredis), it is fairly<br>easy to write a program generating more throughput than valkey-benchmark. The<br>default behavior of valkey-benchmark is to achieve throughput by exploiting<br>concurrency only (i.e. it creates several connections to the server).<br>It does not use pipelining or any parallelism at all (one pending query per<br>connection at most, and no multi-threading), if not explicitly enabled via<br>the <code>-P</code> parameter. So in some way using <code>valkey-benchmark</code> and, triggering, for<br>example, a <code>BGSAVE</code> operation in the background at the same time, will provide<br>the user with numbers more near to the <em>worst case</em> than to the best case.</p>\n<p>To run a benchmark using pipelining mode (and achieve higher throughput),<br>you need to explicitly use the -P option. Please note that it is still a<br>realistic behavior since a lot of Valkey based applications actively use<br>pipelining to improve performance. However you should use a pipeline size that<br>is more or less the average pipeline length you&#39;ll be able to use in your<br>application in order to get realistic numbers.</p>\n<p>The benchmark should apply the same operations, and work in the same way<br>with the multiple data stores you want to compare. It is absolutely pointless to<br>compare the result of valkey-benchmark to the result of another benchmark<br>program and extrapolate.</p>\n<p>For instance, Valkey and memcached in single-threaded mode can be compared on<br>GET/SET operations. Both are in-memory data stores, working mostly in the same<br>way at the protocol level. Provided their respective benchmark application is<br>aggregating queries in the same way (pipelining) and use a similar number of<br>connections, the comparison is actually meaningful.</p>\n<p>When you&#39;re benchmarking a high-performance, in-memory database like Valkey,<br>it may be difficult to saturate<br>the server. Sometimes, the performance bottleneck is on the client side,<br>and not the server-side. In that case, the client (i.e., the benchmarking program itself)<br>must be fixed, or perhaps scaled out, to reach the maximum throughput.</p>\n<h3>Factors impacting Valkey performance</h3>\n<p>There are multiple factors having direct consequences on Valkey performance.<br>We mention them here, since they can alter the result of any benchmarks.<br>Please note however, that a typical Valkey instance running on a low end,<br>untuned box usually provides good enough performance for most applications.</p>\n<ul>\n<li><p>Network bandwidth and latency usually have a direct impact on the performance.<br>It is a good practice to use the ping program to quickly check the latency<br>between the client and server hosts is normal before launching the benchmark.<br>Regarding the bandwidth, it is generally useful to estimate<br>the throughput in Gbit/s and compare it to the theoretical bandwidth<br>of the network. For instance a benchmark setting 4 KB strings<br>in Valkey at 100000 q/s, would actually consume 3.2 Gbit/s of bandwidth<br>and probably fit within a 10 Gbit/s link, but not a 1 Gbit/s one. In many real<br>world scenarios, Valkey throughput is limited by the network well before being<br>limited by the CPU. To consolidate several high-throughput Valkey instances<br>on a single server, it worth considering putting a 10 Gbit/s NIC<br>or multiple 1 Gbit/s NICs with TCP/IP bonding.</p>\n</li>\n<li><p>CPU is another important factor.</p>\n</li>\n<li><p>Speed of RAM and memory bandwidth seem less critical for global performance<br>especially for small objects. For large objects (&gt;10 KB), it may become<br>noticeable though. Usually, it is not really cost-effective to buy expensive<br>fast memory modules to optimize Valkey.</p>\n</li>\n<li><p>Valkey runs slower on a VM compared to running without virtualization using<br>the same hardware. If you have the chance to run Valkey on a physical machine<br>this is preferred. However this does not mean that Valkey is slow in<br>virtualized environments, the delivered performances are still very good<br>and most of the serious performance issues you may incur in virtualized<br>environments are due to over-provisioning, non-local disks with high latency,<br>or old hypervisor software that have slow <code>fork</code> syscall implementation.</p>\n</li>\n<li><p>When the server and client benchmark programs run on the same box, both<br>the TCP/IP loopback and unix domain sockets can be used. Depending on the<br>platform, unix domain sockets can achieve around 50% more throughput than<br>the TCP/IP loopback (on Linux for instance). The default behavior of<br>valkey-benchmark is to use the TCP/IP loopback.</p>\n</li>\n<li><p>The performance benefit of unix domain sockets compared to TCP/IP loopback<br>tends to decrease when pipelining is heavily used (i.e. long pipelines).</p>\n</li>\n<li><p>When an ethernet network is used to access Valkey, aggregating commands using<br>pipelining is especially efficient when the size of the data is kept under<br>the ethernet packet size (about 1500 bytes). Actually, processing 10 bytes,<br>100 bytes, or 1000 bytes queries almost result in the same throughput.<br>See the graph below.</p>\n<p>  <img src=\"Data_size.png\" alt=\"Data size impact\"></p>\n</li>\n<li><p>On multi CPU sockets servers, Valkey performance becomes dependent on the<br>NUMA configuration and process location. The most visible effect is that<br>valkey-benchmark results seem non-deterministic because client and server<br>processes are distributed randomly on the cores. To get deterministic results,<br>it is required to use process placement tools (on Linux: taskset or numactl).<br>The most efficient combination is always to put the client and server on two<br>different cores of the same CPU to benefit from the L3 cache.<br>Here are some results of 4 KB SET benchmark for 3 server CPUs (AMD Istanbul,<br>Intel Nehalem EX, and Intel Westmere) with different relative placements.<br>Please note this benchmark is not meant to compare CPU models between themselves<br>(CPUs exact model and frequency are therefore not disclosed).</p>\n<p>  <img src=\"NUMA_chart.gif\" alt=\"NUMA chart\"></p>\n</li>\n<li><p>With high-end configurations, the number of client connections is also an<br>important factor. Being based on epoll/kqueue, the Valkey event loop is quite<br>scalable. Valkey has already been benchmarked at more than 60000 connections,<br>and was still able to sustain 50000 q/s in these conditions. As a rule of thumb,<br>an instance with 30000 connections can only process half the throughput<br>achievable with 100 connections. Here is an example showing the throughput of<br>a Valkey instance per number of connections:</p>\n<p>  <img src=\"Connections_chart.png\" alt=\"connections chart\"></p>\n</li>\n<li><p>With high-end configurations, it is possible to achieve higher throughput by<br>tuning the NIC(s) configuration and associated interruptions. Best throughput<br>is achieved by setting an affinity between Rx/Tx NIC queues and CPU cores,<br>and activating RPS (Receive Packet Steering) support. More information in this<br><a href=\"https://groups.google.com/forum/#!msg/redis-db/gUhc19gnYgc/BruTPCOroiMJ\">thread</a>.<br>Jumbo frames may also provide a performance boost when large objects are used.</p>\n</li>\n<li><p>Depending on the platform, Valkey can be compiled against different memory<br>allocators (libc malloc, jemalloc, tcmalloc), which may have different behaviors<br>in term of raw speed, internal and external fragmentation.<br>If you did not compile Valkey yourself, you can use the INFO command to check<br>the <code>mem_allocator</code> field. Please note most benchmarks do not run long enough to<br>generate significant external fragmentation (contrary to production Valkey<br>instances).</p>\n</li>\n</ul>\n<h3>Other things to consider</h3>\n<p>One important goal of any benchmark is to get reproducible results, so they<br>can be compared to the results of other tests.</p>\n<ul>\n<li>A good practice is to try to run tests on isolated hardware as much as possible.<br>If it is not possible, then the system must be monitored to check the benchmark<br>is not impacted by some external activity.</li>\n<li>Some configurations (desktops and laptops for sure, some servers as well)<br>have a variable CPU core frequency mechanism. The policy controlling this<br>mechanism can be set at the OS level. Some CPU models are more aggressive than<br>others at adapting the frequency of the CPU cores to the workload. To get<br>reproducible results, it is better to set the highest possible fixed frequency<br>for all the CPU cores involved in the benchmark.</li>\n<li>An important point is to size the system accordingly to the benchmark.<br>The system must have enough RAM and must not swap. On Linux, do not forget<br>to set the <code>overcommit_memory</code> parameter correctly. Please note 32 and 64 bit<br>Valkey instances do not have the same memory footprint.</li>\n<li>If you plan to use RDB or AOF for your benchmark, please check there is no other<br>I/O activity in the system. Avoid putting RDB or AOF files on NAS or NFS shares,<br>or on any other devices impacting your network bandwidth and/or latency<br>(for instance, EBS on Amazon EC2).</li>\n<li>Set Valkey logging level (loglevel parameter) to warning or notice. Avoid putting<br>the generated log file on a remote filesystem.</li>\n<li>Avoid using monitoring tools which can alter the result of the benchmark. For<br>instance using INFO at regular interval to gather statistics is probably fine,<br>but MONITOR will impact the measured performance significantly.</li>\n<li>When running <code>valkey-benchmark</code> on the same machine as the <code>valkey-server</code><br>being tested, you may need to run the benchmark with at least two threads<br>(<code>--threads 2</code>) to prevent the benchmarking tool itself from being the<br>bottleneck, i.e. prevent that <code>valkey-benchmark</code> is running on 100% CPU while<br><code>valkey-server</code> is using less than 100% CPU.</li>\n</ul>\n<h3>Other Valkey benchmarking tools</h3>\n<p>There are several third-party tools that can be used for benchmarking Valkey. Refer to each tool&#39;s<br>documentation for more information about its goals and capabilities.</p>\n<ul>\n<li><a href=\"https://github.com/redislabs/memtier_benchmark\">memtier_benchmark</a> from <a href=\"https://twitter.com/RedisInc\">Redis Ltd.</a> is a NoSQL Valkey, Redis and Memcache traffic generation and benchmarking tool.</li>\n<li><a href=\"https://github.com/twitter/rpc-perf\">rpc-perf</a> from <a href=\"https://twitter.com/twitter\">Twitter</a> is a tool for benchmarking RPC services that supports Valkey and Memcache.</li>\n<li><a href=\"https://github.com/brianfrankcooper/YCSB\">YCSB</a> from <a href=\"https://twitter.com/Yahoo\">Yahoo @Yahoo</a> is a benchmarking framework with clients to many databases, including Valkey.</li>\n</ul>\n<h2>See also</h2>\n<p><a href=\"cli\">valkey-cli</a>, <a href=\"server\">valkey-server</a></p>\n"
      },
      {
        "id": "indexing",
        "topicName": "Secondary indexing",
        "description": "Building secondary indexes in Valkey\n",
        "htmlContent": "<p>Valkey is not exactly a key-value store, since values can be complex data structures. However it has an external key-value shell: at API level data is addressed by the key name. It is fair to say that, natively, Valkey only offers <em>primary key access</em>. However since Valkey is a data structures server, its capabilities can be used for indexing, in order to create secondary indexes of different kinds, including composite (multi-column) indexes.</p>\n<p>This document explains how it is possible to create indexes in Valkey using the following data structures:</p>\n<ul>\n<li>Sorted sets to create secondary indexes by ID or other numerical fields.</li>\n<li>Sorted sets with lexicographical ranges for creating more advanced secondary indexes, composite indexes and graph traversal indexes.</li>\n<li>Sets for creating random indexes.</li>\n<li>Lists for creating simple iterable indexes and last N items indexes.</li>\n</ul>\n<p>Implementing and maintaining indexes with Valkey is an advanced topic, so most<br>users that need to perform complex queries on data should understand if they<br>are better served by a relational store. However often, especially in caching<br>scenarios, there is the explicit need to store indexed data into Valkey in order to speedup common queries which require some form of indexing in order to be executed.</p>\n<h1>Simple numerical indexes with sorted sets</h1>\n<p>The simplest secondary index you can create with Valkey is by using the<br>sorted set data type, which is a data structure representing a set of<br>elements ordered by a floating point number which is the <em>score</em> of<br>each element. Elements are ordered from the smallest to the highest score.</p>\n<p>Since the score is a double precision float, indexes you can build with<br>vanilla sorted sets are limited to things where the indexing field is a number<br>within a given range.</p>\n<p>The two commands to build these kind of indexes are <code>ZADD</code> and<br><code>ZRANGE</code> with the <code>BYSCORE</code> argument to respectively add items and retrieve items within a<br>specified range.</p>\n<p>For instance, it is possible to index a set of person names by their<br>age by adding element to a sorted set. The element will be the name of the<br>person and the score will be the age.</p>\n<pre><code>ZADD myindex 25 Manuel\nZADD myindex 18 Anna\nZADD myindex 35 Jon\nZADD myindex 67 Helen\n</code></pre>\n<p>In order to retrieve all persons with an age between 20 and 40, the following<br>command can be used:</p>\n<pre><code>ZRANGE myindex 20 40 BYSCORE\n1) &quot;Manuel&quot;\n2) &quot;Jon&quot;\n</code></pre>\n<p>By using the <strong>WITHSCORES</strong> option of <code>ZRANGE</code> it is also possible<br>to obtain the scores associated with the returned elements.</p>\n<p>The <code>ZCOUNT</code> command can be used in order to retrieve the number of elements<br>within a given range, without actually fetching the elements, which is also<br>useful, especially given the fact the operation is executed in logarithmic<br>time regardless of the size of the range.</p>\n<p>Ranges can be inclusive or exclusive, please refer to the <code>ZRANGE</code><br>command documentation for more information.</p>\n<p><strong>Note</strong>: Using the <code>ZRANGE</code> with the <code>BYSCORE</code> and <code>REV</code> arguments, it is possible to query a range in<br>reversed order, which is often useful when data is indexed in a given<br>direction (ascending or descending) but we want to retrieve information<br>the other way around.</p>\n<h2>Using objects IDs as associated values</h2>\n<p>In the above example we associated names to ages. However in general we<br>may want to index some field of an object which is stored elsewhere.<br>Instead of using the sorted set value directly to store the data associated<br>with the indexed field, it is possible to store just the ID of the object.</p>\n<p>For example I may have Hashes representing users. Each user is<br>represented by a single key, directly accessible by ID:</p>\n<pre><code>HSET user:1 id 1 username antirez ctime 1444809424 age 38\nHSET user:2 id 2 username maria ctime 1444808132 age 42\nHSET user:3 id 3 username jballard ctime 1443246218 age 33\n</code></pre>\n<p>If I want to create an index in order to query users by their age, I<br>could do:</p>\n<pre><code>ZADD user.age.index 38 1\nZADD user.age.index 42 2\nZADD user.age.index 33 3\n</code></pre>\n<p>This time the value associated with the score in the sorted set is the<br>ID of the object. So once I query the index with <code>ZRANGE</code> with the <code>BYSCORE</code> argument, I&#39;ll<br>also have to retrieve the information I need with <code>HGETALL</code> or similar<br>commands. The obvious advantage is that objects can change without touching<br>the index, as long as we don&#39;t change the indexed field.</p>\n<p>In the next examples we&#39;ll almost always use IDs as values associated with<br>the index, since this is usually the more sounding design, with a few<br>exceptions.</p>\n<h2>Updating simple sorted set indexes</h2>\n<p>Often we index things which change over time. In the above<br>example, the age of the user changes every year. In such a case it would<br>make sense to use the birth date as index instead of the age itself,<br>but there are other cases where we simply want some field to change from<br>time to time, and the index to reflect this change.</p>\n<p>The <code>ZADD</code> command makes updating simple indexes a very trivial operation<br>since re-adding back an element with a different score and the same value<br>will simply update the score and move the element at the right position,<br>so if the user <code>antirez</code> turned 39 years old, in order to update the<br>data in the hash representing the user, and in the index as well, we need<br>to execute the following two commands:</p>\n<pre><code>HSET user:1 age 39\nZADD user.age.index 39 1\n</code></pre>\n<p>The operation may be wrapped in a <code>MULTI</code>/<code>EXEC</code> transaction in order to<br>make sure both fields are updated or none.</p>\n<h2>Turning multi dimensional data into linear data</h2>\n<p>Indexes created with sorted sets are able to index only a single numerical<br>value. Because of this you may think it is impossible to index something<br>which has multiple dimensions using this kind of indexes, but actually this<br>is not always true. If you can efficiently represent something<br>multi-dimensional in a linear way, they it is often possible to use a simple<br>sorted set for indexing.</p>\n<p>For example the <a href=\"../commands/geoadd\">Valkey geo indexing API</a> uses a sorted<br>set to index places by latitude and longitude using a technique called<br><a href=\"https://en.wikipedia.org/wiki/Geohash\">Geo hash</a>. The sorted set score<br>represents alternating bits of longitude and latitude, so that we map the<br>linear score of a sorted set to many small <em>squares</em> in the earth surface.<br>By doing an 8+1 style center plus neighborhoods search it is possible to<br>retrieve elements by radius.</p>\n<h2>Limits of the score</h2>\n<p>Sorted set elements scores are double precision floats. It means that<br>they can represent different decimal or integer values with different<br>errors, because they use an exponential representation internally.<br>However what is interesting for indexing purposes is that the score is<br>always able to represent without any error numbers between -9007199254740992<br>and 9007199254740992, which is <code>-/+ 2^53</code>.</p>\n<p>When representing much larger numbers, you need a different form of indexing<br>that is able to index numbers at any precision, called a lexicographical<br>index.</p>\n<h1>Lexicographical indexes</h1>\n<p>Sorted Sets have an interesting property. When elements are added<br>with the same score, they are sorted lexicographically, comparing the<br>strings as binary data with the <code>memcmp()</code> function.</p>\n<p>For people that don&#39;t know the C language nor the <code>memcmp</code> function, what<br>it means is that elements with the same score are sorted comparing the<br>raw values of their bytes, byte after byte. If the first byte is the same,<br>the second is checked and so forth. If the common prefix of two strings is<br>the same then the longer string is considered the greater of the two,<br>so &quot;foobar&quot; is greater than &quot;foo&quot;.</p>\n<p>There are commands such as <code>ZRANGE</code> and <code>ZLEXCOUNT</code> that<br>are able to query and count ranges in a lexicographically fashion, assuming<br>they are used with sorted sets where all the elements have the same score.</p>\n<p>This Valkey feature is basically equivalent to a <code>b-tree</code> data structure which<br>is often used in order to implement indexes with traditional databases.<br>As you can guess, because of this, it is possible to use this Valkey data<br>structure in order to implement pretty fancy indexes.</p>\n<p>Before we dive into using lexicographical indexes, let&#39;s check how<br>sorted sets behave in this special mode of operation. Since we need to<br>add elements with the same score, we&#39;ll always use the special score of<br>zero.</p>\n<pre><code>ZADD myindex 0 baaa\nZADD myindex 0 abbb\nZADD myindex 0 aaaa\nZADD myindex 0 bbbb\n</code></pre>\n<p>Fetching all the elements from the sorted set immediately reveals that they<br>are ordered lexicographically.</p>\n<pre><code>ZRANGE myindex 0 -1\n1) &quot;aaaa&quot;\n2) &quot;abbb&quot;\n3) &quot;baaa&quot;\n4) &quot;bbbb&quot;\n</code></pre>\n<p>Now we can use <code>ZRANGE</code> with the <code>BYLEX</code> argument in order to perform range queries.</p>\n<pre><code>ZRANGE myindex [a (b BYLEX\n1) &quot;aaaa&quot;\n2) &quot;abbb&quot;\n</code></pre>\n<p>Note that in the range queries we prefixed the <code>min</code> and <code>max</code> elements<br>identifying the range with the special characters <code>[</code> and <code>(</code>.<br>This prefixes are mandatory, and they specify if the elements<br>of the range are inclusive or exclusive. So the range <code>[a (b</code> means give me<br>all the elements lexicographically between <code>a</code> inclusive and <code>b</code> exclusive,<br>which are all the elements starting with <code>a</code>.</p>\n<p>There are also two more special characters indicating the infinitely negative<br>string and the infinitely positive string, which are <code>-</code> and <code>+</code>.</p>\n<pre><code>ZRANGE myindex [b + BYLEX\n1) &quot;baaa&quot;\n2) &quot;bbbb&quot;\n</code></pre>\n<p>That&#39;s it basically. Let&#39;s see how to use these features to build indexes.</p>\n<h2>A first example: completion</h2>\n<p>An interesting application of indexing is completion. Completion is what<br>happens when you start typing your query into a search engine: the user<br>interface will anticipate what you are likely typing, providing common<br>queries that start with the same characters.</p>\n<p>A naive approach to completion is to just add every single query we<br>get from the user into the index. For example if the user searches <code>banana</code><br>we&#39;ll just do:</p>\n<pre><code>ZADD myindex 0 banana\n</code></pre>\n<p>And so forth for each search query ever encountered. Then when we want to<br>complete the user input, we execute a range query using <code>ZRANGE</code> with the <code>BYLEX</code> argument.<br>Imagine the user is typing &quot;bit&quot; inside the search form, and we want to<br>offer possible search keywords starting for &quot;bit&quot;. We send Valkey a command<br>like that:</p>\n<pre><code>ZRANGE myindex &quot;[bit&quot; &quot;[bit\\xff&quot; BYLEX\n</code></pre>\n<p>Basically we create a range using the string the user is typing right now<br>as start, and the same string plus a trailing byte set to 255, which is <code>\\xff</code> in the example, as the end of the range. This way we get all the strings that start for the string the user is typing.</p>\n<p>Note that we don&#39;t want too many items returned, so we may use the <strong>LIMIT</strong> option in order to reduce the number of results.</p>\n<h2>Adding frequency into the mix</h2>\n<p>The above approach is a bit naive, because all the user searches are the same<br>in this way. In a real system we want to complete strings according to their<br>frequency: very popular searches will be proposed with a higher probability<br>compared to search strings typed very rarely.</p>\n<p>In order to implement something which depends on the frequency, and at the<br>same time automatically adapts to future inputs, by purging searches that<br>are no longer popular, we can use a very simple <em>streaming algorithm</em>.</p>\n<p>To start, we modify our index in order to store not just the search term,<br>but also the frequency the term is associated with. So instead of just adding<br><code>banana</code> we add <code>banana:1</code>, where 1 is the frequency.</p>\n<pre><code>ZADD myindex 0 banana:1\n</code></pre>\n<p>We also need logic in order to increment the index if the search term<br>already exists in the index, so what we&#39;ll actually do is something like<br>that:</p>\n<pre><code>ZRANGE myindex &quot;[banana:&quot; + BYLEX LIMIT 0 1\n1) &quot;banana:1&quot;\n</code></pre>\n<p>This will return the single entry of <code>banana</code> if it exists. Then we<br>can increment the associated frequency and send the following two<br>commands:</p>\n<pre><code>ZREM myindex 0 banana:1\nZADD myindex 0 banana:2\n</code></pre>\n<p>Note that because it is possible that there are concurrent updates, the<br>above three commands should be send via a <a href=\"../commands/eval\">Lua script</a><br>instead, so that the Lua script will atomically get the old count and<br>re-add the item with incremented score.</p>\n<p>So the result will be that, every time a user searches for <code>banana</code> we&#39;ll<br>get our entry updated.</p>\n<p>There is more: our goal is to just have items searched very frequently.<br>So we need some form of purging. When we actually query the index<br>in order to complete the user input, we may see something like that:</p>\n<pre><code>ZRANGE myindex &quot;[banana:&quot; + BYLEX LIMIT 0 10\n1) &quot;banana:123&quot;\n2) &quot;banaooo:1&quot;\n3) &quot;banned user:49&quot;\n4) &quot;banning:89&quot;\n</code></pre>\n<p>Apparently nobody searches for &quot;banaooo&quot;, for example, but the query was<br>performed a single time, so we end presenting it to the user.</p>\n<p>This is what we can do. Out of the returned items, we pick a random one,<br>decrement its score by one, and re-add it with the new score.<br>However if the score reaches 0, we simply remove the item from the list.<br>You can use much more advanced systems, but the idea is that the index in<br>the long run will contain top searches, and if top searches will change over<br>the time it will adapt automatically.</p>\n<p>A refinement to this algorithm is to pick entries in the list according to<br>their weight: the higher the score, the less likely entries are picked<br>in order to decrement its score, or evict them.</p>\n<h2>Normalizing strings for case and accents</h2>\n<p>In the completion examples we always used lowercase strings. However<br>reality is much more complex than that: languages have capitalized names,<br>accents, and so forth.</p>\n<p>One simple way do deal with this issues is to actually normalize the<br>string the user searches. Whatever the user searches for &quot;Banana&quot;,<br>&quot;BANANA&quot; or &quot;Ba&#39;nana&quot; we may always turn it into &quot;banana&quot;.</p>\n<p>However sometimes we may like to present the user with the original<br>item typed, even if we normalize the string for indexing. In order to<br>do this, what we do is to change the format of the index so that instead<br>of just storing <code>term:frequency</code> we store <code>normalized:frequency:original</code><br>like in the following example:</p>\n<pre><code>ZADD myindex 0 banana:273:Banana\n</code></pre>\n<p>Basically we add another field that we&#39;ll extract and use only for<br>visualization. Ranges will always be computed using the normalized strings<br>instead. This is a common trick which has multiple applications.</p>\n<h2>Adding auxiliary information in the index</h2>\n<p>When using a sorted set in a direct way, we have two different attributes<br>for each object: the score, which we use as an index, and an associated<br>value. When using lexicographical indexes instead, the score is always<br>set to 0 and basically not used at all. We are left with a single string,<br>which is the element itself.</p>\n<p>Like we did in the previous completion examples, we are still able to<br>store associated data using separators. For example we used the colon in<br>order to add the frequency and the original word for completion.</p>\n<p>In general we can add any kind of associated value to our indexing key.<br>In order to use a lexicographical index to implement a simple key-value store<br>we just store the entry as <code>key:value</code>:</p>\n<pre><code>ZADD myindex 0 mykey:myvalue\n</code></pre>\n<p>And search for the key with:</p>\n<pre><code>ZRANGE myindex [mykey: + BYLEX LIMIT 0 1\n1) &quot;mykey:myvalue&quot;\n</code></pre>\n<p>Then we extract the part after the colon to retrieve the value.<br>However a problem to solve in this case is collisions. The colon character<br>may be part of the key itself, so it must be chosen in order to never<br>collide with the key we add.</p>\n<p>Since lexicographical ranges in Valkey are binary safe you can use any<br>byte or any sequence of bytes. However if you receive untrusted user<br>input, it is better to use some form of escaping in order to guarantee<br>that the separator will never happen to be part of the key.</p>\n<p>For example if you use two null bytes as separator <code>&quot;\\0\\0&quot;</code>, you may<br>want to always escape null bytes into two bytes sequences in your strings.</p>\n<h2>Numerical padding</h2>\n<p>Lexicographical indexes may look like good only when the problem at hand<br>is to index strings. Actually it is very simple to use this kind of index<br>in order to perform indexing of arbitrary precision numbers.</p>\n<p>In the ASCII character set, digits appear in the order from 0 to 9, so<br>if we left-pad numbers with leading zeroes, the result is that comparing<br>them as strings will order them by their numerical value.</p>\n<pre><code>ZADD myindex 0 00324823481:foo\nZADD myindex 0 12838349234:bar\nZADD myindex 0 00000000111:zap\n\nZRANGE myindex 0 -1\n1) &quot;00000000111:zap&quot;\n2) &quot;00324823481:foo&quot;\n3) &quot;12838349234:bar&quot;\n</code></pre>\n<p>We effectively created an index using a numerical field which can be as<br>big as we want. This also works with floating point numbers of any precision<br>by making sure we left pad the numerical part with leading zeroes and the<br>decimal part with trailing zeroes like in the following list of numbers:</p>\n<pre><code>    01000000000000.11000000000000\n    01000000000000.02200000000000\n    00000002121241.34893482930000\n    00999999999999.00000000000000\n</code></pre>\n<h2>Using numbers in binary form</h2>\n<p>Storing numbers in decimal may use too much memory. An alternative approach<br>is just to store numbers, for example 128 bit integers, directly in their<br>binary form. However for this to work, you need to store the numbers in<br><em>big endian format</em>, so that the most significant bytes are stored before<br>the least significant bytes. This way when Valkey compares the strings with<br><code>memcmp()</code>, it will effectively sort the numbers by their value.</p>\n<p>Keep in mind that data stored in binary format is less observable for<br>debugging, harder to parse and export. So it is definitely a trade off.</p>\n<h1>Composite indexes</h1>\n<p>So far we explored ways to index single fields. However we all know that<br>SQL stores are able to create indexes using multiple fields. For example<br>I may index products in a very large store by room number and price.</p>\n<p>I need to run queries in order to retrieve all the products in a given<br>room having a given price range. What I can do is to index each product<br>in the following way:</p>\n<pre><code>ZADD myindex 0 0056:0028.44:90\nZADD myindex 0 0034:0011.00:832\n</code></pre>\n<p>Here the fields are <code>room:price:product_id</code>. I used just four digits padding<br>in the example for simplicity. The auxiliary data (the product ID) does not<br>need any padding.</p>\n<p>With an index like that, to get all the products in room 56 having a price<br>between 10 and 30 dollars is very easy. We can just run the following<br>command:</p>\n<pre><code>ZRANGE myindex [0056:0010.00 [0056:0030.00 BYLEX\n</code></pre>\n<p>The above is called a composed index. Its effectiveness depends on the<br>order of the fields and the queries I want to run. For example the above<br>index cannot be used efficiently in order to get all the products having<br>a specific price range regardless of the room number. However I can use<br>the primary key in order to run queries regardless of the price, like<br><em>give me all the products in room 44</em>.</p>\n<p>Composite indexes are very powerful, and are used in traditional stores<br>in order to optimize complex queries. In Valkey they could be useful both<br>to implement a very fast in-memory Valkey index of something stored into<br>a traditional data store, or in order to directly index Valkey data.</p>\n<h1>Updating lexicographical indexes</h1>\n<p>The value of the index in a lexicographical index can get pretty fancy<br>and hard or slow to rebuild from what we store about the object. So one<br>approach to simplify the handling of the index, at the cost of using more<br>memory, is to also take alongside to the sorted set representing the index<br>a hash mapping the object ID to the current index value.</p>\n<p>So for example, when we index we also add to a hash:</p>\n<pre><code>MULTI\nZADD myindex 0 0056:0028.44:90\nHSET index.content 90 0056:0028.44:90\nEXEC\n</code></pre>\n<p>This is not always needed, but simplifies the operations of updating<br>the index. In order to remove the old information we indexed for the object<br>ID 90, regardless of the <em>current</em> fields values of the object, we just<br>have to retrieve the hash value by object ID and <code>ZREM</code> it in the sorted<br>set view.</p>\n<h1>Representing and querying graphs using a hexastore</h1>\n<p>One cool thing about composite indexes is that they are handy in order<br>to represent graphs, using a data structure which is called<br><a href=\"https://www.vldb.org/pvldb/vol1/1453965.pdf\">Hexastore</a>.</p>\n<p>The hexastore provides a representation for relations between objects,<br>formed by a <em>subject</em>, a <em>predicate</em> and an <em>object</em>.<br>A simple relation between objects could be:</p>\n<pre><code>antirez is-friend-of matteocollina\n</code></pre>\n<p>In order to represent this relation I can store the following element<br>in my lexicographical index:</p>\n<pre><code>ZADD myindex 0 spo:antirez:is-friend-of:matteocollina\n</code></pre>\n<p>Note that I prefixed my item with the string <strong>spo</strong>. It means that<br>the item represents a subject,predicate,object relation.</p>\n<p>In can add 5 more entries for the same relation, but in a different order:</p>\n<pre><code>ZADD myindex 0 sop:antirez:matteocollina:is-friend-of\nZADD myindex 0 ops:matteocollina:is-friend-of:antirez\nZADD myindex 0 osp:matteocollina:antirez:is-friend-of\nZADD myindex 0 pso:is-friend-of:antirez:matteocollina\nZADD myindex 0 pos:is-friend-of:matteocollina:antirez\n</code></pre>\n<p>Now things start to be interesting, and I can query the graph in many<br>different ways. For example, who are all the people <code>antirez</code><br><em>is friend of</em>?</p>\n<pre><code>ZRANGE myindex &quot;[spo:antirez:is-friend-of:&quot; &quot;[spo:antirez:is-friend-of:\\xff&quot; BYLEX\n1) &quot;spo:antirez:is-friend-of:matteocollina&quot;\n2) &quot;spo:antirez:is-friend-of:wonderwoman&quot;\n3) &quot;spo:antirez:is-friend-of:spiderman&quot;\n</code></pre>\n<p>Or, what are all the relationships <code>antirez</code> and <code>matteocollina</code> have where<br>the first is the subject and the second is the object?</p>\n<pre><code>ZRANGE myindex &quot;[sop:antirez:matteocollina:&quot; &quot;[sop:antirez:matteocollina:\\xff&quot; BYLEX\n1) &quot;sop:antirez:matteocollina:is-friend-of&quot;\n2) &quot;sop:antirez:matteocollina:was-at-conference-with&quot;\n3) &quot;sop:antirez:matteocollina:talked-with&quot;\n</code></pre>\n<p>By combining different queries, I can ask fancy questions. For example:<br><em>Who are all my friends that, like beer, live in Barcelona, and matteocollina consider friends as well?</em><br>To get this information I start with an <code>spo</code> query to find all the people<br>I&#39;m friend with. Then for each result I get I perform an <code>spo</code> query<br>to check if they like beer, removing the ones for which I can&#39;t find<br>this relation. I do it again to filter by city. Finally I perform an <code>ops</code><br>query to find, of the list I obtained, who is considered friend by<br>matteocollina.</p>\n<p>Make sure to check <a href=\"https://nodejsconfit.levelgraph.io/\">Matteo Collina&#39;s slides about Levelgraph</a> in order to better understand these ideas.</p>\n<h1>Multi dimensional indexes</h1>\n<p>A more complex type of index is an index that allows you to perform queries<br>where two or more variables are queried at the same time for specific<br>ranges. For example I may have a data set representing persons age and<br>salary, and I want to retrieve all the people between 50 and 55 years old<br>having a salary between 70000 and 85000.</p>\n<p>This query may be performed with a multi column index, but this requires<br>us to select the first variable and then scan the second, which means we<br>may do a lot more work than needed. It is possible to perform these kinds of<br>queries involving multiple variables using different data structures.<br>For example, multi-dimensional trees such as <em>k-d trees</em> or <em>r-trees</em> are<br>sometimes used. Here we&#39;ll describe a different way to index data into<br>multiple dimensions, using a representation trick that allows us to perform<br>the query in a very efficient way using Valkey lexicographical ranges.</p>\n<p>Let&#39;s say we have points in the space, which represent our data samples, where <code>x</code> and <code>y</code> are our coordinates. The max value of both variables is 400.</p>\n<p>In the next figure, the blue box represents our query. We want all the points where <code>x</code> is between 50 and 100, and where <code>y</code> is between 100 and 300.</p>\n<p><img src=\"2idx_0.png\" alt=\"Points in the space\"></p>\n<p>In order to represent data that makes these kinds of queries fast to perform,<br>we start by padding our numbers with 0. So for example imagine we want to<br>add the point 10,25 (x,y) to our index. Given that the maximum range in the<br>example is 400 we can just pad to three digits, so we obtain:</p>\n<pre><code>x = 010\ny = 025\n</code></pre>\n<p>Now what we do is to interleave the digits, taking the leftmost digit<br>in x, and the leftmost digit in y, and so forth, in order to create a single<br>number:</p>\n<pre><code>001205\n</code></pre>\n<p>This is our index, however in order to more easily reconstruct the original<br>representation, if we want (at the cost of space), we may also add the<br>original values as additional columns:</p>\n<pre><code>001205:10:25\n</code></pre>\n<p>Now, let&#39;s reason about this representation and why it is useful in the<br>context of range queries. For example let&#39;s take the center of our blue<br>box, which is at <code>x=75</code> and <code>y=200</code>. We can encode this number as we did<br>earlier by interleaving the digits, obtaining:</p>\n<pre><code>027050\n</code></pre>\n<p>What happens if we substitute the last two digits respectively with 00 and 99?<br>We obtain a range which is lexicographically continuous:</p>\n<pre><code>027000 to 027099\n</code></pre>\n<p>What this maps to is to a square representing all values where the <code>x</code><br>variable is between 70 and 79, and the <code>y</code> variable is between 200 and 209.<br>To identify this specific area, we can write random points in that interval.</p>\n<p><img src=\"2idx_1.png\" alt=\"Small area\"></p>\n<p>So the above lexicographic query allows us to easily query for points in<br>a specific square in the picture. However the square may be too small for<br>the box we are searching, so that too many queries are needed.<br>So we can do the same but instead of replacing the last two digits with 00<br>and 99, we can do it for the last four digits, obtaining the following<br>range:</p>\n<pre><code>020000 029999\n</code></pre>\n<p>This time the range represents all the points where <code>x</code> is between 0 and 99<br>and <code>y</code> is between 200 and 299. Drawing random points in this interval<br>shows us this larger area.</p>\n<p><img src=\"2idx_2.png\" alt=\"Large area\"></p>\n<p>So now our area is too big for our query, and still our search box is<br>not completely included. We need more granularity, but we can easily obtain<br>it by representing our numbers in binary form. This time, when we replace<br>digits instead of getting squares which are ten times bigger, we get squares<br>which are just two times bigger.</p>\n<p>Our numbers in binary form, assuming we need just 9 bits for each variable<br>(in order to represent numbers up to 400 in value) would be:</p>\n<pre><code>x = 75  -&gt; 001001011\ny = 200 -&gt; 011001000\n</code></pre>\n<p>So by interleaving digits, our representation in the index would be:</p>\n<pre><code>000111000011001010:75:200\n</code></pre>\n<p>Let&#39;s see what are our ranges as we substitute the last 2, 4, 6, 8, ...<br>bits with 0s ad 1s in the interleaved representation:</p>\n<pre><code>2 bits: x between 74 and 75, y between 200 and 201 (range=2)\n4 bits: x between 72 and 75, y between 200 and 203 (range=4)\n6 bits: x between 72 and 79, y between 200 and 207 (range=8)\n8 bits: x between 64 and 79, y between 192 and 207 (range=16)\n</code></pre>\n<p>And so forth. Now we have definitely better granularity!<br>As you can see substituting N bits from the index gives us<br>search boxes of side <code>2^(N/2)</code>.</p>\n<p>So what we do is check the dimension where our search box is smaller,<br>and check the nearest power of two to this number. Our search box<br>was 50,100 to 100,300, so it has a width of 50 and a height of 200.<br>We take the smaller of the two, 50, and check the nearest power of two<br>which is 64. 64 is 2^6, so we would work with indexes obtained replacing<br>the latest 12 bits from the interleaved representation (so that we end<br>replacing just 6 bits of each variable).</p>\n<p>However single squares may not cover all our search, so we may need more.<br>What we do is to start with the left bottom corner of our search box,<br>which is 50,100, and find the first range by substituting the last 6 bits<br>in each number with 0. Then we do the same with the right top corner.</p>\n<p>With two trivial nested for loops where we increment only the significant<br>bits, we can find all the squares between these two. For each square we<br>convert the two numbers into our interleaved representation, and create<br>the range using the converted representation as our start, and the same<br>representation but with the latest 12 bits turned on as end range.</p>\n<p>For each square found we perform our query and get the elements inside,<br>removing the elements which are outside our search box.</p>\n<p>Turning this into code is simple. Here is a Ruby example:</p>\n<pre><code class=\"language-ruby\">def spacequery(x0,y0,x1,y1,exp)\n    bits=exp*2\n    x_start = x0/(2**exp)\n    x_end = x1/(2**exp)\n    y_start = y0/(2**exp)\n    y_end = y1/(2**exp)\n    (x_start..x_end).each{|x|\n        (y_start..y_end).each{|y|\n            x_range_start = x*(2**exp)\n            x_range_end = x_range_start | ((2**exp)-1)\n            y_range_start = y*(2**exp)\n            y_range_end = y_range_start | ((2**exp)-1)\n            puts &quot;#{x},#{y} x from #{x_range_start} to #{x_range_end}, y from #{y_range_start} to #{y_range_end}&quot;\n\n            # Turn it into interleaved form for ZRANGE query.\n            # We assume we need 9 bits for each integer, so the final\n            # interleaved representation will be 18 bits.\n            xbin = x_range_start.to_s(2).rjust(9,&#39;0&#39;)\n            ybin = y_range_start.to_s(2).rjust(9,&#39;0&#39;)\n            s = xbin.split(&quot;&quot;).zip(ybin.split(&quot;&quot;)).flatten.compact.join(&quot;&quot;)\n            # Now that we have the start of the range, calculate the end\n            # by replacing the specified number of bits from 0 to 1.\n            e = s[0..-(bits+1)]+(&quot;1&quot;*bits)\n            puts &quot;ZRANGE myindex [#{s} [#{e} BYLEX&quot;\n        }\n    }\nend\n\nspacequery(50,100,100,300,6)\n</code></pre>\n<p>While non immediately trivial this is a very useful indexing strategy that<br>in the future may be implemented in Valkey in a native way.<br>For now, the good thing is that the complexity may be easily encapsulated<br>inside a library that can be used in order to perform indexing and queries.<br>One example of such library is <a href=\"https://github.com/antirez/redimension\">Redimension</a>, a proof of concept Ruby library which indexes N-dimensional data inside Valkey using the technique described here.</p>\n<h1>Multi dimensional indexes with negative or floating point numbers</h1>\n<p>The simplest way to represent negative values is just to work with unsigned<br>integers and represent them using an offset, so that when you index, before<br>translating numbers in the indexed representation, you add the absolute value<br>of your smaller negative integer.</p>\n<p>For floating point numbers, the simplest approach is probably to convert them<br>to integers by multiplying the integer for a power of ten proportional to the<br>number of digits after the dot you want to retain.</p>\n<h1>Non range indexes</h1>\n<p>So far we checked indexes which are useful to query by range or by single<br>item. However other Valkey data structures such as Sets or Lists can be used<br>in order to build other kind of indexes. They are very commonly used but<br>maybe we don&#39;t always realize they are actually a form of indexing.</p>\n<p>For instance I can index object IDs into a Set data type in order to use<br>the <em>get random elements</em> operation via <code>SRANDMEMBER</code> in order to retrieve<br>a set of random objects. Sets can also be used to check for existence when<br>all I need is to test if a given item exists or not or has a single boolean<br>property or not.</p>\n<p>Similarly lists can be used in order to index items into a fixed order.<br>I can add all my items into a List and rotate the list with<br><code>RPOPLPUSH</code> using the same key name as source and destination. This is useful<br>when I want to process a given set of items again and again forever in the<br>same order. Think of an RSS feed system that needs to refresh the local copy<br>periodically.</p>\n<p>Another popular index often used with Valkey is a <strong>capped list</strong>, where items<br>are added with <code>LPUSH</code> and trimmed with <code>LTRIM</code>, in order to create a view<br>with just the latest N items encountered, in the same order they were<br>seen.</p>\n<h1>Index inconsistency</h1>\n<p>Keeping the index updated may be challenging, in the course of months<br>or years it is possible that inconsistencies are added because of software<br>bugs, network partitions or other events.</p>\n<p>Different strategies could be used. If the index data is outside Valkey<br><em>read repair</em> can be a solution, where data is fixed in a lazy way when<br>it is requested. When we index data which is stored in Valkey itself<br>the <code>SCAN</code> family of commands can be used in order to verify, update or<br>rebuild the index from scratch, incrementally.</p>\n"
      },
      {
        "id": "latency-monitor",
        "topicName": "Latency monitoring",
        "description": "Discovering slow server events in Valkey",
        "htmlContent": "<p>Valkey is often used for demanding use cases, where it<br>serves a large number of queries per second per instance, but also has strict latency requirements for the average response<br>time and the worst-case latency.</p>\n<p>While Valkey is an in-memory system, it deals with the operating system in<br>different ways, for example, in the context of persisting to disk.<br>Moreover Valkey implements a rich set of commands. Certain commands<br>are fast and run in constant or logarithmic time. Other commands are slower<br>O(N) commands that can cause latency spikes.</p>\n<p>Finally, Valkey is single threaded. This is usually an advantage<br>from the point of view of the amount of work it can perform per core, and in<br>the latency figures it is able to provide. However, it poses<br>a challenge for latency, since the single<br>thread must be able to perform certain tasks incrementally, for<br>example key expiration, in a way that does not impact the other clients<br>that are served.</p>\n<p>For all these reasons, there is a feature called<br><strong>Latency Monitoring</strong>, that helps the user to check and troubleshoot possible<br>latency problems. Latency monitoring is composed of the following conceptual<br>parts:</p>\n<ul>\n<li>Latency hooks that sample different latency-sensitive code paths.</li>\n<li>Time series recording of latency spikes, split by different events.</li>\n<li>Reporting engine to fetch raw data from the time series.</li>\n<li>Analysis engine to provide human-readable reports and hints according to the measurements.</li>\n</ul>\n<p>The rest of this document covers the latency monitoring subsystem<br>details. For more information about the general topic of Valkey<br>and latency, see <a href=\"latency\">Valkey latency problems troubleshooting</a>.</p>\n<h2>Events and time series</h2>\n<p>Different monitored code paths have different names and are called <em>events</em>.<br>For example, <code>command</code> is an event that measures latency spikes of possibly slow<br>command executions, while <code>fast-command</code> is the event name for the monitoring<br>of the O(1) and O(log N) commands. Other events are less generic and monitor<br>specific operations performed by Valkey. For example, the <code>fork</code> event<br>only monitors the time taken by Valkey to execute the <code>fork(2)</code> system call.</p>\n<p>A latency spike is an event that takes more time to run than the configured latency<br>threshold. There is a separate time series associated with every monitored<br>event. This is how the time series work:</p>\n<ul>\n<li>Every time a latency spike happens, it is logged in the appropriate time series.</li>\n<li>Every time series is composed of 160 elements.</li>\n<li>Each element is a pair made of a Unix timestamp of the time the latency spike was measured and the number of milliseconds the event took to execute.</li>\n<li>Latency spikes for the same event that occur in the same second are merged by taking the maximum latency. Even if continuous latency spikes are measured for a given event, which could happen with a low threshold, at least 160 seconds of history are available.</li>\n<li>Records the all-time maximum latency for every element.</li>\n</ul>\n<p>The framework monitors and logs latency spikes in the execution time of these events:</p>\n<ul>\n<li><code>command</code>: regular commands.</li>\n<li><code>fast-command</code>: O(1) and O(log N) commands.</li>\n<li><code>fork</code>: the <code>fork(2)</code> system call.</li>\n<li><code>rdb-unlink-temp-file</code>: the <code>unlink(2)</code> system call.</li>\n<li><code>aof-fsync-always</code>: the <code>fsync(2)</code> system call when invoked by the <code>appendfsync allways</code> policy.</li>\n<li><code>aof-write</code>: writing to the AOF - a catchall event for <code>write(2)</code> system calls.</li>\n<li><code>aof-write-pending-fsync</code>: the <code>write(2)</code> system call when there is a pending fsync.</li>\n<li><code>aof-write-active-child</code>: the <code>write(2)</code> system call when there are active child processes.</li>\n<li><code>aof-write-alone</code>: the <code>write(2)</code> system call when no pending fsync and no active child process.</li>\n<li><code>aof-fstat</code>: the <code>fstat(2)</code> system call.</li>\n<li><code>aof-rename</code>: the <code>rename(2)</code> system call for renaming the temporary file after completing <code>BGREWRITEAOF</code>.</li>\n<li><code>aof-rewrite-diff-write</code>: writing the differences accumulated while performing <code>BGREWRITEAOF</code>.</li>\n<li><code>active-defrag-cycle</code>: the active defragmentation cycle.</li>\n<li><code>expire-cycle</code>: the expiration cycle.</li>\n<li><code>eviction-cycle</code>: the eviction cycle.</li>\n<li><code>eviction-del</code>: deletes during the eviction cycle.</li>\n</ul>\n<h2>How to enable latency monitoring</h2>\n<p>What is high latency for one use case may not be considered high latency for another. Some applications may require that all queries be served in less than 1 millisecond. For other applications, it may be acceptable for a small amount of clients to experience a 2 second latency on occasion.</p>\n<p>The first step to enable the latency monitor is to set a <strong>latency threshold</strong> in milliseconds. Only events that take longer than the specified threshold will be logged as latency spikes. The user should set the threshold according to their needs. For example, if the application requires a maximum acceptable latency of 100 milliseconds, the threshold should be set to log all the events blocking the server for a time equal or greater to 100 milliseconds.</p>\n<p>Enable the latency monitor at runtime in a production server<br>with the following command:</p>\n<pre><code>CONFIG SET latency-monitor-threshold 100\n</code></pre>\n<p>Monitoring is turned off by default (threshold set to 0), even if the actual cost of latency monitoring is near zero. While the memory requirements of latency monitoring are very small, there is no good reason to raise the baseline memory usage of a Valkey instance that is working well.</p>\n<h2>Report information with the LATENCY command</h2>\n<p>The user interface to the latency monitoring subsystem is the <code>LATENCY</code> command.<br>Like many other Valkey commands, <code>LATENCY</code> accepts subcommands that modify its behavior. These subcommands are:</p>\n<ul>\n<li><code>LATENCY LATEST</code> - returns the latest latency samples for all events.</li>\n<li><code>LATENCY HISTORY</code> - returns latency time series for a given event.</li>\n<li><code>LATENCY RESET</code> - resets latency time series data for one or more events.</li>\n<li><code>LATENCY GRAPH</code> - renders an ASCII-art graph of an event&#39;s latency samples.</li>\n<li><code>LATENCY DOCTOR</code> - replies with a human-readable latency analysis report.</li>\n</ul>\n<p>Refer to each subcommand&#39;s documentation page for further information.</p>\n"
      },
      {
        "id": "latency",
        "topicName": "Diagnosing latency issues",
        "description": "Finding the causes of slow responses",
        "htmlContent": "<p>This document will help you understand what the problem could be if you<br>are experiencing latency problems with Valkey.</p>\n<p>In this context <em>latency</em> is the maximum delay between the time a client<br>issues a command and the time the reply to the command is received by the<br>client. Usually Valkey processing time is extremely low, in the sub microsecond<br>range, but there are certain conditions leading to higher latency figures.</p>\n<h2>I&#39;ve little time, give me the checklist</h2>\n<p>The following documentation is very important in order to run Valkey in<br>a low latency fashion. However I understand that we are busy people, so<br>let&#39;s start with a quick checklist. If you fail following these steps, please<br>return here to read the full documentation.</p>\n<ol>\n<li>Make sure you are not running slow commands that are blocking the server. Use the Valkey <a href=\"../commands/slowlog\">Slow Log feature</a> to check this.</li>\n<li>For EC2 users, make sure you use HVM based modern EC2 instances, like m3.medium. Otherwise fork() is too slow.</li>\n<li>Transparent huge pages must be disabled from your kernel. Use <code>echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</code> to disable them, and restart your Valkey process.</li>\n<li>If you are using a virtual machine, it is possible that you have an intrinsic latency that has nothing to do with Valkey. Check the minimum latency you can expect from your runtime environment using <code>./valkey-cli --intrinsic-latency 100</code>. Note: you need to run this command in <em>the server</em> not in the client.</li>\n<li>Enable and use the <a href=\"latency-monitor\">Latency monitor</a> feature of Valkey in order to get a human readable description of the latency events and causes in your Valkey instance.</li>\n</ol>\n<p>In general, use the following table for durability VS latency/performance tradeoffs, ordered from stronger safety to better latency.</p>\n<ol>\n<li>AOF + fsync always: this is very slow, you should use it only if you know what you are doing.</li>\n<li>AOF + fsync every second: this is a good compromise.</li>\n<li>AOF + fsync every second + no-appendfsync-on-rewrite option set to yes: this is as the above, but avoids to fsync during rewrites to lower the disk pressure.</li>\n<li>AOF + fsync never. Fsyncing is up to the kernel in this setup, even less disk pressure and risk of latency spikes.</li>\n<li>RDB. Here you have a vast spectrum of tradeoffs depending on the save triggers you configure.</li>\n</ol>\n<p>And now for people with 15 minutes to spend, the details...</p>\n<h2>Measuring latency</h2>\n<p>If you are experiencing latency problems, you probably know how to measure<br>it in the context of your application, or maybe your latency problem is very<br>evident even macroscopically. However valkey-cli can be used to measure the<br>latency of a Valkey server in milliseconds, just try:</p>\n<pre><code>valkey-cli --latency -h `host` -p `port`\n</code></pre>\n<h2>Using the internal Valkey latency monitoring subsystem</h2>\n<p>Valkey provides latency monitoring capabilities that<br>are able to sample different execution paths to understand where the<br>server is blocking. This makes debugging of the problems illustrated in<br>this documentation much simpler, so we suggest enabling latency monitoring<br>ASAP. Please refer to the <a href=\"latency-monitor\">Latency monitor documentation</a>.</p>\n<p>While the latency monitoring sampling and reporting capabilities will make<br>it simpler to understand the source of latency in your Valkey system, it is still<br>advised that you read this documentation extensively to better understand<br>the topic of Valkey and latency spikes.</p>\n<h2>Latency baseline</h2>\n<p>There is a kind of latency that is inherently part of the environment where<br>you run Valkey, that is the latency provided by your operating system kernel<br>and, if you are using virtualization, by the hypervisor you are using.</p>\n<p>While this latency can&#39;t be removed it is important to study it because<br>it is the baseline, or in other words, you won&#39;t be able to achieve a Valkey<br>latency that is better than the latency that every process running in your<br>environment will experience because of the kernel or hypervisor implementation<br>or setup.</p>\n<p>We call this kind of latency <strong>intrinsic latency</strong>, and <code>valkey-cli</code><br>is able to measure it. This is an example run.</p>\n<p>Note: the argument <code>100</code> is the number of seconds the test will be executed.<br>The more time we run the test, the more likely we&#39;ll be able to spot<br>latency spikes. 100 seconds is usually appropriate, however you may want<br>to perform a few runs at different times. Please note that the test is CPU<br>intensive and will likely saturate a single core in your system.</p>\n<pre><code>$ ./valkey-cli --intrinsic-latency 100\nMax latency so far: 1 microseconds.\nMax latency so far: 16 microseconds.\nMax latency so far: 50 microseconds.\nMax latency so far: 53 microseconds.\nMax latency so far: 83 microseconds.\nMax latency so far: 115 microseconds.\n</code></pre>\n<p>Note: valkey-cli in this special case needs to <strong>run in the server</strong> where you run or plan to run Valkey, not in the client. In this special mode valkey-cli does not connect to a Valkey server at all: it will just try to measure the largest time the kernel does not provide CPU time to run to the valkey-cli process itself.</p>\n<p>In the above example, the intrinsic latency of the system is just 0.115<br>milliseconds (or 115 microseconds), which is a good news, however keep in mind<br>that the intrinsic latency may change over time depending on the load of the<br>system.</p>\n<p>In a virtualized environments with high load or if there are noisy neighbors,<br>you may get numbers like these:</p>\n<pre><code>$ ./valkey-cli --intrinsic-latency 100\nMax latency so far: 573 microseconds.\nMax latency so far: 695 microseconds.\nMax latency so far: 919 microseconds.\nMax latency so far: 1606 microseconds.\nMax latency so far: 3191 microseconds.\nMax latency so far: 9243 microseconds.\nMax latency so far: 9671 microseconds.\n</code></pre>\n<p>Here we have an intrinsic latency of 9.7 milliseconds: this means that we can&#39;t ask better than that to Valkey. However other runs at different times in different virtualization environments with higher load or with noisy neighbors can easily show even worse values. We were able to measure up to 40 milliseconds in<br>systems otherwise apparently running normally.</p>\n<h2>Latency induced by network and communication</h2>\n<p>Clients connect to Valkey using a TCP/IP connection or a Unix domain connection.<br>The typical latency of a 1 Gbit/s network is about 200 us, while the latency<br>with a Unix domain socket can be as low as 30 us. It actually depends on your<br>network and system hardware. On top of the communication itself, the system<br>adds some more latency (due to thread scheduling, CPU caches, NUMA placement,<br>etc ...). System induced latencies are significantly higher on a virtualized<br>environment than on a physical machine.</p>\n<p>The consequence is even if Valkey processes most commands in sub microsecond<br>range, a client performing many roundtrips to the server will have to pay<br>for these network and system related latencies.</p>\n<p>An efficient client will therefore try to limit the number of roundtrips by<br>pipelining several commands together. This is fully supported by the servers<br>and most clients. Aggregated commands like MSET/MGET can be also used for<br>that purpose. A number of commands also support<br>variadic parameters for all data types.</p>\n<p>Here are some guidelines:</p>\n<ul>\n<li>If you can afford it, prefer a physical machine over a VM to host the server.</li>\n<li>Do not systematically connect/disconnect to the server (especially true<br>for web based applications). Keep your connections as long lived as possible.</li>\n<li>If your client is on the same host than the server, use Unix domain sockets.</li>\n<li>Prefer to use aggregated commands (MSET/MGET), or commands with variadic<br>parameters (if possible) over pipelining.</li>\n<li>Prefer to use pipelining (if possible) over sequence of roundtrips.</li>\n<li>Valkey supports Lua server-side scripting to cover cases that are not suitable<br>for raw pipelining (for instance when the result of a command is an input for<br>the following commands).</li>\n</ul>\n<p>On Linux, some people can achieve better latencies by playing with process<br>placement (taskset), cgroups, real-time priorities (chrt), NUMA<br>configuration (numactl), or by using a low-latency kernel. Please note<br>vanilla Valkey is not really suitable to be bound on a <strong>single</strong> CPU core.<br>Valkey can fork background tasks that can be extremely CPU consuming<br>like <code>BGSAVE</code> or <code>BGREWRITEAOF</code>. These tasks must <strong>never</strong> run on the same core<br>as the main event loop.</p>\n<p>In most situations, these kind of system level optimizations are not needed.<br>Only do them if you require them, and if you are familiar with them.</p>\n<h2>Valkey sequential command execution</h2>\n<p>Valkey uses a <em>mostly</em> single threaded design for command execution. This means that a single process<br>executes all the client commands sequentially, using a technique called <strong>multiplexing</strong>.<br>While multiple commands can have their I/O operations processed concurrently in the background,<br>only one command can be executed at any given moment. This is similar to how Node.js<br>works as well. However, both products are not often perceived as being slow.<br>This is caused in part by the small amount of time to complete a single command execution,<br>but primarily because these products are designed to not block on system calls,<br>such as reading data from or writing data to a socket.</p>\n<h2>Latency generated by slow commands</h2>\n<p>A consequence of being single thread is that when a request is slow to serve<br>all the other clients will wait for this request to be served. When executing<br>normal commands, like <code>GET</code> or <code>SET</code> or <code>LPUSH</code> this is not a problem<br>at all since these commands are executed in constant (and very small) time.<br>However there are commands operating on many elements, like <code>SORT</code>, <code>LREM</code>,<br><code>SUNION</code> and others. For instance taking the intersection of two big sets<br>can take a considerable amount of time.</p>\n<p>The algorithmic complexity of all commands is documented. A good practice<br>is to systematically check it when using commands you are not familiar with.</p>\n<p>If you have latency concerns you should either not use slow commands against<br>values composed of many elements, or you should run a replica using Valkey<br>replication where you run all your slow queries.</p>\n<p>It is possible to monitor slow commands using the Valkey<br><a href=\"../commands/slowlog\">Slow Log feature</a>.</p>\n<p>Additionally, you can use your favorite per-process monitoring program<br>(top, htop, prstat, etc ...) to quickly check the CPU consumption of the<br>main Valkey process. If it is high while the traffic is not, it is usually<br>a sign that slow commands are used.</p>\n<p><strong>IMPORTANT NOTE</strong>: a VERY common source of latency generated by the execution<br>of slow commands is the use of the <code>KEYS</code> command in production environments.<br><code>KEYS</code>, as documented in the Valkey documentation, should only be used for<br>debugging purposes. To<br>iterate the key space and other large collections incrementally, please check<br>the <code>SCAN</code>, <code>SSCAN</code>, <code>HSCAN</code> and <code>ZSCAN</code> commands for more information.</p>\n<h2>Latency generated by fork</h2>\n<p>In order to generate the RDB file in background, or to rewrite the Append Only File if AOF persistence is enabled, Valkey has to fork background processes.<br>The fork operation (running in the main thread) can induce latency by itself.</p>\n<p>Forking is an expensive operation on most Unix-like systems, since it involves<br>copying a good number of objects linked to the process. This is especially<br>true for the page table associated to the virtual memory mechanism.</p>\n<p>For instance on a Linux/AMD64 system, the memory is divided in 4 kB pages.<br>To convert virtual addresses to physical addresses, each process stores<br>a page table (actually represented as a tree) containing at least a pointer<br>per page of the address space of the process. So a large 24 GB Valkey instance<br>requires a page table of 24 GB / 4 kB * 8 = 48 MB.</p>\n<p>When a background save is performed, this instance will have to be forked,<br>which will involve allocating and copying 48 MB of memory. It takes time<br>and CPU, especially on virtual machines where allocation and initialization<br>of a large memory chunk can be expensive.</p>\n<h2>Fork time in different systems</h2>\n<p>Modern hardware is pretty fast at copying the page table.<br>So are modern hardware-assisted virtualized environments,<br>but fork can be really slow in older virtualized environments without hardware support.<br>As of 2024, this is hardly a problem.</p>\n<p>You can measure the fork time for a Valkey instance by<br>performing a BGSAVE and looking at the <code>latest_fork_usec</code> field in the <code>INFO</code> command output.</p>\n<h2>Latency induced by transparent huge pages</h2>\n<p>Unfortunately when a Linux kernel has transparent huge pages enabled, Valkey<br>incurs to a big latency penalty after the <code>fork</code> call is used in order to<br>persist on disk. Huge pages are the cause of the following issue:</p>\n<ol>\n<li>Fork is called, two processes with shared huge pages are created.</li>\n<li>In a busy instance, a few event loops runs will cause commands to target a few thousand of pages, causing the copy on write of almost the whole process memory.</li>\n<li>This will result in big latency and big memory usage.</li>\n</ol>\n<p>Make sure to <strong>disable transparent huge pages</strong> using the following command:</p>\n<pre><code>echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled\n</code></pre>\n<h2>Latency induced by swapping (operating system paging)</h2>\n<p>Linux (and many other modern operating systems) is able to relocate memory<br>pages from the memory to the disk, and vice versa, in order to use the<br>system memory efficiently.</p>\n<p>If a Valkey page is moved by the kernel from the memory to the swap file, when<br>the data stored in this memory page is used by Valkey (for example accessing<br>a key stored into this memory page) the kernel will stop the Valkey process<br>in order to move the page back into the main memory. This is a slow operation<br>involving random I/Os (compared to accessing a page that is already in memory)<br>and will result into anomalous latency experienced by Valkey clients.</p>\n<p>The kernel relocates Valkey memory pages on disk mainly because of three reasons:</p>\n<ul>\n<li>The system is under memory pressure since the running processes are demanding<br>more physical memory than the amount that is available. The simplest instance of<br>this problem is simply Valkey using more memory than is available.</li>\n<li>The Valkey instance data set, or part of the data set, is mostly completely idle<br>(never accessed by clients), so the kernel could swap idle memory pages on disk.<br>This problem is very rare since even a moderately slow instance will touch all<br>the memory pages often, forcing the kernel to retain all the pages in memory.</li>\n<li>Some processes are generating massive read or write I/Os on the system. Because<br>files are generally cached, it tends to put pressure on the kernel to increase<br>the filesystem cache, and therefore generate swapping activity. Please note it<br>includes Valkey RDB and/or AOF background threads which can produce large files.</li>\n</ul>\n<p>Fortunately Linux offers good tools to investigate the problem, so the simplest<br>thing to do is when latency due to swapping is suspected is just to check if<br>this is the case.</p>\n<p>The first thing to do is to checking the amount of Valkey memory that is swapped<br>on disk. In order to do so you need to obtain the Valkey instance pid:</p>\n<pre><code>$ valkey-cli info | grep process_id\nprocess_id:5454\n</code></pre>\n<p>Now enter the /proc file system directory for this process:</p>\n<pre><code>$ cd /proc/5454\n</code></pre>\n<p>Here you&#39;ll find a file called <strong>smaps</strong> that describes the memory layout of<br>the Valkey process (assuming you are using Linux 2.6.16 or newer).<br>This file contains very detailed information about our process memory maps,<br>and one field called <strong>Swap</strong> is exactly what we are looking for. However<br>there is not just a single swap field since the smaps file contains the<br>different memory maps of our Valkey process (The memory layout of a process<br>is more complex than a simple linear array of pages).</p>\n<p>Since we are interested in all the memory swapped by our process the first thing<br>to do is to grep for the Swap field across all the file:</p>\n<pre><code>$ cat smaps | grep &#39;Swap:&#39;\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                 12 kB\nSwap:                156 kB\nSwap:                  8 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  4 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  4 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  4 kB\nSwap:                  4 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\n</code></pre>\n<p>If everything is 0 kB, or if there are sporadic 4k entries, everything is<br>perfectly normal. Actually in our example instance (the one of a real web<br>site running Valkey and serving hundreds of users every second) there are a<br>few entries that show more swapped pages. To investigate if this is a serious<br>problem or not we change our command in order to also print the size of the<br>memory map:</p>\n<pre><code>$ cat smaps | egrep &#39;^(Swap|Size)&#39;\nSize:                316 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  0 kB\nSize:                  8 kB\nSwap:                  0 kB\nSize:                 40 kB\nSwap:                  0 kB\nSize:                132 kB\nSwap:                  0 kB\nSize:             720896 kB\nSwap:                 12 kB\nSize:               4096 kB\nSwap:                156 kB\nSize:               4096 kB\nSwap:                  8 kB\nSize:               4096 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  0 kB\nSize:               1272 kB\nSwap:                  0 kB\nSize:                  8 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  0 kB\nSize:                 16 kB\nSwap:                  0 kB\nSize:                 84 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  0 kB\nSize:                  8 kB\nSwap:                  4 kB\nSize:                  8 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  4 kB\nSize:                144 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  4 kB\nSize:                 12 kB\nSwap:                  4 kB\nSize:                108 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  0 kB\nSize:                272 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  0 kB\n</code></pre>\n<p>As you can see from the output, there is a map of 720896 kB<br>(with just 12 kB swapped) and 156 kB more swapped in another map:<br>basically a very small amount of our memory is swapped so this is not<br>going to create any problem at all.</p>\n<p>If instead a non trivial amount of the process memory is swapped on disk your<br>latency problems are likely related to swapping. If this is the case with your<br>Valkey instance you can further verify it using the <strong>vmstat</strong> command:</p>\n<pre><code>$ vmstat 1\nprocs -----------memory---------- ---swap-- -----io---- -system-- ----cpu----\n r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa\n 0  0   3980 697932 147180 1406456    0    0     2     2    2    0  4  4 91  0\n 0  0   3980 697428 147180 1406580    0    0     0     0 19088 16104  9  6 84  0\n 0  0   3980 697296 147180 1406616    0    0     0    28 18936 16193  7  6 87  0\n 0  0   3980 697048 147180 1406640    0    0     0     0 18613 15987  6  6 88  0\n 2  0   3980 696924 147180 1406656    0    0     0     0 18744 16299  6  5 88  0\n 0  0   3980 697048 147180 1406688    0    0     0     4 18520 15974  6  6 88  0\n^C\n</code></pre>\n<p>The interesting part of the output for our needs are the two columns <strong>si</strong><br>and <strong>so</strong>, that counts the amount of memory swapped from/to the swap file. If<br>you see non zero counts in those two columns then there is swapping activity<br>in your system.</p>\n<p>Finally, the <strong>iostat</strong> command can be used to check the global I/O activity of<br>the system.</p>\n<pre><code>$ iostat -xk 1\navg-cpu:  %user   %nice %system %iowait  %steal   %idle\n          13.55    0.04    2.92    0.53    0.00   82.95\n\nDevice:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await  svctm  %util\nsda               0.77     0.00    0.01    0.00     0.40     0.00    73.65     0.00    3.62   2.58   0.00\nsdb               1.27     4.75    0.82    3.54    38.00    32.32    32.19     0.11   24.80   4.24   1.85\n</code></pre>\n<p>If your latency problem is due to Valkey memory being swapped on disk you need<br>to lower the memory pressure in your system, either adding more RAM if Valkey<br>is using more memory than the available, or avoiding running other memory<br>hungry processes in the same system.</p>\n<h2>Latency due to AOF and disk I/O</h2>\n<p>Another source of latency is due to the Append Only File support on Valkey.<br>The AOF basically uses two system calls to accomplish its work. One is<br>write(2) that is used in order to write data to the append only file, and<br>the other one is fdatasync(2) that is used in order to flush the kernel<br>file buffer on disk in order to ensure the durability level specified by<br>the user.</p>\n<p>Both the write(2) and fdatasync(2) calls can be source of latency.<br>For instance write(2) can block both when there is a system wide sync<br>in progress, or when the output buffers are full and the kernel requires<br>to flush on disk in order to accept new writes.</p>\n<p>The fdatasync(2) call is a worse source of latency as with many combinations<br>of kernels and file systems used it can take from a few milliseconds to<br>a few seconds to complete, especially in the case of some other process<br>doing I/O. For this reason when possible Valkey does the fdatasync(2) call<br>in a different thread.</p>\n<p>We&#39;ll see how configuration can affect the amount and source of latency<br>when using the AOF file.</p>\n<p>The AOF can be configured to perform a fsync on disk in three different<br>ways using the <strong>appendfsync</strong> configuration option (this setting can be<br>modified at runtime using the <strong>CONFIG SET</strong> command).</p>\n<ul>\n<li><p>When appendfsync is set to the value of <strong>no</strong> Valkey performs no fsync.<br>In this configuration the only source of latency can be write(2).<br>When this happens usually there is no solution since simply the disk can&#39;t<br>cope with the speed at which Valkey is receiving data, however this is<br>uncommon if the disk is not seriously slowed down by other processes doing<br>I/O.</p>\n</li>\n<li><p>When appendfsync is set to the value of <strong>everysec</strong> Valkey performs a<br>fsync every second. It uses a different thread, and if the fsync is still<br>in progress Valkey uses a buffer to delay the write(2) call up to two seconds<br>(since write would block on Linux if a fsync is in progress against the<br>same file). However if the fsync is taking too long Valkey will eventually<br>perform the write(2) call even if the fsync is still in progress, and this<br>can be a source of latency.</p>\n</li>\n<li><p>When appendfsync is set to the value of <strong>always</strong> a fsync is performed<br>at every write operation before replying back to the client with an OK code<br>(actually Valkey will try to cluster many commands executed at the same time<br>into a single fsync). In this mode performances are very low in general and<br>it is strongly recommended to use a fast disk and a file system implementation<br>that can perform the fsync in short time.</p>\n</li>\n</ul>\n<p>Most Valkey users will use either the <strong>no</strong> or <strong>everysec</strong> setting for the<br>appendfsync configuration directive. The suggestion for minimum latency is<br>to avoid other processes doing I/O in the same system.<br>Using an SSD disk can help as well, but usually even non SSD disks perform<br>well with the append only file if the disk is spare as Valkey writes<br>to the append only file without performing any seek.</p>\n<p>If you want to investigate your latency issues related to the append only<br>file you can use the strace command under Linux:</p>\n<pre><code>sudo strace -p $(pidof valkey-server) -T -e trace=fdatasync\n</code></pre>\n<p>The above command will show all the fdatasync(2) system calls performed by<br>Valkey in the main thread. With the above command you&#39;ll not see the<br>fdatasync system calls performed by the background thread when the<br>appendfsync config option is set to <strong>everysec</strong>. In order to do so<br>just add the -f switch to strace.</p>\n<p>If you wish you can also see both fdatasync and write system calls with the<br>following command:</p>\n<pre><code>sudo strace -p $(pidof valkey-server) -T -e trace=fdatasync,write\n</code></pre>\n<p>However since write(2) is also used in order to write data to the client<br>sockets this will likely show too many things unrelated to disk I/O.<br>Apparently there is no way to tell strace to just show slow system calls so<br>I use the following command:</p>\n<pre><code>sudo strace -f -p $(pidof valkey-server) -T -e trace=fdatasync,write 2&gt;&amp;1 | grep -v &#39;0.0&#39; | grep -v unfinished\n</code></pre>\n<h2>Latency generated by expires</h2>\n<p>Valkey evict expired keys in two ways:</p>\n<ul>\n<li>One <em>lazy</em> way expires a key when it is requested by a command, but it is found to be already expired.</li>\n<li>One <em>active</em> way expires a few keys every 100 milliseconds.</li>\n</ul>\n<p>The active expiring is designed to be adaptive. An expire cycle is started every 100 milliseconds (10 times per second), and will do the following:</p>\n<ul>\n<li>Sample <code>ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP</code> keys, evicting all the keys already expired.</li>\n<li>If the more than 25% of the keys were found expired, repeat.</li>\n</ul>\n<p>Given that <code>ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP</code> is set to 20 by default, and the process is performed ten times per second, usually just 200 keys per second are actively expired. This is enough to clean the DB fast enough even when already expired keys are not accessed for a long time, so that the <em>lazy</em> algorithm does not help. At the same time expiring just 200 keys per second has no effects in the latency a Valkey instance.</p>\n<p>However the algorithm is adaptive and will loop if it finds more than 25% of keys already expired in the set of sampled keys. But given that we run the algorithm ten times per second, this means that the unlucky event of more than 25% of the keys in our random sample are expiring at least <em>in the same second</em>.</p>\n<p>Basically this means that <strong>if the database has many, many keys expiring in the same second, and these make up at least 25% of the current population of keys with an expire set</strong>, Valkey can block in order to get the percentage of keys already expired below 25%.</p>\n<p>This approach is needed in order to avoid using too much memory for keys that are already expired, and usually is absolutely harmless since it&#39;s strange that a big number of keys are going to expire in the same exact second, but it is not impossible that the user used <code>EXPIREAT</code> extensively with the same Unix time.</p>\n<p>In short: be aware that many keys expiring at the same moment can be a source of latency.</p>\n<h2>Valkey software watchdog</h2>\n<p>The <em>Valkey Software Watchdog</em> is a debugging tool<br>designed to track those latency problems that for one reason or the other<br>escaped an analysis using normal tools.</p>\n<p>The software watchdog is an experimental feature. While it is designed to<br>be used in production environments care should be taken to backup the database<br>before proceeding as it could possibly have unexpected interactions with the<br>normal execution of the Valkey server.</p>\n<p>It is important to use it only as <em>last resort</em> when there is no way to track the issue by other means.</p>\n<p>This is how this feature works:</p>\n<ul>\n<li>The user enables the software watchdog using the <code>CONFIG SET</code> command.</li>\n<li>Valkey starts monitoring itself constantly.</li>\n<li>If Valkey detects that the server is blocked into some operation that is not returning fast enough, and that may be the source of the latency issue, a low level report about where the server is blocked is dumped on the log file.</li>\n<li>The user contacts the developers by opening an issue on GitHub, including the watchdog report in the message.</li>\n</ul>\n<p>Note that this feature cannot be enabled using the valkey.conf file, because it is designed to be enabled only in already running instances and only for debugging purposes.</p>\n<p>To enable the feature just use the following:</p>\n<pre><code>CONFIG SET watchdog-period 500\n</code></pre>\n<p>The period is specified in milliseconds. In the above example I specified to log latency issues only if the server detects a delay of 500 milliseconds or greater. The minimum configurable period is 200 milliseconds.</p>\n<p>When you are done with the software watchdog you can turn it off setting the <code>watchdog-period</code> parameter to 0. <strong>Important:</strong> remember to do this because keeping the instance with the watchdog turned on for a longer time than needed is generally not a good idea.</p>\n<p>The following is an example of what you&#39;ll see printed in the log file once the software watchdog detects a delay longer than the configured one:</p>\n<pre><code>[8547 | signal handler] (1333114359)\n--- WATCHDOG TIMER EXPIRED ---\n/lib/libc.so.6(nanosleep+0x2d) [0x7f16b5c2d39d]\n/lib/libpthread.so.0(+0xf8f0) [0x7f16b5f158f0]\n/lib/libc.so.6(nanosleep+0x2d) [0x7f16b5c2d39d]\n/lib/libc.so.6(usleep+0x34) [0x7f16b5c62844]\n./valkey-server(debugCommand+0x3e1) [0x43ab41]\n./valkey-server(call+0x5d) [0x415a9d]\n./valkey-server(processCommand+0x375) [0x415fc5]\n./valkey-server(processInputBuffer+0x4f) [0x4203cf]\n./valkey-server(readQueryFromClient+0xa0) [0x4204e0]\n./valkey-server(aeProcessEvents+0x128) [0x411b48]\n./valkey-server(aeMain+0x2b) [0x411dbb]\n./valkey-server(main+0x2b6) [0x418556]\n/lib/libc.so.6(__libc_start_main+0xfd) [0x7f16b5ba1c4d]\n./valkey-server() [0x411099]\n------\n</code></pre>\n<p>Note: in the example the <strong>DEBUG SLEEP</strong> command was used in order to block the server. The stack trace is different if the server blocks in a different context.</p>\n<p>If you happen to collect multiple watchdog stack traces you are encouraged to post everything in a GitHub issue.<br>The more traces we obtain, the simpler it will be to understand what the problem with your instance is.</p>\n"
      },
      {
        "id": "lru-cache",
        "topicName": "Key eviction",
        "description": "Overview of Valkey key eviction policies (LRU, LFU, etc.)",
        "htmlContent": "<p>When Valkey is used as a cache, it is often convenient to let it automatically<br>evict old data as you add new data. This behavior is well known in the<br>developer community, since it is the default behavior for the popular<br><em>memcached</em> system.</p>\n<p>This page covers the more general topic of the Valkey <code>maxmemory</code> directive used to limit the memory usage to a fixed amount. It also extensively covers the LRU eviction algorithm used by Valkey, which is actually an approximation of<br>the exact LRU.</p>\n<h2><code>Maxmemory</code> configuration directive</h2>\n<p>The <code>maxmemory</code> configuration directive configures Valkey<br>to use a specified amount of memory for the data set. You can<br>set the configuration directive using the <code>valkey.conf</code> file, or later using<br>the <code>CONFIG SET</code> command at runtime.</p>\n<p>For example, to configure a memory limit of 100 megabytes, you can use the<br>following directive inside the <code>valkey.conf</code> file:</p>\n<pre><code>maxmemory 100mb\n</code></pre>\n<p>Setting <code>maxmemory</code> to zero results into no memory limits. This is the<br>default behavior for 64 bit systems, while 32 bit systems use an implicit<br>memory limit of 3GB.<br>When the specified amount of memory is reached, how <strong>eviction policies</strong> are configured determines the default behavior.<br>Valkey can return errors for commands that could result in more memory<br>being used, or it can evict some old data to return back to the<br>specified limit every time new data is added.</p>\n<h3>Considerations for <code>maxmemory</code> when using replication</h3>\n<p>If you have set up replication, Valkey needs some RAM as a buffer to send data to the replicas and AOF files. This memory is not included in the used memory count that is compared against the <code>maxmemory</code> to trigger eviction. </p>\n<p>The reason for that is that the key eviction process itself generates some changes that need to be added to the replication and AOF buffers. If these buffers were counted for the key eviction, this would result in a loop where a freed memory would immediately be used up by these updates causing more keys to be deleted repeatedly until the database is empty.</p>\n<p>For Valkey with replication configured, it&#39;s recommended to set the <code>maxmemory</code> value lower than for a single instance without replication. This way you ensure there&#39;s enough memory for AOF and replication buffers, and other processes. </p>\n<p>You can estimate how much memory is used by the replication and AOF buffers using the <code>mem_not_counted_for_evict</code> value of the INFO memory command output. </p>\n<h2>Eviction policies</h2>\n<p>The exact behavior Valkey follows when the <code>maxmemory</code> limit is reached is<br>configured using the <code>maxmemory-policy</code> configuration directive.</p>\n<p>The following policies are available:</p>\n<ul>\n<li><strong>noeviction</strong>: New values aren&#39;t saved when memory limit is reached. When a database uses replication, this applies to the primary database</li>\n<li><strong>allkeys-lru</strong>: Keeps most recently used keys; removes least recently used (LRU) keys</li>\n<li><strong>allkeys-lfu</strong>: Keeps frequently used keys; removes least frequently used (LFU) keys</li>\n<li><strong>volatile-lru</strong>: Removes least recently used keys with a time-to-live (TTL) set.</li>\n<li><strong>volatile-lfu</strong>: Removes least frequently used keys with a TTL set.</li>\n<li><strong>allkeys-random</strong>: Randomly removes keys to make space for the new data added.</li>\n<li><strong>volatile-random</strong>: Randomly removes keys with a TTL set.</li>\n<li><strong>volatile-ttl</strong>: Removes keys with a TTL set, the keys with the shortest remaining time-to-live value first.</li>\n</ul>\n<p>The policies <strong>volatile-lru</strong>, <strong>volatile-lfu</strong>, <strong>volatile-random</strong>, and <strong>volatile-ttl</strong> behave like <strong>noeviction</strong> if there are no keys to evict matching the prerequisites.</p>\n<p><strong>LRU</strong>, <strong>LFU</strong> and <strong>volatile-ttl</strong> are implemented using approximated randomized algorithms.</p>\n<p>Picking the right eviction policy is important depending on the access pattern<br>of your application, however you can reconfigure the policy at runtime while<br>the application is running, and monitor the number of cache misses and hits<br>using the Valkey <code>INFO</code> output to tune your setup.</p>\n<p>In general as a rule of thumb:</p>\n<ul>\n<li><p>Use the <strong>allkeys-lru</strong> policy when you expect a power-law distribution in the popularity of your requests. That is, you expect a subset of elements will be accessed far more often than the rest. <strong>This is a good pick if you are unsure</strong>.</p>\n</li>\n<li><p>Use the <strong>allkeys-random</strong> if you have a cyclic access where all the keys are scanned continuously, or when you expect the distribution to be uniform.</p>\n</li>\n<li><p>Use the <strong>volatile-ttl</strong> if you want to be able to provide hints to Valkey about what are good candidate for expiration by using different TTL values when you create your cache objects.</p>\n</li>\n</ul>\n<p>The <strong>volatile-lru</strong> and <strong>volatile-random</strong> policies are mainly useful when you want to use a single instance for both caching and to have a set of persistent keys. However it is usually a better idea to run two Valkey instances to solve such a problem.</p>\n<p>It is also worth noting that setting a TTL value to a key costs memory, so using a policy like <strong>allkeys-lru</strong> is more memory efficient since there is no need for a TTL configuration for the key to be evicted under memory pressure.</p>\n<h2>How the eviction process works</h2>\n<p>It is important to understand that the eviction process works like this:</p>\n<ul>\n<li>A client runs a new command, resulting in more data added.</li>\n<li>Valkey checks the memory usage, and if it is greater than the <code>maxmemory</code> limit , it evicts keys according to the policy.</li>\n<li>A new command is executed, and so forth.</li>\n</ul>\n<p>So we continuously cross the boundaries of the memory limit, by going over it, and then by evicting keys to return back under the limits.</p>\n<p>If a command results in a lot of memory being used (like a big set intersection stored into a new key) for some time, the memory limit can be surpassed by a noticeable amount.</p>\n<h2>Monitor eviction</h2>\n<p>To monitor the point when Valkey starts to evict data, use the <code>INFO MEMORY</code> command. The following fields provide the information about the memory usage and the condition to trigger key eviction:</p>\n<ul>\n<li><code>used_memory</code>: The total number of bytes that the server allocated for storing data. It is the sum of the <code>used_memory_overhead</code> and the <code>used_memory_dataset</code> outputs.</li>\n<li><code>mem_not_counted_for_evict</code>: The amount of memory not counted for eviction. This includes the replication buffer and AOF buffer.</li>\n</ul>\n<p>Thus, the memory usage to trigger eviction is calculated as follows:</p>\n<pre><code>used_memory - mem_not_counted_for_evict &gt; maxmemory\n</code></pre>\n<p>Let&#39;s see how this works in practice. </p>\n<p>Consider the following INFO memory output:</p>\n<pre><code># Memory\nused_memory:12498952\n...\nmaxmemory:10737418240\n...\nmem_not_counted_for_evict:12336\n...\n</code></pre>\n<p>In this example, Valkey will not start data eviction because the actual memory usage is <code>12498952 - 12336 = 12486616</code> which is considerably less than <code>maxmemory</code>.</p>\n<p>The following example shows that we&#39;re nearing eviction:</p>\n<pre><code># Memory\nused_memory:12498952\n...\nmaxmemory:12500000\n...\nmem_not_counted_for_evict:12336\n</code></pre>\n<p>Once eviction happens, additional information is available through the <code>INFO STATS</code> metrics. The <code>total_eviction_exceeded_time</code> metric shows the total time in milliseconds that <code>used_memory</code> exceeded <code>maxmemory</code>.</p>\n<h2>Approximated LRU algorithm</h2>\n<p>Valkey LRU algorithm is not an exact implementation. This means that Valkey is<br>not able to pick the <em>best candidate</em> for eviction, that is, the key that<br>was accessed the furthest in the past. Instead it will try to run an approximation<br>of the LRU algorithm, by sampling a small number of keys, and evicting the<br>one that is the best (with the oldest access time) among the sampled keys, while<br>also managing a pool of good candidates for eviction.<br>This algorithm consumes less memory than an exact LRU algorithm.</p>\n<p>What is important about the Valkey LRU algorithm is that you <strong>are able to tune</strong> the precision of the algorithm by changing the number of samples to check for every eviction. This parameter is controlled by the following configuration directive:</p>\n<pre><code>maxmemory-samples 5\n</code></pre>\n<p>The reason Valkey does not use a true LRU implementation is because it<br>costs more memory. However, the approximation is virtually equivalent for an<br>application using Valkey. This figure compares<br>the LRU approximation used by Valkey with true LRU.</p>\n<p><img src=\"lru_comparison.png\" alt=\"LRU comparison\"></p>\n<p>The test to generate the above graphs filled a server with a given number of keys. The keys were accessed from the first to the last. The first keys are the best candidates for eviction using an LRU algorithm. Later more 50% of keys are added, in order to force half of the old keys to be evicted.</p>\n<p>You can see three kind of dots in the graphs, forming three distinct bands.</p>\n<ul>\n<li>The light gray band are objects that were evicted.</li>\n<li>The gray band are objects that were not evicted.</li>\n<li>The green band are objects that were added.</li>\n</ul>\n<p>In a theoretical LRU implementation we expect that, among the old keys, the first half will be evicted.<br>The Valkey LRU algorithm will instead only <em>probabilistically</em> evicts the older keys.</p>\n<p>As you can see, Redis OSS 3.0 does a reasonable job with 5 samples.<br>Using a sample size of 10, the approximation is very close to an exact LRU implementation.<br>(The LRU algorithm hasn&#39;t changed considerably since this test was performed, so the performance of Valkey is similar in this regard.)</p>\n<p>Note that LRU is just a model to predict how likely a given key will be accessed in the future. Moreover, if your data access pattern closely<br>resembles the power law; most of the accesses will be in the set of keys<br>the LRU approximated algorithm can handle well.</p>\n<p>In simulations we found that using a power law access pattern, the difference between true LRU and Valkey approximation were minimal or non-existent.</p>\n<p>However you can raise the sample size to 10 at the cost of some additional CPU<br>usage to closely approximate true LRU, and check if this makes a<br>difference in your cache misses rate.</p>\n<p>To experiment in production with different values for the sample size by using<br>the <code>CONFIG SET maxmemory-samples &lt;count&gt;</code> command, is very simple.</p>\n<h2>The LFU mode</h2>\n<p>The <a href=\"https://web.archive.org/web/20241019222228/http://antirez.com/news/109\">Least Frequently Used eviction mode</a> is available as an alternative to LRU.<br>This mode may work better (provide a better<br>hits/misses ratio) in certain cases. In LFU mode, Valkey will try to track<br>the frequency of access of items, so the ones used rarely are evicted. This means<br>the keys used often have a higher chance of remaining in memory.</p>\n<p>To configure the LFU mode, the following policies are available:</p>\n<ul>\n<li><code>volatile-lfu</code> Evict using approximated LFU among the keys with a time-to-live (TTL) set.</li>\n<li><code>allkeys-lfu</code> Evict any key using approximated LFU.</li>\n</ul>\n<p>LFU is approximated like LRU: it uses a probabilistic counter, called a <a href=\"https://en.wikipedia.org/wiki/Approximate_counting_algorithm\">Morris counter</a> to estimate the object access frequency using just a few bits per object, combined with a decay period so that the counter is reduced over time. At some point we no longer want to consider keys as frequently accessed, even if they were in the past, so that the algorithm can adapt to a shift in the access pattern.</p>\n<p>That information is sampled similarly to what happens for LRU (as explained in the previous section of this documentation) to select a candidate for eviction.</p>\n<p>However unlike LRU, LFU has certain tunable parameters: for example, how fast<br>should a frequent item lower in rank if it gets no longer accessed? It is also possible to tune the Morris counters range to better adapt the algorithm to specific use cases.</p>\n<p>By default Valkey is configured to:</p>\n<ul>\n<li>Saturate the counter at, around, one million requests.</li>\n<li>Decay the counter every one minute.</li>\n</ul>\n<p>Those should be reasonable values and were tested experimentally, but the user may want to play with these configuration settings to pick optimal values.</p>\n<p>Instructions about how to tune these parameters can be found inside the example <code>valkey.conf</code> file in the source distribution. Briefly, they are:</p>\n<pre><code>lfu-log-factor 10\nlfu-decay-time 1\n</code></pre>\n<p>The decay time is the obvious one, it is the amount of minutes a counter should be decayed, when sampled and found to be older than that value. A special value of <code>0</code> means: we will never decay the counter.</p>\n<p>The counter <em>logarithm factor</em> changes how many hits are needed to saturate the frequency counter, which is just in the range 0-255. The higher the factor, the more accesses are needed to reach the maximum. The lower the factor, the better is the resolution of the counter for low accesses, according to the following table:</p>\n<pre><code>+--------+------------+------------+------------+------------+------------+\n| factor | 100 hits   | 1000 hits  | 100K hits  | 1M hits    | 10M hits   |\n+--------+------------+------------+------------+------------+------------+\n| 0      | 104        | 255        | 255        | 255        | 255        |\n+--------+------------+------------+------------+------------+------------+\n| 1      | 18         | 49         | 255        | 255        | 255        |\n+--------+------------+------------+------------+------------+------------+\n| 10     | 10         | 18         | 142        | 255        | 255        |\n+--------+------------+------------+------------+------------+------------+\n| 100    | 8          | 11         | 49         | 143        | 255        |\n+--------+------------+------------+------------+------------+------------+\n</code></pre>\n<p>So basically the factor is a trade off between better distinguishing items with low accesses VS distinguishing items with high accesses. More information is available in the example <code>valkey.conf</code> file.</p>\n"
      },
      {
        "id": "mass-insertion",
        "topicName": "Bulk loading",
        "description": "Writing data in bulk using the RESP protocol\n",
        "htmlContent": "<p>Bulk loading is the process of loading Valkey with a large amount of pre-existing data. Ideally, you want to perform this operation quickly and efficiently. This document describes some strategies for bulk loading data in Valkey.</p>\n<h2>Bulk loading using the RESP protocol</h2>\n<p>Using a normal Valkey client to perform bulk loading is not a good idea<br>for a few reasons: the naive approach of sending one command after the other<br>is slow because you have to pay for the round trip time for every command.<br>It is possible to use pipelining, but for bulk loading of many records<br>you need to write new commands while you read replies at the same time to<br>make sure you are inserting as fast as possible.</p>\n<p>Only a small percentage of clients support non-blocking I/O, and not all the<br>clients are able to parse the replies in an efficient way in order to maximize<br>throughput. For all of these reasons the preferred way to mass import data into<br>Valkey is to generate a text file containing the Valkey protocol, in raw format,<br>in order to call the commands needed to insert the required data.</p>\n<p>For instance if I need to generate a large data set where there are billions<br>of keys in the form: `keyN -&gt; ValueN&#39; I will create a file containing the<br>following commands in the Valkey protocol format:</p>\n<pre><code>SET Key0 Value0\nSET Key1 Value1\n...\nSET KeyN ValueN\n</code></pre>\n<p>Once this file is created, the remaining action is to feed it to Valkey<br>as fast as possible. In the past the way to do this was to use the<br><code>netcat</code> with the following command:</p>\n<pre><code>(cat data.txt; sleep 10) | nc localhost 6379 &gt; /dev/null\n</code></pre>\n<p>However this is not a very reliable way to perform mass import because netcat<br>does not really know when all the data was transferred and can&#39;t check for<br>errors. The <code>valkey-cli</code> utility<br>supports a <strong>pipe mode</strong> that was designed to perform<br>bulk loading.</p>\n<p>Using the pipe mode the command to run looks like the following:</p>\n<pre><code>cat data.txt | valkey-cli --pipe\n</code></pre>\n<p>That will produce an output similar to this:</p>\n<pre><code>All data transferred. Waiting for the last reply...\nLast reply received from server.\nerrors: 0, replies: 1000000\n</code></pre>\n<p>The valkey-cli utility will also make sure to only redirect errors received<br>from the Valkey instance to the standard output.</p>\n<h3>Generating RESP protocol</h3>\n<p>The RESP protocol is extremely simple to generate and parse, and is<br><a href=\"protocol\">Documented here</a>. However in order to generate protocol for<br>the goal of bulk loading you don&#39;t need to understand every detail of the<br>protocol, but just that every command is represented in the following way:</p>\n<pre><code>*&lt;args&gt;&lt;cr&gt;&lt;lf&gt;\n$&lt;len&gt;&lt;cr&gt;&lt;lf&gt;\n&lt;arg0&gt;&lt;cr&gt;&lt;lf&gt;\n&lt;arg1&gt;&lt;cr&gt;&lt;lf&gt;\n...\n&lt;argN&gt;&lt;cr&gt;&lt;lf&gt;\n</code></pre>\n<p>Where <code>&lt;cr&gt;</code> means &quot;\\r&quot; (or ASCII character 13) and <code>&lt;lf&gt;</code> means &quot;\\n&quot; (or ASCII character 10).</p>\n<p>For instance the command <strong>SET key value</strong> is represented by the following protocol:</p>\n<pre><code>*3&lt;cr&gt;&lt;lf&gt;\n$3&lt;cr&gt;&lt;lf&gt;\nSET&lt;cr&gt;&lt;lf&gt;\n$3&lt;cr&gt;&lt;lf&gt;\nkey&lt;cr&gt;&lt;lf&gt;\n$5&lt;cr&gt;&lt;lf&gt;\nvalue&lt;cr&gt;&lt;lf&gt;\n</code></pre>\n<p>Or represented as a quoted string:</p>\n<pre><code>&quot;*3\\r\\n$3\\r\\nSET\\r\\n$3\\r\\nkey\\r\\n$5\\r\\nvalue\\r\\n&quot;\n</code></pre>\n<p>The file you need to generate for bulk loading is just composed of commands<br>represented in the above way, one after the other.</p>\n<p>The following Ruby function generates valid protocol:</p>\n<pre><code class=\"language-ruby\">def gen_redis_proto(*cmd)\n    proto = &quot;&quot;\n    proto &lt;&lt; &quot;*&quot;+cmd.length.to_s+&quot;\\r\\n&quot;\n    cmd.each{|arg|\n        proto &lt;&lt; &quot;$&quot;+arg.to_s.bytesize.to_s+&quot;\\r\\n&quot;\n        proto &lt;&lt; arg.to_s+&quot;\\r\\n&quot;\n    }\n    proto\nend\n\nputs gen_redis_proto(&quot;SET&quot;,&quot;mykey&quot;,&quot;Hello World!&quot;).inspect\n</code></pre>\n<p>Using the above function it is possible to easily generate the key value pairs<br>in the above example, with this program:</p>\n<pre><code class=\"language-ruby\">(0...1000).each{|n|\n    STDOUT.write(gen_redis_proto(&quot;SET&quot;,&quot;Key#{n}&quot;,&quot;Value#{n}&quot;))\n}\n</code></pre>\n<p>We can run the program directly in pipe to valkey-cli in order to perform our<br>first mass import session.</p>\n<pre><code>$ ruby proto.rb | valkey-cli --pipe\nAll data transferred. Waiting for the last reply...\nLast reply received from server.\nerrors: 0, replies: 1000\n</code></pre>\n<h3>How the pipe mode works under the hood</h3>\n<p>The magic needed inside the pipe mode of valkey-cli is to be as fast as netcat<br>and still be able to understand when the last reply was sent by the server<br>at the same time.</p>\n<p>This is obtained in the following way:</p>\n<ul>\n<li>valkey-cli --pipe tries to send data as fast as possible to the server.</li>\n<li>At the same time it reads data when available, trying to parse it.</li>\n<li>Once there is no more data to read from stdin, it sends a special <strong>ECHO</strong><br>command with a random 20 byte string: we are sure this is the latest command<br>sent, and we are sure we can match the reply checking if we receive the same<br>20 bytes as a bulk reply.</li>\n<li>Once this special final command is sent, the code receiving replies starts<br>to match replies with these 20 bytes. When the matching reply is reached it<br>can exit with success.</li>\n</ul>\n<p>Using this trick we don&#39;t need to parse the protocol we send to the server<br>in order to understand how many commands we are sending, but just the replies.</p>\n<p>However while parsing the replies we take a counter of all the replies parsed<br>so that at the end we are able to tell the user the amount of commands<br>transferred to the server by the mass insert session.</p>\n"
      },
      {
        "id": "performance-on-cpu",
        "topicName": "CPU profiling",
        "description": "Performance engineering guide for on-CPU profiling and tracing\n",
        "htmlContent": "<h2>Filling the performance checklist</h2>\n<p>Valkey is developed with a great emphasis on performance. We do our best with<br>every release to make sure you&#39;ll experience a very stable and fast product. </p>\n<p>Nevertheless, if you&#39;re finding room to improve the efficiency of Valkey or<br>are pursuing a performance regression investigation you will need a concise<br>methodical way of monitoring and analyzing Valkey performance. </p>\n<p>To do so you can rely on different methodologies (some more suited than other<br>depending on the class of issues/analysis we intend to make). A curated list<br>of methodologies and their steps are enumerated by Brendan Greg at the<br><a href=\"https://www.brendangregg.com/methodology.html\">following link</a>. </p>\n<p>We recommend the Utilization Saturation and Errors (USE) Method for answering<br>the question of what is your bottleneck. Check the following mapping between<br>system resource, metric, and tools for a practical deep dive:<br><a href=\"https://www.brendangregg.com/USEmethod/use-rosetta.html\">USE method</a>. </p>\n<h3>Ensuring the CPU is your bottleneck</h3>\n<p>This guide assumes you&#39;ve followed one of the above methodologies to perform a<br>complete check of system health, and identified the bottleneck being the CPU.<br><strong>If you have identified that most of the time is spent blocked on I/O, locks,<br>timers, paging/swapping, etc., this guide is not for you</strong>. </p>\n<h3>Build Prerequisites</h3>\n<p>For a proper On-CPU analysis, Valkey (and any dynamically loaded library like<br>Valkey Modules) requires stack traces to be available to tracers, which you may<br>need to fix first. </p>\n<p>By default, Valkey is compiled with the <code>-O3</code> optimization flag (which we intent to keep<br>during profiling). This means that compiler optimizations are enabled which significantly<br>enhance the performance. Valkey is also compiled with the <code>-fno-omit-frame-pointer</code> flag<br>by default, ensuring that the frame pointer is preserved across function calls.<br>This combination allows for precise stack walking and call stack tracing,<br>which is essential for accurate profiling and debugging. Keeping the frame pointer<br>intact helps profiling tools like <code>perf</code>, <code>gdb</code>, and others correctly attribute on-CPU<br>time to deeper call stack frames, leading to more reliable insights into performance bottlenecks<br>and hotspots. This setup strikes a balance between maintaining a highly optimized executable<br>and ensuring that profiling and tracing tools provide accurate and actionable data.</p>\n<p>It&#39;s important that you ensure that:</p>\n<ul>\n<li>we still run with optimizations to get an accurate representation of production run times, meaning we will keep: <code>-O3</code></li>\n</ul>\n<p>You can do it as follows within valkey main repo:</p>\n<pre><code>$ make SERVER_CFLAGS=&quot;-g&quot;\n</code></pre>\n<h2>A set of instruments to identify performance regressions and/or potential <strong>on-CPU performance</strong> improvements</h2>\n<p>This document focuses specifically on <strong>on-CPU</strong> resource bottlenecks analysis,<br>meaning we&#39;re interested in understanding where threads are spending CPU cycles<br>while running on-CPU and, as importantly, whether those cycles are effectively<br>being used for computation or stalled waiting (not blocked!) for memory I/O,<br>and cache misses, etc.</p>\n<p>For that we will rely on toolkits (perf, bcc tools), and hardware specific PMCs<br>(Performance Monitoring Counters), to proceed with:</p>\n<ul>\n<li><p>Hotspot analysis (perf or bcc tools): to profile code execution and determine which functions are consuming the most time and thus are targets for optimization. We&#39;ll present two options to collect, report, and visualize hotspots either with perf or bcc/BPF tracing tools.</p>\n</li>\n<li><p>Call counts analysis: to count events including function calls, enabling us to correlate several calls/components at once, relying on bcc/BPF tracing tools.</p>\n</li>\n<li><p>Hardware event sampling: crucial for understanding CPU behavior, including memory I/O, stall cycles, and cache misses.</p>\n</li>\n</ul>\n<h3>Tool prerequisites</h3>\n<p>The following steps rely on Linux perf_events (aka <a href=\"https://man7.org/linux/man-pages/man1/perf.1.html\">&quot;perf&quot;</a>), <a href=\"https://github.com/iovisor/bcc\">bcc/BPF tracing tools</a>, and Brendan Greg’s <a href=\"https://github.com/brendangregg/FlameGraph\">FlameGraph repo</a>.</p>\n<p>We assume beforehand you have:</p>\n<ul>\n<li>Installed the perf tool on your system. Most Linux distributions will likely package this as a package related to the kernel. More information about the perf tool can be found at perf <a href=\"https://perf.wiki.kernel.org/\">wiki</a>.</li>\n<li>Followed the install <a href=\"https://github.com/iovisor/bcc/blob/master/INSTALL#installing-bcc\">bcc/BPF</a> instructions to install bcc toolkit on your machine.</li>\n<li>Cloned Brendan Greg’s <a href=\"https://github.com/brendangregg/FlameGraph\">FlameGraph repo</a> and made accessible the <code>difffolded.pl</code> and <code>flamegraph.pl</code> files, to generated the collapsed stack traces and Flame Graphs.</li>\n</ul>\n<h2>Hotspot analysis with perf or eBPF (stack traces sampling)</h2>\n<p>Profiling CPU usage by sampling stack traces at a timed interval is a fast and<br>easy way to identify performance-critical code sections (hotspots).</p>\n<h3>Sampling stack traces using perf</h3>\n<p>To profile both user- and kernel-level stacks of valkey-server for a specific<br>length of time, for example 60 seconds, at a sampling frequency of 999 samples<br>per second:</p>\n<pre><code>$ perf record -g --pid $(pgrep valkey-server) -F 999 -- sleep 60\n</code></pre>\n<h4>Displaying the recorded profile information using perf report</h4>\n<p>By default perf record will generate a perf.data file in the current working<br>directory. </p>\n<p>You can then report with a call-graph output (call chain, stack backtrace),<br>with a minimum call graph inclusion threshold of 0.5%, with:</p>\n<pre><code>$ perf report -g &quot;graph,0.5,caller&quot;\n</code></pre>\n<p>See the <a href=\"https://man7.org/linux/man-pages/man1/perf-report.1.html\">perf report</a><br>documentation for advanced filtering, sorting and aggregation capabilities.</p>\n<h4>Visualizing the recorded profile information using Flame Graphs</h4>\n<p><a href=\"https://www.brendangregg.com/flamegraphs.html\">Flame graphs</a> allow for a quick<br>and accurate visualization of frequent code-paths. They can be generated using<br>Brendan Greg&#39;s open source programs on <a href=\"https://github.com/brendangregg/FlameGraph\">github</a>,<br>which create interactive SVGs from folded stack files.</p>\n<p>Specifically, for perf we need to convert the generated perf.data into the<br>captured stacks, and fold each of them into single lines. You can then render<br>the on-CPU flame graph with:</p>\n<pre><code>$ perf script &gt; valkey.perf.stacks\n$ stackcollapse-perf.pl valkey.perf.stacks &gt; valkey.folded.stacks\n$ flamegraph.pl valkey.folded.stacks &gt; valkey.svg\n</code></pre>\n<p>By default, perf script will generate a perf.data file in the current working<br>directory. See the <a href=\"https://linux.die.net/man/1/perf-script\">perf script</a><br>documentation for advanced usage.</p>\n<p>See <a href=\"https://github.com/brendangregg/FlameGraph#options\">FlameGraph usage options</a><br>for more advanced stack trace visualizations (like the differential one).</p>\n<h4>Archiving and sharing recorded profile information</h4>\n<p>So that analysis of the perf.data contents can be possible on a machine other<br>than the one on which collection happened, you need to export along with the<br>perf.data file all object files with build-ids found in the record data file.<br>This can be easily done with the help of<br><a href=\"https://github.com/torvalds/linux/blob/master/tools/perf/perf-archive.sh\">perf-archive.sh</a><br>script:</p>\n<pre><code>$ perf-archive.sh perf.data\n</code></pre>\n<p>Now please run:</p>\n<pre><code>$ tar xvf perf.data.tar.bz2 -C ~/.debug\n</code></pre>\n<p>on the machine where you need to run <code>perf report</code>.</p>\n<h3>Sampling stack traces using bcc/BPF&#39;s profile</h3>\n<p>Similarly to perf, as of Linux kernel 4.9, BPF-optimized profiling is now fully<br>available with the promise of lower overhead on CPU (as stack traces are<br>frequency counted in kernel context) and disk I/O resources during profiling. </p>\n<p>Apart from that, and relying solely on bcc/BPF&#39;s profile tool, we have also<br>removed the perf.data and intermediate steps if stack traces analysis is our<br>main goal. You can use bcc&#39;s profile tool to output folded format directly, for<br>flame graph generation:</p>\n<pre><code>$ /usr/share/bcc/tools/profile -F 999 -f --pid $(pgrep valkey-server) --duration 60 &gt; valkey.folded.stacks\n</code></pre>\n<p>In that manner, we&#39;ve remove any preprocessing and can render the on-CPU flame<br>graph with a single command:</p>\n<pre><code>$ flamegraph.pl valkey.folded.stacks &gt; valkey.svg\n</code></pre>\n<h3>Visualizing the recorded profile information using Flame Graphs</h3>\n<h2>Call counts analysis with bcc/BPF</h2>\n<p>A function may consume significant CPU cycles either because its code is slow<br>or because it&#39;s frequently called. To answer at what rate functions are being<br>called, you can rely upon call counts analysis using BCC&#39;s <code>funccount</code> tool:</p>\n<pre><code>$ /usr/share/bcc/tools/funccount &#39;valkey-server:(call*|*Read*|*Write*)&#39; --pid $(pgrep valkey-server) --duration 60\nTracing 64 functions for &quot;valkey-server:(call*|*Read*|*Write*)&quot;... Hit Ctrl-C to end.\n\nFUNC                                    COUNT\ncall                                      334\nhandleClientsWithPendingWrites            388\nclientInstallWriteHandler                 388\npostponeClientRead                        514\nhandleClientsWithPendingReadsUsingThreads      735\nhandleClientsWithPendingWritesUsingThreads      735\nprepareClientToWrite                     1442\nDetaching...\n</code></pre>\n<p>The above output shows that, while tracing, the Valkey&#39;s call() function was<br>called 334 times, handleClientsWithPendingWrites() 388 times, etc.</p>\n<h2>Hardware event counting with Performance Monitoring Counters (PMCs)</h2>\n<p>Many modern processors contain a performance monitoring unit (PMU) exposing<br>Performance Monitoring Counters (PMCs). PMCs are crucial for understanding CPU<br>behavior, including memory I/O, stall cycles, and cache misses, and provide<br>low-level CPU performance statistics that aren&#39;t available anywhere else.</p>\n<p>The design and functionality of a PMU is CPU-specific and you should assess<br>your CPU supported counters and features by using <code>perf list</code>. </p>\n<p>To calculate the number of instructions per cycle, the number of micro ops<br>executed, the number of cycles during which no micro ops were dispatched, the<br>number stalled cycles on memory, including a per memory type stalls, for the<br>duration of 60s, specifically for the valkey-server process: </p>\n<pre><code>$ perf stat -e &quot;cpu-clock,cpu-cycles,instructions,uops_executed.core,uops_executed.stall_cycles,cache-references,cache-misses,cycle_activity.stalls_total,cycle_activity.stalls_mem_any,cycle_activity.stalls_l3_miss,cycle_activity.stalls_l2_miss,cycle_activity.stalls_l1d_miss&quot; --pid $(pgrep valkey-server) -- sleep 60\n\nPerformance counter stats for process id &#39;3038&#39;:\n\n  60046.411437      cpu-clock (msec)          #    1.001 CPUs utilized          \n  168991975443      cpu-cycles                #    2.814 GHz                      (36.40%)\n  388248178431      instructions              #    2.30  insn per cycle           (45.50%)\n  443134227322      uops_executed.core        # 7379.862 M/sec                    (45.51%)\n   30317116399      uops_executed.stall_cycles #  504.895 M/sec                    (45.51%)\n     670821512      cache-references          #   11.172 M/sec                    (45.52%)\n      23727619      cache-misses              #    3.537 % of all cache refs      (45.43%)\n   30278479141      cycle_activity.stalls_total #  504.251 M/sec                    (36.33%)\n   19981138777      cycle_activity.stalls_mem_any #  332.762 M/sec                    (36.33%)\n     725708324      cycle_activity.stalls_l3_miss #   12.086 M/sec                    (36.33%)\n    8487905659      cycle_activity.stalls_l2_miss #  141.356 M/sec                    (36.32%)\n   10011909368      cycle_activity.stalls_l1d_miss #  166.736 M/sec                    (36.31%)\n\n  60.002765665 seconds time elapsed\n</code></pre>\n<p>It&#39;s important to know that there are two very different ways in which PMCs can<br>be used (counting and sampling), and we&#39;ve focused solely on PMCs counting for<br>the sake of this analysis. Brendan Greg clearly explains it on the following<br><a href=\"https://www.brendangregg.com/blog/2017-05-04/the-pmcs-of-ec2.html\">link</a>.</p>\n"
      },
      {
        "id": "pipelining",
        "topicName": "Pipelining",
        "description": "How to optimize round-trip times by batching Valkey commands",
        "htmlContent": "<p>Valkey pipelining is a technique for improving performance by issuing multiple commands at once without waiting for the response to each individual command. Pipelining is supported by most Valkey clients. This document describes the problem that pipelining is designed to solve and how pipelining works in Valkey.</p>\n<h2>Request/Response protocols and round-trip time (RTT)</h2>\n<p>Valkey is a TCP server using the client-server model and what is called a <em>Request/Response</em> protocol.</p>\n<p>This means that usually a request is accomplished with the following steps:</p>\n<ul>\n<li>The client sends a query to the server, and reads from the socket, usually in a blocking way, for the server response.</li>\n<li>The server processes the command and sends the response back to the client.</li>\n</ul>\n<p>So for instance a four commands sequence is something like this:</p>\n<ul>\n<li><em>Client:</em> INCR X</li>\n<li><em>Server:</em> 1</li>\n<li><em>Client:</em> INCR X</li>\n<li><em>Server:</em> 2</li>\n<li><em>Client:</em> INCR X</li>\n<li><em>Server:</em> 3</li>\n<li><em>Client:</em> INCR X</li>\n<li><em>Server:</em> 4</li>\n</ul>\n<p>Clients and Servers are connected via a network link.<br>Such a link can be very fast (a loopback interface) or very slow (a connection established over the Internet with many hops between the two hosts).<br>Whatever the network latency is, it takes time for the packets to travel from the client to the server, and back from the server to the client to carry the reply.</p>\n<p>This time is called RTT (Round Trip Time).<br>It&#39;s easy to see how this can affect performance when a client needs to perform many requests in a row (for instance adding many elements to the same list, or populating a database with many keys).<br>For instance if the RTT time is 250 milliseconds (in the case of a very slow link over the Internet), even if the server is able to process 100k requests per second, we&#39;ll be able to process at max four requests per second.</p>\n<p>If the interface used is a loopback interface, the RTT is much shorter, typically sub-millisecond, but even this will add up to a lot if you need to perform many writes in a row.</p>\n<p>Fortunately there is a way to improve this use case.</p>\n<h2>Valkey Pipelining</h2>\n<p>A Request/Response server can be implemented so that it is able to process new requests even if the client hasn&#39;t already read the old responses.<br>This way it is possible to send <em>multiple commands</em> to the server without waiting for the replies at all, and finally read the replies in a single step.</p>\n<p>This is called pipelining, and is a technique widely in use for many decades.<br>For instance many POP3 protocol implementations already support this feature, dramatically speeding up the process of downloading new emails from the server.</p>\n<p>Valkey has supported pipelining since its early days, so whatever version you are running, you can use pipelining with Valkey.<br>This is an example using the raw netcat utility:</p>\n<pre><code class=\"language-bash\">$ (printf &quot;PING\\r\\nPING\\r\\nPING\\r\\n&quot;; sleep 1) | nc localhost 6379\n+PONG\n+PONG\n+PONG\n</code></pre>\n<p>This time we don&#39;t pay the cost of RTT for every call, but just once for the three commands.</p>\n<p>To be explicit, with pipelining the order of operations of our very first example will be the following:</p>\n<ul>\n<li><em>Client:</em> INCR X</li>\n<li><em>Client:</em> INCR X</li>\n<li><em>Client:</em> INCR X</li>\n<li><em>Client:</em> INCR X</li>\n<li><em>Server:</em> 1</li>\n<li><em>Server:</em> 2</li>\n<li><em>Server:</em> 3</li>\n<li><em>Server:</em> 4</li>\n</ul>\n<blockquote>\n<p><strong>IMPORTANT NOTE</strong>: While the client sends commands using pipelining, the server will be forced to queue the replies, using memory. So if you need to send a lot of commands with pipelining, it is better to send them as batches each containing a reasonable number, for instance 10k commands, read the replies, and then send another 10k commands again, and so forth. The speed will be nearly the same, but the additional memory used will be at most the amount needed to queue the replies for these 10k commands.</p>\n</blockquote>\n<h2>It&#39;s not just a matter of RTT</h2>\n<p>Pipelining is not just a way to reduce the latency cost associated with the<br>round trip time, it actually greatly improves the number of operations<br>you can perform per second in a given Valkey server.<br>This is because without using pipelining, serving each command is very cheap from<br>the point of view of accessing the data structures and producing the reply,<br>but it is very costly from the point of view of doing the socket I/O. This<br>involves calling the <code>read()</code> and <code>write()</code> syscall, that means going from user<br>land to kernel land.<br>The context switch is a huge speed penalty.</p>\n<p>When pipelining is used, many commands are usually read with a single <code>read()</code><br>system call, and multiple replies are delivered with a single <code>write()</code> system<br>call. Consequently, the number of total queries performed per second<br>initially increases almost linearly with longer pipelines, and eventually<br>reaches 10 times the baseline obtained without pipelining, as shown in this figure.</p>\n<p><img src=\"pipeline_iops.png\" alt=\"Pipeline size and IOPs\"></p>\n<h2>A real world code example</h2>\n<p>In the following benchmark we&#39;ll use a Ruby client, supporting pipelining, to test the speed improvement due to pipelining:</p>\n<pre><code class=\"language-ruby\">require &#39;rubygems&#39;\nrequire &#39;redis&#39;\n\ndef bench(descr)\n  start = Time.now\n  yield\n  puts &quot;#{descr} #{Time.now - start} seconds&quot;\nend\n\ndef without_pipelining\n  r = Redis.new\n  10_000.times do\n    r.ping\n  end\nend\n\ndef with_pipelining\n  r = Redis.new\n  r.pipelined do\n    10_000.times do\n      r.ping\n    end\n  end\nend\n\nbench(&#39;without pipelining&#39;) do\n  without_pipelining\nend\nbench(&#39;with pipelining&#39;) do\n  with_pipelining\nend\n</code></pre>\n<p>Running the above simple script yields the following figures on my MacOS system, running over the loopback interface, where pipelining will provide the smallest improvement as the RTT is already pretty low:</p>\n<pre><code>without pipelining 1.185238 seconds\nwith pipelining 0.250783 seconds\n</code></pre>\n<p>As you can see, using pipelining, we improved the transfer by a factor of five.</p>\n<h2>Pipelining vs Scripting</h2>\n<p>Using <a href=\"../commands/eval\">Valkey scripting</a>, a number of use cases for pipelining can be addressed more efficiently using scripts that perform a lot of the work needed at the server side.<br>A big advantage of scripting is that it is able to both read and write data with minimal latency, making operations like <em>read, compute, write</em> very fast (pipelining can&#39;t help in this scenario since the client needs the reply of the read command before it can call the write command).</p>\n<p>Sometimes the application may also want to send <code>EVAL</code> or <code>EVALSHA</code> commands in a pipeline.<br>This is entirely possible and Valkey explicitly supports it with the <a href=\"../commands/script-load\">SCRIPT LOAD</a> command (it guarantees that <code>EVALSHA</code> can be called without the risk of failing).</p>\n<h2>Appendix: Why are busy loops slow even on the loopback interface?</h2>\n<p>Even with all the background covered in this page, you may still wonder why<br>a Valkey benchmark like the following (in pseudo code), is slow even when<br>executed in the loopback interface, when the server and the client are running<br>in the same physical machine:</p>\n<pre><code class=\"language-sh\">FOR-ONE-SECOND:\n    Valkey.SET(&quot;foo&quot;,&quot;bar&quot;)\nEND\n</code></pre>\n<p>After all, if both the Valkey process and the benchmark are running in the same<br>box, isn&#39;t it just copying messages in memory from one place to another without<br>any actual latency or networking involved?</p>\n<p>The reason is that processes in a system are not always running, actually it is<br>the kernel scheduler that lets the process run.<br>So, for instance, when the benchmark is allowed to run, it reads the reply from the Valkey server (related to the last command executed), and writes a new command.<br>The command is now in the loopback interface buffer, but in order to be read by the server, the kernel should schedule the server process (currently blocked in a system call)<br>to run, and so forth.<br>So in practical terms the loopback interface still involves network-like latency, because of how the kernel scheduler works.</p>\n<p>Basically a busy loop benchmark is the silliest thing that can be done when<br>metering performances on a networked server. The wise thing is just avoiding<br>benchmarking in this way.</p>\n"
      }
    ]
  },
  {
    "title": "TROUBLESHOOTING",
    "items": [
      {
        "id": "debugging",
        "topicName": "Debugging",
        "description": "A guide to debugging Valkey server processes\n",
        "htmlContent": "<p>Valkey is developed with an emphasis on stability. We do our best with<br>every release to make sure you&#39;ll experience a stable product with no<br>crashes. However, if you ever need to debug the Valkey process itself, read on.</p>\n<p>When Valkey crashes, it produces a detailed report of what happened. However,<br>sometimes looking at the crash report is not enough, nor is it possible for<br>the Valkey core team to reproduce the issue independently. In this scenario, we<br>need help from the user who can reproduce the issue.</p>\n<p>This guide shows how to use GDB to provide the information the<br>Valkey developers will need to track the bug more easily.</p>\n<h2>What is GDB?</h2>\n<p>GDB is the Gnu Debugger: a program that is able to inspect the internal state<br>of another program. Usually tracking and fixing a bug is an exercise in<br>gathering more information about the state of the program at the moment the<br>bug happens, so GDB is an extremely useful tool.</p>\n<p>GDB can be used in two ways:</p>\n<ul>\n<li>It can attach to a running program and inspect the state of it at runtime.</li>\n<li>It can inspect the state of a program that already terminated using what is called a <em>core file</em>, that is, the image of the memory at the time the program was running.</li>\n</ul>\n<p>From the point of view of investigating Valkey bugs we need to use both of these<br>GDB modes. The user able to reproduce the bug attaches GDB to their running Valkey<br>instance, and when the crash happens, they create the <code>core</code> file that in turn<br>the developer will use to inspect the Valkey internals at the time of the crash.</p>\n<p>This way the developer can perform all the inspections in his or her computer<br>without the help of the user, and the user is free to restart Valkey in their<br>production environment.</p>\n<h2>Compiling Valkey without optimizations</h2>\n<p>By default, Valkey is compiled with the <code>-O3</code> optimization flag, which enables<br>a high level of compiler optimizations that aim to maximize runtime performance.<br>Valkey is also compiled with the <code>-fno-omit-frame-pointer</code> flag by default, ensuring that<br>the frame pointer is preserved across function calls. This combination allows for<br>precise stack walking and call stack tracing, which is essential for debugging.</p>\n<p>It is better to attach GDB to Valkey compiled without optimizations using the<br><code>make noopt</code> command (instead of just using the plain <code>make</code> command). However,<br>if you have an already running Valkey in production there is no need to recompile<br>and restart it if this is going to create problems on your side. GDB still works<br>against executables compiled with optimizations.</p>\n<p>You should not be overly concerned at the loss of performance from compiling Valkey<br>without optimizations. It is unlikely that this will cause problems in your<br>environment as Valkey is not very CPU-bound.</p>\n<h2>Attaching GDB to a running process</h2>\n<p>If you have an already running Valkey server, you can attach GDB to it, so that<br>if Valkey crashes it will be possible to both inspect the internals and generate<br>a <code>core dump</code> file.</p>\n<p>After you attach GDB to the Valkey process it will continue running as usual without<br>any loss of performance, so this is not a dangerous procedure.</p>\n<p>In order to attach GDB the first thing you need is the <em>process ID</em> of the running<br>Valkey instance (the <em>pid</em> of the process). You can easily obtain it using<br><code>valkey-cli</code>:</p>\n<pre><code>$ valkey-cli info | grep process_id\nprocess_id:58414\n</code></pre>\n<p>In the above example the process ID is <strong>58414</strong>.</p>\n<p>Login into your Valkey server.</p>\n<p>(Optional but recommended) Start <strong>screen</strong> or <strong>tmux</strong> or any other program that will make sure that your GDB session will not be closed if your ssh connection times out. You can learn more about screen in <a href=\"https://www.linuxjournal.com/article/6340\">this article</a>.</p>\n<p>Attach GDB to the running Valkey server by typing:</p>\n<pre><code>$ gdb &lt;path-to-valkey-executable&gt; &lt;pid&gt;\n</code></pre>\n<p>For example:</p>\n<pre><code>$ gdb /usr/local/bin/valkey-server 58414\n</code></pre>\n<p>GDB will start and will attach to the running server printing something like the following:</p>\n<pre><code>Reading symbols for shared libraries + done\n0x00007fff8d4797e6 in epoll_wait ()\n(gdb)\n</code></pre>\n<p>At this point GDB is attached but <strong>your Valkey instance is blocked by GDB</strong>. In<br>order to let the Valkey instance continue the execution just type <strong>continue</strong> at<br>the GDB prompt, and press enter.</p>\n<pre><code>(gdb) continue\nContinuing.\n</code></pre>\n<p>Done! Now your Valkey instance has GDB attached. Now you can wait for the next crash. :)</p>\n<p>Now it&#39;s time to detach your screen/tmux session, if you are running GDB using it, by<br>pressing <strong>Ctrl-a a</strong> key combination.</p>\n<h2>After the crash</h2>\n<p>Valkey has a command to simulate a segmentation fault (in other words a bad crash) using<br>the <code>DEBUG SEGFAULT</code> command (don&#39;t use it against a real production instance of course!<br>So I&#39;ll use this command to crash my instance to show what happens in the GDB side:</p>\n<pre><code>(gdb) continue\nContinuing.\n\nProgram received signal EXC_BAD_ACCESS, Could not access memory.\nReason: KERN_INVALID_ADDRESS at address: 0xffffffffffffffff\ndebugCommand (c=0x7ffc32005000) at debug.c:220\n220         *((char*)-1) = &#39;x&#39;;\n</code></pre>\n<p>As you can see GDB detected that Valkey crashed, and was even able to show me<br>the file name and line number causing the crash. This is already much better<br>than the Valkey crash report back trace (containing just function names and<br>binary offsets).</p>\n<h2>Obtaining the stack trace</h2>\n<p>The first thing to do is to obtain a full stack trace with GDB. This is as<br>simple as using the <strong>bt</strong> command:</p>\n<pre><code>(gdb) bt\n#0  debugCommand (c=0x7ffc32005000) at debug.c:220\n#1  0x000000010d246d63 in call (c=0x7ffc32005000) at valkey.c:1163\n#2  0x000000010d247290 in processCommand (c=0x7ffc32005000) at valkey.c:1305\n#3  0x000000010d251660 in processInputBuffer (c=0x7ffc32005000) at networking.c:959\n#4  0x000000010d251872 in readQueryFromClient (el=0x0, fd=5, privdata=0x7fff76f1c0b0, mask=220924512) at networking.c:1021\n#5  0x000000010d243523 in aeProcessEvents (eventLoop=0x7fff6ce408d0, flags=220829559) at ae.c:352\n#6  0x000000010d24373b in aeMain (eventLoop=0x10d429ef0) at ae.c:397\n#7  0x000000010d2494ff in main (argc=1, argv=0x10d2b2900) at valkey.c:2046\n</code></pre>\n<p>This shows the backtrace, but we also want to dump the processor registers using the <strong>info registers</strong> command:</p>\n<pre><code>(gdb) info registers\nrax            0x0  0\nrbx            0x7ffc32005000   140721147367424\nrcx            0x10d2b0a60  4515891808\nrdx            0x7fff76f1c0b0   140735188943024\nrsi            0x10d299777  4515796855\nrdi            0x0  0\nrbp            0x7fff6ce40730   0x7fff6ce40730\nrsp            0x7fff6ce40650   0x7fff6ce40650\nr8             0x4f26b3f7   1327936503\nr9             0x7fff6ce40718   140735020271384\nr10            0x81 129\nr11            0x10d430398  4517462936\nr12            0x4b7c04f8babc0  1327936503000000\nr13            0x10d3350a0  4516434080\nr14            0x10d42d9f0  4517452272\nr15            0x10d430398  4517462936\nrip            0x10d26cfd4  0x10d26cfd4 &lt;debugCommand+68&gt;\neflags         0x10246  66118\ncs             0x2b 43\nss             0x0  0\nds             0x0  0\nes             0x0  0\nfs             0x0  0\ngs             0x0  0\n</code></pre>\n<p>Please <strong>make sure to include</strong> both of these outputs in your bug report.</p>\n<h2>Obtaining the core file</h2>\n<p>The next step is to generate the core dump, that is the image of the memory of the running Valkey process. This is done using the <code>gcore</code> command:</p>\n<pre><code>(gdb) gcore\nSaved corefile core.58414\n</code></pre>\n<p>Now you have the core dump to send to the Valkey developer, but <strong>it is important<br>to understand</strong> that this happens to contain all the data that was inside the<br>Valkey instance at the time of the crash; Valkey developers will make sure not to<br>share the content with anyone else, and will delete the file as soon as it is no<br>longer used for debugging purposes, but you are warned that by sending the core<br>file you are sending your data.</p>\n<h2>What to send to developers</h2>\n<p>Finally you can send everything to the Valkey core team:</p>\n<ul>\n<li>The Valkey executable you are using.</li>\n<li>The stack trace produced by the <strong>bt</strong> command, and the registers dump.</li>\n<li>The core file you generated with gdb.</li>\n<li>Information about the operating system and GCC version, and Valkey version you are using.</li>\n</ul>\n<h2>Thank you</h2>\n<p>Your help is extremely important! Many issues can only be tracked this way. So<br>thanks!</p>\n"
      },
      {
        "id": "ldb",
        "topicName": "Debugging Lua scripts",
        "description": "How to use the built-in Lua debugger",
        "htmlContent": "<p>Valkey includes a complete Lua debugger, that can be<br>used to make the task of writing complex Lua scripts much simpler.</p>\n<p>The Valkey Lua debugger, codenamed LDB, has the following important features:</p>\n<ul>\n<li>It uses a server-client model, so it&#39;s a remote debugger.<br>The Valkey server acts as the debugging server, while the default client is <code>valkey-cli</code>.<br>However other clients can be developed by following the simple protocol implemented by the server.</li>\n<li>By default every new debugging session is a forked session.<br>It means that while the Valkey Lua script is being debugged, the server does not block and is usable for development or in order to execute multiple debugging sessions in parallel.<br>This also means that changes are <strong>rolled back</strong> after the script debugging session finished, so that&#39;s possible to restart a new debugging session again, using exactly the same Valkey data set as the previous debugging session.</li>\n<li>An alternative synchronous (non forked) debugging model is available on demand, so that changes to the dataset can be retained.<br>In this mode the server blocks for the time the debugging session is active.</li>\n<li>Support for step by step execution.</li>\n<li>Support for static and dynamic breakpoints.</li>\n<li>Support from logging the debugged script into the debugger console.</li>\n<li>Inspection of Lua variables.</li>\n<li>Tracing of Valkey commands executed by the script.</li>\n<li>Pretty printing of Valkey and Lua values.</li>\n<li>Infinite loops and long execution detection, which simulates a breakpoint.</li>\n</ul>\n<h2>Quick start</h2>\n<p>A simple way to get started with the Lua debugger is to watch this video<br>introduction:</p>\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IMvRfStaoyM\" frameborder=\"0\" allowfullscreen></iframe>\n\n<blockquote>\n<p>Important Note:  please make sure to avoid debugging Lua scripts using your Valkey production server.<br>Use a development server instead.<br>Also note that using the synchronous debugging mode (which is NOT the default) results in the Valkey server blocking for all the time the debugging session lasts.</p>\n</blockquote>\n<p>To start a new debugging session using <code>valkey-cli</code> do the following:</p>\n<ol>\n<li><p>Create your script in some file with your preferred editor. Let&#39;s assume you are editing your Valkey Lua script located at <code>/tmp/script.lua</code>.</p>\n</li>\n<li><p>Start a debugging session with:</p>\n<p> ./valkey-cli --ldb --eval /tmp/script.lua</p>\n</li>\n</ol>\n<p>Note that with the <code>--eval</code> option of <code>valkey-cli</code> you can pass key names and arguments to the script, separated by a comma, like in the following example:</p>\n<pre><code>./valkey-cli --ldb --eval /tmp/script.lua mykey somekey , arg1 arg2\n</code></pre>\n<p>You&#39;ll enter a special mode where <code>valkey-cli</code> no longer accepts its normal<br>commands, but instead prints a help screen and passes the unmodified debugging<br>commands directly to Valkey.</p>\n<p>The only commands which are not passed to the Valkey debugger are:</p>\n<ul>\n<li><code>quit</code> -- this will terminate the debugging session.<br>It&#39;s like removing all the breakpoints and using the <code>continue</code> debugging command.<br>Moreover the command will exit from <code>valkey-cli</code>.</li>\n<li><code>restart</code> -- the debugging session will restart from scratch, <strong>reloading the new version of the script from the file</strong>.<br>So a normal debugging cycle involves modifying the script after some debugging, and calling <code>restart</code> in order to start debugging again with the new script changes.</li>\n<li><code>help</code> -- this command is passed to the Valkey Lua debugger, that will print a list of commands like the following:</li>\n</ul>\n<pre><code>lua debugger&gt; help\nValkey Lua debugger help:\n[h]elp               Show this help.\n[s]tep               Run current line and stop again.\n[n]ext               Alias for step.\n[c]ontinue           Run till next breakpoint.\n[l]ist               List source code around current line.\n[l]ist [line]        List source code around [line].\n                     line = 0 means: current position.\n[l]ist [line] [ctx]  In this form [ctx] specifies how many lines\n                     to show before/after [line].\n[w]hole              List all source code. Alias for &#39;list 1 1000000&#39;.\n[p]rint              Show all the local variables.\n[p]rint &lt;var&gt;        Show the value of the specified variable.\n                     Can also show global vars KEYS and ARGV.\n[b]reak              Show all breakpoints.\n[b]reak &lt;line&gt;       Add a breakpoint to the specified line.\n[b]reak -&lt;line&gt;      Remove breakpoint from the specified line.\n[b]reak 0            Remove all breakpoints.\n[t]race              Show a backtrace.\n[e]val &lt;code&gt;        Execute some Lua code (in a different callframe).\n[r]edis &lt;cmd&gt;        Execute a Valkey command.\n[m]axlen [len]       Trim logged Valkey replies and Lua var dumps to len.\n                     Specifying zero as &lt;len&gt; means unlimited.\n[a]bort              Stop the execution of the script. In sync\n                     mode dataset changes will be retained.\n\nDebugger functions you can call from Lua scripts:\nserver.debug()        Produce logs in the debugger console.\nserver.breakpoint()   Stop execution as if there was a breakpoint in the\n                     next line of code.\n</code></pre>\n<p>Note that when you start the debugger it will start in <strong>stepping mode</strong>.<br>It will stop at the first line of the script that actually does something before executing it.</p>\n<p>From this point you usually call <code>step</code> in order to execute the line and go to the next line.<br>While you step Valkey will show all the commands executed by the server like in the following example:</p>\n<pre><code>* Stopped at 1, stop reason = step over\n-&gt; 1   server.call(&#39;ping&#39;)\nlua debugger&gt; step\n&lt;redis&gt; ping\n&lt;reply&gt; &quot;+PONG&quot;\n* Stopped at 2, stop reason = step over\n</code></pre>\n<p>The <code>&lt;redis&gt;</code> and <code>&lt;reply&gt;</code> lines show the command executed by the line just<br>executed, and the reply from the server. Note that this happens only in stepping mode.<br>If you use <code>continue</code> in order to execute the script till the next breakpoint, commands will not be dumped on the screen to prevent too much output.</p>\n<h2>Termination of the debugging session</h2>\n<p>When the scripts terminates naturally, the debugging session ends and<br><code>valkey-cli</code> returns in its normal non-debugging mode. You can restart the<br>session using the <code>restart</code> command as usual.</p>\n<p>Another way to stop a debugging session is just interrupting <code>valkey-cli</code><br>manually by pressing <code>Ctrl+C</code>. Note that also any event breaking the<br>connection between <code>valkey-cli</code> and the <code>valkey-server</code> will interrupt the<br>debugging session.</p>\n<p>All the forked debugging sessions are terminated when the server is shut<br>down.</p>\n<h2>Abbreviating debugging commands</h2>\n<p>Debugging can be a very repetitive task. For this reason every Valkey<br>debugger command starts with a different character, and you can use the single<br>initial character in order to refer to the command.</p>\n<p>So for example instead of typing <code>step</code> you can just type <code>s</code>.</p>\n<h2>Breakpoints</h2>\n<p>Adding and removing breakpoints is trivial as described in the online help.<br>Just use <code>b 1 2 3 4</code> to add a breakpoint in line 1, 2, 3, 4.<br>The command <code>b 0</code> removes all the breakpoints. Selected breakpoints can be<br>removed using as argument the line where the breakpoint we want to remove is, but prefixed by a minus sign.<br>So for example <code>b -3</code> removes the breakpoint from line 3.</p>\n<p>Note that adding breakpoints to lines that Lua never executes, like declaration of local variables or comments, will not work.<br>The breakpoint will be added but since this part of the script will never be executed, the program will never stop.</p>\n<h2>Dynamic breakpoints</h2>\n<p>Using the <code>breakpoint</code> command it is possible to add breakpoints into specific<br>lines. However sometimes we want to stop the execution of the program only<br>when something special happens. In order to do so, you can use the<br><code>server.breakpoint()</code> function inside your Lua script. When called it simulates<br>a breakpoint in the next line that will be executed.</p>\n<pre><code>if counter &gt; 10 then server.breakpoint() end\n</code></pre>\n<p>This feature is extremely useful when debugging, so that we can avoid<br>continuing the script execution manually multiple times until a given condition<br>is encountered.</p>\n<h2>Synchronous mode</h2>\n<p>As explained previously, but default LDB uses forked sessions with rollback<br>of all the data changes operated by the script while it has being debugged.<br>Determinism is usually a good thing to have during debugging, so that successive<br>debugging sessions can be started without having to reset the database content<br>to its original state.</p>\n<p>However for tracking certain bugs, you may want to retain the changes performed<br>to the key space by each debugging session. When this is a good idea you<br>should start the debugger using a special option, <code>ldb-sync-mode</code>, in <code>valkey-cli</code>.</p>\n<pre><code>./valkey-cli --ldb-sync-mode --eval /tmp/script.lua\n</code></pre>\n<blockquote>\n<p>Note: Valkey server will be unreachable during the debugging session in this mode, so use with care.</p>\n</blockquote>\n<p>In this special mode, the <code>abort</code> command can stop the script half-way taking the changes operated to the dataset.<br>Note that this is different compared to ending the debugging session normally.<br>If you just interrupt <code>valkey-cli</code> the script will be fully executed and then the session terminated.<br>Instead with <code>abort</code> you can interrupt the script execution in the middle and start a new debugging session if needed.</p>\n<h2>Logging from scripts</h2>\n<p>The <code>server.debug()</code> command is a powerful debugging facility that can be<br>called inside the Valkey Lua script in order to log things into the debug<br>console:</p>\n<pre><code>lua debugger&gt; list\n-&gt; 1   local a = {1,2,3}\n   2   local b = false\n   3   server.debug(a,b)\nlua debugger&gt; continue\n&lt;debug&gt; line 3: {1; 2; 3}, false\n</code></pre>\n<p>If the script is executed outside of a debugging session, <code>server.debug()</code> has no effects at all.<br>Note that the function accepts multiple arguments, that are separated by a comma and a space in the output.</p>\n<p>Tables and nested tables are displayed correctly in order to make values simple to observe for the programmer debugging the script.</p>\n<h2>Inspecting the program state with <code>print</code> and <code>eval</code></h2>\n<p>While the <code>server.debug()</code> function can be used in order to print values<br>directly from within the Lua script, often it is useful to observe the local<br>variables of a program while stepping or when stopped into a breakpoint.</p>\n<p>The <code>print</code> command does just that, and performs lookup in the call frames<br>starting from the current one back to the previous ones, up to top-level.<br>This means that even if we are into a nested function inside a Lua script,<br>we can still use <code>print foo</code> to look at the value of <code>foo</code> in the context<br>of the calling function. When called without a variable name, <code>print</code> will<br>print all variables and their respective values.</p>\n<p>The <code>eval</code> command executes small pieces of Lua scripts <strong>outside the context of the current call frame</strong> (evaluating inside the context of the current call frame is not possible with the current Lua internals).<br>However you can use this command in order to test Lua functions.</p>\n<pre><code>lua debugger&gt; e server.sha1hex(&#39;foo&#39;)\n&lt;retval&gt; &quot;0beec7b5ea3f0fdbc95d0dd47f3c5bc275da8a33&quot;\n</code></pre>\n<h2>Debugging clients</h2>\n<p>LDB uses the client-server model where the Valkey server acts as a debugging server that communicates using <a href=\"protocol\">RESP</a>. While <code>valkey-cli</code> is the default debug client, any <a href=\"../clients/\">client</a> can be used for debugging as long as it meets one of the following conditions:</p>\n<ol>\n<li>The client provides a native interface for setting the debug mode and controlling the debug session.</li>\n<li>The client provides an interface for sending arbitrary commands over RESP.</li>\n<li>The client allows sending raw messages to the Valkey server.</li>\n</ol>\n"
      },
      {
        "id": "problems",
        "topicName": "Troubleshooting Valkey",
        "description": "Problems with Valkey? Start here.",
        "htmlContent": "<p>This page tries to help you with what to do if you have issues with Valkey. Part of the Valkey project is helping people that are experiencing problems because we don&#39;t like to leave people alone with their issues.</p>\n<ul>\n<li>If you have <strong>latency problems</strong> with Valkey, that in some way appears to be idle for some time, read our <a href=\"latency\">Valkey latency troubleshooting guide</a>.</li>\n<li>Valkey stable releases are usually very reliable, however in the rare event you are <strong>experiencing crashes</strong> the developers can help a lot more if you provide debugging information. Please read our <a href=\"debugging\">Debugging Valkey guide</a>.</li>\n<li>We have a long history of users experiencing crashes with Valkey that actually turned out to be servers with <strong>broken RAM</strong>. Please test your RAM using <strong>valkey-server --test-memory</strong> in case Valkey is not stable in your system. Valkey built-in memory test is fast and reasonably reliable, but if you can you should reboot your server and use <a href=\"https://memtest86.com\">memtest86</a>.</li>\n</ul>\n"
      }
    ]
  },
  {
    "title": "EXAMPLES & TUTORIALS",
    "items": [
      {
        "id": "twitter-clone",
        "topicName": "Patterns example",
        "description": "Learn several Valkey patterns by building a Twitter clone",
        "htmlContent": "<p>This article describes the design and implementation of a <a href=\"https://github.com/antirez/retwis\">very simple Twitter clone</a> written using PHP with Valkey as the only database. The programming community has traditionally considered key-value stores as a special purpose database that couldn&#39;t be used as a drop-in replacement for a relational database for the development of web applications. This article will try to show that Valkey data structures on top of a key-value layer are an effective data model to implement many kinds of applications.</p>\n<p>Note: the original version of this article was written in 2009 when Redis OSS was<br>released. It was not exactly clear at that time that the data model was<br>suitable to write entire applications. There were many cases of<br>applications using Valkeyt as their main store, so the goal of the article today<br>is to be a tutorial for newcomers. You&#39;ll learn how to design a simple<br>data layout using Valkey, and how to apply different data structures.</p>\n<p>Our Twitter clone, called <a href=\"https://github.com/antirez/retwis\">Retwis</a>, is structurally simple, has very good performance, and can be distributed among any number of web and Valkey servers with little efforts. <a href=\"https://github.com/antirez/retwis\">View the Retwis source code</a>.</p>\n<p>I used PHP for the example because of its universal readability. The same (or better) results can be obtained using Ruby, Python, Erlang, and so on.<br>A few clones exist (however not all the clones use the same data layout as the<br>current version of this tutorial, so please, stick with the official PHP<br>implementation for the sake of following the article better).</p>\n<ul>\n<li><a href=\"https://github.com/danlucraft/retwis-rb\">Retwis-RB</a> is a port of Retwis to Ruby and Sinatra written by Daniel Lucraft.</li>\n<li><a href=\"https://docs.spring.io/spring-data/data-keyvalue/examples/retwisj/current/\">Retwis-J</a> is a port of Retwis to Java, using the Spring Data Framework, written by <a href=\"https://twitter.com/costinl\">Costin Leau</a>. Its source code can be found on <a href=\"https://github.com/SpringSource/spring-data-keyvalue-examples\">GitHub</a>, and there is comprehensive documentation available at <a href=\"https://j.mp/eo6z6I\">springsource.org</a>.</li>\n</ul>\n<h2>What is a key-value store?</h2>\n<p>The essence of a key-value store is the ability to store some data, called a <em>value</em>, inside a key. The value can be retrieved later only if we know the specific key it was stored in. There is no direct way to search for a key by value. In some sense, it is like a very large hash/dictionary, but it is persistent, i.e. when your application ends, the data doesn&#39;t go away. So, for example, I can use the command <code>SET</code> to store the value <em>bar</em> in the key <em>foo</em>:</p>\n<pre><code>SET foo bar\n</code></pre>\n<p>Valkey stores data permanently, so if I later ask &quot;<em>What is the value stored in key foo?</em>&quot; Valkey will reply with <em>bar</em>:</p>\n<pre><code>GET foo =&gt; bar\n</code></pre>\n<p>Other common operations provided by key-value stores are <code>DEL</code>, to delete a given key and its associated value, SET-if-not-exists (called <code>SETNX</code> on Valkey), to assign a value to a key only if the key does not already exist, and <code>INCR</code>, to atomically increment a number stored in a given key:</p>\n<pre><code>SET foo 10\nINCR foo =&gt; 11\nINCR foo =&gt; 12\nINCR foo =&gt; 13\n</code></pre>\n<h2>Atomic operations</h2>\n<p>There is something special about <code>INCR</code>. You may wonder why Valkey provides such an operation if we can do it ourselves with a bit of code? After all, it is as simple as:</p>\n<pre><code>x = GET foo\nx = x + 1\nSET foo x\n</code></pre>\n<p>The problem is that incrementing this way will work as long as there is only one client working with the key <em>foo</em> at one time. See what happens if two clients are accessing this key at the same time:</p>\n<pre><code>x = GET foo (yields 10)\ny = GET foo (yields 10)\nx = x + 1 (x is now 11)\ny = y + 1 (y is now 11)\nSET foo x (foo is now 11)\nSET foo y (foo is now 11)\n</code></pre>\n<p>Something is wrong! We incremented the value two times, but instead of going from 10 to 12, our key holds 11. This is because the increment done with <code>GET / increment / SET</code> <em>is not an atomic operation</em>. Instead the INCR provided by Valkey, Memcached, ..., are atomic implementations, and the server will take care of protecting the key during the time needed to complete the increment in order to prevent simultaneous accesses.</p>\n<p>What makes Valkey different from other key-value stores is that it provides other operations similar to INCR that can be used to model complex problems. This is why you can use Valkey to write whole web applications without using another database like an SQL database, and without going crazy.</p>\n<h2>Beyond key-value stores: lists</h2>\n<p>In this section we will see which Valkey features we need to build our Twitter clone. The first thing to know is that Valkey values can be more than strings. Valkey supports Lists, Sets, Hashes, Sorted Sets, Bitmaps, and HyperLogLog types as values, and there are atomic operations to operate on them so we are safe even with multiple accesses to the same key. Let&#39;s start with Lists:</p>\n<pre><code>LPUSH mylist a (now mylist holds &#39;a&#39;)\nLPUSH mylist b (now mylist holds &#39;b&#39;,&#39;a&#39;)\nLPUSH mylist c (now mylist holds &#39;c&#39;,&#39;b&#39;,&#39;a&#39;)\n</code></pre>\n<p><code>LPUSH</code> means <em>Left Push</em>, that is, add an element to the left (or to the head) of the list stored in <em>mylist</em>. If the key <em>mylist</em> does not exist it is automatically created as an empty list before the PUSH operation. As you can imagine, there is also an <code>RPUSH</code> operation that adds the element to the right of the list (on the tail). This is very useful for our Twitter clone. User updates can be added to a list stored in <code>username:updates</code>, for instance.</p>\n<p>There are operations to get data from Lists, of course. For instance, LRANGE returns a range from the list, or the whole list.</p>\n<pre><code>LRANGE mylist 0 1 =&gt; c,b\n</code></pre>\n<p>LRANGE uses zero-based indexes - that is the first element is 0, the second 1, and so on. The command arguments are <code>LRANGE key first-index last-index</code>. The <em>last-index</em> argument can be negative, with a special meaning: -1 is the last element of the list, -2 the penultimate, and so on. So, to get the whole list use:</p>\n<pre><code>LRANGE mylist 0 -1 =&gt; c,b,a\n</code></pre>\n<p>Other important operations are LLEN that returns the number of elements in the list, and LTRIM that is like LRANGE but instead of returning the specified range <em>trims</em> the list, so it is like <em>Get range from mylist, Set this range as new value</em> but does so atomically.</p>\n<h2>The Set data type</h2>\n<p>Currently we don&#39;t use the Set type in this tutorial, but since we use<br>Sorted Sets, which are kind of a more capable version of Sets, it is better<br>to start introducing Sets first (which are a very useful data structure<br>per se), and later Sorted Sets.</p>\n<p>There are more data types than just Lists. Valkey also supports Sets, which are unsorted collections of elements. It is possible to add, remove, and test for existence of members, and perform the intersection between different Sets. Of course it is possible to get the elements of a Set. Some examples will make it more clear. Keep in mind that <code>SADD</code> is the <em>add to set</em> operation, <code>SREM</code> is the <em>remove from set</em> operation, <code>SISMEMBER</code> is the <em>test if member</em> operation, and <code>SINTER</code> is the <em>perform intersection</em> operation. Other operations are <code>SCARD</code> to get the cardinality (the number of elements) of a Set, and <code>SMEMBERS</code> to return all the members of a Set.</p>\n<pre><code>SADD myset a\nSADD myset b\nSADD myset foo\nSADD myset bar\nSCARD myset =&gt; 4\nSMEMBERS myset =&gt; bar,a,foo,b\n</code></pre>\n<p>Note that <code>SMEMBERS</code> does not return the elements in the same order we added them since Sets are <em>unsorted</em> collections of elements. When you want to store in order it is better to use Lists instead. Some more operations against Sets:</p>\n<pre><code>SADD mynewset b\nSADD mynewset foo\nSADD mynewset hello\nSINTER myset mynewset =&gt; foo,b\n</code></pre>\n<p><code>SINTER</code> can return the intersection between Sets but it is not limited to two Sets. You may ask for the intersection of 4,5, or 10000 Sets. Finally let&#39;s check how <code>SISMEMBER</code> works:</p>\n<pre><code>SISMEMBER myset foo =&gt; 1\nSISMEMBER myset notamember =&gt; 0\n</code></pre>\n<h2>The Sorted Set data type</h2>\n<p>Sorted Sets are similar to Sets: collection of elements. However in Sorted<br>Sets each element is associated with a floating point value, called the<br><em>element score</em>. Because of the score, elements inside a Sorted Set are<br>ordered, since we can always compare two elements by score (and if the score<br>happens to be the same, we compare the two elements as strings).</p>\n<p>Like Sets in Sorted Sets it is not possible to add repeated elements, every<br>element is unique. However it is possible to update an element&#39;s score.</p>\n<p>Sorted Set commands are prefixed with <code>Z</code>. The following is an example<br>of Sorted Sets usage:</p>\n<pre><code>ZADD zset 10 a\nZADD zset 5 b\nZADD zset 12.55 c\nZRANGE zset 0 -1 =&gt; b,a,c\n</code></pre>\n<p>In the above example we added a few elements with <code>ZADD</code>, and later retrieved<br>the elements with <code>ZRANGE</code>. As you can see the elements are returned in order<br>according to their score. In order to check if a given element exists, and<br>also to retrieve its score if it exists, we use the <code>ZSCORE</code> command:</p>\n<pre><code>ZSCORE zset a =&gt; 10\nZSCORE zset non_existing_element =&gt; NULL\n</code></pre>\n<p>Sorted Sets are a very powerful data structure, you can query elements by<br>score range, lexicographically, in reverse order, and so forth.<br>To know more <a href=\"https://redis.io/commands/#sorted_set\">please check the Sorted Set sections in the official Valkey commands documentation</a>.</p>\n<h2>The Hash data type</h2>\n<p>This is the last data structure we use in our program, and is extremely easy<br>to grasp since there is an equivalent in almost every programming language out<br>there: Hashes. Hashes are basically like Ruby or Python hashes, a<br>collection of fields associated with values:</p>\n<pre><code>HMSET myuser name Salvatore surname Sanfilippo country Italy\nHGET myuser surname =&gt; Sanfilippo\n</code></pre>\n<p><code>HMSET</code> can be used to set fields in the hash, that can be retrieved with<br><code>HGET</code> later. It is possible to check if a field exists with <code>HEXISTS</code>, or<br>to increment a hash field with <code>HINCRBY</code> and so forth.</p>\n<p>Hashes are the ideal data structure to represent <em>objects</em>. For example we<br>use Hashes in order to represent Users and Updates in our Twitter clone.</p>\n<p>Okay, we just exposed the basics of the Valkey main data structures,<br>we are ready to start coding!</p>\n<h2>Prerequisites</h2>\n<p>If you haven&#39;t downloaded the <a href=\"https://github.com/antirez/retwis\">Retwis source code</a> already please grab it now. It contains a few PHP files, and also a copy of <a href=\"https://github.com/nrk/predis\">Predis</a>, the PHP client library we use in this example.</p>\n<p>Another thing you probably want is a working Valkey server. Just get the source, build with <code>make</code>, run with <code>./valkey-server</code>, and you&#39;re ready to go. No configuration is required at all in order to play with or run Retwis on your computer.</p>\n<h2>Data layout</h2>\n<p>When working with a relational database, a database schema must be designed so that we&#39;d know the tables, indexes, and so on that the database will contain. We don&#39;t have tables in Valkey, so what do we need to design? We need to identify what keys are needed to represent our objects and what kind of values these keys need to hold.</p>\n<p>Let&#39;s start with Users. We need to represent users, of course, with their username, userid, password, the set of users following a given user, the set of users a given user follows, and so on. The first question is, how should we identify a user? Like in a relational DB, a good solution is to identify different users with different numbers, so we can associate a unique ID with every user. Every other reference to this user will be done by id. Creating unique IDs is very simple to do by using our atomic <code>INCR</code> operation. When we create a new user we can do something like this, assuming the user is called &quot;antirez&quot;:</p>\n<pre><code>INCR next_user_id =&gt; 1000\nHMSET user:1000 username antirez password p1pp0\n</code></pre>\n<p><em>Note: you should use a hashed password in a real application, for simplicity<br>we store the password in clear text.</em></p>\n<p>We use the <code>next_user_id</code> key in order to always get a unique ID for every new user. Then we use this unique ID to name the key holding a Hash with user&#39;s data. <em>This is a common design pattern</em> with key-values stores! Keep it in mind.<br>Besides the fields already defined, we need some more stuff in order to fully define a User. For example, sometimes it can be useful to be able to get the user ID from the username, so every time we add a user, we also populate the <code>users</code> key, which is a Hash, with the username as field, and its ID as value.</p>\n<pre><code>HSET users antirez 1000\n</code></pre>\n<p>This may appear strange at first, but remember that we are only able to access data in a direct way, without secondary indexes. It&#39;s not possible to tell Valkey to return the key that holds a specific value. This is also <em>our strength</em>. This new paradigm is forcing us to organize data so that everything is accessible by <em>primary key</em>, speaking in relational DB terms.</p>\n<h2>Followers, following, and updates</h2>\n<p>There is another central need in our system. A user might have users who follow them, which we&#39;ll call their followers. A user might follow other users, which we&#39;ll call a following. We have a perfect data structure for this. That is... Sets.<br>The uniqueness of Sets elements, and the fact we can test in constant time for<br>existence, are two interesting features. However what about also remembering<br>the time at which a given user started following another one? In an enhanced<br>version of our simple Twitter clone this may be useful, so instead of using<br>a simple Set, we use a Sorted Set, using the user ID of the following or follower<br>user as element, and the unix time at which the relation between the users<br>was created, as our score.</p>\n<p>So let&#39;s define our keys:</p>\n<pre><code>followers:1000 =&gt; Sorted Set of uids of all the followers users\nfollowing:1000 =&gt; Sorted Set of uids of all the following users\n</code></pre>\n<p>We can add new followers with:</p>\n<pre><code>ZADD followers:1000 1401267618 1234 =&gt; Add user 1234 with time 1401267618\n</code></pre>\n<p>Another important thing we need is a place where we can add the updates to display in the user&#39;s home page. We&#39;ll need to access this data in chronological order later, from the most recent update to the oldest, so the perfect kind of data structure for this is a List. Basically every new update will be <code>LPUSH</code>ed in the user updates key, and thanks to <code>LRANGE</code>, we can implement pagination and so on. Note that we use the words <em>updates</em> and <em>posts</em> interchangeably, since updates are actually &quot;little posts&quot; in some way.</p>\n<pre><code>posts:1000 =&gt; a List of post ids - every new post is LPUSHed here.\n</code></pre>\n<p>This list is basically the User timeline. We&#39;ll push the IDs of her/his own<br>posts, and, the IDs of all the posts of created by the following users.<br>Basically, we&#39;ll implement a write fanout.</p>\n<h2>Authentication</h2>\n<p>OK, we have more or less everything about the user except for authentication. We&#39;ll handle authentication in a simple but robust way: we don&#39;t want to use PHP sessions, as our system must be ready to be distributed among different web servers easily, so we&#39;ll keep the whole state in our Valkey database. All we need is a random <strong>unguessable</strong> string to set as the cookie of an authenticated user, and a key that will contain the user ID of the client holding the string.</p>\n<p>We need two things in order to make this thing work in a robust way.<br>First: the current authentication <em>secret</em> (the random unguessable string)<br>should be part of the User object, so when the user is created we also set<br>an <code>auth</code> field in its Hash:</p>\n<pre><code>HSET user:1000 auth fea5e81ac8ca77622bed1c2132a021f9\n</code></pre>\n<p>Moreover, we need a way to map authentication secrets to user IDs, so<br>we also take an <code>auths</code> key, which has as value a Hash type mapping<br>authentication secrets to user IDs.</p>\n<pre><code>HSET auths fea5e81ac8ca77622bed1c2132a021f9 1000\n</code></pre>\n<p>In order to authenticate a user we&#39;ll do these simple steps (see the <code>login.php</code> file in the Retwis source code):</p>\n<ul>\n<li>Get the username and password via the login form.</li>\n<li>Check if the <code>username</code> field actually exists in the <code>users</code> Hash.</li>\n<li>If it exists we have the user id, (i.e. 1000).</li>\n<li>Check if user:1000 password matches, if not, return an error message.</li>\n<li>Ok authenticated! Set &quot;fea5e81ac8ca77622bed1c2132a021f9&quot; (the value of user:1000 <code>auth</code> field) as the &quot;auth&quot; cookie.</li>\n</ul>\n<p>This is the actual code:</p>\n<pre><code class=\"language-php\">include(&quot;retwis.php&quot;);\n\n# Form sanity checks\nif (!gt(&quot;username&quot;) || !gt(&quot;password&quot;))\n    goback(&quot;You need to enter both username and password to login.&quot;);\n\n# The form is ok, check if the username is available\n$username = gt(&quot;username&quot;);\n$password = gt(&quot;password&quot;);\n$r = redisLink();\n$userid = $r-&gt;hget(&quot;users&quot;,$username);\nif (!$userid)\n    goback(&quot;Wrong username or password&quot;);\n$realpassword = $r-&gt;hget(&quot;user:$userid&quot;,&quot;password&quot;);\nif ($realpassword != $password)\n    goback(&quot;Wrong username or password&quot;);\n\n# Username / password OK, set the cookie and redirect to index.php\n$authsecret = $r-&gt;hget(&quot;user:$userid&quot;,&quot;auth&quot;);\nsetcookie(&quot;auth&quot;,$authsecret,time()+3600*24*365);\nheader(&quot;Location: index.php&quot;);\n</code></pre>\n<p>This happens every time a user logs in, but we also need a function <code>isLoggedIn</code> in order to check if a given user is already authenticated or not. These are the logical steps preformed by the <code>isLoggedIn</code> function:</p>\n<ul>\n<li>Get the &quot;auth&quot; cookie from the user. If there is no cookie, the user is not logged in, of course. Let&#39;s call the value of the cookie <code>&lt;authcookie&gt;</code>.</li>\n<li>Check if <code>&lt;authcookie&gt;</code> field in the <code>auths</code> Hash exists, and what the value (the user ID) is (1000 in the example).</li>\n<li>In order for the system to be more robust, also verify that user:1000 auth field also matches.</li>\n<li>OK the user is authenticated, and we loaded a bit of information in the <code>$User</code> global variable.</li>\n</ul>\n<p>The code is simpler than the description, possibly:</p>\n<pre><code class=\"language-php\">function isLoggedIn() {\n    global $User, $_COOKIE;\n\n    if (isset($User)) return true;\n\n    if (isset($_COOKIE[&#39;auth&#39;])) {\n        $r = redisLink();\n        $authcookie = $_COOKIE[&#39;auth&#39;];\n        if ($userid = $r-&gt;hget(&quot;auths&quot;,$authcookie)) {\n            if ($r-&gt;hget(&quot;user:$userid&quot;,&quot;auth&quot;) != $authcookie) return false;\n            loadUserInfo($userid);\n            return true;\n        }\n    }\n    return false;\n}\n\nfunction loadUserInfo($userid) {\n    global $User;\n\n    $r = redisLink();\n    $User[&#39;id&#39;] = $userid;\n    $User[&#39;username&#39;] = $r-&gt;hget(&quot;user:$userid&quot;,&quot;username&quot;);\n    return true;\n}\n</code></pre>\n<p>Having <code>loadUserInfo</code> as a separate function is overkill for our application, but it&#39;s a good approach in a complex application. The only thing that&#39;s missing from all the authentication is the logout. What do we do on logout? That&#39;s simple, we&#39;ll just change the random string in user:1000 <code>auth</code> field, remove the old authentication secret from the <code>auths</code> Hash, and add the new one.</p>\n<p><em>Important:</em> the logout procedure explains why we don&#39;t just authenticate the user after looking up the authentication secret in the <code>auths</code> Hash, but double check it against user:1000 <code>auth</code> field. The true authentication string is the latter, while the <code>auths</code> Hash is just an authentication field that may even be volatile, or, if there are bugs in the program or a script gets interrupted, we may even end with multiple entries in the <code>auths</code> key pointing to the same user ID. The logout code is the following (<code>logout.php</code>):</p>\n<pre><code class=\"language-php\">include(&quot;retwis.php&quot;);\n\nif (!isLoggedIn()) {\n    header(&quot;Location: index.php&quot;);\n    exit;\n}\n\n$r = redisLink();\n$newauthsecret = getrand();\n$userid = $User[&#39;id&#39;];\n$oldauthsecret = $r-&gt;hget(&quot;user:$userid&quot;,&quot;auth&quot;);\n\n$r-&gt;hset(&quot;user:$userid&quot;,&quot;auth&quot;,$newauthsecret);\n$r-&gt;hset(&quot;auths&quot;,$newauthsecret,$userid);\n$r-&gt;hdel(&quot;auths&quot;,$oldauthsecret);\n\nheader(&quot;Location: index.php&quot;);\n</code></pre>\n<p>That is just what we described and should be simple to understand.</p>\n<h2>Updates</h2>\n<p>Updates, also known as posts, are even simpler. In order to create a new post in the database we do something like this:</p>\n<pre><code>INCR next_post_id =&gt; 10343\nHMSET post:10343 user_id $owner_id time $time body &quot;I&#39;m having fun with Retwis&quot;\n</code></pre>\n<p>As you can see each post is just represented by a Hash with three fields. The ID of the user owning the post, the time at which the post was published, and finally, the body of the post, which is, the actual status message.</p>\n<p>After we create a post and we obtain the post ID, we need to LPUSH the ID in the timeline of every user that is following the author of the post, and of course in the list of posts of the author itself (everybody is virtually following herself/himself). This is the file <code>post.php</code> that shows how this is performed:</p>\n<pre><code class=\"language-php\">include(&quot;retwis.php&quot;);\n\nif (!isLoggedIn() || !gt(&quot;status&quot;)) {\n    header(&quot;Location:index.php&quot;);\n    exit;\n}\n\n$r = redisLink();\n$postid = $r-&gt;incr(&quot;next_post_id&quot;);\n$status = str_replace(&quot;\\n&quot;,&quot; &quot;,gt(&quot;status&quot;));\n$r-&gt;hmset(&quot;post:$postid&quot;,&quot;user_id&quot;,$User[&#39;id&#39;],&quot;time&quot;,time(),&quot;body&quot;,$status);\n$followers = $r-&gt;zrange(&quot;followers:&quot;.$User[&#39;id&#39;],0,-1);\n$followers[] = $User[&#39;id&#39;]; /* Add the post to our own posts too */\n\nforeach($followers as $fid) {\n    $r-&gt;lpush(&quot;posts:$fid&quot;,$postid);\n}\n# Push the post on the timeline, and trim the timeline to the\n# newest 1000 elements.\n$r-&gt;lpush(&quot;timeline&quot;,$postid);\n$r-&gt;ltrim(&quot;timeline&quot;,0,1000);\n\nheader(&quot;Location: index.php&quot;);\n</code></pre>\n<p>The core of the function is the <code>foreach</code> loop. We use <code>ZRANGE</code> to get all the followers of the current user, then the loop will <code>LPUSH</code> the push the post in every follower timeline List.</p>\n<p>Note that we also maintain a global timeline for all the posts, so that in the Retwis home page we can show everybody&#39;s updates easily. This requires just doing an <code>LPUSH</code> to the <code>timeline</code> List. Let&#39;s face it, aren&#39;t you starting to think it was a bit strange to have to sort things added in chronological order using <code>ORDER BY</code> with SQL? I think so.</p>\n<p>There is an interesting thing to notice in the code above: we used a new<br>command called <code>LTRIM</code> after we perform the <code>LPUSH</code> operation in the global<br>timeline. This is used in order to trim the list to just 1000 elements. The<br>global timeline is actually only used in order to show a few posts in the<br>home page, there is no need to have the full history of all the posts.</p>\n<p>Basically <code>LTRIM</code> + <code>LPUSH</code> is a way to create a <em>capped collection</em> in Valkey.</p>\n<h2>Paginating updates</h2>\n<p>Now it should be pretty clear how we can use <code>LRANGE</code> in order to get ranges of posts, and render these posts on the screen. The code is simple:</p>\n<pre><code class=\"language-php\">function showPost($id) {\n    $r = redisLink();\n    $post = $r-&gt;hgetall(&quot;post:$id&quot;);\n    if (empty($post)) return false;\n\n    $userid = $post[&#39;user_id&#39;];\n    $username = $r-&gt;hget(&quot;user:$userid&quot;,&quot;username&quot;);\n    $elapsed = strElapsed($post[&#39;time&#39;]);\n    $userlink = &quot;&lt;a class=\\&quot;username\\&quot; href=\\&quot;profile.php?u=&quot;.urlencode($username).&quot;\\&quot;&gt;&quot;.utf8entities($username).&quot;&lt;/a&gt;&quot;;\n\n    echo(&#39;&lt;div class=&quot;post&quot;&gt;&#39;.$userlink.&#39; &#39;.utf8entities($post[&#39;body&#39;]).&quot;&lt;br&gt;&quot;);\n    echo(&#39;&lt;i&gt;posted &#39;.$elapsed.&#39; ago via web&lt;/i&gt;&lt;/div&gt;&#39;);\n    return true;\n}\n\nfunction showUserPosts($userid,$start,$count) {\n    $r = redisLink();\n    $key = ($userid == -1) ? &quot;timeline&quot; : &quot;posts:$userid&quot;;\n    $posts = $r-&gt;lrange($key,$start,$start+$count);\n    $c = 0;\n    foreach($posts as $p) {\n        if (showPost($p)) $c++;\n        if ($c == $count) break;\n    }\n    return count($posts) == $count+1;\n}\n</code></pre>\n<p><code>showPost</code> will simply convert and print a Post in HTML while <code>showUserPosts</code> gets a range of posts and then passes them to <code>showPosts</code>.</p>\n<p><strong>Note:</strong> <code>LRANGE</code> is not very efficient if the list of posts start to be very<br>big, and we want to access elements which are in the middle of the list, since Lists are backed by linked lists. If a system is designed for<br>deep pagination of million of items, it is better to resort to Sorted Sets<br>instead.*</p>\n<h2>Following users</h2>\n<p>It is not hard, but we did not yet check how we create following / follower relationships. If user ID 1000 (antirez) wants to follow user ID 5000 (pippo), we need to create both a following and a follower relationship. We just need to <code>ZADD</code> calls:</p>\n<pre><code>ZADD following:1000 5000\nZADD followers:5000 1000\n</code></pre>\n<p>Note the same pattern again and again. In theory with a relational database, the list of following and followers would be contained in a single table with fields like <code>following_id</code> and <code>follower_id</code>. You can extract the followers or following of every user using an SQL query. With a key-value DB things are a bit different since we need to set both the <code>1000 is following 5000</code> and <code>5000 is followed by 1000</code> relations. This is the price to pay, but on the other hand accessing the data is simpler and extremely fast. Having these things as separate sets allows us to do interesting stuff. For example, using <code>ZINTERSTORE</code> we can have the intersection of <code>following</code> of two different users, so we may add a feature to our Twitter clone so that it is able to tell you very quickly when you visit somebody else&#39;s profile, &quot;you and Alice have 34 followers in common&quot;, and things like that.</p>\n<p>You can find the code that sets or removes a following / follower relation in the <code>follow.php</code> file.</p>\n<h2>Making it horizontally scalable</h2>\n<p>Gentle reader, if you read till this point you are already a hero. Thank you. Before talking about scaling horizontally it is worth checking performance on a single server. Retwis is <em>extremely fast</em>, without any kind of cache. On a very slow and loaded server, an Apache benchmark with 100 parallel clients issuing 100000 requests measured the average pageview to take 5 milliseconds. This means you can serve millions of users every day with just a single Linux box, and this one was monkey ass slow... Imagine the results with more recent hardware.</p>\n<p>However you can&#39;t go with a single server forever, how do you scale a key-value<br>store?</p>\n<p>Retwis does not perform any multi-keys operation, so making it scalable is<br>simple: you may use client-side sharding, or something like a sharding proxy<br>like Twemproxy, or the upcoming Valkey Cluster.</p>\n<p>To know more about those topics please read<br><a href=\"cluster-tutorial\">our documentation about sharding</a>. However, the point here<br>to stress is that in a key-value store, if you design with care, the data set<br>is split among <strong>many independent small keys</strong>. To distribute those keys<br>to multiple nodes is more straightforward and predictable compared to using<br>a semantically more complex database system.</p>\n"
      }
    ]
  },
  {
    "title": "HARDWARE & OPTIMIZATION",
    "items": [
      {
        "id": "ARM",
        "topicName": "ARM support",
        "description": "Exploring Valkey on the ARM CPU Architecture\n",
        "htmlContent": "<p>Valkey supports the ARM processor, for example<br>the Raspberry Pi, as a main platform.<br>While Valkey does run on Android, in the future we look forward to extend our testing efforts to Android<br>to also make it an officially supported platform.</p>\n<p>We believe that Valkey is ideal for IoT and embedded devices for several<br>reasons:</p>\n<ul>\n<li>Valkey has a very small memory footprint and CPU requirements. It can run in small devices like the Raspberry Pi Zero without impacting the overall performance, using a small amount of memory while delivering good performance for many use cases.</li>\n<li>The data structures of Valkey are often an ideal way to model IoT/embedded use cases. Some examples include accumulating time series data, receiving or queuing commands to execute or respond to send back to the remote servers, and so forth.</li>\n<li>Modeling data inside Valkey can be very useful in order to make in-device decisions for appliances that must respond very quickly or when the remote servers are offline.</li>\n<li>Valkey can be used as a communication system between the processes running in the device.</li>\n<li>The append-only file storage of Valkey is well suited for SSD cards.</li>\n<li>The stream data structure was specifically designed for time series applications and has a very low memory overhead.</li>\n</ul>\n<h2>Valkey /proc/cpu/alignment requirements</h2>\n<p>Linux on ARM allows to trap unaligned accesses and fix them inside the kernel<br>in order to continue the execution of the offending program instead of<br>generating a <code>SIGBUS</code>. Valkey avoids any kind<br>of unaligned access, so there is no need to have a specific value for this<br>kernel configuration. Even when kernel alignment fixing set as disabled Valkey should<br>run as expected.</p>\n<h2>Building Valkey in the Pi</h2>\n<ul>\n<li>Download Valkey.</li>\n<li>Use <code>make</code> as usual to create the executable.</li>\n</ul>\n<p>There is nothing special in the process. The only difference is that by<br>default, Valkey uses the <code>libc</code> allocator instead of defaulting to <code>jemalloc</code><br>as it does in other Linux based environments. This is because we believe<br>that for the small use cases inside embedded devices, memory fragmentation<br>is unlikely to be a problem. Moreover <code>jemalloc</code> on ARM may not be as tested<br>as the <code>libc</code> allocator.</p>\n<h2>Performance</h2>\n<p>Performance testing of Valkey was performed on the Raspberry Pi 3 and Pi 1 model B. The difference between the two Pis in terms of delivered performance is quite big. The benchmarks were performed via the<br>loopback interface, since most use cases will probably use Valkey from within<br>the device and not via the network. The following numbers were obtained using<br>Redis OSS 4.0.</p>\n<p>Raspberry Pi 3:</p>\n<ul>\n<li>Test 1 : 5 millions writes with 1 million keys (even distribution among keys).  No persistence, no pipelining. 28,000 ops/sec.</li>\n<li>Test 2: Like test 1 but with pipelining using groups of 8 operations: 80,000 ops/sec.</li>\n<li>Test 3: Like test 1 but with AOF enabled, fsync 1 sec: 23,000 ops/sec</li>\n<li>Test 4: Like test 3, but with an AOF rewrite in progress: 21,000 ops/sec</li>\n</ul>\n<p>Raspberry Pi 1 model B:</p>\n<ul>\n<li>Test 1 : 5 millions writes with 1 million keys (even distribution among keys).  No persistence, no pipelining.  2,200 ops/sec.</li>\n<li>Test 2: Like test 1 but with pipelining using groups of 8 operations: 8,500 ops/sec.</li>\n<li>Test 3: Like test 1 but with AOF enabled, fsync 1 sec: 1,820 ops/sec</li>\n<li>Test 4: Like test 3, but with an AOF rewrite in progress: 1,000 ops/sec</li>\n</ul>\n<p>The benchmarks above are referring to simple <code>SET</code>/<code>GET</code> operations. The performance is similar for all the Valkey fast operations (not running in linear time). However sorted sets may show slightly slower numbers.</p>\n"
      },
      {
        "id": "RDMA",
        "topicName": "RDMA experimental support",
        "description": "Valkey Over RDMA experimental support",
        "htmlContent": "<p>Valkey supports the Remote Direct Memory Access (RDMA) connection type via a<br>Valkey module that can be dynamically loaded on demand.</p>\n<h2>Getting Started</h2>\n<p><a href=\"https://en.wikipedia.org/wiki/Remote_direct_memory_access\">RDMA</a><br>enables direct data exchange between networked computers&#39; main memory,<br>bypassing processors and operating systems.</p>\n<p>As a result, RDMA offers better performance compared to TCP/IP. Test results indicate that<br>Valkey Over RDMA achieves approximately 2 times higher QPS and lower latency.</p>\n<p>Please note that Valkey Over RDMA is currently supported only on Linux.<br>Also, before using Valkey Over RDMA, you must understand how to configure<br>RDMA on your server and client machines.</p>\n<h2>Running manually</h2>\n<p>To run a Valkey server with RDMA mode:</p>\n<pre><code>./src/valkey-server --protected-mode no \\\n     --loadmodule src/valkey-rdma.so bind=192.168.122.100 port=6379\n</code></pre>\n<p>Bind address/port of RDMA can be modified at runtime using the following command:</p>\n<pre><code>192.168.122.100:6379&gt; CONFIG SET rdma-port 6380\n</code></pre>\n<p>Valkey can run both RDMA and TCP/IP concurrently on the same port:</p>\n<pre><code>./src/valkey-server --protected-mode no \\\n     --loadmodule src/valkey-rdma.so bind=192.168.122.100 port=6379 \\\n     --port 6379\n</code></pre>\n<p>Or append <code>loadmodule src/valkey-rdma.so bind=192.168.122.100 port=6379</code> in valkey.conf, then:</p>\n<pre><code>./src/valkey-server valkey.conf\n</code></pre>\n<h3>Prerequisites</h3>\n<p>Note that the network interface (192.168.122.100 of this example) should support<br>RDMA. To test a server supports RDMA or not:</p>\n<pre><code>rdma dev show (a new version iproute2 package)\n</code></pre>\n<p>Or:</p>\n<pre><code>ibv_devices (ibverbs-utils package of Debian/Ubuntu)\n</code></pre>\n<h2>Performance tuning</h2>\n<p>The RDMA completion queue will use the completion vector to signal completion events<br>via hardware interrupts. A large number of hardware interrupts can affect CPU performance.<br>It is possible to tune the performance using <code>rdma-comp-vector</code>.</p>\n<p>See <a href=\"https://man7.org/linux/man-pages/man3/ibv_create_cq.3.html\">RDMA CQ completion vector</a></p>\n<h3>Example 1</h3>\n<ul>\n<li>Pin hardware interrupt vectors [0, 3] to CPU [0, 3].</li>\n<li>Set CPU affinity for valkey to CPU [4, X].</li>\n<li>Any valkey server uses a random RDMA completion vector [-1].</li>\n</ul>\n<p>All valkey servers will not affect each other and will be isolated from kernel interrupts.</p>\n<pre><code>  SYS    SYS    SYS    SYS  VALKEY VALKEY     VALKEY\n   |      |      |      |      |      |          |\n CPU0   CPU1   CPU2   CPU3   CPU4   CPU5   ... CPUX\n   |      |      |      |\n INTR0  INTR1  INTR2  INTR3\n</code></pre>\n<h3>Example 2</h3>\n<ul>\n<li>Pin hardware interrupt vectors [0, X] to CPU [0, X].</li>\n<li>Set CPU affinity for valkey [M] to CPU [M].</li>\n<li>Valkey server [M] uses RDMA completion vector [M].</li>\n</ul>\n<p>A single CPU [M] handles hardware interrupts, the RDMA completion vector [M],<br>and the valkey server [M] within its context only.<br>This avoids overhead and function calls across multiple CPUs, fully isolating<br>each valkey server from one another.</p>\n<pre><code>VALKEY VALKEY VALKEY VALKEY VALKEY VALKEY     VALKEY\n   |      |      |      |      |      |          |\n CPU0   CPU1   CPU2   CPU3   CPU4   CPU5  ...  CPUX\n   |      |      |      |      |      |          |\n INTR0  INTR1  INTR2  INTR3  INTR4  INTR5      INTRX\n</code></pre>\n<p>Use 0 and positive numbers to specify the RDMA completion vector, or specify -1 to allow<br>the server to use a random vector for a new connection. The default vector is -1.</p>\n<h2>Protocol</h2>\n<p>The protocol defines the Queue Pairs (QP) type reliable connection (RC),<br>like TCP, communication commands, and payload exchange mechanism.<br>This dependency is based solely on the RDMA (aka Infiniband) specification<br>and is independent of both software (including the OS and user libraries)<br>and hardware (including vendors and low-level transports).</p>\n<p>Valkey Over RDMA has control-plane (control messages) and data-plane (payload transfer).</p>\n<h3>Control message</h3>\n<p>Control messages use fixed 32-byte big-endian message structures:</p>\n<pre><code class=\"language-C\">typedef struct ValkeyRdmaFeature {\n    /* defined as following Opcodes */\n    uint16_t opcode;\n    /* select features */\n    uint16_t select;\n    uint8_t reserved[20];\n    /* feature bits */\n    uint64_t features;\n} ValkeyRdmaFeature;\n\ntypedef struct ValkeyRdmaKeepalive {\n    /* defined as following Opcodes */\n    uint16_t opcode;\n    uint8_t reserved[30];\n} ValkeyRdmaKeepalive;\n\ntypedef struct ValkeyRdmaMemory {\n    /* defined as following Opcodes */\n    uint16_t opcode;\n    uint8_t reserved[14];\n    /* address of a transfer buffer which is used to receive remote streaming data,\n     * aka &#39;RX buffer address&#39;. The remote side should use this as &#39;TX buffer address&#39; */\n    uint64_t addr;\n    /* length of the &#39;RX buffer&#39; */\n    uint32_t length;\n    /* the RDMA remote key of &#39;RX buffer&#39; */\n    uint32_t key;\n} ValkeyRdmaMemory;\n\ntypedef union ValkeyRdmaCmd {\n    ValkeyRdmaFeature feature;\n    ValkeyRdmaKeepalive keepalive;\n    ValkeyRdmaMemory memory;\n} ValkeyRdmaCmd;\n</code></pre>\n<h3>Opcodes</h3>\n<table>\n<thead>\n<tr>\n<th align=\"center\">Command</th>\n<th align=\"center\">Value</th>\n<th align=\"center\">Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\"><code>GetServerFeature</code></td>\n<td align=\"center\">0</td>\n<td align=\"center\">required, get the features offered by Valkey server</td>\n</tr>\n<tr>\n<td align=\"center\"><code>SetClientFeature</code></td>\n<td align=\"center\">1</td>\n<td align=\"center\">required, negotiate features and set it to Valkey server</td>\n</tr>\n<tr>\n<td align=\"center\"><code>Keepalive</code></td>\n<td align=\"center\">2</td>\n<td align=\"center\">required, detect unexpected orphan connection</td>\n</tr>\n<tr>\n<td align=\"center\"><code>RegisterXferMemory</code></td>\n<td align=\"center\">3</td>\n<td align=\"center\">required, tell the &#39;RX transfer buffer&#39; information to the remote side, and the remote side uses this as &#39;TX transfer buffer&#39;</td>\n</tr>\n</tbody></table>\n<p>Once any new feature and command are introduced into <code>Valkey Over RDMA</code>, the client should<br>detect the new feature <code>VALKEY_RDMA_FEATURE_FOO</code> through the <code>GetServerFeature</code> command,<br>and then use the <code>SetClientFeature</code> command to enable the feature <code>VALKEY_RDMA_FEATURE_FOO</code>.<br>Once <code>VALKEY_RDMA_FEATURE_FOO</code> is negotiated successfully, the optional<br><code>ValkeyRdmaFoo</code> command will be supported within the connection.</p>\n<h3>RDMA Operations</h3>\n<ul>\n<li>Send a control message by RDMA &#39;<strong><code>ibv_post_send</code></strong>&#39; with opcode &#39;<strong><code>IBV_WR_SEND</code></strong>&#39; with structure<br>&#39;ValkeyRdmaCmd&#39;.</li>\n<li>Receive a control message by RDMA &#39;<strong><code>ibv_post_recv</code></strong>&#39;, and the received buffer<br>size should be size of &#39;ValkeyRdmaCmd&#39;.</li>\n<li>Transfer stream data by RDMA &#39;<strong><code>ibv_post_send</code></strong>&#39; with opcode &#39;<strong><code>IBV_WR_RDMA_WRITE</code></strong>&#39; (optional) and<br>&#39;<strong><code>IBV_WR_RDMA_WRITE_WITH_IMM</code></strong>&#39; (required), to write data segments into a connection by<br>RDMA [WRITE][WRITE][WRITE]...[WRITE WITH IMM], the length of total buffer is described by<br>immediate data (unsigned int 32). For example:<br>a, [WRITE 128 bytes][WRITE 256 bytes][WRITE 128 bytes WITH IMM 512] writes 512 bytes to the<br>remote side, the remote side is notified only once.<br>b, [WRITE 128 bytes WITH IMM 128][WRITE 256 bytes WITH IMM 256][WRITE 128 bytes WITH IMM 128]<br>writes 512 bytes to the remote side, the remote side is notified three times.<br>Both example a and b write the same 512 bytes,<br>example a has better performance, however b is easier to implement.</li>\n</ul>\n<h3>Maximum WQEs of RDMA</h3>\n<p>No specific limit, 1024 recommended for WQEs.<br>Flow control for WQE MAY be defined/implemented in the future.</p>\n<h3>The workflow of this protocol</h3>\n<pre><code>                                                                    valkey-server\n                                                                    listen RDMA port\n   valkey-client\n                -------------------RDMA connect--------------------&gt;\n                                                                    accept connection\n                &lt;--------------- Establish RDMA --------------------\n\n                --------Get server feature [@IBV_WR_SEND] ---------&gt;\n\n                --------Set client feature [@IBV_WR_SEND] ---------&gt;\n                                                                    setup RX buffer\n                &lt;---- Register transfer memory [@IBV_WR_SEND] ------\n[@ibv_post_recv]\nsetup TX buffer\n                ----- Register transfer memory [@IBV_WR_SEND] -----&gt;\n                                                                    [@ibv_post_recv]\n                                                                    setup TX buffer\n                -- Valkey commands [@IBV_WR_RDMA_WRITE_WITH_IMM] --&gt;\n                &lt;- Valkey response [@IBV_WR_RDMA_WRITE_WITH_IMM] ---\n                                  .......\n                -- Valkey commands [@IBV_WR_RDMA_WRITE_WITH_IMM] --&gt;\n                &lt;- Valkey response [@IBV_WR_RDMA_WRITE_WITH_IMM] ---\n                                  .......\n\n\nRX is full\n                ----- Register transfer memory [@IBV_WR_SEND] -----&gt;\n                                                                    [@ibv_post_recv]\n                                                                    setup TX buffer\n                &lt;- Valkey response [@IBV_WR_RDMA_WRITE_WITH_IMM] ---\n                                  .......\n\n                                                                    RX is full\n                &lt;---- Register transfer memory [@IBV_WR_SEND] ------\n[@ibv_post_recv]\nsetup TX buffer\n                -- Valkey commands [@IBV_WR_RDMA_WRITE_WITH_IMM] --&gt;\n                &lt;- Valkey response [@IBV_WR_RDMA_WRITE_WITH_IMM] ---\n                                  .......\n\n                -------------------RDMA disconnect-----------------&gt;\n                &lt;------------------RDMA disconnect------------------\n</code></pre>\n<p>The Valkey Over RDMA protocol is designed to efficiently transfer stream data and<br>bears similarities to several mechanisms introduced in academic papers with some differences:</p>\n<ul>\n<li><a href=\"https://dl.acm.org/doi/10.1145/3341302.3342071\">Socksdirect: datacenter sockets can be fast and compatible</a></li>\n<li><a href=\"https://dl.acm.org/doi/abs/10.1145/3132747.3132762\">LITE Kernel RDMA Support for Datacenter Applications</a></li>\n<li><a href=\"https://www.usenix.org/system/files/conference/nsdi14/nsdi14-paper-dragojevic.pdf\">FaRM: Fast Remote Memory</a></li>\n</ul>\n<h2>How does Valkey use RDMA</h2>\n<p>Valkey supports a connection abstraction framework that hides listen/connect/accept/shutdown/read/write,<br>and so on. This allows the connection types to register into Valkey core during startup time.<br>What&#39;s more, a connection type is either Valkey built-in (Ex, TCP/IP and Unix domain socket) or<br>Valkey module (Ex, TLS).<br>Enabling RDMA support needs to link additional libraries, rather than valkey-server&#39;s additional dependence<br>on the shared libraries, build Valkey Over RDMA into Valkey module,<br>Then a user starts valkey-server with RDMA module, valkey-server loads the additional shared libraries on demand.</p>\n<h2>Limitations</h2>\n<ul>\n<li>Valkey Over RDMA is experimental, it may be changed or be removed in any minor or major version.</li>\n<li>TLS is not supported by Valkey Over RDMA. But it is workable in theory by a certain amount of work.</li>\n<li>Valkey Over RDMA is supported on Linux only.</li>\n<li>Not compatible with replication currently, TCP/TLS is needed for replication.</li>\n<li>Depending on different hardware, too many active queue pairs may lead performance drop.</li>\n</ul>\n"
      }
    ]
  }
];
