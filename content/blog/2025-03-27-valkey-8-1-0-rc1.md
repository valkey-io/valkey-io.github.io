+++
# `title` is how your post will be listed and what will appear at the top of the post
title= "Valkey 8.1: Continuing to Deliver Enhanced Performance and Reliability"
# `date` is when your post will be published.
# For the most part, you can leave this as the day you _started_ the post.
# The maintainers will update this value before publishing
# The time is generally irrelvant in how Valkey published, so '01:01:01' is a good placeholder
date= 2025-11-03 01:01:01
# 'description' is what is shown as a snippet/summary in various contexts.
# You can make this the first few lines of the post or (better) a hook for readers.
# Aim for 2 short sentences.
description= "The first release candidate of Valkey 8.1 is now available! Come learn about the exciting improvements in performance, reliability, and observability that are available in this new version."
# 'authors' are the folks who wrote or contributed to the post.
# Each author corresponds to a biography file (more info later in this document)
authors= [ "rdias", "mvisser" ]
+++


The Valkey community is proud to unveil the first release candidate of Valkey 8.1,
a minor update designed to further enhance performance, reliability, and observability 
over Valkey 8.0 for all Valkey installations. 
In this blog, we'll dive a bit deeper into each of these areas 
and talk about the exciting features built for this release.

## Performance

There are many changes in 8.1 that improve Valkey's performance either by decreasing the latency of some operations, increasing the throughput of some operations, or reducing the memory footprint of the overall system.

One of the main changes responsible for several performance improvements is the new hashtable implementation that is used as the main key-value store in Valkey and also used in the Hash, Set, and Sorted Set datatypes implementation.

### The New Hashtable

Valkey is a distributed key-value and therefore is no suprise that a hashtable data structure performs an important role in the way Valkey works.

Almost all commands go through the main key-value store where the several datatypes values are stored, and therefore the hashtable implementation is present in the critical path of most workloads.

The new hashtable implementation is a complete rewrite of the previous hashtable implementation, which reduces the￼memory usage by roughly 20 bytes per key-value pair and improves the latency and ￼CPU usage by rougly 10% for instances without I/O threading.

The previous hashtable implementation, called `dict`, had the traditional design of an array of buckets where each bucket is a collision list. Each collision list element is called a `dictEntry` and holds a single key-value pair. The `dictEntry` structure stores three pointers, one for the key, one for the value, and one for the next `dictEntry` in the collision list. In terms of memory consumption, in a 64bit architecture, each `dictEntry` takes 24 bytes of memory.

```
    +-----------+         +-------+
    | dictEntry |    .--->| "FOO" |
    +-----------+   /     +-------+
    |    key  -----'
    |           |         +-------------------+
    |   value ----------->| serverObject      |
    |           |         +-------------------+
    |   next    |         | type, encoding,   |
    +-----|-----+         | ref-counter, etc. |
          |               | "BAR" (embedded)  |
          v               +-------------------+
    +-----------+
    | dictEntry |
    +-----------+
    |    key    |
    |   value   |
    |   next    |
    +-----|-----+
          |
          v
         ...
```

Regarding memory accesses, the above design requires at least 4 memory accesses to get the value in the case that the key is stored in the first `dictEntry` of the collision list. This might have a significant impact in cache locality when traversing the collision list search for the right key.

The new hashtable implementation improves on the memory footprint required and on the cache locality by taking a different approach on the design of each bucket. Each bucket has a fixed size of 64 bytes (in a 64bit architecture), which usually corresponds to the size of a single cache line. The bucket structure stores 7 pointers, 8 bytes each, plus 8 bytes used for metadata. The 7 pointers are used to store up to 7 entries. Keys that map to the same bucket are all stored in the same bucket. If more than 7 keys map to the same bucket, a new bucket is linked to the previous one using the last of the 7 pointers. Each entry pointer, points to an object that may embed the key and the value.

The 8 bytes of metadata is composed of 1 bit that indicated if there's child bucket linked, 7 bits that are used to indicate the presence of entries, and 7 bytes used as a secondary hash for each entry stored in the bucket.

```
       0          8       16      24      32      40      48      56      64  bytes
       +------------------------------------------------------------------+
       | Metadata | Entry | Entry | Entry | Entry | Entry | Entry | Entry |
       +------------------------------------------------------------------+
      /            ` - - . _ _
     /                         `- - . _ _
    /                                     ` - . _
   +----------------------------------------------+
   | c ppppppp hash hash hash hash hash hash hash |
   +----------------------------------------------+
    |    |       |
    |    |      One byte of hash for each entry position in the bucket.
    |    |
    |   Presence bits. One bit for each entry position, indicating if an
    |   entry present or not.
    |
   Chained? One bit. If set, the last entry is a child bucket pointer.
```

The secondary hashes are used for quickly eliminating hash collisions when looking up a key. In this way, we can avoid comparing the key for a mismatching key, except once in 256.

This new design reduces by one the number of memory accesses required to lookup an entry when there are no collisions, but it reduces a lot more memory accesses to lookup an entry when there are key mapping collisions because each bucket can store 7 entries.

It also reduces the memory footprint by a lot when there are collisions. With 3 keys mapping to the same bucket, the new design is already using less 8 bytes than the old design, which requires 72 bytes of memory (3 `dictEntry` objects). In the new design, the 64 byte bucket can store up to 7 entries, while the old design would require 168 bytes.


### Other Performance Improvements

Several performance improvements were also added to the 8.1 release, here's a list of a few of them:

#### I/O threads improvements

Following up the I/O threads improvements added in 8.0, more operations have been offloaded to the I/O thread pool in the 8.1 release, improving the throughput and latency of some operations.

In the new 8.1 release, TLS connections are now able to efficiently use I/O threads for the several phases of the protocol. The TLS negotiation, which takes non-nigliglibe amount of time to setup new connections, can now be offloaded to the I/O thread pool. This change has improved the rate of accepting new connections by around 300%.

Other sources of overhead in the TLS connection handling were identified, namely the in the calls to `SSL_pending()` and `ERR_clear_error()` functions, which were being called in the main event thread. By offloading these functions to the I/O threads pool, a throughput improvement was achieve in some operations. For instance, it was observed a 10% improvement in `SET` operations throughput, and a 22% improvement in `GET` operations throughput.

Replication traffic efficiency was also improved in 8.1 by offloading the reading of replication stream on the replicas to the I/O thread pool which means they can serve more read traffic. On the primaries, replication stream writes are now offloaded to the I/O thread pool.

#### Sorted set and hyperloglog optimisations 

Valkey 8.1 continues to add optimisations which will greatly benefit users. Leaderboards are a popular use case for Valkey using it’s sorted set data type. Retrieving the specific rank of an entry on the leaderboard is done through the ZRANK operation. 

By analyzing the performance of ZRANK, @ranshid was able to developed a new algorithm to optimise it’s performance by up to 45% depending on the size of the sorted set. 

The probabilistic hyperloglog is another great data type, used for counting unique elements in very large datasets whilst using only 12KB of memory regardless of the amount of elements. By using the  modern CPUs Advanced Vector Extensions, Valkey 8.1 can achieve a 12x speed for the operations like PFMERGE and PFCOUNT on hyperloglog data types.

## Reliability

## Extensability

Valkey is already well known by its extensability features. The sophisticated module sytem allows to extend the core system with new features developed as external modules.

In Valkey 8.1 the module system API was extended with the support for developing new scripting engines as external modules.

This new API opens the door for the development of new language and runtime alternatives to the Lua base scripts supported by the Valkey core when using `EVAL` and `FCALL` commands.

In the future we expect the emergence of new scripting engines. A good candidate is a scripting engine based on WASM, allowing `EVAL` scripts to be written in other languages than Lua and to be executed in more secure sandbox environment.

There are also benefits for existing Lua scripts, since new Lua runtimes can be easily plugged in that provide better security properties and/or better performace.

Developers that intend to build new scripting engines for Valkey should check the [Module API](https://valkey.io/topics/modules-api-ref/) documentation.


## Replication


## Observability

### Log improvements

Valkey 8.1 brings new options to the format of the logfile entries as well as the way timestamps are recorded in the logfile. This makes it easier to consume the log files by log collecting systems. 

The format of the logfile entries is controlled by the `log-format` parameter, where the default is the existing format :

- legacy :  the default, traditional log format
- logfmt : a structured log format; see https://www.brandur.org/logfmt

The formatting of the timestamp of the logfile entries is   controlled by the `log-timestamp-format` parameter, where the default is the existing format : 

- legacy: default format
- iso8601: ISO 8601 extended date and time with time zone, of the form yyyy-mm-ddThh:mm:ss.sss±hh:mm
- milliseconds: milliseconds since the epoch

An example of the format “logfmt” with the timestamp format “iso8601” :

pid=3883950 role=primary timestamp="2025-03-26T05:17:30.402-04:00" level=notice message="oO0OoO0OoO0Oo Valkey is starting oO0OoO0OoO0Oo

An example of the legacy format which remains the same :

3223494:M 18 Mar 2025 14:47:42.070 * oO0OoO0OoO0Oo Valkey is starting oO0OoO0OoO0Oo:

Note : as can be observed from the examples, using both the logfmt and iso8601 format uses around 60% more space so disk space should be considered when implementing these.

### Extending the slowlog to commandlog

Valkey has long had the capability to record slow commands during execution time based on the threshold set with  `slowlog-log-slower-than` parameter to keep the last `slowlog-max-len` entries.

The new COMMANDLOG feature expands the recording of slow commands beyond execution time by adding recording of large requests and replies. These metrics do not necessarily affect execution time but do affect the overall round trip to the application and impact network usage. 

The following parameters configure the recording of COMMANDLOG:
Equivalent to slowlog :
`commandlog-execution-slower-than` 
 `slowlog-log-slower-than`

Request size :
`commandlog-request-larger-than` : [ 1048576 ] request over this size in bytes will be recorded
`commandlog-large-request-max-len` : [ 128 ] number of latest entries to keep

Reply size :
`commandlog-reply-larger-than` : [ 1048576 ] replies over this size in bytes will be recorded
`commandlog-large-reply-max-len` : [ 128 ] number of latest entries to keep

Note : the existing SLOWLOG commands and parameters remain available. The slowlog parameters or the commandlog-execution parameters can be used interchangeably.

#### Improved latency insights

Valkey has a built-in latency monitoring framework which samples latency-sensitive code paths such as for example fork when enabled through `latency-monitor-threshold` https://valkey.io/topics/latency-monitor/. 

The new feature adds to additional metrics to the LATENCY LATEST command that reports on the latest latency events that have been collected. The additional information in Valkey 8.1 reports on the total of the recorded latencies as well as the number recorded spikes for this event. These additional field allow greater insight over Valkey 8 where only the maximum and latest spikes where recorded and reported.

https://valkey.io/commands/latency-latest/

## Additional Highlights

### valkey-benchmark reading from replicas option

`valkey-benchmark` is a commonly used tool to baseline Redis and Valkey performance to compare between different software versions, different hardware or deployments etc. It already had a cluster-aware mode but did not have the ability to run against any replicas as part of the benchmark. 

Valkey replicas are commonly deployed in production to increase availability and can serve read operations. With the Valkey 8.1 addition to read from replicas to valkey-benchmark, this allows for benchmark against these more production like deployments.

Syntax :
`valkey-benchmark` … -- rfr <yes/no/all>

-- rfr yes : the benchmark includes the replicas
-- rfr no : the benchmark only runs against the primary
-- rfr all : the benchmark includes primary and replicas

Note : this option is ONLY available for Valkey cluster deployments so needs to be run with -- cluster
Note : this option does not include the ability to :
    1. distribute writes to primaries and reads to replicas in the ALL mode
    2. not execute writes in the YES mode. Writes are simply failed so the benchmark should be run with specific read commands only in YES mode.

### Conditional updates

This new functionality allows Valkey users to perform conditional updates using the SET command if the given comparison-value matches the key’s current value. This is a not only a quality-of-life improvement for developers as they no longer need to add this condition to their application code, it also saves a roundtrip to first get a value and then compare it before a SET. When using the optional GET as part of the SET IFEQ, the existing value is returned regardless whether it matches the comparison-value.

Syntax:

    SET key value [ NX | XX | IFEQ comparison-value ] [ GET ] [ EX seconds | PX milliseconds | EXAT unix-time-seconds | PXAT unix-time-milliseconds | KEEPTTL ]

## Conclusion

Valkey 8.1 continues the path of innovation and improvements, transparantly bringing more performance and reliability to the user.  We look forward to hearing what you achieve with Valkey 8.1!

## THANK YOU
We appreciate the efforts of all who contributed code to this release!

Karthik Subbarao (KarthikSubbarao), Xuyang WANG (Nugine), Yury Fridlyand (Yury-Fridlyand), Ben Totten (bentotten), Danish Mehmood (danish-mehmood),
Eran Ifrah (eifrah-aws), gmbnomis, kronwerk, Stefan Mueller (muelstefamzn), Ran Shidlansik (ranshid), secwall, Tal Shachar (talxsha),
Uri Yagelnik (uriyage), Basel Naamna (xbasel), Alan Scherger (flyinprogrammer), Amit Nagler (naglera), Binbin (enjoy-binbin),
Caiyi Wu (Codebells), Guillaume Koenig (knggk), Harkrishn Patro (hpatro), Jacob Murphy (murphyjacob4), Jim Brunner (JimB123), Josef Šimánek (simi),
Jungwoo Song (bluayer), Karthick Ariyaratnam (karthyuom), Lipeng Zhu (lipzhu), Madelyn Olson (madolson), Masahiro Ide (imasahiro), Melroy van den Berg (melroy89),
Mikhail Koviazin (mkmkme), Nadav Gigi (NadavGigi), Nadav Levanoni (nadav-levanoni), Nikhil Manglore (Nikhil-Manglore), Parth Patel (parthpatel), Pierre (pieturin),
Ping Xie (PingXie), Qu Chen (QuChen88), Rain Valentine (SoftlyRaining), Ray Cao (RayaCoo), Ricardo Dias (rjd15372), Romain Geissler (Romain-Geissler-1A),
Roman Gershman (romange), Roshan Khatri (roshkhatri), Rueian (rueian), Sarthak Aggarwal (sarthakaggarwal97), Seungmin Lee (sungming2), Shai Zarka (zarkash-aws),
Shivshankar (Shivshankar-Reddy), Sinkevich Artem (ArtSin), Stav Ben-Tov (stav-bentov), Thalia Archibald (thaliaarchi), Vadym Khoptynets (poiuj),
Viktor Söderqvist (zuiderkwast), Viktor Szépe (szepeviktor), Vu Diep (vudiep411), Wen Hui (hwware), Yanqi Lv (lyq2333), Zvi Schneider (zvi-code),
bodong.ybd (yangbodong22011), chx9 (chx9), otheng (otheng03), skyfirelee (artikell), xingbowang (xingbowang), zhaozhao.zz (soloestoy), zhenwei pi(pizhenwei),
zixuan zhao (azuredream), 烈香 (hengyoush), 风去幽墨 (fengquyoumo)
